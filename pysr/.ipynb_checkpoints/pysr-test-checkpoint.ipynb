{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e649e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Loaded data\n"
     ]
    }
   ],
   "source": [
    "import torch, pickle, time, os, random\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.loader import DataLoader\n",
    "# accelerate huggingface to GPU\n",
    "if torch.cuda.is_available():\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator()\n",
    "    device = accelerator.device\n",
    "from pysr import pysr, best\n",
    "from tqdm import tqdm\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "print('Loading data')\n",
    "\n",
    "case='vlarge_all_4t_z0.0_standard_raw'\n",
    "\n",
    "datat=pickle.load(open(osp.expanduser(f'~/../../../scratch/gpfs/cj1223/GraphStorage/{case}/data.pkl'), 'rb'))\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "data=[]\n",
    "for d in datat:\n",
    "    data.append(Data(x=d.x[:,[0,3,4,19,20]], edge_index=d.edge_index, edge_attr=d.edge_attr, y=d.y[0]))\n",
    "\n",
    "try:\n",
    "    n_targ=len(data[0].y)\n",
    "except:\n",
    "    n_targ=1\n",
    "n_feat=len(data[0].x[0])\n",
    "n_feat, n_targ\n",
    "\n",
    "print('Loaded data')\n",
    "\n",
    "from torch.nn import ReLU, Linear, Module, LayerNorm, Sequential\n",
    "class MLP(Module):\n",
    "    def __init__(self, n_in, n_out, hidden=128, nlayers=2, layer_norm=True):\n",
    "        super().__init__()\n",
    "        layers = [Linear(n_in, hidden), ReLU()]\n",
    "        for i in range(nlayers):\n",
    "            layers.append(Linear(hidden, hidden))\n",
    "            layers.append(ReLU()) \n",
    "        if layer_norm:\n",
    "            layers.append(LayerNorm(hidden)) #yay\n",
    "        layers.append(Linear(hidden, n_out))\n",
    "        self.mlp = Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "461c14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_add_pool\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, n_outs=3, hidden_channels=64, n_feat=5, n_targ=1):\n",
    "        super(GCN, self).__init__()\n",
    "        self.g1 = MLP(n_feat, n_outs, hidden = hidden_channels)\n",
    "        self.g2 = MLP(n_outs, n_outs,  hidden = hidden_channels)\n",
    "        self.g3= MLP(n_outs, n_outs, hidden = hidden_channels) \n",
    "    \n",
    "        self.f = MLP(n_outs, n_targ,  hidden = hidden_channels)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        \n",
    "        x = self.g1(x)\n",
    "        \n",
    "#         global adj, batch1, xe\n",
    "        adj = edge_index\n",
    "#         global neighbours\n",
    "#         global N_sum\n",
    "        neighbours = x\n",
    "        batch1=batch\n",
    "        \n",
    "        N_sum = scatter_add(x[adj[0]],adj[1], dim=0)\n",
    "        xe = self.g2(N_sum)\n",
    "        x[adj[1]]+=xe[adj[1]] #only add where we have receiving nodes\n",
    "        x = self.g3(x)\n",
    "\n",
    "        x = global_add_pool(x, batch)\n",
    "\n",
    "        x = self.f(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = GCN(hidden_channels=64)\n",
    "next(model.parameters()).is_cuda ##check number one\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "criterion = torch.nn.MSELoss()\n",
    "# criterion = torch.nn.L1Loss()\n",
    "# criterion = torch.nn.SmoothL1Loss(beta=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "030cb3c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU  False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs=15\n",
    "n_trials=1\n",
    "batch_size=int(2**8)\n",
    "split=0.8\n",
    "test_data=data[int(len(data)*split):]\n",
    "train_data=data[:int(len(data)*split)]\n",
    "# train_data, test_data=train_test_split(data, test_size=0.2)\n",
    "l1_lambda = 1e-4\n",
    "l2_lambda = 0\n",
    "hidden = 128\n",
    "\n",
    "yss, preds=[],[]\n",
    "model = GCN(hidden_channels=hidden)\n",
    "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=1, num_workers=4)\n",
    "\n",
    "test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=0, num_workers=4)    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "print('GPU ', next(model.parameters()).is_cuda)\n",
    "# Initialize our train function\n",
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    for data in tqdm(train_loader, total=len(train_loader)): \n",
    "#         print('batch')\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        loss = criterion(out, data.y.view(-1,1)) \n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "\n",
    "\n",
    "        loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad() \n",
    "#     print(loss, l1_norm*l1_lambda, l2_norm*l2_lambda)\n",
    " # test function\n",
    "\n",
    "def test(loader): ##### transform back missing\n",
    "    model.eval()\n",
    "    outs = []\n",
    "    ys = []\n",
    "    with torch.no_grad(): ##this solves it!!!\n",
    "        for dat in tqdm(loader, total=len(loader)): \n",
    "            \n",
    "            out = model(dat.x, dat.edge_index, dat.batch) \n",
    "            ys.append(dat.y.view(-1,n_targ))\n",
    "            outs.append(out)\n",
    "    outss=torch.vstack(outs)\n",
    "    yss=torch.vstack(ys)\n",
    "    return torch.std(outss - yss, axis=0), outss, yss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf75f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 341/341 [02:52<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 341/341 [02:53<00:00,  1.96it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 341/341 [01:12<00:00,  4.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 86/86 [00:18<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train scatter: [0.3627] \n",
      "         Test scatter: [0.3612]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 341/341 [02:53<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 341/341 [02:53<00:00,  1.96it/s]\n",
      " 92%|████████████████████████████████████████████████████████▎    | 315/341 [01:07<00:05,  4.45it/s]"
     ]
    }
   ],
   "source": [
    "#this uses about 1 GB of memory on the GPU\n",
    "n_epochs = 10 \n",
    "l2_lambda =1e-5 #don't know if this is relevant\n",
    "tr_acc, te_acc = [], []\n",
    "start=time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    print(epoch)\n",
    "    train()\n",
    "    if (epoch+1)%2==0:\n",
    "        train_acc, _ , _ = test(train_loader)\n",
    "        test_acc, _ , _ = test(test_loader)\n",
    "        tr_acc.append(train_acc.cpu())\n",
    "        te_acc.append(test_acc.cpu())\n",
    "        print(f'Epoch: {epoch+1:03d}, Train scatter: {np.round(train_acc.cpu().numpy(), 4)} \\n \\\n",
    "        Test scatter: {np.round(test_acc.cpu().numpy(), 4)}')\n",
    "stop=time.time()\n",
    "spent=stop-start\n",
    "print(f\"{spent:.2f} seconds spent training, {spent/n_epochs:.3f} seconds per epoch. Processed {len(data)*split*n_epochs/spent:.0f} trees per second\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "\n",
    "today = today.strftime(\"%d%m%y\")\n",
    "\n",
    "torch.save(model.state_dict(),f'trained_models/model_{epoch}_{today}.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8244594",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channelse=128)\n",
    "model.load_state_dict(torch.load(f'trained_models', f'model_{epoch}_{date}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c81daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder tensor(2.2795, grad_fn=<MulBackward0>)\n",
      "encoder tensor(1.3704, grad_fn=<MulBackward0>)\n",
      "edge tensor(0.1375, grad_fn=<MulBackward0>)\n",
      "both tensor(1.4758, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('decoder', sum(p.abs().sum() for p in model.f.parameters())/sum(p.numel() for p in model.f.parameters())*100)\n",
    "\n",
    "print('encoder', sum(p.abs().sum() for p in model.g1.parameters())/sum(p.numel() for p in model.g1.parameters())*100)\n",
    "print('edge', sum(p.abs().sum() for p in model.g2.parameters())/sum(p.numel() for p in model.g2.parameters())*100)\n",
    "print('both', sum(p.abs().sum() for p in model.g3.parameters())/sum(p.numel() for p in model.g3.parameters())*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d290ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(osp.join(pointer, model_runs[k], 'trained_model', 'model.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d621ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_f = []\n",
    "y_g1 = []\n",
    "y_g2 = []\n",
    "y_g3 = []\n",
    "x_g1 = []\n",
    "y_t = []\n",
    "batch = []\n",
    "for dat in test_loader:\n",
    "    x_g1.append(dat.x.cpu().detach().numpy())\n",
    "    yg1=model.g1(dat.x)\n",
    "    y_g1.append(yg1.cpu().detach().numpy())\n",
    "    \n",
    "    adj = dat.edge_index\n",
    "    neighbours = yg1\n",
    "    \n",
    "    yg2=model.g2(scatter_add(neighbours[adj[0]], adj[1], dim=0))\n",
    "    y_g2.append(yg2.cpu().detach().numpy())\n",
    "    \n",
    "    yg1[adj[1]]+=yg2[adj[1]]\n",
    "    \n",
    "    yg3 = model.g3(yg1)\n",
    "    \n",
    "    x_f = global_add_pool(yg3, dat.batch)\n",
    "    \n",
    "    yf = model.f(x_f)\n",
    "    y_f.append(yf.cpu().detach().numpy())\n",
    "    \n",
    "    batch.append(dat.batch.cpu().detach().numpy())\n",
    "    y_t.append(dat.y.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=25\n",
    "vals, counts = np.unique(batch[0], return_counts=1)\n",
    "l = np.cumsum(counts)[N-1]\n",
    "x_g1_pysr=np.vstack(x_g1[0][:l])\n",
    "y_g1_pysr=np.vstack(y_g1[0][:l])\n",
    "\n",
    "b_pysr = batch[0][:l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "g1_equations = pysr(\n",
    "    X=x_g1_pysr, y=y_g1_pysr,\n",
    "    procs=4,\n",
    "    niterations=20,\n",
    "    populations=20,\n",
    "    useFrequency=True,\n",
    "    multithreading=True, \n",
    "    binary_operators=[\"plus\", \"sub\", \"mult\", \"div\"],\n",
    "    unary_operators = ['log10_abs', 'sqrt_abs'], ##still need a general power law\n",
    "    batching=1, \n",
    "    batchSize=256,\n",
    "    maxsize=10, update=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3ef6a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pysr in module pysr.sr:\n",
      "\n",
      "pysr(X, y, weights=None, binary_operators=None, unary_operators=None, procs=4, loss='L2DistLoss()', populations=20, niterations=100, ncyclesperiteration=300, alpha=0.1, annealing=False, fractionReplaced=0.1, fractionReplacedHof=0.1, npop=1000, parsimony=0.0001, migration=True, hofMigration=True, shouldOptimizeConstants=True, topn=10, weightAddNode=1, weightInsertNode=3, weightDeleteNode=3, weightDoNothing=1, weightMutateConstant=10, weightMutateOperator=1, weightRandomize=1, weightSimplify=0.01, perturbationFactor=1.0, timeout=None, extra_sympy_mappings=None, extra_torch_mappings=None, extra_jax_mappings=None, equation_file=None, verbosity=1000000000.0, progress=None, maxsize=20, fast_cycle=False, maxdepth=None, variable_names=None, batching=False, batchSize=50, select_k_features=None, warmupMaxsizeBy=0.0, constraints=None, useFrequency=True, tempdir=None, delete_tempfiles=True, julia_optimization=3, julia_project=None, user_input=True, update=True, temp_equation_file=False, output_jax_format=False, output_torch_format=False, optimizer_algorithm='BFGS', optimizer_nrestarts=3, optimize_probability=1.0, optimizer_iterations=10, tournament_selection_n=10, tournament_selection_p=1.0, denoise=False, Xresampled=None, precision=32, multithreading=None)\n",
      "    Run symbolic regression to fit f(X[i, :]) ~ y[i] for all i.\n",
      "    Note: most default parameters have been tuned over several example\n",
      "    equations, but you should adjust `niterations`,\n",
      "    `binary_operators`, `unary_operators` to your requirements.\n",
      "    You can view more detailed explanations of the options on the\n",
      "    [options page](https://pysr.readthedocs.io/en/latest/docs/options/) of the documentation.\n",
      "    \n",
      "    :param X: 2D array. Rows are examples, columns are features. If pandas DataFrame, the columns are used for variable names (so make sure they don't contain spaces).\n",
      "    :type X: np.ndarray/pandas.DataFrame\n",
      "    :param y: 1D array (rows are examples) or 2D array (rows are examples, columns are outputs). Putting in a 2D array will trigger a search for equations for each feature of y.\n",
      "    :type y: np.ndarray\n",
      "    :param weights: same shape as y. Each element is how to weight the mean-square-error loss for that particular element of y.\n",
      "    :type weights: np.ndarray\n",
      "    :param binary_operators: List of strings giving the binary operators in Julia's Base. Default is [\"+\", \"-\", \"*\", \"/\",].\n",
      "    :type binary_operators: list\n",
      "    :param unary_operators: Same but for operators taking a single scalar. Default is [].\n",
      "    :type unary_operators: list\n",
      "    :param procs: Number of processes (=number of populations running).\n",
      "    :type procs: int\n",
      "    :param loss: String of Julia code specifying the loss function.  Can either be a loss from LossFunctions.jl, or your own loss written as a function. Examples of custom written losses include: `myloss(x, y) = abs(x-y)` for non-weighted, or `myloss(x, y, w) = w*abs(x-y)` for weighted.  Among the included losses, these are as follows. Regression: `LPDistLoss{P}()`, `L1DistLoss()`, `L2DistLoss()` (mean square), `LogitDistLoss()`, `HuberLoss(d)`, `L1EpsilonInsLoss(ϵ)`, `L2EpsilonInsLoss(ϵ)`, `PeriodicLoss(c)`, `QuantileLoss(τ)`.  Classification: `ZeroOneLoss()`, `PerceptronLoss()`, `L1HingeLoss()`, `SmoothedL1HingeLoss(γ)`, `ModifiedHuberLoss()`, `L2MarginLoss()`, `ExpLoss()`, `SigmoidLoss()`, `DWDMarginLoss(q)`.\n",
      "    :type loss: str\n",
      "    :param populations: Number of populations running.\n",
      "    :type populations: int\n",
      "    :param niterations: Number of iterations of the algorithm to run. The best equations are printed, and migrate between populations, at the end of each.\n",
      "    :type niterations: int\n",
      "    :param ncyclesperiteration: Number of total mutations to run, per 10 samples of the population, per iteration.\n",
      "    :type ncyclesperiteration: int\n",
      "    :param alpha: Initial temperature.\n",
      "    :type alpha: float\n",
      "    :param annealing: Whether to use annealing. You should (and it is default).\n",
      "    :type annealing: bool\n",
      "    :param fractionReplaced: How much of population to replace with migrating equations from other populations.\n",
      "    :type fractionReplaced: float\n",
      "    :param fractionReplacedHof: How much of population to replace with migrating equations from hall of fame.\n",
      "    :type fractionReplacedHof: float\n",
      "    :param npop: Number of individuals in each population\n",
      "    :type npop: int\n",
      "    :param parsimony: Multiplicative factor for how much to punish complexity.\n",
      "    :type parsimony: float\n",
      "    :param migration: Whether to migrate.\n",
      "    :type migration: bool\n",
      "    :param hofMigration: Whether to have the hall of fame migrate.\n",
      "    :type hofMigration: bool\n",
      "    :param shouldOptimizeConstants: Whether to numerically optimize constants (Nelder-Mead/Newton) at the end of each iteration.\n",
      "    :type shouldOptimizeConstants: bool\n",
      "    :param topn: How many top individuals migrate from each population.\n",
      "    :type topn: int\n",
      "    :param perturbationFactor: Constants are perturbed by a max factor of (perturbationFactor*T + 1). Either multiplied by this or divided by this.\n",
      "    :type perturbationFactor: float\n",
      "    :param weightAddNode: Relative likelihood for mutation to add a node\n",
      "    :type weightAddNode: float\n",
      "    :param weightInsertNode: Relative likelihood for mutation to insert a node\n",
      "    :type weightInsertNode: float\n",
      "    :param weightDeleteNode: Relative likelihood for mutation to delete a node\n",
      "    :type weightDeleteNode: float\n",
      "    :param weightDoNothing: Relative likelihood for mutation to leave the individual\n",
      "    :type weightDoNothing: float\n",
      "    :param weightMutateConstant: Relative likelihood for mutation to change the constant slightly in a random direction.\n",
      "    :type weightMutateConstant: float\n",
      "    :param weightMutateOperator: Relative likelihood for mutation to swap an operator.\n",
      "    :type weightMutateOperator: float\n",
      "    :param weightRandomize: Relative likelihood for mutation to completely delete and then randomly generate the equation\n",
      "    :type weightRandomize: float\n",
      "    :param weightSimplify: Relative likelihood for mutation to simplify constant parts by evaluation\n",
      "    :type weightSimplify: float\n",
      "    :param timeout: Time in seconds to timeout search\n",
      "    :type timeout: float\n",
      "    :param equation_file: Where to save the files (.csv separated by |)\n",
      "    :type equation_file: str\n",
      "    :param verbosity: What verbosity level to use. 0 means minimal print statements.\n",
      "    :type verbosity: int\n",
      "    :param progress: Whether to use a progress bar instead of printing to stdout.\n",
      "    :type progress: bool\n",
      "    :param maxsize: Max size of an equation.\n",
      "    :type maxsize: int\n",
      "    :param maxdepth: Max depth of an equation. You can use both maxsize and maxdepth.  maxdepth is by default set to = maxsize, which means that it is redundant.\n",
      "    :type maxdepth: int\n",
      "    :param fast_cycle: (experimental) - batch over population subsamples. This is a slightly different algorithm than regularized evolution, but does cycles 15% faster. May be algorithmically less efficient.\n",
      "    :type fast_cycle: bool\n",
      "    :param variable_names: a list of names for the variables, other than \"x0\", \"x1\", etc.\n",
      "    :type variable_names: list\n",
      "    :param batching: whether to compare population members on small batches during evolution. Still uses full dataset for comparing against hall of fame.\n",
      "    :type batching: bool\n",
      "    :param batchSize: the amount of data to use if doing batching.\n",
      "    :type batchSize: int\n",
      "    :param select_k_features: whether to run feature selection in Python using random forests, before passing to the symbolic regression code. None means no feature selection; an int means select that many features.\n",
      "    :type select_k_features: None/int\n",
      "    :param warmupMaxsizeBy: whether to slowly increase max size from a small number up to the maxsize (if greater than 0).  If greater than 0, says the fraction of training time at which the current maxsize will reach the user-passed maxsize.\n",
      "    :type warmupMaxsizeBy: float\n",
      "    :param constraints: dictionary of int (unary) or 2-tuples (binary), this enforces maxsize constraints on the individual arguments of operators. E.g., `'pow': (-1, 1)` says that power laws can have any complexity left argument, but only 1 complexity exponent. Use this to force more interpretable solutions.\n",
      "    :type constraints: dict\n",
      "    :param useFrequency: whether to measure the frequency of complexities, and use that instead of parsimony to explore equation space. Will naturally find equations of all complexities.\n",
      "    :type useFrequency: bool\n",
      "    :param julia_optimization: Optimization level (0, 1, 2, 3)\n",
      "    :type julia_optimization: int\n",
      "    :param tempdir: directory for the temporary files\n",
      "    :type tempdir: str/None\n",
      "    :param delete_tempfiles: whether to delete the temporary files after finishing\n",
      "    :type delete_tempfiles: bool\n",
      "    :param julia_project: a Julia environment location containing a Project.toml (and potentially the source code for SymbolicRegression.jl).  Default gives the Python package directory, where a Project.toml file should be present from the install.\n",
      "    :type julia_project: str/None\n",
      "    :param user_input: Whether to ask for user input or not for installing (to be used for automated scripts). Will choose to install when asked.\n",
      "    :type user_input: bool\n",
      "    :param update: Whether to automatically update Julia packages.\n",
      "    :type update: bool\n",
      "    :param temp_equation_file: Whether to put the hall of fame file in the temp directory. Deletion is then controlled with the delete_tempfiles argument.\n",
      "    :type temp_equation_file: bool\n",
      "    :param output_jax_format: Whether to create a 'jax_format' column in the output, containing jax-callable functions and the default parameters in a jax array.\n",
      "    :type output_jax_format: bool\n",
      "    :param output_torch_format: Whether to create a 'torch_format' column in the output, containing a torch module with trainable parameters.\n",
      "    :type output_torch_format: bool\n",
      "    :param tournament_selection_n: Number of expressions to consider in each tournament.\n",
      "    :type tournament_selection_n: int\n",
      "    :param tournament_selection_p: Probability of selecting the best expression in each tournament. The probability will decay as p*(1-p)^n for other expressions, sorted by loss.\n",
      "    :type tournament_selection_p: float\n",
      "    :param denoise: Whether to use a Gaussian Process to denoise the data before inputting to PySR. Can help PySR fit noisy data.\n",
      "    :type denoise: bool\n",
      "    :param precision: What precision to use for the data. By default this is 32 (float32), but you can select 64 or 16 as well.\n",
      "    :type precision: int\n",
      "    :param multithreading: Use multithreading instead of distributed backend. Default is yes. Using procs=0 will turn off both.\n",
      "    :type multithreading: bool\n",
      "    :returns: Results dataframe, giving complexity, MSE, and equations (as strings), as well as functional forms. If list, each element corresponds to a dataframe of equations for each output.\n",
      "    :type: pd.DataFrame/list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pysr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5173c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
