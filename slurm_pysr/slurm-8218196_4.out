Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_szhonf
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:31<4:20:56, 31.38s/it]  0%|          | 2/500 [01:19<5:43:44, 41.41s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.21E+07, Train scatter: [0.9353 0.1747 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1818 0.5356 0.9851], Lowest was [0.9198 0.1818 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1818 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:51<5:04:46, 36.79s/it]  1%|          | 4/500 [02:39<5:43:10, 41.51s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 7.48E+06, Train scatter: [0.9352 0.1754 0.544  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1872 0.5354 0.985 ], Lowest was [0.9197 0.1818 0.5354 0.985 ]
Median for last 10 epochs: [0.9197 0.1845 0.5354 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:11<5:11:38, 37.77s/it]  1%|          | 6/500 [04:00<5:43:02, 41.67s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.64E+06, Train scatter: [0.9347 0.1417 0.5428 0.7271]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9191 0.1446 0.5342 0.7231], Lowest was [0.9191 0.1446 0.5342 0.7231]
Median for last 10 epochs: [0.9191 0.1446 0.5342 0.7231], Epochs since improvement 0
  1%|▏         | 7/500 [04:31<5:14:24, 38.27s/it]  2%|▏         | 8/500 [05:20<5:41:38, 41.66s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.82E+06, Train scatter: [0.9249 0.1258 0.5367 0.669 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9096 0.1268 0.5284 0.6631], Lowest was [0.9096 0.1268 0.5284 0.6631]
Median for last 10 epochs: [0.9144 0.1357 0.5313 0.6931], Epochs since improvement 0
  2%|▏         | 9/500 [05:51<5:14:31, 38.44s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.15E+06, Train scatter: [0.7548 0.1111 0.5217 0.6257]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.739  0.1129 0.514  0.6277], Lowest was [0.739  0.1129 0.514  0.6277]
Median for last 10 epochs: [0.9096 0.1268 0.5284 0.6631], Epochs since improvement 0
  2%|▏         | 10/500 [06:46<5:53:53, 43.33s/it]  2%|▏         | 11/500 [07:17<5:23:02, 39.64s/it]  2%|▏         | 12/500 [08:06<5:45:06, 42.43s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.51E+06, Train scatter: [0.615  0.108  0.4653 0.6371]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6252 0.1107 0.4642 0.6345], Lowest was [0.6252 0.1107 0.4642 0.6277]
Median for last 10 epochs: [0.9096 0.1268 0.5284 0.6631], Epochs since improvement 0
  3%|▎         | 13/500 [08:37<5:17:06, 39.07s/it]  3%|▎         | 14/500 [09:26<5:40:13, 42.00s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.75E+06, Train scatter: [0.5489 0.105  0.3711 0.6109]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5498 0.1102 0.3723 0.6202], Lowest was [0.5498 0.1102 0.3723 0.6202]
Median for last 10 epochs: [0.739  0.1129 0.514  0.6345], Epochs since improvement 0
  3%|▎         | 15/500 [09:58<5:14:35, 38.92s/it]  3%|▎         | 16/500 [10:46<5:37:18, 41.82s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.28E+06, Train scatter: [0.577  0.1012 0.3584 0.598 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5753 0.1084 0.3667 0.6068], Lowest was [0.5498 0.1084 0.3667 0.6068]
Median for last 10 epochs: [0.6252 0.1107 0.4642 0.6277], Epochs since improvement 0
  3%|▎         | 17/500 [11:17<5:11:24, 38.68s/it]  4%|▎         | 18/500 [12:06<5:35:04, 41.71s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.02E+06, Train scatter: [0.5557 0.0951 0.3551 0.6043]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5388 0.0986 0.3529 0.6046], Lowest was [0.5388 0.0986 0.3529 0.6046]
Median for last 10 epochs: [0.5753 0.1102 0.3723 0.6202], Epochs since improvement 0
  4%|▍         | 19/500 [12:37<5:09:12, 38.57s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 9.04E+05, Train scatter: [0.5446 0.0911 0.3325 0.5889]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5261 0.0946 0.3381 0.5902], Lowest was [0.5261 0.0946 0.3381 0.5902]
Median for last 10 epochs: [0.5498 0.1084 0.3667 0.6068], Epochs since improvement 0
  4%|▍         | 20/500 [13:32<5:46:15, 43.28s/it]  4%|▍         | 21/500 [14:03<5:16:50, 39.69s/it]  4%|▍         | 22/500 [14:52<5:38:43, 42.52s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 8.34E+05, Train scatter: [0.5455 0.0896 0.3262 0.5746]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5376 0.0921 0.328  0.5698], Lowest was [0.5261 0.0921 0.328  0.5698]
Median for last 10 epochs: [0.5388 0.0986 0.3529 0.6046], Epochs since improvement 0
  5%|▍         | 23/500 [15:23<5:11:10, 39.14s/it]  5%|▍         | 24/500 [16:13<5:34:21, 42.15s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.65E+05, Train scatter: [0.4933 0.0856 0.3349 0.5752]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4857 0.0865 0.3394 0.57  ], Lowest was [0.4857 0.0865 0.328  0.5698]
Median for last 10 epochs: [0.5376 0.0946 0.3394 0.5902], Epochs since improvement 0
  5%|▌         | 25/500 [16:44<5:07:55, 38.90s/it]  5%|▌         | 26/500 [17:33<5:30:22, 41.82s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 6.57E+05, Train scatter: [0.4635 0.0836 0.3148 0.5397]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4581 0.0852 0.3198 0.5376], Lowest was [0.4581 0.0852 0.3198 0.5376]
Median for last 10 epochs: [0.5261 0.0921 0.3381 0.57  ], Epochs since improvement 0
  5%|▌         | 27/500 [18:04<5:05:05, 38.70s/it]  6%|▌         | 28/500 [18:53<5:29:03, 41.83s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 5.67E+05, Train scatter: [0.6705 0.0825 0.3064 0.5563]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7387 0.0842 0.3121 0.5564], Lowest was [0.4581 0.0842 0.3121 0.5376]
Median for last 10 epochs: [0.5261 0.0865 0.328  0.5698], Epochs since improvement 0
  6%|▌         | 29/500 [19:25<5:03:58, 38.72s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 1.03E+06, Train scatter: [0.4791 0.0842 0.3072 0.5408]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4691 0.0862 0.3087 0.5396], Lowest was [0.4581 0.0842 0.3087 0.5376]
Median for last 10 epochs: [0.4857 0.0862 0.3198 0.5564], Epochs since improvement 0
  6%|▌         | 30/500 [20:19<5:39:40, 43.36s/it]  6%|▌         | 31/500 [20:50<5:10:47, 39.76s/it]  6%|▋         | 32/500 [21:39<5:32:02, 42.57s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.91E+05, Train scatter: [0.6032 0.0808 0.3042 0.5384]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5885 0.082  0.3068 0.5327], Lowest was [0.4581 0.082  0.3068 0.5327]
Median for last 10 epochs: [0.4857 0.0852 0.3121 0.5396], Epochs since improvement 0
  7%|▋         | 33/500 [22:11<5:05:07, 39.20s/it]  7%|▋         | 34/500 [23:00<5:27:39, 42.19s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.80E+05, Train scatter: [0.4483 0.0758 0.3049 0.5135]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4458 0.0767 0.3085 0.5111], Lowest was [0.4458 0.0767 0.3068 0.5111]
Median for last 10 epochs: [0.4691 0.0842 0.3087 0.5376], Epochs since improvement 0
  7%|▋         | 35/500 [23:31<5:01:37, 38.92s/it]  7%|▋         | 36/500 [24:20<5:25:06, 42.04s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 4.00E+05, Train scatter: [0.4476 0.0751 0.2991 0.5128]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4461 0.0755 0.3089 0.5066], Lowest was [0.4458 0.0755 0.3068 0.5066]
Median for last 10 epochs: [0.4691 0.082  0.3087 0.5327], Epochs since improvement 0
  7%|▋         | 37/500 [24:52<4:59:33, 38.82s/it]  8%|▊         | 38/500 [25:41<5:22:50, 41.93s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 7.13E+05, Train scatter: [0.4489 0.0806 0.3114 0.5502]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4436 0.081  0.3139 0.5491], Lowest was [0.4436 0.0755 0.3068 0.5066]
Median for last 10 epochs: [0.4461 0.081  0.3087 0.5327], Epochs since improvement 0
  8%|▊         | 39/500 [26:12<4:57:43, 38.75s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: -1.59E+05, Train scatter: [0.4    0.0722 0.2902 0.4993]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3994 0.0731 0.2953 0.4981], Lowest was [0.3994 0.0731 0.2953 0.4981]
Median for last 10 epochs: [0.4458 0.0767 0.3085 0.5111], Epochs since improvement 0
  8%|▊         | 40/500 [27:07<5:33:12, 43.46s/it]  8%|▊         | 41/500 [27:38<5:04:40, 39.83s/it]  8%|▊         | 42/500 [28:27<5:25:43, 42.67s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -7.67E+04, Train scatter: [0.4464 0.0702 0.2932 0.6441]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4413 0.0708 0.2964 0.6039], Lowest was [0.3994 0.0708 0.2953 0.4981]
Median for last 10 epochs: [0.4436 0.0755 0.3085 0.5111], Epochs since improvement 0
  9%|▊         | 43/500 [28:59<4:59:12, 39.28s/it]  9%|▉         | 44/500 [29:48<5:20:23, 42.16s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.51E+05, Train scatter: [0.291  0.068  0.2899 0.4867]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3057 0.0686 0.2961 0.4884], Lowest was [0.3057 0.0686 0.2953 0.4884]
Median for last 10 epochs: [0.4413 0.0731 0.2964 0.5066], Epochs since improvement 0
  9%|▉         | 45/500 [30:19<4:55:10, 38.93s/it]  9%|▉         | 46/500 [31:08<5:17:49, 42.00s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: -2.56E+05, Train scatter: [0.4048 0.0676 0.2906 0.4771]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.403  0.0685 0.2971 0.4778], Lowest was [0.3057 0.0685 0.2953 0.4778]
Median for last 10 epochs: [0.403  0.0708 0.2964 0.4981], Epochs since improvement 0
  9%|▉         | 47/500 [31:39<4:53:00, 38.81s/it] 10%|▉         | 48/500 [32:29<5:16:28, 42.01s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: -2.48E+05, Train scatter: [0.4171 0.0663 0.2931 0.4758]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4092 0.0674 0.2972 0.4762], Lowest was [0.3057 0.0674 0.2953 0.4762]
Median for last 10 epochs: [0.403  0.0686 0.2964 0.4884], Epochs since improvement 0
 10%|▉         | 49/500 [33:01<4:52:18, 38.89s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: -2.47E+05, Train scatter: [0.3968 0.0657 0.2879 0.4763]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3939 0.0666 0.2928 0.4773], Lowest was [0.3057 0.0666 0.2928 0.4762]
Median for last 10 epochs: [0.403  0.0685 0.2964 0.4778], Epochs since improvement 0
 10%|█         | 50/500 [33:55<5:25:54, 43.46s/it] 10%|█         | 51/500 [34:26<4:58:02, 39.83s/it] 10%|█         | 52/500 [35:15<5:18:51, 42.71s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: -2.44E+05, Train scatter: [0.3737 0.065  0.2863 0.483 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3737 0.0652 0.2908 0.4801], Lowest was [0.3057 0.0652 0.2908 0.4762]
Median for last 10 epochs: [0.3939 0.0674 0.2961 0.4778], Epochs since improvement 0
 11%|█         | 53/500 [35:47<4:52:45, 39.30s/it] 11%|█         | 54/500 [36:36<5:14:45, 42.34s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: -2.66E+05, Train scatter: [0.3674 0.0629 0.2967 0.476 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3696 0.0647 0.3    0.4834], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.3939 0.0666 0.2971 0.4778], Epochs since improvement 0
 11%|█         | 55/500 [37:07<4:49:22, 39.02s/it] 11%|█         | 56/500 [37:57<5:12:05, 42.17s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.38E+06, Train scatter: [0.9348 0.1729 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9192 0.1691 0.5355 0.9847], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.3939 0.0666 0.2972 0.4801], Epochs since improvement 2
 11%|█▏        | 57/500 [38:28<4:47:18, 38.91s/it] 12%|█▏        | 58/500 [39:17<5:08:31, 41.88s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.19E+06, Train scatter: [0.9347 0.1723 0.544  0.9936]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9192 0.1685 0.5354 0.9833], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.3939 0.0666 0.3    0.4834], Epochs since improvement 4
 12%|█▏        | 59/500 [39:49<4:44:42, 38.74s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.01E+06, Train scatter: [0.9353 0.1419 0.543  0.9754]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.139  0.5344 0.9656], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.9192 0.139  0.5344 0.9656], Epochs since improvement 6
 12%|█▏        | 60/500 [40:43<5:18:53, 43.48s/it] 12%|█▏        | 61/500 [41:15<4:51:48, 39.88s/it] 12%|█▏        | 62/500 [42:04<5:11:16, 42.64s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 5.51E+05, Train scatter: [0.9323 0.1184 0.538  0.7572]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9169 0.1172 0.5295 0.7488], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.9192 0.139  0.5344 0.9656], Epochs since improvement 8
 13%|█▎        | 63/500 [42:35<4:45:57, 39.26s/it] 13%|█▎        | 64/500 [43:24<5:07:08, 42.27s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 4.99E+05, Train scatter: [0.9312 0.1158 0.5217 0.7452]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9158 0.1146 0.5133 0.7389], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.9192 0.139  0.5344 0.9656], Epochs since improvement 10
 13%|█▎        | 65/500 [43:56<4:42:51, 39.01s/it] 13%|█▎        | 66/500 [44:45<5:04:31, 42.10s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 5.04E+05, Train scatter: [0.9302 0.1131 0.5159 0.8461]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9148 0.1118 0.5073 0.8439], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.9169 0.1172 0.5295 0.8439], Epochs since improvement 12
 13%|█▎        | 67/500 [45:16<4:40:31, 38.87s/it] 14%|█▎        | 68/500 [46:06<5:02:45, 42.05s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 5.72E+05, Train scatter: [0.9296 0.1094 0.4935 0.7455]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9143 0.1083 0.4875 0.741 ], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.9158 0.1146 0.5133 0.7488], Epochs since improvement 14
 14%|█▍        | 69/500 [46:37<4:39:06, 38.86s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.82E+05, Train scatter: [0.9273 0.1065 0.473  0.694 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9121 0.1055 0.468  0.6869], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.9148 0.1118 0.5073 0.741 ], Epochs since improvement 16
 14%|█▍        | 70/500 [47:33<5:14:57, 43.95s/it] 14%|█▍        | 71/500 [48:05<4:47:28, 40.21s/it] 14%|█▍        | 72/500 [48:53<5:05:03, 42.77s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.60E+05, Train scatter: [0.9249 0.1057 0.469  0.6861]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9098 0.1045 0.4639 0.6769], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.9143 0.1083 0.4875 0.7389], Epochs since improvement 18
 15%|█▍        | 73/500 [49:25<4:40:09, 39.37s/it] 15%|█▍        | 74/500 [50:14<5:01:17, 42.44s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.46E+05, Train scatter: [0.9195 0.1055 0.4683 0.6917]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9046 0.1041 0.4637 0.6801], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.9121 0.1055 0.468  0.6869], Epochs since improvement 20
 15%|█▌        | 75/500 [50:46<4:37:01, 39.11s/it] 15%|█▌        | 75/500 [51:35<4:52:21, 41.27s/it]
Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.15E+05, Train scatter: [0.9056 0.1054 0.4679 0.6827]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8911 0.1041 0.4635 0.6748], Lowest was [0.3057 0.0647 0.2908 0.4762]
Median for last 10 epochs: [0.9098 0.1045 0.4639 0.6801], Epochs since improvement 22
Exited after 76 epochs due to early stopping
3095.56 seconds spent training, 6.191 seconds per epoch. Processed 11248 trees per second
[0.8911009  0.10409521 0.46346432 0.6747339 ]
{'epoch_exit': 75, 'scatter_m_star': 0.8911009, 'lowest_m_star': 0.3056652, 'last20_m_star': 0.91454667, 'last10_m_star': 0.9098173, 'scatter_v_disk': 0.104095206, 'lowest_v_disk': 0.06469306, 'last20_v_disk': 0.11006867, 'last10_v_disk': 0.10450025, 'scatter_m_cold': 0.46346432, 'lowest_m_cold': 0.29078335, 'last20_m_cold': 0.49738485, 'last10_m_cold': 0.46392772, 'scatter_sfr_100': 0.6747339, 'lowest_sfr_100': 0.4761594, 'last20_sfr_100': 0.7399378, 'last10_sfr_100': 0.68011695}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_zmdwhp
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:53:47, 28.11s/it]  0%|          | 2/500 [01:12<5:10:35, 37.42s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.45E+07, Train scatter: [0.9354 0.179  0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1876 0.5357 0.9851], Lowest was [0.9198 0.1876 0.5357 0.9851]
Median for last 10 epochs: [0.9198 0.1876 0.5357 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:39<4:32:01, 32.84s/it]  1%|          | 4/500 [02:23<5:09:28, 37.44s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.48E+07, Train scatter: [0.9353 0.1758 0.5442 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1797 0.5356 0.9851], Lowest was [0.9198 0.1797 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1797 0.5356 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:51<4:38:28, 33.75s/it]  1%|          | 6/500 [03:37<5:12:16, 37.93s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.08E+07, Train scatter: [0.9354 0.1651 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.1677 0.5356 0.9851], Lowest was [0.9198 0.1677 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1677 0.5356 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:04<4:42:33, 34.39s/it]  2%|▏         | 8/500 [04:49<5:10:13, 37.83s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 9.61E+06, Train scatter: [0.9354 0.1477 0.5441 0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1478 0.5355 0.9847], Lowest was [0.9198 0.1478 0.5355 0.9847]
Median for last 10 epochs: [0.9198 0.1578 0.5356 0.9849], Epochs since improvement 0
  2%|▏         | 9/500 [05:16<4:42:54, 34.57s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.70E+06, Train scatter: [0.9352 0.1373 0.544  0.727 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1357 0.5355 0.7214], Lowest was [0.9196 0.1357 0.5355 0.7214]
Median for last 10 epochs: [0.9198 0.1478 0.5355 0.9847], Epochs since improvement 0
  2%|▏         | 10/500 [06:07<5:22:34, 39.50s/it]  2%|▏         | 11/500 [06:34<4:51:31, 35.77s/it]  2%|▏         | 12/500 [07:20<5:15:18, 38.77s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.85E+06, Train scatter: [0.9344 0.1258 0.544  0.6622]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9189 0.1236 0.5354 0.6533], Lowest was [0.9189 0.1236 0.5354 0.6533]
Median for last 10 epochs: [0.9198 0.1478 0.5355 0.9847], Epochs since improvement 0
  3%|▎         | 13/500 [07:47<4:46:25, 35.29s/it]  3%|▎         | 14/500 [08:32<5:10:01, 38.27s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.66E+06, Train scatter: [0.9181 0.1194 0.544  0.658 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.904  0.1182 0.5354 0.6532], Lowest was [0.904  0.1182 0.5354 0.6532]
Median for last 10 epochs: [0.9196 0.1357 0.5355 0.7214], Epochs since improvement 0
  3%|▎         | 15/500 [09:00<4:42:47, 34.98s/it]  3%|▎         | 16/500 [09:44<5:05:03, 37.82s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.50E+06, Train scatter: [0.8726 0.1133 0.5429 0.6216]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8625 0.1123 0.5345 0.6122], Lowest was [0.8625 0.1123 0.5345 0.6122]
Median for last 10 epochs: [0.9189 0.1236 0.5354 0.6533], Epochs since improvement 0
  3%|▎         | 17/500 [10:12<4:39:30, 34.72s/it]  4%|▎         | 18/500 [10:57<5:04:56, 37.96s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 6.25E+06, Train scatter: [0.6167 0.1074 0.5396 0.5984]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6154 0.1074 0.5313 0.594 ], Lowest was [0.6154 0.1074 0.5313 0.594 ]
Median for last 10 epochs: [0.904  0.1182 0.5354 0.6532], Epochs since improvement 0
  4%|▍         | 19/500 [11:25<4:39:45, 34.90s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 6.00E+06, Train scatter: [0.484  0.101  0.5359 0.5817]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4849 0.1013 0.5276 0.58  ], Lowest was [0.4849 0.1013 0.5276 0.58  ]
Median for last 10 epochs: [0.8625 0.1123 0.5345 0.6122], Epochs since improvement 0
  4%|▍         | 20/500 [12:14<5:14:32, 39.32s/it]  4%|▍         | 21/500 [12:42<4:45:15, 35.73s/it]  4%|▍         | 22/500 [13:27<5:07:24, 38.59s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.75E+06, Train scatter: [0.4832 0.0978 0.5301 0.5695]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4865 0.098  0.522  0.5681], Lowest was [0.4849 0.098  0.522  0.5681]
Median for last 10 epochs: [0.6154 0.1074 0.5313 0.594 ], Epochs since improvement 0
  5%|▍         | 23/500 [13:55<4:40:09, 35.24s/it]  5%|▍         | 24/500 [14:40<5:04:56, 38.44s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 5.31E+06, Train scatter: [0.4943 0.094  0.5207 0.5898]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4983 0.0947 0.5133 0.5888], Lowest was [0.4849 0.0947 0.5133 0.5681]
Median for last 10 epochs: [0.4983 0.1013 0.5276 0.5888], Epochs since improvement 0
  5%|▌         | 25/500 [15:08<4:38:32, 35.18s/it]  5%|▌         | 26/500 [15:53<5:01:45, 38.20s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.65E+06, Train scatter: [0.5474 0.0965 0.4842 0.5875]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5547 0.0977 0.4799 0.5971], Lowest was [0.4849 0.0947 0.4799 0.5681]
Median for last 10 epochs: [0.4983 0.098  0.522  0.5888], Epochs since improvement 0
  5%|▌         | 27/500 [16:21<4:36:03, 35.02s/it]  6%|▌         | 28/500 [17:07<5:00:55, 38.25s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.66E+06, Train scatter: [0.5044 0.1045 0.4599 0.6728]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4908 0.1045 0.4527 0.6525], Lowest was [0.4849 0.0947 0.4527 0.5681]
Median for last 10 epochs: [0.4908 0.098  0.5133 0.5888], Epochs since improvement 0
  6%|▌         | 29/500 [17:34<4:35:15, 35.06s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.34E+06, Train scatter: [0.5061 0.103  0.4088 0.6268]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5102 0.1071 0.4097 0.6229], Lowest was [0.4849 0.0947 0.4097 0.5681]
Median for last 10 epochs: [0.4983 0.098  0.4799 0.5971], Epochs since improvement 0
  6%|▌         | 30/500 [18:26<5:12:51, 39.94s/it]  6%|▌         | 31/500 [18:53<4:43:36, 36.28s/it]  6%|▋         | 32/500 [19:39<5:04:16, 39.01s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.80E+06, Train scatter: [0.4336 0.0976 0.3993 0.5977]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.433  0.0975 0.3986 0.5853], Lowest was [0.433  0.0947 0.3986 0.5681]
Median for last 10 epochs: [0.4983 0.0977 0.4527 0.5971], Epochs since improvement 0
  7%|▋         | 33/500 [20:06<4:37:06, 35.60s/it]  7%|▋         | 34/500 [20:52<4:59:20, 38.54s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.32E+06, Train scatter: [0.4846 0.0956 0.3541 0.5888]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4868 0.0941 0.354  0.5852], Lowest was [0.433  0.0941 0.354  0.5681]
Median for last 10 epochs: [0.4908 0.0977 0.4097 0.5971], Epochs since improvement 0
  7%|▋         | 35/500 [21:20<4:33:37, 35.31s/it]  7%|▋         | 36/500 [22:05<4:57:02, 38.41s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.08E+06, Train scatter: [0.474  0.0945 0.4145 0.5966]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.48   0.0929 0.408  0.5937], Lowest was [0.433  0.0929 0.354  0.5681]
Median for last 10 epochs: [0.4868 0.0975 0.408  0.5937], Epochs since improvement 0
  7%|▋         | 37/500 [22:33<4:31:40, 35.21s/it]  8%|▊         | 38/500 [23:18<4:54:22, 38.23s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.79E+06, Train scatter: [0.3996 0.09   0.3279 0.5613]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4172 0.0897 0.3366 0.5658], Lowest was [0.4172 0.0897 0.3366 0.5658]
Median for last 10 epochs: [0.48   0.0941 0.3986 0.5853], Epochs since improvement 0
  8%|▊         | 39/500 [23:46<4:29:53, 35.13s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.73E+06, Train scatter: [0.4015 0.0904 0.3774 0.5731]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4036 0.0899 0.3756 0.5729], Lowest was [0.4036 0.0897 0.3366 0.5658]
Median for last 10 epochs: [0.433  0.0929 0.3756 0.5852], Epochs since improvement 0
  8%|▊         | 40/500 [24:37<5:06:39, 40.00s/it]  8%|▊         | 41/500 [25:05<4:37:32, 36.28s/it]  8%|▊         | 42/500 [25:51<4:59:59, 39.30s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.56E+06, Train scatter: [0.387  0.0913 0.3322 0.5727]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3851 0.0914 0.3394 0.5738], Lowest was [0.3851 0.0897 0.3366 0.5658]
Median for last 10 epochs: [0.4172 0.0914 0.354  0.5738], Epochs since improvement 0
  9%|▊         | 43/500 [26:19<4:32:56, 35.83s/it]  9%|▉         | 44/500 [27:05<4:56:08, 38.97s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.47E+06, Train scatter: [0.3826 0.0864 0.2999 0.5396]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3838 0.0873 0.3071 0.5399], Lowest was [0.3838 0.0873 0.3071 0.5399]
Median for last 10 epochs: [0.4036 0.0899 0.3394 0.5729], Epochs since improvement 0
  9%|▉         | 45/500 [27:33<4:29:56, 35.60s/it]  9%|▉         | 46/500 [28:19<4:51:50, 38.57s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.60E+06, Train scatter: [0.331  0.0861 0.3416 0.5329]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3331 0.0866 0.3424 0.5336], Lowest was [0.3331 0.0866 0.3071 0.5336]
Median for last 10 epochs: [0.3851 0.0897 0.3394 0.5658], Epochs since improvement 0
  9%|▉         | 47/500 [28:46<4:26:30, 35.30s/it] 10%|▉         | 48/500 [29:33<4:50:56, 38.62s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.37E+06, Train scatter: [0.3264 0.0843 0.2947 0.5215]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3299 0.085  0.3037 0.5244], Lowest was [0.3299 0.085  0.3037 0.5244]
Median for last 10 epochs: [0.3838 0.0873 0.3394 0.5399], Epochs since improvement 0
 10%|▉         | 49/500 [30:00<4:25:22, 35.31s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.20E+06, Train scatter: [0.3107 0.0845 0.301  0.5371]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3166 0.0854 0.3142 0.5419], Lowest was [0.3166 0.085  0.3037 0.5244]
Median for last 10 epochs: [0.3331 0.0866 0.3142 0.5399], Epochs since improvement 0
 10%|█         | 50/500 [30:54<5:05:35, 40.74s/it] 10%|█         | 51/500 [31:21<4:35:30, 36.82s/it] 10%|█         | 52/500 [32:08<4:57:30, 39.85s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.29E+06, Train scatter: [0.2848 0.0824 0.3001 0.5278]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.292  0.084  0.3041 0.5287], Lowest was [0.292  0.084  0.3037 0.5244]
Median for last 10 epochs: [0.3299 0.0854 0.3071 0.5336], Epochs since improvement 0
 11%|█         | 53/500 [32:36<4:29:41, 36.20s/it] 11%|█         | 54/500 [33:22<4:50:23, 39.07s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.20E+06, Train scatter: [0.2871 0.0815 0.3222 0.5156]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2967 0.0825 0.3279 0.5195], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.3166 0.085  0.3142 0.5287], Epochs since improvement 0
 11%|█         | 55/500 [33:49<4:24:21, 35.64s/it] 11%|█         | 56/500 [34:35<4:46:20, 38.70s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.72E+06, Train scatter: [0.3543 0.084  0.3451 0.555 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3493 0.0851 0.3466 0.5466], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.3166 0.085  0.3142 0.5287], Epochs since improvement 2
 11%|█▏        | 57/500 [35:03<4:21:16, 35.39s/it] 12%|█▏        | 58/500 [35:49<4:44:21, 38.60s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.90E+05, Train scatter: [0.9354 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.9851], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.3166 0.0851 0.3279 0.5419], Epochs since improvement 4
 12%|█▏        | 59/500 [36:17<4:19:28, 35.30s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.78E+05, Train scatter: [0.9354 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.9851], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.3493 0.0851 0.3466 0.5466], Epochs since improvement 6
 12%|█▏        | 60/500 [37:08<4:55:25, 40.29s/it] 12%|█▏        | 61/500 [37:36<4:27:03, 36.50s/it] 12%|█▏        | 62/500 [38:22<4:46:25, 39.24s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.73E+05, Train scatter: [0.9353 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.9851], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.9197 0.169  0.5355 0.9851], Epochs since improvement 8
 13%|█▎        | 63/500 [38:49<4:20:30, 35.77s/it] 13%|█▎        | 64/500 [39:36<4:42:52, 38.93s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.69E+05, Train scatter: [0.9353 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.9851], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.9197 0.169  0.5355 0.9851], Epochs since improvement 10
 13%|█▎        | 65/500 [40:03<4:17:37, 35.54s/it] 13%|█▎        | 66/500 [40:49<4:38:22, 38.48s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.64E+05, Train scatter: [0.9353 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.9851], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.9197 0.169  0.5355 0.9851], Epochs since improvement 12
 13%|█▎        | 67/500 [41:16<4:14:13, 35.23s/it] 14%|█▎        | 68/500 [42:03<4:37:53, 38.60s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.58E+05, Train scatter: [0.9353 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.9851], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.9197 0.169  0.5355 0.9851], Epochs since improvement 14
 14%|█▍        | 69/500 [42:30<4:13:39, 35.31s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.52E+05, Train scatter: [0.9353 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.9197 0.169  0.5355 0.9851], Epochs since improvement 16
 14%|█▍        | 70/500 [43:22<4:48:52, 40.31s/it] 14%|█▍        | 71/500 [43:50<4:20:56, 36.49s/it] 14%|█▍        | 72/500 [44:36<4:41:18, 39.44s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.46E+05, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.9197 0.169  0.5355 0.9851], Epochs since improvement 18
 15%|█▍        | 73/500 [45:04<4:15:40, 35.93s/it] 15%|█▍        | 74/500 [45:50<4:35:47, 38.84s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.39E+05, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 20
 15%|█▌        | 75/500 [46:17<4:11:25, 35.50s/it] 15%|█▌        | 75/500 [47:04<4:26:44, 37.66s/it]
Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.32E+05, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.292  0.0825 0.3037 0.5195]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 22
Exited after 76 epochs due to early stopping
2824.26 seconds spent training, 5.649 seconds per epoch. Processed 12328 trees per second
[0.91955936 0.16899194 0.5354969  0.9850038 ]
{'epoch_exit': 75, 'scatter_m_star': 0.91955936, 'lowest_m_star': 0.29202232, 'last20_m_star': 0.9196931, 'last10_m_star': 0.9196249, 'scatter_v_disk': 0.16899194, 'lowest_v_disk': 0.08254916, 'last20_v_disk': 0.16899766, 'last10_v_disk': 0.16899705, 'scatter_m_cold': 0.5354969, 'lowest_m_cold': 0.30371022, 'last20_m_cold': 0.5355058, 'last10_m_cold': 0.53550977, 'scatter_sfr_100': 0.9850038, 'lowest_sfr_100': 0.51951325, 'last20_sfr_100': 0.98508286, 'last10_sfr_100': 0.98505133}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_nfkxah
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:48<6:39:28, 48.03s/it]  0%|          | 2/500 [01:59<8:34:07, 61.94s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.46E+07, Train scatter: [0.9352 0.1517 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1478 0.5356 0.9851], Lowest was [0.9196 0.1478 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1478 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:47<7:37:51, 55.27s/it]  1%|          | 4/500 [03:58<8:28:42, 61.54s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.65E+07, Train scatter: [0.9343 0.1045 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9187 0.1029 0.5355 0.9848], Lowest was [0.9187 0.1029 0.5355 0.9848]
Median for last 10 epochs: [0.9187 0.1029 0.5355 0.9848], Epochs since improvement 0
  1%|          | 5/500 [04:45<7:45:02, 56.37s/it]  1%|          | 6/500 [05:57<8:27:37, 61.65s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.15E+07, Train scatter: [0.8928 0.1171 0.544  0.8447]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8786 0.1164 0.5355 0.8345], Lowest was [0.8786 0.1029 0.5355 0.8345]
Median for last 10 epochs: [0.8786 0.1029 0.5355 0.8345], Epochs since improvement 0
  1%|▏         | 7/500 [06:44<7:48:04, 56.97s/it]  2%|▏         | 8/500 [07:55<8:22:47, 61.32s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.51E+06, Train scatter: [0.6923 0.0934 0.544  0.6251]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6817 0.093  0.5354 0.6135], Lowest was [0.6817 0.093  0.5354 0.6135]
Median for last 10 epochs: [0.7801 0.0979 0.5354 0.724 ], Epochs since improvement 0
  2%|▏         | 9/500 [08:42<7:45:01, 56.83s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 5.79E+06, Train scatter: [0.5715 0.0873 0.5439 0.5934]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5585 0.0865 0.5354 0.5875], Lowest was [0.5585 0.0865 0.5354 0.5875]
Median for last 10 epochs: [0.6817 0.093  0.5354 0.6135], Epochs since improvement 0
  2%|▏         | 10/500 [10:00<8:37:13, 63.33s/it]  2%|▏         | 11/500 [10:47<7:56:27, 58.46s/it]  2%|▏         | 12/500 [11:58<8:25:53, 62.20s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 5.14E+06, Train scatter: [0.3347 0.0804 0.5439 0.565 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3448 0.0809 0.5353 0.5626], Lowest was [0.3448 0.0809 0.5353 0.5626]
Median for last 10 epochs: [0.6817 0.093  0.5354 0.6135], Epochs since improvement 0
  3%|▎         | 13/500 [12:45<7:48:27, 57.71s/it]  3%|▎         | 14/500 [13:57<8:22:33, 62.04s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 4.75E+06, Train scatter: [0.2689 0.0778 0.5439 0.5294]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2709 0.0773 0.5353 0.5218], Lowest was [0.2709 0.0773 0.5353 0.5218]
Median for last 10 epochs: [0.5585 0.0865 0.5354 0.5875], Epochs since improvement 0
  3%|▎         | 15/500 [14:45<7:45:58, 57.65s/it]  3%|▎         | 16/500 [15:57<8:19:30, 61.92s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.10E+06, Train scatter: [0.2655 0.0768 0.5439 0.522 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2669 0.0769 0.5353 0.5188], Lowest was [0.2669 0.0769 0.5353 0.5188]
Median for last 10 epochs: [0.3448 0.0809 0.5353 0.5626], Epochs since improvement 0
  3%|▎         | 17/500 [16:44<7:42:57, 57.51s/it]  4%|▎         | 18/500 [17:56<8:17:36, 61.94s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.75E+06, Train scatter: [0.2315 0.0758 0.5438 0.5246]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2361 0.0751 0.5352 0.5154], Lowest was [0.2361 0.0751 0.5352 0.5154]
Median for last 10 epochs: [0.2709 0.0773 0.5353 0.5218], Epochs since improvement 0
  4%|▍         | 19/500 [18:43<7:40:41, 57.47s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.70E+06, Train scatter: [0.3859 0.0792 0.5437 0.5786]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3868 0.0792 0.5351 0.5843], Lowest was [0.2361 0.0751 0.5351 0.5154]
Median for last 10 epochs: [0.2709 0.0773 0.5353 0.5218], Epochs since improvement 0
  4%|▍         | 20/500 [20:02<8:30:04, 63.76s/it]  4%|▍         | 21/500 [20:49<7:49:50, 58.85s/it]  4%|▍         | 22/500 [22:01<8:19:54, 62.75s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.64E+06, Train scatter: [0.2249 0.0736 0.5436 0.5126]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2285 0.0732 0.5351 0.5078], Lowest was [0.2285 0.0732 0.5351 0.5078]
Median for last 10 epochs: [0.2669 0.0769 0.5352 0.5188], Epochs since improvement 0
  5%|▍         | 23/500 [22:48<7:42:00, 58.11s/it]  5%|▍         | 24/500 [24:00<8:14:25, 62.32s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.58E+06, Train scatter: [0.2262 0.0721 0.5436 0.5132]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2248 0.0717 0.535  0.5091], Lowest was [0.2248 0.0717 0.535  0.5078]
Median for last 10 epochs: [0.2361 0.0751 0.5351 0.5154], Epochs since improvement 0
  5%|▌         | 25/500 [24:47<7:37:42, 57.82s/it]  5%|▌         | 26/500 [26:00<8:11:04, 62.16s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.55E+06, Train scatter: [0.2047 0.0703 0.5436 0.5083]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2081 0.0701 0.535  0.5035], Lowest was [0.2081 0.0701 0.535  0.5035]
Median for last 10 epochs: [0.2285 0.0732 0.5351 0.5091], Epochs since improvement 0
  5%|▌         | 27/500 [26:47<7:35:26, 57.77s/it]  6%|▌         | 28/500 [27:59<8:07:04, 61.92s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.53E+06, Train scatter: [0.3296 0.0828 0.5435 0.5393]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3398 0.0817 0.5349 0.5373], Lowest was [0.2081 0.0701 0.5349 0.5035]
Median for last 10 epochs: [0.2285 0.0732 0.535  0.5091], Epochs since improvement 0
  6%|▌         | 29/500 [28:46<7:30:30, 57.39s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.51E+06, Train scatter: [0.2393 0.0715 0.5435 0.5051]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2403 0.071  0.535  0.5   ], Lowest was [0.2081 0.0701 0.5349 0.5   ]
Median for last 10 epochs: [0.2285 0.0717 0.535  0.5078], Epochs since improvement 0
  6%|▌         | 30/500 [30:04<8:19:27, 63.76s/it]  6%|▌         | 31/500 [30:51<7:39:09, 58.74s/it]  6%|▋         | 32/500 [32:03<8:08:18, 62.60s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.51E+06, Train scatter: [0.2185 0.0734 0.5435 0.5036]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2224 0.0728 0.5349 0.4978], Lowest was [0.2081 0.0701 0.5349 0.4978]
Median for last 10 epochs: [0.2248 0.0717 0.535  0.5035], Epochs since improvement 0
  7%|▋         | 33/500 [32:50<7:30:54, 57.93s/it]  7%|▋         | 34/500 [34:01<8:01:10, 61.95s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.48E+06, Train scatter: [0.3499 0.0938 0.5435 0.5623]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3575 0.0921 0.5349 0.5574], Lowest was [0.2081 0.0701 0.5349 0.4978]
Median for last 10 epochs: [0.2403 0.0728 0.5349 0.5035], Epochs since improvement 0
  7%|▋         | 35/500 [34:49<7:25:45, 57.52s/it]  7%|▋         | 36/500 [36:00<7:56:53, 61.67s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.53E+06, Train scatter: [0.2916 0.1289 0.5437 0.5547]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2954 0.1257 0.5351 0.5467], Lowest was [0.2081 0.0701 0.5349 0.4978]
Median for last 10 epochs: [0.2954 0.0817 0.5349 0.5373], Epochs since improvement 2
  7%|▋         | 37/500 [36:47<7:22:03, 57.29s/it]  8%|▊         | 38/500 [37:59<7:54:31, 61.63s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.28E+06, Train scatter: [0.289  0.0792 0.5436 0.524 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2844 0.0777 0.5351 0.5182], Lowest was [0.2081 0.0701 0.5349 0.4978]
Median for last 10 epochs: [0.2844 0.0777 0.535  0.5182], Epochs since improvement 4
  8%|▊         | 39/500 [38:46<7:19:45, 57.23s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.17E+06, Train scatter: [0.238  0.0796 0.5436 0.507 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2468 0.0791 0.535  0.5036], Lowest was [0.2081 0.0701 0.5349 0.4978]
Median for last 10 epochs: [0.2844 0.0791 0.535  0.5182], Epochs since improvement 6
  8%|▊         | 40/500 [40:05<8:08:27, 63.71s/it]  8%|▊         | 41/500 [40:51<7:28:42, 58.66s/it]  8%|▊         | 42/500 [42:02<7:56:01, 62.36s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.19E+06, Train scatter: [0.2614 0.1267 0.5438 0.5474]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2651 0.1239 0.5352 0.5403], Lowest was [0.2081 0.0701 0.5349 0.4978]
Median for last 10 epochs: [0.2844 0.0921 0.5351 0.5403], Epochs since improvement 8
  9%|▊         | 43/500 [42:49<7:19:53, 57.75s/it]  9%|▉         | 44/500 [44:01<7:51:16, 62.01s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.17E+06, Train scatter: [0.2597 0.0933 0.5436 0.5108]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2607 0.0915 0.535  0.506 ], Lowest was [0.2081 0.0701 0.5349 0.4978]
Median for last 10 epochs: [0.2651 0.0915 0.5351 0.5182], Epochs since improvement 10
  9%|▉         | 45/500 [44:48<7:16:09, 57.51s/it]  9%|▉         | 46/500 [46:00<7:46:56, 61.71s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.96E+06, Train scatter: [0.4588 0.0727 0.5436 0.4944]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4452 0.0716 0.5351 0.4894], Lowest was [0.2081 0.0701 0.5349 0.4894]
Median for last 10 epochs: [0.2651 0.0791 0.5351 0.506 ], Epochs since improvement 0
  9%|▉         | 47/500 [46:47<7:12:34, 57.29s/it] 10%|▉         | 48/500 [47:58<7:43:54, 61.58s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.94E+06, Train scatter: [0.3777 0.0688 0.5436 0.497 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3672 0.0678 0.535  0.4903], Lowest was [0.2081 0.0678 0.5349 0.4894]
Median for last 10 epochs: [0.2651 0.0791 0.535  0.5036], Epochs since improvement 0
 10%|▉         | 49/500 [48:46<7:10:13, 57.24s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.91E+06, Train scatter: [0.5812 0.0688 0.5435 0.5248]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5655 0.0678 0.5349 0.5194], Lowest was [0.2081 0.0678 0.5349 0.4894]
Median for last 10 epochs: [0.3672 0.0716 0.535  0.506 ], Epochs since improvement 2
 10%|█         | 50/500 [50:04<7:55:58, 63.46s/it] 10%|█         | 51/500 [50:51<7:18:00, 58.53s/it] 10%|█         | 52/500 [52:02<7:45:47, 62.38s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 2.88E+06, Train scatter: [0.3179 0.079  0.5432 0.4992]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.324  0.0776 0.5346 0.4953], Lowest was [0.2081 0.0678 0.5346 0.4894]
Median for last 10 epochs: [0.3672 0.0716 0.535  0.4953], Epochs since improvement 0
 11%|█         | 53/500 [52:49<7:10:30, 57.79s/it] 11%|█         | 54/500 [53:59<7:37:44, 61.58s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.75E+06, Train scatter: [0.2115 0.0654 0.541  0.4956]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2664 0.0652 0.5325 0.4929], Lowest was [0.2081 0.0652 0.5325 0.4894]
Median for last 10 epochs: [0.3672 0.0678 0.5349 0.4929], Epochs since improvement 0
 11%|█         | 55/500 [54:46<7:04:16, 57.20s/it] 11%|█         | 56/500 [55:58<7:34:19, 61.40s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.69E+06, Train scatter: [0.3016 0.0626 0.5345 0.5449]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4074 0.0619 0.526  0.542 ], Lowest was [0.2081 0.0619 0.526  0.4894]
Median for last 10 epochs: [0.3672 0.0678 0.5346 0.4953], Epochs since improvement 0
 11%|█▏        | 57/500 [56:45<7:01:30, 57.09s/it] 12%|█▏        | 58/500 [57:56<7:33:09, 61.52s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.58E+06, Train scatter: [0.3874 0.0627 0.5294 0.4896]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3783 0.0625 0.521  0.4842], Lowest was [0.2081 0.0619 0.521  0.4842]
Median for last 10 epochs: [0.3783 0.0652 0.5325 0.4953], Epochs since improvement 0
 12%|█▏        | 59/500 [58:44<7:00:19, 57.19s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.80E+06, Train scatter: [0.4051 0.0806 0.544  0.5511]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3986 0.0797 0.5354 0.545 ], Lowest was [0.2081 0.0619 0.521  0.4842]
Median for last 10 epochs: [0.3783 0.0652 0.5325 0.4953], Epochs since improvement 2
 12%|█▏        | 60/500 [1:00:02<7:46:43, 63.65s/it] 12%|█▏        | 61/500 [1:00:49<7:09:33, 58.71s/it] 12%|█▏        | 62/500 [1:02:00<7:35:04, 62.34s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 6.96E+06, Train scatter: [0.9359 0.1724 0.5441 0.9947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9204 0.1685 0.5355 0.9844], Lowest was [0.2081 0.0619 0.521  0.4842]
Median for last 10 epochs: [0.3986 0.0652 0.5325 0.542 ], Epochs since improvement 4
 13%|█▎        | 63/500 [1:02:47<7:00:09, 57.69s/it] 13%|█▎        | 64/500 [1:03:58<7:27:56, 61.64s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.42E+06, Train scatter: [0.8531 0.1349 0.544  0.7753]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8388 0.1336 0.5354 0.7749], Lowest was [0.2081 0.0619 0.521  0.4842]
Median for last 10 epochs: [0.4074 0.0797 0.5354 0.545 ], Epochs since improvement 6
 13%|█▎        | 65/500 [1:04:45<6:55:17, 57.28s/it] 13%|█▎        | 66/500 [1:05:56<7:23:23, 61.30s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.21E+06, Train scatter: [0.6138 0.1116 0.5439 0.6897]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6238 0.1103 0.5353 0.6837], Lowest was [0.2081 0.0619 0.521  0.4842]
Median for last 10 epochs: [0.6238 0.1103 0.5354 0.6837], Epochs since improvement 8
 13%|█▎        | 67/500 [1:06:43<6:51:22, 57.00s/it] 14%|█▎        | 68/500 [1:07:54<7:20:39, 61.20s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.13E+06, Train scatter: [0.5837 0.1046 0.5431 0.6371]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5791 0.1019 0.5345 0.6242], Lowest was [0.2081 0.0619 0.521  0.4842]
Median for last 10 epochs: [0.6238 0.1103 0.5354 0.6837], Epochs since improvement 10
 14%|█▍        | 69/500 [1:08:41<6:49:00, 56.94s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.01E+06, Train scatter: [0.5464 0.0938 0.5318 0.5922]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.545  0.093  0.524  0.5901], Lowest was [0.2081 0.0619 0.521  0.4842]
Median for last 10 epochs: [0.6238 0.1103 0.5353 0.6837], Epochs since improvement 12
 14%|█▍        | 70/500 [1:09:59<7:33:12, 63.24s/it] 14%|█▍        | 71/500 [1:10:46<6:57:19, 58.37s/it] 14%|█▍        | 72/500 [1:11:57<7:23:30, 62.17s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 2.91E+06, Train scatter: [0.549  0.0927 0.527  0.5744]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5394 0.0914 0.5189 0.5717], Lowest was [0.2081 0.0619 0.5189 0.4842]
Median for last 10 epochs: [0.5791 0.1019 0.5345 0.6242], Epochs since improvement 0
 15%|█▍        | 73/500 [1:12:44<6:49:53, 57.60s/it] 15%|█▍        | 74/500 [1:13:56<7:19:40, 61.93s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.72E+06, Train scatter: [0.5591 0.0969 0.5116 0.5945]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5639 0.098  0.5058 0.6022], Lowest was [0.2081 0.0619 0.5058 0.4842]
Median for last 10 epochs: [0.5639 0.098  0.524  0.6022], Epochs since improvement 0
 15%|█▌        | 75/500 [1:14:43<6:46:50, 57.44s/it] 15%|█▌        | 76/500 [1:15:55<7:16:36, 61.78s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.95E+06, Train scatter: [0.4938 0.1018 0.5432 0.6508]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.49   0.1011 0.5348 0.6377], Lowest was [0.2081 0.0619 0.5058 0.4842]
Median for last 10 epochs: [0.545  0.098  0.524  0.6022], Epochs since improvement 2
 15%|█▌        | 77/500 [1:16:42<6:44:12, 57.34s/it] 16%|█▌        | 78/500 [1:17:52<7:10:29, 61.21s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.98E+06, Train scatter: [0.6217 0.1061 0.5439 0.6637]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6298 0.1049 0.5354 0.6598], Lowest was [0.2081 0.0619 0.5058 0.4842]
Median for last 10 epochs: [0.545  0.098  0.524  0.6022], Epochs since improvement 4
 16%|█▌        | 79/500 [1:18:39<6:40:37, 57.10s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.75E+06, Train scatter: [0.5963 0.1077 0.5105 0.682 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.614  0.1063 0.5037 0.6719], Lowest was [0.2081 0.0619 0.5037 0.4842]
Median for last 10 epochs: [0.5639 0.1011 0.5189 0.6377], Epochs since improvement 0
 16%|█▌        | 80/500 [1:19:57<7:23:25, 63.35s/it] 16%|█▌        | 81/500 [1:20:44<6:47:55, 58.41s/it] 16%|█▋        | 82/500 [1:21:56<7:14:38, 62.39s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.24E+06, Train scatter: [0.5947 0.1083 0.4486 0.67  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5986 0.1085 0.4452 0.6671], Lowest was [0.2081 0.0619 0.4452 0.4842]
Median for last 10 epochs: [0.5986 0.1049 0.5058 0.6598], Epochs since improvement 0
 17%|█▋        | 83/500 [1:22:43<6:41:52, 57.82s/it] 17%|█▋        | 84/500 [1:23:53<7:07:23, 61.64s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 1.92E+06, Train scatter: [0.5498 0.0987 0.4166 0.6495]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.539  0.0987 0.4173 0.649 ], Lowest was [0.2081 0.0619 0.4173 0.4842]
Median for last 10 epochs: [0.5986 0.1049 0.5037 0.6598], Epochs since improvement 0
 17%|█▋        | 85/500 [1:24:41<6:36:11, 57.28s/it] 17%|█▋        | 86/500 [1:25:51<7:03:10, 61.33s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 1.53E+06, Train scatter: [0.5481 0.0962 0.416  0.6255]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.546  0.0969 0.4172 0.6217], Lowest was [0.2081 0.0619 0.4172 0.4842]
Median for last 10 epochs: [0.5986 0.1049 0.4452 0.6598], Epochs since improvement 0
 17%|█▋        | 87/500 [1:26:39<6:32:54, 57.08s/it] 18%|█▊        | 88/500 [1:27:49<6:58:53, 61.00s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 1.27E+06, Train scatter: [0.548  0.0808 0.3539 0.5968]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5361 0.0807 0.3541 0.5927], Lowest was [0.2081 0.0619 0.3541 0.4842]
Median for last 10 epochs: [0.546  0.0987 0.4173 0.649 ], Epochs since improvement 0
 18%|█▊        | 89/500 [1:28:36<6:29:08, 56.81s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 9.98E+05, Train scatter: [0.5156 0.0736 0.3412 0.5883]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.507  0.0741 0.3449 0.5872], Lowest was [0.2081 0.0619 0.3449 0.4842]
Median for last 10 epochs: [0.539  0.0969 0.4172 0.6217], Epochs since improvement 0
 18%|█▊        | 90/500 [1:29:53<7:10:46, 63.04s/it] 18%|█▊        | 91/500 [1:30:40<6:37:06, 58.26s/it] 18%|█▊        | 92/500 [1:31:51<7:02:15, 62.10s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 9.75E+05, Train scatter: [0.4684 0.0847 0.3445 0.5924]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.46   0.085  0.3459 0.5845], Lowest was [0.2081 0.0619 0.3449 0.4842]
Median for last 10 epochs: [0.5361 0.085  0.3541 0.5927], Epochs since improvement 2
 19%|█▊        | 93/500 [1:32:38<6:30:25, 57.56s/it] 19%|█▉        | 94/500 [1:33:50<6:57:45, 61.74s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 7.87E+05, Train scatter: [0.6163 0.0717 0.3127 0.5673]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6165 0.0723 0.3297 0.574 ], Lowest was [0.2081 0.0619 0.3297 0.4842]
Median for last 10 epochs: [0.5361 0.0807 0.3459 0.5872], Epochs since improvement 0
 19%|█▉        | 95/500 [1:34:37<6:26:44, 57.30s/it] 19%|█▉        | 96/500 [1:35:48<6:54:05, 61.50s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 6.23E+05, Train scatter: [0.4329 0.073  0.3189 0.5569]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4169 0.0694 0.3221 0.5467], Lowest was [0.2081 0.0619 0.3221 0.4842]
Median for last 10 epochs: [0.507  0.0741 0.3449 0.5845], Epochs since improvement 0
 19%|█▉        | 97/500 [1:36:35<6:23:55, 57.16s/it] 20%|█▉        | 98/500 [1:37:46<6:50:34, 61.28s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 5.31E+05, Train scatter: [0.5112 0.0719 0.3035 0.5521]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5035 0.0743 0.3139 0.5606], Lowest was [0.2081 0.0619 0.3139 0.4842]
Median for last 10 epochs: [0.5035 0.0741 0.3297 0.574 ], Epochs since improvement 0
 20%|█▉        | 99/500 [1:38:35<6:25:14, 57.64s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 4.36E+05, Train scatter: [0.4185 0.0619 0.2833 0.535 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4125 0.062  0.2839 0.5326], Lowest was [0.2081 0.0619 0.2839 0.4842]
Median for last 10 epochs: [0.46   0.0723 0.3221 0.5606], Epochs since improvement 0
 20%|██        | 100/500 [1:39:55<7:08:40, 64.30s/it] 20%|██        | 101/500 [1:40:42<6:33:03, 59.11s/it] 20%|██        | 102/500 [1:41:54<6:57:25, 62.93s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 4.71E+05, Train scatter: [0.459  0.0625 0.2922 0.5289]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4476 0.0608 0.3011 0.5294], Lowest was [0.2081 0.0608 0.2839 0.4842]
Median for last 10 epochs: [0.4476 0.0694 0.3139 0.5467], Epochs since improvement 0
 21%|██        | 103/500 [1:42:41<6:25:22, 58.24s/it] 21%|██        | 104/500 [1:43:53<6:51:02, 62.28s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 4.80E+05, Train scatter: [0.4334 0.0629 0.2944 0.5427]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4379 0.0667 0.3093 0.5544], Lowest was [0.2081 0.0608 0.2839 0.4842]
Median for last 10 epochs: [0.4379 0.0667 0.3093 0.5467], Epochs since improvement 2
 21%|██        | 105/500 [1:44:40<6:20:20, 57.77s/it] 21%|██        | 106/500 [1:45:50<6:44:00, 61.52s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 3.89E+05, Train scatter: [0.5116 0.0673 0.281  0.5523]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5181 0.0676 0.2866 0.5536], Lowest was [0.2081 0.0608 0.2839 0.4842]
Median for last 10 epochs: [0.4476 0.0667 0.3011 0.5536], Epochs since improvement 4
 21%|██▏       | 107/500 [1:46:37<6:14:07, 57.12s/it] 22%|██▏       | 108/500 [1:47:49<6:41:10, 61.40s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 3.41E+05, Train scatter: [0.4142 0.0567 0.2658 0.5113]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4089 0.0563 0.2678 0.5039], Lowest was [0.2081 0.0563 0.2678 0.4842]
Median for last 10 epochs: [0.4379 0.062  0.2866 0.5326], Epochs since improvement 0
 22%|██▏       | 109/500 [1:48:36<6:12:42, 57.19s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 5.72E+05, Train scatter: [0.4316 0.0623 0.2992 0.5235]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4239 0.0607 0.2977 0.5148], Lowest was [0.2081 0.0563 0.2678 0.4842]
Median for last 10 epochs: [0.4379 0.0608 0.2977 0.5294], Epochs since improvement 2
 22%|██▏       | 110/500 [1:49:54<6:51:30, 63.31s/it] 22%|██▏       | 111/500 [1:50:41<6:18:56, 58.45s/it] 22%|██▏       | 112/500 [1:51:52<6:42:54, 62.31s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 7.48E+05, Train scatter: [0.4328 0.065  0.3617 0.5284]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4346 0.0696 0.3637 0.5412], Lowest was [0.2081 0.0563 0.2678 0.4842]
Median for last 10 epochs: [0.4346 0.0667 0.2977 0.5412], Epochs since improvement 4
 23%|██▎       | 113/500 [1:52:39<6:12:16, 57.72s/it] 23%|██▎       | 114/500 [1:53:51<6:38:56, 62.01s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.30E+06, Train scatter: [0.4241 0.0593 0.3778 0.5172]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4166 0.0611 0.3776 0.5225], Lowest was [0.2081 0.0563 0.2678 0.4842]
Median for last 10 epochs: [0.4239 0.0611 0.2977 0.5225], Epochs since improvement 6
 23%|██▎       | 115/500 [1:54:38<6:09:23, 57.57s/it] 23%|██▎       | 116/500 [1:55:49<6:34:01, 61.57s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 5.00E+05, Train scatter: [0.4276 0.0595 0.2825 0.5099]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4181 0.0599 0.2835 0.5036], Lowest was [0.2081 0.0563 0.2678 0.4842]
Median for last 10 epochs: [0.4181 0.0607 0.2977 0.5148], Epochs since improvement 8
 23%|██▎       | 117/500 [1:56:36<6:05:19, 57.23s/it] 24%|██▎       | 118/500 [1:57:47<6:30:19, 61.31s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 3.11E+05, Train scatter: [0.5319 0.0594 0.2997 0.5261]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5234 0.059  0.2999 0.5192], Lowest was [0.2081 0.0563 0.2678 0.4842]
Median for last 10 epochs: [0.4239 0.0607 0.2999 0.5192], Epochs since improvement 10
 24%|██▍       | 119/500 [1:58:34<6:02:15, 57.05s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.98E+05, Train scatter: [0.3867 0.0568 0.2623 0.5189]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3804 0.057  0.2643 0.503 ], Lowest was [0.2081 0.0563 0.2643 0.4842]
Median for last 10 epochs: [0.4181 0.0599 0.2999 0.5192], Epochs since improvement 0
 24%|██▍       | 120/500 [1:59:52<6:40:11, 63.19s/it] 24%|██▍       | 121/500 [2:00:39<6:08:21, 58.32s/it] 24%|██▍       | 122/500 [2:01:50<6:32:07, 62.24s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 3.15E+05, Train scatter: [0.4518 0.0628 0.3086 0.555 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4417 0.0619 0.3094 0.5508], Lowest was [0.2081 0.0563 0.2643 0.4842]
Median for last 10 epochs: [0.4181 0.0599 0.2999 0.5192], Epochs since improvement 2
 25%|██▍       | 123/500 [2:02:37<6:01:53, 57.59s/it] 25%|██▍       | 124/500 [2:03:49<6:28:30, 62.00s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 8.36E+04, Train scatter: [0.4055 0.0537 0.2608 0.4915]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3982 0.0531 0.2615 0.4821], Lowest was [0.2081 0.0531 0.2615 0.4821]
Median for last 10 epochs: [0.4181 0.059  0.2835 0.5036], Epochs since improvement 0
 25%|██▌       | 125/500 [2:04:36<5:59:01, 57.44s/it] 25%|██▌       | 126/500 [2:05:48<6:24:46, 61.73s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: -5.05E+04, Train scatter: [0.279  0.0535 0.2492 0.5045]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2828 0.0537 0.2521 0.4934], Lowest was [0.2081 0.0531 0.2521 0.4821]
Median for last 10 epochs: [0.3982 0.057  0.2643 0.503 ], Epochs since improvement 0
 25%|██▌       | 127/500 [2:06:35<5:56:22, 57.33s/it] 26%|██▌       | 128/500 [2:07:46<6:21:34, 61.55s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -1.28E+05, Train scatter: [0.2665 0.0507 0.2369 0.4784]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2743 0.0507 0.2407 0.4689], Lowest was [0.2081 0.0507 0.2407 0.4689]
Median for last 10 epochs: [0.3804 0.0537 0.2615 0.4934], Epochs since improvement 0
 26%|██▌       | 129/500 [2:08:33<5:53:30, 57.17s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -1.64E+05, Train scatter: [0.551  0.1556 0.4884 0.7811]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5479 0.1519 0.4744 0.7733], Lowest was [0.2081 0.0507 0.2407 0.4689]
Median for last 10 epochs: [0.3982 0.0537 0.2615 0.4934], Epochs since improvement 2
 26%|██▌       | 130/500 [2:09:52<6:32:24, 63.63s/it] 26%|██▌       | 131/500 [2:10:39<6:01:31, 58.78s/it] 26%|██▋       | 132/500 [2:11:51<6:24:23, 62.67s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -2.75E+05, Train scatter: [0.3751 0.0572 0.2631 0.4929]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3638 0.0589 0.264  0.4907], Lowest was [0.2081 0.0507 0.2407 0.4689]
Median for last 10 epochs: [0.3638 0.0537 0.2615 0.4907], Epochs since improvement 4
 27%|██▋       | 133/500 [2:12:38<5:55:22, 58.10s/it] 27%|██▋       | 134/500 [2:13:49<6:17:58, 61.96s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: -3.09E+05, Train scatter: [0.431  0.0507 0.2489 0.4878]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4172 0.0496 0.2506 0.4819], Lowest was [0.2081 0.0496 0.2407 0.4689]
Median for last 10 epochs: [0.3638 0.0537 0.2521 0.4907], Epochs since improvement 0
 27%|██▋       | 135/500 [2:14:36<5:49:35, 57.47s/it] 27%|██▋       | 136/500 [2:15:49<6:15:22, 61.88s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: -3.27E+05, Train scatter: [0.379  0.0498 0.2446 0.4576]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3666 0.0505 0.2465 0.4527], Lowest was [0.2081 0.0496 0.2407 0.4527]
Median for last 10 epochs: [0.3666 0.0507 0.2506 0.4819], Epochs since improvement 0
 27%|██▋       | 137/500 [2:16:36<5:47:40, 57.47s/it] 28%|██▊       | 138/500 [2:17:48<6:14:08, 62.01s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -3.35E+05, Train scatter: [0.3802 0.0493 0.245  0.4547]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3595 0.0503 0.2471 0.4504], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.3666 0.0505 0.2506 0.4819], Epochs since improvement 0
 28%|██▊       | 139/500 [2:18:35<5:45:45, 57.47s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -3.45E+05, Train scatter: [0.3892 0.0529 0.2785 0.4886]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3755 0.0509 0.2768 0.4822], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.3666 0.0505 0.2506 0.4819], Epochs since improvement 2
 28%|██▊       | 140/500 [2:19:53<6:21:16, 63.55s/it] 28%|██▊       | 141/500 [2:20:40<5:50:20, 58.55s/it] 28%|██▊       | 142/500 [2:21:51<6:11:42, 62.30s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -3.52E+05, Train scatter: [0.3598 0.0655 0.2916 0.484 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3529 0.0654 0.2907 0.4823], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.3666 0.0505 0.2506 0.4819], Epochs since improvement 4
 29%|██▊       | 143/500 [2:22:38<5:43:18, 57.70s/it] 29%|██▉       | 144/500 [2:23:49<6:06:17, 61.73s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: -3.57E+05, Train scatter: [0.4641 0.0587 0.3211 0.5302]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4487 0.0569 0.3171 0.5136], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.3666 0.0509 0.2768 0.4822], Epochs since improvement 6
 29%|██▉       | 145/500 [2:24:36<5:39:29, 57.38s/it] 29%|██▉       | 146/500 [2:25:48<6:03:53, 61.68s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: -2.15E+04, Train scatter: [0.9321 0.1725 0.544  0.9933]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9166 0.1687 0.5354 0.9831], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.3755 0.0569 0.2907 0.4823], Epochs since improvement 8
 29%|██▉       | 147/500 [2:26:35<5:37:30, 57.37s/it] 30%|██▉       | 148/500 [2:27:46<6:00:42, 61.48s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: -4.63E+04, Train scatter: [0.9077 0.1117 0.5434 0.9763]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8931 0.1095 0.5348 0.9665], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.4487 0.0654 0.3171 0.5136], Epochs since improvement 10
 30%|██▉       | 149/500 [2:28:34<5:34:43, 57.22s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: -8.90E+04, Train scatter: [0.6395 0.1102 0.5416 0.7572]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6324 0.1072 0.533  0.7503], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.6324 0.1072 0.533  0.7503], Epochs since improvement 12
 30%|███       | 150/500 [2:29:50<6:08:14, 63.13s/it] 30%|███       | 151/500 [2:30:37<5:38:54, 58.26s/it] 30%|███       | 152/500 [2:31:50<6:02:10, 62.44s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: -1.15E+05, Train scatter: [0.4624 0.1041 0.5331 0.7042]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4631 0.1023 0.525  0.6784], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.6324 0.1072 0.533  0.7503], Epochs since improvement 14
 31%|███       | 153/500 [2:32:37<5:34:13, 57.79s/it] 31%|███       | 154/500 [2:33:48<5:57:12, 61.94s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 7.95E+06, Train scatter: [0.9353 0.1742 0.5438 3.64  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1704 0.5353 3.6338], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.8931 0.1095 0.5348 0.9665], Epochs since improvement 16
 31%|███       | 155/500 [2:34:35<5:30:25, 57.46s/it] 31%|███       | 156/500 [2:35:47<5:53:30, 61.66s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 4.86E+04, Train scatter: [0.9356 0.1676 0.5441 0.999 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.1641 0.5355 0.9885], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.8931 0.1095 0.5348 0.9665], Epochs since improvement 18
 31%|███▏      | 157/500 [2:36:33<5:27:04, 57.21s/it] 32%|███▏      | 158/500 [2:37:45<5:50:18, 61.46s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 3.32E+04, Train scatter: [0.9357 0.1458 0.5441 1.0099]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9201 0.1434 0.5355 0.9991], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.9197 0.1434 0.5353 0.9885], Epochs since improvement 20
 32%|███▏      | 159/500 [2:38:32<5:24:39, 57.13s/it]Epoch: 160 done with learning rate 9.05E-03, Train loss: 1.15E+04, Train scatter: [0.934  0.1335 0.5441 1.0085]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9185 0.1324 0.5355 0.9978], Lowest was [0.2081 0.0496 0.2407 0.4504]
Median for last 10 epochs: [0.9197 0.1434 0.5355 0.9978], Epochs since improvement 22
 32%|███▏      | 159/500 [2:39:51<5:42:50, 60.33s/it]
Exited after 160 epochs due to early stopping
9591.76 seconds spent training, 19.184 seconds per epoch. Processed 3630 trees per second
[0.91844827 0.13234974 0.5354483  0.9977864 ]
{'epoch_exit': 159, 'scatter_m_star': 0.91844827, 'lowest_m_star': 0.20806737, 'last20_m_star': 0.90484464, 'last10_m_star': 0.91971344, 'scatter_v_disk': 0.13234974, 'lowest_v_disk': 0.049603816, 'last20_v_disk': 0.12093796, 'last10_v_disk': 0.14336336, 'scatter_m_cold': 0.5354483, 'lowest_m_cold': 0.24072082, 'last20_m_cold': 0.5350455, 'last10_m_cold': 0.53546345, 'scatter_sfr_100': 0.9977864, 'lowest_sfr_100': 0.4503655, 'last20_sfr_100': 0.9748182, 'last10_sfr_100': 0.9978146}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_undqpf
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:41<5:46:43, 41.69s/it]  0%|          | 2/500 [01:45<7:32:39, 54.54s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.08E+07, Train scatter: [0.9352 0.1715 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1684 0.5355 0.9851], Lowest was [0.9196 0.1684 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1684 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:25<6:38:12, 48.07s/it]  1%|          | 4/500 [03:28<7:26:48, 54.05s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.32E+07, Train scatter: [0.9352 0.1613 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.158  0.5355 0.9851], Lowest was [0.9196 0.158  0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.158  0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:09<6:46:34, 49.28s/it]  1%|          | 6/500 [05:13<7:27:27, 54.35s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.86E+07, Train scatter: [0.9351 0.1346 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1318 0.5355 0.985 ], Lowest was [0.9195 0.1318 0.5355 0.985 ]
Median for last 10 epochs: [0.9195 0.1318 0.5355 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [05:54<6:49:05, 49.79s/it]  2%|▏         | 8/500 [06:58<7:24:54, 54.26s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.48E+07, Train scatter: [0.9329 0.1123 0.5441 0.9661]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9174 0.1111 0.5355 0.9575], Lowest was [0.9174 0.1111 0.5355 0.9575]
Median for last 10 epochs: [0.9185 0.1215 0.5355 0.9713], Epochs since improvement 0
  2%|▏         | 9/500 [07:38<6:48:39, 49.94s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 1.13E+07, Train scatter: [0.7638 0.1075 0.5441 0.656 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7563 0.1108 0.5355 0.6579], Lowest was [0.7563 0.1108 0.5355 0.6579]
Median for last 10 epochs: [0.9174 0.1111 0.5355 0.9575], Epochs since improvement 0
  2%|▏         | 10/500 [08:49<7:41:26, 56.50s/it]  2%|▏         | 11/500 [09:30<7:00:26, 51.59s/it]  2%|▏         | 12/500 [10:33<7:29:09, 55.22s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.03E+06, Train scatter: [0.6465 0.097  0.544  0.6637]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6464 0.0966 0.5354 0.6604], Lowest was [0.6464 0.0966 0.5354 0.6579]
Median for last 10 epochs: [0.9174 0.1111 0.5355 0.9575], Epochs since improvement 0
  3%|▎         | 13/500 [11:14<6:51:58, 50.76s/it]  3%|▎         | 14/500 [12:17<7:21:45, 54.54s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.57E+06, Train scatter: [0.4048 0.0845 0.5439 0.5713]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4124 0.0857 0.5354 0.5681], Lowest was [0.4124 0.0857 0.5354 0.5681]
Median for last 10 epochs: [0.7563 0.1108 0.5355 0.6604], Epochs since improvement 0
  3%|▎         | 15/500 [12:57<6:46:30, 50.29s/it]  3%|▎         | 16/500 [14:01<7:18:16, 54.33s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 5.89E+06, Train scatter: [0.3032 0.0873 0.5439 0.5767]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3089 0.0886 0.5354 0.5692], Lowest was [0.3089 0.0857 0.5354 0.5681]
Median for last 10 epochs: [0.6464 0.0966 0.5354 0.6579], Epochs since improvement 0
  3%|▎         | 17/500 [14:42<6:45:15, 50.34s/it]  4%|▎         | 18/500 [15:46<7:17:11, 54.42s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 5.60E+06, Train scatter: [0.2981 0.0828 0.544  0.5319]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3028 0.0838 0.5354 0.5295], Lowest was [0.3028 0.0838 0.5354 0.5295]
Median for last 10 epochs: [0.4124 0.0886 0.5354 0.5692], Epochs since improvement 0
  4%|▍         | 19/500 [16:27<6:42:53, 50.26s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.02E+06, Train scatter: [0.3077 0.0806 0.544  0.5405]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3194 0.0813 0.5355 0.5373], Lowest was [0.3028 0.0813 0.5354 0.5295]
Median for last 10 epochs: [0.3194 0.0857 0.5354 0.5681], Epochs since improvement 0
  4%|▍         | 20/500 [17:37<7:30:25, 56.30s/it]  4%|▍         | 21/500 [18:17<6:51:30, 51.55s/it]  4%|▍         | 22/500 [19:21<7:19:48, 55.21s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.87E+06, Train scatter: [0.2533 0.0799 0.544  0.5107]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2556 0.0804 0.5355 0.5099], Lowest was [0.2556 0.0804 0.5354 0.5099]
Median for last 10 epochs: [0.3089 0.0838 0.5354 0.5373], Epochs since improvement 0
  5%|▍         | 23/500 [20:02<6:43:59, 50.82s/it]  5%|▍         | 24/500 [21:06<7:16:02, 54.96s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.77E+06, Train scatter: [0.3514 0.0794 0.544  0.5412]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3525 0.0797 0.5354 0.5471], Lowest was [0.2556 0.0797 0.5354 0.5099]
Median for last 10 epochs: [0.3089 0.0813 0.5354 0.5373], Epochs since improvement 0
  5%|▌         | 25/500 [21:47<6:40:47, 50.63s/it]  5%|▌         | 26/500 [22:50<7:09:43, 54.40s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 5.36E+06, Train scatter: [0.4128 0.0845 0.5439 0.5244]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4068 0.0842 0.5354 0.5213], Lowest was [0.2556 0.0797 0.5354 0.5099]
Median for last 10 epochs: [0.3194 0.0813 0.5354 0.5295], Epochs since improvement 2
  5%|▌         | 27/500 [23:30<6:35:33, 50.18s/it]  6%|▌         | 28/500 [24:34<7:07:11, 54.30s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.88E+06, Train scatter: [0.3605 0.0778 0.5439 0.5247]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3591 0.0786 0.5354 0.5282], Lowest was [0.2556 0.0786 0.5354 0.5099]
Median for last 10 epochs: [0.3525 0.0804 0.5354 0.5282], Epochs since improvement 0
  6%|▌         | 29/500 [25:15<6:34:10, 50.21s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.66E+06, Train scatter: [0.2342 0.0755 0.5439 0.5106]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2398 0.0761 0.5354 0.5084], Lowest was [0.2398 0.0761 0.5354 0.5084]
Median for last 10 epochs: [0.3525 0.0797 0.5354 0.5213], Epochs since improvement 0
  6%|▌         | 30/500 [26:25<7:19:07, 56.06s/it]  6%|▌         | 31/500 [27:05<6:41:19, 51.34s/it]  6%|▋         | 32/500 [28:09<7:10:07, 55.14s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.54E+06, Train scatter: [0.2244 0.0741 0.5439 0.4984]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2327 0.0745 0.5353 0.4976], Lowest was [0.2327 0.0745 0.5353 0.4976]
Median for last 10 epochs: [0.3525 0.0786 0.5354 0.5213], Epochs since improvement 0
  7%|▋         | 33/500 [28:49<6:34:24, 50.67s/it]  7%|▋         | 34/500 [29:53<7:04:09, 54.61s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 4.51E+06, Train scatter: [0.2125 0.0717 0.5438 0.5016]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2194 0.0724 0.5352 0.4988], Lowest was [0.2194 0.0724 0.5352 0.4976]
Median for last 10 epochs: [0.2398 0.0761 0.5354 0.5084], Epochs since improvement 0
  7%|▋         | 35/500 [30:34<6:31:01, 50.46s/it]  7%|▋         | 36/500 [31:37<7:00:19, 54.35s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 4.51E+06, Train scatter: [0.2404 0.0717 0.5438 0.4974]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2438 0.0723 0.5352 0.499 ], Lowest was [0.2194 0.0723 0.5352 0.4976]
Median for last 10 epochs: [0.2398 0.0745 0.5353 0.499 ], Epochs since improvement 0
  7%|▋         | 37/500 [32:18<6:27:13, 50.18s/it]  8%|▊         | 38/500 [33:22<6:57:49, 54.26s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 4.49E+06, Train scatter: [0.227  0.0767 0.5437 0.5054]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2338 0.0764 0.5352 0.5074], Lowest was [0.2194 0.0723 0.5352 0.4976]
Median for last 10 epochs: [0.2338 0.0745 0.5352 0.499 ], Epochs since improvement 0
  8%|▊         | 39/500 [34:02<6:24:30, 50.04s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 4.46E+06, Train scatter: [0.2674 0.0726 0.5437 0.5439]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2726 0.0721 0.5351 0.55  ], Lowest was [0.2194 0.0721 0.5351 0.4976]
Median for last 10 epochs: [0.2338 0.0724 0.5352 0.499 ], Epochs since improvement 0
  8%|▊         | 40/500 [35:13<7:11:25, 56.27s/it]  8%|▊         | 41/500 [35:53<6:34:35, 51.58s/it]  8%|▊         | 42/500 [36:56<7:00:05, 55.03s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 4.44E+06, Train scatter: [0.2336 0.0703 0.5436 0.5146]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2435 0.0707 0.535  0.523 ], Lowest was [0.2194 0.0707 0.535  0.4976]
Median for last 10 epochs: [0.2435 0.0723 0.5352 0.5074], Epochs since improvement 0
  9%|▊         | 43/500 [37:37<6:25:51, 50.66s/it]  9%|▉         | 44/500 [38:40<6:54:11, 54.50s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.44E+06, Train scatter: [0.2002 0.074  0.5435 0.4947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2074 0.0748 0.5349 0.4921], Lowest was [0.2074 0.0707 0.5349 0.4921]
Median for last 10 epochs: [0.2435 0.0723 0.5351 0.5074], Epochs since improvement 0
  9%|▉         | 45/500 [39:21<6:21:10, 50.27s/it]  9%|▉         | 46/500 [40:24<6:49:37, 54.13s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.43E+06, Train scatter: [0.2297 0.0755 0.5435 0.5091]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2822 0.0755 0.5349 0.5096], Lowest was [0.2074 0.0707 0.5349 0.4921]
Median for last 10 epochs: [0.2435 0.0748 0.535  0.5096], Epochs since improvement 2
  9%|▉         | 47/500 [41:05<6:18:26, 50.12s/it] 10%|▉         | 48/500 [42:09<6:49:29, 54.36s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 4.40E+06, Train scatter: [0.4521 0.0734 0.5434 0.5362]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4373 0.0749 0.5348 0.5266], Lowest was [0.2074 0.0707 0.5348 0.4921]
Median for last 10 epochs: [0.2726 0.0748 0.5349 0.523 ], Epochs since improvement 0
 10%|▉         | 49/500 [42:49<6:17:19, 50.20s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.70E+06, Train scatter: [0.4638 0.0924 0.544  0.5401]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4571 0.0905 0.5355 0.5349], Lowest was [0.2074 0.0707 0.5348 0.4921]
Median for last 10 epochs: [0.2822 0.0749 0.5349 0.523 ], Epochs since improvement 2
 10%|█         | 50/500 [43:58<6:58:29, 55.80s/it] 10%|█         | 51/500 [44:39<6:23:29, 51.25s/it] 10%|█         | 52/500 [45:42<6:49:12, 54.80s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.32E+06, Train scatter: [0.3207 0.0838 0.5438 0.5523]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3137 0.0822 0.5353 0.5506], Lowest was [0.2074 0.0707 0.5348 0.4921]
Median for last 10 epochs: [0.3137 0.0755 0.5349 0.5266], Epochs since improvement 4
 11%|█         | 53/500 [46:23<6:16:51, 50.58s/it] 11%|█         | 54/500 [47:26<6:45:05, 54.50s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.29E+06, Train scatter: [0.3956 0.085  0.5438 0.5101]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3913 0.0829 0.5352 0.5024], Lowest was [0.2074 0.0707 0.5348 0.4921]
Median for last 10 epochs: [0.3913 0.0822 0.5352 0.5266], Epochs since improvement 6
 11%|█         | 55/500 [48:07<6:13:42, 50.39s/it] 11%|█         | 56/500 [49:10<6:41:38, 54.28s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.27E+06, Train scatter: [0.4037 0.0815 0.5436 0.5091]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3949 0.08   0.5351 0.5017], Lowest was [0.2074 0.0707 0.5348 0.4921]
Median for last 10 epochs: [0.3949 0.0822 0.5352 0.5266], Epochs since improvement 8
 11%|█▏        | 57/500 [49:51<6:10:05, 50.13s/it] 12%|█▏        | 58/500 [50:55<6:39:10, 54.19s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.24E+06, Train scatter: [0.3809 0.08   0.5436 0.5604]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3774 0.0782 0.5351 0.5614], Lowest was [0.2074 0.0707 0.5348 0.4921]
Median for last 10 epochs: [0.3913 0.0822 0.5352 0.5349], Epochs since improvement 10
 12%|█▏        | 59/500 [51:35<6:08:32, 50.14s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.32E+06, Train scatter: [0.7662 0.0909 0.5438 0.5771]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7529 0.0904 0.5353 0.5738], Lowest was [0.2074 0.0707 0.5348 0.4921]
Median for last 10 epochs: [0.3913 0.0822 0.5352 0.5506], Epochs since improvement 12
 12%|█▏        | 60/500 [52:44<6:49:40, 55.87s/it] 12%|█▏        | 61/500 [53:25<6:15:24, 51.31s/it] 12%|█▏        | 62/500 [54:29<6:41:47, 55.04s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.24E+06, Train scatter: [0.4094 0.086  0.5437 0.535 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4042 0.0835 0.5351 0.5262], Lowest was [0.2074 0.0707 0.5348 0.4921]
Median for last 10 epochs: [0.3949 0.0829 0.5351 0.5262], Epochs since improvement 14
 13%|█▎        | 63/500 [55:09<6:09:00, 50.67s/it] 13%|█▎        | 64/500 [56:13<6:35:34, 54.44s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.23E+06, Train scatter: [0.4409 0.0835 0.5436 0.5202]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.432  0.0812 0.535  0.513 ], Lowest was [0.2074 0.0707 0.5348 0.4921]
Median for last 10 epochs: [0.4042 0.0812 0.5351 0.5262], Epochs since improvement 16
 13%|█▎        | 65/500 [56:53<6:04:20, 50.25s/it] 13%|█▎        | 66/500 [57:56<6:30:47, 54.03s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.21E+06, Train scatter: [0.3785 0.0827 0.5435 0.5399]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3696 0.0805 0.5349 0.5364], Lowest was [0.2074 0.0707 0.5348 0.4921]
Median for last 10 epochs: [0.4042 0.0812 0.5351 0.5364], Epochs since improvement 18
 13%|█▎        | 67/500 [58:37<6:01:12, 50.05s/it] 14%|█▎        | 68/500 [59:40<6:29:12, 54.06s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.23E+06, Train scatter: [0.4366 0.0789 0.5434 0.507 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4251 0.0789 0.5348 0.4981], Lowest was [0.2074 0.0707 0.5348 0.4921]
Median for last 10 epochs: [0.4251 0.0812 0.535  0.5262], Epochs since improvement 20
 14%|█▍        | 69/500 [1:00:21<5:59:01, 49.98s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.18E+06, Train scatter: [0.4365 0.0794 0.5432 0.5259]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4275 0.0786 0.5347 0.5241], Lowest was [0.2074 0.0707 0.5347 0.4921]
Median for last 10 epochs: [0.4251 0.0805 0.5349 0.5241], Epochs since improvement 0
 14%|█▍        | 70/500 [1:01:30<6:41:00, 55.96s/it] 14%|█▍        | 71/500 [1:02:11<6:06:58, 51.33s/it] 14%|█▍        | 72/500 [1:03:14<6:30:40, 54.77s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.18E+06, Train scatter: [0.3879 0.0765 0.5434 0.5565]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3824 0.0735 0.5348 0.5558], Lowest was [0.2074 0.0707 0.5347 0.4921]
Median for last 10 epochs: [0.4251 0.0789 0.5348 0.5241], Epochs since improvement 2
 15%|█▍        | 73/500 [1:03:54<5:59:31, 50.52s/it] 15%|█▍        | 74/500 [1:04:58<6:26:27, 54.43s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.16E+06, Train scatter: [0.3713 0.0778 0.5432 0.5106]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.362  0.0753 0.5347 0.5065], Lowest was [0.2074 0.0707 0.5347 0.4921]
Median for last 10 epochs: [0.3824 0.0786 0.5348 0.5241], Epochs since improvement 4
 15%|█▌        | 75/500 [1:05:38<5:55:58, 50.26s/it] 15%|█▌        | 76/500 [1:06:42<6:22:55, 54.19s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.14E+06, Train scatter: [0.4402 0.0784 0.5431 0.5435]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4276 0.0776 0.5346 0.5368], Lowest was [0.2074 0.0707 0.5346 0.4921]
Median for last 10 epochs: [0.4251 0.0776 0.5347 0.5241], Epochs since improvement 0
 15%|█▌        | 77/500 [1:07:22<5:53:09, 50.09s/it] 16%|█▌        | 78/500 [1:08:25<6:18:39, 53.84s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.10E+06, Train scatter: [0.3784 0.0678 0.543  0.5063]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3845 0.0681 0.5344 0.5008], Lowest was [0.2074 0.0681 0.5344 0.4921]
Median for last 10 epochs: [0.3845 0.0753 0.5347 0.5241], Epochs since improvement 0
 16%|█▌        | 79/500 [1:09:06<5:50:34, 49.96s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 3.08E+06, Train scatter: [0.3646 0.0901 0.5432 0.5143]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3564 0.0874 0.5346 0.5108], Lowest was [0.2074 0.0681 0.5344 0.4921]
Median for last 10 epochs: [0.3824 0.0753 0.5346 0.5108], Epochs since improvement 2
 16%|█▌        | 80/500 [1:10:17<6:35:06, 56.44s/it] 16%|█▌        | 81/500 [1:10:58<6:00:24, 51.61s/it] 16%|█▋        | 82/500 [1:12:01<6:24:36, 55.21s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 3.07E+06, Train scatter: [0.3972 0.0673 0.5429 0.4985]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3875 0.067  0.5343 0.4939], Lowest was [0.2074 0.067  0.5343 0.4921]
Median for last 10 epochs: [0.3845 0.0753 0.5346 0.5065], Epochs since improvement 0
 17%|█▋        | 83/500 [1:12:42<5:52:56, 50.78s/it] 17%|█▋        | 84/500 [1:13:45<6:16:59, 54.37s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 3.07E+06, Train scatter: [0.3803 0.0754 0.5429 0.4985]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3718 0.0761 0.5343 0.4955], Lowest was [0.2074 0.067  0.5343 0.4921]
Median for last 10 epochs: [0.3845 0.0761 0.5344 0.5008], Epochs since improvement 0
 17%|█▋        | 85/500 [1:14:25<5:47:55, 50.30s/it] 17%|█▋        | 86/500 [1:15:29<6:13:45, 54.17s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 3.06E+06, Train scatter: [0.2579 0.0682 0.5426 0.4963]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2501 0.0693 0.534  0.4886], Lowest was [0.2074 0.067  0.534  0.4886]
Median for last 10 epochs: [0.3718 0.0693 0.5343 0.4955], Epochs since improvement 0
 17%|█▋        | 87/500 [1:16:09<5:44:32, 50.06s/it] 18%|█▊        | 88/500 [1:17:12<6:10:25, 53.94s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 3.06E+06, Train scatter: [0.4376 0.0679 0.5425 0.4979]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4277 0.0678 0.5339 0.4935], Lowest was [0.2074 0.067  0.5339 0.4886]
Median for last 10 epochs: [0.3718 0.0693 0.5343 0.4939], Epochs since improvement 0
 18%|█▊        | 89/500 [1:17:53<5:41:58, 49.92s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 3.03E+06, Train scatter: [0.4111 0.0649 0.5416 0.485 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4005 0.0646 0.533  0.4796], Lowest was [0.2074 0.0646 0.533  0.4796]
Median for last 10 epochs: [0.3875 0.0678 0.534  0.4935], Epochs since improvement 0
 18%|█▊        | 90/500 [1:19:02<6:21:03, 55.76s/it] 18%|█▊        | 91/500 [1:19:43<5:49:49, 51.32s/it] 18%|█▊        | 92/500 [1:20:47<6:14:46, 55.11s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 3.00E+06, Train scatter: [0.3469 0.0616 0.5405 0.4931]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3442 0.0617 0.532  0.4913], Lowest was [0.2074 0.0617 0.532  0.4796]
Median for last 10 epochs: [0.3718 0.0678 0.5339 0.4913], Epochs since improvement 0
 19%|█▊        | 93/500 [1:21:27<5:44:11, 50.74s/it] 19%|█▉        | 94/500 [1:22:30<6:08:16, 54.43s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.91E+06, Train scatter: [0.2109 0.0597 0.5381 0.4854]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2214 0.0596 0.5296 0.4803], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.3442 0.0646 0.533  0.4886], Epochs since improvement 0
 19%|█▉        | 95/500 [1:23:11<5:39:16, 50.26s/it] 19%|█▉        | 96/500 [1:24:14<6:04:06, 54.08s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 5.23E+06, Train scatter: [0.9357 0.1723 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9201 0.1685 0.5355 0.985 ], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.4005 0.0646 0.533  0.4913], Epochs since improvement 2
 19%|█▉        | 97/500 [1:24:55<5:36:03, 50.03s/it] 20%|█▉        | 98/500 [1:25:58<6:01:44, 53.99s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 4.36E+06, Train scatter: [0.9357 0.172  0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9201 0.1683 0.5355 0.9851], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.4005 0.0646 0.533  0.4913], Epochs since improvement 4
 20%|█▉        | 99/500 [1:26:38<5:33:40, 49.93s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 4.21E+06, Train scatter: [0.9357 0.1717 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9201 0.1679 0.5355 0.9851], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.9201 0.1679 0.5355 0.985 ], Epochs since improvement 6
 20%|██        | 100/500 [1:27:48<6:12:51, 55.93s/it] 20%|██        | 101/500 [1:28:29<5:41:14, 51.31s/it] 20%|██        | 102/500 [1:29:32<6:03:56, 54.86s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 4.11E+06, Train scatter: [0.9357 0.1713 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9201 0.1676 0.5355 0.9851], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.9201 0.1679 0.5355 0.9851], Epochs since improvement 8
 21%|██        | 103/500 [1:30:13<5:35:05, 50.64s/it] 21%|██        | 104/500 [1:31:15<5:57:48, 54.21s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 4.04E+06, Train scatter: [0.9358 0.1707 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9202 0.167  0.5355 0.9851], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.9201 0.1679 0.5355 0.9851], Epochs since improvement 10
 21%|██        | 105/500 [1:31:56<5:29:50, 50.10s/it] 21%|██        | 106/500 [1:32:59<5:55:12, 54.09s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 3.98E+06, Train scatter: [0.936  0.1696 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9204 0.166  0.5355 0.985 ], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.9201 0.1676 0.5355 0.9851], Epochs since improvement 12
 21%|██▏       | 107/500 [1:33:40<5:27:32, 50.01s/it] 22%|██▏       | 108/500 [1:34:43<5:53:15, 54.07s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 3.94E+06, Train scatter: [0.9371 0.1637 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9214 0.1603 0.5355 0.9847], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.9202 0.167  0.5355 0.9851], Epochs since improvement 14
 22%|██▏       | 109/500 [1:35:24<5:25:56, 50.02s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 3.90E+06, Train scatter: [0.9372 0.1551 0.5441 0.9948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9216 0.1519 0.5355 0.9844], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.9204 0.166  0.5355 0.985 ], Epochs since improvement 16
 22%|██▏       | 110/500 [1:36:33<6:03:18, 55.89s/it] 22%|██▏       | 111/500 [1:37:14<5:32:35, 51.30s/it] 22%|██▏       | 112/500 [1:38:17<5:54:11, 54.77s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 3.86E+06, Train scatter: [0.9367 0.1365 0.5441 0.9945]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9211 0.134  0.5355 0.9841], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.9211 0.1603 0.5355 0.9847], Epochs since improvement 18
 23%|██▎       | 113/500 [1:38:57<5:25:44, 50.50s/it] 23%|██▎       | 114/500 [1:40:00<5:48:08, 54.11s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 3.83E+06, Train scatter: [0.9354 0.128  0.5441 0.9944]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.126  0.5355 0.984 ], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.9211 0.1519 0.5355 0.9844], Epochs since improvement 20
 23%|██▎       | 115/500 [1:40:40<5:21:16, 50.07s/it] 23%|██▎       | 115/500 [1:41:44<5:40:36, 53.08s/it]
Epoch: 116 done with learning rate 9.77E-03, Train loss: 3.80E+06, Train scatter: [0.9333 0.1188 0.5441 0.9942]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9178 0.1167 0.5355 0.9839], Lowest was [0.2074 0.0596 0.5296 0.4796]
Median for last 10 epochs: [0.9211 0.134  0.5355 0.9841], Epochs since improvement 22
Exited after 116 epochs due to early stopping
6104.31 seconds spent training, 12.209 seconds per epoch. Processed 5704 trees per second
[0.9177721  0.11667461 0.535476   0.9838477 ]
{'epoch_exit': 115, 'scatter_m_star': 0.9177721, 'lowest_m_star': 0.20736532, 'last20_m_star': 0.9201911, 'last10_m_star': 0.92107594, 'scatter_v_disk': 0.11667461, 'lowest_v_disk': 0.059577685, 'last20_v_disk': 0.16313642, 'last10_v_disk': 0.13402727, 'scatter_m_cold': 0.535476, 'lowest_m_cold': 0.5296141, 'last20_m_cold': 0.5354908, 'last10_m_cold': 0.5354923, 'scatter_sfr_100': 0.9838477, 'lowest_sfr_100': 0.4796181, 'last20_sfr_100': 0.98487425, 'last10_sfr_100': 0.9840988}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_ocowde
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:01<8:27:54, 61.07s/it]  0%|          | 2/500 [02:30<10:47:31, 78.02s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.37E+07, Train scatter: [0.9351 0.1293 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1246 0.5355 0.9851], Lowest was [0.9195 0.1246 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1246 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:32<9:43:42, 70.47s/it]   1%|          | 4/500 [05:03<10:49:01, 78.51s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.29E+07, Train scatter: [0.9339 0.1026 0.5428 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9181 0.1025 0.5341 0.9851], Lowest was [0.9181 0.1025 0.5341 0.9851]
Median for last 10 epochs: [0.9181 0.1025 0.5341 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:04<9:56:35, 72.31s/it]   1%|          | 6/500 [07:35<10:48:17, 78.74s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.05E+07, Train scatter: [0.8281 0.0942 0.5302 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8173 0.0947 0.5221 0.9851], Lowest was [0.8173 0.0947 0.5221 0.9851]
Median for last 10 epochs: [0.8173 0.0947 0.5221 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [08:37<10:00:49, 73.12s/it]  2%|▏         | 8/500 [10:08<10:46:01, 78.78s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.78E+07, Train scatter: [0.6726 0.0961 0.4038 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6726 0.0982 0.3991 0.9851], Lowest was [0.6726 0.0947 0.3991 0.9851]
Median for last 10 epochs: [0.7449 0.0965 0.4606 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [11:09<10:00:41, 73.40s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.62E+07, Train scatter: [0.5925 0.0905 0.356  0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5972 0.0935 0.357  0.985 ], Lowest was [0.5972 0.0935 0.357  0.985 ]
Median for last 10 epochs: [0.6726 0.0947 0.3991 0.9851], Epochs since improvement 0
  2%|▏         | 10/500 [12:48<11:02:27, 81.12s/it]  2%|▏         | 11/500 [13:49<10:11:39, 75.05s/it]  2%|▏         | 12/500 [15:22<10:54:15, 80.44s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.51E+07, Train scatter: [0.5397 0.0838 0.3281 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5455 0.086  0.3303 0.985 ], Lowest was [0.5455 0.086  0.3303 0.985 ]
Median for last 10 epochs: [0.6726 0.0947 0.3991 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [16:23<10:06:02, 74.67s/it]  3%|▎         | 14/500 [17:54<10:45:27, 79.69s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.12E+07, Train scatter: [0.5461 0.0823 0.3185 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5569 0.0835 0.3248 0.985 ], Lowest was [0.5455 0.0835 0.3248 0.985 ]
Median for last 10 epochs: [0.5972 0.0935 0.357  0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [18:56<9:59:57, 74.22s/it]   3%|▎         | 16/500 [20:27<10:39:48, 79.31s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.06E+07, Train scatter: [0.4845 0.0823 0.3543 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4896 0.0849 0.3631 0.985 ], Lowest was [0.4896 0.0835 0.3248 0.985 ]
Median for last 10 epochs: [0.5569 0.086  0.357  0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [21:28<9:54:55, 73.90s/it]   4%|▎         | 18/500 [23:00<10:35:06, 79.06s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.86E+07, Train scatter: [0.4933 0.0769 0.3114 0.9949]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4888 0.0766 0.3111 0.9848], Lowest was [0.4888 0.0766 0.3111 0.9848]
Median for last 10 epochs: [0.5455 0.0849 0.3303 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [24:01<9:51:30, 73.79s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 1.16E+07, Train scatter: [0.8983 0.111  0.4303 0.9946]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8866 0.1091 0.4223 0.9843], Lowest was [0.4888 0.0766 0.3111 0.9843]
Median for last 10 epochs: [0.5455 0.0849 0.3303 0.985 ], Epochs since improvement 0
  4%|▍         | 20/500 [25:39<10:47:48, 80.98s/it]  4%|▍         | 21/500 [26:40<9:59:40, 75.12s/it]   4%|▍         | 22/500 [28:12<10:37:43, 80.05s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.75E+06, Train scatter: [0.4358 0.0794 0.3325 0.5858]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4322 0.08   0.3395 0.5885], Lowest was [0.4322 0.0766 0.3111 0.5885]
Median for last 10 epochs: [0.4896 0.0835 0.3395 0.9848], Epochs since improvement 0
  5%|▍         | 23/500 [29:13<9:52:13, 74.49s/it]   5%|▍         | 24/500 [30:44<10:29:07, 79.30s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.91E+06, Train scatter: [0.439  0.0786 0.3376 0.518 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4332 0.0783 0.3433 0.5192], Lowest was [0.4322 0.0766 0.3111 0.5192]
Median for last 10 epochs: [0.4888 0.08   0.3433 0.9843], Epochs since improvement 0
  5%|▌         | 25/500 [31:45<9:45:24, 73.95s/it]   5%|▌         | 26/500 [33:17<10:25:09, 79.13s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.32E+06, Train scatter: [0.4567 0.078  0.3156 0.5036]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4503 0.0784 0.3212 0.5059], Lowest was [0.4322 0.0766 0.3111 0.5059]
Median for last 10 epochs: [0.4503 0.0784 0.3395 0.5885], Epochs since improvement 0
  5%|▌         | 27/500 [34:18<9:41:59, 73.82s/it]   6%|▌         | 28/500 [35:49<10:21:38, 79.02s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.27E+06, Train scatter: [0.4572 0.075  0.3094 0.5104]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4407 0.0745 0.3187 0.5088], Lowest was [0.4322 0.0745 0.3111 0.5059]
Median for last 10 epochs: [0.4407 0.0784 0.3395 0.5192], Epochs since improvement 0
  6%|▌         | 29/500 [36:50<9:38:37, 73.71s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.07E+06, Train scatter: [0.4182 0.0756 0.3072 0.4853]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4158 0.0739 0.3146 0.4851], Lowest was [0.4158 0.0739 0.3111 0.4851]
Median for last 10 epochs: [0.4332 0.0783 0.3212 0.5088], Epochs since improvement 0
  6%|▌         | 30/500 [38:29<10:36:28, 81.25s/it]  6%|▌         | 31/500 [39:31<9:48:45, 75.32s/it]   6%|▋         | 32/500 [41:03<10:25:55, 80.25s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.88E+06, Train scatter: [0.4437 0.0722 0.3058 0.4793]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4298 0.0721 0.3126 0.4812], Lowest was [0.4158 0.0721 0.3111 0.4812]
Median for last 10 epochs: [0.4332 0.0745 0.3187 0.5059], Epochs since improvement 0
  7%|▋         | 33/500 [42:04<9:41:12, 74.67s/it]   7%|▋         | 34/500 [43:36<10:19:09, 79.72s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.22E+06, Train scatter: [0.4067 0.0744 0.4944 0.5234]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3994 0.074  0.4876 0.5264], Lowest was [0.3994 0.0721 0.3111 0.4812]
Median for last 10 epochs: [0.4298 0.074  0.3187 0.5059], Epochs since improvement 0
  7%|▋         | 35/500 [44:37<9:35:26, 74.25s/it]   7%|▋         | 36/500 [46:08<10:13:24, 79.32s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.97E+06, Train scatter: [0.3737 0.0732 0.3637 0.5   ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3807 0.0725 0.3665 0.4972], Lowest was [0.3807 0.0721 0.3111 0.4812]
Median for last 10 epochs: [0.4158 0.0739 0.3187 0.4972], Epochs since improvement 0
  7%|▋         | 37/500 [47:10<9:30:51, 73.98s/it]   8%|▊         | 38/500 [48:41<10:09:42, 79.18s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.71E+06, Train scatter: [0.4146 0.0711 0.2983 0.4743]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4025 0.0706 0.3    0.4739], Lowest was [0.3807 0.0706 0.3    0.4739]
Median for last 10 epochs: [0.4025 0.0725 0.3146 0.4851], Epochs since improvement 0
  8%|▊         | 39/500 [49:43<9:27:38, 73.88s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.57E+06, Train scatter: [0.365  0.0742 0.2858 0.4669]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4485 0.0757 0.2875 0.4686], Lowest was [0.3807 0.0706 0.2875 0.4686]
Median for last 10 epochs: [0.4025 0.0725 0.3126 0.4812], Epochs since improvement 0
  8%|▊         | 40/500 [51:21<10:23:03, 81.27s/it]  8%|▊         | 41/500 [52:23<9:36:35, 75.37s/it]   8%|▊         | 42/500 [53:54<10:12:03, 80.18s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.45E+06, Train scatter: [0.6635 0.0656 0.2843 0.4579]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5928 0.0666 0.2867 0.4612], Lowest was [0.3807 0.0666 0.2867 0.4612]
Median for last 10 epochs: [0.4025 0.0725 0.3    0.4739], Epochs since improvement 0
  9%|▊         | 43/500 [54:56<9:27:38, 74.53s/it]   9%|▉         | 44/500 [56:27<10:04:26, 79.53s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.41E+06, Train scatter: [0.423  0.0699 0.3105 0.4892]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4135 0.0688 0.3161 0.4912], Lowest was [0.3807 0.0666 0.2867 0.4612]
Median for last 10 epochs: [0.4135 0.0706 0.3    0.4739], Epochs since improvement 2
  9%|▉         | 45/500 [57:28<9:21:55, 74.10s/it]   9%|▉         | 46/500 [58:59<9:58:37, 79.11s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.81E+06, Train scatter: [0.3904 0.0611 0.2892 0.4718]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3821 0.0621 0.2909 0.4715], Lowest was [0.3807 0.0621 0.2867 0.4612]
Median for last 10 epochs: [0.4135 0.0688 0.2909 0.4715], Epochs since improvement 0
  9%|▉         | 47/500 [1:00:00<9:17:14, 73.81s/it] 10%|▉         | 48/500 [1:01:31<9:54:54, 78.97s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.17E+06, Train scatter: [0.4243 0.0719 0.283  0.4516]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4115 0.0723 0.2867 0.4496], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.4135 0.0688 0.2875 0.4686], Epochs since improvement 0
 10%|▉         | 49/500 [1:02:33<9:13:58, 73.70s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 6.15E+11, Train scatter: [0.9353 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.9851], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.4135 0.0688 0.2909 0.4715], Epochs since improvement 2
 10%|█         | 50/500 [1:04:11<10:08:01, 81.07s/it] 10%|█         | 51/500 [1:05:13<9:22:54, 75.22s/it]  10%|█         | 52/500 [1:06:43<9:55:56, 79.81s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.07E+07, Train scatter: [0.9353 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.9851], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.4135 0.0723 0.3161 0.4912], Epochs since improvement 4
 11%|█         | 53/500 [1:07:45<9:13:44, 74.33s/it] 11%|█         | 54/500 [1:09:16<9:50:41, 79.47s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.96E+07, Train scatter: [0.9353 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.985 ], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.9197 0.169  0.5355 0.985 ], Epochs since improvement 6
 11%|█         | 55/500 [1:10:18<9:09:32, 74.10s/it] 11%|█         | 56/500 [1:11:49<9:45:39, 79.14s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.85E+07, Train scatter: [0.9353 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.9849], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.9197 0.169  0.5355 0.985 ], Epochs since improvement 8
 11%|█▏        | 57/500 [1:12:50<9:05:14, 73.85s/it] 12%|█▏        | 58/500 [1:14:21<9:41:39, 78.96s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.75E+07, Train scatter: [0.9352 0.1728 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9848], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.9197 0.169  0.5355 0.985 ], Epochs since improvement 10
 12%|█▏        | 59/500 [1:15:23<9:02:18, 73.78s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.58E+07, Train scatter: [0.9308 0.1715 0.5426 0.8985]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9152 0.1677 0.5341 0.888 ], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.9197 0.169  0.5355 0.9849], Epochs since improvement 12
 12%|█▏        | 60/500 [1:17:01<9:55:19, 81.18s/it] 12%|█▏        | 61/500 [1:18:03<9:11:07, 75.32s/it] 12%|█▏        | 62/500 [1:19:34<9:43:49, 79.98s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.04E+07, Train scatter: [0.9311 0.1175 0.5085 0.7149]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9155 0.115  0.5012 0.7063], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9848], Epochs since improvement 14
 13%|█▎        | 63/500 [1:20:35<9:02:23, 74.47s/it] 13%|█▎        | 64/500 [1:22:07<9:38:07, 79.56s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.84E+07, Train scatter: [0.9307 0.1126 0.5284 0.6816]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9152 0.1105 0.5202 0.6737], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.9155 0.1677 0.5341 0.888 ], Epochs since improvement 16
 13%|█▎        | 65/500 [1:23:09<8:58:10, 74.23s/it] 13%|█▎        | 66/500 [1:24:39<9:33:08, 79.24s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.74E+07, Train scatter: [0.9354 0.1738 0.5441 0.9961]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1699 0.5355 0.9856], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.9155 0.1677 0.5341 0.888 ], Epochs since improvement 18
 13%|█▎        | 67/500 [1:25:41<8:53:15, 73.89s/it] 14%|█▎        | 68/500 [1:27:11<9:27:42, 78.85s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.62E+07, Train scatter: [0.9332 0.1151 0.5432 0.6688]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9176 0.1125 0.5346 0.6605], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.9155 0.115  0.5341 0.7063], Epochs since improvement 20
 14%|█▍        | 69/500 [1:28:13<8:49:24, 73.70s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.78E+07, Train scatter: [0.9339 0.1703 0.5439 0.9906]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9183 0.1666 0.5353 0.9803], Lowest was [0.3807 0.0621 0.2867 0.4496]
Median for last 10 epochs: [0.9176 0.115  0.5346 0.7063], Epochs since improvement 22
 14%|█▍        | 69/500 [1:29:52<9:21:20, 78.15s/it]
Exited after 70 epochs due to early stopping
5392.07 seconds spent training, 10.784 seconds per epoch. Processed 6457 trees per second
[0.9183129  0.16654941 0.53529954 0.98031574]
{'epoch_exit': 69, 'scatter_m_star': 0.9183129, 'lowest_m_star': 0.38068038, 'last20_m_star': 0.9189615, 'last10_m_star': 0.9176331, 'scatter_v_disk': 0.16654941, 'lowest_v_disk': 0.062100023, 'last20_v_disk': 0.16834734, 'last10_v_disk': 0.11496416, 'scatter_m_cold': 0.53529954, 'lowest_m_cold': 0.28667298, 'last20_m_cold': 0.5353979, 'last10_m_cold': 0.5346355, 'scatter_sfr_100': 0.98031574, 'lowest_sfr_100': 0.44961467, 'last20_sfr_100': 0.9825827, 'last10_sfr_100': 0.7062822}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_poezko
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:25:09, 53.53s/it]  0%|          | 2/500 [02:13<9:35:15, 69.31s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.17   0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1647 0.5355 0.985 ], Lowest was [0.9196 0.1647 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1647 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:07<8:34:25, 62.10s/it]  1%|          | 4/500 [04:29<9:38:23, 69.97s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 9.06E+07, Train scatter: [0.9352 0.143  0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1385 0.5355 0.9851], Lowest was [0.9196 0.1385 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1385 0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:22<8:48:25, 64.05s/it]  1%|          | 6/500 [06:44<9:36:47, 70.06s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.59E+07, Train scatter: [0.935  0.1153 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9194 0.1138 0.5355 0.9851], Lowest was [0.9194 0.1138 0.5355 0.985 ]
Median for last 10 epochs: [0.9194 0.1138 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:38<8:51:49, 64.72s/it]  2%|▏         | 8/500 [08:59<9:33:19, 69.92s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.31E+07, Train scatter: [0.9335 0.1033 0.5438 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.918  0.1045 0.5352 0.9851], Lowest was [0.918  0.1045 0.5352 0.985 ]
Median for last 10 epochs: [0.9187 0.1092 0.5354 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [09:53<8:50:11, 64.79s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 9.68E+07, Train scatter: [0.9352 0.1605 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1542 0.5355 0.9851], Lowest was [0.918  0.1045 0.5352 0.985 ]
Median for last 10 epochs: [0.9194 0.1138 0.5355 0.9851], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:21<9:48:16, 72.03s/it]  2%|▏         | 11/500 [12:14<9:01:11, 66.40s/it]  2%|▏         | 12/500 [13:35<9:35:39, 70.78s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.30E+07, Train scatter: [0.9345 0.1367 0.544  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9189 0.1333 0.5354 0.9851], Lowest was [0.918  0.1045 0.5352 0.985 ]
Median for last 10 epochs: [0.9194 0.1333 0.5355 0.9851], Epochs since improvement 4
  3%|▎         | 13/500 [14:29<8:52:46, 65.64s/it]  3%|▎         | 14/500 [15:50<9:28:29, 70.18s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 8.04E+07, Train scatter: [0.8897 0.11   0.5439 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8751 0.11   0.5353 0.985 ], Lowest was [0.8751 0.1045 0.5352 0.985 ]
Median for last 10 epochs: [0.9189 0.1138 0.5354 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [16:43<8:47:22, 65.24s/it]  3%|▎         | 16/500 [18:05<9:25:27, 70.10s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.90E+07, Train scatter: [0.7527 0.1025 0.5433 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7453 0.103  0.5348 0.985 ], Lowest was [0.7453 0.103  0.5348 0.985 ]
Median for last 10 epochs: [0.918  0.11   0.5353 0.9851], Epochs since improvement 0
  3%|▎         | 17/500 [18:59<8:44:48, 65.19s/it]  4%|▎         | 18/500 [20:19<9:21:12, 69.86s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.77E+07, Train scatter: [0.5238 0.0962 0.532  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5225 0.0969 0.5241 0.9851], Lowest was [0.5225 0.0969 0.5241 0.985 ]
Median for last 10 epochs: [0.8751 0.11   0.5353 0.9851], Epochs since improvement 0
  4%|▍         | 19/500 [21:13<8:41:08, 65.01s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.64E+07, Train scatter: [0.5094 0.0951 0.4808 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5087 0.0949 0.4735 0.9851], Lowest was [0.5087 0.0949 0.4735 0.985 ]
Median for last 10 epochs: [0.7453 0.103  0.5348 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:42<9:36:38, 72.08s/it]  4%|▍         | 21/500 [23:35<8:51:06, 66.53s/it]  4%|▍         | 22/500 [24:58<9:28:05, 71.31s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.47E+07, Train scatter: [0.5264 0.0913 0.4109 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5222 0.0913 0.4106 0.9851], Lowest was [0.5087 0.0913 0.4106 0.985 ]
Median for last 10 epochs: [0.5225 0.0969 0.5241 0.9851], Epochs since improvement 0
  5%|▍         | 23/500 [25:51<8:44:27, 65.97s/it]  5%|▍         | 24/500 [27:13<9:20:08, 70.61s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.37E+07, Train scatter: [0.5163 0.0879 0.3554 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5326 0.0894 0.3651 0.9851], Lowest was [0.5087 0.0894 0.3651 0.985 ]
Median for last 10 epochs: [0.5225 0.0949 0.4735 0.9851], Epochs since improvement 0
  5%|▌         | 25/500 [28:06<8:38:24, 65.48s/it]  5%|▌         | 26/500 [29:28<9:15:54, 70.37s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.31E+07, Train scatter: [0.4993 0.084  0.3416 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5138 0.0859 0.3481 0.9851], Lowest was [0.5087 0.0859 0.3481 0.985 ]
Median for last 10 epochs: [0.5222 0.0913 0.4106 0.9851], Epochs since improvement 0
  5%|▌         | 27/500 [30:22<8:35:21, 65.37s/it]  6%|▌         | 28/500 [31:42<9:10:51, 70.02s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.29E+07, Train scatter: [0.5007 0.0867 0.347  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5088 0.0882 0.3518 0.9851], Lowest was [0.5087 0.0859 0.3481 0.985 ]
Median for last 10 epochs: [0.5138 0.0894 0.3651 0.9851], Epochs since improvement 2
  6%|▌         | 29/500 [32:36<8:31:43, 65.19s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.23E+07, Train scatter: [0.4648 0.0816 0.3318 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4779 0.0839 0.3413 0.9851], Lowest was [0.4779 0.0839 0.3413 0.985 ]
Median for last 10 epochs: [0.5138 0.0882 0.3518 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [34:05<9:24:51, 72.11s/it]  6%|▌         | 31/500 [34:59<8:41:34, 66.73s/it]  6%|▋         | 32/500 [36:19<9:12:41, 70.86s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.19E+07, Train scatter: [0.487  0.0809 0.3487 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4917 0.0814 0.3541 0.9851], Lowest was [0.4779 0.0814 0.3413 0.985 ]
Median for last 10 epochs: [0.5088 0.0859 0.3518 0.9851], Epochs since improvement 0
  7%|▋         | 33/500 [37:13<8:31:25, 65.71s/it]  7%|▋         | 34/500 [38:35<9:08:40, 70.64s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.16E+07, Train scatter: [0.4721 0.0821 0.3137 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4804 0.0825 0.3193 0.9851], Lowest was [0.4779 0.0814 0.3193 0.985 ]
Median for last 10 epochs: [0.4917 0.0839 0.3481 0.9851], Epochs since improvement 0
  7%|▋         | 35/500 [39:29<8:28:45, 65.65s/it]  7%|▋         | 36/500 [40:50<9:03:34, 70.29s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.08E+07, Train scatter: [0.3763 0.0797 0.3131 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3972 0.0795 0.317  0.985 ], Lowest was [0.3972 0.0795 0.317  0.985 ]
Median for last 10 epochs: [0.4804 0.0825 0.3413 0.9851], Epochs since improvement 0
  7%|▋         | 37/500 [41:44<8:24:18, 65.35s/it]  8%|▊         | 38/500 [43:05<8:58:23, 69.92s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.83E+07, Train scatter: [0.4839 0.091  0.3178 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4895 0.091  0.3242 0.9848], Lowest was [0.3972 0.0795 0.317  0.9848]
Median for last 10 epochs: [0.4804 0.0825 0.3242 0.9851], Epochs since improvement 0
  8%|▊         | 39/500 [43:59<8:20:24, 65.13s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.48E+07, Train scatter: [0.4627 0.0807 0.3205 0.9949]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4623 0.0806 0.3248 0.9846], Lowest was [0.3972 0.0795 0.317  0.9846]
Median for last 10 epochs: [0.4804 0.0814 0.3242 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:27<9:12:58, 72.13s/it]  8%|▊         | 41/500 [46:21<8:29:45, 66.63s/it]  8%|▊         | 42/500 [47:43<9:03:24, 71.19s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 6.54E+06, Train scatter: [0.5086 0.084  0.3227 0.5675]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5205 0.084  0.327  0.5682], Lowest was [0.3972 0.0795 0.317  0.5682]
Median for last 10 epochs: [0.4804 0.0825 0.3242 0.9848], Epochs since improvement 0
  9%|▊         | 43/500 [48:36<8:22:10, 65.93s/it]  9%|▉         | 44/500 [49:58<8:57:23, 70.71s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.43E+06, Train scatter: [0.3822 0.0887 0.3214 0.5574]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.401  0.089  0.3247 0.5569], Lowest was [0.3972 0.0795 0.317  0.5569]
Median for last 10 epochs: [0.4623 0.084  0.3247 0.9846], Epochs since improvement 0
  9%|▉         | 45/500 [50:52<8:17:35, 65.62s/it]  9%|▉         | 46/500 [52:13<8:50:43, 70.14s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.23E+06, Train scatter: [0.4144 0.0829 0.3345 0.5836]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4086 0.082  0.3384 0.5838], Lowest was [0.3972 0.0795 0.317  0.5569]
Median for last 10 epochs: [0.4623 0.084  0.3248 0.5838], Epochs since improvement 2
  9%|▉         | 47/500 [53:07<8:13:09, 65.32s/it] 10%|▉         | 48/500 [54:28<8:47:38, 70.04s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.73E+06, Train scatter: [0.2789 0.0777 0.3351 0.5487]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2921 0.0778 0.3331 0.5482], Lowest was [0.2921 0.0778 0.317  0.5482]
Median for last 10 epochs: [0.4086 0.082  0.327  0.5682], Epochs since improvement 0
 10%|▉         | 49/500 [55:21<8:09:28, 65.12s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.69E+06, Train scatter: [0.3706 0.0775 0.3222 0.5405]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3571 0.0773 0.3254 0.5414], Lowest was [0.2921 0.0773 0.317  0.5414]
Median for last 10 epochs: [0.401  0.082  0.327  0.5569], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [56:51<9:02:38, 72.35s/it] 10%|█         | 51/500 [57:44<8:19:42, 66.78s/it] 10%|█         | 52/500 [59:06<8:51:52, 71.23s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 4.19E+06, Train scatter: [0.4326 0.0786 0.3305 0.5085]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4334 0.0779 0.34   0.5067], Lowest was [0.2921 0.0773 0.317  0.5067]
Median for last 10 epochs: [0.401  0.0779 0.3331 0.5482], Epochs since improvement 0
 11%|█         | 53/500 [1:00:00<8:11:26, 65.96s/it] 11%|█         | 54/500 [1:01:21<8:44:11, 70.52s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.39E+06, Train scatter: [0.41   0.077  0.3686 0.5827]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4106 0.0756 0.3646 0.583 ], Lowest was [0.2921 0.0756 0.317  0.5067]
Median for last 10 epochs: [0.4086 0.0778 0.3384 0.5482], Epochs since improvement 0
 11%|█         | 55/500 [1:02:15<8:05:37, 65.48s/it] 11%|█         | 56/500 [1:03:37<8:41:38, 70.49s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.17E+06, Train scatter: [0.4961 0.0763 0.3237 0.5424]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5239 0.0764 0.3301 0.5545], Lowest was [0.2921 0.0756 0.317  0.5067]
Median for last 10 epochs: [0.4106 0.0773 0.3331 0.5482], Epochs since improvement 2
 11%|█▏        | 57/500 [1:04:30<8:03:14, 65.45s/it] 12%|█▏        | 58/500 [1:05:52<8:37:55, 70.31s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.32E+06, Train scatter: [0.3014 0.0743 0.3044 0.5606]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3109 0.0746 0.3106 0.5621], Lowest was [0.2921 0.0746 0.3106 0.5067]
Median for last 10 epochs: [0.4106 0.0764 0.3301 0.5545], Epochs since improvement 0
 12%|█▏        | 59/500 [1:06:46<8:00:07, 65.32s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.16E+06, Train scatter: [0.2779 0.0728 0.2981 0.4769]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2927 0.0721 0.3    0.4753], Lowest was [0.2921 0.0721 0.3    0.4753]
Median for last 10 epochs: [0.4106 0.0756 0.3301 0.5545], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:08:15<8:51:22, 72.46s/it] 12%|█▏        | 61/500 [1:09:09<8:09:25, 66.89s/it] 12%|█▏        | 62/500 [1:10:31<8:41:13, 71.40s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.52E+06, Train scatter: [0.4092 0.0725 0.2965 0.4823]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4031 0.0721 0.2978 0.4816], Lowest was [0.2921 0.0721 0.2978 0.4753]
Median for last 10 epochs: [0.4031 0.0746 0.3106 0.5545], Epochs since improvement 0
 13%|█▎        | 63/500 [1:11:25<8:01:45, 66.15s/it] 13%|█▎        | 64/500 [1:12:46<8:32:49, 70.57s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.29E+06, Train scatter: [0.3268 0.073  0.3053 0.4901]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3445 0.0725 0.3079 0.4915], Lowest was [0.2921 0.0721 0.2978 0.4753]
Median for last 10 epochs: [0.3445 0.0725 0.3079 0.4915], Epochs since improvement 2
 13%|█▎        | 65/500 [1:13:39<7:55:28, 65.58s/it] 13%|█▎        | 66/500 [1:15:00<8:27:47, 70.20s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.89E+06, Train scatter: [0.2503 0.0699 0.2972 0.4713]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2723 0.07   0.3005 0.4725], Lowest was [0.2723 0.07   0.2978 0.4725]
Median for last 10 epochs: [0.3109 0.0721 0.3005 0.4816], Epochs since improvement 0
 13%|█▎        | 67/500 [1:15:54<7:50:34, 65.21s/it] 14%|█▎        | 68/500 [1:17:15<8:24:09, 70.02s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.67E+06, Train scatter: [0.318  0.0709 0.2929 0.4857]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.33   0.071  0.298  0.4903], Lowest was [0.2723 0.07   0.2978 0.4725]
Median for last 10 epochs: [0.33   0.0721 0.3    0.4816], Epochs since improvement 2
 14%|█▍        | 69/500 [1:18:09<7:48:01, 65.16s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.72E+06, Train scatter: [0.3051 0.0688 0.308  0.4825]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3205 0.0691 0.3189 0.488 ], Lowest was [0.2723 0.0691 0.2978 0.4725]
Median for last 10 epochs: [0.33   0.071  0.3005 0.488 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:19:38<8:38:18, 72.32s/it] 14%|█▍        | 71/500 [1:20:32<7:57:21, 66.76s/it] 14%|█▍        | 72/500 [1:21:53<8:27:54, 71.20s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 4.33E+06, Train scatter: [0.4995 0.0742 0.3372 0.5062]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4943 0.074  0.3382 0.5059], Lowest was [0.2723 0.0691 0.2978 0.4725]
Median for last 10 epochs: [0.33   0.071  0.3079 0.4903], Epochs since improvement 2
 15%|█▍        | 73/500 [1:22:47<7:49:18, 65.95s/it] 15%|█▍        | 74/500 [1:24:08<8:20:41, 70.52s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.69E+06, Train scatter: [0.3741 0.0674 0.3064 0.482 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3709 0.068  0.3122 0.4846], Lowest was [0.2723 0.068  0.2978 0.4725]
Median for last 10 epochs: [0.33   0.07   0.3122 0.488 ], Epochs since improvement 0
 15%|█▌        | 75/500 [1:25:02<7:43:53, 65.49s/it] 15%|█▌        | 76/500 [1:26:23<8:15:19, 70.09s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.50E+06, Train scatter: [0.2809 0.0674 0.2863 0.4815]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3295 0.0683 0.2884 0.4833], Lowest was [0.2723 0.068  0.2884 0.4725]
Median for last 10 epochs: [0.33   0.0691 0.3122 0.488 ], Epochs since improvement 0
 15%|█▌        | 77/500 [1:27:17<7:40:10, 65.27s/it] 16%|█▌        | 78/500 [1:28:38<8:12:53, 70.08s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.50E+06, Train scatter: [0.2287 0.0669 0.2846 0.4651]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2772 0.0686 0.2864 0.4663], Lowest was [0.2723 0.068  0.2864 0.4663]
Median for last 10 epochs: [0.3295 0.0686 0.3122 0.4846], Epochs since improvement 0
 16%|█▌        | 79/500 [1:29:32<7:37:21, 65.18s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.45E+06, Train scatter: [0.2347 0.0635 0.2784 0.4604]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2475 0.0641 0.2847 0.4634], Lowest was [0.2475 0.0641 0.2847 0.4634]
Median for last 10 epochs: [0.3295 0.0683 0.2884 0.4833], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:31:01<8:26:01, 72.29s/it] 16%|█▌        | 81/500 [1:31:55<7:46:37, 66.82s/it] 16%|█▋        | 82/500 [1:33:17<8:17:48, 71.46s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.36E+06, Train scatter: [0.2388 0.0629 0.2782 0.4744]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2979 0.063  0.2806 0.4744], Lowest was [0.2475 0.063  0.2806 0.4634]
Median for last 10 epochs: [0.2979 0.068  0.2864 0.4744], Epochs since improvement 0
 17%|█▋        | 83/500 [1:34:11<7:39:53, 66.17s/it] 17%|█▋        | 84/500 [1:35:32<8:10:02, 70.68s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.36E+06, Train scatter: [0.3251 0.0647 0.2875 0.5358]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3438 0.0648 0.2921 0.543 ], Lowest was [0.2475 0.063  0.2806 0.4634]
Median for last 10 epochs: [0.2979 0.0648 0.2864 0.4744], Epochs since improvement 2
 17%|█▋        | 85/500 [1:36:26<7:33:33, 65.57s/it] 17%|█▋        | 86/500 [1:37:46<8:03:19, 70.05s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.20E+06, Train scatter: [0.2879 0.0649 0.3124 0.4737]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3033 0.0651 0.3148 0.4766], Lowest was [0.2475 0.063  0.2806 0.4634]
Median for last 10 epochs: [0.2979 0.0648 0.2864 0.4744], Epochs since improvement 4
 17%|█▋        | 87/500 [1:38:40<7:28:20, 65.13s/it] 18%|█▊        | 88/500 [1:40:01<7:59:27, 69.82s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.24E+06, Train scatter: [0.3582 0.0653 0.3    0.4529]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.359  0.0654 0.2985 0.4536], Lowest was [0.2475 0.063  0.2806 0.4536]
Median for last 10 epochs: [0.3033 0.0648 0.2921 0.4744], Epochs since improvement 0
 18%|█▊        | 89/500 [1:40:55<7:25:10, 64.99s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.07E+06, Train scatter: [0.2658 0.059  0.2751 0.4588]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3027 0.059  0.2802 0.4605], Lowest was [0.2475 0.059  0.2802 0.4536]
Median for last 10 epochs: [0.3033 0.0648 0.2921 0.4744], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:42:23<8:11:30, 71.93s/it] 18%|█▊        | 91/500 [1:43:16<7:32:53, 66.44s/it] 18%|█▊        | 92/500 [1:44:38<8:02:25, 70.95s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.10E+06, Train scatter: [0.2947 0.0609 0.2698 0.4514]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3198 0.0614 0.2721 0.4521], Lowest was [0.2475 0.059  0.2721 0.4521]
Median for last 10 epochs: [0.3198 0.0648 0.2921 0.4605], Epochs since improvement 0
 19%|█▊        | 93/500 [1:45:32<7:26:16, 65.79s/it] 19%|█▉        | 94/500 [1:46:52<7:55:21, 70.25s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.15E+06, Train scatter: [0.219  0.0589 0.2729 0.456 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2362 0.0592 0.2754 0.4524], Lowest was [0.2362 0.059  0.2721 0.4521]
Median for last 10 epochs: [0.3033 0.0614 0.2802 0.4536], Epochs since improvement 0
 19%|█▉        | 95/500 [1:47:46<7:21:00, 65.34s/it] 19%|█▉        | 96/500 [1:49:07<7:51:59, 70.10s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.03E+06, Train scatter: [0.2216 0.0575 0.2625 0.4474]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2384 0.0579 0.2699 0.4545], Lowest was [0.2362 0.0579 0.2699 0.4521]
Median for last 10 epochs: [0.3027 0.0592 0.2754 0.4536], Epochs since improvement 0
 19%|█▉        | 97/500 [1:50:01<7:18:13, 65.24s/it] 20%|█▉        | 98/500 [1:51:22<7:49:08, 70.02s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.06E+06, Train scatter: [0.2402 0.0559 0.2638 0.4434]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2525 0.0565 0.2688 0.4435], Lowest was [0.2362 0.0565 0.2688 0.4435]
Median for last 10 epochs: [0.2525 0.059  0.2721 0.4524], Epochs since improvement 0
 20%|█▉        | 99/500 [1:52:16<7:15:38, 65.18s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 1.92E+06, Train scatter: [0.2592 0.0609 0.2891 0.4418]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2735 0.0608 0.2933 0.4457], Lowest was [0.2362 0.0565 0.2688 0.4435]
Median for last 10 epochs: [0.2525 0.0592 0.2721 0.4521], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:53:46<8:02:46, 72.42s/it] 20%|██        | 101/500 [1:54:39<7:24:11, 66.80s/it] 20%|██        | 102/500 [1:56:01<7:52:24, 71.22s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 1.89E+06, Train scatter: [0.2205 0.0575 0.2663 0.4416]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2362 0.0567 0.2711 0.445 ], Lowest was [0.2362 0.0565 0.2688 0.4435]
Median for last 10 epochs: [0.2384 0.0579 0.2711 0.4457], Epochs since improvement 0
 21%|██        | 103/500 [1:56:54<7:15:59, 65.89s/it] 21%|██        | 104/500 [1:58:16<7:45:36, 70.55s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 1.78E+06, Train scatter: [0.2051 0.0544 0.2586 0.4365]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2194 0.0547 0.2647 0.4385], Lowest was [0.2194 0.0547 0.2647 0.4385]
Median for last 10 epochs: [0.2384 0.0567 0.2699 0.445 ], Epochs since improvement 0
 21%|██        | 105/500 [1:59:09<7:11:11, 65.50s/it] 21%|██        | 106/500 [2:00:31<7:41:54, 70.34s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 1.74E+06, Train scatter: [0.2729 0.0599 0.2577 0.4467]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2735 0.0598 0.2619 0.45  ], Lowest was [0.2194 0.0547 0.2619 0.4385]
Median for last 10 epochs: [0.2525 0.0567 0.2688 0.445 ], Epochs since improvement 0
 21%|██▏       | 107/500 [2:01:25<7:08:20, 65.40s/it] 22%|██▏       | 108/500 [2:02:46<7:38:44, 70.22s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 1.68E+06, Train scatter: [0.2099 0.0576 0.2698 0.4348]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2324 0.0584 0.2759 0.4404], Lowest was [0.2194 0.0547 0.2619 0.4385]
Median for last 10 epochs: [0.2362 0.0584 0.2711 0.445 ], Epochs since improvement 2
 22%|██▏       | 109/500 [2:03:40<7:04:58, 65.21s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 1.59E+06, Train scatter: [0.3026 0.0628 0.2733 0.4576]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3131 0.0639 0.28   0.464 ], Lowest was [0.2194 0.0547 0.2619 0.4385]
Median for last 10 epochs: [0.2362 0.0584 0.2711 0.445 ], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:05:09<7:50:44, 72.42s/it] 22%|██▏       | 111/500 [2:06:03<7:13:10, 66.81s/it] 22%|██▏       | 112/500 [2:07:24<7:39:18, 71.03s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.43E+06, Train scatter: [0.3912 0.0523 0.2575 0.4308]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3908 0.0523 0.2599 0.4346], Lowest was [0.2194 0.0523 0.2599 0.4346]
Median for last 10 epochs: [0.2735 0.0584 0.2647 0.4404], Epochs since improvement 0
 23%|██▎       | 113/500 [2:08:18<7:05:08, 65.91s/it] 23%|██▎       | 114/500 [2:09:39<7:34:04, 70.58s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.41E+06, Train scatter: [0.196  0.0516 0.2472 0.4235]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2047 0.0524 0.252  0.425 ], Lowest was [0.2047 0.0523 0.252  0.425 ]
Median for last 10 epochs: [0.2735 0.0584 0.2619 0.4404], Epochs since improvement 0
 23%|██▎       | 115/500 [2:10:33<7:00:42, 65.56s/it] 23%|██▎       | 116/500 [2:11:54<7:29:13, 70.19s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.39E+06, Train scatter: [0.2688 0.0584 0.2573 0.4348]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2838 0.0585 0.2614 0.4407], Lowest was [0.2047 0.0523 0.252  0.425 ]
Median for last 10 epochs: [0.2838 0.0584 0.2614 0.4404], Epochs since improvement 2
 23%|██▎       | 117/500 [2:12:48<6:56:33, 65.26s/it] 24%|██▎       | 118/500 [2:14:10<7:27:08, 70.23s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.27E+06, Train scatter: [0.1907 0.0521 0.2473 0.4225]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2003 0.0528 0.2523 0.4241], Lowest was [0.2003 0.0523 0.252  0.4241]
Median for last 10 epochs: [0.2838 0.0528 0.2599 0.4346], Epochs since improvement 0
 24%|██▍       | 119/500 [2:15:03<6:54:33, 65.29s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.28E+06, Train scatter: [0.3558 0.0553 0.2527 0.4296]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.344  0.0556 0.2564 0.4268], Lowest was [0.2003 0.0523 0.252  0.4241]
Median for last 10 epochs: [0.2838 0.0528 0.2564 0.4268], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 24%|██▍       | 120/500 [2:16:32<7:37:07, 72.18s/it] 24%|██▍       | 121/500 [2:17:25<7:00:43, 66.61s/it] 24%|██▍       | 122/500 [2:18:47<7:28:27, 71.18s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 1.15E+06, Train scatter: [0.2365 0.0524 0.2543 0.4231]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2336 0.0528 0.2583 0.4256], Lowest was [0.2003 0.0523 0.252  0.4241]
Median for last 10 epochs: [0.2336 0.0528 0.2564 0.4256], Epochs since improvement 4
 25%|██▍       | 123/500 [2:19:41<6:54:09, 65.91s/it] 25%|██▍       | 124/500 [2:21:02<7:21:47, 70.50s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.28E+06, Train scatter: [0.1861 0.052  0.2578 0.4307]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1913 0.0521 0.2603 0.4262], Lowest was [0.1913 0.0521 0.252  0.4241]
Median for last 10 epochs: [0.2336 0.0528 0.2583 0.4262], Epochs since improvement 0
 25%|██▌       | 125/500 [2:21:56<6:49:06, 65.46s/it] 25%|██▌       | 126/500 [2:23:17<7:18:20, 70.32s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.09E+06, Train scatter: [0.2809 0.0641 0.2833 0.4657]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2847 0.065  0.2926 0.4739], Lowest was [0.1913 0.0521 0.252  0.4241]
Median for last 10 epochs: [0.2336 0.0528 0.2583 0.4262], Epochs since improvement 2
 25%|██▌       | 127/500 [2:24:11<6:46:19, 65.36s/it] 26%|██▌       | 128/500 [2:25:32<7:15:05, 70.18s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 1.08E+06, Train scatter: [0.2133 0.05   0.244  0.4167]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2174 0.0501 0.2475 0.4167], Lowest was [0.1913 0.0501 0.2475 0.4167]
Median for last 10 epochs: [0.2336 0.0528 0.2583 0.4262], Epochs since improvement 0
 26%|██▌       | 129/500 [2:26:26<6:44:00, 65.34s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 1.06E+06, Train scatter: [0.1832 0.0526 0.2534 0.4221]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1918 0.0532 0.2576 0.4217], Lowest was [0.1913 0.0501 0.2475 0.4167]
Median for last 10 epochs: [0.2174 0.0528 0.2583 0.4256], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 26%|██▌       | 130/500 [2:27:55<7:25:41, 72.27s/it] 26%|██▌       | 131/500 [2:28:49<6:50:20, 66.72s/it] 26%|██▋       | 132/500 [2:30:10<7:16:13, 71.12s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 1.06E+06, Train scatter: [0.4136 0.0987 0.3747 0.6303]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4159 0.095  0.3721 0.6092], Lowest was [0.1913 0.0501 0.2475 0.4167]
Median for last 10 epochs: [0.2174 0.0532 0.2603 0.4262], Epochs since improvement 4
 27%|██▋       | 133/500 [2:31:04<6:43:11, 65.92s/it] 27%|██▋       | 134/500 [2:32:26<7:11:09, 70.68s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 1.02E+06, Train scatter: [0.1832 0.0512 0.2599 0.4199]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1889 0.0516 0.2624 0.421 ], Lowest was [0.1889 0.0501 0.2475 0.4167]
Median for last 10 epochs: [0.2174 0.0532 0.2624 0.4217], Epochs since improvement 0
 27%|██▋       | 135/500 [2:33:19<6:39:03, 65.60s/it] 27%|██▋       | 136/500 [2:34:41<7:07:47, 70.52s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 9.35E+05, Train scatter: [0.243  0.0509 0.2548 0.4144]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2566 0.0513 0.2586 0.4188], Lowest was [0.1889 0.0501 0.2475 0.4167]
Median for last 10 epochs: [0.2174 0.0516 0.2586 0.421 ], Epochs since improvement 2
 27%|██▋       | 137/500 [2:35:35<6:35:39, 65.40s/it] 28%|██▊       | 138/500 [2:36:57<7:05:21, 70.50s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: 8.75E+05, Train scatter: [0.2247 0.0557 0.2602 0.4171]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2346 0.0557 0.2636 0.4194], Lowest was [0.1889 0.0501 0.2475 0.4167]
Median for last 10 epochs: [0.2346 0.0532 0.2624 0.421 ], Epochs since improvement 4
 28%|██▊       | 139/500 [2:37:51<6:33:39, 65.43s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: 8.58E+05, Train scatter: [0.2293 0.0544 0.2708 0.4275]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2266 0.0547 0.273  0.4309], Lowest was [0.1889 0.0501 0.2475 0.4167]
Median for last 10 epochs: [0.2346 0.0547 0.2636 0.421 ], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 28%|██▊       | 140/500 [2:39:22<7:18:51, 73.14s/it] 28%|██▊       | 141/500 [2:40:16<6:43:00, 67.35s/it] 28%|██▊       | 142/500 [2:41:38<7:08:36, 71.83s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: 8.01E+05, Train scatter: [0.2043 0.0643 0.2506 0.4512]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.276  0.0633 0.2533 0.4419], Lowest was [0.1889 0.0501 0.2475 0.4167]
Median for last 10 epochs: [0.2346 0.0547 0.2624 0.421 ], Epochs since improvement 8
 29%|██▊       | 143/500 [2:42:32<6:35:02, 66.39s/it] 29%|██▉       | 144/500 [2:43:53<7:00:47, 70.92s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 7.60E+05, Train scatter: [0.1854 0.0491 0.2451 0.418 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1992 0.0496 0.2499 0.4227], Lowest was [0.1889 0.0496 0.2475 0.4167]
Median for last 10 epochs: [0.2346 0.0547 0.2586 0.4227], Epochs since improvement 0
 29%|██▉       | 145/500 [2:44:47<6:28:59, 65.74s/it] 29%|██▉       | 146/500 [2:46:09<6:56:29, 70.59s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 7.42E+05, Train scatter: [0.1697 0.0483 0.2422 0.4065]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1735 0.0485 0.2476 0.4031], Lowest was [0.1735 0.0485 0.2475 0.4031]
Median for last 10 epochs: [0.2266 0.0547 0.2533 0.4227], Epochs since improvement 0
 29%|██▉       | 147/500 [2:47:03<6:25:41, 65.56s/it] 30%|██▉       | 148/500 [2:48:24<6:52:01, 70.23s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 7.07E+05, Train scatter: [0.2234 0.052  0.2491 0.4175]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2307 0.0516 0.2537 0.4214], Lowest was [0.1735 0.0485 0.2475 0.4031]
Median for last 10 epochs: [0.2266 0.0516 0.2533 0.4227], Epochs since improvement 2
 30%|██▉       | 149/500 [2:49:18<6:22:38, 65.41s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 6.14E+05, Train scatter: [0.1665 0.0502 0.2431 0.4145]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1737 0.0505 0.2487 0.4138], Lowest was [0.1735 0.0485 0.2475 0.4031]
Median for last 10 epochs: [0.1992 0.0505 0.2499 0.4214], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 30%|███       | 150/500 [2:50:46<7:01:29, 72.25s/it] 30%|███       | 151/500 [2:51:40<6:28:15, 66.75s/it] 30%|███       | 152/500 [2:53:02<6:53:41, 71.33s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 5.86E+05, Train scatter: [0.1743 0.0473 0.2495 0.4144]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1812 0.0475 0.2533 0.4177], Lowest was [0.1735 0.0475 0.2475 0.4031]
Median for last 10 epochs: [0.1812 0.0496 0.2499 0.4177], Epochs since improvement 0
 31%|███       | 153/500 [2:53:56<6:22:04, 66.06s/it] 31%|███       | 154/500 [2:55:19<6:50:03, 71.11s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 5.10E+05, Train scatter: [0.1976 0.0525 0.267  0.4095]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2099 0.0522 0.2672 0.4075], Lowest was [0.1735 0.0475 0.2475 0.4031]
Median for last 10 epochs: [0.1812 0.0505 0.2533 0.4138], Epochs since improvement 2
 31%|███       | 155/500 [2:56:12<6:18:44, 65.87s/it] 31%|███       | 156/500 [2:57:34<6:44:37, 70.57s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 4.97E+05, Train scatter: [0.1688 0.0465 0.2363 0.3997]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1688 0.0467 0.24   0.3984], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.1812 0.0505 0.2533 0.4138], Epochs since improvement 0
 31%|███▏      | 157/500 [2:58:28<6:14:46, 65.56s/it] 32%|███▏      | 158/500 [2:59:49<6:40:18, 70.23s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 4.25E+05, Train scatter: [0.2318 0.0494 0.2492 0.4128]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2462 0.0504 0.255  0.42  ], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.1812 0.0504 0.2533 0.4138], Epochs since improvement 2
 32%|███▏      | 159/500 [3:00:43<6:11:32, 65.37s/it]Epoch: 160 done with learning rate 9.04E-03, Train loss: 3.79E+05, Train scatter: [0.2038 0.0558 0.2737 0.4232]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2214 0.0559 0.2759 0.425 ], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.2099 0.0504 0.255  0.4177], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 32%|███▏      | 160/500 [3:02:11<6:49:23, 72.24s/it] 32%|███▏      | 161/500 [3:03:05<6:17:13, 66.77s/it] 32%|███▏      | 162/500 [3:04:27<6:40:53, 71.16s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: 1.69E+06, Train scatter: [0.9238 0.1729 0.5441 0.9928]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.91   0.1692 0.5355 0.9833], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.2214 0.0522 0.2672 0.42  ], Epochs since improvement 6
 33%|███▎      | 163/500 [3:05:21<6:10:52, 66.03s/it] 33%|███▎      | 164/500 [3:06:43<6:37:11, 70.93s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: 1.21E+06, Train scatter: [0.4467 0.0823 0.475  0.5735]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4461 0.0814 0.4685 0.5628], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.2462 0.0559 0.2759 0.425 ], Epochs since improvement 8
 33%|███▎      | 165/500 [3:07:37<6:07:31, 65.83s/it] 33%|███▎      | 166/500 [3:08:59<6:32:39, 70.54s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: 5.22E+05, Train scatter: [0.409  0.072  0.4713 0.5355]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4026 0.0703 0.4645 0.5278], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.4026 0.0703 0.4645 0.5278], Epochs since improvement 10
 33%|███▎      | 167/500 [3:09:52<6:03:50, 65.56s/it] 34%|███▎      | 168/500 [3:11:13<6:27:30, 70.03s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: 2.63E+05, Train scatter: [0.4331 0.0685 0.5332 0.5117]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4201 0.0676 0.5249 0.5038], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.4201 0.0703 0.4685 0.5278], Epochs since improvement 12
 34%|███▍      | 169/500 [3:12:07<5:59:56, 65.25s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: 1.25E+05, Train scatter: [0.3638 0.0609 0.5345 0.4894]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3523 0.0609 0.5263 0.4864], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.4201 0.0703 0.5249 0.5278], Epochs since improvement 14
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 34%|███▍      | 170/500 [3:13:35<6:35:46, 71.96s/it] 34%|███▍      | 171/500 [3:14:29<6:05:14, 66.61s/it] 34%|███▍      | 172/500 [3:15:50<6:28:37, 71.09s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: 2.51E+04, Train scatter: [0.4179 0.057  0.5211 0.4737]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4073 0.0575 0.5137 0.4692], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.4073 0.0676 0.5137 0.5038], Epochs since improvement 16
 35%|███▍      | 173/500 [3:16:44<5:59:26, 65.95s/it] 35%|███▍      | 174/500 [3:18:05<6:22:25, 70.38s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -5.87E+04, Train scatter: [0.3816 0.0563 0.4886 0.4645]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3711 0.0563 0.4796 0.4573], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.4026 0.0609 0.5137 0.4864], Epochs since improvement 18
 35%|███▌      | 175/500 [3:18:59<5:54:30, 65.45s/it] 35%|███▌      | 176/500 [3:20:20<6:19:15, 70.23s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -9.51E+04, Train scatter: [0.3655 0.0562 0.4726 0.4551]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3573 0.0562 0.4656 0.4503], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.3711 0.0575 0.5137 0.4692], Epochs since improvement 20
 35%|███▌      | 177/500 [3:21:14<5:51:46, 65.35s/it] 35%|███▌      | 177/500 [3:22:36<6:09:42, 68.68s/it]
Epoch: 178 done with learning rate 8.62E-03, Train loss: -1.12E+05, Train scatter: [0.4353 0.0571 0.5688 0.4723]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4266 0.0579 0.5297 0.4649], Lowest was [0.1688 0.0467 0.24   0.3984]
Median for last 10 epochs: [0.3711 0.0575 0.5137 0.4649], Epochs since improvement 22
Exited after 178 epochs due to early stopping
12156.01 seconds spent training, 24.312 seconds per epoch. Processed 2864 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.42654324 0.0578531  0.5296416  0.4648738 ]
{'epoch_exit': 177, 'scatter_m_star': 0.42654324, 'lowest_m_star': 0.16875888, 'last20_m_star': 0.40497732, 'last10_m_star': 0.3710523, 'scatter_v_disk': 0.057853095, 'lowest_v_disk': 0.046734065, 'last20_v_disk': 0.059401408, 'last10_v_disk': 0.057450365, 'scatter_m_cold': 0.5296416, 'lowest_m_cold': 0.23998259, 'last20_m_cold': 0.49665508, 'last10_m_cold': 0.5137393, 'scatter_sfr_100': 0.4648738, 'lowest_sfr_100': 0.39839137, 'last20_sfr_100': 0.47782427, 'last10_sfr_100': 0.46488783}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
