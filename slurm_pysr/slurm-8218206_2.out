Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_afwvdj
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:33<4:37:24, 33.36s/it]  0%|          | 2/500 [01:21<5:47:20, 41.85s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.27E+07, Train scatter: [0.9352 0.1702 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.31E-01
Test scatter: [0.9196 0.1697 0.5355 0.9851], Lowest was [0.9196 0.1697 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1697 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:51<5:04:41, 36.78s/it]  1%|          | 4/500 [02:39<5:39:46, 41.10s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 6.86E+06, Train scatter: [0.9351 0.1444 0.5439 0.9954]
L1 regularization loss: 1.53E+00, L2 regularization loss: 3.54E-01
Test scatter: [0.9195 0.1432 0.5353 0.985 ], Lowest was [0.9195 0.1432 0.5353 0.985 ]
Median for last 10 epochs: [0.9195 0.1432 0.5353 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:10<5:08:18, 37.37s/it]  1%|          | 6/500 [03:58<5:37:12, 40.96s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 4.80E+06, Train scatter: [0.9339 0.1128 0.5413 0.651 ]
L1 regularization loss: 1.57E+00, L2 regularization loss: 3.91E-01
Test scatter: [0.9182 0.1138 0.5327 0.6408], Lowest was [0.9182 0.1138 0.5327 0.6408]
Median for last 10 epochs: [0.9182 0.1138 0.5327 0.6408], Epochs since improvement 0
  1%|▏         | 7/500 [04:29<5:09:36, 37.68s/it]  2%|▏         | 8/500 [05:17<5:35:38, 40.93s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 3.89E+06, Train scatter: [0.9168 0.0995 0.5316 0.5968]
L1 regularization loss: 1.59E+00, L2 regularization loss: 4.02E-01
Test scatter: [0.9015 0.1007 0.5231 0.5934], Lowest was [0.9015 0.1007 0.5231 0.5934]
Median for last 10 epochs: [0.9099 0.1072 0.5279 0.6171], Epochs since improvement 0
  2%|▏         | 9/500 [05:47<5:09:12, 37.79s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 3.22E+06, Train scatter: [0.7841 0.097  0.4502 0.6097]
L1 regularization loss: 1.61E+00, L2 regularization loss: 4.11E-01
Test scatter: [0.7775 0.0986 0.4429 0.6086], Lowest was [0.7775 0.0986 0.4429 0.5934]
Median for last 10 epochs: [0.9015 0.1007 0.5231 0.6086], Epochs since improvement 0
  2%|▏         | 10/500 [06:41<5:47:49, 42.59s/it]  2%|▏         | 11/500 [07:12<5:17:51, 39.00s/it]  2%|▏         | 12/500 [07:59<5:38:06, 41.57s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.19E+06, Train scatter: [0.6073 0.094  0.3915 0.6096]
L1 regularization loss: 1.62E+00, L2 regularization loss: 4.19E-01
Test scatter: [0.6097 0.0972 0.3942 0.6183], Lowest was [0.6097 0.0972 0.3942 0.5934]
Median for last 10 epochs: [0.9015 0.1007 0.5231 0.6183], Epochs since improvement 0
  3%|▎         | 13/500 [08:30<5:11:18, 38.35s/it]  3%|▎         | 14/500 [09:18<5:33:52, 41.22s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.55E+06, Train scatter: [0.5712 0.0904 0.3632 0.5998]
L1 regularization loss: 1.63E+00, L2 regularization loss: 4.27E-01
Test scatter: [0.5736 0.0924 0.3657 0.6004], Lowest was [0.5736 0.0924 0.3657 0.5934]
Median for last 10 epochs: [0.7775 0.0986 0.4429 0.6086], Epochs since improvement 0
  3%|▎         | 15/500 [09:49<5:08:17, 38.14s/it]  3%|▎         | 16/500 [10:37<5:31:24, 41.08s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.30E+06, Train scatter: [0.5199 0.0877 0.3504 0.5812]
L1 regularization loss: 1.65E+00, L2 regularization loss: 4.35E-01
Test scatter: [0.5268 0.0906 0.3588 0.5853], Lowest was [0.5268 0.0906 0.3588 0.5853]
Median for last 10 epochs: [0.6097 0.0972 0.3942 0.6004], Epochs since improvement 0
  3%|▎         | 17/500 [11:08<5:06:12, 38.04s/it]  4%|▎         | 18/500 [11:56<5:29:32, 41.02s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.09E+06, Train scatter: [0.7159 0.0846 0.346  0.5771]
L1 regularization loss: 1.67E+00, L2 regularization loss: 4.45E-01
Test scatter: [0.6689 0.0866 0.3489 0.5798], Lowest was [0.5268 0.0866 0.3489 0.5798]
Median for last 10 epochs: [0.6097 0.0924 0.3657 0.6004], Epochs since improvement 0
  4%|▍         | 19/500 [12:27<5:04:58, 38.04s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 9.31E+05, Train scatter: [0.5239 0.0823 0.3322 0.5463]
L1 regularization loss: 1.70E+00, L2 regularization loss: 4.58E-01
Test scatter: [0.5294 0.0841 0.3417 0.545 ], Lowest was [0.5268 0.0841 0.3417 0.545 ]
Median for last 10 epochs: [0.5736 0.0906 0.3588 0.5853], Epochs since improvement 0
  4%|▍         | 20/500 [13:20<5:40:14, 42.53s/it]  4%|▍         | 21/500 [13:51<5:12:08, 39.10s/it]  4%|▍         | 22/500 [14:39<5:32:37, 41.75s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.59E+05, Train scatter: [0.4514 0.0804 0.329  0.5481]
L1 regularization loss: 1.73E+00, L2 regularization loss: 4.72E-01
Test scatter: [0.453  0.081  0.3333 0.5388], Lowest was [0.453  0.081  0.3333 0.5388]
Median for last 10 epochs: [0.5294 0.0866 0.3489 0.5798], Epochs since improvement 0
  5%|▍         | 23/500 [15:10<5:06:01, 38.49s/it]  5%|▍         | 24/500 [15:58<5:27:45, 41.31s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.22E+05, Train scatter: [0.4313 0.0782 0.3383 0.5378]
L1 regularization loss: 1.77E+00, L2 regularization loss: 4.88E-01
Test scatter: [0.434  0.0791 0.3452 0.5383], Lowest was [0.434  0.0791 0.3333 0.5383]
Median for last 10 epochs: [0.5268 0.0841 0.3452 0.545 ], Epochs since improvement 0
  5%|▌         | 25/500 [16:29<5:02:12, 38.17s/it]  5%|▌         | 26/500 [17:16<5:24:08, 41.03s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 6.88E+05, Train scatter: [0.4692 0.0781 0.3098 0.5427]
L1 regularization loss: 1.80E+00, L2 regularization loss: 5.06E-01
Test scatter: [0.4703 0.0784 0.3168 0.5432], Lowest was [0.434  0.0784 0.3168 0.5383]
Median for last 10 epochs: [0.4703 0.081  0.3417 0.5432], Epochs since improvement 0
  5%|▌         | 27/500 [17:47<4:59:22, 37.98s/it]  6%|▌         | 28/500 [18:36<5:23:39, 41.14s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 5.06E+05, Train scatter: [0.4878 0.0757 0.2884 0.5232]
L1 regularization loss: 1.84E+00, L2 regularization loss: 5.24E-01
Test scatter: [0.485  0.0767 0.2969 0.5237], Lowest was [0.434  0.0767 0.2969 0.5237]
Median for last 10 epochs: [0.4703 0.0791 0.3333 0.5388], Epochs since improvement 0
  6%|▌         | 29/500 [19:06<4:58:41, 38.05s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.47E+05, Train scatter: [0.4351 0.0747 0.3044 0.5077]
L1 regularization loss: 1.88E+00, L2 regularization loss: 5.46E-01
Test scatter: [0.4391 0.076  0.3127 0.5059], Lowest was [0.434  0.076  0.2969 0.5059]
Median for last 10 epochs: [0.453  0.0784 0.3168 0.5383], Epochs since improvement 0
  6%|▌         | 30/500 [19:59<5:32:50, 42.49s/it]  6%|▌         | 31/500 [20:30<5:04:53, 39.01s/it]  6%|▋         | 32/500 [21:19<5:26:22, 41.84s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.26E+05, Train scatter: [0.43   0.0774 0.2898 0.5435]
L1 regularization loss: 1.92E+00, L2 regularization loss: 5.73E-01
Test scatter: [0.4301 0.078  0.2951 0.5389], Lowest was [0.4301 0.076  0.2951 0.5059]
Median for last 10 epochs: [0.4391 0.078  0.3127 0.5383], Epochs since improvement 0
  7%|▋         | 33/500 [21:50<5:00:18, 38.58s/it]  7%|▋         | 34/500 [22:38<5:22:03, 41.47s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.35E+05, Train scatter: [0.6346 0.0723 0.3332 0.5137]
L1 regularization loss: 1.95E+00, L2 regularization loss: 5.99E-01
Test scatter: [0.6193 0.0735 0.3413 0.506 ], Lowest was [0.4301 0.0735 0.2951 0.5059]
Median for last 10 epochs: [0.4703 0.0767 0.3127 0.5237], Epochs since improvement 0
  7%|▋         | 35/500 [23:08<4:56:10, 38.22s/it]  7%|▋         | 36/500 [23:57<5:19:18, 41.29s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.51E+05, Train scatter: [0.4018 0.0713 0.2859 0.5228]
L1 regularization loss: 1.99E+00, L2 regularization loss: 6.27E-01
Test scatter: [0.3979 0.071  0.2947 0.5107], Lowest was [0.3979 0.071  0.2947 0.5059]
Median for last 10 epochs: [0.4391 0.076  0.2969 0.5107], Epochs since improvement 0
  7%|▋         | 37/500 [24:28<4:54:06, 38.11s/it]  8%|▊         | 38/500 [25:16<5:17:09, 41.19s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.37E+05, Train scatter: [0.4507 0.071  0.291  0.5063]
L1 regularization loss: 2.02E+00, L2 regularization loss: 6.58E-01
Test scatter: [0.4432 0.0717 0.298  0.503 ], Lowest was [0.3979 0.071  0.2947 0.503 ]
Median for last 10 epochs: [0.4391 0.0735 0.298  0.506 ], Epochs since improvement 0
  8%|▊         | 39/500 [25:47<4:52:25, 38.06s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.53E+05, Train scatter: [0.3932 0.0691 0.2849 0.5014]
L1 regularization loss: 2.06E+00, L2 regularization loss: 6.87E-01
Test scatter: [0.3864 0.0706 0.2916 0.4936], Lowest was [0.3864 0.0706 0.2916 0.4936]
Median for last 10 epochs: [0.4301 0.0717 0.2951 0.506 ], Epochs since improvement 0
  8%|▊         | 40/500 [26:40<5:27:07, 42.67s/it]  8%|▊         | 41/500 [27:11<4:59:27, 39.15s/it]  8%|▊         | 42/500 [28:00<5:20:46, 42.02s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.06E+05, Train scatter: [0.5284 0.0635 0.2567 0.4773]
L1 regularization loss: 2.10E+00, L2 regularization loss: 7.16E-01
Test scatter: [0.5067 0.064  0.2651 0.4728], Lowest was [0.3864 0.064  0.2651 0.4728]
Median for last 10 epochs: [0.4432 0.071  0.2947 0.503 ], Epochs since improvement 0
  9%|▊         | 43/500 [28:31<4:54:28, 38.66s/it]  9%|▉         | 44/500 [29:19<5:15:19, 41.49s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.77E+05, Train scatter: [0.4539 0.0615 0.2617 0.4768]
L1 regularization loss: 2.15E+00, L2 regularization loss: 7.47E-01
Test scatter: [0.4525 0.0628 0.2699 0.4756], Lowest was [0.3864 0.0628 0.2651 0.4728]
Median for last 10 epochs: [0.4432 0.0706 0.2916 0.4936], Epochs since improvement 0
  9%|▉         | 45/500 [29:50<4:50:15, 38.28s/it]  9%|▉         | 46/500 [30:38<5:12:52, 41.35s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: -2.86E+05, Train scatter: [0.3652 0.0608 0.2722 0.4793]
L1 regularization loss: 2.19E+00, L2 regularization loss: 7.73E-01
Test scatter: [0.3721 0.0616 0.2818 0.4748], Lowest was [0.3721 0.0616 0.2651 0.4728]
Median for last 10 epochs: [0.4432 0.064  0.2818 0.4756], Epochs since improvement 0
  9%|▉         | 47/500 [31:09<4:48:07, 38.16s/it] 10%|▉         | 48/500 [31:57<5:10:54, 41.27s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: -2.87E+05, Train scatter: [0.3971 0.06   0.265  0.4751]
L1 regularization loss: 2.20E+00, L2 regularization loss: 7.98E-01
Test scatter: [0.3921 0.0604 0.2738 0.47  ], Lowest was [0.3721 0.0604 0.2651 0.47  ]
Median for last 10 epochs: [0.3921 0.0628 0.2738 0.4748], Epochs since improvement 0
 10%|▉         | 49/500 [32:28<4:46:34, 38.13s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: -2.88E+05, Train scatter: [0.3652 0.0591 0.2667 0.4699]
L1 regularization loss: 2.22E+00, L2 regularization loss: 8.25E-01
Test scatter: [0.3637 0.0605 0.2753 0.468 ], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.3921 0.0616 0.2738 0.4728], Epochs since improvement 0
 10%|█         | 50/500 [33:22<5:21:03, 42.81s/it] 10%|█         | 51/500 [33:53<4:53:23, 39.21s/it] 10%|█         | 52/500 [34:41<5:13:05, 41.93s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: -1.82E+05, Train scatter: [0.295  0.0714 0.2992 0.4864]
L1 regularization loss: 2.35E+00, L2 regularization loss: 8.89E-01
Test scatter: [0.3807 0.0718 0.3041 0.4831], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.3807 0.0616 0.2753 0.4748], Epochs since improvement 2
 11%|█         | 53/500 [35:12<4:47:16, 38.56s/it] 11%|█         | 54/500 [36:00<5:09:13, 41.60s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: -2.73E+05, Train scatter: [0.4078 0.0644 0.3015 0.4868]
L1 regularization loss: 2.34E+00, L2 regularization loss: 9.17E-01
Test scatter: [0.4038 0.0656 0.3086 0.486 ], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.3807 0.0616 0.2818 0.4748], Epochs since improvement 4
 11%|█         | 55/500 [36:31<4:44:32, 38.37s/it] 11%|█         | 56/500 [37:20<5:06:13, 41.38s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.06E+08, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 4.85E+00, L2 regularization loss: 1.98E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.3921 0.0656 0.3041 0.4831], Epochs since improvement 6
 11%|█▏        | 57/500 [37:50<4:42:06, 38.21s/it] 12%|█▏        | 58/500 [38:38<5:03:07, 41.15s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.37E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 4.87E+00, L2 regularization loss: 2.09E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.4038 0.0718 0.3086 0.486 ], Epochs since improvement 8
 12%|█▏        | 59/500 [39:09<4:39:33, 38.03s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.96E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 4.88E+00, L2 regularization loss: 2.20E+00
Test scatter: [0.9196 0.1689 0.5355 0.9851], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.9196 0.1689 0.5355 0.9851], Epochs since improvement 10
 12%|█▏        | 60/500 [40:03<5:13:09, 42.70s/it] 12%|█▏        | 61/500 [40:33<4:46:04, 39.10s/it] 12%|█▏        | 62/500 [41:22<5:06:22, 41.97s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.71E+06, Train scatter: [0.9354 0.1726 0.5441 0.9955]
L1 regularization loss: 4.88E+00, L2 regularization loss: 2.30E+00
Test scatter: [0.9198 0.1688 0.5355 0.9851], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.9196 0.1689 0.5355 0.9851], Epochs since improvement 12
 13%|█▎        | 63/500 [41:53<4:41:12, 38.61s/it] 13%|█▎        | 64/500 [42:41<5:01:36, 41.51s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.56E+06, Train scatter: [0.9354 0.1723 0.5441 0.9955]
L1 regularization loss: 4.89E+00, L2 regularization loss: 2.39E+00
Test scatter: [0.9198 0.1684 0.5355 0.9851], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.9196 0.1689 0.5355 0.9851], Epochs since improvement 14
 13%|█▎        | 65/500 [43:12<4:37:58, 38.34s/it] 13%|█▎        | 66/500 [44:00<4:59:13, 41.37s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.45E+06, Train scatter: [0.9357 0.1705 0.544  0.9954]
L1 regularization loss: 4.90E+00, L2 regularization loss: 2.52E+00
Test scatter: [0.9201 0.1667 0.5355 0.9851], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.9198 0.1688 0.5355 0.9851], Epochs since improvement 16
 13%|█▎        | 67/500 [44:31<4:35:50, 38.22s/it] 14%|█▎        | 68/500 [45:19<4:56:29, 41.18s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 9.15E+05, Train scatter: [0.9389 0.1152 0.5435 0.995 ]
L1 regularization loss: 4.93E+00, L2 regularization loss: 2.77E+00
Test scatter: [0.9232 0.1134 0.5349 0.9846], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.9198 0.1684 0.5355 0.9851], Epochs since improvement 18
 14%|█▍        | 69/500 [45:50<4:33:56, 38.14s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 6.14E+05, Train scatter: [0.9386 0.1103 0.5422 0.9947]
L1 regularization loss: 4.93E+00, L2 regularization loss: 2.81E+00
Test scatter: [0.9229 0.1089 0.5337 0.9844], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.9201 0.1667 0.5355 0.9851], Epochs since improvement 20
 14%|█▍        | 70/500 [46:46<5:09:42, 43.21s/it] 14%|█▍        | 71/500 [47:17<4:42:43, 39.54s/it] 14%|█▍        | 71/500 [48:04<4:50:31, 40.63s/it]
Epoch: 72 done with learning rate 9.96E-03, Train loss: 5.62E+05, Train scatter: [0.9385 0.1079 0.5152 0.9942]
L1 regularization loss: 4.93E+00, L2 regularization loss: 2.83E+00
Test scatter: [0.9228 0.1067 0.5079 0.9839], Lowest was [0.3637 0.0604 0.2651 0.468 ]
Median for last 10 epochs: [0.9228 0.1134 0.5349 0.9846], Epochs since improvement 22
Exited after 72 epochs due to early stopping
2885.58 seconds spent training, 5.771 seconds per epoch. Processed 12066 trees per second
[0.9228128  0.10671148 0.50789714 0.9838232 ]
{'epoch_exit': 71, 'scatter_m_star': 0.9228128, 'lowest_m_star': 0.36367178, 'last20_m_star': 0.919801, 'last10_m_star': 0.9228404, 'scatter_v_disk': 0.10671148, 'lowest_v_disk': 0.060438965, 'last20_v_disk': 0.16758966, 'last10_v_disk': 0.113355115, 'scatter_m_cold': 0.50789714, 'lowest_m_cold': 0.26514685, 'last20_m_cold': 0.5354596, 'last10_m_cold': 0.53492516, 'scatter_sfr_100': 0.9838232, 'lowest_sfr_100': 0.46795598, 'last20_sfr_100': 0.9850869, 'last10_sfr_100': 0.9846373}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_ftutyg
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:53:24, 28.07s/it]  0%|          | 2/500 [01:11<5:09:52, 37.34s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.36E+07, Train scatter: [0.9353 0.164  0.5442 0.9954]
L1 regularization loss: 1.51E+00, L2 regularization loss: 3.26E-01
Test scatter: [0.9197 0.1662 0.5356 0.9851], Lowest was [0.9197 0.1662 0.5356 0.9851]
Median for last 10 epochs: [0.9197 0.1662 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:38<4:30:33, 32.66s/it]  1%|          | 4/500 [02:24<5:12:18, 37.78s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.20E+07, Train scatter: [0.9353 0.1765 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.31E-01
Test scatter: [0.9197 0.1779 0.5355 0.9851], Lowest was [0.9197 0.1662 0.5355 0.9851]
Median for last 10 epochs: [0.9197 0.172  0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:51<4:40:11, 33.96s/it]  1%|          | 6/500 [03:36<5:09:44, 37.62s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.47E+06, Train scatter: [0.9352 0.1704 0.5441 0.9954]
L1 regularization loss: 1.53E+00, L2 regularization loss: 3.43E-01
Test scatter: [0.9196 0.1658 0.5356 0.9851], Lowest was [0.9196 0.1658 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1658 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:03<4:41:14, 34.23s/it]  2%|▏         | 8/500 [04:50<5:13:33, 38.24s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.53E+06, Train scatter: [0.9352 0.1511 0.5441 0.9951]
L1 regularization loss: 1.55E+00, L2 regularization loss: 3.65E-01
Test scatter: [0.9196 0.1455 0.5355 0.9848], Lowest was [0.9196 0.1455 0.5355 0.9848]
Median for last 10 epochs: [0.9196 0.1557 0.5355 0.9849], Epochs since improvement 0
  2%|▏         | 9/500 [05:17<4:44:05, 34.72s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.87E+06, Train scatter: [0.935  0.1343 0.5441 0.7173]
L1 regularization loss: 1.58E+00, L2 regularization loss: 3.94E-01
Test scatter: [0.9195 0.1302 0.5355 0.7217], Lowest was [0.9195 0.1302 0.5355 0.7217]
Median for last 10 epochs: [0.9196 0.1455 0.5355 0.9848], Epochs since improvement 0
  2%|▏         | 10/500 [06:08<5:25:31, 39.86s/it]  2%|▏         | 11/500 [06:36<4:53:01, 35.95s/it]  2%|▏         | 12/500 [07:22<5:17:35, 39.05s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.33E+06, Train scatter: [0.9323 0.1195 0.544  0.65  ]
L1 regularization loss: 1.60E+00, L2 regularization loss: 4.05E-01
Test scatter: [0.9166 0.1157 0.5355 0.6472], Lowest was [0.9166 0.1157 0.5355 0.6472]
Median for last 10 epochs: [0.9196 0.1455 0.5355 0.9848], Epochs since improvement 0
  3%|▎         | 13/500 [07:49<4:48:02, 35.49s/it]  3%|▎         | 14/500 [08:35<5:12:12, 38.54s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.58E+06, Train scatter: [0.9032 0.1095 0.5433 0.6239]
L1 regularization loss: 1.61E+00, L2 regularization loss: 4.13E-01
Test scatter: [0.8876 0.1072 0.5347 0.6212], Lowest was [0.8876 0.1072 0.5347 0.6212]
Median for last 10 epochs: [0.9195 0.1302 0.5355 0.7217], Epochs since improvement 0
  3%|▎         | 15/500 [09:02<4:43:35, 35.08s/it]  3%|▎         | 16/500 [09:47<5:08:48, 38.28s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.06E+06, Train scatter: [0.6967 0.1042 0.5401 0.5769]
L1 regularization loss: 1.62E+00, L2 regularization loss: 4.22E-01
Test scatter: [0.6931 0.1028 0.5317 0.5753], Lowest was [0.6931 0.1028 0.5317 0.5753]
Median for last 10 epochs: [0.9166 0.1157 0.5355 0.6472], Epochs since improvement 0
  3%|▎         | 17/500 [10:14<4:41:02, 34.91s/it]  4%|▎         | 18/500 [10:59<5:04:40, 37.93s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 5.62E+06, Train scatter: [0.5265 0.0996 0.5374 0.5751]
L1 regularization loss: 1.64E+00, L2 regularization loss: 4.31E-01
Test scatter: [0.5261 0.0985 0.5289 0.5739], Lowest was [0.5261 0.0985 0.5289 0.5739]
Median for last 10 epochs: [0.8876 0.1072 0.5347 0.6212], Epochs since improvement 0
  4%|▍         | 19/500 [11:26<4:38:00, 34.68s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.28E+06, Train scatter: [0.4852 0.0959 0.5323 0.5571]
L1 regularization loss: 1.65E+00, L2 regularization loss: 4.39E-01
Test scatter: [0.4808 0.0952 0.5241 0.5557], Lowest was [0.4808 0.0952 0.5241 0.5557]
Median for last 10 epochs: [0.6931 0.1028 0.5317 0.5753], Epochs since improvement 0
  4%|▍         | 20/500 [12:17<5:14:47, 39.35s/it]  4%|▍         | 21/500 [12:44<4:45:08, 35.72s/it]  4%|▍         | 22/500 [13:29<5:07:41, 38.62s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.89E+06, Train scatter: [0.5116 0.0945 0.5298 0.6076]
L1 regularization loss: 1.66E+00, L2 regularization loss: 4.47E-01
Test scatter: [0.5228 0.0954 0.5207 0.614 ], Lowest was [0.4808 0.0952 0.5207 0.5557]
Median for last 10 epochs: [0.5261 0.0985 0.5289 0.5753], Epochs since improvement 0
  5%|▍         | 23/500 [13:56<4:39:35, 35.17s/it]  5%|▍         | 24/500 [14:42<5:03:35, 38.27s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.18E+06, Train scatter: [0.6316 0.1038 0.4892 0.593 ]
L1 regularization loss: 1.67E+00, L2 regularization loss: 4.56E-01
Test scatter: [0.6242 0.1032 0.4844 0.5905], Lowest was [0.4808 0.0952 0.4844 0.5557]
Median for last 10 epochs: [0.5261 0.0985 0.5241 0.5753], Epochs since improvement 0
  5%|▌         | 25/500 [15:09<4:36:26, 34.92s/it]  5%|▌         | 26/500 [15:54<5:00:01, 37.98s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.19E+06, Train scatter: [0.6336 0.0978 0.4077 0.5975]
L1 regularization loss: 1.70E+00, L2 regularization loss: 4.66E-01
Test scatter: [0.6423 0.0984 0.4094 0.5948], Lowest was [0.4808 0.0952 0.4094 0.5557]
Median for last 10 epochs: [0.5261 0.0984 0.5207 0.5905], Epochs since improvement 0
  5%|▌         | 27/500 [16:21<4:33:34, 34.70s/it]  6%|▌         | 28/500 [17:07<4:58:31, 37.95s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.00E+06, Train scatter: [0.5701 0.0947 0.3644 0.5912]
L1 regularization loss: 1.71E+00, L2 regularization loss: 4.71E-01
Test scatter: [0.5879 0.0951 0.3667 0.5837], Lowest was [0.4808 0.0951 0.3667 0.5557]
Median for last 10 epochs: [0.5879 0.0954 0.4844 0.5905], Epochs since improvement 0
  6%|▌         | 29/500 [17:34<4:32:46, 34.75s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.08E+06, Train scatter: [0.8302 0.0887 0.3618 0.5926]
L1 regularization loss: 1.72E+00, L2 regularization loss: 4.80E-01
Test scatter: [0.9205 0.0887 0.3644 0.5877], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.6242 0.0954 0.4094 0.5905], Epochs since improvement 0
  6%|▌         | 30/500 [18:26<5:13:22, 40.00s/it]  6%|▌         | 31/500 [18:54<4:42:46, 36.18s/it]  6%|▋         | 32/500 [19:39<5:03:59, 38.97s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 9.25E+06, Train scatter: [0.8009 0.1524 0.5306 0.8874]
L1 regularization loss: 2.16E+00, L2 regularization loss: 6.24E-01
Test scatter: [0.7896 0.1487 0.5241 0.8814], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.6423 0.0984 0.4094 0.5905], Epochs since improvement 2
  7%|▋         | 33/500 [20:06<4:35:38, 35.42s/it]  7%|▋         | 34/500 [20:52<5:00:06, 38.64s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 4.90E+06, Train scatter: [0.6424 0.1405 0.5441 0.8262]
L1 regularization loss: 2.18E+00, L2 regularization loss: 6.63E-01
Test scatter: [0.7004 0.1381 0.5355 0.8225], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.7004 0.0984 0.4094 0.5948], Epochs since improvement 4
  7%|▋         | 35/500 [21:20<4:33:02, 35.23s/it]  7%|▋         | 36/500 [22:06<4:57:12, 38.43s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 4.01E+06, Train scatter: [0.6049 0.1354 0.4934 0.8026]
L1 regularization loss: 2.19E+00, L2 regularization loss: 6.81E-01
Test scatter: [0.639  0.1335 0.4898 0.799 ], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.7004 0.1335 0.4898 0.799 ], Epochs since improvement 6
  7%|▋         | 37/500 [22:33<4:30:44, 35.09s/it]  8%|▊         | 38/500 [23:19<4:55:16, 38.35s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.50E+06, Train scatter: [0.6402 0.1303 0.4673 0.7828]
L1 regularization loss: 2.20E+00, L2 regularization loss: 6.97E-01
Test scatter: [0.7095 0.1283 0.4632 0.7802], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.7095 0.1335 0.4898 0.799 ], Epochs since improvement 8
  8%|▊         | 39/500 [23:46<4:28:52, 35.00s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.20E+06, Train scatter: [0.5879 0.1252 0.4589 0.767 ]
L1 regularization loss: 2.22E+00, L2 regularization loss: 7.16E-01
Test scatter: [0.6107 0.1236 0.4534 0.7641], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.7004 0.1335 0.4898 0.799 ], Epochs since improvement 10
  8%|▊         | 40/500 [24:37<5:06:19, 39.96s/it]  8%|▊         | 41/500 [25:05<4:36:20, 36.12s/it]  8%|▊         | 42/500 [25:51<4:58:37, 39.12s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.98E+06, Train scatter: [0.5921 0.1181 0.4478 0.7427]
L1 regularization loss: 2.23E+00, L2 regularization loss: 7.38E-01
Test scatter: [0.6176 0.1171 0.445  0.7375], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.639  0.1283 0.4632 0.7802], Epochs since improvement 12
  9%|▊         | 43/500 [26:18<4:30:47, 35.55s/it]  9%|▉         | 44/500 [27:04<4:54:47, 38.79s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.65E+06, Train scatter: [0.5215 0.1097 0.4359 0.7119]
L1 regularization loss: 2.25E+00, L2 regularization loss: 7.61E-01
Test scatter: [0.5154 0.1089 0.4252 0.7003], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.6176 0.1236 0.4534 0.7641], Epochs since improvement 14
  9%|▉         | 45/500 [27:31<4:27:41, 35.30s/it]  9%|▉         | 46/500 [28:18<4:52:12, 38.62s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.32E+06, Train scatter: [0.5605 0.1096 0.4412 0.6626]
L1 regularization loss: 2.27E+00, L2 regularization loss: 7.87E-01
Test scatter: [0.5891 0.1173 0.4549 0.6737], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.6107 0.1173 0.4534 0.7375], Epochs since improvement 16
  9%|▉         | 47/500 [28:45<4:25:33, 35.17s/it] 10%|▉         | 48/500 [29:31<4:50:06, 38.51s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.04E+06, Train scatter: [0.5504 0.0971 0.3836 0.6287]
L1 regularization loss: 2.29E+00, L2 regularization loss: 8.08E-01
Test scatter: [0.5689 0.1008 0.3877 0.6303], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.5891 0.1171 0.445  0.7003], Epochs since improvement 18
 10%|▉         | 49/500 [29:59<4:24:07, 35.14s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.82E+06, Train scatter: [0.5232 0.0952 0.3911 0.6284]
L1 regularization loss: 2.31E+00, L2 regularization loss: 8.32E-01
Test scatter: [0.5234 0.0963 0.383  0.6225], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.5689 0.1089 0.4252 0.6737], Epochs since improvement 20
 10%|█         | 50/500 [30:49<4:59:03, 39.87s/it] 10%|█         | 51/500 [31:17<4:29:57, 36.08s/it] 10%|█         | 51/500 [32:03<4:42:10, 37.71s/it]
Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.70E+06, Train scatter: [0.5901 0.093  0.3768 0.6323]
L1 regularization loss: 2.32E+00, L2 regularization loss: 8.53E-01
Test scatter: [0.5923 0.096  0.3758 0.6311], Lowest was [0.4808 0.0887 0.3644 0.5557]
Median for last 10 epochs: [0.5689 0.1008 0.3877 0.6311], Epochs since improvement 22
Exited after 52 epochs due to early stopping
1923.12 seconds spent training, 3.846 seconds per epoch. Processed 18105 trees per second
[0.5922361  0.0960359  0.37577593 0.63105965]
{'epoch_exit': 51, 'scatter_m_star': 0.5922361, 'lowest_m_star': 0.48081148, 'last20_m_star': 0.6014959, 'last10_m_star': 0.5688786, 'scatter_v_disk': 0.0960359, 'lowest_v_disk': 0.088718444, 'last20_v_disk': 0.11721508, 'last10_v_disk': 0.10079463, 'scatter_m_cold': 0.37577593, 'lowest_m_cold': 0.3644359, 'last20_m_cold': 0.44918755, 'last10_m_cold': 0.3877043, 'scatter_sfr_100': 0.63105965, 'lowest_sfr_100': 0.55574876, 'last20_sfr_100': 0.71887386, 'last10_sfr_100': 0.6310784}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_pbargk
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:47<6:34:02, 47.38s/it]  0%|          | 2/500 [01:58<8:27:07, 61.10s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.29E+07, Train scatter: [0.9352 0.1399 0.5441 0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.83E-01
Test scatter: [0.9196 0.1365 0.5355 0.9851], Lowest was [0.9196 0.1365 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1365 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:44<7:30:23, 54.37s/it]  1%|          | 4/500 [03:55<8:23:24, 60.90s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.49E+07, Train scatter: [0.931  0.1002 0.5439 0.9949]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.11E-01
Test scatter: [0.9152 0.0996 0.5354 0.9845], Lowest was [0.9152 0.0996 0.5354 0.9845]
Median for last 10 epochs: [0.9152 0.0996 0.5354 0.9845], Epochs since improvement 0
  1%|          | 5/500 [04:41<7:38:41, 55.60s/it]  1%|          | 6/500 [05:52<8:20:50, 60.83s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.78E+06, Train scatter: [0.8682 0.0914 0.5439 0.6154]
L1 regularization loss: 2.05E+00, L2 regularization loss: 4.52E-01
Test scatter: [0.8517 0.0913 0.5353 0.6118], Lowest was [0.8517 0.0913 0.5353 0.6118]
Median for last 10 epochs: [0.8517 0.0913 0.5353 0.6118], Epochs since improvement 0
  1%|▏         | 7/500 [06:39<7:41:36, 56.18s/it]  2%|▏         | 8/500 [07:49<8:17:29, 60.67s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 5.89E+06, Train scatter: [0.6542 0.0802 0.5438 0.5567]
L1 regularization loss: 2.06E+00, L2 regularization loss: 4.68E-01
Test scatter: [0.6457 0.0806 0.5353 0.5519], Lowest was [0.6457 0.0806 0.5353 0.5519]
Median for last 10 epochs: [0.7487 0.0859 0.5353 0.5819], Epochs since improvement 0
  2%|▏         | 9/500 [08:35<7:39:42, 56.18s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.35E+06, Train scatter: [0.394  0.0764 0.5438 0.544 ]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.79E-01
Test scatter: [0.3927 0.0765 0.5352 0.5376], Lowest was [0.3927 0.0765 0.5352 0.5376]
Median for last 10 epochs: [0.6457 0.0806 0.5353 0.5519], Epochs since improvement 0
  2%|▏         | 10/500 [09:52<8:31:33, 62.64s/it]  2%|▏         | 11/500 [10:39<7:50:21, 57.71s/it]  2%|▏         | 12/500 [11:50<8:21:33, 61.67s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 3.51E+06, Train scatter: [0.2987 0.0724 0.5438 0.5245]
L1 regularization loss: 2.08E+00, L2 regularization loss: 4.87E-01
Test scatter: [0.3027 0.0719 0.5352 0.5226], Lowest was [0.3027 0.0719 0.5352 0.5226]
Median for last 10 epochs: [0.6457 0.0806 0.5353 0.5519], Epochs since improvement 0
  3%|▎         | 13/500 [12:36<7:42:57, 57.04s/it]  3%|▎         | 14/500 [13:47<8:16:55, 61.35s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 3.33E+06, Train scatter: [0.2392 0.0712 0.5436 0.5123]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.92E-01
Test scatter: [0.2472 0.0708 0.5351 0.5049], Lowest was [0.2472 0.0708 0.5351 0.5049]
Median for last 10 epochs: [0.3927 0.0765 0.5352 0.5376], Epochs since improvement 0
  3%|▎         | 15/500 [14:34<7:39:28, 56.84s/it]  3%|▎         | 16/500 [15:45<8:13:15, 61.15s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.24E+06, Train scatter: [0.2197 0.0686 0.5435 0.5079]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.96E-01
Test scatter: [0.2263 0.0684 0.5349 0.5017], Lowest was [0.2263 0.0684 0.5349 0.5017]
Median for last 10 epochs: [0.3027 0.0719 0.5352 0.5226], Epochs since improvement 0
  3%|▎         | 17/500 [16:31<7:37:10, 56.79s/it]  4%|▎         | 18/500 [17:43<8:12:11, 61.27s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.20E+06, Train scatter: [0.226  0.0681 0.5434 0.5176]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.99E-01
Test scatter: [0.2342 0.0682 0.5349 0.5101], Lowest was [0.2263 0.0682 0.5349 0.5017]
Median for last 10 epochs: [0.2472 0.0708 0.5351 0.5101], Epochs since improvement 0
  4%|▍         | 19/500 [18:30<7:35:12, 56.78s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.11E+06, Train scatter: [0.2452 0.0727 0.5433 0.508 ]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.02E-01
Test scatter: [0.2527 0.0723 0.5348 0.5034], Lowest was [0.2263 0.0682 0.5348 0.5017]
Median for last 10 epochs: [0.2472 0.0708 0.5349 0.5049], Epochs since improvement 0
  4%|▍         | 20/500 [19:47<8:24:18, 63.04s/it]  4%|▍         | 21/500 [20:34<7:44:07, 58.14s/it]  4%|▍         | 22/500 [21:45<8:15:00, 62.14s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.01E+06, Train scatter: [0.2235 0.0651 0.5432 0.5011]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.07E-01
Test scatter: [0.2282 0.0652 0.5347 0.4951], Lowest was [0.2263 0.0652 0.5347 0.4951]
Median for last 10 epochs: [0.2342 0.0684 0.5349 0.5034], Epochs since improvement 0
  5%|▍         | 23/500 [22:32<7:37:47, 57.58s/it]  5%|▍         | 24/500 [23:43<8:09:01, 61.64s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 2.96E+06, Train scatter: [0.2136 0.0655 0.5431 0.5043]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.2194 0.0654 0.5346 0.4992], Lowest was [0.2194 0.0652 0.5346 0.4951]
Median for last 10 epochs: [0.2282 0.0682 0.5348 0.5017], Epochs since improvement 0
  5%|▌         | 25/500 [24:30<7:32:34, 57.17s/it]  5%|▌         | 26/500 [25:41<8:05:17, 61.43s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 2.94E+06, Train scatter: [0.1995 0.0629 0.543  0.492 ]
L1 regularization loss: 2.16E+00, L2 regularization loss: 5.17E-01
Test scatter: [0.2076 0.0627 0.5345 0.4874], Lowest was [0.2076 0.0627 0.5345 0.4874]
Median for last 10 epochs: [0.2282 0.0654 0.5347 0.4992], Epochs since improvement 0
  5%|▌         | 27/500 [26:28<7:28:58, 56.95s/it]  6%|▌         | 28/500 [27:39<8:01:56, 61.26s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.90E+06, Train scatter: [0.1908 0.0613 0.5429 0.4911]
L1 regularization loss: 2.18E+00, L2 regularization loss: 5.24E-01
Test scatter: [0.2009 0.0615 0.5344 0.4869], Lowest was [0.2009 0.0615 0.5344 0.4869]
Median for last 10 epochs: [0.2194 0.0652 0.5346 0.4951], Epochs since improvement 0
  6%|▌         | 29/500 [28:26<7:26:22, 56.86s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.89E+06, Train scatter: [0.199  0.0605 0.5427 0.4875]
L1 regularization loss: 2.19E+00, L2 regularization loss: 5.32E-01
Test scatter: [0.2114 0.0611 0.5342 0.4828], Lowest was [0.2009 0.0611 0.5342 0.4828]
Median for last 10 epochs: [0.2114 0.0627 0.5345 0.4874], Epochs since improvement 0
  6%|▌         | 30/500 [29:44<8:15:12, 63.22s/it]  6%|▌         | 31/500 [30:30<7:34:44, 58.18s/it]  6%|▋         | 32/500 [31:41<8:03:40, 62.01s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.87E+06, Train scatter: [0.2811 0.0701 0.5428 0.5604]
L1 regularization loss: 2.22E+00, L2 regularization loss: 5.41E-01
Test scatter: [0.2824 0.0715 0.5344 0.5644], Lowest was [0.2009 0.0611 0.5342 0.4828]
Median for last 10 epochs: [0.2114 0.0627 0.5344 0.4874], Epochs since improvement 2
  7%|▋         | 33/500 [32:28<7:26:45, 57.40s/it]  7%|▋         | 34/500 [33:38<7:55:26, 61.22s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.84E+06, Train scatter: [0.3955 0.0608 0.5426 0.4971]
L1 regularization loss: 2.25E+00, L2 regularization loss: 5.54E-01
Test scatter: [0.3853 0.0603 0.5341 0.4883], Lowest was [0.2009 0.0603 0.5341 0.4828]
Median for last 10 epochs: [0.2114 0.0615 0.5344 0.4874], Epochs since improvement 0
  7%|▋         | 35/500 [34:25<7:20:20, 56.82s/it]  7%|▋         | 36/500 [35:35<7:50:25, 60.83s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.82E+06, Train scatter: [0.2251 0.0651 0.5429 0.503 ]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.64E-01
Test scatter: [0.231  0.0648 0.5344 0.4983], Lowest was [0.2009 0.0603 0.5341 0.4828]
Median for last 10 epochs: [0.231  0.0615 0.5344 0.4883], Epochs since improvement 2
  7%|▋         | 37/500 [36:21<7:16:03, 56.51s/it]  8%|▊         | 38/500 [37:32<7:48:10, 60.80s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.80E+06, Train scatter: [0.2146 0.0646 0.5426 0.4864]
L1 regularization loss: 2.28E+00, L2 regularization loss: 5.76E-01
Test scatter: [0.2189 0.0642 0.5341 0.4783], Lowest was [0.2009 0.0603 0.5341 0.4783]
Median for last 10 epochs: [0.231  0.0642 0.5342 0.4883], Epochs since improvement 0
  8%|▊         | 39/500 [38:19<7:14:12, 56.51s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.78E+06, Train scatter: [0.2203 0.059  0.5423 0.4892]
L1 regularization loss: 2.31E+00, L2 regularization loss: 5.91E-01
Test scatter: [0.2317 0.06   0.5338 0.4861], Lowest was [0.2009 0.06   0.5338 0.4783]
Median for last 10 epochs: [0.2317 0.0642 0.5341 0.4883], Epochs since improvement 0
  8%|▊         | 40/500 [39:36<8:00:54, 62.73s/it]  8%|▊         | 41/500 [40:22<7:22:43, 57.87s/it]  8%|▊         | 42/500 [41:33<7:51:04, 61.71s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.81E+06, Train scatter: [0.48   0.1325 0.5425 0.7094]
L1 regularization loss: 2.39E+00, L2 regularization loss: 6.29E-01
Test scatter: [0.4804 0.1314 0.534  0.7118], Lowest was [0.2009 0.06   0.5338 0.4783]
Median for last 10 epochs: [0.2317 0.0642 0.5341 0.4883], Epochs since improvement 2
  9%|▊         | 43/500 [42:19<7:14:35, 57.06s/it]  9%|▉         | 44/500 [43:31<7:46:17, 61.35s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.76E+06, Train scatter: [0.2368 0.0591 0.5414 0.4754]
L1 regularization loss: 2.41E+00, L2 regularization loss: 6.47E-01
Test scatter: [0.2381 0.0588 0.5329 0.468 ], Lowest was [0.2009 0.0588 0.5329 0.468 ]
Median for last 10 epochs: [0.2317 0.0642 0.534  0.4861], Epochs since improvement 0
  9%|▉         | 45/500 [44:17<7:10:50, 56.81s/it]  9%|▉         | 46/500 [45:28<7:42:02, 61.06s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.75E+06, Train scatter: [0.207  0.0567 0.5404 0.469 ]
L1 regularization loss: 2.44E+00, L2 regularization loss: 6.69E-01
Test scatter: [0.2104 0.0571 0.532  0.4645], Lowest was [0.2009 0.0571 0.532  0.4645]
Median for last 10 epochs: [0.2317 0.06   0.5338 0.4783], Epochs since improvement 0
  9%|▉         | 47/500 [46:14<7:07:13, 56.59s/it] 10%|▉         | 48/500 [47:24<7:37:31, 60.73s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.72E+06, Train scatter: [0.2409 0.0637 0.538  0.5113]
L1 regularization loss: 2.47E+00, L2 regularization loss: 6.90E-01
Test scatter: [0.2433 0.0646 0.5296 0.5148], Lowest was [0.2009 0.0571 0.5296 0.4645]
Median for last 10 epochs: [0.2381 0.06   0.5329 0.4861], Epochs since improvement 0
 10%|▉         | 49/500 [48:10<7:03:27, 56.33s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.92E+06, Train scatter: [0.9329 0.1726 0.5441 0.9952]
L1 regularization loss: 3.29E+00, L2 regularization loss: 9.91E-01
Test scatter: [0.9175 0.1688 0.5355 0.9849], Lowest was [0.2009 0.0571 0.5296 0.4645]
Median for last 10 epochs: [0.2433 0.0646 0.5329 0.5148], Epochs since improvement 2
 10%|█         | 50/500 [49:28<7:50:05, 62.68s/it] 10%|█         | 51/500 [50:14<7:12:15, 57.76s/it] 10%|█         | 52/500 [51:25<7:40:52, 61.72s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.76E+06, Train scatter: [0.9305 0.1642 0.5441 0.9915]
L1 regularization loss: 3.26E+00, L2 regularization loss: 9.98E-01
Test scatter: [0.9152 0.1611 0.5355 0.9814], Lowest was [0.2009 0.0571 0.5296 0.4645]
Median for last 10 epochs: [0.2433 0.0646 0.5329 0.5148], Epochs since improvement 4
 11%|█         | 53/500 [52:11<7:05:02, 57.05s/it] 11%|█         | 54/500 [53:22<7:34:28, 61.14s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.65E+06, Train scatter: [0.9048 0.1298 0.5441 0.6831]
L1 regularization loss: 3.31E+00, L2 regularization loss: 1.13E+00
Test scatter: [0.8906 0.1287 0.5355 0.6787], Lowest was [0.2009 0.0571 0.5296 0.4645]
Median for last 10 epochs: [0.8906 0.1287 0.5355 0.6787], Epochs since improvement 6
 11%|█         | 55/500 [54:08<6:59:52, 56.61s/it] 11%|█         | 56/500 [55:19<7:30:54, 60.93s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.57E+06, Train scatter: [0.7025 0.105  0.544  0.66  ]
L1 regularization loss: 3.34E+00, L2 regularization loss: 1.21E+00
Test scatter: [0.6876 0.1038 0.5355 0.6566], Lowest was [0.2009 0.0571 0.5296 0.4645]
Median for last 10 epochs: [0.8906 0.1287 0.5355 0.6787], Epochs since improvement 8
 11%|█▏        | 57/500 [56:05<6:57:10, 56.50s/it] 12%|█▏        | 58/500 [57:16<7:27:33, 60.76s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.52E+06, Train scatter: [0.6837 0.1048 0.544  0.5907]
L1 regularization loss: 3.36E+00, L2 regularization loss: 1.27E+00
Test scatter: [0.6703 0.1035 0.5354 0.5868], Lowest was [0.2009 0.0571 0.5296 0.4645]
Median for last 10 epochs: [0.8906 0.1287 0.5355 0.6787], Epochs since improvement 10
 12%|█▏        | 59/500 [58:02<6:55:15, 56.50s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.45E+06, Train scatter: [0.5127 0.0999 0.544  0.5756]
L1 regularization loss: 3.36E+00, L2 regularization loss: 1.33E+00
Test scatter: [0.5031 0.0988 0.5354 0.5748], Lowest was [0.2009 0.0571 0.5296 0.4645]
Median for last 10 epochs: [0.6876 0.1038 0.5355 0.6566], Epochs since improvement 12
 12%|█▏        | 60/500 [59:20<7:40:52, 62.85s/it] 12%|█▏        | 61/500 [1:00:06<7:03:30, 57.88s/it] 12%|█▏        | 62/500 [1:01:17<7:30:50, 61.76s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.38E+06, Train scatter: [0.4102 0.0947 0.5439 0.5712]
L1 regularization loss: 3.34E+00, L2 regularization loss: 1.35E+00
Test scatter: [0.4049 0.0929 0.5353 0.5656], Lowest was [0.2009 0.0571 0.5296 0.4645]
Median for last 10 epochs: [0.6703 0.1035 0.5354 0.5868], Epochs since improvement 14
 13%|█▎        | 63/500 [1:02:03<6:55:38, 57.07s/it] 13%|█▎        | 64/500 [1:03:14<7:24:56, 61.23s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.19E+06, Train scatter: [0.3709 0.0868 0.5431 0.546 ]
L1 regularization loss: 3.33E+00, L2 regularization loss: 1.37E+00
Test scatter: [0.3629 0.0855 0.5346 0.5399], Lowest was [0.2009 0.0571 0.5296 0.4645]
Median for last 10 epochs: [0.5031 0.0988 0.5354 0.5748], Epochs since improvement 16
 13%|█▎        | 65/500 [1:04:00<6:51:10, 56.71s/it] 13%|█▎        | 66/500 [1:05:11<7:21:09, 60.99s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.05E+06, Train scatter: [0.4503 0.0787 0.5347 0.5372]
L1 regularization loss: 3.35E+00, L2 regularization loss: 1.43E+00
Test scatter: [0.4419 0.0784 0.5263 0.5388], Lowest was [0.2009 0.0571 0.5263 0.4645]
Median for last 10 epochs: [0.4419 0.0929 0.5353 0.5656], Epochs since improvement 0
 13%|█▎        | 67/500 [1:05:58<6:48:02, 56.54s/it] 14%|█▎        | 68/500 [1:07:09<7:18:54, 60.96s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.96E+06, Train scatter: [0.4596 0.086  0.5306 0.6044]
L1 regularization loss: 3.53E+00, L2 regularization loss: 1.55E+00
Test scatter: [0.4573 0.0841 0.5222 0.5954], Lowest was [0.2009 0.0571 0.5222 0.4645]
Median for last 10 epochs: [0.4419 0.0855 0.5346 0.5656], Epochs since improvement 0
 14%|█▍        | 69/500 [1:07:55<6:45:59, 56.52s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.64E+06, Train scatter: [0.4049 0.0712 0.5268 0.5358]
L1 regularization loss: 3.52E+00, L2 regularization loss: 1.64E+00
Test scatter: [0.3942 0.0701 0.5186 0.5267], Lowest was [0.2009 0.0571 0.5186 0.4645]
Median for last 10 epochs: [0.4049 0.0841 0.5263 0.5399], Epochs since improvement 0
 14%|█▍        | 70/500 [1:09:12<7:28:54, 62.64s/it] 14%|█▍        | 71/500 [1:09:58<6:52:35, 57.71s/it] 14%|█▍        | 72/500 [1:11:08<7:18:34, 61.48s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 2.59E+06, Train scatter: [0.4022 0.0703 0.5222 0.524 ]
L1 regularization loss: 3.54E+00, L2 regularization loss: 1.73E+00
Test scatter: [0.3865 0.0679 0.5141 0.5142], Lowest was [0.2009 0.0571 0.5141 0.4645]
Median for last 10 epochs: [0.3942 0.0784 0.5222 0.5388], Epochs since improvement 0
 15%|█▍        | 73/500 [1:11:55<6:44:58, 56.90s/it] 15%|█▍        | 74/500 [1:13:05<7:12:21, 60.90s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.52E+07, Train scatter: [0.9068 0.1645 0.5442 0.9757]
L1 regularization loss: 4.85E+00, L2 regularization loss: 2.55E+00
Test scatter: [0.893  0.1613 0.5356 0.9661], Lowest was [0.2009 0.0571 0.5141 0.4645]
Median for last 10 epochs: [0.4419 0.0784 0.5222 0.5388], Epochs since improvement 2
 15%|█▌        | 75/500 [1:13:51<6:39:52, 56.45s/it] 15%|█▌        | 76/500 [1:15:02<7:09:28, 60.78s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.13E+06, Train scatter: [0.5574 0.1097 0.5374 0.8857]
L1 regularization loss: 4.86E+00, L2 regularization loss: 2.66E+00
Test scatter: [0.5505 0.1073 0.5292 0.875 ], Lowest was [0.2009 0.0571 0.5141 0.4645]
Median for last 10 epochs: [0.4573 0.0841 0.5222 0.5954], Epochs since improvement 4
 15%|█▌        | 77/500 [1:15:48<6:37:24, 56.37s/it] 16%|█▌        | 78/500 [1:16:58<7:05:04, 60.44s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.62E+06, Train scatter: [0.5705 0.1071 0.4948 0.7922]
L1 regularization loss: 4.86E+00, L2 regularization loss: 2.75E+00
Test scatter: [0.5649 0.1045 0.4869 0.7825], Lowest was [0.2009 0.0571 0.4869 0.4645]
Median for last 10 epochs: [0.5505 0.1045 0.5186 0.7825], Epochs since improvement 0
 16%|█▌        | 79/500 [1:17:44<6:34:00, 56.15s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.25E+06, Train scatter: [0.556  0.1273 0.4606 0.7406]
L1 regularization loss: 4.88E+00, L2 regularization loss: 2.89E+00
Test scatter: [0.5633 0.1264 0.4588 0.7438], Lowest was [0.2009 0.0571 0.4588 0.4645]
Median for last 10 epochs: [0.5633 0.1073 0.5141 0.7825], Epochs since improvement 0
 16%|█▌        | 80/500 [1:19:02<7:18:22, 62.63s/it] 16%|█▌        | 81/500 [1:19:48<6:42:56, 57.70s/it] 16%|█▋        | 82/500 [1:20:59<7:09:19, 61.63s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 1.67E+06, Train scatter: [0.5132 0.0874 0.3678 0.6668]
L1 regularization loss: 4.94E+00, L2 regularization loss: 3.08E+00
Test scatter: [0.5118 0.0881 0.3718 0.6702], Lowest was [0.2009 0.0571 0.3718 0.4645]
Median for last 10 epochs: [0.5633 0.1073 0.4869 0.7825], Epochs since improvement 0
 17%|█▋        | 83/500 [1:21:45<6:36:13, 57.01s/it] 17%|█▋        | 84/500 [1:22:55<7:03:04, 61.02s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 8.77E+05, Train scatter: [0.4981 0.076  0.3127 0.6682]
L1 regularization loss: 4.95E+00, L2 regularization loss: 3.17E+00
Test scatter: [0.4887 0.0749 0.3181 0.6702], Lowest was [0.2009 0.0571 0.3181 0.4645]
Median for last 10 epochs: [0.5505 0.1045 0.4588 0.7438], Epochs since improvement 0
 17%|█▋        | 85/500 [1:23:42<6:31:21, 56.58s/it] 17%|█▋        | 86/500 [1:24:52<6:58:55, 60.71s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 7.38E+05, Train scatter: [0.449  0.0698 0.297  0.6459]
L1 regularization loss: 4.96E+00, L2 regularization loss: 3.26E+00
Test scatter: [0.4436 0.0714 0.3064 0.6502], Lowest was [0.2009 0.0571 0.3064 0.4645]
Median for last 10 epochs: [0.5118 0.0881 0.3718 0.6702], Epochs since improvement 0
 17%|█▋        | 87/500 [1:25:38<6:28:24, 56.43s/it] 18%|█▊        | 88/500 [1:26:48<6:55:32, 60.52s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 6.41E+05, Train scatter: [0.3201 0.0636 0.2845 0.6115]
L1 regularization loss: 4.96E+00, L2 regularization loss: 3.36E+00
Test scatter: [0.3249 0.0649 0.2947 0.6144], Lowest was [0.2009 0.0571 0.2947 0.4645]
Median for last 10 epochs: [0.4887 0.0749 0.3181 0.6702], Epochs since improvement 0
 18%|█▊        | 89/500 [1:27:35<6:25:55, 56.34s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 5.38E+05, Train scatter: [0.3543 0.0641 0.2781 0.6049]
L1 regularization loss: 4.97E+00, L2 regularization loss: 3.45E+00
Test scatter: [0.3469 0.0651 0.2883 0.6038], Lowest was [0.2009 0.0571 0.2883 0.4645]
Median for last 10 epochs: [0.4436 0.0714 0.3064 0.6502], Epochs since improvement 0
 18%|█▊        | 90/500 [1:28:53<7:08:55, 62.77s/it] 18%|█▊        | 91/500 [1:29:39<6:33:57, 57.79s/it] 18%|█▊        | 92/500 [1:30:50<6:59:36, 61.71s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 5.04E+05, Train scatter: [0.4104 0.0611 0.2749 0.588 ]
L1 regularization loss: 5.00E+00, L2 regularization loss: 3.55E+00
Test scatter: [0.4074 0.062  0.2848 0.5878], Lowest was [0.2009 0.0571 0.2848 0.4645]
Median for last 10 epochs: [0.4074 0.0651 0.2947 0.6144], Epochs since improvement 0
 19%|█▊        | 93/500 [1:31:36<6:27:34, 57.14s/it] 19%|█▉        | 94/500 [1:32:46<6:53:13, 61.07s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 4.95E+05, Train scatter: [0.4168 0.0578 0.2707 0.5837]
L1 regularization loss: 5.00E+00, L2 regularization loss: 3.63E+00
Test scatter: [0.4059 0.0591 0.282  0.5823], Lowest was [0.2009 0.0571 0.282  0.4645]
Median for last 10 epochs: [0.4059 0.0649 0.2883 0.6038], Epochs since improvement 0
 19%|█▉        | 95/500 [1:33:33<6:23:03, 56.75s/it] 19%|█▉        | 96/500 [1:34:43<6:48:02, 60.60s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 4.29E+05, Train scatter: [0.4993 0.0668 0.289  0.6045]
L1 regularization loss: 4.99E+00, L2 regularization loss: 3.71E+00
Test scatter: [0.4812 0.0669 0.2962 0.6025], Lowest was [0.2009 0.0571 0.282  0.4645]
Median for last 10 epochs: [0.4059 0.0649 0.2883 0.6025], Epochs since improvement 2
 19%|█▉        | 97/500 [1:35:29<6:18:38, 56.37s/it] 20%|█▉        | 98/500 [1:36:39<6:45:00, 60.45s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 4.27E+05, Train scatter: [0.5095 0.1004 0.4568 0.7546]
L1 regularization loss: 4.99E+00, L2 regularization loss: 3.79E+00
Test scatter: [0.5341 0.0997 0.4484 0.7639], Lowest was [0.2009 0.0571 0.282  0.4645]
Median for last 10 epochs: [0.4074 0.0651 0.2883 0.6025], Epochs since improvement 4
 20%|█▉        | 99/500 [1:37:26<6:15:54, 56.25s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 4.54E+05, Train scatter: [0.4081 0.0559 0.2603 0.5654]
L1 regularization loss: 5.00E+00, L2 regularization loss: 3.92E+00
Test scatter: [0.3974 0.0569 0.2703 0.564 ], Lowest was [0.2009 0.0569 0.2703 0.4645]
Median for last 10 epochs: [0.4074 0.062  0.2848 0.5878], Epochs since improvement 0
 20%|██        | 100/500 [1:38:42<6:54:11, 62.13s/it] 20%|██        | 101/500 [1:39:28<6:22:13, 57.48s/it] 20%|██        | 102/500 [1:40:39<6:47:51, 61.49s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 3.03E+05, Train scatter: [0.4326 0.0552 0.2527 0.5539]
L1 regularization loss: 4.98E+00, L2 regularization loss: 3.98E+00
Test scatter: [0.4154 0.0566 0.2626 0.5515], Lowest was [0.2009 0.0566 0.2626 0.4645]
Median for last 10 epochs: [0.4154 0.0591 0.282  0.5823], Epochs since improvement 0
 21%|██        | 103/500 [1:41:26<6:17:16, 57.02s/it] 21%|██        | 104/500 [1:42:36<6:42:14, 60.95s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 2.71E+05, Train scatter: [0.4045 0.0548 0.2472 0.5411]
L1 regularization loss: 4.96E+00, L2 regularization loss: 4.05E+00
Test scatter: [0.3906 0.0558 0.2565 0.5379], Lowest was [0.2009 0.0558 0.2565 0.4645]
Median for last 10 epochs: [0.4154 0.0569 0.2703 0.564 ], Epochs since improvement 0
 21%|██        | 105/500 [1:43:22<6:12:19, 56.56s/it] 21%|██        | 106/500 [1:44:32<6:36:53, 60.44s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 2.54E+05, Train scatter: [0.4585 0.0545 0.2485 0.533 ]
L1 regularization loss: 4.95E+00, L2 regularization loss: 4.12E+00
Test scatter: [0.4371 0.0545 0.2583 0.5305], Lowest was [0.2009 0.0545 0.2565 0.4645]
Median for last 10 epochs: [0.4154 0.0566 0.2626 0.5515], Epochs since improvement 0
 21%|██▏       | 107/500 [1:45:18<6:08:02, 56.19s/it] 22%|██▏       | 108/500 [1:46:28<6:35:11, 60.49s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 9.12E+05, Train scatter: [0.5314 0.0718 0.2668 0.5592]
L1 regularization loss: 5.50E+00, L2 regularization loss: 4.75E+00
Test scatter: [0.5339 0.0717 0.2778 0.5556], Lowest was [0.2009 0.0545 0.2565 0.4645]
Median for last 10 epochs: [0.4154 0.0566 0.2626 0.5515], Epochs since improvement 2
 22%|██▏       | 109/500 [1:47:14<6:06:05, 56.18s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 2.48E+05, Train scatter: [0.4232 0.0638 0.2567 0.531 ]
L1 regularization loss: 5.47E+00, L2 regularization loss: 4.94E+00
Test scatter: [0.4031 0.0648 0.2626 0.5285], Lowest was [0.2009 0.0545 0.2565 0.4645]
Median for last 10 epochs: [0.4154 0.0566 0.2626 0.5379], Epochs since improvement 4
 22%|██▏       | 110/500 [1:48:31<6:44:07, 62.17s/it] 22%|██▏       | 111/500 [1:49:17<6:11:50, 57.35s/it] 22%|██▏       | 112/500 [1:50:27<6:35:38, 61.18s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.93E+05, Train scatter: [0.5258 0.0578 0.2387 0.5181]
L1 regularization loss: 5.50E+00, L2 regularization loss: 5.01E+00
Test scatter: [0.4979 0.058  0.2472 0.5137], Lowest was [0.2009 0.0545 0.2472 0.4645]
Median for last 10 epochs: [0.4371 0.058  0.2583 0.5305], Epochs since improvement 0
 23%|██▎       | 113/500 [1:51:13<6:05:15, 56.63s/it] 23%|██▎       | 114/500 [1:52:23<6:31:08, 60.80s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.70E+05, Train scatter: [0.3825 0.0563 0.2605 0.5112]
L1 regularization loss: 5.44E+00, L2 regularization loss: 5.07E+00
Test scatter: [0.3648 0.057  0.2721 0.507 ], Lowest was [0.2009 0.0545 0.2472 0.4645]
Median for last 10 epochs: [0.4371 0.058  0.2626 0.5285], Epochs since improvement 2
 23%|██▎       | 115/500 [1:53:09<6:01:32, 56.35s/it] 23%|██▎       | 116/500 [1:54:20<6:28:27, 60.70s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.14E+05, Train scatter: [0.4303 0.0579 0.2352 0.5111]
L1 regularization loss: 5.40E+00, L2 regularization loss: 5.12E+00
Test scatter: [0.4058 0.057  0.2424 0.5051], Lowest was [0.2009 0.0545 0.2424 0.4645]
Median for last 10 epochs: [0.4058 0.058  0.2626 0.5137], Epochs since improvement 0
 23%|██▎       | 117/500 [1:55:07<6:00:01, 56.40s/it] 24%|██▎       | 118/500 [1:56:17<6:25:18, 60.52s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 2.01E+05, Train scatter: [0.4128 0.0578 0.2461 0.5208]
L1 regularization loss: 5.44E+00, L2 regularization loss: 5.21E+00
Test scatter: [0.3964 0.0589 0.2542 0.5161], Lowest was [0.2009 0.0545 0.2424 0.4645]
Median for last 10 epochs: [0.4031 0.058  0.2542 0.5137], Epochs since improvement 2
 24%|██▍       | 119/500 [1:57:03<5:56:44, 56.18s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 7.36E+04, Train scatter: [0.3892 0.0504 0.236  0.5023]
L1 regularization loss: 5.38E+00, L2 regularization loss: 5.26E+00
Test scatter: [0.3719 0.0499 0.2414 0.497 ], Lowest was [0.2009 0.0499 0.2414 0.4645]
Median for last 10 epochs: [0.3964 0.057  0.2472 0.507 ], Epochs since improvement 0
 24%|██▍       | 120/500 [1:58:25<6:46:00, 64.11s/it] 24%|██▍       | 121/500 [1:59:12<6:11:23, 58.79s/it] 24%|██▍       | 122/500 [2:00:23<6:34:03, 62.55s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 4.90E+04, Train scatter: [0.3799 0.0531 0.2429 0.4875]
L1 regularization loss: 5.36E+00, L2 regularization loss: 5.35E+00
Test scatter: [0.3621 0.0527 0.2499 0.4823], Lowest was [0.2009 0.0499 0.2414 0.4645]
Median for last 10 epochs: [0.3719 0.057  0.2499 0.5051], Epochs since improvement 2
 25%|██▍       | 123/500 [2:01:09<6:02:22, 57.67s/it] 25%|██▍       | 124/500 [2:02:19<6:24:13, 61.31s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 7.85E+03, Train scatter: [0.4596 0.0544 0.2344 0.4931]
L1 regularization loss: 5.35E+00, L2 regularization loss: 5.46E+00
Test scatter: [0.4357 0.053  0.2396 0.4888], Lowest was [0.2009 0.0499 0.2396 0.4645]
Median for last 10 epochs: [0.3964 0.053  0.2424 0.497 ], Epochs since improvement 0
 25%|██▌       | 125/500 [2:03:05<5:55:03, 56.81s/it] 25%|██▌       | 126/500 [2:04:17<6:21:39, 61.23s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: -4.00E+04, Train scatter: [0.3882 0.0485 0.222  0.4751]
L1 regularization loss: 5.31E+00, L2 regularization loss: 5.57E+00
Test scatter: [0.3696 0.0483 0.2296 0.4724], Lowest was [0.2009 0.0483 0.2296 0.4645]
Median for last 10 epochs: [0.3719 0.0527 0.2414 0.4888], Epochs since improvement 0
 25%|██▌       | 127/500 [2:05:03<5:52:55, 56.77s/it] 26%|██▌       | 128/500 [2:06:14<6:17:44, 60.93s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -7.89E+04, Train scatter: [0.3763 0.0495 0.2287 0.4705]
L1 regularization loss: 5.30E+00, L2 regularization loss: 5.71E+00
Test scatter: [0.3607 0.0496 0.2357 0.4679], Lowest was [0.2009 0.0483 0.2296 0.4645]
Median for last 10 epochs: [0.3696 0.0499 0.2396 0.4823], Epochs since improvement 2
 26%|██▌       | 129/500 [2:07:00<5:49:27, 56.52s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -1.43E+05, Train scatter: [0.2398 0.046  0.2154 0.4612]
L1 regularization loss: 5.29E+00, L2 regularization loss: 5.87E+00
Test scatter: [0.24   0.0459 0.221  0.4602], Lowest was [0.2009 0.0459 0.221  0.4602]
Median for last 10 epochs: [0.3621 0.0496 0.2357 0.4724], Epochs since improvement 0
 26%|██▌       | 130/500 [2:08:18<6:28:22, 62.98s/it] 26%|██▌       | 131/500 [2:09:04<5:56:25, 57.95s/it] 26%|██▋       | 132/500 [2:10:16<6:20:32, 62.05s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -2.42E+05, Train scatter: [0.3809 0.0455 0.2238 0.4513]
L1 regularization loss: 5.27E+00, L2 regularization loss: 6.00E+00
Test scatter: [0.367  0.0455 0.2295 0.4486], Lowest was [0.2009 0.0455 0.221  0.4486]
Median for last 10 epochs: [0.367  0.0483 0.2296 0.4679], Epochs since improvement 0
 27%|██▋       | 133/500 [2:11:02<5:50:35, 57.32s/it] 27%|██▋       | 134/500 [2:12:13<6:14:01, 61.32s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: -3.12E+05, Train scatter: [0.4141 0.0439 0.2132 0.4402]
L1 regularization loss: 5.33E+00, L2 regularization loss: 6.20E+00
Test scatter: [0.3979 0.0438 0.2188 0.4376], Lowest was [0.2009 0.0438 0.2188 0.4376]
Median for last 10 epochs: [0.367  0.0459 0.2295 0.4602], Epochs since improvement 0
 27%|██▋       | 135/500 [2:12:59<5:45:31, 56.80s/it] 27%|██▋       | 136/500 [2:14:10<6:09:54, 60.97s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: -3.46E+05, Train scatter: [0.1945 0.0473 0.2236 0.4321]
L1 regularization loss: 5.52E+00, L2 regularization loss: 6.51E+00
Test scatter: [0.1949 0.0475 0.2316 0.4299], Lowest was [0.1949 0.0438 0.2188 0.4299]
Median for last 10 epochs: [0.3607 0.0459 0.2295 0.4486], Epochs since improvement 0
 27%|██▋       | 137/500 [2:14:56<5:42:07, 56.55s/it] 28%|██▊       | 138/500 [2:16:07<6:07:05, 60.84s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -3.60E+05, Train scatter: [0.3841 0.0448 0.2235 0.4444]
L1 regularization loss: 5.45E+00, L2 regularization loss: 6.50E+00
Test scatter: [0.3758 0.0442 0.2293 0.445 ], Lowest was [0.1949 0.0438 0.2188 0.4299]
Median for last 10 epochs: [0.367  0.0455 0.2293 0.445 ], Epochs since improvement 2
 28%|██▊       | 139/500 [2:16:53<5:39:52, 56.49s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -3.72E+05, Train scatter: [0.2341 0.0546 0.2177 0.4618]
L1 regularization loss: 5.55E+00, L2 regularization loss: 6.59E+00
Test scatter: [0.2266 0.0548 0.2222 0.4591], Lowest was [0.1949 0.0438 0.2188 0.4299]
Median for last 10 epochs: [0.367  0.0455 0.2293 0.445 ], Epochs since improvement 4
 28%|██▊       | 140/500 [2:18:10<6:16:03, 62.68s/it] 28%|██▊       | 141/500 [2:18:57<5:45:42, 57.78s/it] 28%|██▊       | 142/500 [2:20:08<6:08:54, 61.83s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -3.64E+05, Train scatter: [0.3695 0.0419 0.2132 0.4167]
L1 regularization loss: 5.49E+00, L2 regularization loss: 6.72E+00
Test scatter: [0.3567 0.0418 0.2187 0.4129], Lowest was [0.1949 0.0418 0.2187 0.4129]
Median for last 10 epochs: [0.3567 0.0442 0.2222 0.4376], Epochs since improvement 0
 29%|██▊       | 143/500 [2:20:54<5:39:45, 57.10s/it] 29%|██▉       | 144/500 [2:22:06<6:04:22, 61.41s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: -3.67E+05, Train scatter: [0.3155 0.0492 0.2237 0.4537]
L1 regularization loss: 5.53E+00, L2 regularization loss: 6.84E+00
Test scatter: [0.3107 0.0485 0.2307 0.4482], Lowest was [0.1949 0.0418 0.2187 0.4129]
Median for last 10 epochs: [0.3107 0.0475 0.2293 0.445 ], Epochs since improvement 2
 29%|██▉       | 145/500 [2:22:52<5:36:17, 56.84s/it] 29%|██▉       | 146/500 [2:24:03<5:59:54, 61.00s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: -3.80E+05, Train scatter: [0.2718 0.0434 0.2226 0.414 ]
L1 regularization loss: 5.55E+00, L2 regularization loss: 6.88E+00
Test scatter: [0.2677 0.0427 0.2247 0.4087], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.3107 0.0442 0.2247 0.445 ], Epochs since improvement 0
 29%|██▉       | 147/500 [2:24:49<5:32:47, 56.56s/it] 30%|██▉       | 148/500 [2:25:59<5:56:25, 60.75s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: -8.24E+04, Train scatter: [0.9339 0.1731 0.5441 0.9949]
L1 regularization loss: 7.25E+00, L2 regularization loss: 7.73E+00
Test scatter: [0.9183 0.1692 0.5355 0.9845], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.3107 0.0485 0.2247 0.4482], Epochs since improvement 2
 30%|██▉       | 149/500 [2:26:46<5:30:05, 56.43s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: -1.95E+04, Train scatter: [0.9294 0.1703 0.544  0.9851]
L1 regularization loss: 6.94E+00, L2 regularization loss: 7.56E+00
Test scatter: [0.9139 0.1666 0.5354 0.975 ], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.3567 0.0485 0.2307 0.4482], Epochs since improvement 4
 30%|███       | 150/500 [2:28:03<6:05:54, 62.73s/it] 30%|███       | 151/500 [2:28:49<5:36:05, 57.78s/it] 30%|███       | 152/500 [2:30:01<5:59:08, 61.92s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: -1.12E+05, Train scatter: [0.5122 0.1135 0.5028 0.7394]
L1 regularization loss: 7.26E+00, L2 regularization loss: 7.86E+00
Test scatter: [0.5093 0.1121 0.4964 0.7328], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.5093 0.1121 0.4964 0.7328], Epochs since improvement 6
 31%|███       | 153/500 [2:30:47<5:30:46, 57.19s/it] 31%|███       | 154/500 [2:31:57<5:52:34, 61.14s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: -1.22E+05, Train scatter: [0.4341 0.1036 0.5029 0.6789]
L1 regularization loss: 7.27E+00, L2 regularization loss: 7.99E+00
Test scatter: [0.4316 0.1022 0.4955 0.6713], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.5093 0.1121 0.4964 0.7328], Epochs since improvement 8
 31%|███       | 155/500 [2:32:44<5:26:12, 56.73s/it] 31%|███       | 156/500 [2:33:54<5:47:48, 60.66s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: -1.93E+05, Train scatter: [0.4311 0.0848 0.4229 0.5541]
L1 regularization loss: 7.28E+00, L2 regularization loss: 8.14E+00
Test scatter: [0.4143 0.0827 0.4182 0.5415], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.5093 0.1121 0.4964 0.7328], Epochs since improvement 10
 31%|███▏      | 157/500 [2:34:40<5:22:22, 56.39s/it] 32%|███▏      | 158/500 [2:35:50<5:44:09, 60.38s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: -2.21E+05, Train scatter: [0.281  0.0737 0.3988 0.519 ]
L1 regularization loss: 7.18E+00, L2 regularization loss: 8.10E+00
Test scatter: [0.2767 0.0726 0.3958 0.5093], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.4316 0.1022 0.4955 0.6713], Epochs since improvement 12
 32%|███▏      | 159/500 [2:36:36<5:19:34, 56.23s/it]Epoch: 160 done with learning rate 9.05E-03, Train loss: -2.34E+05, Train scatter: [0.3906 0.0732 0.369  0.5152]
L1 regularization loss: 7.15E+00, L2 regularization loss: 8.01E+00
Test scatter: [0.3816 0.0723 0.3685 0.5063], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.4143 0.0827 0.4182 0.5415], Epochs since improvement 14
 32%|███▏      | 160/500 [2:37:53<5:54:11, 62.50s/it] 32%|███▏      | 161/500 [2:38:40<5:25:47, 57.66s/it] 32%|███▏      | 162/500 [2:39:51<5:47:50, 61.75s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: -2.48E+05, Train scatter: [0.3872 0.1051 0.4203 0.5616]
L1 regularization loss: 7.07E+00, L2 regularization loss: 7.89E+00
Test scatter: [0.3763 0.1031 0.4142 0.5531], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.3816 0.0827 0.4142 0.5415], Epochs since improvement 16
 33%|███▎      | 163/500 [2:40:38<5:20:58, 57.15s/it] 33%|███▎      | 164/500 [2:41:47<5:40:50, 60.87s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: -2.59E+05, Train scatter: [0.4626 0.0684 0.3602 0.5033]
L1 regularization loss: 6.99E+00, L2 regularization loss: 7.89E+00
Test scatter: [0.4514 0.0676 0.3605 0.4935], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.3816 0.0726 0.3958 0.5093], Epochs since improvement 18
 33%|███▎      | 165/500 [2:42:34<5:16:22, 56.67s/it] 33%|███▎      | 166/500 [2:43:44<5:38:00, 60.72s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: -2.45E+05, Train scatter: [0.2161 0.0681 0.3445 0.5073]
L1 regularization loss: 6.91E+00, L2 regularization loss: 7.90E+00
Test scatter: [0.2124 0.0666 0.3432 0.4953], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.3763 0.0723 0.3685 0.5063], Epochs since improvement 20
 33%|███▎      | 167/500 [2:44:31<5:13:33, 56.50s/it] 33%|███▎      | 167/500 [2:45:41<5:30:23, 59.53s/it]
Epoch: 168 done with learning rate 8.86E-03, Train loss: -2.72E+05, Train scatter: [0.2362 0.0698 0.3491 0.5282]
L1 regularization loss: 6.83E+00, L2 regularization loss: 7.84E+00
Test scatter: [0.2327 0.0684 0.3469 0.5157], Lowest was [0.1949 0.0418 0.2187 0.4087]
Median for last 10 epochs: [0.3763 0.0684 0.3605 0.5063], Epochs since improvement 22
Exited after 168 epochs due to early stopping
9941.58 seconds spent training, 19.883 seconds per epoch. Processed 3502 trees per second
[0.23268808 0.06840318 0.34692845 0.51567477]
{'epoch_exit': 167, 'scatter_m_star': 0.23268808, 'lowest_m_star': 0.19487683, 'last20_m_star': 0.3979427, 'last10_m_star': 0.37625438, 'scatter_v_disk': 0.06840318, 'lowest_v_disk': 0.04182113, 'last20_v_disk': 0.07765398, 'last10_v_disk': 0.06840518, 'scatter_m_cold': 0.34692845, 'lowest_m_cold': 0.21868062, 'last20_m_cold': 0.40504643, 'last10_m_cold': 0.36052325, 'scatter_sfr_100': 0.51567477, 'lowest_sfr_100': 0.4087351, 'last20_sfr_100': 0.52858615, 'last10_sfr_100': 0.50625694}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_pwozbn
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:41<5:41:04, 41.01s/it]  0%|          | 2/500 [01:43<7:24:55, 53.60s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.01E+07, Train scatter: [0.9352 0.1713 0.5441 0.9954]
L1 regularization loss: 1.98E+00, L2 regularization loss: 3.76E-01
Test scatter: [0.9196 0.1672 0.5356 0.9851], Lowest was [0.9196 0.1672 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1672 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:23<6:33:09, 47.46s/it]  1%|          | 4/500 [03:25<7:19:55, 53.22s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.21E+07, Train scatter: [0.9352 0.15   0.5441 0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.85E-01
Test scatter: [0.9196 0.1462 0.5355 0.9851], Lowest was [0.9196 0.1462 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1462 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:05<6:40:25, 48.54s/it]  1%|          | 6/500 [05:08<7:18:48, 53.30s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.71E+07, Train scatter: [0.9348 0.1075 0.5441 0.9954]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.01E-01
Test scatter: [0.9192 0.1059 0.5355 0.985 ], Lowest was [0.9192 0.1059 0.5355 0.985 ]
Median for last 10 epochs: [0.9192 0.1059 0.5355 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [05:48<6:42:41, 49.01s/it]  2%|▏         | 8/500 [06:50<7:15:32, 53.11s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.33E+07, Train scatter: [0.9171 0.0898 0.544  0.7684]
L1 regularization loss: 2.04E+00, L2 regularization loss: 4.27E-01
Test scatter: [0.9017 0.0901 0.5354 0.7557], Lowest was [0.9017 0.0901 0.5354 0.7557]
Median for last 10 epochs: [0.9104 0.098  0.5355 0.8703], Epochs since improvement 0
  2%|▏         | 9/500 [07:30<6:41:49, 49.10s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 1.00E+07, Train scatter: [0.8024 0.0942 0.5439 0.63  ]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.62E-01
Test scatter: [0.7881 0.0937 0.5354 0.624 ], Lowest was [0.7881 0.0901 0.5354 0.624 ]
Median for last 10 epochs: [0.9017 0.0937 0.5354 0.7557], Epochs since improvement 0
  2%|▏         | 10/500 [08:39<7:30:02, 55.11s/it]  2%|▏         | 11/500 [09:19<6:51:58, 50.55s/it]  2%|▏         | 12/500 [10:22<7:21:18, 54.26s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.78E+06, Train scatter: [0.644  0.0861 0.5439 0.5678]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.75E-01
Test scatter: [0.6368 0.0858 0.5354 0.562 ], Lowest was [0.6368 0.0858 0.5354 0.562 ]
Median for last 10 epochs: [0.9017 0.0937 0.5354 0.7557], Epochs since improvement 0
  3%|▎         | 13/500 [11:02<6:45:51, 50.00s/it]  3%|▎         | 14/500 [12:07<7:20:45, 54.41s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 5.24E+06, Train scatter: [0.5438 0.0841 0.5439 0.5535]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.85E-01
Test scatter: [0.5363 0.0839 0.5354 0.5493], Lowest was [0.5363 0.0839 0.5354 0.5493]
Median for last 10 epochs: [0.7881 0.0901 0.5354 0.624 ], Epochs since improvement 0
  3%|▎         | 15/500 [12:47<6:44:59, 50.10s/it]  3%|▎         | 16/500 [13:50<7:17:11, 54.20s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.64E+06, Train scatter: [0.4772 0.0799 0.5439 0.5429]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.93E-01
Test scatter: [0.4735 0.0799 0.5354 0.5428], Lowest was [0.4735 0.0799 0.5354 0.5428]
Median for last 10 epochs: [0.6368 0.0858 0.5354 0.562 ], Epochs since improvement 0
  3%|▎         | 17/500 [14:31<6:42:14, 49.97s/it]  4%|▎         | 18/500 [15:34<7:13:00, 53.90s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.59E+06, Train scatter: [0.4928 0.0934 0.5439 0.5676]
L1 regularization loss: 2.11E+00, L2 regularization loss: 5.00E-01
Test scatter: [0.488  0.0917 0.5354 0.563 ], Lowest was [0.4735 0.0799 0.5354 0.5428]
Median for last 10 epochs: [0.5363 0.0858 0.5354 0.562 ], Epochs since improvement 2
  4%|▍         | 19/500 [16:14<6:38:52, 49.76s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.88E+06, Train scatter: [0.3146 0.0815 0.5438 0.56  ]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.08E-01
Test scatter: [0.3195 0.081  0.5353 0.5524], Lowest was [0.3195 0.0799 0.5353 0.5428]
Median for last 10 epochs: [0.488  0.0839 0.5354 0.5524], Epochs since improvement 0
  4%|▍         | 20/500 [17:24<7:26:57, 55.87s/it]  4%|▍         | 21/500 [18:04<6:48:20, 51.15s/it]  4%|▍         | 22/500 [19:08<7:17:09, 54.87s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.66E+06, Train scatter: [0.2652 0.0767 0.5438 0.5244]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.14E-01
Test scatter: [0.2712 0.0769 0.5352 0.5196], Lowest was [0.2712 0.0769 0.5352 0.5196]
Median for last 10 epochs: [0.4735 0.081  0.5354 0.5493], Epochs since improvement 0
  5%|▍         | 23/500 [19:48<6:40:46, 50.41s/it]  5%|▍         | 24/500 [20:51<7:10:33, 54.27s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.57E+06, Train scatter: [0.266  0.0758 0.5438 0.5218]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.20E-01
Test scatter: [0.271  0.076  0.5352 0.519 ], Lowest was [0.271  0.076  0.5352 0.519 ]
Median for last 10 epochs: [0.3195 0.0799 0.5353 0.5428], Epochs since improvement 0
  5%|▌         | 25/500 [21:31<6:36:02, 50.03s/it]  5%|▌         | 26/500 [22:34<7:06:04, 53.93s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.70E+06, Train scatter: [0.2808 0.0769 0.5437 0.5359]
L1 regularization loss: 2.16E+00, L2 regularization loss: 5.28E-01
Test scatter: [0.2841 0.0764 0.5352 0.5311], Lowest was [0.271  0.076  0.5352 0.519 ]
Median for last 10 epochs: [0.2841 0.0769 0.5352 0.5311], Epochs since improvement 0
  5%|▌         | 27/500 [23:14<6:32:08, 49.74s/it]  6%|▌         | 28/500 [24:17<7:02:14, 53.67s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.38E+06, Train scatter: [0.4019 0.0749 0.5437 0.6246]
L1 regularization loss: 2.17E+00, L2 regularization loss: 5.32E-01
Test scatter: [0.4015 0.0747 0.5351 0.6231], Lowest was [0.271  0.0747 0.5351 0.519 ]
Median for last 10 epochs: [0.2841 0.0764 0.5352 0.5311], Epochs since improvement 0
  6%|▌         | 29/500 [24:57<6:28:58, 49.55s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.35E+06, Train scatter: [0.2325 0.0734 0.5436 0.5139]
L1 regularization loss: 2.18E+00, L2 regularization loss: 5.39E-01
Test scatter: [0.2386 0.0735 0.535  0.5076], Lowest was [0.2386 0.0735 0.535  0.5076]
Median for last 10 epochs: [0.2712 0.076  0.5352 0.5196], Epochs since improvement 0
  6%|▌         | 30/500 [26:06<7:15:30, 55.60s/it]  6%|▌         | 31/500 [26:46<6:37:57, 50.91s/it]  6%|▋         | 32/500 [27:49<7:04:50, 54.47s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.28E+06, Train scatter: [0.2865 0.0725 0.5435 0.5332]
L1 regularization loss: 2.19E+00, L2 regularization loss: 5.43E-01
Test scatter: [0.289  0.0723 0.535  0.5337], Lowest was [0.2386 0.0723 0.535  0.5076]
Median for last 10 epochs: [0.2841 0.0747 0.5351 0.5311], Epochs since improvement 0
  7%|▋         | 33/500 [28:29<6:29:58, 50.10s/it]  7%|▋         | 34/500 [29:32<6:59:00, 53.95s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.26E+06, Train scatter: [0.2648 0.0703 0.5435 0.5352]
L1 regularization loss: 2.21E+00, L2 regularization loss: 5.49E-01
Test scatter: [0.2681 0.0703 0.535  0.5327], Lowest was [0.2386 0.0703 0.535  0.5076]
Median for last 10 epochs: [0.2841 0.0735 0.535  0.5327], Epochs since improvement 0
  7%|▋         | 35/500 [30:12<6:25:18, 49.72s/it]  7%|▋         | 36/500 [31:16<6:57:20, 53.97s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.24E+06, Train scatter: [0.2549 0.0744 0.5435 0.51  ]
L1 regularization loss: 2.22E+00, L2 regularization loss: 5.53E-01
Test scatter: [0.2888 0.0741 0.5349 0.509 ], Lowest was [0.2386 0.0703 0.5349 0.5076]
Median for last 10 epochs: [0.2888 0.0735 0.535  0.5327], Epochs since improvement 0
  7%|▋         | 37/500 [31:56<6:23:50, 49.74s/it]  8%|▊         | 38/500 [33:00<6:55:59, 54.03s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.22E+06, Train scatter: [0.2358 0.069  0.5434 0.4961]
L1 regularization loss: 2.23E+00, L2 regularization loss: 5.59E-01
Test scatter: [0.3023 0.0693 0.5349 0.4916], Lowest was [0.2386 0.0693 0.5349 0.4916]
Median for last 10 epochs: [0.2888 0.0723 0.535  0.509 ], Epochs since improvement 0
  8%|▊         | 39/500 [33:40<6:22:42, 49.81s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.27E+06, Train scatter: [0.4545 0.1023 0.5434 0.6946]
L1 regularization loss: 2.25E+00, L2 regularization loss: 5.65E-01
Test scatter: [0.4514 0.1011 0.5349 0.6905], Lowest was [0.2386 0.0693 0.5349 0.4916]
Median for last 10 epochs: [0.289  0.0723 0.5349 0.5327], Epochs since improvement 0
  8%|▊         | 40/500 [34:49<7:07:29, 55.76s/it]  8%|▊         | 41/500 [35:29<6:30:20, 51.02s/it]  8%|▊         | 42/500 [36:34<7:00:01, 55.03s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.19E+06, Train scatter: [0.2072 0.0703 0.5433 0.4966]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.75E-01
Test scatter: [0.3943 0.07   0.5348 0.4946], Lowest was [0.2386 0.0693 0.5348 0.4916]
Median for last 10 epochs: [0.3023 0.0703 0.5349 0.509 ], Epochs since improvement 0
  9%|▊         | 43/500 [37:14<6:25:03, 50.56s/it]  9%|▉         | 44/500 [38:17<6:53:17, 54.38s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.19E+06, Train scatter: [0.2091 0.072  0.5433 0.5056]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.80E-01
Test scatter: [0.4214 0.0716 0.5347 0.4989], Lowest was [0.2386 0.0693 0.5347 0.4916]
Median for last 10 epochs: [0.3943 0.0716 0.5349 0.4989], Epochs since improvement 0
  9%|▉         | 45/500 [38:57<6:19:28, 50.04s/it]  9%|▉         | 46/500 [40:00<6:48:19, 53.96s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.10E+06, Train scatter: [0.2094 0.0687 0.5432 0.5057]
L1 regularization loss: 2.28E+00, L2 regularization loss: 5.88E-01
Test scatter: [0.2266 0.0675 0.5347 0.5023], Lowest was [0.2266 0.0675 0.5347 0.4916]
Median for last 10 epochs: [0.3943 0.07   0.5348 0.4989], Epochs since improvement 0
  9%|▉         | 47/500 [40:40<6:15:42, 49.76s/it] 10%|▉         | 48/500 [41:44<6:46:38, 53.98s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.15E+06, Train scatter: [0.4427 0.0696 0.543  0.5157]
L1 regularization loss: 2.30E+00, L2 regularization loss: 5.96E-01
Test scatter: [0.4327 0.0695 0.5345 0.5089], Lowest was [0.2266 0.0675 0.5345 0.4916]
Median for last 10 epochs: [0.4214 0.07   0.5347 0.5023], Epochs since improvement 0
 10%|▉         | 49/500 [42:24<6:14:17, 49.79s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.04E+06, Train scatter: [0.2072 0.067  0.543  0.5057]
L1 regularization loss: 2.31E+00, L2 regularization loss: 6.05E-01
Test scatter: [0.2191 0.0667 0.5344 0.5043], Lowest was [0.2191 0.0667 0.5344 0.4916]
Median for last 10 epochs: [0.3943 0.0695 0.5347 0.5023], Epochs since improvement 0
 10%|█         | 50/500 [43:34<6:58:25, 55.79s/it] 10%|█         | 51/500 [44:14<6:22:04, 51.06s/it] 10%|█         | 52/500 [45:18<6:51:08, 55.06s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.03E+06, Train scatter: [0.2193 0.0655 0.5429 0.4925]
L1 regularization loss: 2.32E+00, L2 regularization loss: 6.11E-01
Test scatter: [0.2249 0.0656 0.5343 0.4872], Lowest was [0.2191 0.0656 0.5343 0.4872]
Median for last 10 epochs: [0.2266 0.0675 0.5345 0.5023], Epochs since improvement 0
 11%|█         | 53/500 [45:58<6:16:35, 50.55s/it] 11%|█         | 54/500 [47:01<6:43:34, 54.29s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.08E+06, Train scatter: [0.4057 0.0788 0.543  0.5119]
L1 regularization loss: 2.34E+00, L2 regularization loss: 6.25E-01
Test scatter: [0.3954 0.0787 0.5344 0.5042], Lowest was [0.2191 0.0656 0.5343 0.4872]
Median for last 10 epochs: [0.2266 0.0675 0.5344 0.5042], Epochs since improvement 2
 11%|█         | 55/500 [47:41<6:10:51, 50.00s/it] 11%|█         | 56/500 [48:45<6:40:04, 54.06s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.02E+06, Train scatter: [0.2144 0.0647 0.5427 0.4939]
L1 regularization loss: 2.35E+00, L2 regularization loss: 6.30E-01
Test scatter: [0.2218 0.0647 0.5342 0.4895], Lowest was [0.2191 0.0647 0.5342 0.4872]
Median for last 10 epochs: [0.2249 0.0667 0.5344 0.5042], Epochs since improvement 0
 11%|█▏        | 57/500 [49:25<6:07:59, 49.84s/it] 12%|█▏        | 58/500 [50:28<6:36:15, 53.79s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.00E+06, Train scatter: [0.2268 0.0704 0.5428 0.4968]
L1 regularization loss: 2.35E+00, L2 regularization loss: 6.35E-01
Test scatter: [0.2847 0.071  0.5343 0.4917], Lowest was [0.2191 0.0647 0.5342 0.4872]
Median for last 10 epochs: [0.2249 0.0667 0.5343 0.4917], Epochs since improvement 2
 12%|█▏        | 59/500 [51:08<6:05:03, 49.67s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.99E+06, Train scatter: [0.2582 0.0721 0.5424 0.5034]
L1 regularization loss: 2.37E+00, L2 regularization loss: 6.46E-01
Test scatter: [0.2613 0.0707 0.5339 0.4985], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.2613 0.0707 0.5343 0.4917], Epochs since improvement 0
 12%|█▏        | 60/500 [52:19<6:51:07, 56.06s/it] 12%|█▏        | 61/500 [52:59<6:14:52, 51.24s/it] 12%|█▏        | 62/500 [54:02<6:40:52, 54.92s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.00E+06, Train scatter: [0.2803 0.0706 0.5426 0.5163]
L1 regularization loss: 2.38E+00, L2 regularization loss: 6.55E-01
Test scatter: [0.2761 0.0699 0.5341 0.5105], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.2761 0.0707 0.5342 0.4985], Epochs since improvement 2
 13%|█▎        | 63/500 [54:42<6:07:19, 50.43s/it] 13%|█▎        | 64/500 [55:45<6:33:59, 54.22s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.00E+06, Train scatter: [0.2429 0.0644 0.5426 0.507 ]
L1 regularization loss: 2.40E+00, L2 regularization loss: 6.66E-01
Test scatter: [0.297  0.0649 0.5342 0.5064], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.2761 0.0699 0.5342 0.4985], Epochs since improvement 4
 13%|█▎        | 65/500 [56:25<6:02:11, 49.96s/it] 13%|█▎        | 66/500 [57:30<6:33:10, 54.36s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 4.14E+06, Train scatter: [0.9326 0.1727 0.5441 0.997 ]
L1 regularization loss: 3.68E+00, L2 regularization loss: 1.27E+00
Test scatter: [0.9159 0.1686 0.5355 0.9869], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.2847 0.0707 0.5342 0.5064], Epochs since improvement 6
 13%|█▎        | 67/500 [58:10<6:01:04, 50.03s/it] 14%|█▎        | 68/500 [59:13<6:29:04, 54.04s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.74E+06, Train scatter: [0.9357 0.1725 0.5441 0.9933]
L1 regularization loss: 3.68E+00, L2 regularization loss: 1.28E+00
Test scatter: [0.9197 0.1687 0.5355 0.9834], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.297  0.0707 0.5342 0.5105], Epochs since improvement 8
 14%|█▍        | 69/500 [59:53<5:57:43, 49.80s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.52E+06, Train scatter: [0.935  0.1703 0.5441 0.9906]
L1 regularization loss: 3.68E+00, L2 regularization loss: 1.29E+00
Test scatter: [0.9195 0.1666 0.5355 0.9806], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.9159 0.1666 0.5355 0.9806], Epochs since improvement 10
 14%|█▍        | 70/500 [1:01:04<6:41:23, 56.01s/it] 14%|█▍        | 71/500 [1:01:44<6:06:07, 51.21s/it] 14%|█▍        | 72/500 [1:02:47<6:30:58, 54.81s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.48E+06, Train scatter: [0.9338 0.1636 0.5441 0.9854]
L1 regularization loss: 3.68E+00, L2 regularization loss: 1.30E+00
Test scatter: [0.9184 0.1601 0.5355 0.9753], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.9184 0.1666 0.5355 0.9806], Epochs since improvement 12
 15%|█▍        | 73/500 [1:03:27<5:58:15, 50.34s/it] 15%|█▍        | 74/500 [1:04:31<6:26:11, 54.39s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.44E+06, Train scatter: [0.932  0.1382 0.5441 0.9698]
L1 regularization loss: 3.69E+00, L2 regularization loss: 1.32E+00
Test scatter: [0.9168 0.1355 0.5355 0.96  ], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.9184 0.1666 0.5355 0.9806], Epochs since improvement 14
 15%|█▌        | 75/500 [1:05:11<5:54:42, 50.08s/it] 15%|█▌        | 76/500 [1:06:14<6:22:22, 54.11s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.41E+06, Train scatter: [0.9303 0.1266 0.5441 0.937 ]
L1 regularization loss: 3.71E+00, L2 regularization loss: 1.38E+00
Test scatter: [0.9152 0.1242 0.5355 0.9278], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.9184 0.1601 0.5355 0.9753], Epochs since improvement 16
 15%|█▌        | 77/500 [1:06:54<5:51:58, 49.92s/it] 16%|█▌        | 78/500 [1:07:57<6:18:49, 53.86s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.37E+06, Train scatter: [0.9274 0.1155 0.5441 0.7532]
L1 regularization loss: 3.74E+00, L2 regularization loss: 1.49E+00
Test scatter: [0.9126 0.1139 0.5355 0.7463], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.9168 0.1355 0.5355 0.96  ], Epochs since improvement 18
 16%|█▌        | 79/500 [1:08:37<5:48:53, 49.72s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 3.35E+06, Train scatter: [0.9186 0.1114 0.544  0.7156]
L1 regularization loss: 3.76E+00, L2 regularization loss: 1.50E+00
Test scatter: [0.9041 0.1106 0.5355 0.7116], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.9152 0.1242 0.5355 0.9278], Epochs since improvement 20
 16%|█▌        | 80/500 [1:09:47<6:30:59, 55.86s/it] 16%|█▌        | 81/500 [1:10:28<5:57:33, 51.20s/it] 16%|█▌        | 81/500 [1:11:32<6:10:02, 52.99s/it]
Epoch: 82 done with learning rate 9.99E-03, Train loss: 3.33E+06, Train scatter: [0.8775 0.1102 0.544  0.6756]
L1 regularization loss: 3.76E+00, L2 regularization loss: 1.51E+00
Test scatter: [0.8634 0.1094 0.5354 0.6719], Lowest was [0.2191 0.0647 0.5339 0.4872]
Median for last 10 epochs: [0.9126 0.1139 0.5355 0.7463], Epochs since improvement 22
Exited after 82 epochs due to early stopping
4292.18 seconds spent training, 8.584 seconds per epoch. Processed 8112 trees per second
[0.8633681  0.10940878 0.5354261  0.6719186 ]
{'epoch_exit': 81, 'scatter_m_star': 0.8633681, 'lowest_m_star': 0.21912362, 'last20_m_star': 0.9155633, 'last10_m_star': 0.9125815, 'scatter_v_disk': 0.10940878, 'lowest_v_disk': 0.06472133, 'last20_v_disk': 0.12981382, 'last10_v_disk': 0.113901325, 'scatter_m_cold': 0.5354261, 'lowest_m_cold': 0.5338822, 'last20_m_cold': 0.53546953, 'last10_m_cold': 0.53546596, 'scatter_sfr_100': 0.6719186, 'lowest_sfr_100': 0.4872199, 'last20_sfr_100': 0.94388187, 'last10_sfr_100': 0.7462552}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_cfkmkl
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:00<8:25:42, 60.81s/it]  0%|          | 2/500 [02:29<10:42:35, 77.42s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.25E+07, Train scatter: [0.9352 0.1425 0.5441 0.9954]
L1 regularization loss: 2.45E+00, L2 regularization loss: 4.24E-01
Test scatter: [0.9196 0.139  0.5355 0.9851], Lowest was [0.9196 0.139  0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.139  0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:30<9:37:14, 69.69s/it]   1%|          | 4/500 [05:00<10:41:39, 77.62s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.19E+07, Train scatter: [0.9345 0.1064 0.5441 0.9955]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.29E-01
Test scatter: [0.9189 0.1036 0.5355 0.9851], Lowest was [0.9189 0.1036 0.5355 0.9851]
Median for last 10 epochs: [0.9189 0.1036 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:00<9:50:22, 71.56s/it]   1%|          | 6/500 [07:31<10:41:48, 77.95s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 7.54E+07, Train scatter: [0.8539 0.0919 0.5416 0.9954]
L1 regularization loss: 2.49E+00, L2 regularization loss: 4.37E-01
Test scatter: [0.8475 0.092  0.5331 0.9851], Lowest was [0.8475 0.092  0.5331 0.9851]
Median for last 10 epochs: [0.8475 0.092  0.5331 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [08:31<9:54:05, 72.30s/it]   2%|▏         | 8/500 [10:01<10:38:19, 77.84s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.13E+07, Train scatter: [0.7662 0.0987 0.4566 0.9954]
L1 regularization loss: 2.50E+00, L2 regularization loss: 4.51E-01
Test scatter: [0.7489 0.0972 0.4483 0.9851], Lowest was [0.7489 0.092  0.4483 0.9851]
Median for last 10 epochs: [0.7982 0.0946 0.4907 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [11:02<9:52:48, 72.44s/it] Epoch: 10 done with learning rate 8.15E-04, Train loss: 6.92E+07, Train scatter: [0.7298 0.0845 0.3827 0.9954]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.61E-01
Test scatter: [0.7244 0.0854 0.3843 0.985 ], Lowest was [0.7244 0.0854 0.3843 0.985 ]
Median for last 10 epochs: [0.7489 0.092  0.4483 0.9851], Epochs since improvement 0
  2%|▏         | 10/500 [12:40<10:55:28, 80.26s/it]  2%|▏         | 11/500 [13:40<10:05:20, 74.28s/it]  2%|▏         | 12/500 [15:10<10:42:34, 79.00s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.83E+07, Train scatter: [0.6896 0.0834 0.3797 0.9954]
L1 regularization loss: 2.53E+00, L2 regularization loss: 4.67E-01
Test scatter: [0.6911 0.0843 0.3799 0.985 ], Lowest was [0.6911 0.0843 0.3799 0.985 ]
Median for last 10 epochs: [0.7489 0.092  0.4483 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [16:11<9:55:43, 73.40s/it]   3%|▎         | 14/500 [17:40<10:33:55, 78.26s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.75E+07, Train scatter: [0.5641 0.0819 0.3396 0.9954]
L1 regularization loss: 2.54E+00, L2 regularization loss: 4.72E-01
Test scatter: [0.5702 0.0814 0.3434 0.9851], Lowest was [0.5702 0.0814 0.3434 0.985 ]
Median for last 10 epochs: [0.7244 0.0854 0.3843 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [18:41<9:50:04, 73.00s/it]   3%|▎         | 16/500 [20:11<10:29:33, 78.05s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.59E+07, Train scatter: [0.5192 0.0769 0.3138 0.9954]
L1 regularization loss: 2.56E+00, L2 regularization loss: 4.80E-01
Test scatter: [0.5211 0.0763 0.3187 0.9851], Lowest was [0.5211 0.0763 0.3187 0.985 ]
Median for last 10 epochs: [0.6911 0.0843 0.3799 0.9851], Epochs since improvement 0
  3%|▎         | 17/500 [21:11<9:45:37, 72.75s/it]   4%|▎         | 18/500 [22:41<10:26:27, 77.98s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 5.93E+07, Train scatter: [0.8708 0.1315 0.5433 0.9964]
L1 regularization loss: 2.66E+00, L2 regularization loss: 5.13E-01
Test scatter: [0.8555 0.1279 0.5346 0.9865], Lowest was [0.5211 0.0763 0.3187 0.985 ]
Median for last 10 epochs: [0.6911 0.0843 0.3799 0.9851], Epochs since improvement 2
  4%|▍         | 19/500 [23:42<9:43:24, 72.77s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.03E+06, Train scatter: [0.4783 0.0969 0.4564 0.6766]
L1 regularization loss: 2.69E+00, L2 regularization loss: 5.39E-01
Test scatter: [0.4762 0.0949 0.4495 0.6779], Lowest was [0.4762 0.0763 0.3187 0.6779]
Median for last 10 epochs: [0.5702 0.0843 0.3799 0.9851], Epochs since improvement 0
  4%|▍         | 20/500 [25:19<10:41:45, 80.22s/it]  4%|▍         | 21/500 [26:20<9:53:25, 74.33s/it]   4%|▍         | 22/500 [27:50<10:29:14, 78.98s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.75E+06, Train scatter: [0.3459 0.0839 0.4162 0.556 ]
L1 regularization loss: 2.69E+00, L2 regularization loss: 5.45E-01
Test scatter: [0.3511 0.0826 0.4111 0.5578], Lowest was [0.3511 0.0763 0.3187 0.5578]
Median for last 10 epochs: [0.5211 0.0826 0.4111 0.9851], Epochs since improvement 0
  5%|▍         | 23/500 [28:50<9:43:52, 73.44s/it]   5%|▍         | 24/500 [30:20<10:20:08, 78.17s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.19E+06, Train scatter: [0.324  0.0833 0.3999 0.574 ]
L1 regularization loss: 2.70E+00, L2 regularization loss: 5.52E-01
Test scatter: [0.3272 0.0826 0.4    0.5736], Lowest was [0.3272 0.0763 0.3187 0.5578]
Median for last 10 epochs: [0.4762 0.0826 0.4111 0.6779], Epochs since improvement 0
  5%|▌         | 25/500 [31:20<9:37:35, 72.96s/it]   5%|▌         | 26/500 [32:51<10:17:11, 78.13s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.66E+06, Train scatter: [0.3937 0.0776 0.3524 0.6007]
L1 regularization loss: 2.71E+00, L2 regularization loss: 5.63E-01
Test scatter: [0.3937 0.077  0.353  0.6183], Lowest was [0.3272 0.0763 0.3187 0.5578]
Median for last 10 epochs: [0.3937 0.0826 0.4111 0.6183], Epochs since improvement 2
  5%|▌         | 27/500 [33:51<9:34:37, 72.89s/it]   6%|▌         | 28/500 [35:21<10:13:25, 77.98s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.49E+06, Train scatter: [0.4283 0.0719 0.325  0.5181]
L1 regularization loss: 2.73E+00, L2 regularization loss: 5.76E-01
Test scatter: [0.4255 0.0714 0.328  0.5249], Lowest was [0.3272 0.0714 0.3187 0.5249]
Median for last 10 epochs: [0.3937 0.0826 0.4    0.5736], Epochs since improvement 0
  6%|▌         | 29/500 [36:22<9:31:26, 72.80s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.31E+06, Train scatter: [0.3945 0.0721 0.3233 0.509 ]
L1 regularization loss: 2.75E+00, L2 regularization loss: 5.90E-01
Test scatter: [0.3905 0.071  0.3263 0.5083], Lowest was [0.3272 0.071  0.3187 0.5083]
Median for last 10 epochs: [0.3905 0.077  0.353  0.5578], Epochs since improvement 0
  6%|▌         | 30/500 [37:59<10:27:07, 80.06s/it]  6%|▌         | 31/500 [38:59<9:39:32, 74.14s/it]   6%|▋         | 32/500 [40:30<10:17:15, 79.14s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.13E+06, Train scatter: [0.4216 0.071  0.3183 0.533 ]
L1 regularization loss: 2.79E+00, L2 regularization loss: 6.08E-01
Test scatter: [0.4136 0.0707 0.3221 0.5319], Lowest was [0.3272 0.0707 0.3187 0.5083]
Median for last 10 epochs: [0.3937 0.0714 0.328  0.5319], Epochs since improvement 0
  7%|▋         | 33/500 [41:31<9:33:22, 73.67s/it]   7%|▋         | 34/500 [43:01<10:10:17, 78.58s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.86E+06, Train scatter: [0.3748 0.0679 0.3241 0.6375]
L1 regularization loss: 2.82E+00, L2 regularization loss: 6.29E-01
Test scatter: [0.3745 0.0678 0.3256 0.6559], Lowest was [0.3272 0.0678 0.3187 0.5083]
Median for last 10 epochs: [0.3937 0.071  0.3263 0.5319], Epochs since improvement 0
  7%|▋         | 35/500 [44:02<9:27:43, 73.26s/it]   7%|▋         | 36/500 [45:31<10:04:02, 78.11s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.88E+06, Train scatter: [0.3157 0.0678 0.3308 0.5385]
L1 regularization loss: 2.85E+00, L2 regularization loss: 6.51E-01
Test scatter: [0.3151 0.0688 0.3373 0.5547], Lowest was [0.3151 0.0678 0.3187 0.5083]
Median for last 10 epochs: [0.3905 0.0707 0.3263 0.5319], Epochs since improvement 0
  7%|▋         | 37/500 [46:32<9:22:11, 72.85s/it]   8%|▊         | 38/500 [48:02<10:01:25, 78.11s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.98E+06, Train scatter: [0.2675 0.0683 0.3122 0.514 ]
L1 regularization loss: 2.90E+00, L2 regularization loss: 6.81E-01
Test scatter: [0.2751 0.0678 0.3169 0.5137], Lowest was [0.2751 0.0678 0.3169 0.5083]
Median for last 10 epochs: [0.3745 0.0688 0.3256 0.5319], Epochs since improvement 0
  8%|▊         | 39/500 [49:03<9:19:59, 72.88s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.52E+06, Train scatter: [0.393  0.0669 0.3198 0.5076]
L1 regularization loss: 2.94E+00, L2 regularization loss: 7.09E-01
Test scatter: [0.3781 0.0673 0.3238 0.5224], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.3745 0.0678 0.3238 0.5319], Epochs since improvement 0
  8%|▊         | 40/500 [50:40<10:15:52, 80.33s/it]  8%|▊         | 41/500 [51:41<9:28:53, 74.36s/it]   8%|▊         | 42/500 [53:10<10:01:45, 78.83s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 5.04E+07, Train scatter: [0.9289 0.1584 0.5417 0.9171]
L1 regularization loss: 5.75E+00, L2 regularization loss: 1.48E+00
Test scatter: [0.9136 0.1551 0.5332 0.909 ], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.3745 0.0678 0.3256 0.5547], Epochs since improvement 2
  9%|▊         | 43/500 [54:11<9:19:22, 73.44s/it]   9%|▉         | 44/500 [55:41<9:56:55, 78.54s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.60E+07, Train scatter: [0.8524 0.1215 0.5396 0.7491]
L1 regularization loss: 5.85E+00, L2 regularization loss: 1.56E+00
Test scatter: [0.8403 0.1195 0.5312 0.7438], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.3781 0.0688 0.3373 0.5547], Epochs since improvement 4
  9%|▉         | 45/500 [56:42<9:14:37, 73.14s/it]  9%|▉         | 46/500 [58:12<9:51:40, 78.19s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.18E+07, Train scatter: [0.7267 0.117  0.5295 0.7399]
L1 regularization loss: 5.88E+00, L2 regularization loss: 1.68E+00
Test scatter: [0.7196 0.1144 0.5216 0.7327], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.7196 0.1144 0.5216 0.7327], Epochs since improvement 6
  9%|▉         | 47/500 [59:13<9:10:43, 72.94s/it] 10%|▉         | 48/500 [1:00:42<9:46:20, 77.83s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 9.27E+06, Train scatter: [0.5539 0.1113 0.5094 0.6987]
L1 regularization loss: 5.92E+00, L2 regularization loss: 1.81E+00
Test scatter: [0.5543 0.1097 0.5025 0.6917], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.7196 0.1144 0.5216 0.7327], Epochs since improvement 8
 10%|▉         | 49/500 [1:01:43<9:06:52, 72.75s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 6.90E+06, Train scatter: [0.5602 0.1107 0.5064 0.6595]
L1 regularization loss: 5.95E+00, L2 regularization loss: 1.86E+00
Test scatter: [0.5434 0.1068 0.499  0.6495], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.7196 0.1144 0.5216 0.7327], Epochs since improvement 10
 10%|█         | 50/500 [1:03:20<10:00:01, 80.00s/it] 10%|█         | 51/500 [1:04:21<9:16:09, 74.32s/it]  10%|█         | 52/500 [1:05:51<9:50:42, 79.11s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 6.08E+06, Train scatter: [0.5532 0.1209 0.4935 0.6922]
L1 regularization loss: 5.97E+00, L2 regularization loss: 1.90E+00
Test scatter: [0.5266 0.1163 0.4852 0.6768], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.5543 0.1144 0.5025 0.6917], Epochs since improvement 12
 11%|█         | 53/500 [1:06:52<9:08:25, 73.62s/it] 11%|█         | 54/500 [1:08:21<9:42:07, 78.31s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 5.70E+06, Train scatter: [0.4213 0.1032 0.4479 0.6103]
L1 regularization loss: 5.99E+00, L2 regularization loss: 1.95E+00
Test scatter: [0.4119 0.1004 0.443  0.6023], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.5434 0.1097 0.499  0.6768], Epochs since improvement 14
 11%|█         | 55/500 [1:09:22<9:01:58, 73.08s/it] 11%|█         | 56/500 [1:10:53<9:39:35, 78.32s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.62E+06, Train scatter: [0.412  0.1034 0.4528 0.5922]
L1 regularization loss: 6.00E+00, L2 regularization loss: 2.01E+00
Test scatter: [0.3948 0.0995 0.4466 0.5817], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.5266 0.1068 0.4852 0.6495], Epochs since improvement 16
 11%|█▏        | 57/500 [1:11:54<9:00:01, 73.14s/it] 12%|█▏        | 58/500 [1:13:23<9:34:54, 78.04s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 4.19E+06, Train scatter: [0.3662 0.0935 0.4115 0.5673]
L1 regularization loss: 6.01E+00, L2 regularization loss: 2.06E+00
Test scatter: [0.3556 0.0913 0.4109 0.5607], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.4119 0.1004 0.4466 0.6023], Epochs since improvement 18
 12%|█▏        | 59/500 [1:14:24<8:54:40, 72.75s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.83E+06, Train scatter: [0.4565 0.0935 0.3999 0.5536]
L1 regularization loss: 6.03E+00, L2 regularization loss: 2.11E+00
Test scatter: [0.4417 0.0916 0.4    0.5481], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.4119 0.0995 0.443  0.5817], Epochs since improvement 20
 12%|█▏        | 60/500 [1:16:01<9:47:15, 80.08s/it] 12%|█▏        | 61/500 [1:17:02<9:03:54, 74.34s/it] 12%|█▏        | 61/500 [1:18:30<9:25:02, 77.23s/it]
Epoch: 62 done with learning rate 9.31E-03, Train loss: 9.20E+06, Train scatter: [0.6187 0.1652 0.5151 0.7478]
L1 regularization loss: 6.10E+00, L2 regularization loss: 2.20E+00
Test scatter: [0.609  0.1615 0.5075 0.7399], Lowest was [0.2751 0.0673 0.3169 0.5083]
Median for last 10 epochs: [0.4119 0.0995 0.443  0.5817], Epochs since improvement 22
Exited after 62 epochs due to early stopping
4710.88 seconds spent training, 9.422 seconds per epoch. Processed 7391 trees per second
[0.6090321  0.16151732 0.5074594  0.7398994 ]
{'epoch_exit': 61, 'scatter_m_star': 0.6090321, 'lowest_m_star': 0.27507505, 'last20_m_star': 0.5349914, 'last10_m_star': 0.41186908, 'scatter_v_disk': 0.16151732, 'lowest_v_disk': 0.067256615, 'last20_v_disk': 0.10823166, 'last10_v_disk': 0.09953247, 'scatter_m_cold': 0.5074594, 'lowest_m_cold': 0.31685612, 'last20_m_cold': 0.49208605, 'last10_m_cold': 0.4430188, 'scatter_sfr_100': 0.7398994, 'lowest_sfr_100': 0.50831103, 'last20_sfr_100': 0.6631687, 'last10_sfr_100': 0.58168304}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_xnoqhi
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:27:18, 53.79s/it]  0%|          | 2/500 [02:14<9:39:20, 69.80s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.1722 0.5441 0.9953]
L1 regularization loss: 2.44E+00, L2 regularization loss: 4.23E-01
Test scatter: [0.9196 0.1678 0.5355 0.985 ], Lowest was [0.9196 0.1678 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1678 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:08<8:35:35, 62.24s/it]  1%|          | 4/500 [04:29<9:36:15, 69.71s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.96E+07, Train scatter: [0.9352 0.1327 0.5441 0.9954]
L1 regularization loss: 2.45E+00, L2 regularization loss: 4.25E-01
Test scatter: [0.9196 0.1281 0.5355 0.985 ], Lowest was [0.9196 0.1281 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1281 0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:22<8:45:35, 63.71s/it]  1%|          | 6/500 [06:43<9:33:54, 69.70s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.22E+07, Train scatter: [0.9349 0.114  0.5441 0.9954]
L1 regularization loss: 2.46E+00, L2 regularization loss: 4.28E-01
Test scatter: [0.9192 0.1114 0.5355 0.9851], Lowest was [0.9192 0.1114 0.5355 0.985 ]
Median for last 10 epochs: [0.9192 0.1114 0.5355 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [07:36<8:47:50, 64.24s/it]  2%|▏         | 8/500 [08:57<9:29:19, 69.43s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.04E+07, Train scatter: [0.9303 0.1038 0.544  0.9955]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.32E-01
Test scatter: [0.9148 0.1024 0.5354 0.9851], Lowest was [0.9148 0.1024 0.5354 0.985 ]
Median for last 10 epochs: [0.917  0.1069 0.5355 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [09:50<8:45:59, 64.28s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.92E+07, Train scatter: [0.7834 0.0931 0.5439 0.9954]
L1 regularization loss: 2.49E+00, L2 regularization loss: 4.39E-01
Test scatter: [0.7694 0.0931 0.5353 0.9851], Lowest was [0.7694 0.0931 0.5353 0.985 ]
Median for last 10 epochs: [0.9148 0.1024 0.5354 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:18<9:44:48, 71.61s/it]  2%|▏         | 11/500 [12:11<8:58:30, 66.07s/it]  2%|▏         | 12/500 [13:32<9:33:09, 70.47s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.79E+07, Train scatter: [0.6557 0.0868 0.5438 0.9954]
L1 regularization loss: 2.50E+00, L2 regularization loss: 4.48E-01
Test scatter: [0.6478 0.0869 0.5352 0.985 ], Lowest was [0.6478 0.0869 0.5352 0.985 ]
Median for last 10 epochs: [0.9148 0.1024 0.5354 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:25<8:50:13, 65.33s/it]  3%|▎         | 14/500 [15:46<9:26:02, 69.88s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.71E+07, Train scatter: [0.5489 0.0828 0.5428 0.9953]
L1 regularization loss: 2.51E+00, L2 regularization loss: 4.56E-01
Test scatter: [0.5394 0.0832 0.5343 0.985 ], Lowest was [0.5394 0.0832 0.5343 0.985 ]
Median for last 10 epochs: [0.7694 0.0931 0.5353 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [16:39<8:44:33, 64.89s/it]  3%|▎         | 16/500 [17:59<9:21:23, 69.59s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.64E+07, Train scatter: [0.4498 0.08   0.5323 0.9953]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.64E-01
Test scatter: [0.4438 0.0805 0.5244 0.985 ], Lowest was [0.4438 0.0805 0.5244 0.985 ]
Median for last 10 epochs: [0.6478 0.0869 0.5352 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [18:52<8:40:15, 64.63s/it]  4%|▎         | 18/500 [20:13<9:18:21, 69.50s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.57E+07, Train scatter: [0.5316 0.0808 0.5245 0.9953]
L1 regularization loss: 2.53E+00, L2 regularization loss: 4.69E-01
Test scatter: [0.5239 0.0813 0.5169 0.9849], Lowest was [0.4438 0.0805 0.5169 0.9849]
Median for last 10 epochs: [0.5394 0.0832 0.5343 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [21:07<8:37:52, 64.60s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.46E+07, Train scatter: [0.6243 0.0925 0.4478 0.9953]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.77E-01
Test scatter: [0.6405 0.0927 0.445  0.985 ], Lowest was [0.4438 0.0805 0.445  0.9849]
Median for last 10 epochs: [0.5394 0.0832 0.5244 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:34<9:31:40, 71.46s/it]  4%|▍         | 21/500 [23:27<8:47:05, 66.02s/it]  4%|▍         | 22/500 [24:50<9:24:52, 70.90s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.34E+07, Train scatter: [0.5767 0.0907 0.3717 0.9953]
L1 regularization loss: 2.56E+00, L2 regularization loss: 4.82E-01
Test scatter: [0.5913 0.0898 0.3771 0.985 ], Lowest was [0.4438 0.0805 0.3771 0.9849]
Median for last 10 epochs: [0.5394 0.0832 0.5169 0.985 ], Epochs since improvement 0
  5%|▍         | 23/500 [25:43<8:41:27, 65.59s/it]  5%|▍         | 24/500 [27:03<9:15:11, 69.98s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.29E+07, Train scatter: [0.5113 0.0878 0.3754 0.9953]
L1 regularization loss: 2.58E+00, L2 regularization loss: 4.89E-01
Test scatter: [0.5138 0.0864 0.3754 0.985 ], Lowest was [0.4438 0.0805 0.3754 0.9849]
Median for last 10 epochs: [0.5239 0.0864 0.445  0.985 ], Epochs since improvement 0
  5%|▌         | 25/500 [27:56<8:34:35, 65.00s/it]  5%|▌         | 26/500 [29:17<9:10:45, 69.72s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.23E+07, Train scatter: [0.5535 0.0874 0.3332 0.9953]
L1 regularization loss: 2.59E+00, L2 regularization loss: 4.95E-01
Test scatter: [0.5372 0.0864 0.335  0.985 ], Lowest was [0.4438 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.5372 0.0864 0.3771 0.985 ], Epochs since improvement 0
  5%|▌         | 27/500 [30:11<8:32:21, 64.99s/it]  6%|▌         | 28/500 [31:31<9:07:22, 69.58s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.24E+07, Train scatter: [0.4996 0.0834 0.3899 0.9954]
L1 regularization loss: 2.62E+00, L2 regularization loss: 5.06E-01
Test scatter: [0.5178 0.0835 0.3969 0.985 ], Lowest was [0.4438 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.5372 0.0864 0.3771 0.985 ], Epochs since improvement 2
  6%|▌         | 29/500 [32:25<8:28:01, 64.72s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.40E+10, Train scatter: [0.9153 0.1716 0.544  0.9955]
L1 regularization loss: 4.68E+00, L2 regularization loss: 9.22E-01
Test scatter: [0.9005 0.1679 0.5354 0.9851], Lowest was [0.4438 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.5372 0.0864 0.3771 0.985 ], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [33:52<9:19:55, 71.48s/it]  6%|▌         | 31/500 [34:45<8:36:21, 66.06s/it]  6%|▋         | 32/500 [36:06<9:09:10, 70.41s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 1.98E+07, Train scatter: [0.6307 0.1527 0.5435 0.9955]
L1 regularization loss: 4.70E+00, L2 regularization loss: 9.76E-01
Test scatter: [0.6245 0.1495 0.5349 0.9852], Lowest was [0.4438 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.5372 0.0864 0.3969 0.985 ], Epochs since improvement 6
  7%|▋         | 33/500 [36:59<8:27:43, 65.23s/it]  7%|▋         | 34/500 [38:20<9:02:45, 69.88s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 1.45E+07, Train scatter: [0.6613 0.1207 0.5431 0.9955]
L1 regularization loss: 4.72E+00, L2 regularization loss: 1.01E+00
Test scatter: [0.6517 0.1182 0.5346 0.9852], Lowest was [0.4438 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.6245 0.1182 0.5346 0.9851], Epochs since improvement 8
  7%|▋         | 35/500 [39:13<8:22:30, 64.84s/it]  7%|▋         | 36/500 [40:33<8:57:36, 69.52s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 1.19E+07, Train scatter: [0.4902 0.1136 0.5427 0.9955]
L1 regularization loss: 4.73E+00, L2 regularization loss: 1.03E+00
Test scatter: [0.4786 0.1112 0.5341 0.9852], Lowest was [0.4438 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.6245 0.1182 0.5346 0.9852], Epochs since improvement 10
  7%|▋         | 37/500 [41:27<8:19:21, 64.71s/it]  8%|▊         | 38/500 [42:47<8:53:22, 69.27s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.03E+07, Train scatter: [0.4798 0.1103 0.5421 0.9955]
L1 regularization loss: 4.73E+00, L2 regularization loss: 1.04E+00
Test scatter: [0.47   0.1081 0.5336 0.9852], Lowest was [0.4438 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.6245 0.1182 0.5346 0.9852], Epochs since improvement 12
  8%|▊         | 39/500 [43:40<8:15:49, 64.53s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 9.86E+06, Train scatter: [0.4454 0.1103 0.5408 0.9955]
L1 regularization loss: 4.74E+00, L2 regularization loss: 1.06E+00
Test scatter: [0.4415 0.1082 0.5323 0.9852], Lowest was [0.4415 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.4786 0.1112 0.5341 0.9852], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:08<9:07:06, 71.36s/it]  8%|▊         | 41/500 [46:01<8:24:20, 65.93s/it]  8%|▊         | 42/500 [47:21<8:55:48, 70.19s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 8.85E+06, Train scatter: [0.4625 0.1099 0.5388 0.9955]
L1 regularization loss: 4.75E+00, L2 regularization loss: 1.08E+00
Test scatter: [0.465  0.1082 0.5303 0.9852], Lowest was [0.4415 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.47   0.1082 0.5336 0.9852], Epochs since improvement 2
  9%|▊         | 43/500 [48:14<8:16:29, 65.19s/it]  9%|▉         | 44/500 [49:36<8:51:48, 69.98s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 8.24E+06, Train scatter: [0.4716 0.1092 0.5344 0.9955]
L1 regularization loss: 4.76E+00, L2 regularization loss: 1.10E+00
Test scatter: [0.4634 0.1071 0.526  0.9852], Lowest was [0.4415 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.465  0.1082 0.5323 0.9852], Epochs since improvement 4
  9%|▉         | 45/500 [50:29<8:12:40, 64.97s/it]  9%|▉         | 46/500 [51:50<8:47:37, 69.73s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 7.56E+06, Train scatter: [0.4605 0.1096 0.5247 0.9955]
L1 regularization loss: 4.77E+00, L2 regularization loss: 1.13E+00
Test scatter: [0.4519 0.1073 0.5166 0.9852], Lowest was [0.4415 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.4634 0.1081 0.5303 0.9852], Epochs since improvement 6
  9%|▉         | 47/500 [52:43<8:08:43, 64.73s/it] 10%|▉         | 48/500 [54:04<8:45:16, 69.73s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 6.79E+06, Train scatter: [0.3968 0.104  0.5142 0.9955]
L1 regularization loss: 4.78E+00, L2 regularization loss: 1.16E+00
Test scatter: [0.392  0.1021 0.5064 0.9852], Lowest was [0.392  0.0805 0.335  0.9849]
Median for last 10 epochs: [0.4519 0.1073 0.526  0.9852], Epochs since improvement 0
 10%|▉         | 49/500 [54:57<8:06:53, 64.78s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 6.19E+06, Train scatter: [0.4289 0.1033 0.5035 0.9955]
L1 regularization loss: 4.79E+00, L2 regularization loss: 1.20E+00
Test scatter: [0.42   0.1013 0.4961 0.9852], Lowest was [0.392  0.0805 0.335  0.9849]
Median for last 10 epochs: [0.4519 0.1071 0.5166 0.9852], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [56:25<8:56:03, 71.47s/it] 10%|█         | 51/500 [57:18<8:13:35, 65.96s/it] 10%|█         | 52/500 [58:38<8:45:31, 70.38s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 6.41E+06, Train scatter: [0.4959 0.1061 0.4627 0.9956]
L1 regularization loss: 4.80E+00, L2 regularization loss: 1.23E+00
Test scatter: [0.4887 0.1038 0.4575 0.9852], Lowest was [0.392  0.0805 0.335  0.9849]
Median for last 10 epochs: [0.4519 0.1038 0.5064 0.9852], Epochs since improvement 4
 11%|█         | 53/500 [59:31<8:05:32, 65.17s/it] 11%|█         | 54/500 [1:00:52<8:38:12, 69.71s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 5.44E+06, Train scatter: [0.3933 0.0991 0.4506 0.9956]
L1 regularization loss: 4.82E+00, L2 regularization loss: 1.27E+00
Test scatter: [0.3876 0.0968 0.445  0.9852], Lowest was [0.3876 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.42   0.1021 0.4961 0.9852], Epochs since improvement 0
 11%|█         | 55/500 [1:01:45<8:00:22, 64.77s/it] 11%|█         | 56/500 [1:03:05<8:33:58, 69.46s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.43E+06, Train scatter: [0.3271 0.085  0.4218 0.9956]
L1 regularization loss: 4.83E+00, L2 regularization loss: 1.31E+00
Test scatter: [0.326  0.0832 0.4167 0.9852], Lowest was [0.326  0.0805 0.335  0.9849]
Median for last 10 epochs: [0.392  0.1013 0.4575 0.9852], Epochs since improvement 0
 11%|█▏        | 57/500 [1:03:59<7:57:01, 64.61s/it] 12%|█▏        | 58/500 [1:05:19<8:31:13, 69.40s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.17E+06, Train scatter: [0.3128 0.0826 0.4096 0.9955]
L1 regularization loss: 4.84E+00, L2 regularization loss: 1.33E+00
Test scatter: [0.3109 0.0807 0.4053 0.9852], Lowest was [0.3109 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.3876 0.0968 0.445  0.9852], Epochs since improvement 0
 12%|█▏        | 59/500 [1:06:12<7:54:05, 64.50s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.05E+06, Train scatter: [0.4063 0.0845 0.3987 0.9956]
L1 regularization loss: 4.84E+00, L2 regularization loss: 1.34E+00
Test scatter: [0.4021 0.0822 0.3946 0.9852], Lowest was [0.3109 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.3876 0.0832 0.4167 0.9852], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:07:40<8:44:13, 71.48s/it] 12%|█▏        | 61/500 [1:08:33<8:03:34, 66.09s/it] 12%|█▏        | 62/500 [1:09:58<8:41:45, 71.47s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 4.56E+06, Train scatter: [0.4311 0.0956 0.5309 0.9956]
L1 regularization loss: 4.85E+00, L2 regularization loss: 1.37E+00
Test scatter: [0.4284 0.0926 0.5223 0.9853], Lowest was [0.3109 0.0805 0.335  0.9849]
Median for last 10 epochs: [0.3876 0.0832 0.4167 0.9852], Epochs since improvement 4
 13%|█▎        | 63/500 [1:10:51<8:01:40, 66.13s/it] 13%|█▎        | 64/500 [1:12:14<8:36:26, 71.07s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.88E+06, Train scatter: [0.3325 0.0786 0.468  0.9955]
L1 regularization loss: 4.86E+00, L2 regularization loss: 1.38E+00
Test scatter: [0.33   0.0773 0.459  0.9851], Lowest was [0.3109 0.0773 0.335  0.9849]
Median for last 10 epochs: [0.33   0.0822 0.4167 0.9852], Epochs since improvement 0
 13%|█▎        | 65/500 [1:13:07<7:57:24, 65.85s/it] 13%|█▎        | 66/500 [1:14:33<8:40:01, 71.89s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.74E+06, Train scatter: [0.3606 0.0778 0.45   0.9955]
L1 regularization loss: 4.90E+00, L2 regularization loss: 1.40E+00
Test scatter: [0.3597 0.0759 0.4421 0.9852], Lowest was [0.3109 0.0759 0.335  0.9849]
Median for last 10 epochs: [0.3597 0.0807 0.4421 0.9852], Epochs since improvement 0
 13%|█▎        | 67/500 [1:15:29<8:04:23, 67.12s/it] 14%|█▎        | 68/500 [1:16:49<8:30:53, 70.96s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.03E+06, Train scatter: [0.4676 0.0851 0.404  0.9955]
L1 regularization loss: 4.90E+00, L2 regularization loss: 1.42E+00
Test scatter: [0.4542 0.0827 0.4005 0.9852], Lowest was [0.3109 0.0759 0.335  0.9849]
Median for last 10 epochs: [0.4021 0.0822 0.4421 0.9852], Epochs since improvement 2
 14%|█▍        | 69/500 [1:17:42<7:50:56, 65.56s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.69E+06, Train scatter: [0.4447 0.0759 0.3843 0.9955]
L1 regularization loss: 4.90E+00, L2 regularization loss: 1.43E+00
Test scatter: [0.4363 0.0742 0.3806 0.9852], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.4284 0.0773 0.4421 0.9852], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:19:10<8:36:38, 72.09s/it] 14%|█▍        | 71/500 [1:20:03<7:54:40, 66.39s/it] 14%|█▍        | 72/500 [1:21:23<8:22:24, 70.43s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 9.66E+06, Train scatter: [0.9222 0.1658 0.544  0.9955]
L1 regularization loss: 4.98E+00, L2 regularization loss: 1.49E+00
Test scatter: [0.9071 0.1622 0.5354 0.9852], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.4363 0.0773 0.4421 0.9852], Epochs since improvement 2
 15%|█▍        | 73/500 [1:22:16<7:44:16, 65.24s/it] 15%|█▍        | 74/500 [1:23:36<8:16:02, 69.86s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.11E+06, Train scatter: [0.3531 0.0853 0.5416 0.9955]
L1 regularization loss: 4.98E+00, L2 regularization loss: 1.51E+00
Test scatter: [0.3524 0.0829 0.533  0.9852], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.4363 0.0827 0.4421 0.9852], Epochs since improvement 4
 15%|█▌        | 75/500 [1:24:29<7:39:18, 64.84s/it] 15%|█▌        | 76/500 [1:25:51<8:13:32, 69.84s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.00E+06, Train scatter: [0.4547 0.0828 0.5373 0.9955]
L1 regularization loss: 4.98E+00, L2 regularization loss: 1.51E+00
Test scatter: [0.4457 0.081  0.5288 0.9852], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.4457 0.0827 0.5288 0.9852], Epochs since improvement 6
 15%|█▌        | 77/500 [1:26:44<7:36:45, 64.79s/it] 16%|█▌        | 78/500 [1:28:04<8:08:45, 69.49s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.38E+06, Train scatter: [0.3223 0.0796 0.5023 0.9955]
L1 regularization loss: 4.99E+00, L2 regularization loss: 1.53E+00
Test scatter: [0.3196 0.0779 0.4936 0.9851], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.4363 0.081  0.5288 0.9852], Epochs since improvement 8
 16%|█▌        | 79/500 [1:28:57<7:32:44, 64.52s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.19E+06, Train scatter: [0.3263 0.0794 0.4846 0.9954]
L1 regularization loss: 5.00E+00, L2 regularization loss: 1.56E+00
Test scatter: [0.3239 0.0782 0.476  0.9851], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.3524 0.081  0.5288 0.9852], Epochs since improvement 10
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:30:26<8:22:31, 71.79s/it] 16%|█▌        | 81/500 [1:31:19<7:42:11, 66.18s/it] 16%|█▋        | 82/500 [1:32:40<8:12:05, 70.64s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.15E+06, Train scatter: [0.4795 0.0795 0.4877 0.9954]
L1 regularization loss: 5.00E+00, L2 regularization loss: 1.58E+00
Test scatter: [0.4668 0.0784 0.4784 0.985 ], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.3524 0.0784 0.4936 0.9851], Epochs since improvement 12
 17%|█▋        | 83/500 [1:33:33<7:34:34, 65.41s/it] 17%|█▋        | 84/500 [1:34:55<8:06:11, 70.12s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 1.91E+06, Train scatter: [0.4901 0.0834 0.4715 0.9954]
L1 regularization loss: 5.01E+00, L2 regularization loss: 1.59E+00
Test scatter: [0.4749 0.0831 0.4627 0.985 ], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.4457 0.0784 0.4784 0.9851], Epochs since improvement 14
 17%|█▋        | 85/500 [1:35:48<7:30:03, 65.07s/it] 17%|█▋        | 86/500 [1:37:09<8:01:57, 69.85s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 1.48E+06, Train scatter: [0.3401 0.0762 0.404  0.9954]
L1 regularization loss: 5.01E+00, L2 regularization loss: 1.60E+00
Test scatter: [0.3376 0.0743 0.4012 0.9851], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.3376 0.0782 0.476  0.9851], Epochs since improvement 16
 17%|█▋        | 87/500 [1:38:02<7:26:52, 64.92s/it] 18%|█▊        | 88/500 [1:39:22<7:56:17, 69.36s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 1.42E+06, Train scatter: [0.4934 0.0828 0.4075 0.9954]
L1 regularization loss: 5.01E+00, L2 regularization loss: 1.62E+00
Test scatter: [0.4912 0.0793 0.4008 0.9851], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.4668 0.0784 0.4627 0.9851], Epochs since improvement 18
 18%|█▊        | 89/500 [1:40:16<7:23:03, 64.68s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.28E+06, Train scatter: [0.6756 0.0984 0.5405 0.9953]
L1 regularization loss: 5.01E+00, L2 regularization loss: 1.63E+00
Test scatter: [0.6628 0.0952 0.5318 0.9849], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.4749 0.0793 0.4627 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:41:44<8:10:04, 71.72s/it] 18%|█▊        | 91/500 [1:42:37<7:31:30, 66.24s/it] 18%|█▊        | 92/500 [1:44:00<8:04:12, 71.21s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 1.56E+06, Train scatter: [0.4239 0.0868 0.4095 0.9953]
L1 regularization loss: 5.01E+00, L2 regularization loss: 1.63E+00
Test scatter: [0.4209 0.0833 0.4041 0.9849], Lowest was [0.3109 0.0742 0.335  0.9849]
Median for last 10 epochs: [0.4749 0.0831 0.4041 0.985 ], Epochs since improvement 0
 19%|█▊        | 93/500 [1:44:53<7:26:38, 65.85s/it] 19%|█▉        | 94/500 [1:46:15<7:56:33, 70.43s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 1.01E+06, Train scatter: [0.3389 0.0756 0.393  0.9953]
L1 regularization loss: 5.01E+00, L2 regularization loss: 1.65E+00
Test scatter: [0.3407 0.0734 0.3898 0.985 ], Lowest was [0.3109 0.0734 0.335  0.9849]
Median for last 10 epochs: [0.4209 0.0793 0.4012 0.985 ], Epochs since improvement 0
 19%|█▉        | 95/500 [1:47:08<7:20:52, 65.32s/it] 19%|█▉        | 96/500 [1:48:28<7:49:56, 69.79s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 9.55E+05, Train scatter: [0.3251 0.0742 0.3872 0.9953]
L1 regularization loss: 5.02E+00, L2 regularization loss: 1.66E+00
Test scatter: [0.3174 0.0744 0.3842 0.985 ], Lowest was [0.3109 0.0734 0.335  0.9849]
Median for last 10 epochs: [0.4209 0.0793 0.4008 0.985 ], Epochs since improvement 2
 19%|█▉        | 97/500 [1:49:21<7:15:04, 64.78s/it] 20%|█▉        | 98/500 [1:50:42<7:46:57, 69.69s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 1.07E+06, Train scatter: [0.3409 0.0757 0.3916 0.9953]
L1 regularization loss: 5.02E+00, L2 regularization loss: 1.67E+00
Test scatter: [0.3336 0.0758 0.39   0.985 ], Lowest was [0.3109 0.0734 0.335  0.9849]
Median for last 10 epochs: [0.3407 0.0758 0.39   0.985 ], Epochs since improvement 4
 20%|█▉        | 99/500 [1:51:36<7:13:01, 64.79s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 8.72E+05, Train scatter: [0.447  0.0736 0.3826 0.9953]
L1 regularization loss: 5.02E+00, L2 regularization loss: 1.69E+00
Test scatter: [0.4377 0.0734 0.3816 0.985 ], Lowest was [0.3109 0.0734 0.335  0.9849]
Median for last 10 epochs: [0.3407 0.0744 0.3898 0.985 ], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:53:04<7:58:26, 71.77s/it] 20%|██        | 101/500 [1:53:57<7:20:18, 66.21s/it] 20%|██        | 102/500 [1:55:18<7:47:42, 70.51s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 6.37E+05, Train scatter: [0.3177 0.0733 0.3851 0.9953]
L1 regularization loss: 5.03E+00, L2 regularization loss: 1.71E+00
Test scatter: [0.309  0.0744 0.3877 0.985 ], Lowest was [0.309  0.0734 0.335  0.9849]
Median for last 10 epochs: [0.3336 0.0744 0.3877 0.985 ], Epochs since improvement 0
 21%|██        | 103/500 [1:56:11<7:12:09, 65.31s/it] 21%|██        | 104/500 [1:57:31<7:41:09, 69.87s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 5.41E+05, Train scatter: [0.5402 0.1032 0.4213 0.9954]
L1 regularization loss: 5.03E+00, L2 regularization loss: 1.72E+00
Test scatter: [0.5459 0.0988 0.4116 0.9851], Lowest was [0.309  0.0734 0.335  0.9849]
Median for last 10 epochs: [0.3336 0.0744 0.3877 0.985 ], Epochs since improvement 2
 21%|██        | 105/500 [1:58:25<7:06:59, 64.86s/it] 21%|██        | 106/500 [1:59:45<7:37:27, 69.66s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 4.38E+05, Train scatter: [0.3232 0.0701 0.374  0.9953]
L1 regularization loss: 5.04E+00, L2 regularization loss: 1.73E+00
Test scatter: [0.3271 0.0684 0.3722 0.985 ], Lowest was [0.309  0.0684 0.335  0.9849]
Median for last 10 epochs: [0.3336 0.0744 0.3877 0.985 ], Epochs since improvement 0
 21%|██▏       | 107/500 [2:00:39<7:04:19, 64.78s/it] 22%|██▏       | 108/500 [2:01:59<7:34:17, 69.53s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 4.84E+05, Train scatter: [0.2988 0.0699 0.3698 0.9954]
L1 regularization loss: 5.04E+00, L2 regularization loss: 1.74E+00
Test scatter: [0.2976 0.0676 0.3674 0.985 ], Lowest was [0.2976 0.0676 0.335  0.9849]
Median for last 10 epochs: [0.3271 0.0734 0.3816 0.985 ], Epochs since improvement 0
 22%|██▏       | 109/500 [2:02:53<7:01:24, 64.67s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 1.12E+06, Train scatter: [0.4429 0.0705 0.4304 0.9953]
L1 regularization loss: 5.05E+00, L2 regularization loss: 1.75E+00
Test scatter: [0.4332 0.0697 0.4254 0.985 ], Lowest was [0.2976 0.0676 0.335  0.9849]
Median for last 10 epochs: [0.3271 0.0697 0.3877 0.985 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:04:20<7:45:04, 71.55s/it] 22%|██▏       | 111/500 [2:05:14<7:08:16, 66.06s/it] 22%|██▏       | 112/500 [2:06:34<7:34:36, 70.30s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 5.05E+05, Train scatter: [0.4631 0.0815 0.3886 0.9954]
L1 regularization loss: 5.05E+00, L2 regularization loss: 1.76E+00
Test scatter: [0.4656 0.0778 0.3807 0.985 ], Lowest was [0.2976 0.0676 0.335  0.9849]
Median for last 10 epochs: [0.4332 0.0697 0.3807 0.985 ], Epochs since improvement 4
 23%|██▎       | 113/500 [2:07:27<7:00:22, 65.17s/it] 23%|██▎       | 114/500 [2:08:47<7:27:41, 69.59s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 5.57E+05, Train scatter: [0.3148 0.0745 0.3748 0.9953]
L1 regularization loss: 5.05E+00, L2 regularization loss: 1.77E+00
Test scatter: [0.3116 0.076  0.3752 0.985 ], Lowest was [0.2976 0.0676 0.335  0.9849]
Median for last 10 epochs: [0.3271 0.0697 0.3752 0.985 ], Epochs since improvement 6
 23%|██▎       | 115/500 [2:09:40<6:54:53, 64.66s/it] 23%|██▎       | 116/500 [2:11:01<7:24:57, 69.53s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.11E+06, Train scatter: [0.4552 0.0697 0.3728 0.9953]
L1 regularization loss: 5.06E+00, L2 regularization loss: 1.79E+00
Test scatter: [0.4459 0.0682 0.3705 0.985 ], Lowest was [0.2976 0.0676 0.335  0.9849]
Median for last 10 epochs: [0.4332 0.0697 0.3752 0.985 ], Epochs since improvement 8
 23%|██▎       | 117/500 [2:11:54<6:52:47, 64.67s/it] 24%|██▎       | 118/500 [2:13:15<7:22:23, 69.49s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 5.33E+05, Train scatter: [0.4401 0.0669 0.3648 0.9953]
L1 regularization loss: 5.06E+00, L2 regularization loss: 1.80E+00
Test scatter: [0.4316 0.0653 0.3605 0.985 ], Lowest was [0.2976 0.0653 0.335  0.9849]
Median for last 10 epochs: [0.4332 0.0697 0.3752 0.985 ], Epochs since improvement 0
 24%|██▍       | 119/500 [2:14:08<6:50:34, 64.66s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 4.31E+05, Train scatter: [0.424  0.0666 0.3612 0.9954]
L1 regularization loss: 5.06E+00, L2 regularization loss: 1.82E+00
Test scatter: [0.4153 0.0673 0.3625 0.985 ], Lowest was [0.2976 0.0653 0.335  0.9849]
Median for last 10 epochs: [0.4316 0.0682 0.3705 0.985 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 24%|██▍       | 120/500 [2:15:36<7:33:06, 71.54s/it] 24%|██▍       | 121/500 [2:16:29<6:57:17, 66.06s/it] 24%|██▍       | 122/500 [2:17:50<7:23:56, 70.47s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 8.54E+05, Train scatter: [0.4738 0.0798 0.3867 0.9953]
L1 regularization loss: 5.07E+00, L2 regularization loss: 1.83E+00
Test scatter: [0.4624 0.0773 0.3845 0.985 ], Lowest was [0.2976 0.0653 0.335  0.9849]
Median for last 10 epochs: [0.4316 0.0682 0.3705 0.985 ], Epochs since improvement 4
 25%|██▍       | 123/500 [2:18:44<6:51:01, 65.41s/it] 25%|██▍       | 124/500 [2:20:04<7:17:11, 69.76s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 4.28E+05, Train scatter: [0.4476 0.0656 0.3651 0.9953]
L1 regularization loss: 5.07E+00, L2 regularization loss: 1.84E+00
Test scatter: [0.4373 0.0657 0.3675 0.9849], Lowest was [0.2976 0.0653 0.335  0.9849]
Median for last 10 epochs: [0.4373 0.0673 0.3675 0.985 ], Epochs since improvement 6
 25%|██▌       | 125/500 [2:20:57<6:45:09, 64.83s/it] 25%|██▌       | 126/500 [2:22:17<7:13:32, 69.55s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 4.96E+05, Train scatter: [0.4546 0.0749 0.4038 0.9952]
L1 regularization loss: 5.12E+00, L2 regularization loss: 1.90E+00
Test scatter: [0.4446 0.0738 0.4    0.9848], Lowest was [0.2976 0.0653 0.335  0.9848]
Median for last 10 epochs: [0.4373 0.0673 0.3675 0.985 ], Epochs since improvement 0
 25%|██▌       | 127/500 [2:23:11<6:42:17, 64.71s/it] 26%|██▌       | 128/500 [2:24:32<7:12:20, 69.73s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 4.81E+05, Train scatter: [0.366  0.0835 0.4161 0.9952]
L1 regularization loss: 5.13E+00, L2 regularization loss: 1.92E+00
Test scatter: [0.3641 0.0804 0.4088 0.9849], Lowest was [0.2976 0.0653 0.335  0.9848]
Median for last 10 epochs: [0.4373 0.0738 0.3845 0.9849], Epochs since improvement 2
 26%|██▌       | 129/500 [2:25:26<6:40:41, 64.80s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 4.18E+05, Train scatter: [0.4976 0.1256 0.5004 0.9944]
L1 regularization loss: 5.14E+00, L2 regularization loss: 1.93E+00
Test scatter: [0.4888 0.1222 0.49   0.9841], Lowest was [0.2976 0.0653 0.335  0.9841]
Median for last 10 epochs: [0.4446 0.0773 0.4    0.9849], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 26%|██▌       | 130/500 [2:26:54<7:23:23, 71.90s/it] 26%|██▌       | 131/500 [2:27:47<6:48:02, 66.35s/it] 26%|██▋       | 132/500 [2:29:09<7:14:18, 70.81s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 2.12E+05, Train scatter: [0.4506 0.0672 0.3671 0.9948]
L1 regularization loss: 5.14E+00, L2 regularization loss: 1.94E+00
Test scatter: [0.4407 0.0667 0.3665 0.9845], Lowest was [0.2976 0.0653 0.335  0.9841]
Median for last 10 epochs: [0.4407 0.0738 0.4    0.9848], Epochs since improvement 2
 27%|██▋       | 133/500 [2:30:02<6:41:09, 65.58s/it] 27%|██▋       | 134/500 [2:31:23<7:07:38, 70.10s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 4.41E+05, Train scatter: [0.4882 0.0858 0.4347 0.9744]
L1 regularization loss: 5.19E+00, L2 regularization loss: 2.02E+00
Test scatter: [0.4787 0.0846 0.4305 0.9643], Lowest was [0.2976 0.0653 0.335  0.9643]
Median for last 10 epochs: [0.4446 0.0804 0.4088 0.9845], Epochs since improvement 0
 27%|██▋       | 135/500 [2:32:16<6:35:49, 65.07s/it] 27%|██▋       | 136/500 [2:33:36<7:02:39, 69.67s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 1.38E+05, Train scatter: [0.4432 0.08   0.4766 0.6802]
L1 regularization loss: 5.22E+00, L2 regularization loss: 2.06E+00
Test scatter: [0.4344 0.0783 0.4673 0.674 ], Lowest was [0.2976 0.0653 0.335  0.674 ]
Median for last 10 epochs: [0.4407 0.0804 0.4305 0.9841], Epochs since improvement 0
 27%|██▋       | 137/500 [2:34:30<6:31:50, 64.77s/it] 28%|██▊       | 138/500 [2:35:50<6:59:38, 69.55s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -1.51E+05, Train scatter: [0.2819 0.0705 0.4469 0.5865]
L1 regularization loss: 5.22E+00, L2 regularization loss: 2.07E+00
Test scatter: [0.2814 0.0687 0.4381 0.578 ], Lowest was [0.2814 0.0653 0.335  0.578 ]
Median for last 10 epochs: [0.4407 0.0783 0.4381 0.9643], Epochs since improvement 0
 28%|██▊       | 139/500 [2:36:44<6:29:04, 64.67s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -1.98E+05, Train scatter: [0.275  0.0672 0.3776 0.5305]
L1 regularization loss: 5.22E+00, L2 regularization loss: 2.08E+00
Test scatter: [0.2736 0.0654 0.3751 0.5198], Lowest was [0.2736 0.0653 0.335  0.5198]
Median for last 10 epochs: [0.4344 0.0687 0.4305 0.674 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 28%|██▊       | 140/500 [2:38:13<7:13:00, 72.17s/it] 28%|██▊       | 141/500 [2:39:07<6:37:42, 66.47s/it] 28%|██▊       | 142/500 [2:40:27<7:01:06, 70.58s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -1.28E+05, Train scatter: [0.2785 0.0643 0.3724 0.5253]
L1 regularization loss: 5.22E+00, L2 regularization loss: 2.09E+00
Test scatter: [0.278  0.063  0.3712 0.5162], Lowest was [0.2736 0.063  0.335  0.5162]
Median for last 10 epochs: [0.2814 0.0687 0.4305 0.578 ], Epochs since improvement 0
 29%|██▊       | 143/500 [2:41:20<6:28:50, 65.35s/it] 29%|██▉       | 144/500 [2:42:41<6:55:44, 70.07s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: -2.20E+05, Train scatter: [0.2605 0.0634 0.3724 0.5283]
L1 regularization loss: 5.23E+00, L2 regularization loss: 2.10E+00
Test scatter: [0.2606 0.0621 0.3683 0.5171], Lowest was [0.2606 0.0621 0.335  0.5162]
Median for last 10 epochs: [0.278  0.0654 0.3751 0.5198], Epochs since improvement 0
 29%|██▉       | 145/500 [2:43:34<6:24:35, 65.00s/it] 29%|██▉       | 146/500 [2:44:56<6:52:40, 69.95s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: -2.35E+05, Train scatter: [0.2536 0.067  0.3858 0.552 ]
L1 regularization loss: 5.23E+00, L2 regularization loss: 2.12E+00
Test scatter: [0.2542 0.0673 0.3865 0.5466], Lowest was [0.2542 0.0621 0.335  0.5162]
Median for last 10 epochs: [0.2736 0.0654 0.3751 0.5198], Epochs since improvement 0
 29%|██▉       | 147/500 [2:45:49<6:21:47, 64.89s/it] 30%|██▉       | 148/500 [2:47:09<6:48:05, 69.56s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: -2.26E+05, Train scatter: [0.3008 0.0771 0.4056 0.5269]
L1 regularization loss: 5.24E+00, L2 regularization loss: 2.13E+00
Test scatter: [0.3007 0.0739 0.3951 0.5151], Lowest was [0.2542 0.0621 0.335  0.5151]
Median for last 10 epochs: [0.2736 0.0654 0.3751 0.5171], Epochs since improvement 0
 30%|██▉       | 149/500 [2:48:02<6:18:06, 64.63s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: -2.46E+05, Train scatter: [0.2435 0.0693 0.3652 0.5154]
L1 regularization loss: 5.24E+00, L2 regularization loss: 2.14E+00
Test scatter: [0.2445 0.0699 0.3644 0.5065], Lowest was [0.2445 0.0621 0.335  0.5065]
Median for last 10 epochs: [0.2606 0.0673 0.3712 0.5162], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 30%|███       | 150/500 [2:49:32<7:00:38, 72.11s/it] 30%|███       | 151/500 [2:50:25<6:27:01, 66.54s/it] 30%|███       | 152/500 [2:51:46<6:50:01, 70.69s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: -2.48E+05, Train scatter: [0.2533 0.0693 0.4075 0.521 ]
L1 regularization loss: 5.25E+00, L2 regularization loss: 2.15E+00
Test scatter: [0.254  0.0698 0.4105 0.514 ], Lowest was [0.2445 0.0621 0.335  0.5065]
Median for last 10 epochs: [0.2542 0.0698 0.3865 0.5151], Epochs since improvement 2
 31%|███       | 153/500 [2:52:39<6:18:37, 65.47s/it] 31%|███       | 154/500 [2:54:01<6:45:48, 70.37s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: -2.11E+05, Train scatter: [0.2515 0.0621 0.3753 0.5158]
L1 regularization loss: 5.26E+00, L2 regularization loss: 2.17E+00
Test scatter: [0.2549 0.0612 0.3714 0.5044], Lowest was [0.2445 0.0612 0.335  0.5044]
Median for last 10 epochs: [0.2542 0.0698 0.3865 0.514 ], Epochs since improvement 0
 31%|███       | 155/500 [2:54:54<6:15:11, 65.25s/it] 31%|███       | 156/500 [2:56:15<6:40:42, 69.89s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: -2.37E+05, Train scatter: [0.2439 0.0616 0.3497 0.5084]
L1 regularization loss: 5.27E+00, L2 regularization loss: 2.19E+00
Test scatter: [0.2456 0.0605 0.3483 0.4979], Lowest was [0.2445 0.0605 0.335  0.4979]
Median for last 10 epochs: [0.254  0.0698 0.3714 0.5065], Epochs since improvement 0
 31%|███▏      | 157/500 [2:57:08<6:10:51, 64.87s/it] 32%|███▏      | 158/500 [2:58:29<6:36:54, 69.63s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: -2.41E+05, Train scatter: [0.2354 0.0607 0.3651 0.5087]
L1 regularization loss: 5.28E+00, L2 regularization loss: 2.20E+00
Test scatter: [0.2364 0.0597 0.3594 0.4974], Lowest was [0.2364 0.0597 0.335  0.4974]
Median for last 10 epochs: [0.2456 0.0612 0.3644 0.5044], Epochs since improvement 0
 32%|███▏      | 159/500 [2:59:22<6:07:56, 64.74s/it]Epoch: 160 done with learning rate 9.04E-03, Train loss: -2.61E+05, Train scatter: [0.2412 0.0693 0.3671 0.5173]
L1 regularization loss: 5.28E+00, L2 regularization loss: 2.21E+00
Test scatter: [0.2414 0.0689 0.3676 0.5093], Lowest was [0.2364 0.0597 0.335  0.4974]
Median for last 10 epochs: [0.2456 0.0612 0.3676 0.5044], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 32%|███▏      | 160/500 [3:00:50<6:46:26, 71.72s/it] 32%|███▏      | 161/500 [3:01:44<6:14:07, 66.22s/it] 32%|███▏      | 162/500 [3:03:04<6:37:24, 70.55s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: -2.63E+05, Train scatter: [0.2467 0.0612 0.3631 0.5133]
L1 regularization loss: 5.29E+00, L2 regularization loss: 2.23E+00
Test scatter: [0.2488 0.0604 0.357  0.5015], Lowest was [0.2364 0.0597 0.335  0.4974]
Median for last 10 epochs: [0.2456 0.0605 0.3594 0.5015], Epochs since improvement 4
 33%|███▎      | 163/500 [3:03:58<6:07:23, 65.41s/it] 33%|███▎      | 164/500 [3:05:19<6:33:55, 70.34s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: -2.48E+05, Train scatter: [0.2332 0.0643 0.353  0.5173]
L1 regularization loss: 5.31E+00, L2 regularization loss: 2.25E+00
Test scatter: [0.2337 0.0634 0.3521 0.5094], Lowest was [0.2337 0.0597 0.335  0.4974]
Median for last 10 epochs: [0.2414 0.0605 0.357  0.5015], Epochs since improvement 0
 33%|███▎      | 165/500 [3:06:13<6:03:53, 65.18s/it] 33%|███▎      | 166/500 [3:07:34<6:29:46, 70.02s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: -2.69E+05, Train scatter: [0.2295 0.0608 0.3541 0.5036]
L1 regularization loss: 5.31E+00, L2 regularization loss: 2.27E+00
Test scatter: [0.2302 0.0596 0.3537 0.4944], Lowest was [0.2302 0.0596 0.335  0.4944]
Median for last 10 epochs: [0.2364 0.0604 0.357  0.5015], Epochs since improvement 0
 33%|███▎      | 167/500 [3:08:27<6:00:45, 65.00s/it] 34%|███▎      | 168/500 [3:09:49<6:26:57, 69.93s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: -2.67E+05, Train scatter: [0.2337 0.0593 0.3414 0.4999]
L1 regularization loss: 5.32E+00, L2 regularization loss: 2.29E+00
Test scatter: [0.2335 0.0584 0.3391 0.4899], Lowest was [0.2302 0.0584 0.335  0.4899]
Median for last 10 epochs: [0.2337 0.0604 0.3537 0.5015], Epochs since improvement 0
 34%|███▍      | 169/500 [3:10:42<5:58:19, 64.95s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -2.77E+05, Train scatter: [0.2806 0.0616 0.3418 0.5429]
L1 regularization loss: 5.32E+00, L2 regularization loss: 2.31E+00
Test scatter: [0.2838 0.061  0.3394 0.533 ], Lowest was [0.2302 0.0584 0.335  0.4899]
Median for last 10 epochs: [0.2337 0.0604 0.3521 0.5015], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 34%|███▍      | 170/500 [3:12:10<6:34:32, 71.74s/it] 34%|███▍      | 171/500 [3:13:03<6:02:55, 66.19s/it] 34%|███▍      | 172/500 [3:14:23<6:24:54, 70.41s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -2.79E+05, Train scatter: [0.2192 0.06   0.3423 0.4974]
L1 regularization loss: 5.32E+00, L2 regularization loss: 2.32E+00
Test scatter: [0.2203 0.0593 0.3409 0.4882], Lowest was [0.2203 0.0584 0.335  0.4882]
Median for last 10 epochs: [0.2335 0.0596 0.3409 0.4944], Epochs since improvement 0
 35%|███▍      | 173/500 [3:15:16<5:54:39, 65.08s/it] 35%|███▍      | 174/500 [3:16:35<6:17:26, 69.47s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -2.82E+05, Train scatter: [0.2421 0.0646 0.3465 0.5211]
L1 regularization loss: 5.32E+00, L2 regularization loss: 2.34E+00
Test scatter: [0.2438 0.0644 0.3442 0.5122], Lowest was [0.2203 0.0584 0.335  0.4882]
Median for last 10 epochs: [0.2335 0.0596 0.3409 0.4944], Epochs since improvement 2
 35%|███▌      | 175/500 [3:17:28<5:48:52, 64.41s/it] 35%|███▌      | 176/500 [3:18:47<6:12:12, 68.93s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -2.78E+05, Train scatter: [0.2602 0.0655 0.3663 0.5453]
L1 regularization loss: 5.34E+00, L2 regularization loss: 2.36E+00
Test scatter: [0.264  0.0655 0.3618 0.5375], Lowest was [0.2203 0.0584 0.335  0.4882]
Median for last 10 epochs: [0.2438 0.061  0.3409 0.5122], Epochs since improvement 4
 35%|███▌      | 177/500 [3:19:40<5:44:42, 64.03s/it] 36%|███▌      | 178/500 [3:21:01<6:10:35, 69.05s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -2.83E+05, Train scatter: [0.2229 0.0608 0.3554 0.4937]
L1 regularization loss: 5.34E+00, L2 regularization loss: 2.38E+00
Test scatter: [0.2242 0.0596 0.353  0.4849], Lowest was [0.2203 0.0584 0.335  0.4849]
Median for last 10 epochs: [0.2438 0.061  0.3442 0.5122], Epochs since improvement 0
 36%|███▌      | 179/500 [3:21:53<5:42:57, 64.10s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -2.90E+05, Train scatter: [0.2116 0.0594 0.327  0.4945]
L1 regularization loss: 5.33E+00, L2 regularization loss: 2.39E+00
Test scatter: [0.2126 0.0584 0.3253 0.4858], Lowest was [0.2126 0.0584 0.3253 0.4849]
Median for last 10 epochs: [0.2242 0.0596 0.3442 0.4882], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 36%|███▌      | 180/500 [3:23:21<6:18:55, 71.05s/it] 36%|███▌      | 181/500 [3:24:13<5:48:36, 65.57s/it] 36%|███▋      | 182/500 [3:25:34<6:11:02, 70.01s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -2.90E+05, Train scatter: [0.2169 0.0577 0.3289 0.4929]
L1 regularization loss: 5.33E+00, L2 regularization loss: 2.40E+00
Test scatter: [0.22   0.0573 0.3284 0.4846], Lowest was [0.2126 0.0573 0.3253 0.4846]
Median for last 10 epochs: [0.2242 0.0596 0.3442 0.4858], Epochs since improvement 0
 37%|███▋      | 183/500 [3:26:26<5:42:25, 64.81s/it] 37%|███▋      | 184/500 [3:27:46<6:04:32, 69.22s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -2.90E+05, Train scatter: [0.2032 0.0587 0.3288 0.4899]
L1 regularization loss: 5.34E+00, L2 regularization loss: 2.42E+00
Test scatter: [0.2044 0.0577 0.3268 0.482 ], Lowest was [0.2044 0.0573 0.3253 0.482 ]
Median for last 10 epochs: [0.22   0.0584 0.3284 0.4849], Epochs since improvement 0
 37%|███▋      | 185/500 [3:28:39<5:37:10, 64.22s/it] 37%|███▋      | 186/500 [3:29:58<6:00:20, 68.86s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -2.93E+05, Train scatter: [0.2196 0.0638 0.3408 0.5059]
L1 regularization loss: 5.34E+00, L2 regularization loss: 2.43E+00
Test scatter: [0.2222 0.0635 0.3392 0.4993], Lowest was [0.2044 0.0573 0.3253 0.482 ]
Median for last 10 epochs: [0.22   0.0584 0.3284 0.4849], Epochs since improvement 2
 37%|███▋      | 187/500 [3:30:51<5:33:42, 63.97s/it] 38%|███▊      | 188/500 [3:32:11<5:58:03, 68.86s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -2.91E+05, Train scatter: [0.2166 0.06   0.3296 0.4904]
L1 regularization loss: 5.34E+00, L2 regularization loss: 2.45E+00
Test scatter: [0.2202 0.0592 0.3313 0.482 ], Lowest was [0.2044 0.0573 0.3253 0.482 ]
Median for last 10 epochs: [0.22   0.0584 0.3284 0.4846], Epochs since improvement 4
 38%|███▊      | 189/500 [3:33:04<5:31:47, 64.01s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -2.97E+05, Train scatter: [0.2118 0.0623 0.3863 0.4977]
L1 regularization loss: 5.35E+00, L2 regularization loss: 2.47E+00
Test scatter: [0.2174 0.0618 0.3839 0.4899], Lowest was [0.2044 0.0573 0.3253 0.482 ]
Median for last 10 epochs: [0.22   0.0592 0.3313 0.4846], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 38%|███▊      | 190/500 [3:34:32<6:07:54, 71.21s/it] 38%|███▊      | 191/500 [3:35:24<5:38:08, 65.66s/it] 38%|███▊      | 192/500 [3:36:44<5:58:46, 69.89s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -2.92E+05, Train scatter: [0.2418 0.059  0.3075 0.4927]
L1 regularization loss: 5.37E+00, L2 regularization loss: 2.51E+00
Test scatter: [0.2355 0.0581 0.3058 0.4842], Lowest was [0.2044 0.0573 0.3058 0.482 ]
Median for last 10 epochs: [0.2202 0.0592 0.3313 0.4842], Epochs since improvement 0
 39%|███▊      | 193/500 [3:37:37<5:31:11, 64.73s/it] 39%|███▉      | 194/500 [3:38:57<5:53:42, 69.35s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -2.98E+05, Train scatter: [0.22   0.0528 0.3111 0.4853]
L1 regularization loss: 5.37E+00, L2 regularization loss: 2.53E+00
Test scatter: [0.2221 0.052  0.3108 0.4771], Lowest was [0.2044 0.052  0.3058 0.4771]
Median for last 10 epochs: [0.2221 0.0592 0.3313 0.4842], Epochs since improvement 0
 39%|███▉      | 195/500 [3:39:50<5:27:08, 64.36s/it] 39%|███▉      | 196/500 [3:41:10<5:50:58, 69.27s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -3.03E+05, Train scatter: [0.2064 0.0549 0.2913 0.5167]
L1 regularization loss: 5.38E+00, L2 regularization loss: 2.55E+00
Test scatter: [0.2076 0.0541 0.2921 0.5115], Lowest was [0.2044 0.052  0.2921 0.4771]
Median for last 10 epochs: [0.2202 0.0581 0.3108 0.4842], Epochs since improvement 0
 39%|███▉      | 197/500 [3:42:03<5:24:50, 64.32s/it] 40%|███▉      | 198/500 [3:43:23<5:47:32, 69.05s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -3.12E+05, Train scatter: [0.1964 0.0532 0.2875 0.4836]
L1 regularization loss: 5.41E+00, L2 regularization loss: 2.58E+00
Test scatter: [0.1979 0.0525 0.2883 0.4765], Lowest was [0.1979 0.052  0.2883 0.4765]
Median for last 10 epochs: [0.2174 0.0541 0.3058 0.4842], Epochs since improvement 0
 40%|███▉      | 199/500 [3:44:16<5:21:52, 64.16s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -3.23E+05, Train scatter: [0.2285 0.0558 0.2886 0.4963]
L1 regularization loss: 5.41E+00, L2 regularization loss: 2.61E+00
Test scatter: [0.2262 0.0545 0.2866 0.4863], Lowest was [0.1979 0.052  0.2866 0.4765]
Median for last 10 epochs: [0.2221 0.0541 0.2921 0.4842], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 40%|████      | 200/500 [3:45:43<5:54:57, 70.99s/it] 40%|████      | 201/500 [3:46:36<5:26:31, 65.52s/it] 40%|████      | 202/500 [3:47:56<5:46:52, 69.84s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -3.22E+05, Train scatter: [0.1931 0.0506 0.2878 0.4841]
L1 regularization loss: 5.44E+00, L2 regularization loss: 2.65E+00
Test scatter: [0.1953 0.0505 0.2868 0.4769], Lowest was [0.1953 0.0505 0.2866 0.4765]
Median for last 10 epochs: [0.2076 0.0525 0.2883 0.4771], Epochs since improvement 0
 41%|████      | 203/500 [3:48:49<5:20:37, 64.77s/it] 41%|████      | 204/500 [3:50:09<5:42:19, 69.39s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -3.19E+05, Train scatter: [0.1859 0.0504 0.2789 0.48  ]
L1 regularization loss: 5.43E+00, L2 regularization loss: 2.67E+00
Test scatter: [0.1877 0.0496 0.2758 0.4713], Lowest was [0.1877 0.0496 0.2758 0.4713]
Median for last 10 epochs: [0.1979 0.0525 0.2868 0.4769], Epochs since improvement 0
 41%|████      | 205/500 [3:51:01<5:16:21, 64.34s/it] 41%|████      | 206/500 [3:52:21<5:38:27, 69.07s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -3.30E+05, Train scatter: [0.2085 0.0475 0.2611 0.4792]
L1 regularization loss: 5.44E+00, L2 regularization loss: 2.69E+00
Test scatter: [0.2103 0.0471 0.2599 0.4724], Lowest was [0.1877 0.0471 0.2599 0.4713]
Median for last 10 epochs: [0.1979 0.0505 0.2866 0.4765], Epochs since improvement 0
 41%|████▏     | 207/500 [3:53:14<5:13:14, 64.14s/it] 42%|████▏     | 208/500 [3:54:34<5:35:10, 68.87s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -3.24E+05, Train scatter: [0.192  0.0569 0.2654 0.4891]
L1 regularization loss: 5.45E+00, L2 regularization loss: 2.71E+00
Test scatter: [0.196  0.0561 0.2644 0.4816], Lowest was [0.1877 0.0471 0.2599 0.4713]
Median for last 10 epochs: [0.196  0.0505 0.2758 0.4769], Epochs since improvement 2
 42%|████▏     | 209/500 [3:55:27<5:10:12, 63.96s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -3.34E+05, Train scatter: [0.2018 0.0474 0.2509 0.4797]
L1 regularization loss: 5.45E+00, L2 regularization loss: 2.72E+00
Test scatter: [0.2034 0.0472 0.2517 0.4737], Lowest was [0.1877 0.0471 0.2517 0.4713]
Median for last 10 epochs: [0.196  0.0496 0.2644 0.4737], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 42%|████▏     | 210/500 [3:56:53<5:42:01, 70.76s/it] 42%|████▏     | 211/500 [3:57:46<5:14:33, 65.31s/it] 42%|████▏     | 212/500 [3:59:06<5:34:36, 69.71s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -3.36E+05, Train scatter: [0.1962 0.0491 0.2793 0.4763]
L1 regularization loss: 5.44E+00, L2 regularization loss: 2.73E+00
Test scatter: [0.2009 0.0486 0.2779 0.4703], Lowest was [0.1877 0.0471 0.2517 0.4703]
Median for last 10 epochs: [0.2009 0.0486 0.2644 0.4724], Epochs since improvement 0
 43%|████▎     | 213/500 [3:59:58<5:09:04, 64.61s/it] 43%|████▎     | 214/500 [4:01:19<5:31:08, 69.47s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: -3.35E+05, Train scatter: [0.1975 0.0493 0.2641 0.4869]
L1 regularization loss: 5.45E+00, L2 regularization loss: 2.75E+00
Test scatter: [0.1978 0.0491 0.2633 0.4808], Lowest was [0.1877 0.0471 0.2517 0.4703]
Median for last 10 epochs: [0.2009 0.0486 0.2633 0.4737], Epochs since improvement 2
 43%|████▎     | 215/500 [4:02:12<5:06:20, 64.49s/it] 43%|████▎     | 216/500 [4:03:33<5:29:12, 69.55s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -3.41E+05, Train scatter: [0.1907 0.0482 0.2566 0.4767]
L1 regularization loss: 5.44E+00, L2 regularization loss: 2.76E+00
Test scatter: [0.1944 0.0477 0.2558 0.4695], Lowest was [0.1877 0.0471 0.2517 0.4695]
Median for last 10 epochs: [0.1978 0.0486 0.2633 0.4737], Epochs since improvement 0
 43%|████▎     | 217/500 [4:04:26<5:04:08, 64.48s/it] 44%|████▎     | 218/500 [4:05:47<5:26:36, 69.49s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -3.35E+05, Train scatter: [0.1798 0.0515 0.2751 0.4867]
L1 regularization loss: 5.46E+00, L2 regularization loss: 2.78E+00
Test scatter: [0.1829 0.0512 0.2758 0.481 ], Lowest was [0.1829 0.0471 0.2517 0.4695]
Median for last 10 epochs: [0.1978 0.0486 0.2633 0.4737], Epochs since improvement 0
 44%|████▍     | 219/500 [4:06:40<5:01:49, 64.45s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -3.32E+05, Train scatter: [0.1834 0.0472 0.251  0.4761]
L1 regularization loss: 5.47E+00, L2 regularization loss: 2.80E+00
Test scatter: [0.1861 0.0467 0.2513 0.4692], Lowest was [0.1829 0.0467 0.2513 0.4692]
Median for last 10 epochs: [0.1944 0.0486 0.2633 0.4703], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 44%|████▍     | 220/500 [4:08:08<5:33:26, 71.45s/it] 44%|████▍     | 221/500 [4:09:01<5:06:17, 65.87s/it] 44%|████▍     | 222/500 [4:10:20<5:24:19, 70.00s/it]Epoch: 222 done with learning rate 7.33E-03, Train loss: -3.47E+05, Train scatter: [0.1775 0.0467 0.2486 0.4745]
L1 regularization loss: 5.46E+00, L2 regularization loss: 2.81E+00
Test scatter: [0.1796 0.0462 0.2476 0.4692], Lowest was [0.1796 0.0462 0.2476 0.4692]
Median for last 10 epochs: [0.1861 0.0477 0.2558 0.4695], Epochs since improvement 0
 45%|████▍     | 223/500 [4:11:13<4:59:32, 64.88s/it] 45%|████▍     | 224/500 [4:12:34<5:20:07, 69.59s/it]Epoch: 224 done with learning rate 7.26E-03, Train loss: -3.40E+05, Train scatter: [0.188  0.0466 0.2447 0.4793]
L1 regularization loss: 5.49E+00, L2 regularization loss: 2.83E+00
Test scatter: [0.1918 0.0465 0.2472 0.4748], Lowest was [0.1796 0.0462 0.2472 0.4692]
Median for last 10 epochs: [0.1861 0.0467 0.2513 0.4695], Epochs since improvement 0
 45%|████▌     | 225/500 [4:13:27<4:55:49, 64.55s/it] 45%|████▌     | 226/500 [4:14:47<5:16:51, 69.38s/it]Epoch: 226 done with learning rate 7.20E-03, Train loss: -3.48E+05, Train scatter: [0.1617 0.0454 0.2395 0.469 ]
L1 regularization loss: 5.49E+00, L2 regularization loss: 2.84E+00
Test scatter: [0.163  0.0453 0.2409 0.4629], Lowest was [0.163  0.0453 0.2409 0.4629]
Median for last 10 epochs: [0.1829 0.0465 0.2476 0.4692], Epochs since improvement 0
 45%|████▌     | 227/500 [4:15:40<4:53:10, 64.43s/it] 46%|████▌     | 228/500 [4:17:01<5:13:56, 69.25s/it]Epoch: 228 done with learning rate 7.13E-03, Train loss: -3.47E+05, Train scatter: [0.1737 0.0531 0.2798 0.4892]
L1 regularization loss: 5.49E+00, L2 regularization loss: 2.86E+00
Test scatter: [0.179  0.0528 0.2812 0.4862], Lowest was [0.163  0.0453 0.2409 0.4629]
Median for last 10 epochs: [0.1796 0.0465 0.2476 0.4692], Epochs since improvement 2
 46%|████▌     | 229/500 [4:17:53<4:50:32, 64.33s/it]Epoch: 230 done with learning rate 7.06E-03, Train loss: -3.45E+05, Train scatter: [0.1654 0.0465 0.2583 0.4718]
L1 regularization loss: 5.51E+00, L2 regularization loss: 2.88E+00
Test scatter: [0.1696 0.0464 0.2596 0.4672], Lowest was [0.163  0.0453 0.2409 0.4629]
Median for last 10 epochs: [0.179  0.0464 0.2476 0.4692], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 46%|████▌     | 230/500 [4:19:20<5:19:51, 71.08s/it] 46%|████▌     | 231/500 [4:20:13<4:53:53, 65.55s/it] 46%|████▋     | 232/500 [4:21:33<5:12:48, 70.03s/it]Epoch: 232 done with learning rate 6.99E-03, Train loss: -3.53E+05, Train scatter: [0.1859 0.0491 0.2597 0.4752]
L1 regularization loss: 5.51E+00, L2 regularization loss: 2.90E+00
Test scatter: [0.1849 0.0484 0.2616 0.4711], Lowest was [0.163  0.0453 0.2409 0.4629]
Median for last 10 epochs: [0.179  0.0465 0.2596 0.4711], Epochs since improvement 6
 47%|████▋     | 233/500 [4:22:26<4:48:25, 64.82s/it] 47%|████▋     | 234/500 [4:23:46<5:07:45, 69.42s/it]Epoch: 234 done with learning rate 6.93E-03, Train loss: -3.50E+05, Train scatter: [0.1561 0.0447 0.2414 0.4628]
L1 regularization loss: 5.53E+00, L2 regularization loss: 2.93E+00
Test scatter: [0.1568 0.0443 0.2434 0.4567], Lowest was [0.1568 0.0443 0.2409 0.4567]
Median for last 10 epochs: [0.1696 0.0464 0.2596 0.4672], Epochs since improvement 0
 47%|████▋     | 235/500 [4:24:39<4:44:27, 64.41s/it] 47%|████▋     | 236/500 [4:25:59<5:04:20, 69.17s/it]Epoch: 236 done with learning rate 6.86E-03, Train loss: -3.56E+05, Train scatter: [0.1619 0.0447 0.2434 0.4641]
L1 regularization loss: 5.54E+00, L2 regularization loss: 2.96E+00
Test scatter: [0.1687 0.0448 0.2451 0.4594], Lowest was [0.1568 0.0443 0.2409 0.4567]
Median for last 10 epochs: [0.1696 0.0464 0.2596 0.4672], Epochs since improvement 2
 47%|████▋     | 237/500 [4:26:52<4:41:34, 64.24s/it] 48%|████▊     | 238/500 [4:28:12<5:00:43, 68.87s/it]Epoch: 238 done with learning rate 6.79E-03, Train loss: -3.59E+05, Train scatter: [0.1785 0.0861 0.3138 0.497 ]
L1 regularization loss: 5.55E+00, L2 regularization loss: 3.00E+00
Test scatter: [0.1784 0.0828 0.3093 0.4849], Lowest was [0.1568 0.0443 0.2409 0.4567]
Median for last 10 epochs: [0.1696 0.0464 0.2596 0.4672], Epochs since improvement 4
 48%|████▊     | 239/500 [4:29:04<4:38:41, 64.07s/it]Epoch: 240 done with learning rate 6.72E-03, Train loss: -3.32E+05, Train scatter: [0.168  0.0487 0.2562 0.465 ]
L1 regularization loss: 5.81E+00, L2 regularization loss: 3.14E+00
Test scatter: [0.1745 0.0483 0.2586 0.4599], Lowest was [0.1568 0.0443 0.2409 0.4567]
Median for last 10 epochs: [0.1745 0.0483 0.2586 0.4599], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 48%|████▊     | 240/500 [4:30:31<5:07:13, 70.90s/it] 48%|████▊     | 241/500 [4:31:24<4:42:26, 65.43s/it] 48%|████▊     | 242/500 [4:32:44<4:59:36, 69.68s/it]Epoch: 242 done with learning rate 6.65E-03, Train loss: -3.53E+05, Train scatter: [0.1537 0.048  0.2735 0.4676]
L1 regularization loss: 5.80E+00, L2 regularization loss: 3.15E+00
Test scatter: [0.1559 0.0468 0.2701 0.4564], Lowest was [0.1559 0.0443 0.2409 0.4564]
Median for last 10 epochs: [0.1687 0.0468 0.2586 0.4594], Epochs since improvement 0
 49%|████▊     | 243/500 [4:33:36<4:36:40, 64.59s/it] 49%|████▉     | 244/500 [4:34:56<4:54:46, 69.09s/it]Epoch: 244 done with learning rate 6.58E-03, Train loss: -3.64E+05, Train scatter: [0.1521 0.0438 0.2361 0.4554]
L1 regularization loss: 5.79E+00, L2 regularization loss: 3.18E+00
Test scatter: [0.1538 0.0433 0.2368 0.4472], Lowest was [0.1538 0.0433 0.2368 0.4472]
Median for last 10 epochs: [0.1687 0.0468 0.2586 0.4594], Epochs since improvement 0
 49%|████▉     | 245/500 [4:35:49<4:32:45, 64.18s/it] 49%|████▉     | 246/500 [4:37:09<4:51:38, 68.89s/it]Epoch: 246 done with learning rate 6.51E-03, Train loss: -3.64E+05, Train scatter: [0.1804 0.0554 0.2709 0.4759]
L1 regularization loss: 5.79E+00, L2 regularization loss: 3.20E+00
Test scatter: [0.1821 0.0542 0.2734 0.4706], Lowest was [0.1538 0.0433 0.2368 0.4472]
Median for last 10 epochs: [0.1745 0.0483 0.2701 0.4599], Epochs since improvement 2
 49%|████▉     | 247/500 [4:38:01<4:29:58, 64.03s/it] 50%|████▉     | 248/500 [4:39:21<4:48:29, 68.69s/it]Epoch: 248 done with learning rate 6.44E-03, Train loss: -3.52E+05, Train scatter: [0.1541 0.0468 0.2424 0.4569]
L1 regularization loss: 5.80E+00, L2 regularization loss: 3.22E+00
Test scatter: [0.1546 0.0464 0.2439 0.4508], Lowest was [0.1538 0.0433 0.2368 0.4472]
Median for last 10 epochs: [0.1559 0.0468 0.2586 0.4564], Epochs since improvement 4
 50%|████▉     | 249/500 [4:40:13<4:27:12, 63.88s/it]Epoch: 250 done with learning rate 6.37E-03, Train loss: -3.66E+05, Train scatter: [0.1562 0.0491 0.2612 0.4554]
L1 regularization loss: 5.80E+00, L2 regularization loss: 3.24E+00
Test scatter: [0.1545 0.0484 0.2659 0.4501], Lowest was [0.1538 0.0433 0.2368 0.4472]
Median for last 10 epochs: [0.1546 0.0468 0.2659 0.4508], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 50%|█████     | 250/500 [4:41:41<4:55:44, 70.98s/it] 50%|█████     | 251/500 [4:42:34<4:31:52, 65.51s/it] 50%|█████     | 252/500 [4:43:55<4:50:07, 70.19s/it]Epoch: 252 done with learning rate 6.30E-03, Train loss: -3.65E+05, Train scatter: [0.1589 0.0607 0.2629 0.4527]
L1 regularization loss: 5.82E+00, L2 regularization loss: 3.26E+00
Test scatter: [0.1595 0.0599 0.2614 0.4426], Lowest was [0.1538 0.0433 0.2368 0.4426]
Median for last 10 epochs: [0.1546 0.0484 0.2614 0.4501], Epochs since improvement 0
 51%|█████     | 253/500 [4:44:47<4:27:13, 64.91s/it] 51%|█████     | 254/500 [4:46:07<4:44:41, 69.44s/it]Epoch: 254 done with learning rate 6.23E-03, Train loss: -3.71E+05, Train scatter: [0.14   0.0433 0.2373 0.4456]
L1 regularization loss: 5.82E+00, L2 regularization loss: 3.28E+00
Test scatter: [0.1394 0.043  0.2404 0.4387], Lowest was [0.1394 0.043  0.2368 0.4387]
Median for last 10 epochs: [0.1546 0.0484 0.2614 0.4501], Epochs since improvement 0
 51%|█████     | 255/500 [4:47:00<4:23:06, 64.43s/it] 51%|█████     | 256/500 [4:48:20<4:40:25, 68.96s/it]Epoch: 256 done with learning rate 6.15E-03, Train loss: -3.65E+05, Train scatter: [0.1621 0.048  0.241  0.4429]
L1 regularization loss: 5.84E+00, L2 regularization loss: 3.30E+00
Test scatter: [0.1617 0.0469 0.2418 0.434 ], Lowest was [0.1394 0.043  0.2368 0.434 ]
Median for last 10 epochs: [0.1546 0.0469 0.2439 0.4426], Epochs since improvement 0
 51%|█████▏    | 257/500 [4:49:12<4:19:36, 64.10s/it] 52%|█████▏    | 258/500 [4:50:32<4:37:14, 68.74s/it]Epoch: 258 done with learning rate 6.08E-03, Train loss: -3.76E+05, Train scatter: [0.157  0.0553 0.2766 0.4819]
L1 regularization loss: 5.85E+00, L2 regularization loss: 3.32E+00
Test scatter: [0.1527 0.0537 0.2761 0.4658], Lowest was [0.1394 0.043  0.2368 0.434 ]
Median for last 10 epochs: [0.1545 0.0484 0.2614 0.4426], Epochs since improvement 2
 52%|█████▏    | 259/500 [4:51:25<4:16:34, 63.88s/it]Epoch: 260 done with learning rate 6.01E-03, Train loss: -3.79E+05, Train scatter: [0.1394 0.0503 0.2487 0.4436]
L1 regularization loss: 5.87E+00, L2 regularization loss: 3.35E+00
Test scatter: [0.137  0.0491 0.2478 0.4329], Lowest was [0.137  0.043  0.2368 0.4329]
Median for last 10 epochs: [0.1527 0.0491 0.2478 0.4387], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 52%|█████▏    | 260/500 [4:52:52<4:43:33, 70.89s/it] 52%|█████▏    | 261/500 [4:53:44<4:20:37, 65.43s/it] 52%|█████▏    | 262/500 [4:55:06<4:38:11, 70.13s/it]Epoch: 262 done with learning rate 5.94E-03, Train loss: -3.73E+05, Train scatter: [0.1779 0.0535 0.2407 0.4422]
L1 regularization loss: 5.96E+00, L2 regularization loss: 3.41E+00
Test scatter: [0.1802 0.0525 0.2401 0.4333], Lowest was [0.137  0.043  0.2368 0.4329]
Median for last 10 epochs: [0.1527 0.0491 0.2418 0.434 ], Epochs since improvement 2
 53%|█████▎    | 263/500 [4:55:58<4:16:15, 64.87s/it] 53%|█████▎    | 264/500 [4:57:19<4:34:31, 69.79s/it]Epoch: 264 done with learning rate 5.86E-03, Train loss: -3.64E+05, Train scatter: [0.1504 0.0461 0.2424 0.4501]
L1 regularization loss: 5.99E+00, L2 regularization loss: 3.44E+00
Test scatter: [0.1504 0.0458 0.2456 0.4452], Lowest was [0.137  0.043  0.2368 0.4329]
Median for last 10 epochs: [0.1527 0.0491 0.2456 0.434 ], Epochs since improvement 4
 53%|█████▎    | 265/500 [4:58:12<4:13:12, 64.65s/it] 53%|█████▎    | 266/500 [4:59:33<4:30:48, 69.44s/it]Epoch: 266 done with learning rate 5.79E-03, Train loss: -3.77E+05, Train scatter: [0.1614 0.0644 0.342  0.4857]
L1 regularization loss: 5.98E+00, L2 regularization loss: 3.45E+00
Test scatter: [0.1599 0.0648 0.3416 0.4852], Lowest was [0.137  0.043  0.2368 0.4329]
Median for last 10 epochs: [0.1527 0.0525 0.2478 0.4452], Epochs since improvement 6
 53%|█████▎    | 267/500 [5:00:25<4:09:58, 64.37s/it] 54%|█████▎    | 268/500 [5:01:45<4:26:46, 68.99s/it]Epoch: 268 done with learning rate 5.72E-03, Train loss: -3.84E+05, Train scatter: [0.1357 0.0461 0.2473 0.4488]
L1 regularization loss: 6.10E+00, L2 regularization loss: 3.53E+00
Test scatter: [0.1341 0.0456 0.2463 0.4381], Lowest was [0.1341 0.043  0.2368 0.4329]
Median for last 10 epochs: [0.1504 0.0491 0.2463 0.4381], Epochs since improvement 0
 54%|█████▍    | 269/500 [5:02:38<4:06:43, 64.08s/it]Epoch: 270 done with learning rate 5.64E-03, Train loss: -3.87E+05, Train scatter: [0.1477 0.0503 0.2603 0.4533]
L1 regularization loss: 6.10E+00, L2 regularization loss: 3.56E+00
Test scatter: [0.1455 0.05   0.2609 0.4461], Lowest was [0.1341 0.043  0.2368 0.4329]
Median for last 10 epochs: [0.1504 0.05   0.2463 0.4452], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 54%|█████▍    | 270/500 [5:04:05<4:32:28, 71.08s/it] 54%|█████▍    | 271/500 [5:04:58<4:10:25, 65.61s/it] 54%|█████▍    | 272/500 [5:06:18<4:25:59, 70.00s/it]Epoch: 272 done with learning rate 5.57E-03, Train loss: -3.76E+05, Train scatter: [0.1328 0.0445 0.2325 0.4446]
L1 regularization loss: 6.13E+00, L2 regularization loss: 3.59E+00
Test scatter: [0.1314 0.0436 0.2325 0.4306], Lowest was [0.1314 0.043  0.2325 0.4306]
Median for last 10 epochs: [0.1455 0.0458 0.2463 0.4452], Epochs since improvement 0
 55%|█████▍    | 273/500 [5:07:11<4:05:09, 64.80s/it] 55%|█████▍    | 274/500 [5:08:31<4:21:50, 69.51s/it]Epoch: 274 done with learning rate 5.50E-03, Train loss: -3.99E+05, Train scatter: [0.1424 0.0452 0.2333 0.4395]
L1 regularization loss: 6.13E+00, L2 regularization loss: 3.60E+00
Test scatter: [0.142  0.0445 0.2332 0.4273], Lowest was [0.1314 0.043  0.2325 0.4273]
Median for last 10 epochs: [0.142  0.0456 0.2463 0.4381], Epochs since improvement 0
 55%|█████▌    | 275/500 [5:09:24<4:01:39, 64.44s/it] 55%|█████▌    | 276/500 [5:10:44<4:18:33, 69.26s/it]Epoch: 276 done with learning rate 5.42E-03, Train loss: -1.98E+05, Train scatter: [0.3746 0.0724 0.3362 0.5956]
L1 regularization loss: 6.52E+00, L2 regularization loss: 3.85E+00
Test scatter: [0.3685 0.0709 0.3309 0.5867], Lowest was [0.1314 0.043  0.2325 0.4273]
Median for last 10 epochs: [0.142  0.0456 0.2463 0.4381], Epochs since improvement 2
 55%|█████▌    | 277/500 [5:11:37<3:58:51, 64.27s/it] 56%|█████▌    | 278/500 [5:12:58<4:15:50, 69.15s/it]Epoch: 278 done with learning rate 5.35E-03, Train loss: -2.88E+05, Train scatter: [0.225  0.0546 0.2681 0.5041]
L1 regularization loss: 6.56E+00, L2 regularization loss: 3.92E+00
Test scatter: [0.2236 0.0542 0.266  0.497 ], Lowest was [0.1314 0.043  0.2325 0.4273]
Median for last 10 epochs: [0.1455 0.05   0.2609 0.4461], Epochs since improvement 4
 56%|█████▌    | 279/500 [5:13:50<3:56:27, 64.20s/it]Epoch: 280 done with learning rate 5.28E-03, Train loss: -3.41E+05, Train scatter: [0.166  0.0549 0.264  0.48  ]
L1 regularization loss: 6.56E+00, L2 regularization loss: 3.94E+00
Test scatter: [0.1597 0.0531 0.2641 0.4708], Lowest was [0.1314 0.043  0.2325 0.4273]
Median for last 10 epochs: [0.1597 0.0531 0.2641 0.4708], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 56%|█████▌    | 280/500 [5:15:18<4:20:47, 71.12s/it] 56%|█████▌    | 281/500 [5:16:10<3:59:31, 65.62s/it] 56%|█████▋    | 282/500 [5:17:31<4:15:08, 70.22s/it]Epoch: 282 done with learning rate 5.20E-03, Train loss: -3.45E+05, Train scatter: [0.2115 0.0507 0.27   0.4857]
L1 regularization loss: 6.56E+00, L2 regularization loss: 3.94E+00
Test scatter: [0.2017 0.0505 0.2716 0.4777], Lowest was [0.1314 0.043  0.2325 0.4273]
Median for last 10 epochs: [0.2017 0.0531 0.266  0.4777], Epochs since improvement 8
 57%|█████▋    | 283/500 [5:18:24<3:54:52, 64.94s/it] 57%|█████▋    | 284/500 [5:19:44<4:10:27, 69.57s/it]Epoch: 284 done with learning rate 5.13E-03, Train loss: -3.69E+05, Train scatter: [0.1584 0.0478 0.2529 0.4627]
L1 regularization loss: 6.57E+00, L2 regularization loss: 3.96E+00
Test scatter: [0.1505 0.0469 0.2544 0.4514], Lowest was [0.1314 0.043  0.2325 0.4273]
Median for last 10 epochs: [0.2017 0.0531 0.266  0.4777], Epochs since improvement 10
 57%|█████▋    | 285/500 [5:20:37<3:51:03, 64.48s/it] 57%|█████▋    | 286/500 [5:21:58<4:07:29, 69.39s/it]Epoch: 286 done with learning rate 5.06E-03, Train loss: -3.76E+05, Train scatter: [0.1747 0.0524 0.2703 0.5244]
L1 regularization loss: 6.57E+00, L2 regularization loss: 3.96E+00
Test scatter: [0.166  0.0513 0.2675 0.485 ], Lowest was [0.1314 0.043  0.2325 0.4273]
Median for last 10 epochs: [0.166  0.0513 0.266  0.4777], Epochs since improvement 12
 57%|█████▋    | 287/500 [5:22:50<3:48:30, 64.37s/it] 58%|█████▊    | 288/500 [5:24:11<4:05:02, 69.35s/it]Epoch: 288 done with learning rate 4.98E-03, Train loss: -3.69E+05, Train scatter: [0.1722 0.0477 0.2835 0.4596]
L1 regularization loss: 6.62E+00, L2 regularization loss: 4.02E+00
Test scatter: [0.1638 0.0475 0.2835 0.4511], Lowest was [0.1314 0.043  0.2325 0.4273]
Median for last 10 epochs: [0.1638 0.0505 0.2675 0.4708], Epochs since improvement 14
 58%|█████▊    | 289/500 [5:25:04<3:46:18, 64.35s/it]Epoch: 290 done with learning rate 4.91E-03, Train loss: -3.90E+05, Train scatter: [0.1537 0.0478 0.2582 0.4508]
L1 regularization loss: 6.62E+00, L2 regularization loss: 4.03E+00
Test scatter: [0.1533 0.0482 0.2577 0.4389], Lowest was [0.1314 0.043  0.2325 0.4273]
Median for last 10 epochs: [0.1638 0.0482 0.2675 0.4514], Epochs since improvement 16
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 58%|█████▊    | 290/500 [5:26:32<4:09:36, 71.32s/it] 58%|█████▊    | 291/500 [5:27:24<3:48:56, 65.73s/it] 58%|█████▊    | 292/500 [5:28:44<4:02:05, 69.84s/it]Epoch: 292 done with learning rate 4.83E-03, Train loss: -3.89E+05, Train scatter: [0.1767 0.0537 0.2439 0.4613]
L1 regularization loss: 6.64E+00, L2 regularization loss: 4.05E+00
Test scatter: [0.1655 0.0519 0.244  0.4478], Lowest was [0.1314 0.043  0.2325 0.4273]
Median for last 10 epochs: [0.1638 0.0482 0.2577 0.4511], Epochs since improvement 18
 59%|█████▊    | 293/500 [5:29:36<3:43:05, 64.67s/it] 59%|█████▉    | 294/500 [5:30:57<3:58:35, 69.49s/it]Epoch: 294 done with learning rate 4.76E-03, Train loss: -3.96E+05, Train scatter: [0.1918 0.0554 0.2605 0.4891]
L1 regularization loss: 6.64E+00, L2 regularization loss: 4.05E+00
Test scatter: [0.1921 0.055  0.2603 0.4844], Lowest was [0.1314 0.043  0.2325 0.4273]
Median for last 10 epochs: [0.1655 0.0513 0.2603 0.4511], Epochs since improvement 20
 59%|█████▉    | 295/500 [5:31:50<3:40:08, 64.43s/it] 59%|█████▉    | 296/500 [5:33:12<3:56:48, 69.65s/it]Epoch: 296 done with learning rate 4.69E-03, Train loss: -4.10E+05, Train scatter: [0.1668 0.0432 0.2348 0.4456]
L1 regularization loss: 6.64E+00, L2 regularization loss: 4.07E+00
Test scatter: [0.166  0.0425 0.2349 0.4309], Lowest was [0.1314 0.0425 0.2325 0.4273]
Median for last 10 epochs: [0.1655 0.0482 0.2577 0.4478], Epochs since improvement 0
 59%|█████▉    | 297/500 [5:34:04<3:38:21, 64.54s/it] 60%|█████▉    | 298/500 [5:35:24<3:52:54, 69.18s/it]Epoch: 298 done with learning rate 4.61E-03, Train loss: -4.12E+05, Train scatter: [0.1353 0.0416 0.234  0.4469]
L1 regularization loss: 6.65E+00, L2 regularization loss: 4.08E+00
Test scatter: [0.1322 0.041  0.2351 0.4371], Lowest was [0.1314 0.041  0.2325 0.4273]
Median for last 10 epochs: [0.1655 0.0482 0.244  0.4389], Epochs since improvement 0
 60%|█████▉    | 299/500 [5:36:17<3:35:11, 64.24s/it]Epoch: 300 done with learning rate 4.54E-03, Train loss: -4.20E+05, Train scatter: [0.1476 0.0442 0.2275 0.4443]
L1 regularization loss: 6.65E+00, L2 regularization loss: 4.09E+00
Test scatter: [0.1414 0.0435 0.2286 0.4306], Lowest was [0.1314 0.041  0.2286 0.4273]
Median for last 10 epochs: [0.1655 0.0435 0.2351 0.4371], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 60%|██████    | 300/500 [5:37:47<4:00:13, 72.07s/it] 60%|██████    | 301/500 [5:38:40<3:39:53, 66.30s/it] 60%|██████    | 302/500 [5:40:00<3:52:40, 70.51s/it]Epoch: 302 done with learning rate 4.47E-03, Train loss: -4.22E+05, Train scatter: [0.1374 0.0435 0.2259 0.4405]
L1 regularization loss: 6.68E+00, L2 regularization loss: 4.11E+00
Test scatter: [0.1343 0.0428 0.2296 0.4302], Lowest was [0.1314 0.041  0.2286 0.4273]
Median for last 10 epochs: [0.1414 0.0428 0.2349 0.4309], Epochs since improvement 2
 61%|██████    | 303/500 [5:40:53<3:33:55, 65.15s/it] 61%|██████    | 304/500 [5:42:13<3:47:05, 69.52s/it]Epoch: 304 done with learning rate 4.39E-03, Train loss: -4.28E+05, Train scatter: [0.1347 0.0422 0.235  0.4557]
L1 regularization loss: 6.69E+00, L2 regularization loss: 4.13E+00
Test scatter: [0.1317 0.0417 0.2345 0.4446], Lowest was [0.1314 0.041  0.2286 0.4273]
Median for last 10 epochs: [0.1343 0.0425 0.2345 0.4309], Epochs since improvement 4
 61%|██████    | 305/500 [5:43:06<3:29:42, 64.53s/it] 61%|██████    | 306/500 [5:44:26<3:43:50, 69.23s/it]Epoch: 306 done with learning rate 4.32E-03, Train loss: -4.23E+05, Train scatter: [0.1293 0.0452 0.2401 0.4444]
L1 regularization loss: 6.71E+00, L2 regularization loss: 4.14E+00
Test scatter: [0.125  0.0439 0.2389 0.4318], Lowest was [0.125  0.041  0.2286 0.4273]
Median for last 10 epochs: [0.1322 0.0428 0.2345 0.4318], Epochs since improvement 0
 61%|██████▏   | 307/500 [5:45:19<3:26:46, 64.28s/it] 62%|██████▏   | 308/500 [5:46:39<3:41:02, 69.07s/it]Epoch: 308 done with learning rate 4.25E-03, Train loss: -4.33E+05, Train scatter: [0.1269 0.0409 0.2201 0.4323]
L1 regularization loss: 6.71E+00, L2 regularization loss: 4.16E+00
Test scatter: [0.1228 0.0402 0.221  0.4211], Lowest was [0.1228 0.0402 0.221  0.4211]
Median for last 10 epochs: [0.1317 0.0428 0.2296 0.4306], Epochs since improvement 0
 62%|██████▏   | 309/500 [5:47:32<3:24:18, 64.18s/it]Epoch: 310 done with learning rate 4.17E-03, Train loss: -4.26E+05, Train scatter: [0.1447 0.0414 0.2248 0.4312]
L1 regularization loss: 6.72E+00, L2 regularization loss: 4.18E+00
Test scatter: [0.1418 0.0406 0.2263 0.4189], Lowest was [0.1228 0.0402 0.221  0.4189]
Median for last 10 epochs: [0.1317 0.0417 0.2296 0.4302], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 62%|██████▏   | 310/500 [5:48:58<3:44:16, 70.83s/it] 62%|██████▏   | 311/500 [5:49:51<3:25:59, 65.39s/it] 62%|██████▏   | 312/500 [5:51:11<3:38:50, 69.84s/it]Epoch: 312 done with learning rate 4.10E-03, Train loss: -4.40E+05, Train scatter: [0.1347 0.0409 0.2196 0.4276]
L1 regularization loss: 6.74E+00, L2 regularization loss: 4.19E+00
Test scatter: [0.1309 0.0403 0.2216 0.4157], Lowest was [0.1228 0.0402 0.221  0.4157]
Median for last 10 epochs: [0.1309 0.0406 0.2263 0.4211], Epochs since improvement 0
 63%|██████▎   | 313/500 [5:52:04<3:21:40, 64.71s/it] 63%|██████▎   | 314/500 [5:53:23<3:34:19, 69.14s/it]Epoch: 314 done with learning rate 4.03E-03, Train loss: -4.32E+05, Train scatter: [0.1515 0.0414 0.2247 0.4271]
L1 regularization loss: 6.76E+00, L2 regularization loss: 4.21E+00
Test scatter: [0.1462 0.0403 0.2232 0.4143], Lowest was [0.1228 0.0402 0.221  0.4143]
Median for last 10 epochs: [0.1309 0.0403 0.2232 0.4189], Epochs since improvement 0
 63%|██████▎   | 315/500 [5:54:16<3:18:03, 64.24s/it] 63%|██████▎   | 316/500 [5:55:37<3:32:43, 69.37s/it]Epoch: 316 done with learning rate 3.95E-03, Train loss: -4.39E+05, Train scatter: [0.1804 0.0466 0.2472 0.5449]
L1 regularization loss: 6.76E+00, L2 regularization loss: 4.22E+00
Test scatter: [0.1774 0.0458 0.245  0.5317], Lowest was [0.1228 0.0402 0.221  0.4143]
Median for last 10 epochs: [0.1418 0.0403 0.2232 0.4189], Epochs since improvement 2
 63%|██████▎   | 317/500 [5:56:30<3:16:29, 64.42s/it] 64%|██████▎   | 318/500 [5:57:50<3:29:47, 69.16s/it]Epoch: 318 done with learning rate 3.88E-03, Train loss: -4.40E+05, Train scatter: [0.1822 0.0441 0.2413 0.479 ]
L1 regularization loss: 6.78E+00, L2 regularization loss: 4.25E+00
Test scatter: [0.1759 0.0432 0.2387 0.462 ], Lowest was [0.1228 0.0402 0.221  0.4143]
Median for last 10 epochs: [0.1462 0.0406 0.2263 0.4189], Epochs since improvement 4
 64%|██████▍   | 319/500 [5:58:43<3:13:50, 64.26s/it]Epoch: 320 done with learning rate 3.81E-03, Train loss: -4.54E+05, Train scatter: [0.133  0.0471 0.2401 0.4478]
L1 regularization loss: 6.81E+00, L2 regularization loss: 4.26E+00
Test scatter: [0.1316 0.0465 0.2385 0.4345], Lowest was [0.1228 0.0402 0.221  0.4143]
Median for last 10 epochs: [0.1462 0.0432 0.2385 0.4345], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 64%|██████▍   | 320/500 [6:00:10<3:33:17, 71.10s/it] 64%|██████▍   | 321/500 [6:01:03<3:15:46, 65.62s/it] 64%|██████▍   | 322/500 [6:02:23<3:27:22, 69.90s/it]Epoch: 322 done with learning rate 3.74E-03, Train loss: -4.51E+05, Train scatter: [0.1339 0.0404 0.2204 0.4278]
L1 regularization loss: 6.82E+00, L2 regularization loss: 4.28E+00
Test scatter: [0.13   0.0397 0.2204 0.4149], Lowest was [0.1228 0.0397 0.2204 0.4143]
Median for last 10 epochs: [0.1462 0.0432 0.2385 0.4345], Epochs since improvement 0
 65%|██████▍   | 323/500 [6:03:16<3:11:06, 64.78s/it] 65%|██████▍   | 324/500 [6:04:36<3:23:14, 69.29s/it]Epoch: 324 done with learning rate 3.67E-03, Train loss: -4.57E+05, Train scatter: [0.1283 0.0426 0.225  0.4347]
L1 regularization loss: 6.83E+00, L2 regularization loss: 4.29E+00
Test scatter: [0.1259 0.0419 0.2238 0.4221], Lowest was [0.1228 0.0397 0.2204 0.4143]
Median for last 10 epochs: [0.1316 0.0432 0.2385 0.4345], Epochs since improvement 2
 65%|██████▌   | 325/500 [6:05:28<3:07:34, 64.31s/it] 65%|██████▌   | 326/500 [6:06:47<3:19:15, 68.71s/it]Epoch: 326 done with learning rate 3.60E-03, Train loss: -4.48E+05, Train scatter: [0.1554 0.0434 0.2252 0.4285]
L1 regularization loss: 6.86E+00, L2 regularization loss: 4.32E+00
Test scatter: [0.1527 0.0426 0.2266 0.4178], Lowest was [0.1228 0.0397 0.2204 0.4143]
Median for last 10 epochs: [0.1316 0.0426 0.2266 0.4221], Epochs since improvement 4
 65%|██████▌   | 327/500 [6:07:40<3:04:21, 63.94s/it] 66%|██████▌   | 328/500 [6:08:59<3:16:34, 68.57s/it]Epoch: 328 done with learning rate 3.53E-03, Train loss: -4.56E+05, Train scatter: [0.1347 0.041  0.2184 0.4185]
L1 regularization loss: 6.87E+00, L2 regularization loss: 4.33E+00
Test scatter: [0.1306 0.0402 0.2199 0.407 ], Lowest was [0.1228 0.0397 0.2199 0.407 ]
Median for last 10 epochs: [0.1306 0.0419 0.2238 0.4178], Epochs since improvement 0
 66%|██████▌   | 329/500 [6:09:52<3:01:53, 63.82s/it]Epoch: 330 done with learning rate 3.45E-03, Train loss: -4.57E+05, Train scatter: [0.1213 0.0413 0.2218 0.4222]
L1 regularization loss: 6.88E+00, L2 regularization loss: 4.35E+00
Test scatter: [0.1191 0.0406 0.2251 0.4113], Lowest was [0.1191 0.0397 0.2199 0.407 ]
Median for last 10 epochs: [0.13   0.0406 0.2238 0.4149], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 66%|██████▌   | 330/500 [6:11:20<3:20:54, 70.91s/it] 66%|██████▌   | 331/500 [6:12:13<3:04:35, 65.53s/it] 66%|██████▋   | 332/500 [6:13:34<3:16:52, 70.31s/it]Epoch: 332 done with learning rate 3.38E-03, Train loss: -4.53E+05, Train scatter: [0.1299 0.044  0.2273 0.4285]
L1 regularization loss: 6.91E+00, L2 regularization loss: 4.38E+00
Test scatter: [0.1259 0.043  0.2276 0.4156], Lowest was [0.1191 0.0397 0.2199 0.407 ]
Median for last 10 epochs: [0.1259 0.0419 0.2251 0.4156], Epochs since improvement 2
 67%|██████▋   | 333/500 [6:14:27<3:01:14, 65.12s/it] 67%|██████▋   | 334/500 [6:15:48<3:13:15, 69.85s/it]Epoch: 334 done with learning rate 3.32E-03, Train loss: -4.66E+05, Train scatter: [0.1328 0.0402 0.2166 0.4141]
L1 regularization loss: 6.91E+00, L2 regularization loss: 4.39E+00
Test scatter: [0.1295 0.0396 0.2183 0.4022], Lowest was [0.1191 0.0396 0.2183 0.4022]
Median for last 10 epochs: [0.1295 0.0406 0.2251 0.4113], Epochs since improvement 0
 67%|██████▋   | 335/500 [6:16:41<2:58:02, 64.75s/it] 67%|██████▋   | 336/500 [6:18:02<3:10:17, 69.62s/it]Epoch: 336 done with learning rate 3.25E-03, Train loss: -4.67E+05, Train scatter: [0.1213 0.0392 0.2181 0.4169]
L1 regularization loss: 6.95E+00, L2 regularization loss: 4.41E+00
Test scatter: [0.1173 0.0389 0.2198 0.4048], Lowest was [0.1173 0.0389 0.2183 0.4022]
Median for last 10 epochs: [0.1259 0.0402 0.2199 0.407 ], Epochs since improvement 0
 67%|██████▋   | 337/500 [6:18:55<2:55:24, 64.57s/it] 68%|██████▊   | 338/500 [6:20:14<3:06:46, 69.18s/it]Epoch: 338 done with learning rate 3.18E-03, Train loss: -4.73E+05, Train scatter: [0.1281 0.0401 0.2131 0.4128]
L1 regularization loss: 6.95E+00, L2 regularization loss: 4.42E+00
Test scatter: [0.1249 0.0394 0.2152 0.3998], Lowest was [0.1173 0.0389 0.2152 0.3998]
Median for last 10 epochs: [0.1249 0.0396 0.2198 0.4048], Epochs since improvement 0
 68%|██████▊   | 339/500 [6:21:07<2:52:21, 64.24s/it]Epoch: 340 done with learning rate 3.11E-03, Train loss: -4.63E+05, Train scatter: [0.208  0.0481 0.222  0.4281]
L1 regularization loss: 6.95E+00, L2 regularization loss: 4.43E+00
Test scatter: [0.1996 0.047  0.2243 0.4156], Lowest was [0.1173 0.0389 0.2152 0.3998]
Median for last 10 epochs: [0.1259 0.0396 0.2198 0.4048], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 68%|██████▊   | 340/500 [6:22:35<3:10:27, 71.42s/it] 68%|██████▊   | 341/500 [6:23:28<2:54:39, 65.91s/it] 68%|██████▊   | 342/500 [6:24:48<3:04:32, 70.08s/it]Epoch: 342 done with learning rate 3.04E-03, Train loss: -4.74E+05, Train scatter: [0.1153 0.0395 0.2115 0.422 ]
L1 regularization loss: 6.97E+00, L2 regularization loss: 4.45E+00
Test scatter: [0.1135 0.0391 0.2135 0.4109], Lowest was [0.1135 0.0389 0.2135 0.3998]
Median for last 10 epochs: [0.1249 0.0394 0.2183 0.4048], Epochs since improvement 0
 69%|██████▊   | 343/500 [6:25:41<2:49:43, 64.86s/it] 69%|██████▉   | 344/500 [6:27:01<3:00:24, 69.39s/it]Epoch: 344 done with learning rate 2.97E-03, Train loss: -4.79E+05, Train scatter: [0.1191 0.0394 0.2111 0.4209]
L1 regularization loss: 6.98E+00, L2 regularization loss: 4.46E+00
Test scatter: [0.1188 0.0389 0.2134 0.4118], Lowest was [0.1135 0.0389 0.2134 0.3998]
Median for last 10 epochs: [0.1188 0.0391 0.2152 0.4109], Epochs since improvement 0
 69%|██████▉   | 345/500 [6:27:54<2:46:19, 64.39s/it] 69%|██████▉   | 346/500 [6:29:14<2:57:28, 69.15s/it]Epoch: 346 done with learning rate 2.90E-03, Train loss: -4.79E+05, Train scatter: [0.1209 0.0397 0.2184 0.4186]
L1 regularization loss: 7.00E+00, L2 regularization loss: 4.47E+00
Test scatter: [0.1199 0.0392 0.2218 0.4092], Lowest was [0.1135 0.0389 0.2134 0.3998]
Median for last 10 epochs: [0.1199 0.0392 0.2152 0.4109], Epochs since improvement 2
 69%|██████▉   | 347/500 [6:30:07<2:43:44, 64.21s/it] 70%|██████▉   | 348/500 [6:31:27<2:54:42, 68.97s/it]Epoch: 348 done with learning rate 2.84E-03, Train loss: -4.79E+05, Train scatter: [0.1192 0.0422 0.2184 0.4131]
L1 regularization loss: 7.02E+00, L2 regularization loss: 4.49E+00
Test scatter: [0.1191 0.042  0.2229 0.4037], Lowest was [0.1135 0.0389 0.2134 0.3998]
Median for last 10 epochs: [0.1191 0.0392 0.2218 0.4109], Epochs since improvement 4
 70%|██████▉   | 349/500 [6:32:19<2:41:23, 64.13s/it]Epoch: 350 done with learning rate 2.77E-03, Train loss: -4.73E+05, Train scatter: [0.1173 0.0379 0.2069 0.4015]
L1 regularization loss: 7.04E+00, L2 regularization loss: 4.51E+00
Test scatter: [0.1161 0.0376 0.2095 0.39  ], Lowest was [0.1135 0.0376 0.2095 0.39  ]
Median for last 10 epochs: [0.1188 0.0391 0.2135 0.4092], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 70%|███████   | 350/500 [6:33:47<2:58:06, 71.25s/it] 70%|███████   | 351/500 [6:34:40<2:43:16, 65.75s/it] 70%|███████   | 352/500 [6:36:01<2:53:12, 70.22s/it]Epoch: 352 done with learning rate 2.71E-03, Train loss: -4.86E+05, Train scatter: [0.1293 0.0386 0.2081 0.4021]
L1 regularization loss: 7.06E+00, L2 regularization loss: 4.52E+00
Test scatter: [0.1254 0.0382 0.2112 0.3921], Lowest was [0.1135 0.0376 0.2095 0.39  ]
Median for last 10 epochs: [0.1191 0.0389 0.2134 0.4037], Epochs since improvement 2
 71%|███████   | 353/500 [6:36:54<2:39:16, 65.01s/it] 71%|███████   | 354/500 [6:38:15<2:49:59, 69.86s/it]Epoch: 354 done with learning rate 2.64E-03, Train loss: -4.86E+05, Train scatter: [0.129  0.0404 0.2059 0.3998]
L1 regularization loss: 7.08E+00, L2 regularization loss: 4.54E+00
Test scatter: [0.124  0.0395 0.2085 0.3879], Lowest was [0.1135 0.0376 0.2085 0.3879]
Median for last 10 epochs: [0.1199 0.0392 0.2112 0.3921], Epochs since improvement 0
 71%|███████   | 355/500 [6:39:08<2:36:36, 64.80s/it] 71%|███████   | 356/500 [6:40:28<2:46:22, 69.32s/it]Epoch: 356 done with learning rate 2.58E-03, Train loss: -4.92E+05, Train scatter: [0.1244 0.0405 0.2239 0.4006]
L1 regularization loss: 7.09E+00, L2 regularization loss: 4.55E+00
Test scatter: [0.1238 0.04   0.2253 0.3919], Lowest was [0.1135 0.0376 0.2085 0.3879]
Median for last 10 epochs: [0.1238 0.0395 0.2112 0.3919], Epochs since improvement 2
 71%|███████▏  | 357/500 [6:41:20<2:33:17, 64.32s/it] 72%|███████▏  | 358/500 [6:42:41<2:43:33, 69.11s/it]Epoch: 358 done with learning rate 2.51E-03, Train loss: -4.94E+05, Train scatter: [0.121  0.039  0.2075 0.4061]
L1 regularization loss: 7.11E+00, L2 regularization loss: 4.56E+00
Test scatter: [0.1186 0.0385 0.2104 0.3955], Lowest was [0.1135 0.0376 0.2085 0.3879]
Median for last 10 epochs: [0.1238 0.0385 0.2104 0.3919], Epochs since improvement 4
 72%|███████▏  | 359/500 [6:43:33<2:30:48, 64.17s/it]Epoch: 360 done with learning rate 2.45E-03, Train loss: -4.94E+05, Train scatter: [0.1127 0.0376 0.2073 0.3972]
L1 regularization loss: 7.14E+00, L2 regularization loss: 4.58E+00
Test scatter: [0.1107 0.0372 0.2104 0.3861], Lowest was [0.1107 0.0372 0.2085 0.3861]
Median for last 10 epochs: [0.1238 0.0385 0.2104 0.3919], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 72%|███████▏  | 360/500 [6:45:01<2:46:08, 71.20s/it] 72%|███████▏  | 361/500 [6:45:54<2:32:06, 65.65s/it] 72%|███████▏  | 362/500 [6:47:14<2:41:13, 70.10s/it]Epoch: 362 done with learning rate 2.38E-03, Train loss: -4.96E+05, Train scatter: [0.1127 0.038  0.2054 0.3956]
L1 regularization loss: 7.16E+00, L2 regularization loss: 4.60E+00
Test scatter: [0.1115 0.0376 0.2085 0.3864], Lowest was [0.1107 0.0372 0.2085 0.3861]
Median for last 10 epochs: [0.1186 0.0385 0.2104 0.3879], Epochs since improvement 2
 73%|███████▎  | 363/500 [6:48:07<2:28:08, 64.88s/it] 73%|███████▎  | 364/500 [6:49:28<2:38:11, 69.79s/it]Epoch: 364 done with learning rate 2.32E-03, Train loss: -5.01E+05, Train scatter: [0.1119 0.0396 0.2131 0.3991]
L1 regularization loss: 7.18E+00, L2 regularization loss: 4.61E+00
Test scatter: [0.1102 0.0388 0.2159 0.3883], Lowest was [0.1102 0.0372 0.2085 0.3861]
Median for last 10 epochs: [0.1115 0.0385 0.2104 0.3883], Epochs since improvement 0
 73%|███████▎  | 365/500 [6:50:21<2:25:30, 64.67s/it] 73%|███████▎  | 366/500 [6:51:41<2:35:10, 69.48s/it]Epoch: 366 done with learning rate 2.26E-03, Train loss: -5.00E+05, Train scatter: [0.1112 0.0377 0.204  0.3932]
L1 regularization loss: 7.21E+00, L2 regularization loss: 4.62E+00
Test scatter: [0.1102 0.0372 0.2072 0.3834], Lowest was [0.1102 0.0372 0.2072 0.3834]
Median for last 10 epochs: [0.1107 0.0376 0.2104 0.3864], Epochs since improvement 0
 73%|███████▎  | 367/500 [6:52:34<2:22:55, 64.48s/it] 74%|███████▎  | 368/500 [6:53:55<2:32:40, 69.40s/it]Epoch: 368 done with learning rate 2.20E-03, Train loss: -5.00E+05, Train scatter: [0.1188 0.0371 0.2045 0.3962]
L1 regularization loss: 7.22E+00, L2 regularization loss: 4.64E+00
Test scatter: [0.1166 0.0366 0.2075 0.3841], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1107 0.0372 0.2085 0.3861], Epochs since improvement 0
 74%|███████▍  | 369/500 [6:54:48<2:20:37, 64.41s/it]Epoch: 370 done with learning rate 2.14E-03, Train loss: -2.40E+05, Train scatter: [0.34   0.0803 0.3454 0.5114]
L1 regularization loss: 7.64E+00, L2 regularization loss: 4.81E+00
Test scatter: [0.3321 0.079  0.3443 0.5072], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1115 0.0376 0.2085 0.3864], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 74%|███████▍  | 370/500 [6:56:15<2:34:11, 71.17s/it] 74%|███████▍  | 371/500 [6:57:08<2:21:12, 65.68s/it] 74%|███████▍  | 372/500 [6:58:29<2:30:03, 70.34s/it]Epoch: 372 done with learning rate 2.08E-03, Train loss: -3.88E+05, Train scatter: [0.1583 0.0584 0.2469 0.4771]
L1 regularization loss: 7.67E+00, L2 regularization loss: 4.84E+00
Test scatter: [0.1525 0.0564 0.2472 0.4553], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1166 0.0388 0.2159 0.3883], Epochs since improvement 4
 75%|███████▍  | 373/500 [6:59:22<2:17:40, 65.05s/it] 75%|███████▍  | 374/500 [7:00:42<2:26:31, 69.78s/it]Epoch: 374 done with learning rate 2.02E-03, Train loss: -4.17E+05, Train scatter: [0.1294 0.0448 0.2317 0.4263]
L1 regularization loss: 7.67E+00, L2 regularization loss: 4.85E+00
Test scatter: [0.1245 0.0436 0.2323 0.4157], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1245 0.0436 0.2323 0.4157], Epochs since improvement 6
 75%|███████▌  | 375/500 [7:01:35<2:14:42, 64.66s/it] 75%|███████▌  | 376/500 [7:02:57<2:23:59, 69.67s/it]Epoch: 376 done with learning rate 1.96E-03, Train loss: -4.25E+05, Train scatter: [0.125  0.0444 0.2203 0.4168]
L1 regularization loss: 7.66E+00, L2 regularization loss: 4.85E+00
Test scatter: [0.1221 0.0436 0.2229 0.4055], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1245 0.0436 0.2323 0.4157], Epochs since improvement 8
 75%|███████▌  | 377/500 [7:03:49<2:12:22, 64.58s/it] 76%|███████▌  | 378/500 [7:05:09<2:20:49, 69.26s/it]Epoch: 378 done with learning rate 1.90E-03, Train loss: -4.41E+05, Train scatter: [0.1282 0.0418 0.2168 0.4093]
L1 regularization loss: 7.66E+00, L2 regularization loss: 4.85E+00
Test scatter: [0.1264 0.0409 0.2187 0.3989], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1264 0.0436 0.2323 0.4157], Epochs since improvement 10
 76%|███████▌  | 379/500 [7:06:02<2:09:45, 64.34s/it]Epoch: 380 done with learning rate 1.84E-03, Train loss: -4.48E+05, Train scatter: [0.1238 0.0426 0.2161 0.409 ]
L1 regularization loss: 7.66E+00, L2 regularization loss: 4.86E+00
Test scatter: [0.1206 0.0418 0.2185 0.3978], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1245 0.0436 0.2229 0.4055], Epochs since improvement 12
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 76%|███████▌  | 380/500 [7:07:30<2:22:58, 71.48s/it] 76%|███████▌  | 381/500 [7:08:23<2:10:32, 65.82s/it] 76%|███████▋  | 382/500 [7:09:43<2:17:57, 70.15s/it]Epoch: 382 done with learning rate 1.78E-03, Train loss: -3.65E+05, Train scatter: [0.7035 0.1521 0.5176 0.8403]
L1 regularization loss: 7.86E+00, L2 regularization loss: 4.92E+00
Test scatter: [0.6917 0.1481 0.5079 0.8312], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1245 0.0436 0.2229 0.4055], Epochs since improvement 14
 77%|███████▋  | 383/500 [7:10:36<2:06:37, 64.94s/it] 77%|███████▋  | 384/500 [7:11:57<2:14:37, 69.63s/it]Epoch: 384 done with learning rate 1.73E-03, Train loss: -2.28E+05, Train scatter: [0.4147 0.0656 0.4103 0.5239]
L1 regularization loss: 8.17E+00, L2 regularization loss: 5.11E+00
Test scatter: [0.4046 0.0652 0.4092 0.5172], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1264 0.0436 0.2229 0.4055], Epochs since improvement 16
 77%|███████▋  | 385/500 [7:12:50<2:03:49, 64.60s/it] 77%|███████▋  | 386/500 [7:14:11<2:12:09, 69.56s/it]Epoch: 386 done with learning rate 1.67E-03, Train loss: -3.17E+05, Train scatter: [0.1724 0.0551 0.3634 0.4812]
L1 regularization loss: 8.18E+00, L2 regularization loss: 5.15E+00
Test scatter: [0.1702 0.0557 0.3636 0.4776], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1702 0.0557 0.3636 0.4776], Epochs since improvement 18
 77%|███████▋  | 387/500 [7:15:04<2:01:36, 64.57s/it] 78%|███████▊  | 388/500 [7:16:25<2:09:41, 69.48s/it]Epoch: 388 done with learning rate 1.62E-03, Train loss: -3.66E+05, Train scatter: [0.1512 0.0504 0.2904 0.4622]
L1 regularization loss: 8.19E+00, L2 regularization loss: 5.17E+00
Test scatter: [0.1485 0.0506 0.2929 0.4554], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1702 0.0557 0.3636 0.4776], Epochs since improvement 20
 78%|███████▊  | 389/500 [7:17:17<1:59:20, 64.51s/it]Epoch: 390 done with learning rate 1.56E-03, Train loss: -3.96E+05, Train scatter: [0.1429 0.0453 0.2597 0.4441]
L1 regularization loss: 8.19E+00, L2 regularization loss: 5.19E+00
Test scatter: [0.1378 0.0449 0.2606 0.4324], Lowest was [0.1102 0.0366 0.2072 0.3834]
Median for last 10 epochs: [0.1702 0.0557 0.3636 0.4776], Epochs since improvement 22
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 78%|███████▊  | 389/500 [7:18:44<2:05:11, 67.67s/it]
Exited after 390 epochs due to early stopping
26324.68 seconds spent training, 52.649 seconds per epoch. Processed 1323 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.13781981 0.04487965 0.26058373 0.4324246 ]
{'epoch_exit': 389, 'scatter_m_star': 0.13781981, 'lowest_m_star': 0.11016382, 'last20_m_star': 0.14315507, 'last10_m_star': 0.17023316, 'scatter_v_disk': 0.04487965, 'lowest_v_disk': 0.036577825, 'last20_v_disk': 0.047748014, 'last10_v_disk': 0.055726968, 'scatter_m_cold': 0.26058373, 'lowest_m_cold': 0.20722821, 'last20_m_cold': 0.2538711, 'last10_m_cold': 0.36359972, 'scatter_sfr_100': 0.4324246, 'lowest_sfr_100': 0.3834309, 'last20_sfr_100': 0.44385958, 'last10_sfr_100': 0.4776164}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
