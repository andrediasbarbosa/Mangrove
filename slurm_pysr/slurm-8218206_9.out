Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_ssvxda
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:32<4:28:42, 32.31s/it]  0%|          | 2/500 [01:20<5:43:30, 41.39s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.26E+07, Train scatter: [0.9352 0.1704 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.31E-01
Test scatter: [0.9196 0.1689 0.5355 0.9851], Lowest was [0.9196 0.1689 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1689 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:51<5:04:19, 36.74s/it]  1%|          | 4/500 [02:39<5:40:51, 41.23s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 6.81E+06, Train scatter: [0.935  0.1462 0.5439 0.9953]
L1 regularization loss: 1.53E+00, L2 regularization loss: 3.54E-01
Test scatter: [0.9195 0.145  0.5353 0.985 ], Lowest was [0.9195 0.145  0.5353 0.985 ]
Median for last 10 epochs: [0.9195 0.145  0.5353 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:10<5:10:41, 37.66s/it]  1%|          | 6/500 [03:59<5:40:27, 41.35s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.16E+06, Train scatter: [0.9344 0.126  0.5423 0.7048]
L1 regularization loss: 1.57E+00, L2 regularization loss: 3.90E-01
Test scatter: [0.9189 0.125  0.5337 0.6977], Lowest was [0.9189 0.125  0.5337 0.6977]
Median for last 10 epochs: [0.9189 0.125  0.5337 0.6977], Epochs since improvement 0
  1%|▏         | 7/500 [04:30<5:12:41, 38.06s/it]  2%|▏         | 8/500 [05:18<5:38:36, 41.29s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.14E+06, Train scatter: [0.9166 0.1027 0.5328 0.6112]
L1 regularization loss: 1.59E+00, L2 regularization loss: 4.03E-01
Test scatter: [0.9013 0.1034 0.5245 0.6028], Lowest was [0.9013 0.1034 0.5245 0.6028]
Median for last 10 epochs: [0.9101 0.1142 0.5291 0.6502], Epochs since improvement 0
  2%|▏         | 9/500 [05:50<5:12:35, 38.20s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 3.39E+06, Train scatter: [0.7972 0.0975 0.4657 0.6046]
L1 regularization loss: 1.61E+00, L2 regularization loss: 4.14E-01
Test scatter: [0.7891 0.0999 0.4567 0.602 ], Lowest was [0.7891 0.0999 0.4567 0.602 ]
Median for last 10 epochs: [0.9013 0.1034 0.5245 0.6028], Epochs since improvement 0
  2%|▏         | 10/500 [06:43<5:50:47, 42.95s/it]  2%|▏         | 11/500 [07:15<5:20:59, 39.38s/it]  2%|▏         | 12/500 [08:03<5:42:20, 42.09s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.42E+06, Train scatter: [0.6088 0.0942 0.4309 0.632 ]
L1 regularization loss: 1.63E+00, L2 regularization loss: 4.23E-01
Test scatter: [0.6051 0.0963 0.4269 0.6363], Lowest was [0.6051 0.0963 0.4269 0.602 ]
Median for last 10 epochs: [0.9013 0.1034 0.5245 0.6363], Epochs since improvement 0
  3%|▎         | 13/500 [08:34<5:15:10, 38.83s/it]  3%|▎         | 14/500 [09:22<5:37:52, 41.71s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.61E+06, Train scatter: [0.5387 0.0888 0.3755 0.5816]
L1 regularization loss: 1.64E+00, L2 regularization loss: 4.31E-01
Test scatter: [0.5501 0.091  0.3749 0.5841], Lowest was [0.5501 0.091  0.3749 0.5841]
Median for last 10 epochs: [0.7891 0.0999 0.4567 0.6028], Epochs since improvement 0
  3%|▎         | 15/500 [09:54<5:11:50, 38.58s/it]  3%|▎         | 16/500 [10:42<5:35:34, 41.60s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.28E+06, Train scatter: [0.5949 0.0927 0.363  0.6083]
L1 regularization loss: 1.66E+00, L2 regularization loss: 4.38E-01
Test scatter: [0.5928 0.0957 0.3773 0.6062], Lowest was [0.5501 0.091  0.3749 0.5841]
Median for last 10 epochs: [0.6051 0.0963 0.4269 0.6028], Epochs since improvement 2
  3%|▎         | 17/500 [11:14<5:10:01, 38.51s/it]  4%|▎         | 18/500 [12:02<5:33:06, 41.47s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.14E+06, Train scatter: [0.5434 0.0862 0.3418 0.5622]
L1 regularization loss: 1.67E+00, L2 regularization loss: 4.46E-01
Test scatter: [0.551  0.0886 0.3554 0.5665], Lowest was [0.5501 0.0886 0.3554 0.5665]
Median for last 10 epochs: [0.5928 0.0957 0.3773 0.602 ], Epochs since improvement 0
  4%|▍         | 19/500 [12:33<5:07:49, 38.40s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 9.48E+05, Train scatter: [0.5245 0.0869 0.3394 0.5756]
L1 regularization loss: 1.70E+00, L2 regularization loss: 4.55E-01
Test scatter: [0.525  0.0896 0.3543 0.577 ], Lowest was [0.525  0.0886 0.3543 0.5665]
Median for last 10 epochs: [0.551  0.091  0.3749 0.5841], Epochs since improvement 0
  4%|▍         | 20/500 [13:27<5:43:14, 42.91s/it]  4%|▍         | 21/500 [13:58<5:15:03, 39.46s/it]  4%|▍         | 22/500 [14:47<5:36:00, 42.18s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 8.57E+05, Train scatter: [0.5422 0.081  0.315  0.5581]
L1 regularization loss: 1.72E+00, L2 regularization loss: 4.68E-01
Test scatter: [0.5377 0.0824 0.3234 0.5516], Lowest was [0.525  0.0824 0.3234 0.5516]
Median for last 10 epochs: [0.5501 0.0896 0.3554 0.577 ], Epochs since improvement 0
  5%|▍         | 23/500 [15:18<5:09:19, 38.91s/it]  5%|▍         | 24/500 [16:06<5:30:53, 41.71s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.89E+05, Train scatter: [0.5747 0.0798 0.3158 0.5487]
L1 regularization loss: 1.76E+00, L2 regularization loss: 4.83E-01
Test scatter: [0.5629 0.0811 0.3209 0.5422], Lowest was [0.525  0.0811 0.3209 0.5422]
Median for last 10 epochs: [0.551  0.0886 0.3543 0.5665], Epochs since improvement 0
  5%|▌         | 25/500 [16:38<5:05:36, 38.60s/it]  5%|▌         | 26/500 [17:26<5:27:44, 41.49s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.02E+05, Train scatter: [0.4492 0.0762 0.3    0.5342]
L1 regularization loss: 1.80E+00, L2 regularization loss: 5.00E-01
Test scatter: [0.4584 0.0777 0.3095 0.5322], Lowest was [0.4584 0.0777 0.3095 0.5322]
Median for last 10 epochs: [0.5377 0.0824 0.3234 0.5516], Epochs since improvement 0
  5%|▌         | 27/500 [17:57<5:03:04, 38.45s/it]  6%|▌         | 28/500 [18:45<5:25:45, 41.41s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 5.37E+05, Train scatter: [0.5192 0.0753 0.2958 0.5234]
L1 regularization loss: 1.85E+00, L2 regularization loss: 5.23E-01
Test scatter: [0.5534 0.0774 0.303  0.5218], Lowest was [0.4584 0.0774 0.303  0.5218]
Median for last 10 epochs: [0.5377 0.0811 0.3209 0.5422], Epochs since improvement 0
  6%|▌         | 29/500 [19:17<5:01:08, 38.36s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.34E+05, Train scatter: [0.4395 0.0753 0.2901 0.5154]
L1 regularization loss: 1.88E+00, L2 regularization loss: 5.44E-01
Test scatter: [0.4547 0.0775 0.305  0.5152], Lowest was [0.4547 0.0774 0.303  0.5152]
Median for last 10 epochs: [0.5377 0.0777 0.3095 0.5322], Epochs since improvement 0
  6%|▌         | 30/500 [20:10<5:35:14, 42.80s/it]  6%|▌         | 31/500 [20:41<5:07:51, 39.38s/it]  6%|▋         | 32/500 [21:30<5:28:22, 42.10s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.75E+05, Train scatter: [0.4572 0.0746 0.3023 0.5693]
L1 regularization loss: 1.91E+00, L2 regularization loss: 5.66E-01
Test scatter: [0.4509 0.0751 0.3089 0.5641], Lowest was [0.4509 0.0751 0.303  0.5152]
Median for last 10 epochs: [0.4584 0.0775 0.3089 0.5322], Epochs since improvement 0
  7%|▋         | 33/500 [22:01<5:02:50, 38.91s/it]  7%|▋         | 34/500 [22:50<5:24:57, 41.84s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.90E+05, Train scatter: [0.4769 0.0721 0.2825 0.5027]
L1 regularization loss: 1.99E+00, L2 regularization loss: 6.04E-01
Test scatter: [0.4657 0.0739 0.2902 0.5005], Lowest was [0.4509 0.0739 0.2902 0.5005]
Median for last 10 epochs: [0.4584 0.0774 0.305  0.5218], Epochs since improvement 0
  7%|▋         | 35/500 [23:21<4:59:51, 38.69s/it]  7%|▋         | 36/500 [24:10<5:22:03, 41.65s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.47E+05, Train scatter: [0.4383 0.0699 0.2783 0.513 ]
L1 regularization loss: 2.03E+00, L2 regularization loss: 6.32E-01
Test scatter: [0.4337 0.0713 0.2905 0.5164], Lowest was [0.4337 0.0713 0.2902 0.5005]
Median for last 10 epochs: [0.4547 0.0751 0.303  0.5164], Epochs since improvement 0
  7%|▋         | 37/500 [24:41<4:57:52, 38.60s/it]  8%|▊         | 38/500 [25:30<5:20:39, 41.64s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 5.30E+05, Train scatter: [0.4862 0.0765 0.2848 0.5391]
L1 regularization loss: 2.07E+00, L2 regularization loss: 6.61E-01
Test scatter: [0.4792 0.0793 0.2896 0.5338], Lowest was [0.4337 0.0713 0.2896 0.5005]
Median for last 10 epochs: [0.4547 0.0751 0.2905 0.5164], Epochs since improvement 0
  8%|▊         | 39/500 [26:02<4:56:50, 38.64s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: -1.77E+03, Train scatter: [0.3821 0.0678 0.2646 0.4963]
L1 regularization loss: 2.09E+00, L2 regularization loss: 6.84E-01
Test scatter: [0.3744 0.0692 0.2767 0.4985], Lowest was [0.3744 0.0692 0.2767 0.4985]
Median for last 10 epochs: [0.4509 0.0739 0.2902 0.5164], Epochs since improvement 0
  8%|▊         | 40/500 [26:55<5:31:17, 43.21s/it]  8%|▊         | 41/500 [27:27<5:03:33, 39.68s/it]  8%|▊         | 42/500 [28:15<5:22:52, 42.30s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.74E+05, Train scatter: [0.4221 0.0623 0.2622 0.4797]
L1 regularization loss: 2.10E+00, L2 regularization loss: 7.02E-01
Test scatter: [0.4173 0.0635 0.2729 0.4795], Lowest was [0.3744 0.0635 0.2729 0.4795]
Median for last 10 epochs: [0.4337 0.0713 0.2896 0.5005], Epochs since improvement 0
  9%|▊         | 43/500 [28:47<4:57:27, 39.05s/it]  9%|▉         | 44/500 [29:35<5:17:43, 41.81s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.88E+05, Train scatter: [0.2754 0.061  0.2686 0.4753]
L1 regularization loss: 2.12E+00, L2 regularization loss: 7.22E-01
Test scatter: [0.3004 0.0627 0.2777 0.4757], Lowest was [0.3004 0.0627 0.2729 0.4757]
Median for last 10 epochs: [0.4173 0.0692 0.2777 0.4985], Epochs since improvement 0
  9%|▉         | 45/500 [30:06<4:53:23, 38.69s/it]  9%|▉         | 46/500 [30:55<5:15:14, 41.66s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: -2.94E+05, Train scatter: [0.2508 0.0624 0.265  0.484 ]
L1 regularization loss: 2.14E+00, L2 regularization loss: 7.46E-01
Test scatter: [0.3058 0.0635 0.2739 0.4805], Lowest was [0.3004 0.0627 0.2729 0.4757]
Median for last 10 epochs: [0.3744 0.0635 0.2767 0.4805], Epochs since improvement 2
  9%|▉         | 47/500 [31:26<4:51:20, 38.59s/it] 10%|▉         | 48/500 [32:15<5:13:25, 41.60s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: -2.96E+05, Train scatter: [0.2243 0.0594 0.2652 0.4695]
L1 regularization loss: 2.18E+00, L2 regularization loss: 7.78E-01
Test scatter: [0.2331 0.0599 0.2755 0.4701], Lowest was [0.2331 0.0599 0.2729 0.4701]
Median for last 10 epochs: [0.3058 0.0635 0.2755 0.4795], Epochs since improvement 0
 10%|▉         | 49/500 [32:47<4:49:47, 38.55s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: -2.88E+05, Train scatter: [0.2583 0.0658 0.2814 0.4937]
L1 regularization loss: 2.27E+00, L2 regularization loss: 8.26E-01
Test scatter: [0.261  0.066  0.293  0.4901], Lowest was [0.2331 0.0599 0.2729 0.4701]
Median for last 10 epochs: [0.3004 0.0635 0.2755 0.4795], Epochs since improvement 2
 10%|█         | 50/500 [33:40<5:23:12, 43.09s/it] 10%|█         | 51/500 [34:12<4:56:17, 39.59s/it] 10%|█         | 52/500 [35:00<5:15:19, 42.23s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: -2.88E+05, Train scatter: [0.2231 0.0581 0.2653 0.4703]
L1 regularization loss: 2.31E+00, L2 regularization loss: 8.64E-01
Test scatter: [0.2328 0.0589 0.274  0.4725], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.261  0.0627 0.2755 0.4757], Epochs since improvement 0
 11%|█         | 53/500 [35:32<4:50:32, 39.00s/it] 11%|█         | 54/500 [36:20<5:11:18, 41.88s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: -2.99E+05, Train scatter: [0.2598 0.0583 0.281  0.4777]
L1 regularization loss: 2.33E+00, L2 regularization loss: 8.99E-01
Test scatter: [0.2636 0.0601 0.2918 0.4794], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.261  0.0601 0.2755 0.4794], Epochs since improvement 2
 11%|█         | 55/500 [36:51<4:47:13, 38.73s/it] 11%|█         | 56/500 [37:40<5:08:50, 41.74s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: -2.91E+05, Train scatter: [0.229  0.0616 0.2988 0.4727]
L1 regularization loss: 2.38E+00, L2 regularization loss: 9.51E-01
Test scatter: [0.2335 0.0613 0.3042 0.4732], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.2335 0.0601 0.2918 0.4732], Epochs since improvement 4
 11%|█▏        | 57/500 [38:12<4:45:41, 38.69s/it] 12%|█▏        | 58/500 [39:00<5:06:33, 41.61s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.41E+06, Train scatter: [0.889  0.1519 0.5316 0.9428]
L1 regularization loss: 3.40E+00, L2 regularization loss: 1.51E+00
Test scatter: [0.8745 0.1497 0.5247 0.9341], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.261  0.0613 0.293  0.4794], Epochs since improvement 6
 12%|█▏        | 59/500 [39:32<4:43:47, 38.61s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: -6.69E+04, Train scatter: [0.4738 0.0931 0.4442 0.6234]
L1 regularization loss: 3.40E+00, L2 regularization loss: 1.60E+00
Test scatter: [0.4735 0.0931 0.4409 0.6158], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.2636 0.0613 0.3042 0.4794], Epochs since improvement 8
 12%|█▏        | 60/500 [40:26<5:16:22, 43.14s/it] 12%|█▏        | 61/500 [40:57<4:50:16, 39.67s/it] 12%|█▏        | 62/500 [41:46<5:08:47, 42.30s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: -1.32E+05, Train scatter: [0.5348 0.0895 0.4316 0.5975]
L1 regularization loss: 3.36E+00, L2 regularization loss: 1.61E+00
Test scatter: [0.5399 0.0944 0.4357 0.6123], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.4735 0.0931 0.4357 0.6123], Epochs since improvement 10
 13%|█▎        | 63/500 [42:17<4:44:22, 39.05s/it] 13%|█▎        | 64/500 [43:06<5:04:27, 41.90s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: -1.61E+05, Train scatter: [0.4351 0.0802 0.4068 0.5647]
L1 regularization loss: 3.33E+00, L2 regularization loss: 1.64E+00
Test scatter: [0.4399 0.0822 0.414  0.5685], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.4735 0.0931 0.4357 0.6123], Epochs since improvement 12
 13%|█▎        | 65/500 [43:37<4:41:12, 38.79s/it] 13%|█▎        | 66/500 [44:26<5:03:24, 41.94s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: -1.88E+05, Train scatter: [0.4319 0.0812 0.425  0.5692]
L1 regularization loss: 3.31E+00, L2 regularization loss: 1.67E+00
Test scatter: [0.4264 0.0808 0.4159 0.5662], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.4735 0.0931 0.4357 0.6123], Epochs since improvement 14
 13%|█▎        | 67/500 [44:58<4:40:23, 38.85s/it] 14%|█▎        | 68/500 [45:47<5:00:49, 41.78s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: -2.09E+05, Train scatter: [0.5547 0.0744 0.384  0.5402]
L1 regularization loss: 3.31E+00, L2 regularization loss: 1.72E+00
Test scatter: [0.5428 0.0752 0.3919 0.5398], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.4735 0.0822 0.4159 0.5685], Epochs since improvement 16
 14%|█▍        | 69/500 [46:18<4:37:28, 38.63s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: -2.21E+05, Train scatter: [0.3546 0.0699 0.422  0.5291]
L1 regularization loss: 3.31E+00, L2 regularization loss: 1.77E+00
Test scatter: [0.3463 0.0705 0.4236 0.5266], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.4399 0.0808 0.4159 0.5662], Epochs since improvement 18
 14%|█▍        | 70/500 [47:14<5:13:25, 43.73s/it] 14%|█▍        | 71/500 [47:45<4:46:19, 40.05s/it] 14%|█▍        | 72/500 [48:35<5:05:47, 42.87s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: -2.39E+05, Train scatter: [0.409  0.0662 0.3424 0.5051]
L1 regularization loss: 3.31E+00, L2 regularization loss: 1.81E+00
Test scatter: [0.4043 0.0668 0.3497 0.5102], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.4264 0.0752 0.414  0.5398], Epochs since improvement 20
 15%|█▍        | 73/500 [49:06<4:40:32, 39.42s/it] 15%|█▍        | 73/500 [49:55<4:51:59, 41.03s/it]
Epoch: 74 done with learning rate 1.00E-02, Train loss: -2.49E+05, Train scatter: [0.4092 0.069  0.3383 0.5012]
L1 regularization loss: 3.32E+00, L2 regularization loss: 1.86E+00
Test scatter: [0.4025 0.0689 0.3385 0.4994], Lowest was [0.2328 0.0589 0.2729 0.4701]
Median for last 10 epochs: [0.4043 0.0705 0.3919 0.5266], Epochs since improvement 22
Exited after 74 epochs due to early stopping
2995.54 seconds spent training, 5.991 seconds per epoch. Processed 11623 trees per second
[0.40247118 0.06889649 0.33850357 0.4994075 ]
{'epoch_exit': 73, 'scatter_m_star': 0.40247118, 'lowest_m_star': 0.23279497, 'last20_m_star': 0.43317503, 'last10_m_star': 0.40426242, 'scatter_v_disk': 0.06889649, 'lowest_v_disk': 0.058894526, 'last20_v_disk': 0.07802718, 'last10_v_disk': 0.07047746, 'scatter_m_cold': 0.33850357, 'lowest_m_cold': 0.27289268, 'last20_m_cold': 0.41493785, 'last10_m_cold': 0.39191666, 'scatter_sfr_100': 0.4994075, 'lowest_sfr_100': 0.47010922, 'last20_sfr_100': 0.5529884, 'last10_sfr_100': 0.52661115}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_ilppsy
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:54:07, 28.15s/it]  0%|          | 2/500 [01:12<5:14:10, 37.85s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.36E+07, Train scatter: [0.9353 0.1641 0.5442 0.9954]
L1 regularization loss: 1.51E+00, L2 regularization loss: 3.26E-01
Test scatter: [0.9197 0.1663 0.5356 0.9851], Lowest was [0.9197 0.1663 0.5356 0.9851]
Median for last 10 epochs: [0.9197 0.1663 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:39<4:32:54, 32.95s/it]  1%|          | 4/500 [02:25<5:14:00, 37.98s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.19E+07, Train scatter: [0.9353 0.1768 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.32E-01
Test scatter: [0.9197 0.1783 0.5355 0.9851], Lowest was [0.9197 0.1663 0.5355 0.9851]
Median for last 10 epochs: [0.9197 0.1723 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:52<4:41:09, 34.08s/it]  1%|          | 6/500 [03:38<5:12:47, 37.99s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.47E+06, Train scatter: [0.9352 0.1649 0.5442 0.9954]
L1 regularization loss: 1.54E+00, L2 regularization loss: 3.44E-01
Test scatter: [0.9196 0.1601 0.5356 0.9851], Lowest was [0.9196 0.1601 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1601 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:05<4:43:11, 34.47s/it]  2%|▏         | 8/500 [04:50<5:10:26, 37.86s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.42E+06, Train scatter: [0.9352 0.1478 0.5441 0.9951]
L1 regularization loss: 1.55E+00, L2 regularization loss: 3.65E-01
Test scatter: [0.9196 0.143  0.5355 0.9847], Lowest was [0.9196 0.143  0.5355 0.9847]
Median for last 10 epochs: [0.9196 0.1515 0.5355 0.9849], Epochs since improvement 0
  2%|▏         | 9/500 [05:17<4:42:38, 34.54s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.80E+06, Train scatter: [0.935  0.1322 0.5441 0.6814]
L1 regularization loss: 1.58E+00, L2 regularization loss: 3.95E-01
Test scatter: [0.9194 0.1276 0.5355 0.679 ], Lowest was [0.9194 0.1276 0.5355 0.679 ]
Median for last 10 epochs: [0.9196 0.143  0.5355 0.9847], Epochs since improvement 0
  2%|▏         | 10/500 [06:08<5:23:43, 39.64s/it]  2%|▏         | 11/500 [06:36<4:52:07, 35.84s/it]  2%|▏         | 12/500 [07:21<5:14:32, 38.67s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.26E+06, Train scatter: [0.9315 0.1209 0.544  0.6337]
L1 regularization loss: 1.60E+00, L2 regularization loss: 4.04E-01
Test scatter: [0.9156 0.1159 0.5354 0.6243], Lowest was [0.9156 0.1159 0.5354 0.6243]
Median for last 10 epochs: [0.9196 0.143  0.5355 0.9847], Epochs since improvement 0
  3%|▎         | 13/500 [07:48<4:45:43, 35.20s/it]  3%|▎         | 14/500 [08:34<5:10:22, 38.32s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.89E+07, Train scatter: [0.9351 0.1785 0.5442 0.983 ]
L1 regularization loss: 1.66E+00, L2 regularization loss: 4.30E-01
Test scatter: [0.9195 0.1801 0.5356 0.9721], Lowest was [0.9156 0.1159 0.5354 0.6243]
Median for last 10 epochs: [0.9195 0.143  0.5355 0.9721], Epochs since improvement 2
  3%|▎         | 15/500 [09:01<4:43:01, 35.01s/it]  3%|▎         | 16/500 [09:47<5:08:53, 38.29s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 8.58E+06, Train scatter: [0.9317 0.154  0.5441 0.774 ]
L1 regularization loss: 1.67E+00, L2 regularization loss: 4.48E-01
Test scatter: [0.9164 0.1543 0.5355 0.7786], Lowest was [0.9156 0.1159 0.5354 0.6243]
Median for last 10 epochs: [0.9194 0.143  0.5355 0.7786], Epochs since improvement 4
  3%|▎         | 17/500 [10:14<4:41:37, 34.98s/it]  4%|▎         | 18/500 [11:00<5:07:28, 38.27s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.21E+06, Train scatter: [0.8481 0.1302 0.5439 0.6612]
L1 regularization loss: 1.70E+00, L2 regularization loss: 4.71E-01
Test scatter: [0.8401 0.1319 0.5353 0.6504], Lowest was [0.8401 0.1159 0.5353 0.6243]
Median for last 10 epochs: [0.9164 0.1319 0.5355 0.679 ], Epochs since improvement 0
  4%|▍         | 19/500 [11:27<4:40:22, 34.97s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 6.14E+06, Train scatter: [0.6148 0.116  0.5434 0.6272]
L1 regularization loss: 1.73E+00, L2 regularization loss: 5.05E-01
Test scatter: [0.6269 0.1196 0.5348 0.6242], Lowest was [0.6269 0.1159 0.5348 0.6242]
Median for last 10 epochs: [0.9156 0.1319 0.5354 0.6504], Epochs since improvement 0
  4%|▍         | 20/500 [12:17<5:15:00, 39.38s/it]  4%|▍         | 21/500 [12:44<4:45:29, 35.76s/it]  4%|▍         | 22/500 [13:29<5:07:06, 38.55s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.69E+06, Train scatter: [0.5359 0.1072 0.5409 0.6235]
L1 regularization loss: 1.74E+00, L2 regularization loss: 5.21E-01
Test scatter: [0.5414 0.1089 0.5322 0.6166], Lowest was [0.5414 0.1089 0.5322 0.6166]
Median for last 10 epochs: [0.8401 0.1319 0.5353 0.6504], Epochs since improvement 0
  5%|▍         | 23/500 [13:57<4:40:13, 35.25s/it]  5%|▍         | 24/500 [14:42<5:03:55, 38.31s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 5.26E+06, Train scatter: [0.5399 0.1036 0.533  0.5879]
L1 regularization loss: 1.76E+00, L2 regularization loss: 5.34E-01
Test scatter: [0.5424 0.1048 0.5249 0.5849], Lowest was [0.5414 0.1048 0.5249 0.5849]
Median for last 10 epochs: [0.6269 0.1196 0.5348 0.6242], Epochs since improvement 0
  5%|▌         | 25/500 [15:10<4:37:20, 35.03s/it]  5%|▌         | 26/500 [15:54<4:58:54, 37.84s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.47E+06, Train scatter: [0.5155 0.1002 0.4956 0.5781]
L1 regularization loss: 1.77E+00, L2 regularization loss: 5.51E-01
Test scatter: [0.5321 0.1021 0.4954 0.5826], Lowest was [0.5321 0.1021 0.4954 0.5826]
Median for last 10 epochs: [0.5424 0.1089 0.5322 0.6166], Epochs since improvement 0
  5%|▌         | 27/500 [16:21<4:33:08, 34.65s/it]  6%|▌         | 28/500 [17:07<4:57:58, 37.88s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.60E+06, Train scatter: [0.4904 0.1012 0.4507 0.5975]
L1 regularization loss: 1.79E+00, L2 regularization loss: 5.64E-01
Test scatter: [0.5197 0.1034 0.4522 0.6013], Lowest was [0.5197 0.1021 0.4522 0.5826]
Median for last 10 epochs: [0.5414 0.1048 0.5249 0.6013], Epochs since improvement 0
  6%|▌         | 29/500 [17:34<4:32:27, 34.71s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.29E+06, Train scatter: [0.7151 0.0961 0.4378 0.5771]
L1 regularization loss: 1.80E+00, L2 regularization loss: 5.73E-01
Test scatter: [0.6468 0.0982 0.4352 0.5764], Lowest was [0.5197 0.0982 0.4352 0.5764]
Median for last 10 epochs: [0.5414 0.1034 0.4954 0.5849], Epochs since improvement 0
  6%|▌         | 30/500 [18:24<5:07:55, 39.31s/it]  6%|▌         | 31/500 [18:52<4:39:22, 35.74s/it]  6%|▋         | 32/500 [19:37<5:01:27, 38.65s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.33E+06, Train scatter: [0.499  0.0963 0.4143 0.6466]
L1 regularization loss: 1.82E+00, L2 regularization loss: 5.84E-01
Test scatter: [0.5026 0.0994 0.4098 0.6363], Lowest was [0.5026 0.0982 0.4098 0.5764]
Median for last 10 epochs: [0.5321 0.1021 0.4522 0.5849], Epochs since improvement 0
  7%|▋         | 33/500 [20:05<4:34:52, 35.32s/it]  7%|▋         | 34/500 [20:51<4:59:19, 38.54s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.17E+06, Train scatter: [0.4167 0.0923 0.3652 0.5865]
L1 regularization loss: 1.83E+00, L2 regularization loss: 5.95E-01
Test scatter: [0.4353 0.0942 0.3739 0.5905], Lowest was [0.4353 0.0942 0.3739 0.5764]
Median for last 10 epochs: [0.5197 0.0994 0.4352 0.5905], Epochs since improvement 0
  7%|▋         | 35/500 [21:18<4:32:43, 35.19s/it]  7%|▋         | 36/500 [22:03<4:55:51, 38.26s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 1.92E+06, Train scatter: [0.4732 0.0916 0.3778 0.6168]
L1 regularization loss: 1.85E+00, L2 regularization loss: 6.06E-01
Test scatter: [0.4729 0.0936 0.3799 0.6081], Lowest was [0.4353 0.0936 0.3739 0.5764]
Median for last 10 epochs: [0.5026 0.0982 0.4098 0.6013], Epochs since improvement 0
  7%|▋         | 37/500 [22:31<4:30:25, 35.04s/it]  8%|▊         | 38/500 [23:16<4:53:11, 38.08s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.87E+06, Train scatter: [0.4941 0.0902 0.3871 0.5802]
L1 regularization loss: 1.86E+00, L2 regularization loss: 6.15E-01
Test scatter: [0.4914 0.0922 0.391  0.5806], Lowest was [0.4353 0.0922 0.3739 0.5764]
Median for last 10 epochs: [0.4914 0.0942 0.391  0.5905], Epochs since improvement 0
  8%|▊         | 39/500 [23:44<4:28:44, 34.98s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.78E+06, Train scatter: [0.4284 0.0907 0.3418 0.5634]
L1 regularization loss: 1.88E+00, L2 regularization loss: 6.26E-01
Test scatter: [0.4383 0.0928 0.35   0.5722], Lowest was [0.4353 0.0922 0.35   0.5722]
Median for last 10 epochs: [0.4729 0.0936 0.3799 0.5905], Epochs since improvement 0
  8%|▊         | 40/500 [24:37<5:09:17, 40.34s/it]  8%|▊         | 41/500 [25:04<4:38:54, 36.46s/it]  8%|▊         | 42/500 [25:49<4:58:21, 39.09s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.65E+06, Train scatter: [0.4031 0.0896 0.337  0.5549]
L1 regularization loss: 1.90E+00, L2 regularization loss: 6.39E-01
Test scatter: [0.4247 0.0918 0.3443 0.5665], Lowest was [0.4247 0.0918 0.3443 0.5665]
Median for last 10 epochs: [0.4383 0.0928 0.3739 0.5806], Epochs since improvement 0
  9%|▊         | 43/500 [26:17<4:31:02, 35.58s/it]  9%|▉         | 44/500 [27:02<4:52:06, 38.43s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.65E+06, Train scatter: [0.3764 0.0882 0.3355 0.5561]
L1 regularization loss: 1.92E+00, L2 regularization loss: 6.55E-01
Test scatter: [0.3971 0.0909 0.346  0.5669], Lowest was [0.3971 0.0909 0.3443 0.5665]
Median for last 10 epochs: [0.4383 0.0922 0.35   0.5722], Epochs since improvement 0
  9%|▉         | 45/500 [27:29<4:26:21, 35.12s/it]  9%|▉         | 46/500 [28:15<4:49:23, 38.25s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.44E+06, Train scatter: [0.3822 0.0875 0.3424 0.5437]
L1 regularization loss: 1.98E+00, L2 regularization loss: 6.84E-01
Test scatter: [0.4064 0.0898 0.3456 0.5533], Lowest was [0.3971 0.0898 0.3443 0.5533]
Median for last 10 epochs: [0.4247 0.0918 0.346  0.5669], Epochs since improvement 0
  9%|▉         | 47/500 [28:42<4:24:05, 34.98s/it] 10%|▉         | 48/500 [29:28<4:47:17, 38.14s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.40E+06, Train scatter: [0.3862 0.0897 0.3284 0.5458]
L1 regularization loss: 2.00E+00, L2 regularization loss: 7.04E-01
Test scatter: [0.4132 0.0923 0.3348 0.558 ], Lowest was [0.3971 0.0898 0.3348 0.5533]
Median for last 10 epochs: [0.4132 0.0918 0.3456 0.5665], Epochs since improvement 0
 10%|▉         | 49/500 [29:55<4:22:23, 34.91s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.28E+06, Train scatter: [0.373  0.0851 0.3389 0.5564]
L1 regularization loss: 2.02E+00, L2 regularization loss: 7.25E-01
Test scatter: [0.3804 0.0873 0.3437 0.5592], Lowest was [0.3804 0.0873 0.3348 0.5533]
Median for last 10 epochs: [0.4064 0.0909 0.3443 0.5592], Epochs since improvement 0
 10%|█         | 50/500 [30:45<4:56:52, 39.58s/it] 10%|█         | 51/500 [31:13<4:29:12, 35.97s/it] 10%|█         | 52/500 [31:59<4:50:01, 38.84s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.14E+06, Train scatter: [0.3514 0.0827 0.3606 0.5502]
L1 regularization loss: 2.03E+00, L2 regularization loss: 7.46E-01
Test scatter: [0.3586 0.0849 0.3695 0.5618], Lowest was [0.3586 0.0849 0.3348 0.5533]
Median for last 10 epochs: [0.3971 0.0898 0.3456 0.5592], Epochs since improvement 0
 11%|█         | 53/500 [32:26<4:23:57, 35.43s/it] 11%|█         | 54/500 [33:12<4:46:36, 38.56s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.06E+06, Train scatter: [0.3775 0.0835 0.3078 0.5184]
L1 regularization loss: 2.05E+00, L2 regularization loss: 7.68E-01
Test scatter: [0.3996 0.0858 0.318  0.5294], Lowest was [0.3586 0.0849 0.318  0.5294]
Median for last 10 epochs: [0.3996 0.0873 0.3437 0.558 ], Epochs since improvement 0
 11%|█         | 55/500 [33:39<4:21:30, 35.26s/it] 11%|█         | 56/500 [34:25<4:43:50, 38.36s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.06E+06, Train scatter: [0.4572 0.0814 0.3154 0.5809]
L1 regularization loss: 2.07E+00, L2 regularization loss: 7.90E-01
Test scatter: [0.4532 0.0837 0.323  0.5821], Lowest was [0.3586 0.0837 0.318  0.5294]
Median for last 10 epochs: [0.3996 0.0858 0.3348 0.5592], Epochs since improvement 0
 11%|█▏        | 57/500 [34:52<4:18:55, 35.07s/it] 12%|█▏        | 58/500 [35:38<4:41:53, 38.27s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.16E+06, Train scatter: [0.3325 0.0812 0.3566 0.5319]
L1 regularization loss: 2.10E+00, L2 regularization loss: 8.20E-01
Test scatter: [0.3456 0.0837 0.3618 0.5436], Lowest was [0.3456 0.0837 0.318  0.5294]
Median for last 10 epochs: [0.3804 0.0849 0.3437 0.5592], Epochs since improvement 0
 12%|█▏        | 59/500 [36:06<4:17:16, 35.00s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 9.18E+05, Train scatter: [0.3486 0.0789 0.2969 0.5031]
L1 regularization loss: 2.11E+00, L2 regularization loss: 8.44E-01
Test scatter: [0.3536 0.0813 0.3087 0.5125], Lowest was [0.3456 0.0813 0.3087 0.5125]
Median for last 10 epochs: [0.3586 0.0837 0.323  0.5436], Epochs since improvement 0
 12%|█▏        | 60/500 [36:56<4:51:42, 39.78s/it] 12%|█▏        | 61/500 [37:24<4:24:04, 36.09s/it] 12%|█▏        | 62/500 [38:10<4:45:16, 39.08s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 9.76E+05, Train scatter: [0.3122 0.0824 0.3288 0.5162]
L1 regularization loss: 2.14E+00, L2 regularization loss: 8.72E-01
Test scatter: [0.3304 0.0854 0.3399 0.5273], Lowest was [0.3304 0.0813 0.3087 0.5125]
Median for last 10 epochs: [0.3536 0.0837 0.323  0.5294], Epochs since improvement 0
 13%|█▎        | 63/500 [38:37<4:19:15, 35.60s/it] 13%|█▎        | 64/500 [39:24<4:42:53, 38.93s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 7.83E+05, Train scatter: [0.3908 0.0811 0.3154 0.5323]
L1 regularization loss: 2.14E+00, L2 regularization loss: 8.94E-01
Test scatter: [0.3985 0.0842 0.3225 0.5409], Lowest was [0.3304 0.0813 0.3087 0.5125]
Median for last 10 epochs: [0.3536 0.0837 0.323  0.5409], Epochs since improvement 2
 13%|█▎        | 65/500 [39:52<4:17:14, 35.48s/it] 13%|█▎        | 66/500 [40:38<4:41:10, 38.87s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 7.61E+05, Train scatter: [0.299  0.076  0.306  0.4925]
L1 regularization loss: 2.17E+00, L2 regularization loss: 9.23E-01
Test scatter: [0.3085 0.0786 0.3135 0.4973], Lowest was [0.3085 0.0786 0.3087 0.4973]
Median for last 10 epochs: [0.3456 0.0837 0.3225 0.5273], Epochs since improvement 0
 13%|█▎        | 67/500 [41:06<4:15:41, 35.43s/it] 14%|█▎        | 68/500 [41:52<4:39:14, 38.78s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.50E+06, Train scatter: [0.3195 0.0856 0.4343 0.5436]
L1 regularization loss: 2.33E+00, L2 regularization loss: 1.02E+00
Test scatter: [0.3407 0.0871 0.434  0.5422], Lowest was [0.3085 0.0786 0.3087 0.4973]
Median for last 10 epochs: [0.3407 0.0842 0.3225 0.5273], Epochs since improvement 2
 14%|█▍        | 69/500 [42:20<4:14:02, 35.37s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.77E+06, Train scatter: [0.3138 0.0785 0.4081 0.4949]
L1 regularization loss: 2.36E+00, L2 regularization loss: 1.06E+00
Test scatter: [0.3213 0.0802 0.4078 0.4958], Lowest was [0.3085 0.0786 0.3087 0.4958]
Median for last 10 epochs: [0.3304 0.0842 0.3399 0.5273], Epochs since improvement 0
 14%|█▍        | 70/500 [43:12<4:49:10, 40.35s/it] 14%|█▍        | 71/500 [43:39<4:21:01, 36.51s/it] 14%|█▍        | 72/500 [44:25<4:41:02, 39.40s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.61E+06, Train scatter: [0.4105 0.0948 0.4431 0.5699]
L1 regularization loss: 2.38E+00, L2 regularization loss: 1.08E+00
Test scatter: [0.394  0.0945 0.4401 0.5695], Lowest was [0.3085 0.0786 0.3087 0.4958]
Median for last 10 epochs: [0.3407 0.0842 0.4078 0.5409], Epochs since improvement 2
 15%|█▍        | 73/500 [44:53<4:14:57, 35.83s/it] 15%|█▍        | 74/500 [45:39<4:35:47, 38.84s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 9.97E+05, Train scatter: [0.3096 0.0773 0.3123 0.515 ]
L1 regularization loss: 2.40E+00, L2 regularization loss: 1.11E+00
Test scatter: [0.3228 0.079  0.3195 0.5168], Lowest was [0.3085 0.0786 0.3087 0.4958]
Median for last 10 epochs: [0.3228 0.0802 0.4078 0.5168], Epochs since improvement 4
 15%|█▌        | 75/500 [46:06<4:10:49, 35.41s/it] 15%|█▌        | 76/500 [46:52<4:32:02, 38.50s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 5.69E+05, Train scatter: [0.3084 0.0759 0.299  0.525 ]
L1 regularization loss: 2.41E+00, L2 regularization loss: 1.14E+00
Test scatter: [0.3216 0.0768 0.3068 0.5249], Lowest was [0.3085 0.0768 0.3068 0.4958]
Median for last 10 epochs: [0.3228 0.0802 0.4078 0.5249], Epochs since improvement 0
 15%|█▌        | 77/500 [47:19<4:07:56, 35.17s/it] 16%|█▌        | 78/500 [48:06<4:31:41, 38.63s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 1.16E+06, Train scatter: [0.2601 0.0761 0.2957 0.5414]
L1 regularization loss: 2.47E+00, L2 regularization loss: 1.18E+00
Test scatter: [0.2753 0.077  0.3038 0.5451], Lowest was [0.2753 0.0768 0.3038 0.4958]
Median for last 10 epochs: [0.3216 0.079  0.3195 0.5249], Epochs since improvement 0
 16%|█▌        | 79/500 [48:33<4:06:59, 35.20s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 4.33E+05, Train scatter: [0.3212 0.0749 0.296  0.5042]
L1 regularization loss: 2.47E+00, L2 regularization loss: 1.20E+00
Test scatter: [0.3339 0.0767 0.3085 0.4996], Lowest was [0.2753 0.0767 0.3038 0.4958]
Median for last 10 epochs: [0.3228 0.077  0.3085 0.5249], Epochs since improvement 0
 16%|█▌        | 80/500 [49:25<4:40:16, 40.04s/it] 16%|█▌        | 81/500 [49:52<4:12:54, 36.22s/it] 16%|█▋        | 82/500 [50:38<4:33:42, 39.29s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 3.78E+05, Train scatter: [0.2607 0.0715 0.2672 0.4721]
L1 regularization loss: 2.46E+00, L2 regularization loss: 1.22E+00
Test scatter: [0.2714 0.0725 0.2781 0.473 ], Lowest was [0.2714 0.0725 0.2781 0.473 ]
Median for last 10 epochs: [0.3216 0.0768 0.3068 0.5168], Epochs since improvement 0
 17%|█▋        | 83/500 [51:06<4:08:12, 35.71s/it] 17%|█▋        | 84/500 [51:52<4:29:36, 38.88s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 3.93E+05, Train scatter: [0.2843 0.0712 0.2803 0.4907]
L1 regularization loss: 2.47E+00, L2 regularization loss: 1.23E+00
Test scatter: [0.2859 0.0728 0.2921 0.4894], Lowest was [0.2714 0.0725 0.2781 0.473 ]
Median for last 10 epochs: [0.2859 0.0767 0.3038 0.4996], Epochs since improvement 2
 17%|█▋        | 85/500 [52:19<4:05:04, 35.43s/it] 17%|█▋        | 86/500 [53:06<4:27:09, 38.72s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 3.94E+05, Train scatter: [0.2686 0.0739 0.2945 0.5116]
L1 regularization loss: 2.49E+00, L2 regularization loss: 1.26E+00
Test scatter: [0.2724 0.0749 0.3049 0.5147], Lowest was [0.2714 0.0725 0.2781 0.473 ]
Median for last 10 epochs: [0.2753 0.0749 0.3038 0.4996], Epochs since improvement 4
 17%|█▋        | 87/500 [53:33<4:02:42, 35.26s/it] 18%|█▊        | 88/500 [54:20<4:26:13, 38.77s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 4.09E+05, Train scatter: [0.2612 0.0718 0.2785 0.4959]
L1 regularization loss: 2.51E+00, L2 regularization loss: 1.29E+00
Test scatter: [0.2688 0.0737 0.2894 0.4913], Lowest was [0.2688 0.0725 0.2781 0.473 ]
Median for last 10 epochs: [0.2724 0.0737 0.2921 0.4913], Epochs since improvement 0
 18%|█▊        | 89/500 [54:47<4:01:47, 35.30s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.88E+05, Train scatter: [0.2916 0.0724 0.2704 0.5046]
L1 regularization loss: 2.56E+00, L2 regularization loss: 1.34E+00
Test scatter: [0.2933 0.0732 0.2798 0.5044], Lowest was [0.2688 0.0725 0.2781 0.473 ]
Median for last 10 epochs: [0.2724 0.0732 0.2894 0.4913], Epochs since improvement 2
 18%|█▊        | 90/500 [55:39<4:35:42, 40.35s/it] 18%|█▊        | 91/500 [56:07<4:08:31, 36.46s/it] 18%|█▊        | 92/500 [56:53<4:28:12, 39.44s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 1.76E+05, Train scatter: [0.2304 0.0689 0.259  0.4758]
L1 regularization loss: 2.56E+00, L2 regularization loss: 1.36E+00
Test scatter: [0.2432 0.0697 0.2677 0.4756], Lowest was [0.2432 0.0697 0.2677 0.473 ]
Median for last 10 epochs: [0.2724 0.0732 0.2894 0.4913], Epochs since improvement 0
 19%|█▊        | 93/500 [57:20<4:02:52, 35.80s/it] 19%|█▉        | 94/500 [58:07<4:23:46, 38.98s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 1.21E+05, Train scatter: [0.2304 0.0681 0.2638 0.4721]
L1 regularization loss: 2.55E+00, L2 regularization loss: 1.38E+00
Test scatter: [0.2439 0.0692 0.2759 0.4756], Lowest was [0.2432 0.0692 0.2677 0.473 ]
Median for last 10 epochs: [0.2688 0.0732 0.2798 0.4913], Epochs since improvement 0
 19%|█▉        | 95/500 [58:34<3:59:26, 35.47s/it] 19%|█▉        | 96/500 [59:20<4:19:51, 38.59s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 5.10E+04, Train scatter: [0.3186 0.078  0.3102 0.5772]
L1 regularization loss: 2.56E+00, L2 regularization loss: 1.41E+00
Test scatter: [0.3161 0.0805 0.3211 0.5642], Lowest was [0.2432 0.0692 0.2677 0.473 ]
Median for last 10 epochs: [0.2688 0.0732 0.2798 0.4913], Epochs since improvement 2
 19%|█▉        | 97/500 [59:47<3:56:28, 35.21s/it] 20%|█▉        | 98/500 [1:00:34<4:18:31, 38.59s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 4.98E+04, Train scatter: [0.3543 0.0777 0.3584 0.5186]
L1 regularization loss: 2.56E+00, L2 regularization loss: 1.43E+00
Test scatter: [0.3573 0.0765 0.3565 0.511 ], Lowest was [0.2432 0.0692 0.2677 0.473 ]
Median for last 10 epochs: [0.2933 0.0732 0.2798 0.5044], Epochs since improvement 4
 20%|█▉        | 99/500 [1:01:01<3:55:28, 35.23s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: -9.04E+04, Train scatter: [0.2417 0.0671 0.2556 0.4704]
L1 regularization loss: 2.56E+00, L2 regularization loss: 1.45E+00
Test scatter: [0.2566 0.0686 0.2657 0.4721], Lowest was [0.2432 0.0686 0.2657 0.4721]
Median for last 10 epochs: [0.2566 0.0697 0.2759 0.4756], Epochs since improvement 0
 20%|██        | 100/500 [1:01:53<4:28:54, 40.34s/it] 20%|██        | 101/500 [1:02:22<4:04:12, 36.72s/it] 20%|██        | 102/500 [1:03:12<4:30:43, 40.81s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: -1.18E+05, Train scatter: [0.2146 0.0652 0.2516 0.4594]
L1 regularization loss: 2.56E+00, L2 regularization loss: 1.47E+00
Test scatter: [0.2305 0.0662 0.2625 0.4602], Lowest was [0.2305 0.0662 0.2625 0.4602]
Median for last 10 epochs: [0.2566 0.0692 0.2759 0.4756], Epochs since improvement 0
 21%|██        | 103/500 [1:03:40<4:05:07, 37.05s/it] 21%|██        | 104/500 [1:04:29<4:27:35, 40.54s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: -1.66E+05, Train scatter: [0.2804 0.0645 0.2501 0.4597]
L1 regularization loss: 2.57E+00, L2 regularization loss: 1.48E+00
Test scatter: [0.287  0.0652 0.2601 0.4609], Lowest was [0.2305 0.0652 0.2601 0.4602]
Median for last 10 epochs: [0.287  0.0686 0.2657 0.4721], Epochs since improvement 0
 21%|██        | 105/500 [1:04:56<4:01:08, 36.63s/it] 21%|██        | 106/500 [1:05:41<4:16:22, 39.04s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: -1.82E+05, Train scatter: [0.2202 0.065  0.258  0.4633]
L1 regularization loss: 2.57E+00, L2 regularization loss: 1.51E+00
Test scatter: [0.2352 0.0655 0.2686 0.4651], Lowest was [0.2305 0.0652 0.2601 0.4602]
Median for last 10 epochs: [0.2566 0.0662 0.2657 0.4651], Epochs since improvement 2
 21%|██▏       | 107/500 [1:06:08<3:52:16, 35.46s/it] 22%|██▏       | 108/500 [1:06:54<4:12:17, 38.62s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: -2.34E+05, Train scatter: [0.2307 0.0626 0.247  0.4555]
L1 regularization loss: 2.58E+00, L2 regularization loss: 1.52E+00
Test scatter: [0.236  0.0633 0.2576 0.4586], Lowest was [0.2305 0.0633 0.2576 0.4586]
Median for last 10 epochs: [0.236  0.0655 0.2625 0.4609], Epochs since improvement 0
 22%|██▏       | 109/500 [1:07:21<3:49:14, 35.18s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: -2.41E+05, Train scatter: [0.2083 0.0623 0.2493 0.4545]
L1 regularization loss: 2.57E+00, L2 regularization loss: 1.54E+00
Test scatter: [0.2189 0.0632 0.2598 0.4548], Lowest was [0.2189 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.2352 0.0652 0.2601 0.4602], Epochs since improvement 0
 22%|██▏       | 110/500 [1:08:13<4:19:57, 39.99s/it] 22%|██▏       | 111/500 [1:08:40<3:54:55, 36.23s/it] 22%|██▏       | 112/500 [1:09:26<4:12:24, 39.03s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: -2.60E+05, Train scatter: [0.2037 0.0618 0.2482 0.4575]
L1 regularization loss: 2.59E+00, L2 regularization loss: 1.56E+00
Test scatter: [0.2172 0.0632 0.2596 0.4588], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.2352 0.0633 0.2598 0.4588], Epochs since improvement 0
 23%|██▎       | 113/500 [1:09:53<3:48:53, 35.49s/it] 23%|██▎       | 114/500 [1:10:39<4:09:10, 38.73s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 2.96E+09, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 7.13E+00, L2 regularization loss: 3.42E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.2352 0.0633 0.2598 0.4588], Epochs since improvement 2
 23%|██▎       | 115/500 [1:11:07<3:46:55, 35.37s/it] 23%|██▎       | 116/500 [1:11:53<4:07:50, 38.73s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 5.19E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 7.14E+00, L2 regularization loss: 3.49E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.236  0.0633 0.2598 0.4588], Epochs since improvement 4
 23%|██▎       | 117/500 [1:12:20<3:45:03, 35.26s/it] 24%|██▎       | 118/500 [1:13:07<4:06:54, 38.78s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 4.39E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 7.14E+00, L2 regularization loss: 3.52E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 6
 24%|██▍       | 119/500 [1:13:35<3:44:14, 35.31s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 4.02E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 7.14E+00, L2 regularization loss: 3.53E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 8
 24%|██▍       | 120/500 [1:14:26<4:14:17, 40.15s/it] 24%|██▍       | 121/500 [1:14:53<3:49:28, 36.33s/it] 24%|██▍       | 122/500 [1:15:39<4:06:41, 39.16s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 3.79E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 7.14E+00, L2 regularization loss: 3.54E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 10
 25%|██▍       | 123/500 [1:16:06<3:43:36, 35.59s/it] 25%|██▍       | 124/500 [1:16:52<4:01:27, 38.53s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 3.65E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 7.14E+00, L2 regularization loss: 3.54E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 12
 25%|██▌       | 125/500 [1:17:19<3:40:26, 35.27s/it] 25%|██▌       | 126/500 [1:18:06<4:00:45, 38.62s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 3.53E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 7.13E+00, L2 regularization loss: 3.57E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 14
 25%|██▌       | 127/500 [1:18:33<3:38:44, 35.19s/it] 26%|██▌       | 128/500 [1:19:20<4:00:17, 38.76s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 3.43E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 7.13E+00, L2 regularization loss: 3.57E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 16
 26%|██▌       | 129/500 [1:19:47<3:38:00, 35.26s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 3.33E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 7.12E+00, L2 regularization loss: 3.57E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 18
 26%|██▌       | 130/500 [1:20:39<4:07:36, 40.15s/it] 26%|██▌       | 131/500 [1:21:06<3:43:35, 36.36s/it] 26%|██▋       | 132/500 [1:21:52<3:59:50, 39.11s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 3.24E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 7.11E+00, L2 regularization loss: 3.57E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 20
 27%|██▋       | 133/500 [1:22:19<3:37:53, 35.62s/it] 27%|██▋       | 133/500 [1:23:06<3:49:19, 37.49s/it]
Epoch: 134 done with learning rate 9.53E-03, Train loss: 3.15E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 7.10E+00, L2 regularization loss: 3.56E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2172 0.0632 0.2576 0.4548]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 22
Exited after 134 epochs due to early stopping
4986.25 seconds spent training, 9.972 seconds per epoch. Processed 6983 trees per second
[0.9195579 0.1689888 0.5354724 0.9850301]
{'epoch_exit': 133, 'scatter_m_star': 0.9195579, 'lowest_m_star': 0.21719898, 'last20_m_star': 0.9196043, 'last10_m_star': 0.9195941, 'scatter_v_disk': 0.1689888, 'lowest_v_disk': 0.06320515, 'last20_v_disk': 0.1689935, 'last10_v_disk': 0.16899343, 'scatter_m_cold': 0.5354724, 'lowest_m_cold': 0.25759003, 'last20_m_cold': 0.53548926, 'last10_m_cold': 0.5354883, 'scatter_sfr_100': 0.9850301, 'lowest_sfr_100': 0.4547674, 'last20_sfr_100': 0.98512936, 'last10_sfr_100': 0.9850956}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_fewcoe
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:47<6:35:58, 47.61s/it]  0%|          | 2/500 [01:58<8:28:36, 61.28s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.30E+07, Train scatter: [0.9351 0.1345 0.544  0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.83E-01
Test scatter: [0.9195 0.132  0.5354 0.9851], Lowest was [0.9195 0.132  0.5354 0.9851]
Median for last 10 epochs: [0.9195 0.132  0.5354 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:45<7:33:24, 54.74s/it]  1%|          | 4/500 [03:56<8:24:30, 61.03s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.48E+07, Train scatter: [0.9298 0.0993 0.5439 0.9946]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.11E-01
Test scatter: [0.9139 0.0982 0.5353 0.9842], Lowest was [0.9139 0.0982 0.5353 0.9842]
Median for last 10 epochs: [0.9139 0.0982 0.5353 0.9842], Epochs since improvement 0
  1%|          | 5/500 [04:42<7:41:03, 55.89s/it]  1%|          | 6/500 [05:53<8:20:59, 60.85s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.21E+06, Train scatter: [0.8157 0.094  0.5438 0.6649]
L1 regularization loss: 2.05E+00, L2 regularization loss: 4.55E-01
Test scatter: [0.8016 0.0923 0.5353 0.6591], Lowest was [0.8016 0.0923 0.5353 0.6591]
Median for last 10 epochs: [0.8016 0.0923 0.5353 0.6591], Epochs since improvement 0
  1%|▏         | 7/500 [06:40<7:42:01, 56.23s/it]  2%|▏         | 8/500 [07:51<8:20:07, 60.99s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 5.68E+06, Train scatter: [0.6142 0.0845 0.5437 0.5806]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.70E-01
Test scatter: [0.6107 0.0841 0.5352 0.5769], Lowest was [0.6107 0.0841 0.5352 0.5769]
Median for last 10 epochs: [0.7062 0.0882 0.5352 0.618 ], Epochs since improvement 0
  2%|▏         | 9/500 [08:37<7:42:23, 56.50s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.36E+06, Train scatter: [0.4318 0.0784 0.5437 0.5487]
L1 regularization loss: 2.08E+00, L2 regularization loss: 4.80E-01
Test scatter: [0.4348 0.0781 0.5351 0.5446], Lowest was [0.4348 0.0781 0.5351 0.5446]
Median for last 10 epochs: [0.6107 0.0841 0.5352 0.5769], Epochs since improvement 0
  2%|▏         | 10/500 [09:55<8:35:36, 63.13s/it]  2%|▏         | 11/500 [10:42<7:53:39, 58.12s/it]  2%|▏         | 12/500 [11:52<8:21:54, 61.71s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 3.92E+06, Train scatter: [0.3952 0.0736 0.5437 0.5271]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.87E-01
Test scatter: [0.3913 0.073  0.5351 0.5241], Lowest was [0.3913 0.073  0.5351 0.5241]
Median for last 10 epochs: [0.6107 0.0841 0.5352 0.5769], Epochs since improvement 0
  3%|▎         | 13/500 [12:39<7:43:37, 57.12s/it]  3%|▎         | 14/500 [13:50<8:17:21, 61.40s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 3.42E+06, Train scatter: [0.3017 0.0695 0.5436 0.5171]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.91E-01
Test scatter: [0.3025 0.07   0.5351 0.5144], Lowest was [0.3025 0.07   0.5351 0.5144]
Median for last 10 epochs: [0.4348 0.0781 0.5351 0.5446], Epochs since improvement 0
  3%|▎         | 15/500 [14:37<7:40:37, 56.98s/it]  3%|▎         | 16/500 [15:48<8:13:49, 61.22s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.47E+06, Train scatter: [0.4028 0.0673 0.5436 0.5146]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.95E-01
Test scatter: [0.3974 0.0677 0.5351 0.5123], Lowest was [0.3025 0.0677 0.5351 0.5123]
Median for last 10 epochs: [0.3974 0.073  0.5351 0.5241], Epochs since improvement 0
  3%|▎         | 17/500 [16:34<7:37:31, 56.84s/it]  4%|▎         | 18/500 [17:46<8:11:21, 61.17s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.28E+06, Train scatter: [0.3301 0.0719 0.5436 0.5174]
L1 regularization loss: 2.12E+00, L2 regularization loss: 4.98E-01
Test scatter: [0.3273 0.073  0.5351 0.518 ], Lowest was [0.3025 0.0677 0.5351 0.5123]
Median for last 10 epochs: [0.3913 0.073  0.5351 0.518 ], Epochs since improvement 2
  4%|▍         | 19/500 [18:32<7:35:01, 56.76s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.23E+06, Train scatter: [0.2562 0.0638 0.5435 0.4994]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.02E-01
Test scatter: [0.2539 0.0646 0.5349 0.4945], Lowest was [0.2539 0.0646 0.5349 0.4945]
Median for last 10 epochs: [0.3273 0.07   0.5351 0.5144], Epochs since improvement 0
  4%|▍         | 20/500 [19:50<8:25:47, 63.22s/it]  4%|▍         | 21/500 [20:37<7:44:55, 58.24s/it]  4%|▍         | 22/500 [21:48<8:15:26, 62.19s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.17E+06, Train scatter: [0.2185 0.0624 0.5433 0.5049]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.06E-01
Test scatter: [0.2233 0.0633 0.5348 0.504 ], Lowest was [0.2233 0.0633 0.5348 0.4945]
Median for last 10 epochs: [0.3025 0.0677 0.5351 0.5123], Epochs since improvement 0
  5%|▍         | 23/500 [22:35<7:37:29, 57.55s/it]  5%|▍         | 24/500 [23:47<8:11:14, 61.92s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.12E+06, Train scatter: [0.2471 0.062  0.5432 0.4899]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.2532 0.0623 0.5347 0.4837], Lowest was [0.2233 0.0623 0.5347 0.4837]
Median for last 10 epochs: [0.2539 0.0646 0.5349 0.504 ], Epochs since improvement 0
  5%|▌         | 25/500 [24:34<7:33:58, 57.34s/it]  5%|▌         | 26/500 [25:45<8:06:35, 61.59s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.10E+06, Train scatter: [0.1971 0.0626 0.543  0.4938]
L1 regularization loss: 2.16E+00, L2 regularization loss: 5.17E-01
Test scatter: [0.2076 0.0626 0.5345 0.4875], Lowest was [0.2076 0.0623 0.5345 0.4837]
Median for last 10 epochs: [0.2532 0.0633 0.5348 0.4945], Epochs since improvement 0
  5%|▌         | 27/500 [26:32<7:30:18, 57.12s/it]  6%|▌         | 28/500 [27:43<8:03:05, 61.41s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.08E+06, Train scatter: [0.2169 0.0601 0.543  0.492 ]
L1 regularization loss: 2.19E+00, L2 regularization loss: 5.24E-01
Test scatter: [0.2251 0.0606 0.5345 0.4874], Lowest was [0.2076 0.0606 0.5345 0.4837]
Median for last 10 epochs: [0.2251 0.0626 0.5347 0.4875], Epochs since improvement 0
  6%|▌         | 29/500 [28:30<7:26:52, 56.93s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.05E+06, Train scatter: [0.3797 0.0638 0.543  0.4952]
L1 regularization loss: 2.21E+00, L2 regularization loss: 5.32E-01
Test scatter: [0.376  0.064  0.5345 0.4879], Lowest was [0.2076 0.0606 0.5345 0.4837]
Median for last 10 epochs: [0.2251 0.0626 0.5345 0.4875], Epochs since improvement 2
  6%|▌         | 30/500 [29:48<8:15:45, 63.29s/it]  6%|▌         | 31/500 [30:35<7:35:39, 58.29s/it]  6%|▋         | 32/500 [31:47<8:07:08, 62.45s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.03E+06, Train scatter: [0.1939 0.0593 0.5429 0.4869]
L1 regularization loss: 2.24E+00, L2 regularization loss: 5.43E-01
Test scatter: [0.1994 0.0592 0.5344 0.4788], Lowest was [0.1994 0.0592 0.5344 0.4788]
Median for last 10 epochs: [0.2251 0.0623 0.5345 0.4874], Epochs since improvement 0
  7%|▋         | 33/500 [32:34<7:29:06, 57.70s/it]  7%|▋         | 34/500 [33:44<7:57:10, 61.44s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.00E+06, Train scatter: [0.253  0.0653 0.543  0.4944]
L1 regularization loss: 2.26E+00, L2 regularization loss: 5.53E-01
Test scatter: [0.2549 0.0657 0.5345 0.4885], Lowest was [0.1994 0.0592 0.5344 0.4788]
Median for last 10 epochs: [0.2251 0.0626 0.5345 0.4875], Epochs since improvement 2
  7%|▋         | 35/500 [34:30<7:21:59, 57.03s/it]  7%|▋         | 36/500 [35:42<7:54:54, 61.41s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.98E+06, Train scatter: [0.2371 0.0572 0.5426 0.4779]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.61E-01
Test scatter: [0.2444 0.0583 0.5342 0.4756], Lowest was [0.1994 0.0583 0.5342 0.4756]
Median for last 10 epochs: [0.2444 0.0606 0.5345 0.4874], Epochs since improvement 0
  7%|▋         | 37/500 [36:29<7:19:28, 56.95s/it]  8%|▊         | 38/500 [37:39<7:49:53, 61.03s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.97E+06, Train scatter: [0.1982 0.0569 0.5424 0.4753]
L1 regularization loss: 2.30E+00, L2 regularization loss: 5.74E-01
Test scatter: [0.2016 0.0567 0.534  0.4693], Lowest was [0.1994 0.0567 0.534  0.4693]
Median for last 10 epochs: [0.2444 0.0592 0.5344 0.4788], Epochs since improvement 0
  8%|▊         | 39/500 [38:26<7:15:48, 56.72s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.01E+06, Train scatter: [0.2254 0.0775 0.542  0.5031]
L1 regularization loss: 2.37E+00, L2 regularization loss: 6.02E-01
Test scatter: [0.2327 0.0772 0.5335 0.4969], Lowest was [0.1994 0.0567 0.5335 0.4693]
Median for last 10 epochs: [0.2327 0.0592 0.5342 0.4788], Epochs since improvement 0
  8%|▊         | 40/500 [39:43<8:02:13, 62.90s/it]  8%|▊         | 41/500 [40:30<7:23:58, 58.04s/it]  8%|▊         | 42/500 [41:40<7:51:53, 61.82s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.99E+06, Train scatter: [0.4293 0.1064 0.5411 0.5409]
L1 regularization loss: 2.40E+00, L2 regularization loss: 6.21E-01
Test scatter: [0.4232 0.104  0.5327 0.5328], Lowest was [0.1994 0.0567 0.5327 0.4693]
Median for last 10 epochs: [0.2444 0.0657 0.534  0.4885], Epochs since improvement 0
  9%|▊         | 43/500 [42:27<7:16:10, 57.27s/it]  9%|▉         | 44/500 [43:39<7:49:26, 61.77s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.94E+06, Train scatter: [0.3921 0.0578 0.5384 0.4739]
L1 regularization loss: 2.44E+00, L2 regularization loss: 6.47E-01
Test scatter: [0.3852 0.058  0.53   0.4669], Lowest was [0.1994 0.0567 0.53   0.4669]
Median for last 10 epochs: [0.2444 0.0583 0.5335 0.4756], Epochs since improvement 0
  9%|▉         | 45/500 [44:26<7:14:02, 57.24s/it]  9%|▉         | 46/500 [45:38<7:45:28, 61.52s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.29E+06, Train scatter: [0.9344 0.1272 0.5438 0.974 ]
L1 regularization loss: 2.64E+00, L2 regularization loss: 7.26E-01
Test scatter: [0.9189 0.1267 0.5352 0.9651], Lowest was [0.1994 0.0567 0.53   0.4669]
Median for last 10 epochs: [0.3852 0.0772 0.5335 0.4969], Epochs since improvement 2
  9%|▉         | 47/500 [46:24<7:10:45, 57.05s/it] 10%|▉         | 48/500 [47:35<7:40:16, 61.10s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 5.29E+06, Train scatter: [0.9347 0.1624 0.5441 0.9753]
L1 regularization loss: 3.34E+00, L2 regularization loss: 1.12E+00
Test scatter: [0.9192 0.159  0.5355 0.9686], Lowest was [0.1994 0.0567 0.53   0.4669]
Median for last 10 epochs: [0.4232 0.104  0.5335 0.5328], Epochs since improvement 4
 10%|▉         | 49/500 [48:21<7:06:45, 56.78s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 4.19E+06, Train scatter: [0.9255 0.1309 0.544  0.8921]
L1 regularization loss: 3.37E+00, L2 regularization loss: 1.18E+00
Test scatter: [0.9101 0.1293 0.5355 0.8783], Lowest was [0.1994 0.0567 0.53   0.4669]
Median for last 10 epochs: [0.9101 0.1267 0.5352 0.8783], Epochs since improvement 6
 10%|█         | 50/500 [49:38<7:50:48, 62.77s/it] 10%|█         | 51/500 [50:25<7:13:30, 57.93s/it] 10%|█         | 52/500 [51:36<7:42:09, 61.90s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.71E+06, Train scatter: [0.6417 0.1221 0.5438 0.8207]
L1 regularization loss: 3.37E+00, L2 regularization loss: 1.20E+00
Test scatter: [0.6299 0.121  0.5352 0.8223], Lowest was [0.1994 0.0567 0.53   0.4669]
Median for last 10 epochs: [0.9101 0.1267 0.5352 0.8783], Epochs since improvement 8
 11%|█         | 53/500 [52:23<7:07:06, 57.33s/it] 11%|█         | 54/500 [53:33<7:34:21, 61.12s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.60E+06, Train scatter: [0.6113 0.1285 0.5437 0.7638]
L1 regularization loss: 3.38E+00, L2 regularization loss: 1.23E+00
Test scatter: [0.6049 0.1267 0.5351 0.7637], Lowest was [0.1994 0.0567 0.53   0.4669]
Median for last 10 epochs: [0.9101 0.1267 0.5352 0.8783], Epochs since improvement 10
 11%|█         | 55/500 [54:19<7:01:04, 56.77s/it] 11%|█         | 56/500 [55:30<7:30:08, 60.83s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.52E+06, Train scatter: [0.5136 0.1295 0.5423 0.7535]
L1 regularization loss: 3.40E+00, L2 regularization loss: 1.26E+00
Test scatter: [0.5121 0.1276 0.5338 0.753 ], Lowest was [0.1994 0.0567 0.53   0.4669]
Median for last 10 epochs: [0.6299 0.1276 0.5352 0.8223], Epochs since improvement 12
 11%|█▏        | 57/500 [56:16<6:57:40, 56.57s/it] 12%|█▏        | 58/500 [57:28<7:29:26, 61.01s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.44E+06, Train scatter: [0.5041 0.1164 0.5393 0.6616]
L1 regularization loss: 3.42E+00, L2 regularization loss: 1.32E+00
Test scatter: [0.4938 0.1138 0.5308 0.6522], Lowest was [0.1994 0.0567 0.53   0.4669]
Median for last 10 epochs: [0.6049 0.1267 0.5351 0.7637], Epochs since improvement 14
 12%|█▏        | 59/500 [58:14<6:57:02, 56.74s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.35E+06, Train scatter: [0.5445 0.1098 0.5346 0.6398]
L1 regularization loss: 3.45E+00, L2 regularization loss: 1.37E+00
Test scatter: [0.5546 0.1099 0.5263 0.6511], Lowest was [0.1994 0.0567 0.5263 0.4669]
Median for last 10 epochs: [0.5546 0.121  0.5338 0.753 ], Epochs since improvement 0
 12%|█▏        | 60/500 [59:32<7:41:41, 62.96s/it] 12%|█▏        | 61/500 [1:00:18<7:05:00, 58.09s/it] 12%|█▏        | 62/500 [1:01:29<7:32:04, 61.93s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.38E+06, Train scatter: [0.562  0.1295 0.5442 0.8441]
L1 regularization loss: 3.50E+00, L2 regularization loss: 1.45E+00
Test scatter: [0.5606 0.1274 0.5356 0.8349], Lowest was [0.1994 0.0567 0.5263 0.4669]
Median for last 10 epochs: [0.5546 0.1267 0.5338 0.753 ], Epochs since improvement 2
 13%|█▎        | 63/500 [1:02:16<6:57:50, 57.37s/it] 13%|█▎        | 64/500 [1:03:27<7:25:27, 61.30s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.30E+06, Train scatter: [0.4418 0.1147 0.5395 0.6913]
L1 regularization loss: 3.48E+00, L2 regularization loss: 1.44E+00
Test scatter: [0.445  0.1134 0.5311 0.6866], Lowest was [0.1994 0.0567 0.5263 0.4669]
Median for last 10 epochs: [0.5121 0.1138 0.5311 0.6866], Epochs since improvement 4
 13%|█▎        | 65/500 [1:04:13<6:52:35, 56.91s/it] 13%|█▎        | 66/500 [1:05:25<7:22:56, 61.24s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.21E+06, Train scatter: [0.5633 0.1013 0.5355 0.6426]
L1 regularization loss: 3.47E+00, L2 regularization loss: 1.48E+00
Test scatter: [0.5606 0.0995 0.5274 0.6348], Lowest was [0.1994 0.0567 0.5263 0.4669]
Median for last 10 epochs: [0.5546 0.1134 0.5308 0.6522], Epochs since improvement 6
 13%|█▎        | 67/500 [1:06:11<6:50:16, 56.85s/it] 14%|█▎        | 68/500 [1:07:23<7:21:28, 61.32s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.16E+06, Train scatter: [0.508  0.0918 0.5336 0.5937]
L1 regularization loss: 3.47E+00, L2 regularization loss: 1.54E+00
Test scatter: [0.4984 0.0906 0.5258 0.5936], Lowest was [0.1994 0.0567 0.5258 0.4669]
Median for last 10 epochs: [0.5546 0.1099 0.5274 0.6511], Epochs since improvement 0
 14%|█▍        | 69/500 [1:08:09<6:48:26, 56.86s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.08E+06, Train scatter: [0.444  0.0841 0.5302 0.5589]
L1 regularization loss: 3.52E+00, L2 regularization loss: 1.65E+00
Test scatter: [0.4317 0.0818 0.5223 0.5524], Lowest was [0.1994 0.0567 0.5223 0.4669]
Median for last 10 epochs: [0.4984 0.0995 0.5274 0.6348], Epochs since improvement 0
 14%|█▍        | 70/500 [1:09:30<7:38:57, 64.04s/it] 14%|█▍        | 71/500 [1:10:17<7:00:54, 58.87s/it] 14%|█▍        | 72/500 [1:11:28<7:25:14, 62.42s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.04E+06, Train scatter: [0.6066 0.0866 0.53   0.5679]
L1 regularization loss: 3.53E+00, L2 regularization loss: 1.71E+00
Test scatter: [0.5968 0.0867 0.5223 0.5669], Lowest was [0.1994 0.0567 0.5223 0.4669]
Median for last 10 epochs: [0.4984 0.0906 0.5258 0.5936], Epochs since improvement 2
 15%|█▍        | 73/500 [1:12:14<6:50:16, 57.65s/it] 15%|█▍        | 74/500 [1:13:26<7:19:33, 61.91s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.09E+06, Train scatter: [0.5615 0.1195 0.5446 0.8213]
L1 regularization loss: 3.85E+00, L2 regularization loss: 1.91E+00
Test scatter: [0.5547 0.119  0.536  0.8147], Lowest was [0.1994 0.0567 0.5223 0.4669]
Median for last 10 epochs: [0.5547 0.0906 0.5258 0.5936], Epochs since improvement 4
 15%|█▌        | 75/500 [1:14:13<6:46:01, 57.32s/it] 15%|█▌        | 76/500 [1:15:24<7:14:34, 61.50s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.61E+06, Train scatter: [0.4576 0.087  0.4881 0.6687]
L1 regularization loss: 3.84E+00, L2 regularization loss: 1.96E+00
Test scatter: [0.4532 0.0878 0.4863 0.6574], Lowest was [0.1994 0.0567 0.4863 0.4669]
Median for last 10 epochs: [0.4984 0.0878 0.5223 0.5936], Epochs since improvement 0
 15%|█▌        | 77/500 [1:16:11<6:42:14, 57.06s/it] 16%|█▌        | 78/500 [1:17:21<7:10:28, 61.21s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 1.99E+06, Train scatter: [0.4292 0.0811 0.4614 0.5876]
L1 regularization loss: 3.84E+00, L2 regularization loss: 2.04E+00
Test scatter: [0.4272 0.0829 0.4645 0.5848], Lowest was [0.1994 0.0567 0.4645 0.4669]
Median for last 10 epochs: [0.4532 0.0867 0.5223 0.5848], Epochs since improvement 0
 16%|█▌        | 79/500 [1:18:08<6:38:44, 56.83s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 1.27E+06, Train scatter: [0.5167 0.0705 0.3592 0.5522]
L1 regularization loss: 3.87E+00, L2 regularization loss: 2.13E+00
Test scatter: [0.5011 0.0715 0.3595 0.5483], Lowest was [0.1994 0.0567 0.3595 0.4669]
Median for last 10 epochs: [0.5011 0.0867 0.4863 0.5848], Epochs since improvement 0
 16%|█▌        | 80/500 [1:19:26<7:22:29, 63.21s/it] 16%|█▌        | 81/500 [1:20:13<6:47:05, 58.29s/it] 16%|█▋        | 82/500 [1:21:25<7:14:12, 62.33s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 9.38E+05, Train scatter: [0.4546 0.0639 0.3177 0.5293]
L1 regularization loss: 3.86E+00, L2 regularization loss: 2.20E+00
Test scatter: [0.4481 0.0647 0.3245 0.5288], Lowest was [0.1994 0.0567 0.3245 0.4669]
Median for last 10 epochs: [0.4532 0.0829 0.4645 0.5848], Epochs since improvement 0
 17%|█▋        | 83/500 [1:22:12<6:40:42, 57.65s/it] 17%|█▋        | 84/500 [1:23:23<7:08:27, 61.80s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 6.53E+05, Train scatter: [0.2743 0.0603 0.2855 0.5119]
L1 regularization loss: 3.83E+00, L2 regularization loss: 2.26E+00
Test scatter: [0.2909 0.061  0.29   0.5116], Lowest was [0.1994 0.0567 0.29   0.4669]
Median for last 10 epochs: [0.4481 0.0715 0.3595 0.5483], Epochs since improvement 0
 17%|█▋        | 85/500 [1:24:10<6:36:07, 57.27s/it] 17%|█▋        | 86/500 [1:25:21<7:04:11, 61.48s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 5.52E+05, Train scatter: [0.3821 0.0619 0.285  0.5121]
L1 regularization loss: 3.85E+00, L2 regularization loss: 2.37E+00
Test scatter: [0.3879 0.0615 0.3014 0.5132], Lowest was [0.1994 0.0567 0.29   0.4669]
Median for last 10 epochs: [0.4272 0.0647 0.3245 0.5288], Epochs since improvement 2
 17%|█▋        | 87/500 [1:26:08<6:33:03, 57.10s/it] 18%|█▊        | 88/500 [1:27:18<6:59:56, 61.16s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 4.58E+05, Train scatter: [0.2375 0.0548 0.2626 0.4983]
L1 regularization loss: 3.83E+00, L2 regularization loss: 2.48E+00
Test scatter: [0.2514 0.0544 0.2687 0.4941], Lowest was [0.1994 0.0544 0.2687 0.4669]
Median for last 10 epochs: [0.3879 0.0615 0.3014 0.5132], Epochs since improvement 0
 18%|█▊        | 89/500 [1:28:05<6:29:12, 56.82s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 9.82E+05, Train scatter: [0.416  0.058  0.2869 0.5088]
L1 regularization loss: 3.87E+00, L2 regularization loss: 2.61E+00
Test scatter: [0.4146 0.0578 0.2888 0.5029], Lowest was [0.1994 0.0544 0.2687 0.4669]
Median for last 10 epochs: [0.3879 0.061  0.29   0.5116], Epochs since improvement 2
 18%|█▊        | 90/500 [1:29:23<7:11:49, 63.19s/it] 18%|█▊        | 91/500 [1:30:10<6:37:12, 58.27s/it] 18%|█▊        | 92/500 [1:31:22<7:03:32, 62.29s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 4.03E+05, Train scatter: [0.2378 0.0559 0.2634 0.4926]
L1 regularization loss: 3.82E+00, L2 regularization loss: 2.68E+00
Test scatter: [0.247  0.0575 0.2731 0.4863], Lowest was [0.1994 0.0544 0.2687 0.4669]
Median for last 10 epochs: [0.2909 0.0578 0.2888 0.5029], Epochs since improvement 4
 19%|█▊        | 93/500 [1:32:08<6:30:46, 57.61s/it] 19%|█▉        | 94/500 [1:33:20<6:58:09, 61.80s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 3.36E+05, Train scatter: [0.2765 0.0586 0.2573 0.492 ]
L1 regularization loss: 3.83E+00, L2 regularization loss: 2.77E+00
Test scatter: [0.2845 0.059  0.2714 0.4889], Lowest was [0.1994 0.0544 0.2687 0.4669]
Median for last 10 epochs: [0.2845 0.0578 0.2731 0.4941], Epochs since improvement 6
 19%|█▉        | 95/500 [1:34:07<6:26:28, 57.26s/it] 19%|█▉        | 96/500 [1:35:18<6:53:23, 61.39s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.74E+05, Train scatter: [0.2275 0.0525 0.2407 0.4766]
L1 regularization loss: 3.80E+00, L2 regularization loss: 2.85E+00
Test scatter: [0.24   0.0536 0.25   0.4697], Lowest was [0.1994 0.0536 0.25   0.4669]
Median for last 10 epochs: [0.2514 0.0575 0.2714 0.4889], Epochs since improvement 0
 19%|█▉        | 97/500 [1:36:04<6:22:59, 57.02s/it] 20%|█▉        | 98/500 [1:37:16<6:51:11, 61.37s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.80E+05, Train scatter: [0.3374 0.0629 0.272  0.5079]
L1 regularization loss: 3.81E+00, L2 regularization loss: 2.94E+00
Test scatter: [0.3342 0.0627 0.2838 0.5036], Lowest was [0.1994 0.0536 0.25   0.4669]
Median for last 10 epochs: [0.2845 0.0578 0.2731 0.4889], Epochs since improvement 2
 20%|█▉        | 99/500 [1:38:03<6:20:43, 56.97s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 2.50E+05, Train scatter: [0.2057 0.0566 0.2441 0.4658]
L1 regularization loss: 3.81E+00, L2 regularization loss: 3.02E+00
Test scatter: [0.2137 0.0554 0.2531 0.4616], Lowest was [0.1994 0.0536 0.25   0.4616]
Median for last 10 epochs: [0.247  0.0575 0.2714 0.4863], Epochs since improvement 0
 20%|██        | 100/500 [1:39:20<7:00:20, 63.05s/it] 20%|██        | 101/500 [1:40:07<6:26:48, 58.17s/it] 20%|██        | 102/500 [1:41:18<6:51:46, 62.08s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 2.39E+05, Train scatter: [0.2149 0.0519 0.2455 0.4709]
L1 regularization loss: 3.79E+00, L2 regularization loss: 3.08E+00
Test scatter: [0.2178 0.0512 0.2536 0.4668], Lowest was [0.1994 0.0512 0.25   0.4616]
Median for last 10 epochs: [0.24   0.0554 0.2536 0.4697], Epochs since improvement 0
 21%|██        | 103/500 [1:42:04<6:19:55, 57.42s/it] 21%|██        | 104/500 [1:43:15<6:44:20, 61.27s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 2.05E+05, Train scatter: [0.2325 0.0523 0.2339 0.4609]
L1 regularization loss: 3.76E+00, L2 regularization loss: 3.13E+00
Test scatter: [0.2368 0.0542 0.2419 0.4595], Lowest was [0.1994 0.0512 0.2419 0.4595]
Median for last 10 epochs: [0.2368 0.0542 0.2531 0.4668], Epochs since improvement 0
 21%|██        | 105/500 [1:44:01<6:14:23, 56.87s/it] 21%|██        | 106/500 [1:45:12<6:39:54, 60.90s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 2.27E+05, Train scatter: [0.1986 0.0503 0.2307 0.4616]
L1 regularization loss: 3.77E+00, L2 regularization loss: 3.21E+00
Test scatter: [0.2064 0.0511 0.2404 0.4592], Lowest was [0.1994 0.0511 0.2404 0.4592]
Median for last 10 epochs: [0.2178 0.0542 0.2531 0.4616], Epochs since improvement 0
 21%|██▏       | 107/500 [1:45:58<6:10:42, 56.60s/it] 22%|██▏       | 108/500 [1:47:10<6:39:50, 61.20s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 1.53E+05, Train scatter: [0.2271 0.0568 0.2329 0.4618]
L1 regularization loss: 3.75E+00, L2 regularization loss: 3.26E+00
Test scatter: [0.236  0.0583 0.2432 0.4632], Lowest was [0.1994 0.0511 0.2404 0.4592]
Median for last 10 epochs: [0.2178 0.0542 0.2432 0.4616], Epochs since improvement 2
 22%|██▏       | 109/500 [1:47:57<6:10:36, 56.87s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 2.83E+05, Train scatter: [0.1962 0.0504 0.2386 0.4608]
L1 regularization loss: 4.01E+00, L2 regularization loss: 3.48E+00
Test scatter: [0.2005 0.051  0.2448 0.4591], Lowest was [0.1994 0.051  0.2404 0.4591]
Median for last 10 epochs: [0.2178 0.0512 0.2432 0.4595], Epochs since improvement 0
 22%|██▏       | 110/500 [1:49:15<6:50:49, 63.20s/it] 22%|██▏       | 111/500 [1:50:02<6:17:39, 58.25s/it] 22%|██▏       | 112/500 [1:51:12<6:40:44, 61.97s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.20E+05, Train scatter: [0.2268 0.0498 0.2299 0.4538]
L1 regularization loss: 3.88E+00, L2 regularization loss: 3.51E+00
Test scatter: [0.2265 0.0496 0.2397 0.4536], Lowest was [0.1994 0.0496 0.2397 0.4536]
Median for last 10 epochs: [0.2265 0.0511 0.2419 0.4592], Epochs since improvement 0
 23%|██▎       | 113/500 [1:51:59<6:09:55, 57.35s/it] 23%|██▎       | 114/500 [1:53:10<6:36:02, 61.56s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.16E+05, Train scatter: [0.1837 0.0475 0.2202 0.4434]
L1 regularization loss: 3.84E+00, L2 regularization loss: 3.57E+00
Test scatter: [0.1884 0.0479 0.2297 0.4406], Lowest was [0.1884 0.0479 0.2297 0.4406]
Median for last 10 epochs: [0.2064 0.051  0.2404 0.4591], Epochs since improvement 0
 23%|██▎       | 115/500 [1:53:57<6:06:33, 57.12s/it] 23%|██▎       | 116/500 [1:55:08<6:31:23, 61.16s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 5.63E+04, Train scatter: [0.1994 0.0517 0.2351 0.4486]
L1 regularization loss: 3.85E+00, L2 regularization loss: 3.64E+00
Test scatter: [0.2018 0.0507 0.2434 0.4468], Lowest was [0.1884 0.0479 0.2297 0.4406]
Median for last 10 epochs: [0.2018 0.0507 0.2432 0.4536], Epochs since improvement 2
 23%|██▎       | 117/500 [1:55:54<6:03:03, 56.88s/it] 24%|██▎       | 118/500 [1:57:05<6:28:03, 60.95s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 3.12E+05, Train scatter: [0.2202 0.0561 0.2437 0.4732]
L1 regularization loss: 4.36E+00, L2 regularization loss: 4.02E+00
Test scatter: [0.227  0.0558 0.2511 0.4706], Lowest was [0.1884 0.0479 0.2297 0.4406]
Median for last 10 epochs: [0.2018 0.0507 0.2434 0.4536], Epochs since improvement 4
 24%|██▍       | 119/500 [1:57:52<6:00:12, 56.73s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 8.23E+04, Train scatter: [0.2302 0.05   0.2283 0.477 ]
L1 regularization loss: 4.23E+00, L2 regularization loss: 4.07E+00
Test scatter: [0.235  0.0501 0.2364 0.4678], Lowest was [0.1884 0.0479 0.2297 0.4406]
Median for last 10 epochs: [0.2265 0.0501 0.2397 0.4536], Epochs since improvement 6
 24%|██▍       | 120/500 [1:59:09<6:37:55, 62.83s/it] 24%|██▍       | 121/500 [1:59:56<6:06:37, 58.04s/it] 24%|██▍       | 122/500 [2:01:06<6:29:41, 61.86s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 6.12E+04, Train scatter: [0.2321 0.0498 0.235  0.4632]
L1 regularization loss: 4.22E+00, L2 regularization loss: 4.15E+00
Test scatter: [0.2311 0.0499 0.2413 0.452 ], Lowest was [0.1884 0.0479 0.2297 0.4406]
Median for last 10 epochs: [0.227  0.0501 0.2413 0.452 ], Epochs since improvement 8
 25%|██▍       | 123/500 [2:01:53<6:00:41, 57.41s/it] 25%|██▍       | 124/500 [2:03:04<6:24:26, 61.35s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.79E+04, Train scatter: [0.2049 0.0495 0.2305 0.4478]
L1 regularization loss: 4.19E+00, L2 regularization loss: 4.20E+00
Test scatter: [0.2041 0.0486 0.2375 0.4451], Lowest was [0.1884 0.0479 0.2297 0.4406]
Median for last 10 epochs: [0.227  0.0501 0.2413 0.452 ], Epochs since improvement 10
 25%|██▌       | 125/500 [2:03:51<5:56:11, 56.99s/it] 25%|██▌       | 126/500 [2:05:01<6:20:10, 60.99s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 2.88E+05, Train scatter: [0.1951 0.0562 0.2418 0.4594]
L1 regularization loss: 4.78E+00, L2 regularization loss: 4.61E+00
Test scatter: [0.196  0.0557 0.2452 0.4547], Lowest was [0.1884 0.0479 0.2297 0.4406]
Median for last 10 epochs: [0.227  0.0501 0.2413 0.4547], Epochs since improvement 12
 25%|██▌       | 127/500 [2:05:48<5:53:16, 56.83s/it] 26%|██▌       | 128/500 [2:06:59<6:17:41, 60.92s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -1.64E+05, Train scatter: [0.1788 0.0466 0.2228 0.4349]
L1 regularization loss: 4.53E+00, L2 regularization loss: 4.56E+00
Test scatter: [0.1813 0.0462 0.2303 0.4287], Lowest was [0.1813 0.0462 0.2297 0.4287]
Median for last 10 epochs: [0.2041 0.0499 0.2375 0.452 ], Epochs since improvement 0
 26%|██▌       | 129/500 [2:07:46<5:50:41, 56.71s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -2.45E+05, Train scatter: [0.1796 0.045  0.2139 0.427 ]
L1 regularization loss: 4.46E+00, L2 regularization loss: 4.57E+00
Test scatter: [0.1814 0.0452 0.2207 0.4233], Lowest was [0.1813 0.0452 0.2207 0.4233]
Median for last 10 epochs: [0.196  0.0486 0.2375 0.4451], Epochs since improvement 0
 26%|██▌       | 130/500 [2:09:02<6:26:06, 62.61s/it] 26%|██▌       | 131/500 [2:09:49<5:56:05, 57.90s/it] 26%|██▋       | 132/500 [2:11:00<6:19:32, 61.88s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -3.14E+05, Train scatter: [0.1605 0.0496 0.2144 0.4304]
L1 regularization loss: 4.40E+00, L2 regularization loss: 4.57E+00
Test scatter: [0.1613 0.047  0.2231 0.4288], Lowest was [0.1613 0.0452 0.2207 0.4233]
Median for last 10 epochs: [0.1814 0.047  0.2303 0.4288], Epochs since improvement 0
 27%|██▋       | 133/500 [2:11:47<5:51:31, 57.47s/it] 27%|██▋       | 134/500 [2:13:03<6:23:47, 62.92s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: -3.61E+05, Train scatter: [0.157  0.0441 0.2088 0.416 ]
L1 regularization loss: 4.35E+00, L2 regularization loss: 4.59E+00
Test scatter: [0.1577 0.0441 0.2165 0.4129], Lowest was [0.1577 0.0441 0.2165 0.4129]
Median for last 10 epochs: [0.1813 0.0462 0.2231 0.4287], Epochs since improvement 0
 27%|██▋       | 135/500 [2:13:49<5:52:54, 58.01s/it] 27%|██▋       | 136/500 [2:15:00<6:15:36, 61.91s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: -3.80E+05, Train scatter: [0.2111 0.0505 0.2182 0.4309]
L1 regularization loss: 4.38E+00, L2 regularization loss: 4.64E+00
Test scatter: [0.2256 0.0522 0.2275 0.4318], Lowest was [0.1577 0.0441 0.2165 0.4129]
Median for last 10 epochs: [0.1813 0.0462 0.2231 0.4287], Epochs since improvement 2
 27%|██▋       | 137/500 [2:15:47<5:46:55, 57.34s/it] 28%|██▊       | 138/500 [2:16:58<6:10:42, 61.44s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -3.94E+05, Train scatter: [0.1584 0.0431 0.2111 0.413 ]
L1 regularization loss: 4.42E+00, L2 regularization loss: 4.73E+00
Test scatter: [0.1561 0.0435 0.219  0.4101], Lowest was [0.1561 0.0435 0.2165 0.4101]
Median for last 10 epochs: [0.1613 0.0452 0.2207 0.4233], Epochs since improvement 0
 28%|██▊       | 139/500 [2:17:45<5:43:20, 57.06s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -3.99E+05, Train scatter: [0.1576 0.0419 0.2123 0.4133]
L1 regularization loss: 4.54E+00, L2 regularization loss: 4.85E+00
Test scatter: [0.1624 0.0418 0.2187 0.4067], Lowest was [0.1561 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1613 0.0441 0.219  0.4129], Epochs since improvement 0
 28%|██▊       | 140/500 [2:19:03<6:20:14, 63.37s/it] 28%|██▊       | 141/500 [2:19:50<5:50:18, 58.55s/it] 28%|██▊       | 142/500 [2:21:01<6:11:47, 62.31s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -3.98E+05, Train scatter: [0.2005 0.0538 0.233  0.4286]
L1 regularization loss: 4.76E+00, L2 regularization loss: 5.10E+00
Test scatter: [0.2    0.0555 0.2453 0.4305], Lowest was [0.1561 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1624 0.0441 0.219  0.4129], Epochs since improvement 2
 29%|██▊       | 143/500 [2:21:49<5:43:42, 57.77s/it] 29%|██▉       | 144/500 [2:23:00<6:06:53, 61.83s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: -4.00E+05, Train scatter: [0.1515 0.0461 0.2224 0.4145]
L1 regularization loss: 4.72E+00, L2 regularization loss: 5.17E+00
Test scatter: [0.1507 0.045  0.227  0.4108], Lowest was [0.1507 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1624 0.045  0.227  0.4108], Epochs since improvement 0
 29%|██▉       | 145/500 [2:23:47<5:39:43, 57.42s/it] 29%|██▉       | 146/500 [2:24:59<6:04:10, 61.73s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: -4.05E+05, Train scatter: [0.1845 0.0484 0.2254 0.4277]
L1 regularization loss: 4.80E+00, L2 regularization loss: 5.28E+00
Test scatter: [0.1807 0.0489 0.2369 0.4263], Lowest was [0.1507 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1624 0.045  0.227  0.4108], Epochs since improvement 2
 29%|██▉       | 147/500 [2:25:46<5:36:52, 57.26s/it] 30%|██▉       | 148/500 [2:26:56<5:59:42, 61.31s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: -3.94E+05, Train scatter: [0.1738 0.0462 0.2402 0.4199]
L1 regularization loss: 4.96E+00, L2 regularization loss: 5.47E+00
Test scatter: [0.1675 0.0465 0.2461 0.4133], Lowest was [0.1507 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1675 0.0465 0.2369 0.4133], Epochs since improvement 4
 30%|██▉       | 149/500 [2:27:43<5:32:56, 56.91s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: -3.93E+05, Train scatter: [0.1527 0.0436 0.219  0.4236]
L1 regularization loss: 5.23E+00, L2 regularization loss: 5.70E+00
Test scatter: [0.1448 0.043  0.2223 0.4134], Lowest was [0.1448 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1675 0.0465 0.2369 0.4134], Epochs since improvement 0
 30%|███       | 150/500 [2:29:01<6:08:02, 63.09s/it] 30%|███       | 151/500 [2:29:48<5:39:02, 58.29s/it] 30%|███       | 152/500 [2:30:59<6:00:39, 62.18s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: -1.96E+05, Train scatter: [0.2681 0.0761 0.3245 0.5249]
L1 regularization loss: 5.96E+00, L2 regularization loss: 6.67E+00
Test scatter: [0.2606 0.0747 0.325  0.5205], Lowest was [0.1448 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1675 0.0465 0.2369 0.4134], Epochs since improvement 2
 31%|███       | 153/500 [2:31:46<5:33:05, 57.60s/it] 31%|███       | 154/500 [2:32:57<5:55:55, 61.72s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: -3.62E+05, Train scatter: [0.1608 0.0483 0.2473 0.473 ]
L1 regularization loss: 5.78E+00, L2 regularization loss: 6.72E+00
Test scatter: [0.1591 0.0475 0.2489 0.469 ], Lowest was [0.1448 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1675 0.0475 0.2461 0.4263], Epochs since improvement 4
 31%|███       | 155/500 [2:33:44<5:29:31, 57.31s/it] 31%|███       | 156/500 [2:34:55<5:52:01, 61.40s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: -3.87E+05, Train scatter: [0.1749 0.044  0.2343 0.4256]
L1 regularization loss: 5.63E+00, L2 regularization loss: 6.66E+00
Test scatter: [0.1702 0.043  0.2354 0.4154], Lowest was [0.1448 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1675 0.0465 0.2461 0.4154], Epochs since improvement 6
 31%|███▏      | 157/500 [2:35:42<5:26:28, 57.11s/it] 32%|███▏      | 158/500 [2:36:54<5:49:47, 61.37s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: -3.99E+05, Train scatter: [0.1525 0.0437 0.2346 0.4217]
L1 regularization loss: 5.56E+00, L2 regularization loss: 6.60E+00
Test scatter: [0.1488 0.0426 0.2363 0.4113], Lowest was [0.1448 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1591 0.043  0.2363 0.4154], Epochs since improvement 8
 32%|███▏      | 159/500 [2:37:41<5:24:13, 57.05s/it]Epoch: 160 done with learning rate 9.05E-03, Train loss: -3.80E+05, Train scatter: [0.3042 0.0443 0.2235 0.4468]
L1 regularization loss: 5.54E+00, L2 regularization loss: 6.69E+00
Test scatter: [0.2976 0.0432 0.2235 0.4332], Lowest was [0.1448 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1702 0.0432 0.2363 0.4332], Epochs since improvement 10
 32%|███▏      | 160/500 [2:38:59<5:59:36, 63.46s/it] 32%|███▏      | 161/500 [2:39:46<5:30:32, 58.50s/it] 32%|███▏      | 162/500 [2:40:57<5:51:30, 62.40s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: -4.07E+05, Train scatter: [0.1826 0.044  0.2357 0.4324]
L1 regularization loss: 5.51E+00, L2 regularization loss: 6.75E+00
Test scatter: [0.1802 0.0437 0.2371 0.4272], Lowest was [0.1448 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1702 0.0432 0.2363 0.4272], Epochs since improvement 12
 33%|███▎      | 163/500 [2:41:44<5:24:02, 57.69s/it] 33%|███▎      | 164/500 [2:42:55<5:44:41, 61.55s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: -4.01E+05, Train scatter: [0.153  0.0445 0.2423 0.4602]
L1 regularization loss: 5.74E+00, L2 regularization loss: 6.88E+00
Test scatter: [0.1494 0.0438 0.2434 0.456 ], Lowest was [0.1448 0.0418 0.2165 0.4067]
Median for last 10 epochs: [0.1702 0.0432 0.2363 0.4272], Epochs since improvement 14
 33%|███▎      | 165/500 [2:43:41<5:18:51, 57.11s/it] 33%|███▎      | 166/500 [2:44:53<5:42:06, 61.46s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: -4.15E+05, Train scatter: [0.1723 0.0413 0.2228 0.4234]
L1 regularization loss: 5.62E+00, L2 regularization loss: 6.88E+00
Test scatter: [0.1659 0.0404 0.2233 0.4186], Lowest was [0.1448 0.0404 0.2165 0.4067]
Median for last 10 epochs: [0.1659 0.0432 0.2363 0.4272], Epochs since improvement 0
 33%|███▎      | 167/500 [2:45:40<5:16:45, 57.07s/it] 34%|███▎      | 168/500 [2:46:51<5:39:48, 61.41s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: -4.31E+05, Train scatter: [0.2531 0.041  0.2157 0.4216]
L1 regularization loss: 5.55E+00, L2 regularization loss: 6.86E+00
Test scatter: [0.2469 0.0406 0.2188 0.4146], Lowest was [0.1448 0.0404 0.2165 0.4067]
Median for last 10 epochs: [0.1802 0.0432 0.2235 0.4272], Epochs since improvement 2
 34%|███▍      | 169/500 [2:47:38<5:14:33, 57.02s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -4.26E+05, Train scatter: [0.1866 0.0464 0.2358 0.4276]
L1 regularization loss: 5.71E+00, L2 regularization loss: 6.94E+00
Test scatter: [0.1849 0.0456 0.2371 0.4212], Lowest was [0.1448 0.0404 0.2165 0.4067]
Median for last 10 epochs: [0.1802 0.0437 0.2371 0.4212], Epochs since improvement 4
 34%|███▍      | 170/500 [2:48:57<5:49:07, 63.48s/it] 34%|███▍      | 171/500 [2:49:44<5:21:05, 58.56s/it] 34%|███▍      | 172/500 [2:50:54<5:38:57, 62.01s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -4.29E+05, Train scatter: [0.1498 0.0433 0.2253 0.4261]
L1 regularization loss: 5.61E+00, L2 regularization loss: 6.94E+00
Test scatter: [0.1488 0.043  0.2292 0.4168], Lowest was [0.1448 0.0404 0.2165 0.4067]
Median for last 10 epochs: [0.1659 0.043  0.2292 0.4186], Epochs since improvement 6
 35%|███▍      | 173/500 [2:51:41<5:13:33, 57.53s/it] 35%|███▍      | 174/500 [2:52:52<5:34:19, 61.53s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -4.26E+05, Train scatter: [0.1437 0.0402 0.2119 0.4112]
L1 regularization loss: 5.75E+00, L2 regularization loss: 7.07E+00
Test scatter: [0.1392 0.0398 0.2143 0.4027], Lowest was [0.1392 0.0398 0.2143 0.4027]
Median for last 10 epochs: [0.1659 0.0406 0.2233 0.4168], Epochs since improvement 0
 35%|███▌      | 175/500 [2:53:38<5:09:13, 57.09s/it] 35%|███▌      | 176/500 [2:54:49<5:30:08, 61.14s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -3.95E+05, Train scatter: [0.1311 0.0419 0.2291 0.4182]
L1 regularization loss: 5.84E+00, L2 regularization loss: 7.20E+00
Test scatter: [0.1276 0.0415 0.2312 0.4102], Lowest was [0.1276 0.0398 0.2143 0.4027]
Median for last 10 epochs: [0.1488 0.0415 0.2292 0.4146], Epochs since improvement 0
 35%|███▌      | 177/500 [2:55:36<5:06:01, 56.85s/it] 36%|███▌      | 178/500 [2:56:48<5:29:18, 61.36s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -4.31E+05, Train scatter: [0.1221 0.0424 0.2204 0.4162]
L1 regularization loss: 5.79E+00, L2 regularization loss: 7.17E+00
Test scatter: [0.1202 0.0415 0.221  0.4065], Lowest was [0.1202 0.0398 0.2143 0.4027]
Median for last 10 epochs: [0.1392 0.0415 0.2292 0.4102], Epochs since improvement 0
 36%|███▌      | 179/500 [2:57:35<5:04:51, 56.98s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -4.41E+05, Train scatter: [0.1485 0.0433 0.2183 0.4188]
L1 regularization loss: 5.83E+00, L2 regularization loss: 7.19E+00
Test scatter: [0.1419 0.0426 0.22   0.4099], Lowest was [0.1202 0.0398 0.2143 0.4027]
Median for last 10 epochs: [0.1392 0.0415 0.221  0.4099], Epochs since improvement 2
 36%|███▌      | 180/500 [2:58:51<5:35:36, 62.93s/it] 36%|███▌      | 181/500 [2:59:38<5:08:59, 58.12s/it] 36%|███▋      | 182/500 [3:00:49<5:27:40, 61.82s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -4.30E+05, Train scatter: [0.1356 0.0402 0.2093 0.4075]
L1 regularization loss: 5.90E+00, L2 regularization loss: 7.27E+00
Test scatter: [0.1329 0.0398 0.2101 0.3993], Lowest was [0.1202 0.0398 0.2101 0.3993]
Median for last 10 epochs: [0.1329 0.0415 0.22   0.4065], Epochs since improvement 0
 37%|███▋      | 183/500 [3:01:35<5:02:23, 57.24s/it] 37%|███▋      | 184/500 [3:02:46<5:23:30, 61.43s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -3.88E+05, Train scatter: [0.3428 0.0417 0.2345 0.4107]
L1 regularization loss: 6.38E+00, L2 regularization loss: 7.68E+00
Test scatter: [0.3338 0.0411 0.236  0.4049], Lowest was [0.1202 0.0398 0.2101 0.3993]
Median for last 10 epochs: [0.1329 0.0415 0.221  0.4065], Epochs since improvement 2
 37%|███▋      | 185/500 [3:03:33<4:59:33, 57.06s/it] 37%|███▋      | 186/500 [3:04:44<5:19:45, 61.10s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -4.36E+05, Train scatter: [0.2406 0.0423 0.2121 0.4166]
L1 regularization loss: 6.19E+00, L2 regularization loss: 7.58E+00
Test scatter: [0.2361 0.0416 0.213  0.4061], Lowest was [0.1202 0.0398 0.2101 0.3993]
Median for last 10 epochs: [0.1419 0.0415 0.22   0.4061], Epochs since improvement 4
 37%|███▋      | 187/500 [3:05:31<4:56:41, 56.87s/it] 38%|███▊      | 188/500 [3:06:41<5:16:39, 60.90s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -4.30E+05, Train scatter: [0.1413 0.042  0.2245 0.426 ]
L1 regularization loss: 6.32E+00, L2 regularization loss: 7.61E+00
Test scatter: [0.1393 0.0416 0.2258 0.4175], Lowest was [0.1202 0.0398 0.2101 0.3993]
Median for last 10 epochs: [0.1419 0.0416 0.22   0.4061], Epochs since improvement 6
 38%|███▊      | 189/500 [3:07:28<4:54:16, 56.77s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -4.58E+05, Train scatter: [0.12   0.0386 0.2089 0.3991]
L1 regularization loss: 6.12E+00, L2 regularization loss: 7.56E+00
Test scatter: [0.1213 0.0382 0.2115 0.3911], Lowest was [0.1202 0.0382 0.2101 0.3911]
Median for last 10 epochs: [0.1393 0.0411 0.213  0.4049], Epochs since improvement 0
 38%|███▊      | 190/500 [3:08:45<5:24:14, 62.76s/it] 38%|███▊      | 191/500 [3:09:32<4:59:22, 58.13s/it] 38%|███▊      | 192/500 [3:10:43<5:17:31, 61.86s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -4.63E+05, Train scatter: [0.1306 0.0461 0.2213 0.4135]
L1 regularization loss: 6.13E+00, L2 regularization loss: 7.57E+00
Test scatter: [0.1297 0.0449 0.2222 0.4026], Lowest was [0.1202 0.0382 0.2101 0.3911]
Median for last 10 epochs: [0.1393 0.0416 0.2222 0.4049], Epochs since improvement 2
 39%|███▊      | 193/500 [3:11:30<4:53:35, 57.38s/it] 39%|███▉      | 194/500 [3:12:41<5:13:52, 61.54s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -4.52E+05, Train scatter: [0.3181 0.056  0.2675 0.5422]
L1 regularization loss: 6.20E+00, L2 regularization loss: 7.60E+00
Test scatter: [0.3069 0.0543 0.2638 0.5353], Lowest was [0.1202 0.0382 0.2101 0.3911]
Median for last 10 epochs: [0.1393 0.0416 0.2222 0.4061], Epochs since improvement 4
 39%|███▉      | 195/500 [3:13:28<4:50:03, 57.06s/it] 39%|███▉      | 196/500 [3:14:39<5:10:46, 61.34s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -4.77E+05, Train scatter: [0.1182 0.038  0.2025 0.3915]
L1 regularization loss: 6.15E+00, L2 regularization loss: 7.58E+00
Test scatter: [0.1217 0.0377 0.2054 0.3829], Lowest was [0.1202 0.0377 0.2054 0.3829]
Median for last 10 epochs: [0.1297 0.0416 0.2222 0.4026], Epochs since improvement 0
 39%|███▉      | 197/500 [3:15:26<4:47:35, 56.95s/it] 40%|███▉      | 198/500 [3:16:36<5:06:51, 60.96s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -4.78E+05, Train scatter: [0.1228 0.0398 0.2054 0.3919]
L1 regularization loss: 6.15E+00, L2 regularization loss: 7.60E+00
Test scatter: [0.1234 0.0395 0.2098 0.3843], Lowest was [0.1202 0.0377 0.2054 0.3829]
Median for last 10 epochs: [0.1234 0.0395 0.2115 0.3911], Epochs since improvement 2
 40%|███▉      | 199/500 [3:17:23<4:44:32, 56.72s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -4.82E+05, Train scatter: [0.1229 0.0382 0.2054 0.3923]
L1 regularization loss: 6.19E+00, L2 regularization loss: 7.62E+00
Test scatter: [0.1232 0.0378 0.2076 0.3828], Lowest was [0.1202 0.0377 0.2054 0.3828]
Median for last 10 epochs: [0.1234 0.0395 0.2098 0.3843], Epochs since improvement 0
 40%|████      | 200/500 [3:18:42<5:17:23, 63.48s/it] 40%|████      | 201/500 [3:19:29<4:51:28, 58.49s/it] 40%|████      | 202/500 [3:20:40<5:09:41, 62.35s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -4.79E+05, Train scatter: [0.1173 0.0391 0.2114 0.3954]
L1 regularization loss: 6.26E+00, L2 regularization loss: 7.67E+00
Test scatter: [0.1173 0.0386 0.2125 0.3895], Lowest was [0.1173 0.0377 0.2054 0.3828]
Median for last 10 epochs: [0.1232 0.0386 0.2098 0.3843], Epochs since improvement 0
 41%|████      | 203/500 [3:21:27<4:45:57, 57.77s/it] 41%|████      | 204/500 [3:22:39<5:05:54, 62.01s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -4.87E+05, Train scatter: [0.1331 0.0387 0.22   0.4118]
L1 regularization loss: 6.36E+00, L2 regularization loss: 7.74E+00
Test scatter: [0.1348 0.0386 0.2212 0.4068], Lowest was [0.1173 0.0377 0.2054 0.3828]
Median for last 10 epochs: [0.1232 0.0386 0.2098 0.3843], Epochs since improvement 2
 41%|████      | 205/500 [3:23:26<4:42:11, 57.40s/it] 41%|████      | 206/500 [3:24:37<5:01:22, 61.51s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -4.93E+05, Train scatter: [0.1274 0.0366 0.2    0.3874]
L1 regularization loss: 6.41E+00, L2 regularization loss: 7.79E+00
Test scatter: [0.1279 0.0363 0.2022 0.3779], Lowest was [0.1173 0.0363 0.2022 0.3779]
Median for last 10 epochs: [0.1234 0.0386 0.2098 0.3843], Epochs since improvement 0
 41%|████▏     | 207/500 [3:25:24<4:39:11, 57.17s/it] 42%|████▏     | 208/500 [3:26:35<4:58:11, 61.27s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -4.87E+05, Train scatter: [0.1196 0.0389 0.2099 0.3876]
L1 regularization loss: 6.51E+00, L2 regularization loss: 7.86E+00
Test scatter: [0.1195 0.0388 0.2137 0.38  ], Lowest was [0.1173 0.0363 0.2022 0.3779]
Median for last 10 epochs: [0.1232 0.0386 0.2125 0.3828], Epochs since improvement 2
 42%|████▏     | 209/500 [3:27:22<4:35:50, 56.87s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -4.94E+05, Train scatter: [0.118  0.0365 0.2013 0.3898]
L1 regularization loss: 6.65E+00, L2 regularization loss: 7.97E+00
Test scatter: [0.1195 0.0362 0.2037 0.3794], Lowest was [0.1173 0.0362 0.2022 0.3779]
Median for last 10 epochs: [0.1195 0.0386 0.2125 0.38  ], Epochs since improvement 0
 42%|████▏     | 210/500 [3:28:39<5:05:06, 63.13s/it] 42%|████▏     | 211/500 [3:29:26<4:40:29, 58.23s/it] 42%|████▏     | 212/500 [3:30:38<4:58:52, 62.26s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -4.86E+05, Train scatter: [0.1146 0.037  0.1971 0.382 ]
L1 regularization loss: 6.76E+00, L2 regularization loss: 8.05E+00
Test scatter: [0.1164 0.0366 0.2003 0.3731], Lowest was [0.1164 0.0362 0.2003 0.3731]
Median for last 10 epochs: [0.1195 0.0366 0.2037 0.3794], Epochs since improvement 0
 43%|████▎     | 213/500 [3:31:24<4:35:05, 57.51s/it] 43%|████▎     | 214/500 [3:32:36<4:54:05, 61.70s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: -5.02E+05, Train scatter: [0.1189 0.0387 0.203  0.3886]
L1 regularization loss: 6.86E+00, L2 regularization loss: 8.13E+00
Test scatter: [0.1199 0.0384 0.2041 0.3782], Lowest was [0.1164 0.0362 0.2003 0.3731]
Median for last 10 epochs: [0.1195 0.0366 0.2037 0.3782], Epochs since improvement 2
 43%|████▎     | 215/500 [3:33:23<4:32:07, 57.29s/it] 43%|████▎     | 216/500 [3:34:34<4:51:16, 61.54s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -4.76E+05, Train scatter: [0.1122 0.0375 0.2007 0.382 ]
L1 regularization loss: 7.01E+00, L2 regularization loss: 8.25E+00
Test scatter: [0.1179 0.0373 0.2027 0.3746], Lowest was [0.1164 0.0362 0.2003 0.3731]
Median for last 10 epochs: [0.1195 0.0373 0.2037 0.3782], Epochs since improvement 4
 43%|████▎     | 217/500 [3:35:21<4:29:46, 57.20s/it] 44%|████▎     | 218/500 [3:36:33<4:49:22, 61.57s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -5.06E+05, Train scatter: [0.1129 0.0362 0.2033 0.38  ]
L1 regularization loss: 7.08E+00, L2 regularization loss: 8.36E+00
Test scatter: [0.1157 0.0362 0.2056 0.3713], Lowest was [0.1157 0.0362 0.2003 0.3713]
Median for last 10 epochs: [0.1179 0.0366 0.2037 0.3746], Epochs since improvement 0
 44%|████▍     | 219/500 [3:37:20<4:27:42, 57.16s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -5.11E+05, Train scatter: [0.1079 0.0353 0.1977 0.3786]
L1 regularization loss: 7.18E+00, L2 regularization loss: 8.46E+00
Test scatter: [0.1108 0.0354 0.2004 0.3709], Lowest was [0.1108 0.0354 0.2003 0.3709]
Median for last 10 epochs: [0.1164 0.0366 0.2027 0.3731], Epochs since improvement 0
 44%|████▍     | 220/500 [3:38:38<4:55:29, 63.32s/it] 44%|████▍     | 221/500 [3:39:24<4:31:21, 58.36s/it] 44%|████▍     | 222/500 [3:40:35<4:47:10, 61.98s/it]Epoch: 222 done with learning rate 7.33E-03, Train loss: -5.18E+05, Train scatter: [0.1115 0.0352 0.1969 0.3783]
L1 regularization loss: 7.32E+00, L2 regularization loss: 8.57E+00
Test scatter: [0.1155 0.0353 0.1989 0.3713], Lowest was [0.1108 0.0353 0.1989 0.3709]
Median for last 10 epochs: [0.1157 0.0362 0.2027 0.3713], Epochs since improvement 0
 45%|████▍     | 223/500 [3:41:22<4:25:22, 57.48s/it] 45%|████▍     | 224/500 [3:42:33<4:43:19, 61.59s/it]Epoch: 224 done with learning rate 7.26E-03, Train loss: -5.01E+05, Train scatter: [0.1112 0.0373 0.1978 0.381 ]
L1 regularization loss: 7.47E+00, L2 regularization loss: 8.67E+00
Test scatter: [0.1149 0.0368 0.2004 0.3723], Lowest was [0.1108 0.0353 0.1989 0.3709]
Median for last 10 epochs: [0.1155 0.0362 0.2004 0.3713], Epochs since improvement 2
 45%|████▌     | 225/500 [3:43:20<4:22:31, 57.28s/it] 45%|████▌     | 226/500 [3:44:31<4:40:12, 61.36s/it]Epoch: 226 done with learning rate 7.20E-03, Train loss: -5.11E+05, Train scatter: [0.1124 0.0365 0.1954 0.3766]
L1 regularization loss: 7.58E+00, L2 regularization loss: 8.83E+00
Test scatter: [0.1146 0.0366 0.1986 0.3694], Lowest was [0.1108 0.0353 0.1986 0.3694]
Median for last 10 epochs: [0.1149 0.0362 0.2004 0.3713], Epochs since improvement 0
 45%|████▌     | 227/500 [3:45:18<4:19:04, 56.94s/it] 46%|████▌     | 228/500 [3:46:29<4:37:27, 61.20s/it]Epoch: 228 done with learning rate 7.13E-03, Train loss: -5.23E+05, Train scatter: [0.1034 0.036  0.1993 0.3743]
L1 regularization loss: 7.62E+00, L2 regularization loss: 8.92E+00
Test scatter: [0.1054 0.036  0.2029 0.368 ], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1146 0.036  0.2004 0.3709], Epochs since improvement 0
 46%|████▌     | 229/500 [3:47:16<4:17:05, 56.92s/it]Epoch: 230 done with learning rate 7.06E-03, Train loss: -2.93E+05, Train scatter: [0.3866 0.0529 0.2627 0.4795]
L1 regularization loss: 1.11E+01, L2 regularization loss: 1.08E+01
Test scatter: [0.3764 0.0528 0.2648 0.4783], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1149 0.0366 0.2004 0.3713], Epochs since improvement 2
 46%|████▌     | 230/500 [3:48:33<4:44:12, 63.16s/it] 46%|████▌     | 231/500 [3:49:20<4:21:06, 58.24s/it] 46%|████▋     | 232/500 [3:50:31<4:37:25, 62.11s/it]Epoch: 232 done with learning rate 6.99E-03, Train loss: -3.87E+05, Train scatter: [0.3428 0.0424 0.2289 0.4347]
L1 regularization loss: 1.11E+01, L2 regularization loss: 1.09E+01
Test scatter: [0.3333 0.042  0.2317 0.427 ], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1149 0.0368 0.2029 0.3723], Epochs since improvement 4
 47%|████▋     | 233/500 [3:51:18<4:16:20, 57.60s/it] 47%|████▋     | 234/500 [3:52:29<4:33:00, 61.58s/it]Epoch: 234 done with learning rate 6.93E-03, Train loss: -4.21E+05, Train scatter: [0.1809 0.0423 0.2382 0.4241]
L1 regularization loss: 1.12E+01, L2 regularization loss: 1.10E+01
Test scatter: [0.1731 0.0421 0.2398 0.4184], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1731 0.042  0.2317 0.4184], Epochs since improvement 6
 47%|████▋     | 235/500 [3:53:16<4:12:28, 57.16s/it] 47%|████▋     | 236/500 [3:54:27<4:30:14, 61.42s/it]Epoch: 236 done with learning rate 6.86E-03, Train loss: -4.29E+05, Train scatter: [0.1568 0.0404 0.2118 0.4023]
L1 regularization loss: 1.12E+01, L2 regularization loss: 1.11E+01
Test scatter: [0.1513 0.0401 0.2139 0.3923], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1731 0.042  0.2317 0.4184], Epochs since improvement 8
 47%|████▋     | 237/500 [3:55:14<4:09:52, 57.01s/it] 48%|████▊     | 238/500 [3:56:25<4:27:25, 61.24s/it]Epoch: 238 done with learning rate 6.79E-03, Train loss: -4.38E+05, Train scatter: [0.1268 0.0407 0.2228 0.4062]
L1 regularization loss: 1.12E+01, L2 regularization loss: 1.12E+01
Test scatter: [0.1243 0.0403 0.2252 0.3959], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1731 0.042  0.2317 0.4184], Epochs since improvement 10
 48%|████▊     | 239/500 [3:57:12<4:07:44, 56.95s/it]Epoch: 240 done with learning rate 6.72E-03, Train loss: -4.61E+05, Train scatter: [0.1545 0.0382 0.2101 0.3982]
L1 regularization loss: 1.12E+01, L2 regularization loss: 1.12E+01
Test scatter: [0.1481 0.0378 0.2118 0.3866], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1513 0.0403 0.2252 0.3959], Epochs since improvement 12
 48%|████▊     | 240/500 [3:58:30<4:34:13, 63.28s/it] 48%|████▊     | 241/500 [3:59:17<4:11:52, 58.35s/it] 48%|████▊     | 242/500 [4:00:29<4:27:46, 62.27s/it]Epoch: 242 done with learning rate 6.65E-03, Train loss: -4.69E+05, Train scatter: [0.1211 0.0396 0.211  0.399 ]
L1 regularization loss: 1.11E+01, L2 regularization loss: 1.13E+01
Test scatter: [0.1192 0.0389 0.2123 0.3867], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1481 0.0401 0.2139 0.3923], Epochs since improvement 14
 49%|████▊     | 243/500 [4:01:15<4:06:53, 57.64s/it] 49%|████▉     | 244/500 [4:02:27<4:23:32, 61.77s/it]Epoch: 244 done with learning rate 6.58E-03, Train loss: -4.73E+05, Train scatter: [0.1261 0.0392 0.2055 0.3969]
L1 regularization loss: 1.11E+01, L2 regularization loss: 1.13E+01
Test scatter: [0.1256 0.0389 0.2081 0.3862], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1256 0.0389 0.2123 0.3867], Epochs since improvement 16
 49%|████▉     | 245/500 [4:03:14<4:03:20, 57.26s/it] 49%|████▉     | 246/500 [4:04:25<4:20:09, 61.45s/it]Epoch: 246 done with learning rate 6.51E-03, Train loss: -4.66E+05, Train scatter: [0.1105 0.038  0.2022 0.3895]
L1 regularization loss: 1.11E+01, L2 regularization loss: 1.13E+01
Test scatter: [0.1088 0.0376 0.2045 0.3792], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1243 0.0389 0.2118 0.3866], Epochs since improvement 18
 49%|████▉     | 247/500 [4:05:12<4:00:34, 57.06s/it] 50%|████▉     | 248/500 [4:06:22<4:16:59, 61.19s/it]Epoch: 248 done with learning rate 6.44E-03, Train loss: -4.66E+05, Train scatter: [0.1273 0.0382 0.2042 0.3935]
L1 regularization loss: 1.11E+01, L2 regularization loss: 1.14E+01
Test scatter: [0.1222 0.0379 0.2071 0.3814], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1222 0.0379 0.2081 0.3862], Epochs since improvement 20
 50%|████▉     | 249/500 [4:07:09<3:57:56, 56.88s/it]Epoch: 250 done with learning rate 6.37E-03, Train loss: -4.84E+05, Train scatter: [0.1162 0.0416 0.2142 0.397 ]
L1 regularization loss: 1.11E+01, L2 regularization loss: 1.14E+01
Test scatter: [0.1149 0.041  0.2167 0.3862], Lowest was [0.1054 0.0353 0.1986 0.368 ]
Median for last 10 epochs: [0.1192 0.0389 0.2081 0.3862], Epochs since improvement 22
 50%|████▉     | 249/500 [4:08:26<4:10:26, 59.87s/it]
Exited after 250 epochs due to early stopping
14906.93 seconds spent training, 29.814 seconds per epoch. Processed 2336 trees per second
[0.11487097 0.04096721 0.21668199 0.38623804]
{'epoch_exit': 249, 'scatter_m_star': 0.114870965, 'lowest_m_star': 0.10542884, 'last20_m_star': 0.124945775, 'last10_m_star': 0.1191986, 'scatter_v_disk': 0.040967207, 'lowest_v_disk': 0.03534207, 'last20_v_disk': 0.039531752, 'last10_v_disk': 0.038871713, 'scatter_m_cold': 0.21668199, 'lowest_m_cold': 0.1985889, 'last20_m_cold': 0.21309423, 'last10_m_cold': 0.2080932, 'scatter_sfr_100': 0.38623804, 'lowest_sfr_100': 0.3679779, 'last20_sfr_100': 0.38667488, 'last10_sfr_100': 0.3862188}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_nxofmc
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:40<5:40:30, 40.94s/it]  0%|          | 2/500 [01:43<7:26:35, 53.81s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.01E+07, Train scatter: [0.9352 0.1712 0.5441 0.9954]
L1 regularization loss: 1.98E+00, L2 regularization loss: 3.76E-01
Test scatter: [0.9196 0.1672 0.5356 0.9851], Lowest was [0.9196 0.1672 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1672 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:24<6:34:57, 47.68s/it]  1%|          | 4/500 [03:27<7:24:00, 53.71s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.21E+07, Train scatter: [0.9352 0.1538 0.5441 0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.85E-01
Test scatter: [0.9196 0.1497 0.5355 0.9851], Lowest was [0.9196 0.1497 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1497 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:07<6:42:51, 48.83s/it]  1%|          | 6/500 [05:09<7:20:52, 53.55s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.70E+07, Train scatter: [0.9348 0.1065 0.544  0.9954]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.01E-01
Test scatter: [0.9192 0.1058 0.5354 0.985 ], Lowest was [0.9192 0.1058 0.5354 0.985 ]
Median for last 10 epochs: [0.9192 0.1058 0.5354 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [05:50<6:43:51, 49.15s/it]  2%|▏         | 8/500 [06:52<7:18:00, 53.41s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.32E+07, Train scatter: [0.9098 0.0916 0.5439 0.8046]
L1 regularization loss: 2.04E+00, L2 regularization loss: 4.27E-01
Test scatter: [0.8955 0.0921 0.5353 0.8104], Lowest was [0.8955 0.0921 0.5353 0.8104]
Median for last 10 epochs: [0.9074 0.0989 0.5354 0.8977], Epochs since improvement 0
  2%|▏         | 9/500 [07:33<6:43:48, 49.35s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 1.01E+07, Train scatter: [0.8096 0.097  0.5437 0.6417]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.61E-01
Test scatter: [0.7983 0.0963 0.5352 0.6417], Lowest was [0.7983 0.0921 0.5352 0.6417]
Median for last 10 epochs: [0.8955 0.0963 0.5353 0.8104], Epochs since improvement 0
  2%|▏         | 10/500 [08:42<7:33:50, 55.57s/it]  2%|▏         | 11/500 [09:23<6:55:30, 50.98s/it]  2%|▏         | 12/500 [10:25<7:22:54, 54.46s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.01E+06, Train scatter: [0.6711 0.0866 0.5437 0.5762]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.76E-01
Test scatter: [0.667  0.0865 0.5352 0.5735], Lowest was [0.667  0.0865 0.5352 0.5735]
Median for last 10 epochs: [0.8955 0.0963 0.5353 0.8104], Epochs since improvement 0
  3%|▎         | 13/500 [11:05<6:47:27, 50.20s/it]  3%|▎         | 14/500 [12:09<7:20:26, 54.38s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 5.47E+06, Train scatter: [0.5535 0.0848 0.5437 0.5645]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.87E-01
Test scatter: [0.5506 0.0844 0.5351 0.562 ], Lowest was [0.5506 0.0844 0.5351 0.562 ]
Median for last 10 epochs: [0.7983 0.0921 0.5352 0.6417], Epochs since improvement 0
  3%|▎         | 15/500 [12:50<6:45:28, 50.16s/it]  3%|▎         | 16/500 [13:53<7:16:14, 54.08s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.67E+06, Train scatter: [0.4663 0.0807 0.5436 0.5447]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.96E-01
Test scatter: [0.4614 0.0814 0.5351 0.5423], Lowest was [0.4614 0.0814 0.5351 0.5423]
Median for last 10 epochs: [0.667  0.0865 0.5352 0.5735], Epochs since improvement 0
  3%|▎         | 17/500 [14:33<6:42:24, 49.99s/it]  4%|▎         | 18/500 [15:36<7:12:36, 53.85s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.07E+06, Train scatter: [0.3588 0.077  0.5435 0.5467]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.02E-01
Test scatter: [0.3624 0.0775 0.535  0.5466], Lowest was [0.3624 0.0775 0.535  0.5423]
Median for last 10 epochs: [0.5506 0.0844 0.5351 0.562 ], Epochs since improvement 0
  4%|▍         | 19/500 [16:17<6:40:01, 49.90s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 4.20E+06, Train scatter: [0.4186 0.0773 0.5436 0.5284]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.07E-01
Test scatter: [0.4142 0.0771 0.535  0.5243], Lowest was [0.3624 0.0771 0.535  0.5243]
Median for last 10 epochs: [0.4614 0.0814 0.5351 0.5466], Epochs since improvement 0
  4%|▍         | 20/500 [17:27<7:26:29, 55.81s/it]  4%|▍         | 21/500 [18:07<6:48:49, 51.21s/it]  4%|▍         | 22/500 [19:11<7:18:08, 55.00s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.67E+06, Train scatter: [0.2761 0.075  0.5435 0.5198]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.2731 0.0752 0.535  0.5199], Lowest was [0.2731 0.0752 0.535  0.5199]
Median for last 10 epochs: [0.4142 0.0775 0.535  0.5423], Epochs since improvement 0
  5%|▍         | 23/500 [19:51<6:42:42, 50.66s/it]  5%|▍         | 24/500 [20:56<7:15:06, 54.85s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.58E+06, Train scatter: [0.2688 0.075  0.5435 0.518 ]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.15E-01
Test scatter: [0.2711 0.0748 0.535  0.5165], Lowest was [0.2711 0.0748 0.535  0.5165]
Median for last 10 epochs: [0.3624 0.0771 0.535  0.5243], Epochs since improvement 0
  5%|▌         | 25/500 [21:36<6:39:50, 50.51s/it]  5%|▌         | 26/500 [22:39<7:07:38, 54.13s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.48E+06, Train scatter: [0.3007 0.0735 0.5435 0.5486]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.18E-01
Test scatter: [0.3038 0.0735 0.5349 0.5493], Lowest was [0.2711 0.0735 0.5349 0.5165]
Median for last 10 epochs: [0.3038 0.0752 0.535  0.5243], Epochs since improvement 0
  5%|▌         | 27/500 [23:20<6:34:42, 50.07s/it]  6%|▌         | 28/500 [24:23<7:05:09, 54.05s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.44E+06, Train scatter: [0.2168 0.072  0.5435 0.5098]
L1 regularization loss: 2.16E+00, L2 regularization loss: 5.22E-01
Test scatter: [0.2223 0.0722 0.5349 0.5086], Lowest was [0.2223 0.0722 0.5349 0.5086]
Median for last 10 epochs: [0.2731 0.0748 0.535  0.5199], Epochs since improvement 0
  6%|▌         | 29/500 [25:04<6:32:26, 49.99s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.43E+06, Train scatter: [0.208  0.071  0.5433 0.5076]
L1 regularization loss: 2.17E+00, L2 regularization loss: 5.25E-01
Test scatter: [0.2104 0.0708 0.5348 0.5023], Lowest was [0.2104 0.0708 0.5348 0.5023]
Median for last 10 epochs: [0.2711 0.0735 0.5349 0.5165], Epochs since improvement 0
  6%|▌         | 30/500 [26:13<7:17:06, 55.80s/it]  6%|▌         | 31/500 [26:53<6:40:18, 51.21s/it]  6%|▋         | 32/500 [27:57<7:08:12, 54.90s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.37E+06, Train scatter: [0.2551 0.0698 0.5433 0.5248]
L1 regularization loss: 2.18E+00, L2 regularization loss: 5.28E-01
Test scatter: [0.261  0.0695 0.5348 0.522 ], Lowest was [0.2104 0.0695 0.5348 0.5023]
Median for last 10 epochs: [0.261  0.0722 0.5349 0.5165], Epochs since improvement 0
  7%|▋         | 33/500 [28:37<6:33:25, 50.55s/it]  7%|▋         | 34/500 [29:41<7:02:51, 54.44s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.34E+06, Train scatter: [0.2165 0.071  0.5432 0.5109]
L1 regularization loss: 2.19E+00, L2 regularization loss: 5.34E-01
Test scatter: [0.2192 0.0707 0.5347 0.5081], Lowest was [0.2104 0.0695 0.5347 0.5023]
Median for last 10 epochs: [0.2223 0.0708 0.5348 0.5086], Epochs since improvement 0
  7%|▋         | 35/500 [30:21<6:29:44, 50.29s/it]  7%|▋         | 36/500 [31:25<6:58:40, 54.14s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.34E+06, Train scatter: [0.2338 0.0693 0.5432 0.5047]
L1 regularization loss: 2.20E+00, L2 regularization loss: 5.40E-01
Test scatter: [0.2385 0.0691 0.5346 0.4995], Lowest was [0.2104 0.0691 0.5346 0.4995]
Median for last 10 epochs: [0.2223 0.0707 0.5348 0.5081], Epochs since improvement 0
  7%|▋         | 37/500 [32:05<6:26:19, 50.06s/it]  8%|▊         | 38/500 [33:09<6:57:01, 54.16s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.30E+06, Train scatter: [0.1942 0.0674 0.5431 0.5019]
L1 regularization loss: 2.21E+00, L2 regularization loss: 5.45E-01
Test scatter: [0.1973 0.0673 0.5345 0.4985], Lowest was [0.1973 0.0673 0.5345 0.4985]
Median for last 10 epochs: [0.2192 0.0695 0.5347 0.5023], Epochs since improvement 0
  8%|▊         | 39/500 [33:49<6:23:51, 49.96s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.30E+06, Train scatter: [0.2747 0.0723 0.543  0.525 ]
L1 regularization loss: 2.26E+00, L2 regularization loss: 5.57E-01
Test scatter: [0.2719 0.0709 0.5345 0.5242], Lowest was [0.1973 0.0673 0.5345 0.4985]
Median for last 10 epochs: [0.2385 0.0695 0.5346 0.5081], Epochs since improvement 0
  8%|▊         | 40/500 [34:59<7:09:20, 56.00s/it]  8%|▊         | 41/500 [35:40<6:32:48, 51.35s/it]  8%|▊         | 42/500 [36:43<7:00:28, 55.08s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.31E+06, Train scatter: [0.2164 0.0678 0.543  0.5092]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.66E-01
Test scatter: [0.2204 0.0676 0.5345 0.5085], Lowest was [0.1973 0.0673 0.5345 0.4985]
Median for last 10 epochs: [0.2204 0.0691 0.5345 0.5081], Epochs since improvement 0
  9%|▊         | 43/500 [37:24<6:25:48, 50.65s/it]  9%|▉         | 44/500 [38:27<6:53:22, 54.39s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.26E+06, Train scatter: [0.2018 0.0667 0.5429 0.5092]
L1 regularization loss: 2.29E+00, L2 regularization loss: 5.75E-01
Test scatter: [0.2072 0.0663 0.5344 0.5067], Lowest was [0.1973 0.0663 0.5344 0.4985]
Median for last 10 epochs: [0.2204 0.0676 0.5345 0.5067], Epochs since improvement 0
  9%|▉         | 45/500 [39:07<6:21:21, 50.29s/it]  9%|▉         | 46/500 [40:11<6:50:22, 54.23s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.29E+06, Train scatter: [0.2039 0.0698 0.5427 0.5009]
L1 regularization loss: 2.30E+00, L2 regularization loss: 5.81E-01
Test scatter: [0.2118 0.0691 0.5342 0.4965], Lowest was [0.1973 0.0663 0.5342 0.4965]
Median for last 10 epochs: [0.2118 0.0676 0.5345 0.5067], Epochs since improvement 0
  9%|▉         | 47/500 [40:51<6:17:52, 50.05s/it] 10%|▉         | 48/500 [41:55<6:48:18, 54.20s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.27E+06, Train scatter: [0.2246 0.0681 0.5428 0.5225]
L1 regularization loss: 2.31E+00, L2 regularization loss: 5.89E-01
Test scatter: [0.2444 0.0688 0.5342 0.5197], Lowest was [0.1973 0.0663 0.5342 0.4965]
Median for last 10 epochs: [0.2204 0.0688 0.5344 0.5085], Epochs since improvement 2
 10%|▉         | 49/500 [42:36<6:16:22, 50.07s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.27E+06, Train scatter: [0.2088 0.0767 0.5428 0.5022]
L1 regularization loss: 2.32E+00, L2 regularization loss: 6.00E-01
Test scatter: [0.277  0.0755 0.5343 0.4975], Lowest was [0.1973 0.0663 0.5342 0.4965]
Median for last 10 epochs: [0.2204 0.0688 0.5343 0.5067], Epochs since improvement 4
 10%|█         | 50/500 [43:45<6:59:04, 55.88s/it] 10%|█         | 51/500 [44:25<6:23:20, 51.23s/it] 10%|█         | 52/500 [45:30<6:52:40, 55.27s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.26E+06, Train scatter: [0.211  0.0676 0.5427 0.4959]
L1 regularization loss: 2.34E+00, L2 regularization loss: 6.08E-01
Test scatter: [0.2146 0.0673 0.5342 0.4944], Lowest was [0.1973 0.0663 0.5342 0.4944]
Median for last 10 epochs: [0.2146 0.0688 0.5342 0.4975], Epochs since improvement 0
 11%|█         | 53/500 [46:11<6:19:01, 50.88s/it] 11%|█         | 54/500 [47:14<6:45:48, 54.59s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.24E+06, Train scatter: [0.1965 0.0665 0.5425 0.496 ]
L1 regularization loss: 2.34E+00, L2 regularization loss: 6.15E-01
Test scatter: [0.2016 0.0661 0.534  0.4904], Lowest was [0.1973 0.0661 0.534  0.4904]
Median for last 10 epochs: [0.2146 0.0688 0.5342 0.4965], Epochs since improvement 0
 11%|█         | 55/500 [47:54<6:13:25, 50.35s/it] 11%|█         | 56/500 [48:58<6:42:51, 54.44s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.24E+06, Train scatter: [0.2584 0.0651 0.5424 0.4974]
L1 regularization loss: 2.36E+00, L2 regularization loss: 6.23E-01
Test scatter: [0.262  0.0649 0.5339 0.4915], Lowest was [0.1973 0.0649 0.5339 0.4904]
Median for last 10 epochs: [0.2444 0.0673 0.5342 0.4944], Epochs since improvement 0
 11%|█▏        | 57/500 [49:39<6:10:53, 50.23s/it] 12%|█▏        | 58/500 [50:44<6:42:22, 54.62s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.22E+06, Train scatter: [0.233  0.0661 0.5423 0.5062]
L1 regularization loss: 2.38E+00, L2 regularization loss: 6.37E-01
Test scatter: [0.2367 0.0657 0.5337 0.4969], Lowest was [0.1973 0.0649 0.5337 0.4904]
Median for last 10 epochs: [0.2367 0.0661 0.534  0.4944], Epochs since improvement 0
 12%|█▏        | 59/500 [51:24<6:09:41, 50.30s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.19E+06, Train scatter: [0.2896 0.0904 0.542  0.5137]
L1 regularization loss: 2.40E+00, L2 regularization loss: 6.49E-01
Test scatter: [0.2883 0.09   0.5335 0.5131], Lowest was [0.1973 0.0649 0.5335 0.4904]
Median for last 10 epochs: [0.2367 0.0661 0.5339 0.4944], Epochs since improvement 0
 12%|█▏        | 60/500 [52:36<6:57:09, 56.89s/it] 12%|█▏        | 61/500 [53:16<6:19:59, 51.94s/it] 12%|█▏        | 62/500 [54:20<6:43:31, 55.28s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.18E+06, Train scatter: [0.2125 0.0752 0.5421 0.4917]
L1 regularization loss: 2.42E+00, L2 regularization loss: 6.60E-01
Test scatter: [0.2171 0.0753 0.5336 0.4901], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.2367 0.0661 0.5337 0.4915], Epochs since improvement 0
 13%|█▎        | 63/500 [55:00<6:10:19, 50.85s/it] 13%|█▎        | 64/500 [56:03<6:36:36, 54.58s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.21E+06, Train scatter: [0.2047 0.0653 0.5423 0.4979]
L1 regularization loss: 2.44E+00, L2 regularization loss: 6.73E-01
Test scatter: [0.2126 0.0653 0.5337 0.4924], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.2367 0.0657 0.5337 0.4924], Epochs since improvement 2
 13%|█▎        | 65/500 [56:43<6:04:03, 50.22s/it] 13%|█▎        | 66/500 [57:47<6:32:41, 54.29s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.10E+06, Train scatter: [0.4267 0.0697 0.5422 0.5015]
L1 regularization loss: 2.48E+00, L2 regularization loss: 6.92E-01
Test scatter: [0.423  0.0685 0.5336 0.4953], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.2367 0.0685 0.5336 0.4953], Epochs since improvement 4
 13%|█▎        | 67/500 [58:28<6:01:40, 50.12s/it] 14%|█▎        | 68/500 [59:32<6:30:49, 54.28s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.06E+06, Train scatter: [0.4738 0.0776 0.5422 0.5476]
L1 regularization loss: 2.50E+00, L2 regularization loss: 7.08E-01
Test scatter: [0.4636 0.077  0.5337 0.5493], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.2883 0.0753 0.5336 0.4953], Epochs since improvement 6
 14%|█▍        | 69/500 [1:00:12<5:59:34, 50.06s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 8.21E+06, Train scatter: [0.9353 0.1735 0.5441 0.9956]
L1 regularization loss: 4.16E+00, L2 regularization loss: 1.43E+00
Test scatter: [0.9197 0.1696 0.5355 0.9852], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.423  0.0753 0.5337 0.4953], Epochs since improvement 8
 14%|█▍        | 70/500 [1:01:22<6:42:13, 56.12s/it] 14%|█▍        | 71/500 [1:02:03<6:08:20, 51.52s/it] 14%|█▍        | 72/500 [1:03:05<6:31:22, 54.87s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 6.80E+06, Train scatter: [0.9354 0.1737 0.5441 0.9964]
L1 regularization loss: 4.23E+00, L2 regularization loss: 1.54E+00
Test scatter: [0.9198 0.1698 0.5355 0.986 ], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.4636 0.077  0.5337 0.5493], Epochs since improvement 10
 15%|█▍        | 73/500 [1:03:46<5:59:12, 50.47s/it] 15%|█▍        | 74/500 [1:04:51<6:29:15, 54.83s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 5.98E+06, Train scatter: [0.9351 0.1733 0.5441 0.9945]
L1 regularization loss: 4.23E+00, L2 regularization loss: 1.55E+00
Test scatter: [0.9195 0.1694 0.5355 0.9841], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.9195 0.1694 0.5355 0.9841], Epochs since improvement 12
 15%|█▌        | 75/500 [1:05:31<5:57:40, 50.49s/it] 15%|█▌        | 76/500 [1:06:36<6:27:02, 54.77s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 5.64E+06, Train scatter: [0.9349 0.1729 0.5441 0.9935]
L1 regularization loss: 4.23E+00, L2 regularization loss: 1.55E+00
Test scatter: [0.9193 0.169  0.5355 0.9832], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.9195 0.1694 0.5355 0.9841], Epochs since improvement 14
 15%|█▌        | 77/500 [1:07:16<5:55:36, 50.44s/it] 16%|█▌        | 78/500 [1:08:18<6:19:32, 53.96s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 5.43E+06, Train scatter: [0.9346 0.1719 0.5441 0.9921]
L1 regularization loss: 4.22E+00, L2 regularization loss: 1.56E+00
Test scatter: [0.919  0.1681 0.5355 0.9817], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.9195 0.1694 0.5355 0.9841], Epochs since improvement 16
 16%|█▌        | 79/500 [1:08:59<5:50:41, 49.98s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 5.41E+06, Train scatter: [0.9344 0.1703 0.5441 0.9918]
L1 regularization loss: 4.21E+00, L2 regularization loss: 1.56E+00
Test scatter: [0.9188 0.1666 0.5355 0.9814], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.9193 0.169  0.5355 0.9832], Epochs since improvement 18
 16%|█▌        | 80/500 [1:10:08<6:30:24, 55.77s/it] 16%|█▌        | 81/500 [1:10:49<5:57:56, 51.26s/it] 16%|█▋        | 82/500 [1:11:52<6:20:57, 54.68s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 5.05E+06, Train scatter: [0.9341 0.164  0.5441 0.9891]
L1 regularization loss: 4.22E+00, L2 regularization loss: 1.59E+00
Test scatter: [0.9185 0.1605 0.5355 0.9788], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.919  0.1681 0.5355 0.9817], Epochs since improvement 20
 17%|█▋        | 83/500 [1:12:32<5:50:16, 50.40s/it] 17%|█▋        | 83/500 [1:13:36<6:09:49, 53.21s/it]
Epoch: 84 done with learning rate 9.99E-03, Train loss: 4.26E+06, Train scatter: [0.9332 0.1324 0.5441 0.9821]
L1 regularization loss: 4.23E+00, L2 regularization loss: 1.65E+00
Test scatter: [0.9176 0.1303 0.5355 0.9719], Lowest was [0.1973 0.0649 0.5335 0.4901]
Median for last 10 epochs: [0.9188 0.1666 0.5355 0.9814], Epochs since improvement 22
Exited after 84 epochs due to early stopping
4416.68 seconds spent training, 8.833 seconds per epoch. Processed 7883 trees per second
[0.91756624 0.13027683 0.5354804  0.97190964]
{'epoch_exit': 83, 'scatter_m_star': 0.91756624, 'lowest_m_star': 0.19732392, 'last20_m_star': 0.9189219, 'last10_m_star': 0.91883165, 'scatter_v_disk': 0.13027683, 'lowest_v_disk': 0.06486564, 'last20_v_disk': 0.16730702, 'last10_v_disk': 0.16656204, 'scatter_m_cold': 0.5354804, 'lowest_m_cold': 0.5334715, 'last20_m_cold': 0.535491, 'last10_m_cold': 0.5354951, 'scatter_sfr_100': 0.97190964, 'lowest_sfr_100': 0.49005678, 'last20_sfr_100': 0.9815859, 'last10_sfr_100': 0.9814336}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_eaolpr
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:01<8:33:02, 61.69s/it]  0%|          | 2/500 [02:31<10:47:00, 77.95s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.22E+07, Train scatter: [0.9351 0.132  0.5441 0.9954]
L1 regularization loss: 2.45E+00, L2 regularization loss: 4.24E-01
Test scatter: [0.9195 0.1274 0.5355 0.9851], Lowest was [0.9195 0.1274 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1274 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:32<9:43:08, 70.40s/it]   1%|          | 4/500 [05:02<10:46:53, 78.25s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.05E+07, Train scatter: [0.932  0.1    0.5438 0.9955]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.29E-01
Test scatter: [0.9164 0.0985 0.5352 0.9852], Lowest was [0.9164 0.0985 0.5352 0.9851]
Median for last 10 epochs: [0.9164 0.0985 0.5352 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:04<9:55:04, 72.13s/it]   1%|          | 6/500 [07:35<10:48:08, 78.72s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 7.94E+07, Train scatter: [0.9365 0.1201 0.542  0.9955]
L1 regularization loss: 2.49E+00, L2 regularization loss: 4.37E-01
Test scatter: [0.9209 0.1173 0.5334 0.9851], Lowest was [0.9164 0.0985 0.5334 0.9851]
Median for last 10 epochs: [0.9164 0.0985 0.5334 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [08:36<9:59:26, 72.96s/it]   2%|▏         | 8/500 [10:07<10:44:47, 78.63s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.64E+07, Train scatter: [0.9346 0.1019 0.4692 0.9954]
L1 regularization loss: 2.51E+00, L2 regularization loss: 4.45E-01
Test scatter: [0.9189 0.1008 0.4595 0.9851], Lowest was [0.9164 0.0985 0.4595 0.9851]
Median for last 10 epochs: [0.9176 0.0996 0.4965 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [11:08<9:58:43, 73.16s/it] Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.43E+07, Train scatter: [0.9314 0.1016 0.4082 0.9954]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.53E-01
Test scatter: [0.9158 0.1041 0.4067 0.9851], Lowest was [0.9158 0.0985 0.4067 0.9851]
Median for last 10 epochs: [0.9164 0.1008 0.4595 0.9851], Epochs since improvement 0
  2%|▏         | 10/500 [12:46<10:59:46, 80.79s/it]  2%|▏         | 11/500 [13:47<10:09:55, 74.84s/it]  2%|▏         | 12/500 [15:18<10:48:28, 79.73s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.31E+07, Train scatter: [0.6991 0.1011 0.3873 0.9954]
L1 regularization loss: 2.54E+00, L2 regularization loss: 4.68E-01
Test scatter: [0.6948 0.1033 0.3883 0.9851], Lowest was [0.6948 0.0985 0.3883 0.9851]
Median for last 10 epochs: [0.9164 0.1033 0.4595 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [16:19<10:01:38, 74.12s/it]  3%|▎         | 14/500 [17:50<10:39:41, 78.97s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.22E+07, Train scatter: [0.6091 0.0862 0.3476 0.9954]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.74E-01
Test scatter: [0.6256 0.0879 0.3488 0.9851], Lowest was [0.6256 0.0879 0.3488 0.9851]
Median for last 10 epochs: [0.9158 0.1033 0.4067 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [18:51<9:55:19, 73.65s/it]   3%|▎         | 16/500 [20:21<10:34:44, 78.69s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.93E+07, Train scatter: [0.4859 0.0828 0.3534 0.9955]
L1 regularization loss: 2.56E+00, L2 regularization loss: 4.78E-01
Test scatter: [0.508  0.0841 0.3556 0.9852], Lowest was [0.508  0.0841 0.3488 0.9851]
Median for last 10 epochs: [0.6948 0.1008 0.3883 0.9851], Epochs since improvement 0
  3%|▎         | 17/500 [21:23<9:51:58, 73.54s/it]   4%|▎         | 18/500 [22:54<10:33:19, 78.84s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 2.33E+07, Train scatter: [0.3953 0.0797 0.3385 0.8418]
L1 regularization loss: 2.57E+00, L2 regularization loss: 4.88E-01
Test scatter: [0.412  0.0795 0.341  0.8372], Lowest was [0.412  0.0795 0.341  0.8372]
Median for last 10 epochs: [0.6256 0.0879 0.3556 0.9851], Epochs since improvement 0
  4%|▍         | 19/500 [23:56<9:50:30, 73.66s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 4.98E+06, Train scatter: [0.4402 0.0769 0.3634 0.7182]
L1 regularization loss: 2.60E+00, L2 regularization loss: 5.03E-01
Test scatter: [0.4394 0.0756 0.3661 0.7215], Lowest was [0.412  0.0756 0.341  0.7215]
Median for last 10 epochs: [0.508  0.0841 0.3556 0.9851], Epochs since improvement 0
  4%|▍         | 20/500 [25:33<10:46:10, 80.77s/it]  4%|▍         | 21/500 [26:35<9:58:48, 75.01s/it]   4%|▍         | 22/500 [28:06<10:36:48, 79.93s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.79E+06, Train scatter: [0.2891 0.0692 0.3095 0.5237]
L1 regularization loss: 2.63E+00, L2 regularization loss: 5.18E-01
Test scatter: [0.2979 0.0692 0.3121 0.5238], Lowest was [0.2979 0.0692 0.3121 0.5238]
Median for last 10 epochs: [0.4394 0.0795 0.3488 0.8372], Epochs since improvement 0
  5%|▍         | 23/500 [29:07<9:51:38, 74.42s/it]   5%|▍         | 24/500 [30:38<10:27:40, 79.12s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.51E+06, Train scatter: [0.3132 0.0704 0.3203 0.5128]
L1 regularization loss: 2.66E+00, L2 regularization loss: 5.33E-01
Test scatter: [0.3176 0.0698 0.3217 0.5119], Lowest was [0.2979 0.0692 0.3121 0.5119]
Median for last 10 epochs: [0.412  0.0756 0.341  0.7215], Epochs since improvement 0
  5%|▌         | 25/500 [31:39<9:43:49, 73.75s/it]   5%|▌         | 26/500 [33:10<10:23:43, 78.95s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.22E+06, Train scatter: [0.2842 0.0668 0.3097 0.5967]
L1 regularization loss: 2.69E+00, L2 regularization loss: 5.44E-01
Test scatter: [0.2884 0.0663 0.3131 0.6035], Lowest was [0.2884 0.0663 0.3121 0.5119]
Median for last 10 epochs: [0.3176 0.0698 0.3217 0.6035], Epochs since improvement 0
  5%|▌         | 27/500 [34:11<9:40:42, 73.66s/it]   6%|▌         | 28/500 [35:42<10:20:22, 78.86s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.15E+06, Train scatter: [0.3193 0.067  0.302  0.508 ]
L1 regularization loss: 2.71E+00, L2 regularization loss: 5.54E-01
Test scatter: [0.3001 0.0662 0.3037 0.5075], Lowest was [0.2884 0.0662 0.3037 0.5075]
Median for last 10 epochs: [0.3001 0.0692 0.3131 0.5238], Epochs since improvement 0
  6%|▌         | 29/500 [36:43<9:37:40, 73.59s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.07E+06, Train scatter: [0.2594 0.0654 0.3043 0.4886]
L1 regularization loss: 2.77E+00, L2 regularization loss: 5.75E-01
Test scatter: [0.259  0.0646 0.3069 0.4881], Lowest was [0.259  0.0646 0.3037 0.4881]
Median for last 10 epochs: [0.2979 0.0663 0.3121 0.5119], Epochs since improvement 0
  6%|▌         | 30/500 [38:21<10:33:42, 80.90s/it]  6%|▌         | 31/500 [39:23<9:46:38, 75.05s/it]   6%|▋         | 32/500 [40:53<10:21:45, 79.71s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.96E+06, Train scatter: [0.2926 0.0691 0.3134 0.5321]
L1 regularization loss: 2.80E+00, L2 regularization loss: 5.91E-01
Test scatter: [0.2899 0.0684 0.3171 0.5311], Lowest was [0.259  0.0646 0.3037 0.4881]
Median for last 10 epochs: [0.2899 0.0663 0.3131 0.5119], Epochs since improvement 2
  7%|▋         | 33/500 [41:55<9:38:02, 74.27s/it]   7%|▋         | 34/500 [43:26<10:15:07, 79.20s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.84E+06, Train scatter: [0.266  0.0657 0.3056 0.5688]
L1 regularization loss: 2.84E+00, L2 regularization loss: 6.06E-01
Test scatter: [0.2705 0.0652 0.3057 0.5743], Lowest was [0.259  0.0646 0.3037 0.4881]
Median for last 10 epochs: [0.2884 0.0662 0.3069 0.5311], Epochs since improvement 4
  7%|▋         | 35/500 [44:27<9:32:59, 73.93s/it]   7%|▋         | 36/500 [45:58<10:10:04, 78.89s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.81E+06, Train scatter: [0.3091 0.0643 0.2965 0.4883]
L1 regularization loss: 2.88E+00, L2 regularization loss: 6.24E-01
Test scatter: [0.3014 0.0638 0.2988 0.4824], Lowest was [0.259  0.0638 0.2988 0.4824]
Median for last 10 epochs: [0.2899 0.0652 0.3057 0.5075], Epochs since improvement 0
  7%|▋         | 37/500 [47:00<9:29:01, 73.74s/it]   8%|▊         | 38/500 [48:31<10:08:27, 79.02s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.13E+06, Train scatter: [0.2374 0.0674 0.2962 0.4719]
L1 regularization loss: 2.94E+00, L2 regularization loss: 6.50E-01
Test scatter: [0.2466 0.0672 0.2965 0.4735], Lowest was [0.2466 0.0638 0.2965 0.4735]
Median for last 10 epochs: [0.2705 0.0652 0.3057 0.4881], Epochs since improvement 0
  8%|▊         | 39/500 [49:32<9:26:53, 73.78s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.56E+06, Train scatter: [0.3068 0.0644 0.3171 0.4946]
L1 regularization loss: 2.98E+00, L2 regularization loss: 6.74E-01
Test scatter: [0.299  0.0645 0.3189 0.5011], Lowest was [0.2466 0.0638 0.2965 0.4735]
Median for last 10 epochs: [0.2899 0.0652 0.3057 0.5011], Epochs since improvement 2
  8%|▊         | 40/500 [51:10<10:20:18, 80.91s/it]  8%|▊         | 41/500 [52:11<9:34:15, 75.07s/it]   8%|▊         | 42/500 [53:42<10:09:04, 79.79s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.38E+06, Train scatter: [0.2199 0.0583 0.2833 0.4591]
L1 regularization loss: 3.02E+00, L2 regularization loss: 7.02E-01
Test scatter: [0.2225 0.0587 0.2861 0.4633], Lowest was [0.2225 0.0587 0.2861 0.4633]
Median for last 10 epochs: [0.2705 0.0645 0.2988 0.4824], Epochs since improvement 0
  9%|▊         | 43/500 [54:44<9:25:28, 74.24s/it]   9%|▉         | 44/500 [56:14<10:01:38, 79.16s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.46E+06, Train scatter: [0.2194 0.0596 0.2888 0.4618]
L1 regularization loss: 3.11E+00, L2 regularization loss: 7.51E-01
Test scatter: [0.2348 0.0596 0.2918 0.4611], Lowest was [0.2225 0.0587 0.2861 0.4611]
Median for last 10 epochs: [0.2466 0.0638 0.2965 0.4735], Epochs since improvement 0
  9%|▉         | 45/500 [57:15<9:19:31, 73.78s/it]   9%|▉         | 46/500 [58:46<9:55:23, 78.69s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.25E+06, Train scatter: [0.2223 0.0587 0.28   0.4674]
L1 regularization loss: 3.16E+00, L2 regularization loss: 7.95E-01
Test scatter: [0.2285 0.0584 0.2806 0.4713], Lowest was [0.2225 0.0584 0.2806 0.4611]
Median for last 10 epochs: [0.2348 0.0596 0.2918 0.4713], Epochs since improvement 0
  9%|▉         | 47/500 [59:47<9:14:44, 73.48s/it] 10%|▉         | 48/500 [1:01:17<9:52:12, 78.61s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.09E+06, Train scatter: [0.3019 0.0787 0.2825 0.4515]
L1 regularization loss: 3.22E+00, L2 regularization loss: 8.53E-01
Test scatter: [0.3038 0.0746 0.2835 0.4507], Lowest was [0.2225 0.0584 0.2806 0.4507]
Median for last 10 epochs: [0.2348 0.0596 0.2861 0.4633], Epochs since improvement 0
 10%|▉         | 49/500 [1:02:19<9:11:51, 73.42s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.95E+06, Train scatter: [0.2219 0.0575 0.2704 0.4486]
L1 regularization loss: 3.29E+00, L2 regularization loss: 9.15E-01
Test scatter: [0.2293 0.0583 0.2718 0.451 ], Lowest was [0.2225 0.0583 0.2718 0.4507]
Median for last 10 epochs: [0.2293 0.0587 0.2835 0.4611], Epochs since improvement 0
 10%|█         | 50/500 [1:03:56<10:05:03, 80.67s/it] 10%|█         | 51/500 [1:04:58<9:20:39, 74.92s/it]  10%|█         | 52/500 [1:06:27<9:51:48, 79.26s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.84E+06, Train scatter: [0.2187 0.0694 0.2821 0.4693]
L1 regularization loss: 3.34E+00, L2 regularization loss: 9.75E-01
Test scatter: [0.2362 0.0675 0.2834 0.4665], Lowest was [0.2225 0.0583 0.2718 0.4507]
Median for last 10 epochs: [0.2348 0.0596 0.2834 0.4611], Epochs since improvement 2
 11%|█         | 53/500 [1:07:29<9:11:08, 73.98s/it] 11%|█         | 54/500 [1:08:59<9:45:54, 78.82s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.73E+06, Train scatter: [0.4419 0.0741 0.2831 0.4449]
L1 regularization loss: 3.40E+00, L2 regularization loss: 1.04E+00
Test scatter: [0.4552 0.0734 0.2876 0.4434], Lowest was [0.2225 0.0583 0.2718 0.4434]
Median for last 10 epochs: [0.2362 0.0675 0.2834 0.451 ], Epochs since improvement 0
 11%|█         | 55/500 [1:10:00<9:05:48, 73.59s/it] 11%|█         | 56/500 [1:11:31<9:42:47, 78.76s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.63E+06, Train scatter: [0.2255 0.056  0.2774 0.4328]
L1 regularization loss: 3.46E+00, L2 regularization loss: 1.10E+00
Test scatter: [0.2474 0.0569 0.2829 0.4385], Lowest was [0.2225 0.0569 0.2718 0.4385]
Median for last 10 epochs: [0.2474 0.0675 0.2834 0.4507], Epochs since improvement 0
 11%|█▏        | 57/500 [1:12:32<9:02:51, 73.52s/it] 12%|█▏        | 58/500 [1:14:03<9:38:49, 78.57s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.58E+06, Train scatter: [0.33   0.059  0.2745 0.4445]
L1 regularization loss: 3.51E+00, L2 regularization loss: 1.16E+00
Test scatter: [0.3272 0.0587 0.277  0.4415], Lowest was [0.2225 0.0569 0.2718 0.4385]
Median for last 10 epochs: [0.2474 0.0587 0.2829 0.4434], Epochs since improvement 2
 12%|█▏        | 59/500 [1:15:04<8:59:30, 73.40s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.58E+06, Train scatter: [0.3647 0.0595 0.2955 0.4682]
L1 regularization loss: 3.63E+00, L2 regularization loss: 1.26E+00
Test scatter: [0.3855 0.0613 0.2957 0.4731], Lowest was [0.2225 0.0569 0.2718 0.4385]
Median for last 10 epochs: [0.3272 0.0613 0.2834 0.4434], Epochs since improvement 4
 12%|█▏        | 60/500 [1:16:42<9:52:04, 80.74s/it] 12%|█▏        | 61/500 [1:17:43<9:07:49, 74.87s/it] 12%|█▏        | 62/500 [1:19:14<9:40:29, 79.52s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.22E+06, Train scatter: [0.4115 0.0744 0.4913 0.5001]
L1 regularization loss: 3.85E+00, L2 regularization loss: 1.43E+00
Test scatter: [0.4045 0.074  0.4829 0.4935], Lowest was [0.2225 0.0569 0.2718 0.4385]
Median for last 10 epochs: [0.3855 0.0613 0.2876 0.4434], Epochs since improvement 6
 13%|█▎        | 63/500 [1:20:15<8:58:51, 73.99s/it] 13%|█▎        | 64/500 [1:21:46<9:35:00, 79.13s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.36E+06, Train scatter: [0.2661 0.0634 0.2956 0.4381]
L1 regularization loss: 3.87E+00, L2 regularization loss: 1.48E+00
Test scatter: [0.326  0.0632 0.2966 0.44  ], Lowest was [0.2225 0.0569 0.2718 0.4385]
Median for last 10 epochs: [0.3272 0.0613 0.2957 0.4415], Epochs since improvement 8
 13%|█▎        | 65/500 [1:22:47<8:54:55, 73.78s/it] 13%|█▎        | 66/500 [1:24:17<9:29:28, 78.73s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.23E+06, Train scatter: [0.1991 0.0557 0.2808 0.4326]
L1 regularization loss: 3.90E+00, L2 regularization loss: 1.54E+00
Test scatter: [0.2078 0.057  0.2824 0.432 ], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.3272 0.0613 0.2957 0.4415], Epochs since improvement 0
 13%|█▎        | 67/500 [1:25:19<8:50:49, 73.55s/it] 14%|█▎        | 68/500 [1:26:49<9:24:30, 78.41s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.81E+08, Train scatter: [0.935  0.1728 0.5441 0.9954]
L1 regularization loss: 1.20E+01, L2 regularization loss: 4.62E+00
Test scatter: [0.9194 0.169  0.5355 0.985 ], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.3855 0.0632 0.2966 0.4731], Epochs since improvement 2
 14%|█▍        | 69/500 [1:27:50<8:46:50, 73.34s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 8.71E+05, Train scatter: [0.9309 0.2387 0.5432 0.9919]
L1 regularization loss: 1.20E+01, L2 regularization loss: 4.81E+00
Test scatter: [0.9154 0.2321 0.5347 0.9818], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.4045 0.074  0.4829 0.4935], Epochs since improvement 4
 14%|█▍        | 70/500 [1:29:31<9:44:27, 81.55s/it] 14%|█▍        | 71/500 [1:30:32<9:00:25, 75.58s/it] 14%|█▍        | 72/500 [1:32:03<9:31:46, 80.16s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.50E+05, Train scatter: [0.886  0.1268 0.5247 0.9412]
L1 regularization loss: 1.20E+01, L2 regularization loss: 4.96E+00
Test scatter: [0.8711 0.1254 0.5163 0.931 ], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.8711 0.1254 0.5163 0.931 ], Epochs since improvement 6
 15%|█▍        | 73/500 [1:33:05<8:50:13, 74.50s/it] 15%|█▍        | 74/500 [1:34:35<9:23:40, 79.39s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.06E+05, Train scatter: [0.7664 0.1307 0.5252 0.8368]
L1 regularization loss: 1.21E+01, L2 regularization loss: 5.15E+00
Test scatter: [0.7506 0.128  0.517  0.8271], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.8711 0.128  0.517  0.931 ], Epochs since improvement 8
 15%|█▌        | 75/500 [1:35:37<8:44:04, 73.99s/it] 15%|█▌        | 76/500 [1:37:06<9:16:09, 78.70s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.13E+03, Train scatter: [0.5942 0.1152 0.5008 0.719 ]
L1 regularization loss: 1.21E+01, L2 regularization loss: 5.36E+00
Test scatter: [0.5827 0.1128 0.4939 0.7106], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.8711 0.128  0.517  0.931 ], Epochs since improvement 10
 15%|█▌        | 77/500 [1:38:08<8:38:03, 73.48s/it] 16%|█▌        | 78/500 [1:39:39<9:14:34, 78.85s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: -4.10E+04, Train scatter: [0.5725 0.1109 0.4936 0.708 ]
L1 regularization loss: 1.21E+01, L2 regularization loss: 5.45E+00
Test scatter: [0.5605 0.1086 0.4849 0.6983], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.7506 0.1254 0.5163 0.8271], Epochs since improvement 12
 16%|█▌        | 79/500 [1:40:40<8:36:03, 73.55s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: -2.77E+04, Train scatter: [0.5122 0.1121 0.4741 0.6893]
L1 regularization loss: 1.22E+01, L2 regularization loss: 5.53E+00
Test scatter: [0.5024 0.1095 0.4687 0.6805], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.5827 0.1128 0.4939 0.7106], Epochs since improvement 14
 16%|█▌        | 80/500 [1:42:20<9:28:52, 81.27s/it] 16%|█▌        | 81/500 [1:43:21<8:46:10, 75.35s/it] 16%|█▋        | 82/500 [1:44:52<9:16:29, 79.88s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: -8.93E+04, Train scatter: [0.4967 0.1029 0.4582 0.6551]
L1 regularization loss: 1.22E+01, L2 regularization loss: 5.61E+00
Test scatter: [0.4865 0.1008 0.4527 0.6461], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.5605 0.1095 0.4849 0.6983], Epochs since improvement 16
 17%|█▋        | 83/500 [1:45:53<8:37:04, 74.40s/it] 17%|█▋        | 84/500 [1:47:23<9:08:47, 79.15s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: -8.79E+04, Train scatter: [0.4725 0.1031 0.4799 0.6423]
L1 regularization loss: 1.22E+01, L2 regularization loss: 5.67E+00
Test scatter: [0.4627 0.1011 0.4723 0.6367], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.5024 0.1086 0.4723 0.6805], Epochs since improvement 18
 17%|█▋        | 85/500 [1:48:25<8:31:09, 73.90s/it] 17%|█▋        | 86/500 [1:49:55<9:03:41, 78.80s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: -1.03E+05, Train scatter: [0.536  0.0996 0.4566 0.6469]
L1 regularization loss: 1.22E+01, L2 regularization loss: 5.75E+00
Test scatter: [0.5201 0.0972 0.4504 0.6334], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.5024 0.1011 0.4687 0.6461], Epochs since improvement 20
 17%|█▋        | 87/500 [1:50:57<8:26:43, 73.62s/it] 17%|█▋        | 87/500 [1:52:27<8:53:50, 77.56s/it]
Epoch: 88 done with learning rate 9.98E-03, Train loss: 9.75E+04, Train scatter: [0.9117 0.1498 0.5285 0.9311]
L1 regularization loss: 1.23E+01, L2 regularization loss: 5.91E+00
Test scatter: [0.8965 0.1464 0.5204 0.9236], Lowest was [0.2078 0.0569 0.2718 0.432 ]
Median for last 10 epochs: [0.5024 0.1011 0.4687 0.6461], Epochs since improvement 22
Exited after 88 epochs due to early stopping
6747.45 seconds spent training, 13.495 seconds per epoch. Processed 5160 trees per second
[0.8964942  0.14642014 0.52042216 0.92357016]
{'epoch_exit': 87, 'scatter_m_star': 0.8964942, 'lowest_m_star': 0.20780765, 'last20_m_star': 0.57162464, 'last10_m_star': 0.5023817, 'scatter_v_disk': 0.14642014, 'lowest_v_disk': 0.05687049, 'last20_v_disk': 0.111180514, 'last10_v_disk': 0.10112623, 'scatter_m_cold': 0.52042216, 'lowest_m_cold': 0.2717985, 'last20_m_cold': 0.48941144, 'last10_m_cold': 0.46874842, 'scatter_sfr_100': 0.92357016, 'lowest_sfr_100': 0.4319935, 'last20_sfr_100': 0.70444, 'last10_sfr_100': 0.64605415}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_bsglvp
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:24:11, 53.41s/it]  0%|          | 2/500 [02:14<9:37:25, 69.57s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.1727 0.5441 0.9953]
L1 regularization loss: 2.44E+00, L2 regularization loss: 4.23E-01
Test scatter: [0.9196 0.1682 0.5355 0.985 ], Lowest was [0.9196 0.1682 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1682 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:07<8:35:14, 62.20s/it]  1%|          | 4/500 [04:29<9:37:42, 69.89s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.76E+07, Train scatter: [0.9352 0.1323 0.5441 0.9955]
L1 regularization loss: 2.46E+00, L2 regularization loss: 4.25E-01
Test scatter: [0.9195 0.1301 0.5355 0.9851], Lowest was [0.9195 0.1301 0.5355 0.985 ]
Median for last 10 epochs: [0.9195 0.1301 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [05:22<8:47:42, 63.96s/it]  1%|          | 6/500 [06:44<9:34:51, 69.82s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.34E+07, Train scatter: [0.9349 0.1089 0.5441 0.9955]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.28E-01
Test scatter: [0.9193 0.1068 0.5355 0.9851], Lowest was [0.9193 0.1068 0.5355 0.985 ]
Median for last 10 epochs: [0.9193 0.1068 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:37<8:49:32, 64.45s/it]  2%|▏         | 8/500 [08:58<9:30:40, 69.59s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.16E+07, Train scatter: [0.9298 0.0992 0.544  0.9955]
L1 regularization loss: 2.48E+00, L2 regularization loss: 4.33E-01
Test scatter: [0.9142 0.0979 0.5354 0.9851], Lowest was [0.9142 0.0979 0.5354 0.985 ]
Median for last 10 epochs: [0.9168 0.1024 0.5355 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [09:51<8:47:54, 64.51s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 9.99E+07, Train scatter: [0.9322 0.1754 0.5442 0.9955]
L1 regularization loss: 2.49E+00, L2 regularization loss: 4.40E-01
Test scatter: [0.9167 0.165  0.5356 0.9851], Lowest was [0.9142 0.0979 0.5354 0.985 ]
Median for last 10 epochs: [0.9167 0.1068 0.5355 0.9851], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:19<9:45:07, 71.65s/it]  2%|▏         | 11/500 [12:12<8:58:35, 66.08s/it]  2%|▏         | 12/500 [13:33<9:35:07, 70.71s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 1.04E+08, Train scatter: [0.9354 0.16   0.5441 0.9954]
L1 regularization loss: 2.53E+00, L2 regularization loss: 4.49E-01
Test scatter: [0.9199 0.1555 0.5355 0.9851], Lowest was [0.9142 0.0979 0.5354 0.985 ]
Median for last 10 epochs: [0.9193 0.1301 0.5355 0.9851], Epochs since improvement 4
  3%|▎         | 13/500 [14:27<8:51:26, 65.48s/it]  3%|▎         | 14/500 [15:47<9:27:01, 70.00s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 9.15E+07, Train scatter: [0.9352 0.1401 0.544  0.9955]
L1 regularization loss: 2.54E+00, L2 regularization loss: 4.54E-01
Test scatter: [0.9196 0.1388 0.5355 0.9851], Lowest was [0.9142 0.0979 0.5354 0.985 ]
Median for last 10 epochs: [0.9193 0.1388 0.5355 0.9851], Epochs since improvement 6
  3%|▎         | 15/500 [16:40<8:45:07, 64.96s/it]  3%|▎         | 16/500 [18:01<9:22:47, 69.77s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 8.86E+07, Train scatter: [0.9344 0.124  0.544  0.9955]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.65E-01
Test scatter: [0.919  0.1238 0.5354 0.9852], Lowest was [0.9142 0.0979 0.5354 0.985 ]
Median for last 10 epochs: [0.919  0.1388 0.5355 0.9851], Epochs since improvement 0
  3%|▎         | 17/500 [18:55<8:41:42, 64.81s/it]  4%|▎         | 18/500 [20:17<9:22:26, 70.01s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 8.63E+07, Train scatter: [0.9287 0.1143 0.5438 0.9955]
L1 regularization loss: 2.57E+00, L2 regularization loss: 4.79E-01
Test scatter: [0.9134 0.1139 0.5352 0.9851], Lowest was [0.9134 0.0979 0.5352 0.985 ]
Median for last 10 epochs: [0.919  0.1388 0.5355 0.9851], Epochs since improvement 0
  4%|▍         | 19/500 [21:10<8:41:03, 65.00s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.44E+07, Train scatter: [0.804  0.1093 0.5399 0.9954]
L1 regularization loss: 2.59E+00, L2 regularization loss: 5.00E-01
Test scatter: [0.79   0.1086 0.5315 0.9851], Lowest was [0.79   0.0979 0.5315 0.985 ]
Median for last 10 epochs: [0.919  0.1238 0.5354 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:40<9:38:38, 72.33s/it]  4%|▍         | 21/500 [23:33<8:52:16, 66.67s/it]  4%|▍         | 22/500 [24:54<9:25:24, 70.97s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 8.12E+07, Train scatter: [0.6493 0.0962 0.4615 0.9954]
L1 regularization loss: 2.61E+00, L2 regularization loss: 5.27E-01
Test scatter: [0.6447 0.0968 0.4599 0.9851], Lowest was [0.6447 0.0968 0.4599 0.985 ]
Median for last 10 epochs: [0.9134 0.1139 0.5352 0.9851], Epochs since improvement 0
  5%|▍         | 23/500 [25:48<8:42:47, 65.76s/it]  5%|▍         | 24/500 [27:09<9:19:02, 70.47s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.89E+07, Train scatter: [0.5479 0.0933 0.4238 0.9954]
L1 regularization loss: 2.62E+00, L2 regularization loss: 5.37E-01
Test scatter: [0.5449 0.0934 0.4234 0.985 ], Lowest was [0.5449 0.0934 0.4234 0.985 ]
Median for last 10 epochs: [0.79   0.1086 0.5315 0.9851], Epochs since improvement 0
  5%|▌         | 25/500 [28:03<8:37:39, 65.39s/it]  5%|▌         | 26/500 [29:24<9:14:21, 70.17s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.76E+07, Train scatter: [0.5224 0.0871 0.4008 0.9954]
L1 regularization loss: 2.63E+00, L2 regularization loss: 5.47E-01
Test scatter: [0.5184 0.0878 0.4005 0.985 ], Lowest was [0.5184 0.0878 0.4005 0.985 ]
Median for last 10 epochs: [0.6447 0.0968 0.4599 0.9851], Epochs since improvement 0
  5%|▌         | 27/500 [30:18<8:34:02, 65.21s/it]  6%|▌         | 28/500 [31:38<9:09:34, 69.86s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.65E+07, Train scatter: [0.4905 0.0825 0.3667 0.9954]
L1 regularization loss: 2.64E+00, L2 regularization loss: 5.60E-01
Test scatter: [0.489  0.0835 0.3703 0.985 ], Lowest was [0.489  0.0835 0.3703 0.985 ]
Median for last 10 epochs: [0.5449 0.0934 0.4234 0.985 ], Epochs since improvement 0
  6%|▌         | 29/500 [32:32<8:30:13, 65.00s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.59E+07, Train scatter: [0.4893 0.0814 0.3576 0.9953]
L1 regularization loss: 2.65E+00, L2 regularization loss: 5.75E-01
Test scatter: [0.4951 0.0817 0.3592 0.985 ], Lowest was [0.489  0.0817 0.3592 0.985 ]
Median for last 10 epochs: [0.5184 0.0878 0.4005 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [34:00<9:22:50, 71.85s/it]  6%|▌         | 31/500 [34:53<8:38:34, 66.34s/it]  6%|▋         | 32/500 [36:16<9:15:06, 71.17s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.54E+07, Train scatter: [0.4507 0.0799 0.3543 0.9954]
L1 regularization loss: 2.66E+00, L2 regularization loss: 5.83E-01
Test scatter: [0.4513 0.0806 0.3593 0.985 ], Lowest was [0.4513 0.0806 0.3592 0.985 ]
Median for last 10 epochs: [0.4951 0.0835 0.3703 0.985 ], Epochs since improvement 0
  7%|▋         | 33/500 [37:09<8:32:36, 65.86s/it]  7%|▋         | 34/500 [38:30<9:06:59, 70.43s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.50E+07, Train scatter: [0.4506 0.0835 0.4027 0.9954]
L1 regularization loss: 2.67E+00, L2 regularization loss: 5.92E-01
Test scatter: [0.4513 0.084  0.4058 0.985 ], Lowest was [0.4513 0.0806 0.3592 0.985 ]
Median for last 10 epochs: [0.489  0.0835 0.3703 0.985 ], Epochs since improvement 0
  7%|▋         | 35/500 [39:24<8:26:25, 65.34s/it]  7%|▋         | 36/500 [40:44<9:00:48, 69.93s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.41E+07, Train scatter: [0.445  0.0807 0.3474 0.9953]
L1 regularization loss: 2.68E+00, L2 regularization loss: 5.99E-01
Test scatter: [0.4502 0.0802 0.353  0.985 ], Lowest was [0.4502 0.0802 0.353  0.985 ]
Median for last 10 epochs: [0.4513 0.0817 0.3593 0.985 ], Epochs since improvement 0
  7%|▋         | 37/500 [41:38<8:21:45, 65.02s/it]  8%|▊         | 38/500 [42:59<8:57:37, 69.82s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 7.33E+07, Train scatter: [0.3219 0.0767 0.3417 0.9954]
L1 regularization loss: 2.69E+00, L2 regularization loss: 6.10E-01
Test scatter: [0.3339 0.0771 0.3443 0.985 ], Lowest was [0.3339 0.0771 0.3443 0.985 ]
Median for last 10 epochs: [0.4513 0.0806 0.3592 0.985 ], Epochs since improvement 0
  8%|▊         | 39/500 [43:53<8:19:13, 64.98s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 7.14E+07, Train scatter: [0.5363 0.0844 0.3907 0.9954]
L1 regularization loss: 2.71E+00, L2 regularization loss: 6.23E-01
Test scatter: [0.536  0.0852 0.3928 0.985 ], Lowest was [0.3339 0.0771 0.3443 0.985 ]
Median for last 10 epochs: [0.4513 0.0806 0.3593 0.985 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:21<9:11:42, 71.96s/it]  8%|▊         | 41/500 [46:14<8:28:01, 66.41s/it]  8%|▊         | 42/500 [47:36<9:01:26, 70.93s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 6.71E+07, Train scatter: [0.5232 0.0827 0.3575 0.9946]
L1 regularization loss: 2.73E+00, L2 regularization loss: 6.39E-01
Test scatter: [0.5193 0.0816 0.355  0.9843], Lowest was [0.3339 0.0771 0.3443 0.9843]
Median for last 10 epochs: [0.4513 0.0816 0.355  0.985 ], Epochs since improvement 0
  9%|▊         | 43/500 [48:29<8:20:19, 65.69s/it]  9%|▉         | 44/500 [49:51<8:55:58, 70.52s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.31E+07, Train scatter: [0.3519 0.0757 0.3352 0.9935]
L1 regularization loss: 2.75E+00, L2 regularization loss: 6.59E-01
Test scatter: [0.3561 0.0762 0.3377 0.9834], Lowest was [0.3339 0.0762 0.3377 0.9834]
Median for last 10 epochs: [0.4502 0.0802 0.353  0.985 ], Epochs since improvement 0
  9%|▉         | 45/500 [50:45<8:15:57, 65.40s/it]  9%|▉         | 46/500 [52:06<8:51:03, 70.18s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.02E+07, Train scatter: [0.3353 0.0831 0.3514 0.7103]
L1 regularization loss: 2.79E+00, L2 regularization loss: 6.97E-01
Test scatter: [0.3359 0.0831 0.3521 0.7106], Lowest was [0.3339 0.0762 0.3377 0.7106]
Median for last 10 epochs: [0.3561 0.0816 0.3521 0.9843], Epochs since improvement 0
  9%|▉         | 47/500 [52:59<8:11:58, 65.16s/it] 10%|▉         | 48/500 [54:21<8:48:11, 70.11s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 5.38E+06, Train scatter: [0.306  0.077  0.3409 0.5617]
L1 regularization loss: 2.82E+00, L2 regularization loss: 7.25E-01
Test scatter: [0.3074 0.0772 0.3453 0.5625], Lowest was [0.3074 0.0762 0.3377 0.5625]
Median for last 10 epochs: [0.3561 0.0816 0.3521 0.9834], Epochs since improvement 0
 10%|▉         | 49/500 [55:14<8:09:34, 65.13s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 4.56E+06, Train scatter: [0.2996 0.0808 0.3465 0.6321]
L1 regularization loss: 2.84E+00, L2 regularization loss: 7.43E-01
Test scatter: [0.3089 0.0815 0.3501 0.6356], Lowest was [0.3074 0.0762 0.3377 0.5625]
Median for last 10 epochs: [0.3359 0.0815 0.3501 0.7106], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [56:43<9:01:49, 72.24s/it] 10%|█         | 51/500 [57:37<8:18:47, 66.65s/it] 10%|█         | 52/500 [58:58<8:50:37, 71.07s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 4.57E+06, Train scatter: [0.2753 0.0814 0.3546 0.5653]
L1 regularization loss: 2.87E+00, L2 regularization loss: 7.63E-01
Test scatter: [0.2866 0.0812 0.3618 0.5706], Lowest was [0.2866 0.0762 0.3377 0.5625]
Median for last 10 epochs: [0.3089 0.0812 0.3501 0.6356], Epochs since improvement 0
 11%|█         | 53/500 [59:52<8:10:27, 65.83s/it] 11%|█         | 54/500 [1:01:12<8:42:15, 70.26s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.98E+06, Train scatter: [0.2626 0.0727 0.3303 0.534 ]
L1 regularization loss: 2.88E+00, L2 regularization loss: 7.80E-01
Test scatter: [0.2676 0.0729 0.3351 0.5335], Lowest was [0.2676 0.0729 0.3351 0.5335]
Median for last 10 epochs: [0.3074 0.0812 0.3501 0.5706], Epochs since improvement 0
 11%|█         | 55/500 [1:02:06<8:03:58, 65.26s/it] 11%|█         | 56/500 [1:03:27<8:38:12, 70.03s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.04E+06, Train scatter: [0.2591 0.0729 0.3439 0.5335]
L1 regularization loss: 2.92E+00, L2 regularization loss: 8.08E-01
Test scatter: [0.2716 0.0731 0.3494 0.5355], Lowest was [0.2676 0.0729 0.3351 0.5335]
Median for last 10 epochs: [0.2866 0.0772 0.3494 0.5625], Epochs since improvement 2
 11%|█▏        | 57/500 [1:04:21<8:00:26, 65.07s/it] 12%|█▏        | 58/500 [1:05:41<8:33:57, 69.77s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.82E+06, Train scatter: [0.2458 0.0696 0.3255 0.5289]
L1 regularization loss: 2.94E+00, L2 regularization loss: 8.33E-01
Test scatter: [0.2535 0.0699 0.3294 0.5313], Lowest was [0.2535 0.0699 0.3294 0.5313]
Median for last 10 epochs: [0.2716 0.0731 0.3494 0.5355], Epochs since improvement 0
 12%|█▏        | 59/500 [1:06:35<7:56:14, 64.79s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.63E+07, Train scatter: [0.8864 0.1153 0.5436 0.6837]
L1 regularization loss: 3.05E+00, L2 regularization loss: 9.27E-01
Test scatter: [0.8708 0.1144 0.535  0.6747], Lowest was [0.2535 0.0699 0.3294 0.5313]
Median for last 10 epochs: [0.2716 0.0731 0.3494 0.5355], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:08:03<8:46:32, 71.80s/it] 12%|█▏        | 61/500 [1:08:56<8:04:27, 66.21s/it] 12%|█▏        | 62/500 [1:10:16<8:32:37, 70.22s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 7.84E+06, Train scatter: [0.5239 0.0974 0.4618 0.6218]
L1 regularization loss: 3.12E+00, L2 regularization loss: 1.09E+00
Test scatter: [0.5058 0.0961 0.4566 0.6217], Lowest was [0.2535 0.0699 0.3294 0.5313]
Median for last 10 epochs: [0.2716 0.0731 0.3494 0.5355], Epochs since improvement 4
 13%|█▎        | 63/500 [1:11:09<7:53:47, 65.05s/it] 13%|█▎        | 64/500 [1:12:29<8:25:59, 69.63s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 6.58E+06, Train scatter: [0.524  0.0933 0.4555 0.5914]
L1 regularization loss: 3.15E+00, L2 regularization loss: 1.17E+00
Test scatter: [0.5097 0.092  0.4572 0.5863], Lowest was [0.2535 0.0699 0.3294 0.5313]
Median for last 10 epochs: [0.5058 0.092  0.4566 0.5863], Epochs since improvement 6
 13%|█▎        | 65/500 [1:13:22<7:48:48, 64.66s/it] 13%|█▎        | 66/500 [1:14:42<8:21:09, 69.28s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 5.59E+06, Train scatter: [0.5145 0.0908 0.3949 0.5662]
L1 regularization loss: 3.16E+00, L2 regularization loss: 1.22E+00
Test scatter: [0.5084 0.0905 0.4003 0.5658], Lowest was [0.2535 0.0699 0.3294 0.5313]
Median for last 10 epochs: [0.5084 0.092  0.4566 0.5863], Epochs since improvement 8
 13%|█▎        | 67/500 [1:15:35<7:45:05, 64.45s/it] 14%|█▎        | 68/500 [1:16:55<8:17:11, 69.05s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 4.69E+06, Train scatter: [0.4868 0.0861 0.3735 0.5515]
L1 regularization loss: 3.17E+00, L2 regularization loss: 1.28E+00
Test scatter: [0.4772 0.0853 0.3774 0.5508], Lowest was [0.2535 0.0699 0.3294 0.5313]
Median for last 10 epochs: [0.5084 0.092  0.4566 0.5863], Epochs since improvement 10
 14%|█▍        | 69/500 [1:17:48<7:41:29, 64.24s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 7.95E+06, Train scatter: [0.6915 0.1022 0.5058 0.6455]
L1 regularization loss: 3.22E+00, L2 regularization loss: 1.40E+00
Test scatter: [0.6821 0.1016 0.4992 0.6418], Lowest was [0.2535 0.0699 0.3294 0.5313]
Median for last 10 epochs: [0.5084 0.092  0.4566 0.5863], Epochs since improvement 12
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:19:17<8:33:22, 71.63s/it] 14%|█▍        | 71/500 [1:20:10<7:52:35, 66.10s/it] 14%|█▍        | 72/500 [1:21:31<8:22:40, 70.47s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 5.44E+06, Train scatter: [0.4743 0.0884 0.4432 0.5789]
L1 regularization loss: 3.24E+00, L2 regularization loss: 1.46E+00
Test scatter: [0.4696 0.0873 0.4363 0.5761], Lowest was [0.2535 0.0699 0.3294 0.5313]
Median for last 10 epochs: [0.5084 0.0905 0.4363 0.5761], Epochs since improvement 14
 15%|█▍        | 73/500 [1:22:24<7:44:32, 65.27s/it] 15%|█▍        | 74/500 [1:23:44<8:15:35, 69.80s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 4.56E+06, Train scatter: [0.53   0.0846 0.3773 0.5622]
L1 regularization loss: 3.25E+00, L2 regularization loss: 1.51E+00
Test scatter: [0.5384 0.0855 0.3858 0.5735], Lowest was [0.2535 0.0699 0.3294 0.5313]
Median for last 10 epochs: [0.5084 0.0873 0.4003 0.5735], Epochs since improvement 16
 15%|█▌        | 75/500 [1:24:37<7:39:00, 64.80s/it] 15%|█▌        | 76/500 [1:25:57<8:09:26, 69.26s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 4.20E+06, Train scatter: [0.4924 0.0833 0.3741 0.544 ]
L1 regularization loss: 3.26E+00, L2 regularization loss: 1.54E+00
Test scatter: [0.5012 0.0841 0.3814 0.5497], Lowest was [0.2535 0.0699 0.3294 0.5313]
Median for last 10 epochs: [0.5012 0.0855 0.3858 0.5735], Epochs since improvement 18
 15%|█▌        | 77/500 [1:26:50<7:33:58, 64.39s/it] 16%|█▌        | 78/500 [1:28:11<8:07:43, 69.34s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.73E+06, Train scatter: [0.4318 0.0766 0.3489 0.529 ]
L1 regularization loss: 3.29E+00, L2 regularization loss: 1.58E+00
Test scatter: [0.425  0.0762 0.3526 0.5264], Lowest was [0.2535 0.0699 0.3294 0.5264]
Median for last 10 epochs: [0.5012 0.0855 0.3858 0.5735], Epochs since improvement 0
 16%|█▌        | 79/500 [1:29:04<7:32:09, 64.44s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 3.64E+06, Train scatter: [0.4877 0.0739 0.3435 0.5211]
L1 regularization loss: 3.31E+00, L2 regularization loss: 1.62E+00
Test scatter: [0.476  0.0739 0.3485 0.5238], Lowest was [0.2535 0.0699 0.3294 0.5238]
Median for last 10 epochs: [0.476  0.0841 0.3814 0.5497], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:30:33<8:22:03, 71.72s/it] 16%|█▌        | 81/500 [1:31:26<7:41:59, 66.16s/it] 16%|█▋        | 82/500 [1:32:46<8:10:52, 70.46s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 3.33E+06, Train scatter: [0.4176 0.0763 0.3421 0.5291]
L1 regularization loss: 3.32E+00, L2 regularization loss: 1.66E+00
Test scatter: [0.411  0.0763 0.3458 0.5301], Lowest was [0.2535 0.0699 0.3294 0.5238]
Median for last 10 epochs: [0.476  0.0763 0.3526 0.5301], Epochs since improvement 2
 17%|█▋        | 83/500 [1:33:39<7:33:18, 65.23s/it] 17%|█▋        | 84/500 [1:35:00<8:04:20, 69.86s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 3.19E+06, Train scatter: [0.4187 0.0772 0.337  0.5375]
L1 regularization loss: 3.34E+00, L2 regularization loss: 1.69E+00
Test scatter: [0.4131 0.0778 0.3399 0.5403], Lowest was [0.2535 0.0699 0.3294 0.5238]
Median for last 10 epochs: [0.425  0.0763 0.3485 0.5301], Epochs since improvement 4
 17%|█▋        | 85/500 [1:35:53<7:28:29, 64.84s/it] 17%|█▋        | 86/500 [1:37:13<7:58:44, 69.38s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.79E+06, Train scatter: [0.2583 0.0706 0.3177 0.4978]
L1 regularization loss: 3.36E+00, L2 regularization loss: 1.71E+00
Test scatter: [0.2669 0.0703 0.3213 0.4981], Lowest was [0.2535 0.0699 0.3213 0.4981]
Median for last 10 epochs: [0.4131 0.0762 0.3458 0.5264], Epochs since improvement 0
 17%|█▋        | 87/500 [1:38:06<7:23:57, 64.50s/it] 18%|█▊        | 88/500 [1:39:26<7:54:56, 69.17s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.68E+06, Train scatter: [0.2548 0.0692 0.3227 0.5048]
L1 regularization loss: 3.38E+00, L2 regularization loss: 1.73E+00
Test scatter: [0.2646 0.0682 0.3263 0.4944], Lowest was [0.2535 0.0682 0.3213 0.4944]
Median for last 10 epochs: [0.411  0.0739 0.3399 0.5238], Epochs since improvement 0
 18%|█▊        | 89/500 [1:40:20<7:20:58, 64.38s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.65E+06, Train scatter: [0.2713 0.0658 0.3073 0.4874]
L1 regularization loss: 3.40E+00, L2 regularization loss: 1.76E+00
Test scatter: [0.272  0.0653 0.3136 0.488 ], Lowest was [0.2535 0.0653 0.3136 0.488 ]
Median for last 10 epochs: [0.272  0.0703 0.3263 0.4981], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:41:48<8:08:40, 71.51s/it] 18%|█▊        | 91/500 [1:42:41<7:29:47, 65.98s/it] 18%|█▊        | 92/500 [1:44:01<7:58:10, 70.32s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.45E+06, Train scatter: [0.2677 0.0691 0.3065 0.4988]
L1 regularization loss: 3.42E+00, L2 regularization loss: 1.78E+00
Test scatter: [0.2702 0.0693 0.312  0.4962], Lowest was [0.2535 0.0653 0.312  0.488 ]
Median for last 10 epochs: [0.2702 0.0693 0.3213 0.4962], Epochs since improvement 0
 19%|█▊        | 93/500 [1:44:54<7:21:43, 65.12s/it] 19%|█▉        | 94/500 [1:46:15<7:52:22, 69.81s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.42E+06, Train scatter: [0.2372 0.0704 0.3116 0.4964]
L1 regularization loss: 3.43E+00, L2 regularization loss: 1.79E+00
Test scatter: [0.2488 0.0718 0.3205 0.4926], Lowest was [0.2488 0.0653 0.312  0.488 ]
Median for last 10 epochs: [0.2669 0.0693 0.3205 0.4944], Epochs since improvement 0
 19%|█▉        | 95/500 [1:47:08<7:17:20, 64.79s/it] 19%|█▉        | 96/500 [1:48:29<7:48:29, 69.58s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.33E+06, Train scatter: [0.2453 0.069  0.3002 0.4748]
L1 regularization loss: 3.45E+00, L2 regularization loss: 1.81E+00
Test scatter: [0.2558 0.0705 0.3093 0.4783], Lowest was [0.2488 0.0653 0.3093 0.4783]
Median for last 10 epochs: [0.2646 0.0693 0.3136 0.4926], Epochs since improvement 0
 19%|█▉        | 97/500 [1:49:22<7:14:11, 64.65s/it] 20%|█▉        | 98/500 [1:50:42<7:44:14, 69.29s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.21E+06, Train scatter: [0.2447 0.0605 0.2935 0.4734]
L1 regularization loss: 3.47E+00, L2 regularization loss: 1.82E+00
Test scatter: [0.2482 0.0612 0.2961 0.4673], Lowest was [0.2482 0.0612 0.2961 0.4673]
Median for last 10 epochs: [0.2558 0.0693 0.312  0.488 ], Epochs since improvement 0
 20%|█▉        | 99/500 [1:51:35<7:10:34, 64.42s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 2.09E+06, Train scatter: [0.2506 0.0603 0.2948 0.4612]
L1 regularization loss: 3.48E+00, L2 regularization loss: 1.83E+00
Test scatter: [0.2586 0.0627 0.3007 0.4693], Lowest was [0.2482 0.0612 0.2961 0.4673]
Median for last 10 epochs: [0.2558 0.0693 0.3093 0.4783], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:53:02<7:55:16, 71.29s/it] 20%|██        | 101/500 [1:53:56<7:17:51, 65.84s/it] 20%|██        | 102/500 [1:55:16<7:44:58, 70.10s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 2.08E+06, Train scatter: [0.2268 0.0587 0.2958 0.4697]
L1 regularization loss: 3.49E+00, L2 regularization loss: 1.84E+00
Test scatter: [0.2322 0.0598 0.2973 0.4701], Lowest was [0.2322 0.0598 0.2961 0.4673]
Median for last 10 epochs: [0.2488 0.0627 0.3007 0.4701], Epochs since improvement 0
 21%|██        | 103/500 [1:56:09<7:09:56, 64.98s/it] 21%|██        | 104/500 [1:57:30<7:40:42, 69.80s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 1.95E+06, Train scatter: [0.2334 0.0643 0.2928 0.5004]
L1 regularization loss: 3.51E+00, L2 regularization loss: 1.85E+00
Test scatter: [0.2359 0.0631 0.2912 0.4785], Lowest was [0.2322 0.0598 0.2912 0.4673]
Median for last 10 epochs: [0.2482 0.0627 0.2973 0.4701], Epochs since improvement 0
 21%|██        | 105/500 [1:58:23<7:06:22, 64.77s/it] 21%|██        | 106/500 [1:59:43<7:35:21, 69.34s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 1.85E+06, Train scatter: [0.2276 0.0567 0.279  0.4505]
L1 regularization loss: 3.52E+00, L2 regularization loss: 1.86E+00
Test scatter: [0.2302 0.0573 0.2822 0.4474], Lowest was [0.2302 0.0573 0.2822 0.4474]
Median for last 10 epochs: [0.2359 0.0612 0.2961 0.4693], Epochs since improvement 0
 21%|██▏       | 107/500 [2:00:36<7:02:20, 64.48s/it] 22%|██▏       | 108/500 [2:01:56<7:32:38, 69.28s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 1.72E+06, Train scatter: [0.2733 0.0627 0.3031 0.4839]
L1 regularization loss: 3.53E+00, L2 regularization loss: 1.88E+00
Test scatter: [0.2786 0.0633 0.3037 0.488 ], Lowest was [0.2302 0.0573 0.2822 0.4474]
Median for last 10 epochs: [0.2359 0.0627 0.2973 0.4701], Epochs since improvement 2
 22%|██▏       | 109/500 [2:02:49<6:59:42, 64.41s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 1.54E+06, Train scatter: [0.3778 0.0708 0.2849 0.4723]
L1 regularization loss: 3.54E+00, L2 regularization loss: 1.89E+00
Test scatter: [0.3745 0.0714 0.2908 0.4712], Lowest was [0.2302 0.0573 0.2822 0.4474]
Median for last 10 epochs: [0.2359 0.0631 0.2912 0.4712], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:04:17<7:44:05, 71.40s/it] 22%|██▏       | 111/500 [2:05:10<7:07:23, 65.92s/it] 22%|██▏       | 112/500 [2:06:30<7:33:08, 70.07s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.50E+06, Train scatter: [0.2231 0.0558 0.2771 0.4453]
L1 regularization loss: 3.55E+00, L2 regularization loss: 1.89E+00
Test scatter: [0.2287 0.0568 0.2801 0.443 ], Lowest was [0.2287 0.0568 0.2801 0.443 ]
Median for last 10 epochs: [0.2359 0.0631 0.2908 0.4712], Epochs since improvement 0
 23%|██▎       | 113/500 [2:07:23<6:59:06, 64.98s/it] 23%|██▎       | 114/500 [2:08:43<7:27:48, 69.61s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.47E+06, Train scatter: [0.2131 0.0551 0.2791 0.441 ]
L1 regularization loss: 3.57E+00, L2 regularization loss: 1.91E+00
Test scatter: [0.2217 0.0568 0.2853 0.4512], Lowest was [0.2217 0.0568 0.2801 0.443 ]
Median for last 10 epochs: [0.2302 0.0573 0.2853 0.4512], Epochs since improvement 0
 23%|██▎       | 115/500 [2:09:37<6:55:00, 64.68s/it] 23%|██▎       | 116/500 [2:10:57<7:25:00, 69.53s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.48E+06, Train scatter: [0.2385 0.0607 0.2785 0.4492]
L1 regularization loss: 3.58E+00, L2 regularization loss: 1.92E+00
Test scatter: [0.2378 0.0608 0.2796 0.4489], Lowest was [0.2217 0.0568 0.2796 0.443 ]
Median for last 10 epochs: [0.2378 0.0608 0.2853 0.4512], Epochs since improvement 0
 23%|██▎       | 117/500 [2:11:51<6:52:14, 64.58s/it] 24%|██▎       | 118/500 [2:13:11<7:21:45, 69.39s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.28E+06, Train scatter: [0.2116 0.057  0.2816 0.4422]
L1 regularization loss: 3.59E+00, L2 regularization loss: 1.93E+00
Test scatter: [0.216  0.0576 0.2856 0.4456], Lowest was [0.216  0.0568 0.2796 0.443 ]
Median for last 10 epochs: [0.2287 0.0576 0.2853 0.4489], Epochs since improvement 0
 24%|██▍       | 119/500 [2:14:04<6:49:34, 64.50s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.27E+06, Train scatter: [0.2692 0.0551 0.2794 0.4528]
L1 regularization loss: 3.61E+00, L2 regularization loss: 1.95E+00
Test scatter: [0.2699 0.0551 0.286  0.4484], Lowest was [0.216  0.0551 0.2796 0.443 ]
Median for last 10 epochs: [0.2287 0.0568 0.2853 0.4484], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 24%|██▍       | 120/500 [2:15:31<7:31:47, 71.34s/it] 24%|██▍       | 121/500 [2:16:25<6:55:57, 65.85s/it] 24%|██▍       | 122/500 [2:17:46<7:24:34, 70.57s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 1.28E+06, Train scatter: [0.2176 0.0628 0.2789 0.4437]
L1 regularization loss: 3.64E+00, L2 regularization loss: 1.98E+00
Test scatter: [0.2234 0.0622 0.2823 0.4404], Lowest was [0.216  0.0551 0.2796 0.4404]
Median for last 10 epochs: [0.2234 0.0576 0.2853 0.4484], Epochs since improvement 0
 25%|██▍       | 123/500 [2:18:39<6:50:45, 65.37s/it] 25%|██▍       | 124/500 [2:20:00<7:17:46, 69.86s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.42E+06, Train scatter: [0.2068 0.0541 0.2749 0.4305]
L1 regularization loss: 3.66E+00, L2 regularization loss: 2.01E+00
Test scatter: [0.2111 0.0547 0.2775 0.4296], Lowest was [0.2111 0.0547 0.2775 0.4296]
Median for last 10 epochs: [0.2234 0.0576 0.2823 0.4456], Epochs since improvement 0
 25%|██▌       | 125/500 [2:20:53<6:45:05, 64.81s/it] 25%|██▌       | 126/500 [2:22:13<7:12:57, 69.46s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.19E+06, Train scatter: [0.2183 0.0559 0.2768 0.4439]
L1 regularization loss: 3.67E+00, L2 regularization loss: 2.03E+00
Test scatter: [0.2217 0.0559 0.2795 0.444 ], Lowest was [0.2111 0.0547 0.2775 0.4296]
Median for last 10 epochs: [0.2217 0.0559 0.2823 0.444 ], Epochs since improvement 2
 25%|██▌       | 127/500 [2:23:06<6:41:08, 64.53s/it] 26%|██▌       | 128/500 [2:24:28<7:11:50, 69.65s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 1.13E+06, Train scatter: [0.1962 0.0512 0.266  0.425 ]
L1 regularization loss: 3.69E+00, L2 regularization loss: 2.05E+00
Test scatter: [0.1991 0.051  0.2674 0.4225], Lowest was [0.1991 0.051  0.2674 0.4225]
Median for last 10 epochs: [0.2217 0.0551 0.2795 0.4404], Epochs since improvement 0
 26%|██▌       | 129/500 [2:25:21<6:39:57, 64.68s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 1.20E+06, Train scatter: [0.2309 0.0577 0.2907 0.4841]
L1 regularization loss: 3.70E+00, L2 regularization loss: 2.06E+00
Test scatter: [0.2305 0.0569 0.29   0.4783], Lowest was [0.1991 0.051  0.2674 0.4225]
Median for last 10 epochs: [0.2217 0.0559 0.2795 0.4404], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 26%|██▌       | 130/500 [2:26:48<7:20:07, 71.37s/it] 26%|██▌       | 131/500 [2:27:41<6:45:11, 65.88s/it] 26%|██▋       | 132/500 [2:29:01<7:10:41, 70.22s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 1.11E+06, Train scatter: [0.2186 0.054  0.2722 0.4392]
L1 regularization loss: 3.71E+00, L2 regularization loss: 2.08E+00
Test scatter: [0.2202 0.0539 0.2763 0.4355], Lowest was [0.1991 0.051  0.2674 0.4225]
Median for last 10 epochs: [0.2202 0.0547 0.2775 0.4355], Epochs since improvement 4
 27%|██▋       | 133/500 [2:29:54<6:38:05, 65.08s/it] 27%|██▋       | 134/500 [2:31:15<7:05:14, 69.71s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 1.03E+06, Train scatter: [0.2157 0.0529 0.2664 0.4192]
L1 regularization loss: 3.72E+00, L2 regularization loss: 2.10E+00
Test scatter: [0.2151 0.0525 0.2693 0.4166], Lowest was [0.1991 0.051  0.2674 0.4166]
Median for last 10 epochs: [0.2202 0.0539 0.2763 0.4355], Epochs since improvement 0
 27%|██▋       | 135/500 [2:32:08<6:34:09, 64.79s/it] 27%|██▋       | 136/500 [2:33:29<7:01:44, 69.52s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 1.00E+06, Train scatter: [0.2197 0.0523 0.264  0.4205]
L1 regularization loss: 3.73E+00, L2 regularization loss: 2.11E+00
Test scatter: [0.2167 0.052  0.265  0.4172], Lowest was [0.1991 0.051  0.265  0.4166]
Median for last 10 epochs: [0.2167 0.0525 0.2693 0.4225], Epochs since improvement 0
 27%|██▋       | 137/500 [2:34:22<6:30:38, 64.57s/it] 28%|██▊       | 138/500 [2:35:42<6:57:20, 69.17s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: 9.53E+05, Train scatter: [0.2705 0.0538 0.2766 0.459 ]
L1 regularization loss: 3.74E+00, L2 regularization loss: 2.13E+00
Test scatter: [0.265  0.0531 0.2772 0.4586], Lowest was [0.1991 0.051  0.265  0.4166]
Median for last 10 epochs: [0.2202 0.0531 0.2763 0.4355], Epochs since improvement 2
 28%|██▊       | 139/500 [2:36:35<6:27:15, 64.36s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: 8.83E+05, Train scatter: [0.2205 0.0505 0.2749 0.4194]
L1 regularization loss: 3.75E+00, L2 regularization loss: 2.14E+00
Test scatter: [0.2207 0.0504 0.2794 0.4154], Lowest was [0.1991 0.0504 0.265  0.4154]
Median for last 10 epochs: [0.2202 0.0525 0.2763 0.4172], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 28%|██▊       | 140/500 [2:38:02<7:07:35, 71.27s/it] 28%|██▊       | 141/500 [2:38:55<6:33:47, 65.82s/it] 28%|██▊       | 142/500 [2:40:15<6:58:30, 70.14s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: 9.37E+05, Train scatter: [0.1832 0.0545 0.2671 0.4252]
L1 regularization loss: 3.78E+00, L2 regularization loss: 2.17E+00
Test scatter: [0.1847 0.054  0.2649 0.4147], Lowest was [0.1847 0.0504 0.2649 0.4147]
Median for last 10 epochs: [0.2167 0.0525 0.2693 0.4166], Epochs since improvement 0
 29%|██▊       | 143/500 [2:41:08<6:26:47, 65.01s/it] 29%|██▉       | 144/500 [2:42:29<6:54:08, 69.80s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 8.05E+05, Train scatter: [0.1877 0.053  0.2656 0.4194]
L1 regularization loss: 3.79E+00, L2 regularization loss: 2.18E+00
Test scatter: [0.1898 0.0533 0.2677 0.4209], Lowest was [0.1847 0.0504 0.2649 0.4147]
Median for last 10 epochs: [0.2167 0.0531 0.2677 0.4172], Epochs since improvement 2
 29%|██▉       | 145/500 [2:43:22<6:23:12, 64.77s/it] 29%|██▉       | 146/500 [2:44:44<6:51:23, 69.73s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 7.96E+05, Train scatter: [0.1729 0.0503 0.2592 0.4186]
L1 regularization loss: 3.81E+00, L2 regularization loss: 2.20E+00
Test scatter: [0.1766 0.0499 0.2605 0.413 ], Lowest was [0.1766 0.0499 0.2605 0.413 ]
Median for last 10 epochs: [0.1898 0.0531 0.2677 0.4154], Epochs since improvement 0
 29%|██▉       | 147/500 [2:45:37<6:20:54, 64.74s/it] 30%|██▉       | 148/500 [2:47:00<6:52:08, 70.25s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 7.48E+05, Train scatter: [0.2615 0.049  0.2546 0.4107]
L1 regularization loss: 3.82E+00, L2 regularization loss: 2.22E+00
Test scatter: [0.2584 0.0489 0.256  0.4086], Lowest was [0.1766 0.0489 0.256  0.4086]
Median for last 10 epochs: [0.1898 0.0504 0.2649 0.4147], Epochs since improvement 0
 30%|██▉       | 149/500 [2:47:54<6:21:42, 65.25s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 1.16E+06, Train scatter: [0.1857 0.0523 0.2811 0.4387]
L1 regularization loss: 3.86E+00, L2 regularization loss: 2.26E+00
Test scatter: [0.1905 0.0528 0.282  0.433 ], Lowest was [0.1766 0.0489 0.256  0.4086]
Median for last 10 epochs: [0.1898 0.0528 0.2649 0.4147], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 30%|███       | 150/500 [2:49:24<7:04:12, 72.72s/it] 30%|███       | 151/500 [2:50:17<6:28:39, 66.82s/it] 30%|███       | 152/500 [2:51:36<6:49:32, 70.61s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 7.08E+05, Train scatter: [0.1693 0.049  0.2619 0.4146]
L1 regularization loss: 3.87E+00, L2 regularization loss: 2.28E+00
Test scatter: [0.1735 0.0491 0.2635 0.4119], Lowest was [0.1735 0.0489 0.256  0.4086]
Median for last 10 epochs: [0.1898 0.0499 0.2635 0.413 ], Epochs since improvement 0
 31%|███       | 153/500 [2:52:29<6:17:42, 65.31s/it] 31%|███       | 154/500 [2:53:50<6:43:29, 69.97s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 6.02E+05, Train scatter: [0.2453 0.0606 0.2898 0.4483]
L1 regularization loss: 3.89E+00, L2 regularization loss: 2.30E+00
Test scatter: [0.2334 0.0606 0.2912 0.4496], Lowest was [0.1735 0.0489 0.256  0.4086]
Median for last 10 epochs: [0.1905 0.0499 0.2635 0.413 ], Epochs since improvement 2
 31%|███       | 155/500 [2:54:43<6:13:06, 64.89s/it] 31%|███       | 156/500 [2:56:04<6:39:12, 69.63s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 5.26E+05, Train scatter: [0.1688 0.0471 0.2512 0.4077]
L1 regularization loss: 3.91E+00, L2 regularization loss: 2.33E+00
Test scatter: [0.1699 0.0471 0.2517 0.4015], Lowest was [0.1699 0.0471 0.2517 0.4015]
Median for last 10 epochs: [0.1905 0.0491 0.2635 0.4119], Epochs since improvement 0
 31%|███▏      | 157/500 [2:56:57<6:09:22, 64.61s/it] 32%|███▏      | 158/500 [2:58:17<6:35:38, 69.41s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 4.60E+05, Train scatter: [0.2317 0.0701 0.2986 0.5299]
L1 regularization loss: 3.93E+00, L2 regularization loss: 2.35E+00
Test scatter: [0.2271 0.0698 0.3015 0.532 ], Lowest was [0.1699 0.0471 0.2517 0.4015]
Median for last 10 epochs: [0.1905 0.0528 0.282  0.433 ], Epochs since improvement 2
 32%|███▏      | 159/500 [2:59:10<6:06:28, 64.48s/it]Epoch: 160 done with learning rate 9.04E-03, Train loss: 3.83E+05, Train scatter: [0.1838 0.0589 0.2942 0.4407]
L1 regularization loss: 3.96E+00, L2 regularization loss: 2.39E+00
Test scatter: [0.1793 0.0588 0.2961 0.4423], Lowest was [0.1699 0.0471 0.2517 0.4015]
Median for last 10 epochs: [0.1793 0.0588 0.2912 0.4423], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 32%|███▏      | 160/500 [3:00:38<6:44:15, 71.34s/it] 32%|███▏      | 161/500 [3:01:31<6:12:10, 65.87s/it] 32%|███▏      | 162/500 [3:02:51<6:36:22, 70.36s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: 2.92E+05, Train scatter: [0.1779 0.0528 0.2711 0.4259]
L1 regularization loss: 3.99E+00, L2 regularization loss: 2.41E+00
Test scatter: [0.1764 0.0528 0.273  0.4281], Lowest was [0.1699 0.0471 0.2517 0.4015]
Median for last 10 epochs: [0.1793 0.0588 0.2912 0.4423], Epochs since improvement 6
 33%|███▎      | 163/500 [3:03:45<6:06:01, 65.17s/it] 33%|███▎      | 164/500 [3:05:05<6:30:18, 69.70s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: 2.31E+05, Train scatter: [0.1803 0.0502 0.2567 0.4089]
L1 regularization loss: 4.00E+00, L2 regularization loss: 2.43E+00
Test scatter: [0.1787 0.0498 0.259  0.403 ], Lowest was [0.1699 0.0471 0.2517 0.4015]
Median for last 10 epochs: [0.1787 0.0528 0.273  0.4281], Epochs since improvement 8
 33%|███▎      | 165/500 [3:05:58<6:01:18, 64.71s/it] 33%|███▎      | 166/500 [3:07:19<6:27:17, 69.57s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: 1.62E+05, Train scatter: [0.1445 0.0441 0.251  0.3998]
L1 regularization loss: 4.02E+00, L2 regularization loss: 2.46E+00
Test scatter: [0.1469 0.0439 0.2485 0.3945], Lowest was [0.1469 0.0439 0.2485 0.3945]
Median for last 10 epochs: [0.1787 0.0528 0.273  0.4281], Epochs since improvement 0
 33%|███▎      | 167/500 [3:08:12<5:58:30, 64.60s/it] 34%|███▎      | 168/500 [3:09:33<6:24:40, 69.52s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: 7.10E+04, Train scatter: [0.1873 0.0516 0.2792 0.4479]
L1 regularization loss: 4.05E+00, L2 regularization loss: 2.49E+00
Test scatter: [0.1853 0.0512 0.2809 0.4516], Lowest was [0.1469 0.0439 0.2485 0.3945]
Median for last 10 epochs: [0.1787 0.0512 0.273  0.4281], Epochs since improvement 2
 34%|███▍      | 169/500 [3:10:26<5:56:08, 64.56s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -6.44E+03, Train scatter: [0.2193 0.0481 0.2437 0.3985]
L1 regularization loss: 4.06E+00, L2 regularization loss: 2.51E+00
Test scatter: [0.2165 0.048  0.2469 0.4021], Lowest was [0.1469 0.0439 0.2469 0.3945]
Median for last 10 epochs: [0.1787 0.0498 0.259  0.403 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 34%|███▍      | 170/500 [3:11:53<6:33:08, 71.48s/it] 34%|███▍      | 171/500 [3:12:47<6:02:00, 66.02s/it] 34%|███▍      | 172/500 [3:14:07<6:24:13, 70.28s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -7.51E+04, Train scatter: [0.1432 0.0479 0.249  0.3969]
L1 regularization loss: 4.07E+00, L2 regularization loss: 2.53E+00
Test scatter: [0.1438 0.0474 0.2465 0.3946], Lowest was [0.1438 0.0439 0.2465 0.3945]
Median for last 10 epochs: [0.1787 0.048  0.2485 0.4021], Epochs since improvement 0
 35%|███▍      | 173/500 [3:15:00<5:54:56, 65.13s/it] 35%|███▍      | 174/500 [3:16:20<6:18:27, 69.66s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -1.12E+05, Train scatter: [0.1708 0.0438 0.2392 0.3872]
L1 regularization loss: 4.09E+00, L2 regularization loss: 2.56E+00
Test scatter: [0.1711 0.0434 0.2415 0.3866], Lowest was [0.1438 0.0434 0.2415 0.3866]
Median for last 10 epochs: [0.1711 0.0474 0.2469 0.3946], Epochs since improvement 0
 35%|███▌      | 175/500 [3:17:13<5:50:31, 64.71s/it] 35%|███▌      | 176/500 [3:18:34<6:15:03, 69.46s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -1.80E+05, Train scatter: [0.1366 0.043  0.2297 0.3853]
L1 regularization loss: 4.09E+00, L2 regularization loss: 2.59E+00
Test scatter: [0.1386 0.0428 0.2319 0.3837], Lowest was [0.1386 0.0428 0.2319 0.3837]
Median for last 10 epochs: [0.1711 0.0474 0.2465 0.3946], Epochs since improvement 0
 35%|███▌      | 177/500 [3:19:27<5:47:32, 64.56s/it] 36%|███▌      | 178/500 [3:20:47<6:12:00, 69.32s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -2.28E+05, Train scatter: [0.1786 0.0433 0.2288 0.3854]
L1 regularization loss: 4.11E+00, L2 regularization loss: 2.61E+00
Test scatter: [0.1793 0.043  0.233  0.3851], Lowest was [0.1386 0.0428 0.2319 0.3837]
Median for last 10 epochs: [0.1711 0.0434 0.2415 0.3866], Epochs since improvement 2
 36%|███▌      | 179/500 [3:21:41<5:45:02, 64.49s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -2.63E+05, Train scatter: [0.1457 0.0486 0.2478 0.4148]
L1 regularization loss: 4.12E+00, L2 regularization loss: 2.64E+00
Test scatter: [0.1461 0.049  0.2489 0.4091], Lowest was [0.1386 0.0428 0.2319 0.3837]
Median for last 10 epochs: [0.1461 0.0434 0.2415 0.3866], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 36%|███▌      | 180/500 [3:23:08<6:19:44, 71.20s/it] 36%|███▌      | 181/500 [3:24:01<5:49:56, 65.82s/it] 36%|███▋      | 182/500 [3:25:21<6:12:05, 70.21s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -2.69E+05, Train scatter: [0.3479 0.0511 0.2564 0.4119]
L1 regularization loss: 4.15E+00, L2 regularization loss: 2.68E+00
Test scatter: [0.342  0.0505 0.2562 0.406 ], Lowest was [0.1386 0.0428 0.2319 0.3837]
Median for last 10 epochs: [0.1711 0.0434 0.2415 0.3866], Epochs since improvement 6
 37%|███▋      | 183/500 [3:26:14<5:43:40, 65.05s/it] 37%|███▋      | 184/500 [3:27:35<6:06:49, 69.65s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -3.07E+05, Train scatter: [0.3564 0.0421 0.2259 0.3829]
L1 regularization loss: 4.16E+00, L2 regularization loss: 2.70E+00
Test scatter: [0.3468 0.0419 0.2291 0.3807], Lowest was [0.1386 0.0419 0.2291 0.3807]
Median for last 10 epochs: [0.1793 0.043  0.233  0.3851], Epochs since improvement 0
 37%|███▋      | 185/500 [3:28:28<5:39:36, 64.69s/it] 37%|███▋      | 186/500 [3:29:48<6:02:23, 69.25s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -3.26E+05, Train scatter: [0.1378 0.0422 0.2183 0.382 ]
L1 regularization loss: 4.18E+00, L2 regularization loss: 2.73E+00
Test scatter: [0.1378 0.0421 0.223  0.3832], Lowest was [0.1378 0.0419 0.223  0.3807]
Median for last 10 epochs: [0.1793 0.043  0.233  0.3851], Epochs since improvement 0
 37%|███▋      | 187/500 [3:30:41<5:35:50, 64.38s/it] 38%|███▊      | 188/500 [3:32:02<6:00:29, 69.32s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -3.26E+05, Train scatter: [0.138  0.0426 0.2282 0.384 ]
L1 regularization loss: 4.22E+00, L2 regularization loss: 2.77E+00
Test scatter: [0.1404 0.0424 0.229  0.3842], Lowest was [0.1378 0.0419 0.223  0.3807]
Median for last 10 epochs: [0.1461 0.0424 0.2291 0.3842], Epochs since improvement 2
 38%|███▊      | 189/500 [3:32:55<5:33:54, 64.42s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -3.65E+05, Train scatter: [0.1431 0.0454 0.2418 0.4004]
L1 regularization loss: 4.23E+00, L2 regularization loss: 2.81E+00
Test scatter: [0.1443 0.045  0.2452 0.4021], Lowest was [0.1378 0.0419 0.223  0.3807]
Median for last 10 epochs: [0.1443 0.0424 0.2291 0.3842], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 38%|███▊      | 190/500 [3:34:22<6:08:44, 71.37s/it] 38%|███▊      | 191/500 [3:35:15<5:39:10, 65.86s/it] 38%|███▊      | 192/500 [3:36:35<5:59:40, 70.07s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -3.80E+05, Train scatter: [0.3181 0.0477 0.2394 0.4044]
L1 regularization loss: 4.25E+00, L2 regularization loss: 2.84E+00
Test scatter: [0.3097 0.0469 0.2381 0.3975], Lowest was [0.1378 0.0419 0.223  0.3807]
Median for last 10 epochs: [0.1443 0.0424 0.2291 0.3842], Epochs since improvement 6
 39%|███▊      | 193/500 [3:37:28<5:32:09, 64.92s/it] 39%|███▉      | 194/500 [3:38:48<5:54:49, 69.57s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -3.68E+05, Train scatter: [0.3646 0.0419 0.2244 0.3846]
L1 regularization loss: 4.29E+00, L2 regularization loss: 2.88E+00
Test scatter: [0.3558 0.0417 0.2283 0.3833], Lowest was [0.1378 0.0417 0.223  0.3807]
Median for last 10 epochs: [0.1443 0.0424 0.229  0.3842], Epochs since improvement 0
 39%|███▉      | 195/500 [3:39:41<5:28:28, 64.62s/it] 39%|███▉      | 196/500 [3:41:02<5:51:31, 69.38s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -3.82E+05, Train scatter: [0.3502 0.0411 0.2269 0.3865]
L1 regularization loss: 4.28E+00, L2 regularization loss: 2.89E+00
Test scatter: [0.3399 0.0411 0.2314 0.3891], Lowest was [0.1378 0.0411 0.223  0.3807]
Median for last 10 epochs: [0.3097 0.0424 0.2314 0.3891], Epochs since improvement 0
 39%|███▉      | 197/500 [3:41:55<5:25:29, 64.45s/it] 40%|███▉      | 198/500 [3:43:16<5:49:35, 69.46s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -3.94E+05, Train scatter: [0.3639 0.0492 0.2339 0.4132]
L1 regularization loss: 4.28E+00, L2 regularization loss: 2.90E+00
Test scatter: [0.3542 0.0481 0.2353 0.4084], Lowest was [0.1378 0.0411 0.223  0.3807]
Median for last 10 epochs: [0.3399 0.045  0.2353 0.3975], Epochs since improvement 2
 40%|███▉      | 199/500 [3:44:09<5:23:41, 64.52s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -3.68E+05, Train scatter: [0.3981 0.0438 0.2201 0.3915]
L1 regularization loss: 4.33E+00, L2 regularization loss: 2.93E+00
Test scatter: [0.3873 0.0432 0.2227 0.3887], Lowest was [0.1378 0.0411 0.2227 0.3807]
Median for last 10 epochs: [0.3542 0.0432 0.2314 0.3891], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 40%|████      | 200/500 [3:45:37<5:58:13, 71.64s/it] 40%|████      | 201/500 [3:46:30<5:29:08, 66.05s/it] 40%|████      | 202/500 [3:47:50<5:48:13, 70.11s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -3.97E+05, Train scatter: [0.1613 0.0483 0.2557 0.4244]
L1 regularization loss: 4.35E+00, L2 regularization loss: 2.96E+00
Test scatter: [0.1643 0.0479 0.2581 0.4214], Lowest was [0.1378 0.0411 0.2227 0.3807]
Median for last 10 epochs: [0.3542 0.0432 0.2314 0.3891], Epochs since improvement 2
 41%|████      | 203/500 [3:48:43<5:21:32, 64.96s/it] 41%|████      | 204/500 [3:50:03<5:43:05, 69.55s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -3.88E+05, Train scatter: [0.3359 0.0434 0.2237 0.3992]
L1 regularization loss: 4.44E+00, L2 regularization loss: 3.04E+00
Test scatter: [0.327  0.0434 0.2288 0.3965], Lowest was [0.1378 0.0411 0.2227 0.3807]
Median for last 10 epochs: [0.3399 0.0434 0.2314 0.3965], Epochs since improvement 4
 41%|████      | 205/500 [3:50:56<5:17:31, 64.58s/it] 41%|████      | 206/500 [3:52:16<5:38:42, 69.13s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -3.97E+05, Train scatter: [0.2516 0.0456 0.2478 0.422 ]
L1 regularization loss: 4.45E+00, L2 regularization loss: 3.07E+00
Test scatter: [0.2445 0.0458 0.2537 0.4209], Lowest was [0.1378 0.0411 0.2227 0.3807]
Median for last 10 epochs: [0.327  0.0458 0.2353 0.4084], Epochs since improvement 6
 41%|████▏     | 207/500 [3:53:09<5:13:51, 64.27s/it] 42%|████▏     | 208/500 [3:54:30<5:36:59, 69.24s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -4.04E+05, Train scatter: [0.1575 0.0421 0.214  0.3931]
L1 regularization loss: 4.49E+00, L2 regularization loss: 3.09E+00
Test scatter: [0.1559 0.0416 0.2175 0.3884], Lowest was [0.1378 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.2445 0.0434 0.2288 0.3965], Epochs since improvement 0
 42%|████▏     | 209/500 [3:55:22<5:11:54, 64.31s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -4.17E+05, Train scatter: [0.1331 0.0448 0.248  0.4234]
L1 regularization loss: 4.51E+00, L2 regularization loss: 3.10E+00
Test scatter: [0.1337 0.0441 0.25   0.4176], Lowest was [0.1337 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.1643 0.0441 0.25   0.4176], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 42%|████▏     | 210/500 [3:56:49<5:43:18, 71.03s/it] 42%|████▏     | 211/500 [3:57:42<5:16:12, 65.65s/it] 42%|████▏     | 212/500 [3:59:03<5:36:45, 70.16s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -4.17E+05, Train scatter: [0.1262 0.0421 0.2287 0.3983]
L1 regularization loss: 4.52E+00, L2 regularization loss: 3.12E+00
Test scatter: [0.1276 0.042  0.2334 0.3961], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.1559 0.0434 0.2334 0.3965], Epochs since improvement 0
 43%|████▎     | 213/500 [3:59:56<5:11:02, 65.03s/it] 43%|████▎     | 214/500 [4:01:17<5:33:32, 69.97s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: 5.35E+04, Train scatter: [0.9348 0.1722 0.5404 0.9894]
L1 regularization loss: 6.33E+00, L2 regularization loss: 3.79E+00
Test scatter: [0.9192 0.1683 0.532  0.9792], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.1559 0.0441 0.25   0.4176], Epochs since improvement 2
 43%|████▎     | 215/500 [4:02:10<5:08:10, 64.88s/it] 43%|████▎     | 216/500 [4:03:31<5:29:33, 69.63s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -4.47E+04, Train scatter: [0.8912 0.1206 0.539  0.799 ]
L1 regularization loss: 6.39E+00, L2 regularization loss: 3.90E+00
Test scatter: [0.8766 0.1194 0.5307 0.7935], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.1559 0.0441 0.25   0.4176], Epochs since improvement 4
 43%|████▎     | 217/500 [4:04:24<5:04:46, 64.62s/it] 44%|████▎     | 218/500 [4:05:44<5:25:02, 69.16s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -1.17E+05, Train scatter: [0.7291 0.1157 0.4936 0.7362]
L1 regularization loss: 6.56E+00, L2 regularization loss: 4.34E+00
Test scatter: [0.7175 0.1143 0.4886 0.7281], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.7175 0.1143 0.4886 0.7281], Epochs since improvement 6
 44%|████▍     | 219/500 [4:06:37<5:01:10, 64.31s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -1.49E+05, Train scatter: [0.5383 0.105  0.4755 0.6736]
L1 regularization loss: 6.56E+00, L2 regularization loss: 4.33E+00
Test scatter: [0.5251 0.1037 0.4707 0.6671], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.7175 0.1143 0.4886 0.7281], Epochs since improvement 8
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 44%|████▍     | 220/500 [4:08:06<5:35:06, 71.81s/it] 44%|████▍     | 221/500 [4:08:59<5:07:41, 66.17s/it] 44%|████▍     | 222/500 [4:10:19<5:25:47, 70.32s/it]Epoch: 222 done with learning rate 7.33E-03, Train loss: -1.77E+05, Train scatter: [0.4751 0.0951 0.4439 0.6226]
L1 regularization loss: 6.56E+00, L2 regularization loss: 4.35E+00
Test scatter: [0.4538 0.0937 0.4412 0.6143], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.7175 0.1143 0.4886 0.7281], Epochs since improvement 10
 45%|████▍     | 223/500 [4:11:12<5:00:27, 65.08s/it] 45%|████▍     | 224/500 [4:12:32<5:20:38, 69.71s/it]Epoch: 224 done with learning rate 7.26E-03, Train loss: -1.95E+05, Train scatter: [0.4563 0.0878 0.497  0.5835]
L1 regularization loss: 6.64E+00, L2 regularization loss: 4.41E+00
Test scatter: [0.4464 0.0869 0.4896 0.5766], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.5251 0.1037 0.4886 0.6671], Epochs since improvement 12
 45%|████▌     | 225/500 [4:13:25<4:56:30, 64.69s/it] 45%|████▌     | 226/500 [4:14:46<5:16:47, 69.37s/it]Epoch: 226 done with learning rate 7.20E-03, Train loss: -2.06E+05, Train scatter: [0.4914 0.0846 0.3997 0.5655]
L1 regularization loss: 6.62E+00, L2 regularization loss: 4.43E+00
Test scatter: [0.4776 0.0838 0.3985 0.5592], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.4776 0.0937 0.4707 0.6143], Epochs since improvement 14
 45%|████▌     | 227/500 [4:15:39<4:53:16, 64.46s/it] 46%|████▌     | 228/500 [4:16:59<5:13:56, 69.25s/it]Epoch: 228 done with learning rate 7.13E-03, Train loss: -2.30E+05, Train scatter: [0.3543 0.0775 0.3757 0.5401]
L1 regularization loss: 6.61E+00, L2 regularization loss: 4.47E+00
Test scatter: [0.3485 0.0763 0.3739 0.5319], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.4538 0.0869 0.4412 0.5766], Epochs since improvement 16
 46%|████▌     | 229/500 [4:17:52<4:50:46, 64.38s/it]Epoch: 230 done with learning rate 7.06E-03, Train loss: -2.41E+05, Train scatter: [0.3886 0.0738 0.3562 0.5251]
L1 regularization loss: 6.63E+00, L2 regularization loss: 4.51E+00
Test scatter: [0.3783 0.0728 0.3554 0.5171], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.4464 0.0838 0.3985 0.5592], Epochs since improvement 18
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 46%|████▌     | 230/500 [4:19:19<5:20:24, 71.20s/it] 46%|████▌     | 231/500 [4:20:12<4:54:57, 65.79s/it] 46%|████▋     | 232/500 [4:21:33<5:13:37, 70.21s/it]Epoch: 232 done with learning rate 6.99E-03, Train loss: -2.46E+05, Train scatter: [0.4582 0.0836 0.382  0.5592]
L1 regularization loss: 6.66E+00, L2 regularization loss: 4.56E+00
Test scatter: [0.4436 0.0819 0.3797 0.549 ], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.4436 0.0819 0.3797 0.549 ], Epochs since improvement 20
 47%|████▋     | 233/500 [4:22:26<4:49:31, 65.06s/it] 47%|████▋     | 233/500 [4:23:47<5:02:17, 67.93s/it]
Epoch: 234 done with learning rate 6.93E-03, Train loss: -2.45E+05, Train scatter: [0.4135 0.0714 0.3486 0.5167]
L1 regularization loss: 6.70E+00, L2 regularization loss: 4.62E+00
Test scatter: [0.4032 0.0701 0.3477 0.5093], Lowest was [0.1276 0.0411 0.2175 0.3807]
Median for last 10 epochs: [0.4032 0.0763 0.3739 0.5319], Epochs since improvement 22
Exited after 234 epochs due to early stopping
15827.60 seconds spent training, 31.655 seconds per epoch. Processed 2200 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.40319923 0.07012059 0.3477137  0.50930816]
{'epoch_exit': 233, 'scatter_m_star': 0.40319923, 'lowest_m_star': 0.12759876, 'last20_m_star': 0.45009613, 'last10_m_star': 0.40321067, 'scatter_v_disk': 0.07012059, 'lowest_v_disk': 0.041100528, 'last20_v_disk': 0.085351355, 'last10_v_disk': 0.07630299, 'scatter_m_cold': 0.3477137, 'lowest_m_cold': 0.2175012, 'last20_m_cold': 0.4198411, 'last10_m_cold': 0.37392575, 'scatter_sfr_100': 0.50930816, 'lowest_sfr_100': 0.38069874, 'last20_sfr_100': 0.5679076, 'last10_sfr_100': 0.53192073}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
