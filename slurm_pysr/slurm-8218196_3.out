Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_tifrct
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:30<4:16:13, 30.81s/it]  0%|          | 2/500 [01:17<5:34:28, 40.30s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.21E+07, Train scatter: [0.9353 0.1747 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1818 0.5356 0.9851], Lowest was [0.9198 0.1818 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1818 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:48<4:56:29, 35.79s/it]  1%|          | 4/500 [02:35<5:32:32, 40.23s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 7.46E+06, Train scatter: [0.9352 0.1758 0.544  0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1877 0.5354 0.985 ], Lowest was [0.9197 0.1818 0.5354 0.985 ]
Median for last 10 epochs: [0.9197 0.1847 0.5354 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:05<5:03:00, 36.73s/it]  1%|          | 6/500 [03:53<5:32:21, 40.37s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.65E+06, Train scatter: [0.9347 0.1421 0.5428 0.7271]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9191 0.1451 0.5343 0.7226], Lowest was [0.9191 0.1451 0.5343 0.7226]
Median for last 10 epochs: [0.9191 0.1451 0.5343 0.7226], Epochs since improvement 0
  1%|▏         | 7/500 [04:23<5:05:25, 37.17s/it]  2%|▏         | 8/500 [05:11<5:31:23, 40.41s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.83E+06, Train scatter: [0.9244 0.1256 0.5367 0.6745]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9092 0.1268 0.5284 0.6714], Lowest was [0.9092 0.1268 0.5284 0.6714]
Median for last 10 epochs: [0.9142 0.136  0.5313 0.697 ], Epochs since improvement 0
  2%|▏         | 9/500 [05:41<5:05:33, 37.34s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.19E+06, Train scatter: [0.7974 0.1116 0.5223 0.6249]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.782  0.1129 0.5144 0.6222], Lowest was [0.782  0.1129 0.5144 0.6222]
Median for last 10 epochs: [0.9092 0.1268 0.5284 0.6714], Epochs since improvement 0
  2%|▏         | 10/500 [06:34<5:42:53, 41.99s/it]  2%|▏         | 11/500 [07:04<5:13:37, 38.48s/it]  2%|▏         | 12/500 [07:51<5:34:57, 41.18s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.60E+06, Train scatter: [0.6263 0.1087 0.4454 0.6661]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6328 0.1118 0.4407 0.6574], Lowest was [0.6328 0.1118 0.4407 0.6222]
Median for last 10 epochs: [0.9092 0.1268 0.5284 0.6714], Epochs since improvement 0
  3%|▎         | 13/500 [08:22<5:08:25, 38.00s/it]  3%|▎         | 14/500 [09:09<5:30:34, 40.81s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.69E+06, Train scatter: [0.554  0.1035 0.3765 0.6074]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5596 0.1083 0.3771 0.62  ], Lowest was [0.5596 0.1083 0.3771 0.62  ]
Median for last 10 epochs: [0.782  0.1129 0.5144 0.6574], Epochs since improvement 0
  3%|▎         | 15/500 [09:40<5:05:14, 37.76s/it]  3%|▎         | 16/500 [10:28<5:28:10, 40.68s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.32E+06, Train scatter: [0.5438 0.0993 0.3579 0.5973]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5398 0.1037 0.3574 0.5972], Lowest was [0.5398 0.1037 0.3574 0.5972]
Median for last 10 epochs: [0.6328 0.1118 0.4407 0.6222], Epochs since improvement 0
  3%|▎         | 17/500 [10:58<5:03:17, 37.68s/it]  4%|▎         | 18/500 [11:46<5:26:17, 40.62s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.07E+06, Train scatter: [0.5627 0.0969 0.355  0.6122]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5557 0.0999 0.356  0.6088], Lowest was [0.5398 0.0999 0.356  0.5972]
Median for last 10 epochs: [0.5596 0.1083 0.3771 0.62  ], Epochs since improvement 0
  4%|▍         | 19/500 [12:16<5:01:39, 37.63s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 9.13E+05, Train scatter: [0.5258 0.0936 0.3452 0.5948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5173 0.0966 0.3445 0.5923], Lowest was [0.5173 0.0966 0.3445 0.5923]
Median for last 10 epochs: [0.5557 0.1037 0.3574 0.6088], Epochs since improvement 0
  4%|▍         | 20/500 [13:08<5:35:33, 41.94s/it]  4%|▍         | 21/500 [13:39<5:07:39, 38.54s/it]  4%|▍         | 22/500 [14:27<5:28:34, 41.24s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 8.15E+05, Train scatter: [0.5395 0.0893 0.3541 0.5732]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5312 0.0932 0.355  0.5753], Lowest was [0.5173 0.0932 0.3445 0.5753]
Median for last 10 epochs: [0.5398 0.0999 0.356  0.5972], Epochs since improvement 0
  5%|▍         | 23/500 [14:57<5:02:28, 38.05s/it]  5%|▍         | 24/500 [15:44<5:23:22, 40.76s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.36E+05, Train scatter: [0.4763 0.0854 0.3155 0.5495]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4707 0.0876 0.3213 0.5478], Lowest was [0.4707 0.0876 0.3213 0.5478]
Median for last 10 epochs: [0.5312 0.0966 0.355  0.5923], Epochs since improvement 0
  5%|▌         | 25/500 [16:15<4:58:39, 37.72s/it]  5%|▌         | 26/500 [17:02<5:20:15, 40.54s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 6.25E+05, Train scatter: [0.4988 0.0854 0.3218 0.5419]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4868 0.0872 0.326  0.5394], Lowest was [0.4707 0.0872 0.3213 0.5394]
Median for last 10 epochs: [0.5173 0.0932 0.3445 0.5753], Epochs since improvement 0
  5%|▌         | 27/500 [17:33<4:56:02, 37.55s/it]  6%|▌         | 28/500 [18:20<5:18:51, 40.53s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 5.85E+05, Train scatter: [0.457  0.0812 0.2971 0.5295]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4594 0.0817 0.301  0.5265], Lowest was [0.4594 0.0817 0.301  0.5265]
Median for last 10 epochs: [0.4868 0.0876 0.326  0.5478], Epochs since improvement 0
  6%|▌         | 29/500 [18:51<4:54:47, 37.55s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 6.00E+05, Train scatter: [0.4754 0.0813 0.3047 0.5394]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.469  0.0823 0.3086 0.5369], Lowest was [0.4594 0.0817 0.301  0.5265]
Median for last 10 epochs: [0.4707 0.0872 0.3213 0.5394], Epochs since improvement 2
  6%|▌         | 30/500 [19:43<5:29:05, 42.01s/it]  6%|▌         | 31/500 [20:14<5:01:37, 38.59s/it]  6%|▋         | 32/500 [21:01<5:21:43, 41.25s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.26E+05, Train scatter: [0.4745 0.0798 0.2913 0.5222]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4608 0.0811 0.2971 0.5198], Lowest was [0.4594 0.0811 0.2971 0.5198]
Median for last 10 epochs: [0.469  0.0823 0.3086 0.5369], Epochs since improvement 0
  7%|▋         | 33/500 [21:32<4:56:10, 38.05s/it]  7%|▋         | 34/500 [22:19<5:17:10, 40.84s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 4.73E+05, Train scatter: [0.4254 0.0778 0.2972 0.5411]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4209 0.0784 0.3025 0.5338], Lowest was [0.4209 0.0784 0.2971 0.5198]
Median for last 10 epochs: [0.4608 0.0817 0.3025 0.5338], Epochs since improvement 0
  7%|▋         | 35/500 [22:50<4:52:37, 37.76s/it]  7%|▋         | 36/500 [23:37<5:14:49, 40.71s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.80E+05, Train scatter: [0.4976 0.075  0.2857 0.5104]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5021 0.0759 0.2914 0.5084], Lowest was [0.4209 0.0759 0.2914 0.5084]
Median for last 10 epochs: [0.4608 0.0811 0.301  0.5265], Epochs since improvement 0
  7%|▋         | 37/500 [24:08<4:50:35, 37.66s/it]  8%|▊         | 38/500 [24:55<5:12:37, 40.60s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.69E+05, Train scatter: [0.4259 0.0754 0.3011 0.5443]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4268 0.0773 0.3069 0.5439], Lowest was [0.4209 0.0759 0.2914 0.5084]
Median for last 10 epochs: [0.4608 0.0784 0.3025 0.5338], Epochs since improvement 2
  8%|▊         | 39/500 [25:26<4:48:55, 37.61s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.29E+04, Train scatter: [0.4156 0.0703 0.2746 0.4887]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4019 0.071  0.2829 0.4874], Lowest was [0.4019 0.071  0.2829 0.4874]
Median for last 10 epochs: [0.4268 0.0773 0.2971 0.5198], Epochs since improvement 0
  8%|▊         | 40/500 [26:19<5:23:37, 42.21s/it]  8%|▊         | 41/500 [26:49<4:56:17, 38.73s/it]  8%|▊         | 42/500 [27:37<5:14:57, 41.26s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.57E+05, Train scatter: [0.4168 0.0673 0.2722 0.4844]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4179 0.0679 0.2787 0.4835], Lowest was [0.4019 0.0679 0.2787 0.4835]
Median for last 10 epochs: [0.4209 0.0759 0.2914 0.5084], Epochs since improvement 0
  9%|▊         | 43/500 [28:07<4:49:46, 38.05s/it]  9%|▉         | 44/500 [28:55<5:10:31, 40.86s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.71E+05, Train scatter: [0.4148 0.0652 0.2731 0.4812]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4212 0.0668 0.2804 0.4826], Lowest was [0.4019 0.0668 0.2787 0.4826]
Median for last 10 epochs: [0.4212 0.071  0.2829 0.4874], Epochs since improvement 0
  9%|▉         | 45/500 [29:25<4:46:31, 37.78s/it]  9%|▉         | 46/500 [30:12<5:07:24, 40.63s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: -2.70E+05, Train scatter: [0.3918 0.0653 0.2776 0.5021]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4048 0.0666 0.2851 0.4911], Lowest was [0.4019 0.0666 0.2787 0.4826]
Median for last 10 epochs: [0.4179 0.0679 0.2829 0.4874], Epochs since improvement 0
  9%|▉         | 47/500 [30:43<4:43:51, 37.60s/it] 10%|▉         | 48/500 [31:31<5:05:45, 40.59s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: -2.79E+05, Train scatter: [0.2985 0.0643 0.2791 0.4768]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3225 0.0658 0.2842 0.4778], Lowest was [0.3225 0.0658 0.2787 0.4778]
Median for last 10 epochs: [0.4048 0.0668 0.2829 0.4835], Epochs since improvement 0
 10%|▉         | 49/500 [32:01<4:42:24, 37.57s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: -2.74E+05, Train scatter: [0.2496 0.0671 0.2936 0.4885]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2615 0.0701 0.3056 0.493 ], Lowest was [0.2615 0.0658 0.2787 0.4778]
Median for last 10 epochs: [0.4048 0.0668 0.2842 0.4835], Epochs since improvement 0
 10%|█         | 50/500 [32:53<5:14:42, 41.96s/it] 10%|█         | 51/500 [33:24<4:48:29, 38.55s/it] 10%|█         | 52/500 [34:11<5:07:46, 41.22s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: -2.87E+05, Train scatter: [0.309  0.0627 0.2872 0.4797]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3188 0.0642 0.2946 0.479 ], Lowest was [0.2615 0.0642 0.2787 0.4778]
Median for last 10 epochs: [0.3225 0.0666 0.2851 0.4826], Epochs since improvement 0
 11%|█         | 53/500 [34:42<4:43:17, 38.02s/it] 11%|█         | 54/500 [35:29<5:03:28, 40.83s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: -2.76E+05, Train scatter: [0.2444 0.0644 0.2903 0.4813]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2477 0.0653 0.2945 0.4787], Lowest was [0.2477 0.0642 0.2787 0.4778]
Median for last 10 epochs: [0.3188 0.0658 0.2945 0.479 ], Epochs since improvement 0
 11%|█         | 55/500 [36:00<4:40:02, 37.76s/it] 11%|█         | 56/500 [36:48<5:01:31, 40.75s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: -2.88E+05, Train scatter: [0.2128 0.0607 0.2769 0.4761]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2282 0.0618 0.2832 0.4777], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.2615 0.0653 0.2945 0.4787], Epochs since improvement 0
 11%|█▏        | 57/500 [37:18<4:38:29, 37.72s/it] 12%|█▏        | 58/500 [38:05<4:58:52, 40.57s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.03E+08, Train scatter: [0.9538 0.1769 0.5442 0.991 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9384 0.173  0.5356 0.9806], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.2615 0.0653 0.2946 0.479 ], Epochs since improvement 2
 12%|█▏        | 59/500 [38:36<4:36:20, 37.60s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.25E+06, Train scatter: [0.7084 0.1411 0.5417 1.0492]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6933 0.1376 0.5332 1.0389], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.3188 0.0653 0.2946 0.479 ], Epochs since improvement 4
 12%|█▏        | 60/500 [39:28<5:08:05, 42.01s/it] 12%|█▏        | 61/500 [39:59<4:42:12, 38.57s/it] 12%|█▏        | 62/500 [40:47<5:02:13, 41.40s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.13E+06, Train scatter: [0.5403 0.1112 0.5286 1.0019]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5321 0.1086 0.5203 0.9914], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.5321 0.1086 0.5203 0.9806], Epochs since improvement 6
 13%|█▎        | 63/500 [41:18<4:37:48, 38.14s/it] 13%|█▎        | 64/500 [42:05<4:58:25, 41.07s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 8.78E+05, Train scatter: [0.5175 0.1106 0.5091 0.936 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5099 0.108  0.5004 0.9259], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.5321 0.1086 0.5203 0.9806], Epochs since improvement 8
 13%|█▎        | 65/500 [42:36<4:34:52, 37.91s/it] 13%|█▎        | 66/500 [43:24<4:55:53, 40.91s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 7.27E+05, Train scatter: [0.545  0.1106 0.5074 0.8334]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5373 0.108  0.4994 0.8238], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.5373 0.1086 0.5203 0.9806], Epochs since improvement 10
 13%|█▎        | 67/500 [43:54<4:32:58, 37.83s/it] 14%|█▎        | 68/500 [44:42<4:53:45, 40.80s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 5.21E+05, Train scatter: [0.5188 0.1066 0.5081 0.6722]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.512  0.1044 0.502  0.6641], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.5321 0.108  0.502  0.9259], Epochs since improvement 12
 14%|█▍        | 69/500 [45:13<4:31:45, 37.83s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.49E+05, Train scatter: [0.4412 0.0998 0.4916 0.6556]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4254 0.0972 0.4854 0.6428], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.512  0.108  0.5004 0.8238], Epochs since improvement 14
 14%|█▍        | 70/500 [46:07<5:05:51, 42.68s/it] 14%|█▍        | 71/500 [46:38<4:39:23, 39.08s/it] 14%|█▍        | 72/500 [47:25<4:56:01, 41.50s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.44E+05, Train scatter: [0.3433 0.096  0.4923 0.6168]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3392 0.0946 0.4865 0.6115], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.5099 0.1044 0.4994 0.6641], Epochs since improvement 16
 15%|█▍        | 73/500 [47:56<4:32:22, 38.27s/it] 15%|█▍        | 74/500 [48:44<4:52:49, 41.24s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 8.01E+04, Train scatter: [0.3657 0.0922 0.4899 0.5988]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3563 0.0906 0.4844 0.5928], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.4254 0.0972 0.4865 0.6428], Epochs since improvement 18
 15%|█▌        | 75/500 [49:15<4:29:46, 38.09s/it] 15%|█▌        | 76/500 [50:03<4:50:09, 41.06s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 8.71E+03, Train scatter: [0.3231 0.0879 0.4744 0.5868]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3123 0.0857 0.4689 0.5743], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.3563 0.0946 0.4854 0.6115], Epochs since improvement 20
 15%|█▌        | 77/500 [50:33<4:27:23, 37.93s/it] 15%|█▌        | 77/500 [51:21<4:42:08, 40.02s/it]
Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.94E+04, Train scatter: [0.4437 0.0883 0.4486 0.5827]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.443  0.0876 0.4424 0.5806], Lowest was [0.2282 0.0618 0.2787 0.4777]
Median for last 10 epochs: [0.3563 0.0906 0.4844 0.5928], Epochs since improvement 22
Exited after 78 epochs due to early stopping
3081.56 seconds spent training, 6.163 seconds per epoch. Processed 11299 trees per second
[0.44295406 0.08756565 0.44241777 0.5805403 ]
{'epoch_exit': 77, 'scatter_m_star': 0.44295406, 'lowest_m_star': 0.22815494, 'last20_m_star': 0.47641078, 'last10_m_star': 0.3563399, 'scatter_v_disk': 0.08756565, 'lowest_v_disk': 0.061779507, 'last20_v_disk': 0.10084152, 'last10_v_disk': 0.09061115, 'scatter_m_cold': 0.44241777, 'lowest_m_cold': 0.27872208, 'last20_m_cold': 0.49295, 'last10_m_cold': 0.48437864, 'scatter_sfr_100': 0.5805403, 'lowest_sfr_100': 0.47765887, 'last20_sfr_100': 0.6534506, 'last10_sfr_100': 0.59279066}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_ejbyua
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:27<3:49:10, 27.56s/it]  0%|          | 2/500 [01:10<5:02:35, 36.46s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.45E+07, Train scatter: [0.9354 0.179  0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1876 0.5357 0.9851], Lowest was [0.9198 0.1876 0.5357 0.9851]
Median for last 10 epochs: [0.9198 0.1876 0.5357 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:36<4:25:04, 32.00s/it]  1%|          | 4/500 [02:21<5:06:42, 37.10s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.47E+07, Train scatter: [0.9354 0.1744 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.177  0.5356 0.9851], Lowest was [0.9198 0.177  0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.177  0.5356 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:48<4:35:15, 33.37s/it]  1%|          | 6/500 [03:32<5:04:23, 36.97s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.07E+07, Train scatter: [0.9354 0.1663 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.1682 0.5356 0.9851], Lowest was [0.9198 0.1682 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1682 0.5356 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [03:59<4:36:27, 33.65s/it]  2%|▏         | 8/500 [04:43<5:02:47, 36.93s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 9.80E+06, Train scatter: [0.9353 0.1589 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1596 0.5356 0.9848], Lowest was [0.9197 0.1596 0.5356 0.9848]
Median for last 10 epochs: [0.9198 0.1639 0.5356 0.9849], Epochs since improvement 0
  2%|▏         | 9/500 [05:10<4:36:00, 33.73s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.22E+06, Train scatter: [0.9352 0.1404 0.544  0.756 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1386 0.5355 0.75  ], Lowest was [0.9196 0.1386 0.5355 0.75  ]
Median for last 10 epochs: [0.9197 0.1596 0.5356 0.9848], Epochs since improvement 0
  2%|▏         | 10/500 [05:59<5:14:27, 38.51s/it]  2%|▏         | 11/500 [06:26<4:44:39, 34.93s/it]  2%|▏         | 12/500 [07:10<5:06:36, 37.70s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.15E+06, Train scatter: [0.9344 0.1272 0.544  0.6649]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9189 0.1246 0.5354 0.6579], Lowest was [0.9189 0.1246 0.5354 0.6579]
Median for last 10 epochs: [0.9197 0.1596 0.5356 0.9848], Epochs since improvement 0
  3%|▎         | 13/500 [07:36<4:39:27, 34.43s/it]  3%|▎         | 14/500 [08:21<5:02:43, 37.37s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.72E+06, Train scatter: [0.9163 0.1174 0.5438 0.6248]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9028 0.1165 0.5353 0.6189], Lowest was [0.9028 0.1165 0.5353 0.6189]
Median for last 10 epochs: [0.9196 0.1386 0.5355 0.75  ], Epochs since improvement 0
  3%|▎         | 15/500 [08:47<4:36:15, 34.18s/it]  3%|▎         | 16/500 [09:32<5:00:20, 37.23s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.54E+06, Train scatter: [0.7862 0.1105 0.5416 0.6002]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7824 0.1102 0.5334 0.593 ], Lowest was [0.7824 0.1102 0.5334 0.593 ]
Median for last 10 epochs: [0.9189 0.1246 0.5354 0.6579], Epochs since improvement 0
  3%|▎         | 17/500 [09:59<4:34:27, 34.09s/it]  4%|▎         | 18/500 [10:42<4:56:33, 36.92s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 6.31E+06, Train scatter: [0.5679 0.1049 0.5388 0.586 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5663 0.105  0.5307 0.5827], Lowest was [0.5663 0.105  0.5307 0.5827]
Median for last 10 epochs: [0.9028 0.1165 0.5353 0.6189], Epochs since improvement 0
  4%|▍         | 19/500 [11:09<4:31:38, 33.89s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 6.08E+06, Train scatter: [0.4889 0.1005 0.5358 0.5801]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4937 0.0997 0.5279 0.5822], Lowest was [0.4937 0.0997 0.5279 0.5822]
Median for last 10 epochs: [0.7824 0.1102 0.5334 0.593 ], Epochs since improvement 0
  4%|▍         | 20/500 [11:58<5:07:19, 38.41s/it]  4%|▍         | 21/500 [12:25<4:39:06, 34.96s/it]  4%|▍         | 22/500 [13:09<5:00:17, 37.69s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.78E+06, Train scatter: [0.466  0.0965 0.5306 0.5656]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4726 0.0956 0.5228 0.5679], Lowest was [0.4726 0.0956 0.5228 0.5679]
Median for last 10 epochs: [0.5663 0.105  0.5307 0.5827], Epochs since improvement 0
  5%|▍         | 23/500 [13:36<4:33:40, 34.42s/it]  5%|▍         | 24/500 [14:20<4:57:35, 37.51s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 5.42E+06, Train scatter: [0.4818 0.0977 0.5179 0.5738]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.477  0.0976 0.51   0.5771], Lowest was [0.4726 0.0956 0.51   0.5679]
Median for last 10 epochs: [0.4937 0.0997 0.5279 0.5822], Epochs since improvement 0
  5%|▌         | 25/500 [14:47<4:31:45, 34.33s/it]  5%|▌         | 26/500 [15:31<4:53:19, 37.13s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.97E+06, Train scatter: [0.4888 0.1032 0.5036 0.6051]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.501  0.1021 0.4969 0.5997], Lowest was [0.4726 0.0956 0.4969 0.5679]
Median for last 10 epochs: [0.4937 0.0997 0.5228 0.5822], Epochs since improvement 0
  5%|▌         | 27/500 [15:58<4:28:20, 34.04s/it]  6%|▌         | 28/500 [16:43<4:53:24, 37.30s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.20E+06, Train scatter: [0.5    0.1008 0.3902 0.6099]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5119 0.1026 0.403  0.6202], Lowest was [0.4726 0.0956 0.403  0.5679]
Median for last 10 epochs: [0.4937 0.0997 0.51   0.5822], Epochs since improvement 0
  6%|▌         | 29/500 [17:09<4:28:06, 34.15s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.48E+06, Train scatter: [0.5053 0.0958 0.3538 0.5772]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.515  0.0949 0.3634 0.5754], Lowest was [0.4726 0.0949 0.3634 0.5679]
Median for last 10 epochs: [0.501  0.0976 0.4969 0.5771], Epochs since improvement 0
  6%|▌         | 30/500 [17:59<5:03:04, 38.69s/it]  6%|▌         | 31/500 [18:26<4:34:39, 35.14s/it]  6%|▋         | 32/500 [19:10<4:55:05, 37.83s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.19E+06, Train scatter: [0.5315 0.0947 0.3401 0.5695]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4927 0.0936 0.3508 0.5681], Lowest was [0.4726 0.0936 0.3508 0.5679]
Median for last 10 epochs: [0.501  0.0976 0.403  0.5771], Epochs since improvement 0
  7%|▋         | 33/500 [19:37<4:28:46, 34.53s/it]  7%|▋         | 34/500 [20:21<4:51:27, 37.53s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 1.90E+06, Train scatter: [0.5135 0.091  0.3261 0.5544]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4854 0.0902 0.3324 0.5493], Lowest was [0.4726 0.0902 0.3324 0.5493]
Median for last 10 epochs: [0.501  0.0949 0.3634 0.5754], Epochs since improvement 0
  7%|▋         | 35/500 [20:48<4:25:51, 34.30s/it]  7%|▋         | 36/500 [21:32<4:49:14, 37.40s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.00E+06, Train scatter: [0.3999 0.0904 0.3256 0.5722]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4021 0.0899 0.3307 0.5673], Lowest was [0.4021 0.0899 0.3307 0.5493]
Median for last 10 epochs: [0.4927 0.0936 0.3508 0.5681], Epochs since improvement 0
  7%|▋         | 37/500 [21:59<4:24:24, 34.26s/it]  8%|▊         | 38/500 [22:44<4:47:23, 37.32s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.75E+06, Train scatter: [0.303  0.087  0.3084 0.5293]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3135 0.0871 0.3176 0.5259], Lowest was [0.3135 0.0871 0.3176 0.5259]
Median for last 10 epochs: [0.4854 0.0902 0.3324 0.5673], Epochs since improvement 0
  8%|▊         | 39/500 [23:11<4:23:01, 34.23s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.58E+06, Train scatter: [0.3069 0.0886 0.3348 0.5438]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3104 0.0893 0.3302 0.5349], Lowest was [0.3104 0.0871 0.3176 0.5259]
Median for last 10 epochs: [0.4021 0.0899 0.3307 0.5493], Epochs since improvement 0
  8%|▊         | 40/500 [24:02<5:00:36, 39.21s/it]  8%|▊         | 41/500 [24:29<4:31:48, 35.53s/it]  8%|▊         | 42/500 [25:13<4:51:30, 38.19s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.57E+06, Train scatter: [0.3497 0.0874 0.3043 0.5284]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3422 0.0886 0.3126 0.5249], Lowest was [0.3104 0.0871 0.3126 0.5249]
Median for last 10 epochs: [0.3422 0.0893 0.3302 0.5349], Epochs since improvement 0
  9%|▊         | 43/500 [25:40<4:25:11, 34.82s/it]  9%|▉         | 44/500 [26:24<4:46:30, 37.70s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.39E+06, Train scatter: [0.2807 0.0845 0.299  0.5161]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2848 0.0856 0.3054 0.5107], Lowest was [0.2848 0.0856 0.3054 0.5107]
Median for last 10 epochs: [0.3135 0.0886 0.3176 0.5259], Epochs since improvement 0
  9%|▉         | 45/500 [26:51<4:21:29, 34.48s/it]  9%|▉         | 46/500 [27:36<4:43:44, 37.50s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.35E+06, Train scatter: [0.3251 0.0828 0.3131 0.5416]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3314 0.0827 0.326  0.5398], Lowest was [0.2848 0.0827 0.3054 0.5107]
Median for last 10 epochs: [0.3135 0.0871 0.3176 0.5259], Epochs since improvement 0
  9%|▉         | 47/500 [28:03<4:19:13, 34.33s/it] 10%|▉         | 48/500 [28:47<4:41:29, 37.37s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.22E+06, Train scatter: [0.2901 0.0836 0.3126 0.5383]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2914 0.0842 0.314  0.5393], Lowest was [0.2848 0.0827 0.3054 0.5107]
Median for last 10 epochs: [0.3104 0.0856 0.314  0.5349], Epochs since improvement 2
 10%|▉         | 49/500 [29:14<4:17:05, 34.20s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.38E+06, Train scatter: [0.3662 0.0873 0.3143 0.5661]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3671 0.0877 0.3212 0.5701], Lowest was [0.2848 0.0827 0.3054 0.5107]
Median for last 10 epochs: [0.3314 0.0856 0.314  0.5393], Epochs since improvement 4
 10%|█         | 50/500 [30:04<4:51:38, 38.89s/it] 10%|█         | 51/500 [30:31<4:24:48, 35.39s/it] 10%|█         | 52/500 [31:16<4:46:20, 38.35s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.32E+06, Train scatter: [0.3293 0.0977 0.3288 0.5597]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3367 0.0967 0.3316 0.5671], Lowest was [0.2848 0.0827 0.3054 0.5107]
Median for last 10 epochs: [0.3314 0.0856 0.3212 0.5398], Epochs since improvement 6
 11%|█         | 53/500 [31:43<4:20:08, 34.92s/it] 11%|█         | 54/500 [32:28<4:41:21, 37.85s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.36E+06, Train scatter: [0.2964 0.0835 0.3053 0.5543]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3012 0.084  0.3111 0.5467], Lowest was [0.2848 0.0827 0.3054 0.5107]
Median for last 10 epochs: [0.3314 0.0842 0.3212 0.5467], Epochs since improvement 8
 11%|█         | 55/500 [32:55<4:16:25, 34.57s/it] 11%|█         | 56/500 [33:40<4:39:09, 37.72s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.15E+06, Train scatter: [0.3002 0.0821 0.3119 0.5266]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2949 0.0835 0.3149 0.5215], Lowest was [0.2848 0.0827 0.3054 0.5107]
Median for last 10 epochs: [0.3012 0.0842 0.3149 0.5467], Epochs since improvement 10
 11%|█▏        | 57/500 [34:07<4:14:27, 34.46s/it] 12%|█▏        | 58/500 [34:53<4:39:59, 38.01s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.05E+06, Train scatter: [0.3288 0.0884 0.2988 0.532 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3387 0.0889 0.3061 0.5354], Lowest was [0.2848 0.0827 0.3054 0.5107]
Median for last 10 epochs: [0.3367 0.0877 0.3149 0.5467], Epochs since improvement 12
 12%|█▏        | 59/500 [35:20<4:15:20, 34.74s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 9.95E+05, Train scatter: [0.2592 0.0803 0.3385 0.5031]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2675 0.0809 0.3541 0.5057], Lowest was [0.2675 0.0809 0.3054 0.5057]
Median for last 10 epochs: [0.3012 0.084  0.3149 0.5354], Epochs since improvement 0
 12%|█▏        | 60/500 [36:10<4:47:05, 39.15s/it] 12%|█▏        | 61/500 [36:37<4:19:36, 35.48s/it] 12%|█▏        | 62/500 [37:22<4:39:49, 38.33s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 9.99E+05, Train scatter: [0.2909 0.0769 0.3114 0.543 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2993 0.0786 0.3263 0.5497], Lowest was [0.2675 0.0786 0.3054 0.5057]
Median for last 10 epochs: [0.2993 0.0835 0.3149 0.5354], Epochs since improvement 0
 13%|█▎        | 63/500 [37:49<4:14:10, 34.90s/it] 13%|█▎        | 64/500 [38:33<4:34:55, 37.83s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 9.06E+05, Train scatter: [0.2606 0.0782 0.2789 0.5015]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2683 0.0806 0.2853 0.5014], Lowest was [0.2675 0.0786 0.2853 0.5014]
Median for last 10 epochs: [0.2949 0.0809 0.3149 0.5215], Epochs since improvement 0
 13%|█▎        | 65/500 [39:00<4:10:25, 34.54s/it] 13%|█▎        | 66/500 [39:45<4:31:39, 37.56s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 8.33E+05, Train scatter: [0.2754 0.077  0.2979 0.5012]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2798 0.0784 0.3098 0.5025], Lowest was [0.2675 0.0784 0.2853 0.5014]
Median for last 10 epochs: [0.2798 0.0806 0.3098 0.5057], Epochs since improvement 0
 13%|█▎        | 67/500 [40:12<4:08:14, 34.40s/it] 14%|█▎        | 68/500 [40:57<4:31:03, 37.65s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 7.70E+05, Train scatter: [0.2445 0.0742 0.2779 0.5064]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2504 0.0753 0.2858 0.5033], Lowest was [0.2504 0.0753 0.2853 0.5014]
Median for last 10 epochs: [0.2683 0.0786 0.3098 0.5033], Epochs since improvement 0
 14%|█▍        | 69/500 [41:24<4:07:33, 34.46s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 6.84E+05, Train scatter: [0.2713 0.0739 0.2848 0.4935]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2702 0.0747 0.2879 0.497 ], Lowest was [0.2504 0.0747 0.2853 0.497 ]
Median for last 10 epochs: [0.2702 0.0784 0.2879 0.5025], Epochs since improvement 0
 14%|█▍        | 70/500 [42:14<4:40:10, 39.09s/it] 14%|█▍        | 71/500 [42:41<4:13:39, 35.48s/it] 14%|█▍        | 72/500 [43:26<4:32:51, 38.25s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 6.69E+05, Train scatter: [0.2692 0.0728 0.3357 0.5042]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2762 0.0739 0.3402 0.5042], Lowest was [0.2504 0.0739 0.2853 0.497 ]
Median for last 10 epochs: [0.2702 0.0753 0.2879 0.5025], Epochs since improvement 0
 15%|█▍        | 73/500 [43:52<4:07:55, 34.84s/it] 15%|█▍        | 74/500 [44:37<4:27:32, 37.68s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 5.83E+05, Train scatter: [0.2462 0.072  0.2792 0.4899]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2516 0.0737 0.2887 0.4932], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.2702 0.0747 0.2887 0.5025], Epochs since improvement 0
 15%|█▌        | 75/500 [45:04<4:03:53, 34.43s/it] 15%|█▌        | 76/500 [45:48<4:25:22, 37.55s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 8.15E+06, Train scatter: [0.9366 0.1728 0.5433 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.921  0.1689 0.5348 0.9851], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.2702 0.0747 0.2887 0.5033], Epochs since improvement 2
 15%|█▌        | 77/500 [46:15<4:01:36, 34.27s/it] 16%|█▌        | 78/500 [47:00<4:23:49, 37.51s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 5.16E+06, Train scatter: [0.9377 0.1699 0.5465 0.9959]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9221 0.1662 0.5377 0.9855], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.2762 0.0747 0.3402 0.5042], Epochs since improvement 4
 16%|█▌        | 79/500 [47:27<4:00:15, 34.24s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 3.80E+06, Train scatter: [0.9368 0.1608 0.5211 0.9959]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9213 0.1578 0.5175 0.9855], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.921  0.1578 0.5175 0.9851], Epochs since improvement 6
 16%|█▌        | 80/500 [48:16<4:31:42, 38.82s/it] 16%|█▌        | 81/500 [48:43<4:05:36, 35.17s/it] 16%|█▋        | 82/500 [49:27<4:24:14, 37.93s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 3.88E+06, Train scatter: [0.9341 0.1513 0.528  0.996 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9186 0.1489 0.5199 0.9856], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.921  0.1578 0.5199 0.9855], Epochs since improvement 8
 17%|█▋        | 83/500 [49:54<4:00:00, 34.53s/it] 17%|█▋        | 84/500 [50:39<4:20:40, 37.60s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.51E+06, Train scatter: [0.9318 0.1364 0.5158 0.9941]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9164 0.1348 0.5086 0.9837], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.921  0.1578 0.5199 0.9855], Epochs since improvement 10
 17%|█▋        | 85/500 [51:05<3:57:15, 34.30s/it] 17%|█▋        | 86/500 [51:49<4:16:37, 37.19s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.04E+06, Train scatter: [0.9289 0.1307 0.5076 0.9936]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9137 0.1294 0.5016 0.9833], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.9186 0.1489 0.5175 0.9855], Epochs since improvement 12
 17%|█▋        | 87/500 [52:16<3:54:07, 34.01s/it] 18%|█▊        | 88/500 [53:00<4:15:34, 37.22s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 1.72E+06, Train scatter: [0.9262 0.1251 0.5018 0.9933]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9111 0.1243 0.4963 0.9829], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.9164 0.1348 0.5086 0.9837], Epochs since improvement 14
 18%|█▊        | 89/500 [53:27<3:53:11, 34.04s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 1.51E+06, Train scatter: [0.9231 0.1214 0.4881 0.9926]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.908  0.1208 0.4841 0.9823], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.9137 0.1294 0.5016 0.9833], Epochs since improvement 16
 18%|█▊        | 90/500 [54:17<4:24:34, 38.72s/it] 18%|█▊        | 91/500 [54:43<3:59:18, 35.11s/it] 18%|█▊        | 92/500 [55:27<4:16:57, 37.79s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 1.35E+06, Train scatter: [0.9197 0.1188 0.4788 0.9919]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9048 0.1184 0.4759 0.9816], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.9111 0.1243 0.4963 0.9829], Epochs since improvement 18
 19%|█▊        | 93/500 [55:54<3:53:43, 34.46s/it] 19%|█▉        | 94/500 [56:38<4:13:08, 37.41s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 1.23E+06, Train scatter: [0.9161 0.1166 0.4737 0.9911]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9013 0.1162 0.469  0.9808], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.908  0.1208 0.4841 0.9823], Epochs since improvement 20
 19%|█▉        | 95/500 [57:05<3:50:49, 34.20s/it] 19%|█▉        | 95/500 [57:50<4:06:34, 36.53s/it]
Epoch: 96 done with learning rate 9.94E-03, Train loss: 1.13E+06, Train scatter: [0.9119 0.1144 0.4636 0.9901]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8973 0.1139 0.4611 0.9798], Lowest was [0.2504 0.0737 0.2853 0.4932]
Median for last 10 epochs: [0.9048 0.1184 0.4759 0.9816], Epochs since improvement 22
Exited after 96 epochs due to early stopping
3470.33 seconds spent training, 6.941 seconds per epoch. Processed 10033 trees per second
[0.8972871  0.11390769 0.46105954 0.9797986 ]
{'epoch_exit': 95, 'scatter_m_star': 0.8972871, 'lowest_m_star': 0.25040326, 'last20_m_star': 0.9123752, 'last10_m_star': 0.90477556, 'scatter_v_disk': 0.11390769, 'lowest_v_disk': 0.07369459, 'last20_v_disk': 0.12685236, 'last10_v_disk': 0.118396, 'scatter_m_cold': 0.46105954, 'lowest_m_cold': 0.2853499, 'last20_m_cold': 0.49897066, 'last10_m_cold': 0.47591445, 'scatter_sfr_100': 0.9797986, 'lowest_sfr_100': 0.4931593, 'last20_sfr_100': 0.9830836, 'last10_sfr_100': 0.98161507}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_vvrqpf
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:46<6:24:40, 46.25s/it]  0%|          | 2/500 [01:54<8:11:35, 59.23s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.47E+07, Train scatter: [0.9352 0.1519 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1479 0.5356 0.9851], Lowest was [0.9196 0.1479 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1479 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:40<7:19:14, 53.03s/it]  1%|          | 4/500 [03:49<8:10:28, 59.33s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.65E+07, Train scatter: [0.9339 0.1012 0.5441 0.9947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9183 0.0992 0.5355 0.9844], Lowest was [0.9183 0.0992 0.5355 0.9844]
Median for last 10 epochs: [0.9183 0.0992 0.5355 0.9844], Epochs since improvement 0
  1%|          | 5/500 [04:34<7:28:30, 54.36s/it]  1%|          | 6/500 [05:43<8:08:27, 59.33s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.12E+07, Train scatter: [0.8105 0.107  0.544  0.6955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7989 0.106  0.5354 0.6858], Lowest was [0.7989 0.0992 0.5354 0.6858]
Median for last 10 epochs: [0.7989 0.0992 0.5354 0.6858], Epochs since improvement 0
  1%|▏         | 7/500 [06:29<7:30:39, 54.85s/it]  2%|▏         | 8/500 [07:38<8:06:30, 59.33s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.19E+06, Train scatter: [0.6527 0.0895 0.5439 0.5742]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6502 0.0894 0.5354 0.5701], Lowest was [0.6502 0.0894 0.5354 0.5701]
Median for last 10 epochs: [0.7246 0.0943 0.5354 0.628 ], Epochs since improvement 0
  2%|▏         | 9/500 [08:23<7:30:33, 55.06s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 5.46E+06, Train scatter: [0.5199 0.0839 0.5439 0.5434]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5186 0.0841 0.5354 0.5421], Lowest was [0.5186 0.0841 0.5354 0.5421]
Median for last 10 epochs: [0.6502 0.0894 0.5354 0.5701], Epochs since improvement 0
  2%|▏         | 10/500 [09:39<8:20:27, 61.28s/it]  2%|▏         | 11/500 [10:25<7:41:09, 56.58s/it]  2%|▏         | 12/500 [11:33<8:10:04, 60.26s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 4.76E+06, Train scatter: [0.3008 0.0793 0.5439 0.5776]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3072 0.0796 0.5354 0.572 ], Lowest was [0.3072 0.0796 0.5354 0.5421]
Median for last 10 epochs: [0.6502 0.0894 0.5354 0.572 ], Epochs since improvement 0
  3%|▎         | 13/500 [12:19<7:33:14, 55.84s/it]  3%|▎         | 14/500 [13:28<8:05:22, 59.92s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 4.33E+06, Train scatter: [0.3675 0.077  0.5439 0.544 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3726 0.0765 0.5353 0.5419], Lowest was [0.3072 0.0765 0.5353 0.5419]
Median for last 10 epochs: [0.5186 0.0841 0.5354 0.5701], Epochs since improvement 0
  3%|▎         | 15/500 [14:14<7:29:51, 55.65s/it]  3%|▎         | 16/500 [15:24<8:02:50, 59.86s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.01E+06, Train scatter: [0.2293 0.0761 0.5439 0.5159]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.235  0.0755 0.5353 0.5125], Lowest was [0.235  0.0755 0.5353 0.5125]
Median for last 10 epochs: [0.3726 0.0796 0.5354 0.5421], Epochs since improvement 0
  3%|▎         | 17/500 [16:09<7:27:43, 55.62s/it]  4%|▎         | 18/500 [17:19<8:01:33, 59.95s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.94E+06, Train scatter: [0.2327 0.0746 0.5438 0.5148]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.238  0.075  0.5352 0.5134], Lowest was [0.235  0.075  0.5352 0.5125]
Median for last 10 epochs: [0.3072 0.0765 0.5353 0.5419], Epochs since improvement 0
  4%|▍         | 19/500 [18:05<7:25:59, 55.63s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.87E+06, Train scatter: [0.2489 0.0721 0.5438 0.5257]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2553 0.0721 0.5352 0.5272], Lowest was [0.235  0.0721 0.5352 0.5125]
Median for last 10 epochs: [0.2553 0.0755 0.5353 0.5272], Epochs since improvement 0
  4%|▍         | 20/500 [19:21<8:14:00, 61.75s/it]  4%|▍         | 21/500 [20:07<7:34:34, 56.94s/it]  4%|▍         | 22/500 [21:16<8:04:05, 60.76s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.83E+06, Train scatter: [0.293  0.0707 0.5438 0.5274]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2936 0.0706 0.5352 0.5273], Lowest was [0.235  0.0706 0.5352 0.5125]
Median for last 10 epochs: [0.2553 0.075  0.5352 0.5272], Epochs since improvement 0
  5%|▍         | 23/500 [22:02<7:27:11, 56.25s/it]  5%|▍         | 24/500 [23:12<7:57:47, 60.23s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.80E+06, Train scatter: [0.3048 0.0717 0.5437 0.5597]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3044 0.071  0.5352 0.5574], Lowest was [0.235  0.0706 0.5352 0.5125]
Median for last 10 epochs: [0.2553 0.0721 0.5352 0.5272], Epochs since improvement 0
  5%|▌         | 25/500 [23:57<7:22:34, 55.91s/it]  5%|▌         | 26/500 [25:07<7:53:01, 59.88s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.56E+06, Train scatter: [0.2034 0.0685 0.5436 0.5012]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2077 0.0684 0.535  0.4968], Lowest was [0.2077 0.0684 0.535  0.4968]
Median for last 10 epochs: [0.2553 0.071  0.5352 0.5272], Epochs since improvement 0
  5%|▌         | 27/500 [25:52<7:18:27, 55.62s/it]  6%|▌         | 28/500 [27:02<7:50:23, 59.79s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.52E+06, Train scatter: [0.2752 0.0682 0.5436 0.5015]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2771 0.0674 0.535  0.4935], Lowest was [0.2077 0.0674 0.535  0.4935]
Median for last 10 epochs: [0.2771 0.0706 0.5352 0.5272], Epochs since improvement 0
  6%|▌         | 29/500 [27:47<7:16:01, 55.55s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.40E+06, Train scatter: [0.3898 0.0674 0.5435 0.5006]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3818 0.0671 0.5349 0.4953], Lowest was [0.2077 0.0671 0.5349 0.4935]
Median for last 10 epochs: [0.2936 0.0684 0.535  0.4968], Epochs since improvement 0
  6%|▌         | 30/500 [29:04<8:04:51, 61.90s/it]  6%|▌         | 31/500 [29:50<7:26:02, 57.06s/it]  6%|▋         | 32/500 [31:00<7:54:20, 60.81s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.37E+06, Train scatter: [0.2144 0.0639 0.5433 0.5118]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2175 0.0634 0.5347 0.5059], Lowest was [0.2077 0.0634 0.5347 0.4935]
Median for last 10 epochs: [0.2771 0.0674 0.535  0.4968], Epochs since improvement 0
  7%|▋         | 33/500 [31:45<7:17:47, 56.25s/it]  7%|▋         | 34/500 [32:54<7:46:41, 60.09s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.34E+06, Train scatter: [0.4508 0.0783 0.5432 0.5109]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4423 0.0779 0.5347 0.5086], Lowest was [0.2077 0.0634 0.5347 0.4935]
Median for last 10 epochs: [0.2771 0.0674 0.5349 0.4968], Epochs since improvement 0
  7%|▋         | 35/500 [33:40<7:11:57, 55.74s/it]  7%|▋         | 36/500 [34:49<7:41:48, 59.72s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.30E+06, Train scatter: [0.271  0.0738 0.543  0.5215]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2735 0.0728 0.5345 0.5184], Lowest was [0.2077 0.0634 0.5345 0.4935]
Median for last 10 epochs: [0.2771 0.0674 0.5347 0.5059], Epochs since improvement 0
  7%|▋         | 37/500 [35:34<7:08:10, 55.49s/it]  8%|▊         | 38/500 [36:44<7:39:15, 59.64s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.48E+08, Train scatter: [0.935  0.1675 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9194 0.1636 0.5355 0.9848], Lowest was [0.2077 0.0634 0.5345 0.4935]
Median for last 10 epochs: [0.3818 0.0728 0.5347 0.5086], Epochs since improvement 2
  8%|▊         | 39/500 [37:29<7:05:33, 55.39s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 4.68E+06, Train scatter: [0.9278 0.135  0.544  0.9932]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9122 0.1325 0.5354 0.9829], Lowest was [0.2077 0.0634 0.5345 0.4935]
Median for last 10 epochs: [0.4423 0.0779 0.5347 0.5184], Epochs since improvement 4
  8%|▊         | 40/500 [38:45<7:50:45, 61.40s/it]  8%|▊         | 41/500 [39:30<7:13:39, 56.69s/it]  8%|▊         | 42/500 [40:40<7:41:26, 60.45s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 4.53E+06, Train scatter: [0.6899 0.1158 0.5439 0.985 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6885 0.1142 0.5353 0.9745], Lowest was [0.2077 0.0634 0.5345 0.4935]
Median for last 10 epochs: [0.6885 0.1142 0.5353 0.9745], Epochs since improvement 6
  9%|▊         | 43/500 [41:25<7:06:13, 55.96s/it]  9%|▉         | 44/500 [42:35<7:37:08, 60.15s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.41E+06, Train scatter: [0.6033 0.1167 0.5437 0.97  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6012 0.1161 0.5351 0.96  ], Lowest was [0.2077 0.0634 0.5345 0.4935]
Median for last 10 epochs: [0.6885 0.1161 0.5353 0.9745], Epochs since improvement 8
  9%|▉         | 45/500 [43:21<7:02:57, 55.78s/it]  9%|▉         | 46/500 [44:30<7:33:34, 59.94s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.26E+06, Train scatter: [0.4773 0.1099 0.5436 0.9468]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4686 0.1078 0.535  0.9358], Lowest was [0.2077 0.0634 0.5345 0.4935]
Median for last 10 epochs: [0.6885 0.1161 0.5353 0.9745], Epochs since improvement 10
  9%|▉         | 47/500 [45:16<6:59:48, 55.60s/it] 10%|▉         | 48/500 [46:25<7:29:12, 59.63s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 4.15E+06, Train scatter: [0.5259 0.1205 0.5432 0.8603]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5258 0.1187 0.5346 0.8516], Lowest was [0.2077 0.0634 0.5345 0.4935]
Median for last 10 epochs: [0.6012 0.1161 0.5351 0.96  ], Epochs since improvement 12
 10%|▉         | 49/500 [47:10<6:56:36, 55.42s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 4.02E+06, Train scatter: [0.5023 0.1137 0.5427 0.7522]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4932 0.1113 0.5341 0.7421], Lowest was [0.2077 0.0634 0.5341 0.4935]
Median for last 10 epochs: [0.5258 0.1142 0.535  0.9358], Epochs since improvement 0
 10%|█         | 50/500 [48:26<7:40:53, 61.45s/it] 10%|█         | 51/500 [49:12<7:04:42, 56.75s/it] 10%|█         | 52/500 [50:21<7:32:14, 60.57s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.95E+06, Train scatter: [0.4979 0.1077 0.5414 0.7326]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4868 0.1059 0.5329 0.7233], Lowest was [0.2077 0.0634 0.5329 0.4935]
Median for last 10 epochs: [0.4932 0.1113 0.5346 0.8516], Epochs since improvement 0
 11%|█         | 53/500 [51:07<6:57:44, 56.07s/it] 11%|█         | 54/500 [52:16<7:27:05, 60.15s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.84E+06, Train scatter: [0.5143 0.1083 0.5404 0.6768]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4997 0.1056 0.5319 0.667 ], Lowest was [0.2077 0.0634 0.5319 0.4935]
Median for last 10 epochs: [0.4932 0.1078 0.5341 0.7421], Epochs since improvement 0
 11%|█         | 55/500 [53:02<6:53:46, 55.79s/it] 11%|█         | 56/500 [54:11<7:23:01, 59.87s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.75E+06, Train scatter: [0.533  0.1108 0.5381 0.7094]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5275 0.1095 0.5297 0.7098], Lowest was [0.2077 0.0634 0.5297 0.4935]
Median for last 10 epochs: [0.4997 0.1095 0.5329 0.7233], Epochs since improvement 0
 11%|█▏        | 57/500 [54:57<6:50:28, 55.59s/it] 12%|█▏        | 58/500 [56:07<7:20:23, 59.78s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.68E+06, Train scatter: [0.5547 0.1074 0.5365 0.6971]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5426 0.1059 0.528  0.6948], Lowest was [0.2077 0.0634 0.528  0.4935]
Median for last 10 epochs: [0.4997 0.1059 0.5319 0.7098], Epochs since improvement 0
 12%|█▏        | 59/500 [56:52<6:48:38, 55.60s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.60E+06, Train scatter: [0.613  0.104  0.5354 0.6958]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.594  0.1021 0.5269 0.6889], Lowest was [0.2077 0.0634 0.5269 0.4935]
Median for last 10 epochs: [0.5275 0.1059 0.5297 0.6948], Epochs since improvement 0
 12%|█▏        | 60/500 [58:08<7:30:56, 61.49s/it] 12%|█▏        | 61/500 [58:53<6:55:11, 56.75s/it] 12%|█▏        | 62/500 [1:00:03<7:22:47, 60.66s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.55E+06, Train scatter: [0.3859 0.1012 0.5335 0.6507]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3886 0.0993 0.5255 0.6451], Lowest was [0.2077 0.0634 0.5255 0.4935]
Median for last 10 epochs: [0.5275 0.1056 0.528  0.6889], Epochs since improvement 0
 13%|█▎        | 63/500 [1:00:49<6:48:51, 56.14s/it] 13%|█▎        | 64/500 [1:01:57<7:15:15, 59.90s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.78E+06, Train scatter: [0.9009 0.2003 0.5369 0.7625]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8861 0.196  0.5285 0.7498], Lowest was [0.2077 0.0634 0.5255 0.4935]
Median for last 10 epochs: [0.5426 0.1059 0.528  0.6948], Epochs since improvement 2
 13%|█▎        | 65/500 [1:02:43<6:42:59, 55.58s/it] 13%|█▎        | 66/500 [1:03:52<7:12:07, 59.74s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.68E+06, Train scatter: [0.5759 0.1175 0.539  0.7447]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5698 0.1166 0.5308 0.7381], Lowest was [0.2077 0.0634 0.5255 0.4935]
Median for last 10 epochs: [0.5698 0.1059 0.528  0.6948], Epochs since improvement 4
 13%|█▎        | 67/500 [1:04:38<6:40:34, 55.51s/it] 14%|█▎        | 68/500 [1:05:47<7:08:56, 59.58s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.55E+06, Train scatter: [0.5267 0.1067 0.5345 0.6784]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.515  0.1045 0.5261 0.6694], Lowest was [0.2077 0.0634 0.5255 0.4935]
Median for last 10 epochs: [0.5698 0.1045 0.5269 0.6889], Epochs since improvement 6
 14%|█▍        | 69/500 [1:06:33<6:38:05, 55.42s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.48E+06, Train scatter: [0.4521 0.0961 0.5302 0.6322]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4483 0.0948 0.522  0.6272], Lowest was [0.2077 0.0634 0.522  0.4935]
Median for last 10 epochs: [0.515  0.1045 0.5261 0.6694], Epochs since improvement 0
 14%|█▍        | 70/500 [1:07:47<7:18:06, 61.13s/it] 14%|█▍        | 71/500 [1:08:33<6:43:46, 56.47s/it] 14%|█▍        | 72/500 [1:09:42<7:09:12, 60.17s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.33E+06, Train scatter: [0.4404 0.1031 0.5303 0.6411]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4413 0.1021 0.5226 0.6398], Lowest was [0.2077 0.0634 0.522  0.4935]
Median for last 10 epochs: [0.515  0.1045 0.5261 0.6694], Epochs since improvement 2
 15%|█▍        | 73/500 [1:10:27<6:37:20, 55.83s/it] 15%|█▍        | 74/500 [1:11:37<7:06:43, 60.10s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.22E+06, Train scatter: [0.404  0.0992 0.525  0.5994]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3957 0.0978 0.5171 0.5975], Lowest was [0.2077 0.0634 0.5171 0.4935]
Median for last 10 epochs: [0.4483 0.1021 0.5226 0.6398], Epochs since improvement 0
 15%|█▌        | 75/500 [1:12:23<6:35:03, 55.77s/it] 15%|█▌        | 76/500 [1:13:32<7:03:02, 59.86s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.49E+06, Train scatter: [0.8725 0.154  0.5426 0.7208]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8582 0.1503 0.5341 0.7135], Lowest was [0.2077 0.0634 0.5171 0.4935]
Median for last 10 epochs: [0.4483 0.1021 0.5226 0.6398], Epochs since improvement 2
 15%|█▌        | 77/500 [1:14:18<6:31:48, 55.58s/it] 16%|█▌        | 78/500 [1:15:27<6:58:29, 59.50s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.10E+06, Train scatter: [0.541  0.103  0.5379 0.6117]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5294 0.1008 0.5297 0.6057], Lowest was [0.2077 0.0634 0.5171 0.4935]
Median for last 10 epochs: [0.4483 0.1008 0.5226 0.6272], Epochs since improvement 4
 16%|█▌        | 79/500 [1:16:12<6:28:29, 55.37s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.81E+06, Train scatter: [0.7956 0.0947 0.5187 0.5939]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.748  0.0938 0.5108 0.5915], Lowest was [0.2077 0.0634 0.5108 0.4935]
Median for last 10 epochs: [0.5294 0.1008 0.5226 0.6057], Epochs since improvement 0
 16%|█▌        | 80/500 [1:17:28<7:10:12, 61.46s/it] 16%|█▌        | 81/500 [1:18:14<6:36:07, 56.72s/it] 16%|█▋        | 82/500 [1:19:24<7:04:01, 60.86s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 3.01E+06, Train scatter: [0.6043 0.1184 0.5438 0.7552]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6006 0.1174 0.5353 0.7513], Lowest was [0.2077 0.0634 0.5108 0.4935]
Median for last 10 epochs: [0.6006 0.1008 0.5297 0.6057], Epochs since improvement 2
 17%|█▋        | 83/500 [1:20:10<6:31:04, 56.27s/it] 17%|█▋        | 84/500 [1:21:19<6:56:33, 60.08s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.94E+06, Train scatter: [0.5718 0.1153 0.5435 0.7455]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5635 0.114  0.5349 0.7401], Lowest was [0.2077 0.0634 0.5108 0.4935]
Median for last 10 epochs: [0.6006 0.114  0.5341 0.7135], Epochs since improvement 4
 17%|█▋        | 85/500 [1:22:04<6:25:34, 55.74s/it] 17%|█▋        | 86/500 [1:23:13<6:50:56, 59.56s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.82E+06, Train scatter: [0.4783 0.1099 0.5204 0.699 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4732 0.1078 0.5133 0.6888], Lowest was [0.2077 0.0634 0.5108 0.4935]
Median for last 10 epochs: [0.5635 0.1078 0.5297 0.6888], Epochs since improvement 6
 17%|█▋        | 87/500 [1:23:58<6:21:13, 55.38s/it] 18%|█▊        | 88/500 [1:25:07<6:48:17, 59.46s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.28E+06, Train scatter: [0.5685 0.1014 0.4418 0.6663]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.577  0.1027 0.4399 0.6826], Lowest was [0.2077 0.0634 0.4399 0.4935]
Median for last 10 epochs: [0.577  0.1078 0.5133 0.6888], Epochs since improvement 0
 18%|█▊        | 89/500 [1:25:53<6:18:57, 55.32s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 1.20E+06, Train scatter: [0.4391 0.0842 0.3848 0.6473]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4389 0.0861 0.3954 0.6529], Lowest was [0.2077 0.0634 0.3954 0.4935]
Median for last 10 epochs: [0.5635 0.1078 0.5133 0.6888], Epochs since improvement 0
 18%|█▊        | 90/500 [1:27:09<6:59:54, 61.45s/it] 18%|█▊        | 91/500 [1:27:55<6:26:50, 56.75s/it] 18%|█▊        | 92/500 [1:29:04<6:52:30, 60.66s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 8.48E+05, Train scatter: [0.4478 0.0728 0.34   0.6457]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4428 0.0755 0.3468 0.6564], Lowest was [0.2077 0.0634 0.3468 0.4935]
Median for last 10 epochs: [0.4732 0.1027 0.4399 0.6826], Epochs since improvement 0
 19%|█▊        | 93/500 [1:29:50<6:21:04, 56.18s/it] 19%|█▉        | 94/500 [1:30:59<6:46:08, 60.02s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 7.07E+05, Train scatter: [0.424  0.0673 0.3158 0.6029]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4122 0.0687 0.3251 0.6083], Lowest was [0.2077 0.0634 0.3251 0.4935]
Median for last 10 epochs: [0.4428 0.0861 0.3954 0.6564], Epochs since improvement 0
 19%|█▉        | 95/500 [1:31:45<6:16:00, 55.71s/it] 19%|█▉        | 96/500 [1:32:53<6:41:05, 59.57s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 6.17E+05, Train scatter: [0.4152 0.0655 0.3035 0.5747]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.407  0.0666 0.3102 0.576 ], Lowest was [0.2077 0.0634 0.3102 0.4935]
Median for last 10 epochs: [0.4389 0.0755 0.3468 0.6529], Epochs since improvement 0
 19%|█▉        | 97/500 [1:33:39<6:12:10, 55.41s/it] 20%|█▉        | 98/500 [1:34:47<6:37:15, 59.29s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 5.21E+05, Train scatter: [0.4755 0.0664 0.331  0.5582]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4618 0.0665 0.3389 0.5614], Lowest was [0.2077 0.0634 0.3102 0.4935]
Median for last 10 epochs: [0.4389 0.0687 0.3389 0.6083], Epochs since improvement 2
 20%|█▉        | 99/500 [1:35:33<6:09:17, 55.26s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 4.96E+05, Train scatter: [0.2971 0.0614 0.2934 0.5489]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.312  0.0625 0.3033 0.5477], Lowest was [0.2077 0.0625 0.3033 0.4935]
Median for last 10 epochs: [0.4122 0.0666 0.3251 0.576 ], Epochs since improvement 0
 20%|██        | 100/500 [1:36:50<6:50:49, 61.62s/it] 20%|██        | 101/500 [1:37:36<6:18:11, 56.87s/it] 20%|██        | 102/500 [1:38:45<6:41:47, 60.57s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 4.12E+05, Train scatter: [0.4269 0.0601 0.2908 0.5394]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4109 0.0603 0.2965 0.5362], Lowest was [0.2077 0.0603 0.2965 0.4935]
Median for last 10 epochs: [0.4109 0.0665 0.3102 0.5614], Epochs since improvement 0
 21%|██        | 103/500 [1:39:30<6:11:02, 56.08s/it] 21%|██        | 104/500 [1:40:40<6:37:26, 60.22s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 4.48E+05, Train scatter: [0.4476 0.0632 0.2951 0.5499]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4365 0.0642 0.3025 0.5495], Lowest was [0.2077 0.0603 0.2965 0.4935]
Median for last 10 epochs: [0.4109 0.0642 0.3033 0.5495], Epochs since improvement 2
 21%|██        | 105/500 [1:41:26<6:07:32, 55.83s/it] 21%|██        | 106/500 [1:42:35<6:32:34, 59.78s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 3.42E+05, Train scatter: [0.4143 0.0566 0.2837 0.5246]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3981 0.0566 0.2912 0.524 ], Lowest was [0.2077 0.0566 0.2912 0.4935]
Median for last 10 epochs: [0.4109 0.0625 0.3025 0.5477], Epochs since improvement 0
 21%|██▏       | 107/500 [1:43:20<6:03:46, 55.54s/it] 22%|██▏       | 108/500 [1:44:30<6:30:57, 59.84s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 4.23E+05, Train scatter: [0.4389 0.0661 0.309  0.5195]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4237 0.0652 0.3145 0.5178], Lowest was [0.2077 0.0566 0.2912 0.4935]
Median for last 10 epochs: [0.4109 0.0625 0.3025 0.5362], Epochs since improvement 2
 22%|██▏       | 109/500 [1:45:16<6:02:02, 55.56s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 2.64E+05, Train scatter: [0.3488 0.0597 0.296  0.5373]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3523 0.0607 0.3037 0.538 ], Lowest was [0.2077 0.0566 0.2912 0.4935]
Median for last 10 epochs: [0.4109 0.0607 0.3025 0.5362], Epochs since improvement 4
 22%|██▏       | 110/500 [1:46:31<6:39:22, 61.44s/it] 22%|██▏       | 111/500 [1:47:17<6:07:33, 56.69s/it] 22%|██▏       | 112/500 [1:48:26<6:30:29, 60.39s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 2.54E+05, Train scatter: [0.4365 0.053  0.2629 0.4888]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4241 0.0529 0.2699 0.4866], Lowest was [0.2077 0.0529 0.2699 0.4866]
Median for last 10 epochs: [0.4237 0.0607 0.3025 0.524 ], Epochs since improvement 0
 23%|██▎       | 113/500 [1:49:11<6:01:00, 55.97s/it] 23%|██▎       | 114/500 [1:50:21<6:26:26, 60.07s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 2.00E+05, Train scatter: [0.295  0.0559 0.2736 0.4815]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2956 0.0569 0.2825 0.4778], Lowest was [0.2077 0.0529 0.2699 0.4778]
Median for last 10 epochs: [0.3981 0.0569 0.2912 0.5178], Epochs since improvement 0
 23%|██▎       | 115/500 [1:51:07<5:57:35, 55.73s/it] 23%|██▎       | 116/500 [1:52:16<6:22:44, 59.80s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 3.06E+05, Train scatter: [0.4011 0.0772 0.3813 0.5384]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3979 0.0767 0.3847 0.5348], Lowest was [0.2077 0.0529 0.2699 0.4778]
Median for last 10 epochs: [0.3979 0.0607 0.3037 0.5178], Epochs since improvement 2
 23%|██▎       | 117/500 [1:53:02<5:54:44, 55.57s/it] 24%|██▎       | 118/500 [1:54:10<6:18:51, 59.51s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 3.07E+05, Train scatter: [0.4226 0.0499 0.2487 0.4763]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4082 0.0506 0.2572 0.4774], Lowest was [0.2077 0.0506 0.2572 0.4774]
Median for last 10 epochs: [0.3979 0.0569 0.2825 0.4866], Epochs since improvement 0
 24%|██▍       | 119/500 [1:54:56<5:51:35, 55.37s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 9.75E+04, Train scatter: [0.3976 0.049  0.2393 0.46  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3864 0.0499 0.2463 0.4574], Lowest was [0.2077 0.0499 0.2463 0.4574]
Median for last 10 epochs: [0.3979 0.0529 0.2699 0.4778], Epochs since improvement 0
 24%|██▍       | 120/500 [1:56:11<6:28:07, 61.28s/it] 24%|██▍       | 121/500 [1:56:57<5:57:27, 56.59s/it] 24%|██▍       | 122/500 [1:58:06<6:20:18, 60.37s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 5.31E+04, Train scatter: [0.2554 0.0539 0.25   0.4607]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2619 0.054  0.2549 0.4597], Lowest was [0.2077 0.0499 0.2463 0.4574]
Median for last 10 epochs: [0.3864 0.054  0.2572 0.4774], Epochs since improvement 2
 25%|██▍       | 123/500 [1:58:52<5:51:44, 55.98s/it] 25%|██▍       | 124/500 [2:00:00<6:14:48, 59.81s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.53E+04, Train scatter: [0.3328 0.0472 0.2494 0.4496]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3133 0.0466 0.2568 0.4455], Lowest was [0.2077 0.0466 0.2463 0.4455]
Median for last 10 epochs: [0.3864 0.0506 0.2568 0.4597], Epochs since improvement 0
 25%|██▌       | 125/500 [2:00:46<5:47:09, 55.55s/it] 25%|██▌       | 126/500 [2:01:55<6:11:22, 59.58s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: -4.09E+04, Train scatter: [0.3417 0.0465 0.2352 0.4456]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3381 0.0465 0.243  0.4413], Lowest was [0.2077 0.0465 0.243  0.4413]
Median for last 10 epochs: [0.3381 0.0499 0.2549 0.4574], Epochs since improvement 0
 25%|██▌       | 127/500 [2:02:41<5:44:15, 55.38s/it] 26%|██▌       | 128/500 [2:03:50<6:10:10, 59.71s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 8.79E+04, Train scatter: [0.3608 0.0473 0.2609 0.4429]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3602 0.0469 0.2679 0.4406], Lowest was [0.2077 0.0465 0.243  0.4406]
Median for last 10 epochs: [0.3381 0.0469 0.2549 0.4455], Epochs since improvement 0
 26%|██▌       | 129/500 [2:04:36<5:43:03, 55.48s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -2.10E+05, Train scatter: [0.3451 0.0453 0.2256 0.4361]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3383 0.0462 0.2306 0.4326], Lowest was [0.2077 0.0462 0.2306 0.4326]
Median for last 10 epochs: [0.3381 0.0466 0.2549 0.4413], Epochs since improvement 0
 26%|██▌       | 130/500 [2:05:51<6:18:47, 61.42s/it] 26%|██▌       | 131/500 [2:06:37<5:48:24, 56.65s/it] 26%|██▋       | 132/500 [2:07:46<6:11:14, 60.53s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -3.02E+05, Train scatter: [0.2216 0.0456 0.2223 0.4496]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2172 0.0445 0.2265 0.4412], Lowest was [0.2077 0.0445 0.2265 0.4326]
Median for last 10 epochs: [0.3381 0.0465 0.243  0.4412], Epochs since improvement 0
 27%|██▋       | 133/500 [2:08:32<5:42:36, 56.01s/it] 27%|██▋       | 134/500 [2:09:41<6:06:07, 60.02s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: -2.60E+05, Train scatter: [0.3669 0.0503 0.3844 0.4573]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3601 0.0491 0.3768 0.4476], Lowest was [0.2077 0.0445 0.2265 0.4326]
Median for last 10 epochs: [0.3383 0.0465 0.243  0.4412], Epochs since improvement 2
 27%|██▋       | 135/500 [2:10:27<5:38:43, 55.68s/it] 27%|██▋       | 136/500 [2:11:36<6:02:25, 59.74s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: -3.70E+05, Train scatter: [0.3539 0.0445 0.2372 0.4339]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3432 0.045  0.2442 0.4321], Lowest was [0.2077 0.0445 0.2265 0.4321]
Median for last 10 epochs: [0.3432 0.0462 0.2442 0.4406], Epochs since improvement 0
 27%|██▋       | 137/500 [2:12:21<5:35:39, 55.48s/it] 28%|██▊       | 138/500 [2:13:30<5:59:05, 59.52s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -3.82E+05, Train scatter: [0.3125 0.0436 0.2242 0.4247]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3084 0.0432 0.2295 0.4207], Lowest was [0.2077 0.0432 0.2265 0.4207]
Median for last 10 epochs: [0.3383 0.045  0.2306 0.4326], Epochs since improvement 0
 28%|██▊       | 139/500 [2:14:16<5:32:45, 55.31s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -3.93E+05, Train scatter: [0.2297 0.0451 0.2196 0.4333]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2204 0.0447 0.2252 0.4278], Lowest was [0.2077 0.0432 0.2252 0.4207]
Median for last 10 epochs: [0.3084 0.0447 0.2295 0.4321], Epochs since improvement 0
 28%|██▊       | 140/500 [2:15:32<6:09:38, 61.61s/it] 28%|██▊       | 141/500 [2:16:18<5:39:54, 56.81s/it] 28%|██▊       | 142/500 [2:17:27<6:01:17, 60.55s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -3.91E+05, Train scatter: [0.3326 0.0462 0.2203 0.4208]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3245 0.046  0.2243 0.4185], Lowest was [0.2077 0.0432 0.2243 0.4185]
Median for last 10 epochs: [0.3245 0.045  0.2295 0.4278], Epochs since improvement 0
 29%|██▊       | 143/500 [2:18:13<5:33:30, 56.05s/it] 29%|██▉       | 144/500 [2:19:22<5:56:42, 60.12s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: -3.60E+05, Train scatter: [0.3767 0.0426 0.2309 0.4203]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3674 0.0424 0.2342 0.4158], Lowest was [0.2077 0.0424 0.2243 0.4158]
Median for last 10 epochs: [0.3245 0.0447 0.2295 0.4207], Epochs since improvement 0
 29%|██▉       | 145/500 [2:20:08<5:30:03, 55.79s/it] 29%|██▉       | 146/500 [2:21:17<5:52:17, 59.71s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: -4.02E+05, Train scatter: [0.2184 0.0437 0.2303 0.4289]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2036 0.0441 0.2352 0.4285], Lowest was [0.2036 0.0424 0.2243 0.4158]
Median for last 10 epochs: [0.3084 0.0441 0.2295 0.4207], Epochs since improvement 0
 29%|██▉       | 147/500 [2:22:02<5:26:17, 55.46s/it] 30%|██▉       | 148/500 [2:23:11<5:49:03, 59.50s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: -3.83E+05, Train scatter: [0.1902 0.0482 0.2622 0.434 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1901 0.0476 0.2719 0.4268], Lowest was [0.1901 0.0424 0.2243 0.4158]
Median for last 10 epochs: [0.2204 0.0447 0.2342 0.4268], Epochs since improvement 0
 30%|██▉       | 149/500 [2:23:57<5:23:54, 55.37s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: -4.04E+05, Train scatter: [0.3543 0.0418 0.2235 0.4176]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.347  0.0416 0.2261 0.412 ], Lowest was [0.1901 0.0416 0.2243 0.412 ]
Median for last 10 epochs: [0.3245 0.0441 0.2342 0.4185], Epochs since improvement 0
 30%|███       | 150/500 [2:25:12<5:57:35, 61.30s/it] 30%|███       | 151/500 [2:25:58<5:29:03, 56.57s/it] 30%|███       | 152/500 [2:27:07<5:49:42, 60.29s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: -4.07E+05, Train scatter: [0.2116 0.0455 0.229  0.4329]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.209  0.0447 0.2357 0.427 ], Lowest was [0.1901 0.0416 0.2243 0.412 ]
Median for last 10 epochs: [0.209  0.0441 0.2352 0.4268], Epochs since improvement 2
 31%|███       | 153/500 [2:27:52<5:23:18, 55.90s/it] 31%|███       | 154/500 [2:29:01<5:44:58, 59.82s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: -3.86E+05, Train scatter: [0.4558 0.0467 0.2385 0.4494]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4415 0.0459 0.2428 0.4458], Lowest was [0.1901 0.0416 0.2243 0.412 ]
Median for last 10 epochs: [0.209  0.0447 0.2357 0.427 ], Epochs since improvement 4
 31%|███       | 155/500 [2:29:47<5:19:24, 55.55s/it] 31%|███       | 156/500 [2:30:56<5:41:29, 59.56s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: -3.98E+05, Train scatter: [0.3701 0.0453 0.2359 0.432 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3596 0.0461 0.2418 0.4327], Lowest was [0.1901 0.0416 0.2243 0.412 ]
Median for last 10 epochs: [0.347  0.0459 0.2418 0.427 ], Epochs since improvement 6
 31%|███▏      | 157/500 [2:31:41<5:16:28, 55.36s/it] 32%|███▏      | 158/500 [2:32:51<5:39:09, 59.50s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: -4.01E+05, Train scatter: [0.1734 0.0512 0.2303 0.4255]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1705 0.0503 0.2322 0.4168], Lowest was [0.1705 0.0416 0.2243 0.412 ]
Median for last 10 epochs: [0.347  0.0459 0.2357 0.427 ], Epochs since improvement 0
 32%|███▏      | 159/500 [2:33:36<5:14:39, 55.37s/it]Epoch: 160 done with learning rate 9.05E-03, Train loss: -4.08E+05, Train scatter: [0.1551 0.0498 0.2449 0.4327]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1546 0.0492 0.2479 0.4265], Lowest was [0.1546 0.0416 0.2243 0.412 ]
Median for last 10 epochs: [0.209  0.0461 0.2418 0.427 ], Epochs since improvement 0
 32%|███▏      | 160/500 [2:34:51<5:47:30, 61.32s/it] 32%|███▏      | 161/500 [2:35:37<5:19:48, 56.60s/it] 32%|███▏      | 162/500 [2:36:46<5:40:00, 60.36s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: -4.09E+05, Train scatter: [0.3499 0.0415 0.2223 0.4169]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3424 0.0409 0.2245 0.4104], Lowest was [0.1546 0.0409 0.2243 0.4104]
Median for last 10 epochs: [0.3424 0.0461 0.2418 0.4265], Epochs since improvement 0
 33%|███▎      | 163/500 [2:37:32<5:14:23, 55.97s/it] 33%|███▎      | 164/500 [2:38:41<5:35:00, 59.82s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: -4.11E+05, Train scatter: [0.3531 0.043  0.2326 0.4159]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3427 0.0427 0.2363 0.4075], Lowest was [0.1546 0.0409 0.2243 0.4075]
Median for last 10 epochs: [0.3424 0.0461 0.2363 0.4168], Epochs since improvement 0
 33%|███▎      | 165/500 [2:39:27<5:10:36, 55.63s/it] 33%|███▎      | 166/500 [2:40:36<5:33:01, 59.82s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: -4.12E+05, Train scatter: [0.3716 0.0409 0.2228 0.4115]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3626 0.0407 0.2266 0.4052], Lowest was [0.1546 0.0407 0.2243 0.4052]
Median for last 10 epochs: [0.3424 0.0427 0.2322 0.4104], Epochs since improvement 0
 33%|███▎      | 167/500 [2:41:22<5:08:32, 55.59s/it] 34%|███▎      | 168/500 [2:42:30<5:28:43, 59.41s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: -4.21E+05, Train scatter: [0.1731 0.042  0.2232 0.4129]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1699 0.042  0.2275 0.4063], Lowest was [0.1546 0.0407 0.2243 0.4052]
Median for last 10 epochs: [0.3424 0.042  0.2275 0.4075], Epochs since improvement 2
 34%|███▍      | 169/500 [2:43:16<5:04:51, 55.26s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -4.27E+05, Train scatter: [0.362  0.046  0.2229 0.4203]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3546 0.046  0.2277 0.4176], Lowest was [0.1546 0.0407 0.2243 0.4052]
Median for last 10 epochs: [0.3427 0.042  0.2275 0.4075], Epochs since improvement 4
 34%|███▍      | 170/500 [2:44:33<5:39:29, 61.73s/it] 34%|███▍      | 171/500 [2:45:18<5:12:04, 56.91s/it] 34%|███▍      | 172/500 [2:46:29<5:32:56, 60.90s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -4.28E+05, Train scatter: [0.1965 0.0402 0.2154 0.4071]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1911 0.0401 0.2183 0.4016], Lowest was [0.1546 0.0401 0.2183 0.4016]
Median for last 10 epochs: [0.3427 0.042  0.2275 0.4063], Epochs since improvement 0
 35%|███▍      | 173/500 [2:47:14<5:06:56, 56.32s/it] 35%|███▍      | 174/500 [2:48:24<5:28:20, 60.43s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -4.25E+05, Train scatter: [0.1818 0.0417 0.2206 0.419 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1785 0.0413 0.2225 0.4116], Lowest was [0.1546 0.0401 0.2183 0.4016]
Median for last 10 epochs: [0.1911 0.0413 0.2266 0.4063], Epochs since improvement 2
 35%|███▌      | 175/500 [2:49:10<5:03:04, 55.95s/it] 35%|███▌      | 176/500 [2:50:19<5:23:25, 59.89s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -4.37E+05, Train scatter: [0.2025 0.0508 0.2382 0.4445]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2069 0.0501 0.2403 0.4352], Lowest was [0.1546 0.0401 0.2183 0.4016]
Median for last 10 epochs: [0.1911 0.042  0.2275 0.4116], Epochs since improvement 4
 35%|███▌      | 177/500 [2:51:04<4:59:29, 55.63s/it] 36%|███▌      | 178/500 [2:52:14<5:21:27, 59.90s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -4.32E+05, Train scatter: [0.2795 0.0399 0.2155 0.4039]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2749 0.0393 0.2169 0.3965], Lowest was [0.1546 0.0393 0.2169 0.3965]
Median for last 10 epochs: [0.2069 0.0413 0.2225 0.4116], Epochs since improvement 0
 36%|███▌      | 179/500 [2:53:00<4:57:36, 55.63s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -4.43E+05, Train scatter: [0.2073 0.0427 0.2397 0.4063]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2069 0.0424 0.2392 0.398 ], Lowest was [0.1546 0.0393 0.2169 0.3965]
Median for last 10 epochs: [0.2069 0.0413 0.2225 0.4016], Epochs since improvement 2
 36%|███▌      | 180/500 [2:54:15<5:27:15, 61.36s/it] 36%|███▌      | 181/500 [2:55:00<5:01:17, 56.67s/it] 36%|███▋      | 182/500 [2:56:10<5:20:09, 60.41s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -4.48E+05, Train scatter: [0.3446 0.039  0.2117 0.4009]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.335  0.0388 0.2141 0.3929], Lowest was [0.1546 0.0388 0.2141 0.3929]
Median for last 10 epochs: [0.2069 0.0413 0.2225 0.398 ], Epochs since improvement 0
 37%|███▋      | 183/500 [2:56:55<4:55:40, 55.96s/it] 37%|███▋      | 184/500 [2:58:05<5:16:51, 60.16s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -4.46E+05, Train scatter: [0.324  0.0455 0.2336 0.4063]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3172 0.0456 0.2378 0.4034], Lowest was [0.1546 0.0388 0.2141 0.3929]
Median for last 10 epochs: [0.2749 0.0424 0.2378 0.398 ], Epochs since improvement 2
 37%|███▋      | 185/500 [2:58:51<4:53:04, 55.82s/it] 37%|███▋      | 186/500 [3:00:00<5:13:19, 59.87s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -4.27E+05, Train scatter: [0.5465 0.0496 0.2447 0.5594]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5476 0.0493 0.2468 0.5617], Lowest was [0.1546 0.0388 0.2141 0.3929]
Median for last 10 epochs: [0.3172 0.0424 0.2378 0.398 ], Epochs since improvement 4
 37%|███▋      | 187/500 [3:00:46<4:49:51, 55.57s/it] 38%|███▊      | 188/500 [3:01:55<5:10:27, 59.70s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -4.09E+05, Train scatter: [0.3924 0.0547 0.2931 0.4654]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3829 0.0538 0.2901 0.4595], Lowest was [0.1546 0.0388 0.2141 0.3929]
Median for last 10 epochs: [0.335  0.0456 0.2392 0.4034], Epochs since improvement 6
 38%|███▊      | 189/500 [3:02:41<4:47:28, 55.46s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -4.45E+05, Train scatter: [0.1409 0.0439 0.2359 0.4161]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1382 0.043  0.2362 0.4028], Lowest was [0.1382 0.0388 0.2141 0.3929]
Median for last 10 epochs: [0.335  0.0456 0.2378 0.4034], Epochs since improvement 0
 38%|███▊      | 190/500 [3:03:57<5:18:31, 61.65s/it] 38%|███▊      | 191/500 [3:04:42<4:52:58, 56.89s/it] 38%|███▊      | 192/500 [3:05:52<5:11:56, 60.77s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -4.55E+05, Train scatter: [0.1331 0.0384 0.2127 0.3989]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1346 0.0382 0.2151 0.3896], Lowest was [0.1346 0.0382 0.2141 0.3896]
Median for last 10 epochs: [0.3172 0.0456 0.2378 0.4034], Epochs since improvement 0
 39%|███▊      | 193/500 [3:06:38<4:48:06, 56.31s/it] 39%|███▉      | 194/500 [3:07:48<5:07:32, 60.30s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -4.68E+05, Train scatter: [0.3057 0.0399 0.2078 0.3989]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.301  0.0395 0.2101 0.3898], Lowest was [0.1346 0.0382 0.2101 0.3896]
Median for last 10 epochs: [0.301  0.043  0.2362 0.4028], Epochs since improvement 0
 39%|███▉      | 195/500 [3:08:34<4:44:27, 55.96s/it] 39%|███▉      | 196/500 [3:09:43<5:04:21, 60.07s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -4.70E+05, Train scatter: [0.1669 0.0384 0.2156 0.3952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1613 0.0384 0.2191 0.3863], Lowest was [0.1346 0.0382 0.2101 0.3863]
Median for last 10 epochs: [0.1613 0.0395 0.2191 0.3898], Epochs since improvement 0
 39%|███▉      | 197/500 [3:10:29<4:41:31, 55.75s/it] 40%|███▉      | 198/500 [3:11:38<5:01:20, 59.87s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -4.74E+05, Train scatter: [0.1756 0.0397 0.2087 0.3993]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1698 0.0393 0.2105 0.3897], Lowest was [0.1346 0.0382 0.2101 0.3863]
Median for last 10 epochs: [0.1613 0.0393 0.2151 0.3897], Epochs since improvement 2
 40%|███▉      | 199/500 [3:12:24<4:38:54, 55.60s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -4.78E+05, Train scatter: [0.1162 0.0375 0.2105 0.3893]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1168 0.0372 0.2124 0.3792], Lowest was [0.1168 0.0372 0.2101 0.3792]
Median for last 10 epochs: [0.1613 0.0384 0.2124 0.3896], Epochs since improvement 0
 40%|████      | 200/500 [3:13:40<5:08:45, 61.75s/it] 40%|████      | 201/500 [3:14:26<4:43:49, 56.96s/it] 40%|████      | 202/500 [3:15:35<5:01:17, 60.66s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -4.83E+05, Train scatter: [0.114  0.0376 0.2069 0.3929]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1164 0.0374 0.21   0.3856], Lowest was [0.1164 0.0372 0.21   0.3792]
Median for last 10 epochs: [0.1613 0.0384 0.2105 0.3863], Epochs since improvement 0
 41%|████      | 203/500 [3:16:21<4:38:13, 56.21s/it] 41%|████      | 204/500 [3:17:30<4:56:28, 60.10s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -4.81E+05, Train scatter: [0.1244 0.0383 0.2105 0.3985]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1256 0.038  0.2128 0.3889], Lowest was [0.1164 0.0372 0.21   0.3792]
Median for last 10 epochs: [0.1256 0.038  0.2124 0.3863], Epochs since improvement 2
 41%|████      | 205/500 [3:18:16<4:34:25, 55.81s/it] 41%|████      | 206/500 [3:19:25<4:53:09, 59.83s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -4.85E+05, Train scatter: [0.1173 0.0367 0.2011 0.3838]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.12   0.0364 0.2043 0.3768], Lowest was [0.1164 0.0364 0.2043 0.3768]
Median for last 10 epochs: [0.12   0.0374 0.2105 0.3856], Epochs since improvement 0
 41%|████▏     | 207/500 [3:20:11<4:31:34, 55.61s/it] 42%|████▏     | 208/500 [3:21:20<4:50:32, 59.70s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -4.87E+05, Train scatter: [0.1335 0.0388 0.2085 0.3909]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1373 0.0391 0.2134 0.3852], Lowest was [0.1164 0.0364 0.2043 0.3768]
Median for last 10 epochs: [0.12   0.0374 0.2124 0.3852], Epochs since improvement 2
 42%|████▏     | 209/500 [3:22:06<4:29:12, 55.51s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -4.94E+05, Train scatter: [0.1207 0.0379 0.2046 0.3996]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1207 0.0376 0.2065 0.3899], Lowest was [0.1164 0.0364 0.2043 0.3768]
Median for last 10 epochs: [0.1207 0.0376 0.21   0.3856], Epochs since improvement 4
 42%|████▏     | 210/500 [3:23:22<4:58:28, 61.75s/it] 42%|████▏     | 211/500 [3:24:08<4:34:22, 56.96s/it] 42%|████▏     | 212/500 [3:25:17<4:50:43, 60.57s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -4.90E+05, Train scatter: [0.1666 0.0401 0.2057 0.3947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1623 0.0394 0.2092 0.3849], Lowest was [0.1164 0.0364 0.2043 0.3768]
Median for last 10 epochs: [0.1256 0.038  0.2092 0.3852], Epochs since improvement 6
 43%|████▎     | 213/500 [3:26:03<4:28:19, 56.10s/it] 43%|████▎     | 214/500 [3:27:12<4:45:48, 59.96s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: -5.02E+05, Train scatter: [0.114  0.0364 0.201  0.384 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1172 0.0362 0.2044 0.3768], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1207 0.0376 0.2065 0.3849], Epochs since improvement 0
 43%|████▎     | 215/500 [3:27:57<4:24:33, 55.70s/it] 43%|████▎     | 216/500 [3:29:07<4:43:17, 59.85s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -4.10E+05, Train scatter: [0.1277 0.0407 0.2208 0.4169]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1287 0.0402 0.2226 0.4096], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1287 0.0391 0.2092 0.3852], Epochs since improvement 2
 43%|████▎     | 217/500 [3:29:53<4:22:24, 55.64s/it] 44%|████▎     | 218/500 [3:31:01<4:39:45, 59.52s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -4.45E+05, Train scatter: [0.1313 0.0404 0.2115 0.4007]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1341 0.04   0.2136 0.3914], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1287 0.0394 0.2092 0.3899], Epochs since improvement 4
 44%|████▍     | 219/500 [3:31:47<4:19:22, 55.38s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -4.75E+05, Train scatter: [0.1277 0.0377 0.2112 0.3896]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1305 0.0374 0.213  0.3813], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1305 0.0394 0.213  0.3849], Epochs since improvement 6
 44%|████▍     | 220/500 [3:33:03<4:46:57, 61.49s/it] 44%|████▍     | 221/500 [3:33:48<4:23:49, 56.74s/it] 44%|████▍     | 222/500 [3:34:58<4:39:59, 60.43s/it]Epoch: 222 done with learning rate 7.33E-03, Train loss: -4.11E+05, Train scatter: [0.124  0.0386 0.2082 0.3918]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1265 0.0381 0.2101 0.3824], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1287 0.0381 0.213  0.3824], Epochs since improvement 8
 45%|████▍     | 223/500 [3:35:43<4:18:23, 55.97s/it] 45%|████▍     | 224/500 [3:36:53<4:36:41, 60.15s/it]Epoch: 224 done with learning rate 7.26E-03, Train loss: -2.55E+05, Train scatter: [0.3832 0.0671 0.3621 0.4897]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3738 0.0668 0.3649 0.4832], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1305 0.04   0.2136 0.3914], Epochs since improvement 10
 45%|████▌     | 225/500 [3:37:39<4:15:54, 55.84s/it] 45%|████▌     | 226/500 [3:38:48<4:33:08, 59.81s/it]Epoch: 226 done with learning rate 7.20E-03, Train loss: -3.76E+05, Train scatter: [0.1757 0.0441 0.2445 0.4454]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1695 0.0434 0.2441 0.4367], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1341 0.04   0.2136 0.3914], Epochs since improvement 12
 45%|████▌     | 227/500 [3:39:34<4:12:53, 55.58s/it] 46%|████▌     | 228/500 [3:40:42<4:29:13, 59.39s/it]Epoch: 228 done with learning rate 7.13E-03, Train loss: -4.15E+05, Train scatter: [0.152  0.0418 0.2416 0.429 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1487 0.0412 0.2408 0.4204], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1487 0.0412 0.2408 0.4204], Epochs since improvement 14
 46%|████▌     | 229/500 [3:41:27<4:09:31, 55.25s/it]Epoch: 230 done with learning rate 7.06E-03, Train loss: -4.22E+05, Train scatter: [0.2329 0.0512 0.3029 0.4531]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2349 0.0521 0.3033 0.453 ], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1695 0.0434 0.2441 0.4367], Epochs since improvement 16
 46%|████▌     | 230/500 [3:42:44<4:36:48, 61.51s/it] 46%|████▌     | 231/500 [3:43:29<4:14:42, 56.81s/it] 46%|████▋     | 232/500 [3:44:39<4:31:30, 60.79s/it]Epoch: 232 done with learning rate 6.99E-03, Train loss: -4.43E+05, Train scatter: [0.1425 0.0399 0.2187 0.4128]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1362 0.0392 0.22   0.4037], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1695 0.0434 0.2441 0.4367], Epochs since improvement 18
 47%|████▋     | 233/500 [3:45:25<4:10:41, 56.33s/it] 47%|████▋     | 234/500 [3:46:34<4:26:22, 60.08s/it]Epoch: 234 done with learning rate 6.93E-03, Train loss: -4.55E+05, Train scatter: [0.1321 0.0399 0.2126 0.412 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1271 0.0393 0.2161 0.4037], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1487 0.0412 0.2408 0.4204], Epochs since improvement 20
 47%|████▋     | 235/500 [3:47:20<4:06:25, 55.80s/it] 47%|████▋     | 235/500 [3:48:30<4:17:40, 58.34s/it]
Epoch: 236 done with learning rate 6.86E-03, Train loss: -4.63E+05, Train scatter: [0.1342 0.0391 0.2186 0.4088]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1315 0.0384 0.2213 0.3993], Lowest was [0.1164 0.0362 0.2043 0.3768]
Median for last 10 epochs: [0.1362 0.0393 0.2213 0.4037], Epochs since improvement 22
Exited after 236 epochs due to early stopping
13710.27 seconds spent training, 27.421 seconds per epoch. Processed 2540 trees per second
[0.13151892 0.03844481 0.22130318 0.3992914 ]
{'epoch_exit': 235, 'scatter_m_star': 0.13151892, 'lowest_m_star': 0.11640404, 'last20_m_star': 0.13510354, 'last10_m_star': 0.13615364, 'scatter_v_disk': 0.038444806, 'lowest_v_disk': 0.036158543, 'last20_v_disk': 0.039688513, 'last10_v_disk': 0.039346214, 'scatter_m_cold': 0.22130318, 'lowest_m_cold': 0.20426305, 'last20_m_cold': 0.22067137, 'last10_m_cold': 0.22130983, 'scatter_sfr_100': 0.3992914, 'lowest_sfr_100': 0.3767751, 'last20_sfr_100': 0.40368253, 'last10_sfr_100': 0.4036834}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_ztdsmd
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:40<5:35:43, 40.37s/it]  0%|          | 2/500 [01:42<7:20:21, 53.05s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.08E+07, Train scatter: [0.9352 0.1715 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1684 0.5355 0.9851], Lowest was [0.9196 0.1684 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1684 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:21<6:28:27, 46.90s/it]  1%|          | 4/500 [03:23<7:15:08, 52.64s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.32E+07, Train scatter: [0.9352 0.1615 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1581 0.5355 0.9851], Lowest was [0.9196 0.1581 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1581 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:03<6:35:45, 47.97s/it]  1%|          | 6/500 [05:04<7:13:47, 52.69s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.86E+07, Train scatter: [0.9351 0.1372 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1341 0.5355 0.9851], Lowest was [0.9196 0.1341 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1341 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [05:44<6:37:56, 48.43s/it]  2%|▏         | 8/500 [06:46<7:12:37, 52.76s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.49E+07, Train scatter: [0.933  0.1128 0.5441 0.9515]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9176 0.1119 0.5355 0.9449], Lowest was [0.9176 0.1119 0.5355 0.9449]
Median for last 10 epochs: [0.9186 0.123  0.5355 0.965 ], Epochs since improvement 0
  2%|▏         | 9/500 [07:26<6:38:07, 48.65s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 1.14E+07, Train scatter: [0.7699 0.1046 0.5441 0.6612]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7619 0.1046 0.5355 0.6584], Lowest was [0.7619 0.1046 0.5355 0.6584]
Median for last 10 epochs: [0.9176 0.1119 0.5355 0.9449], Epochs since improvement 0
  2%|▏         | 10/500 [08:34<7:27:23, 54.78s/it]  2%|▏         | 11/500 [09:14<6:48:36, 50.14s/it]  2%|▏         | 12/500 [10:15<7:15:28, 53.54s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.37E+06, Train scatter: [0.6779 0.098  0.544  0.6121]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.67   0.0988 0.5355 0.61  ], Lowest was [0.67   0.0988 0.5355 0.61  ]
Median for last 10 epochs: [0.9176 0.1119 0.5355 0.9449], Epochs since improvement 0
  3%|▎         | 13/500 [10:55<6:40:30, 49.34s/it]  3%|▎         | 14/500 [11:58<7:13:17, 53.49s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.76E+06, Train scatter: [0.6264 0.092  0.544  0.5968]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6179 0.0919 0.5354 0.5934], Lowest was [0.6179 0.0919 0.5354 0.5934]
Median for last 10 epochs: [0.7619 0.1046 0.5355 0.6584], Epochs since improvement 0
  3%|▎         | 15/500 [12:38<6:38:51, 49.34s/it]  3%|▎         | 16/500 [13:40<7:10:02, 53.31s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.17E+06, Train scatter: [0.4964 0.0906 0.544  0.5619]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4906 0.0903 0.5354 0.5605], Lowest was [0.4906 0.0903 0.5354 0.5605]
Median for last 10 epochs: [0.67   0.0988 0.5355 0.61  ], Epochs since improvement 0
  3%|▎         | 17/500 [14:20<6:36:07, 49.21s/it]  4%|▎         | 18/500 [15:22<7:07:06, 53.17s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 8.28E+06, Train scatter: [0.8194 0.1232 0.5441 0.6978]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8047 0.1206 0.5355 0.6907], Lowest was [0.4906 0.0903 0.5354 0.5605]
Median for last 10 epochs: [0.67   0.0988 0.5355 0.61  ], Epochs since improvement 2
  4%|▍         | 19/500 [16:02<6:33:51, 49.13s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.18E+06, Train scatter: [0.4839 0.0904 0.5441 0.5775]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4842 0.0889 0.5355 0.5767], Lowest was [0.4842 0.0889 0.5354 0.5605]
Median for last 10 epochs: [0.6179 0.0919 0.5355 0.5934], Epochs since improvement 0
  4%|▍         | 20/500 [17:11<7:21:37, 55.20s/it]  4%|▍         | 21/500 [17:51<6:43:08, 50.50s/it]  4%|▍         | 22/500 [18:53<7:10:17, 54.01s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.75E+06, Train scatter: [0.3337 0.0848 0.544  0.5487]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3404 0.0851 0.5354 0.5465], Lowest was [0.3404 0.0851 0.5354 0.5465]
Median for last 10 epochs: [0.4906 0.0903 0.5354 0.5767], Epochs since improvement 0
  5%|▍         | 23/500 [19:33<6:35:04, 49.70s/it]  5%|▍         | 24/500 [20:34<7:02:46, 53.29s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.51E+06, Train scatter: [0.3233 0.0813 0.5439 0.5424]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3361 0.0819 0.5353 0.545 ], Lowest was [0.3361 0.0819 0.5353 0.545 ]
Median for last 10 epochs: [0.4842 0.0889 0.5354 0.5605], Epochs since improvement 0
  5%|▌         | 25/500 [21:14<6:29:39, 49.22s/it]  5%|▌         | 26/500 [22:16<6:58:05, 52.92s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.44E+06, Train scatter: [0.3905 0.0811 0.5439 0.5594]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4064 0.0813 0.5353 0.5651], Lowest was [0.3361 0.0813 0.5353 0.545 ]
Median for last 10 epochs: [0.4064 0.0851 0.5354 0.5651], Epochs since improvement 0
  5%|▌         | 27/500 [22:55<6:25:37, 48.92s/it]  6%|▌         | 28/500 [23:58<6:56:59, 53.01s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.14E+06, Train scatter: [0.384  0.083  0.544  0.5794]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3924 0.0833 0.5354 0.5835], Lowest was [0.3361 0.0813 0.5353 0.545 ]
Median for last 10 epochs: [0.3924 0.0833 0.5354 0.5651], Epochs since improvement 2
  6%|▌         | 29/500 [24:37<6:24:15, 48.95s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.89E+06, Train scatter: [0.2418 0.0825 0.5439 0.5225]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2507 0.0824 0.5353 0.52  ], Lowest was [0.2507 0.0813 0.5353 0.52  ]
Median for last 10 epochs: [0.3404 0.0824 0.5353 0.5465], Epochs since improvement 0
  6%|▌         | 30/500 [25:46<7:09:01, 54.77s/it]  6%|▌         | 31/500 [26:25<6:33:08, 50.30s/it]  6%|▋         | 32/500 [27:28<7:01:15, 54.01s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.96E+06, Train scatter: [0.2448 0.079  0.5439 0.5227]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3052 0.0791 0.5353 0.5156], Lowest was [0.2507 0.0791 0.5353 0.5156]
Median for last 10 epochs: [0.3361 0.0819 0.5353 0.545 ], Epochs since improvement 0
  7%|▋         | 33/500 [28:08<6:27:09, 49.74s/it]  7%|▋         | 34/500 [29:10<6:55:04, 53.44s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.83E+06, Train scatter: [0.2373 0.0797 0.5438 0.523 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.262  0.0795 0.5352 0.5165], Lowest was [0.2507 0.0791 0.5352 0.5156]
Median for last 10 epochs: [0.3052 0.0813 0.5353 0.52  ], Epochs since improvement 0
  7%|▋         | 35/500 [29:50<6:22:22, 49.34s/it]  7%|▋         | 36/500 [30:52<6:51:47, 53.25s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.78E+06, Train scatter: [0.2796 0.0749 0.5437 0.5224]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2951 0.0751 0.5351 0.5231], Lowest was [0.2507 0.0751 0.5351 0.5156]
Median for last 10 epochs: [0.2951 0.0795 0.5353 0.52  ], Epochs since improvement 0
  7%|▋         | 37/500 [31:32<6:19:51, 49.23s/it]  8%|▊         | 38/500 [32:34<6:47:39, 52.94s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.76E+06, Train scatter: [0.2191 0.0718 0.5436 0.5029]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2224 0.0718 0.5351 0.5005], Lowest was [0.2224 0.0718 0.5351 0.5005]
Median for last 10 epochs: [0.262  0.0791 0.5352 0.5165], Epochs since improvement 0
  8%|▊         | 39/500 [33:13<6:16:36, 49.02s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.79E+06, Train scatter: [0.2124 0.0739 0.5436 0.5099]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2643 0.0732 0.535  0.5075], Lowest was [0.2224 0.0718 0.535  0.5005]
Median for last 10 epochs: [0.2643 0.0751 0.5351 0.5156], Epochs since improvement 0
  8%|▊         | 40/500 [34:22<7:01:46, 55.01s/it]  8%|▊         | 41/500 [35:02<6:25:48, 50.43s/it]  8%|▊         | 42/500 [36:04<6:52:07, 53.99s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.81E+06, Train scatter: [0.2102 0.0736 0.5435 0.8696]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2907 0.0736 0.5349 0.8626], Lowest was [0.2224 0.0718 0.5349 0.5005]
Median for last 10 epochs: [0.2643 0.0736 0.5351 0.5165], Epochs since improvement 0
  9%|▊         | 43/500 [36:44<6:18:41, 49.72s/it]  9%|▉         | 44/500 [37:46<6:45:16, 53.32s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.73E+06, Train scatter: [0.2139 0.0697 0.5434 0.5034]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3113 0.0692 0.5349 0.5012], Lowest was [0.2224 0.0692 0.5349 0.5005]
Median for last 10 epochs: [0.2907 0.0732 0.535  0.5075], Epochs since improvement 0
  9%|▉         | 45/500 [38:26<6:13:27, 49.25s/it]  9%|▉         | 46/500 [39:29<6:43:33, 53.33s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.70E+06, Train scatter: [0.225  0.0755 0.5435 0.5115]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2599 0.0754 0.5349 0.512 ], Lowest was [0.2224 0.0692 0.5349 0.5005]
Median for last 10 epochs: [0.2643 0.0732 0.5349 0.5075], Epochs since improvement 2
  9%|▉         | 47/500 [40:08<6:11:48, 49.25s/it] 10%|▉         | 48/500 [41:12<6:43:03, 53.50s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.79E+06, Train scatter: [0.2344 0.0833 0.5433 0.5312]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4182 0.0814 0.5348 0.5266], Lowest was [0.2224 0.0692 0.5348 0.5005]
Median for last 10 epochs: [0.2907 0.0736 0.5349 0.512 ], Epochs since improvement 0
 10%|▉         | 49/500 [41:51<6:11:20, 49.40s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.81E+06, Train scatter: [0.5206 0.0965 0.5435 0.578 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5241 0.0948 0.535  0.5721], Lowest was [0.2224 0.0692 0.5348 0.5005]
Median for last 10 epochs: [0.3113 0.0754 0.5349 0.5266], Epochs since improvement 2
 10%|█         | 50/500 [43:00<6:53:51, 55.18s/it] 10%|█         | 51/500 [43:40<6:18:28, 50.58s/it] 10%|█         | 52/500 [44:43<6:45:06, 54.25s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.58E+06, Train scatter: [0.4604 0.0817 0.5435 0.5302]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4472 0.0805 0.5349 0.5253], Lowest was [0.2224 0.0692 0.5348 0.5005]
Median for last 10 epochs: [0.4182 0.0805 0.5349 0.5253], Epochs since improvement 4
 11%|█         | 53/500 [45:23<6:11:46, 49.90s/it] 11%|█         | 54/500 [46:25<6:39:23, 53.73s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.54E+06, Train scatter: [0.3218 0.0793 0.5434 0.528 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3259 0.0788 0.5348 0.5243], Lowest was [0.2224 0.0692 0.5348 0.5005]
Median for last 10 epochs: [0.4182 0.0805 0.5349 0.5253], Epochs since improvement 6
 11%|█         | 55/500 [47:05<6:07:27, 49.55s/it] 11%|█         | 56/500 [48:08<6:35:57, 53.51s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.52E+06, Train scatter: [0.3553 0.0807 0.5434 0.6419]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3469 0.0792 0.5349 0.6391], Lowest was [0.2224 0.0692 0.5348 0.5005]
Median for last 10 epochs: [0.4182 0.0805 0.5349 0.5266], Epochs since improvement 8
 11%|█▏        | 57/500 [48:48<6:04:38, 49.39s/it] 12%|█▏        | 58/500 [49:50<6:32:51, 53.33s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.49E+06, Train scatter: [0.3989 0.0813 0.5433 0.5342]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.39   0.0803 0.5347 0.5324], Lowest was [0.2224 0.0692 0.5347 0.5005]
Median for last 10 epochs: [0.39   0.0803 0.5349 0.5324], Epochs since improvement 0
 12%|█▏        | 59/500 [50:30<6:01:56, 49.24s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.52E+06, Train scatter: [0.451  0.1054 0.5433 0.5536]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4397 0.1043 0.5347 0.5478], Lowest was [0.2224 0.0692 0.5347 0.5005]
Median for last 10 epochs: [0.39   0.0803 0.5348 0.5324], Epochs since improvement 2
 12%|█▏        | 60/500 [51:38<6:41:49, 54.79s/it] 12%|█▏        | 61/500 [52:17<6:07:58, 50.29s/it] 12%|█▏        | 62/500 [53:20<6:34:06, 53.99s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.49E+06, Train scatter: [0.4    0.0751 0.543  0.4937]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3925 0.0745 0.5345 0.4896], Lowest was [0.2224 0.0692 0.5345 0.4896]
Median for last 10 epochs: [0.39   0.0792 0.5347 0.5324], Epochs since improvement 0
 13%|█▎        | 63/500 [54:00<6:02:03, 49.71s/it] 13%|█▎        | 64/500 [55:01<6:27:33, 53.33s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.46E+06, Train scatter: [0.3587 0.0775 0.5431 0.5045]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3505 0.077  0.5345 0.5033], Lowest was [0.2224 0.0692 0.5345 0.4896]
Median for last 10 epochs: [0.39   0.0792 0.5347 0.5324], Epochs since improvement 2
 13%|█▎        | 65/500 [55:41<5:57:08, 49.26s/it] 13%|█▎        | 66/500 [56:42<6:21:49, 52.79s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.49E+06, Train scatter: [0.4917 0.0738 0.5428 0.4894]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4818 0.0733 0.5342 0.4859], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.3925 0.077  0.5345 0.5033], Epochs since improvement 0
 13%|█▎        | 67/500 [57:22<5:52:53, 48.90s/it] 14%|█▎        | 68/500 [58:23<6:18:51, 52.62s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.45E+06, Train scatter: [0.3787 0.0763 0.5428 0.5012]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3682 0.0755 0.5342 0.4983], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.3925 0.0755 0.5345 0.4983], Epochs since improvement 2
 14%|█▍        | 69/500 [59:03<5:50:30, 48.80s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.48E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.3925 0.0755 0.5345 0.4983], Epochs since improvement 4
 14%|█▍        | 70/500 [1:00:11<6:31:05, 54.57s/it] 14%|█▍        | 71/500 [1:00:51<5:58:34, 50.15s/it] 14%|█▍        | 72/500 [1:01:52<6:21:33, 53.49s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 9.25E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.4818 0.077  0.5345 0.5033], Epochs since improvement 6
 15%|█▍        | 73/500 [1:02:32<5:51:16, 49.36s/it] 15%|█▍        | 74/500 [1:03:34<6:18:00, 53.24s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 7.32E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 8
 15%|█▌        | 75/500 [1:04:14<5:48:44, 49.23s/it] 15%|█▌        | 76/500 [1:05:15<6:13:08, 52.80s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 6.11E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 10
 15%|█▌        | 77/500 [1:05:55<5:44:32, 48.87s/it] 16%|█▌        | 78/500 [1:06:58<6:12:41, 52.99s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 5.23E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 12
 16%|█▌        | 79/500 [1:07:37<5:43:50, 49.00s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 4.62E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 14
 16%|█▌        | 80/500 [1:08:46<6:24:11, 54.88s/it] 16%|█▌        | 81/500 [1:09:26<5:51:33, 50.34s/it] 16%|█▋        | 82/500 [1:10:27<6:13:47, 53.65s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 4.16E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 16
 17%|█▋        | 83/500 [1:11:07<5:43:34, 49.44s/it] 17%|█▋        | 84/500 [1:12:08<6:07:56, 53.07s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 3.81E+06, Train scatter: [0.9352 0.1728 0.544  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5354 0.985 ], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 18
 17%|█▋        | 85/500 [1:12:48<5:39:32, 49.09s/it] 17%|█▋        | 86/500 [1:13:49<6:03:57, 52.75s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 3.54E+06, Train scatter: [0.9352 0.1728 0.544  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5354 0.985 ], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 20
 17%|█▋        | 87/500 [1:14:29<5:36:01, 48.82s/it] 17%|█▋        | 87/500 [1:15:31<5:58:30, 52.08s/it]
Epoch: 88 done with learning rate 9.98E-03, Train loss: 3.32E+06, Train scatter: [0.9352 0.1728 0.544  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5354 0.985 ], Lowest was [0.2224 0.0692 0.5342 0.4859]
Median for last 10 epochs: [0.9196 0.169  0.5354 0.985 ], Epochs since improvement 22
Exited after 88 epochs due to early stopping
4531.31 seconds spent training, 9.063 seconds per epoch. Processed 7684 trees per second
[0.91955763 0.1689792  0.53538007 0.98499185]
{'epoch_exit': 87, 'scatter_m_star': 0.91955763, 'lowest_m_star': 0.22243871, 'last20_m_star': 0.919585, 'last10_m_star': 0.9195845, 'scatter_v_disk': 0.1689792, 'lowest_v_disk': 0.069166765, 'last20_v_disk': 0.168984, 'last10_v_disk': 0.16898367, 'scatter_m_cold': 0.53538007, 'lowest_m_cold': 0.534189, 'last20_m_cold': 0.5354942, 'last10_m_cold': 0.53544676, 'scatter_sfr_100': 0.98499185, 'lowest_sfr_100': 0.48585853, 'last20_sfr_100': 0.985031, 'last10_sfr_100': 0.98502624}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_saicdt
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:00<8:20:27, 60.18s/it]  0%|          | 2/500 [02:27<10:32:30, 76.21s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.34E+07, Train scatter: [0.9351 0.1289 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1247 0.5355 0.9851], Lowest was [0.9195 0.1247 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1247 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:27<9:29:31, 68.76s/it]   1%|          | 4/500 [04:56<10:34:50, 76.80s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.35E+07, Train scatter: [0.9308 0.1035 0.5429 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9149 0.1046 0.5343 0.9851], Lowest was [0.9149 0.1046 0.5343 0.9851]
Median for last 10 epochs: [0.9149 0.1046 0.5343 0.9851], Epochs since improvement 0
  1%|          | 5/500 [05:56<9:43:34, 70.74s/it]   1%|          | 6/500 [07:25<10:31:57, 76.76s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.02E+08, Train scatter: [0.9352 0.1629 0.5423 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1575 0.5336 0.985 ], Lowest was [0.9149 0.1046 0.5336 0.985 ]
Median for last 10 epochs: [0.9149 0.1046 0.5336 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [08:24<9:45:14, 71.23s/it]   2%|▏         | 8/500 [09:53<10:28:26, 76.64s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.11E+07, Train scatter: [0.7478 0.1063 0.449  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7309 0.1042 0.4388 0.985 ], Lowest was [0.7309 0.1042 0.4388 0.985 ]
Median for last 10 epochs: [0.8229 0.1044 0.4862 0.985 ], Epochs since improvement 0
  2%|▏         | 9/500 [10:52<9:44:12, 71.39s/it] Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.60E+07, Train scatter: [0.5462 0.0977 0.4042 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5491 0.0983 0.4017 0.985 ], Lowest was [0.5491 0.0983 0.4017 0.985 ]
Median for last 10 epochs: [0.7309 0.1042 0.4388 0.985 ], Epochs since improvement 0
  2%|▏         | 10/500 [12:28<10:42:46, 78.71s/it]  2%|▏         | 11/500 [13:28<9:55:00, 73.01s/it]   2%|▏         | 12/500 [14:56<10:31:51, 77.69s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.45E+07, Train scatter: [0.4803 0.0928 0.3731 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4923 0.0949 0.372  0.985 ], Lowest was [0.4923 0.0949 0.372  0.985 ]
Median for last 10 epochs: [0.7309 0.1042 0.4388 0.985 ], Epochs since improvement 0
  3%|▎         | 13/500 [15:56<9:47:30, 72.38s/it]   3%|▎         | 14/500 [17:24<10:24:15, 77.07s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.34E+07, Train scatter: [0.446  0.0879 0.3556 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4629 0.091  0.3579 0.985 ], Lowest was [0.4629 0.091  0.3579 0.985 ]
Median for last 10 epochs: [0.5491 0.0983 0.4017 0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [18:24<9:41:35, 71.95s/it]   3%|▎         | 16/500 [19:52<10:18:57, 76.73s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.84E+07, Train scatter: [0.4403 0.0844 0.343  0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4483 0.0871 0.3477 0.985 ], Lowest was [0.4483 0.0871 0.3477 0.985 ]
Median for last 10 epochs: [0.4923 0.0949 0.372  0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [20:52<9:37:19, 71.72s/it]   4%|▎         | 18/500 [22:21<10:17:32, 76.87s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 2.15E+07, Train scatter: [0.3511 0.0791 0.3287 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3688 0.0811 0.336  0.9848], Lowest was [0.3688 0.0811 0.336  0.9848]
Median for last 10 epochs: [0.4629 0.091  0.3579 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [23:21<9:35:53, 71.84s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 1.03E+07, Train scatter: [0.432  0.0841 0.3628 0.669 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.432  0.0843 0.3641 0.6682], Lowest was [0.3688 0.0811 0.336  0.6682]
Median for last 10 epochs: [0.4483 0.0871 0.3579 0.985 ], Epochs since improvement 0
  4%|▍         | 20/500 [24:56<10:31:09, 78.89s/it]  4%|▍         | 21/500 [25:57<9:44:58, 73.28s/it]   4%|▍         | 22/500 [27:25<10:20:15, 77.86s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.59E+06, Train scatter: [0.3321 0.0828 0.3441 0.6148]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3399 0.0825 0.3505 0.6217], Lowest was [0.3399 0.0811 0.336  0.6217]
Median for last 10 epochs: [0.432  0.0843 0.3505 0.9848], Epochs since improvement 0
  5%|▍         | 23/500 [28:25<9:36:19, 72.49s/it]   5%|▍         | 24/500 [29:53<10:11:17, 77.05s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.67E+06, Train scatter: [0.2559 0.0754 0.3182 0.5141]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2626 0.0758 0.3247 0.5171], Lowest was [0.2626 0.0758 0.3247 0.5171]
Median for last 10 epochs: [0.3688 0.0825 0.3477 0.6682], Epochs since improvement 0
  5%|▌         | 25/500 [30:53<9:29:45, 71.97s/it]   5%|▌         | 26/500 [32:22<10:08:29, 77.02s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.35E+06, Train scatter: [0.2574 0.0749 0.3293 0.5258]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2647 0.0744 0.3287 0.5231], Lowest was [0.2626 0.0744 0.3247 0.5171]
Median for last 10 epochs: [0.3399 0.0811 0.336  0.6217], Epochs since improvement 0
  5%|▌         | 27/500 [33:22<9:27:36, 72.00s/it]   6%|▌         | 28/500 [34:50<10:05:07, 76.92s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.15E+06, Train scatter: [0.3549 0.0779 0.3313 0.5242]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3675 0.0776 0.3391 0.5336], Lowest was [0.2626 0.0744 0.3247 0.5171]
Median for last 10 epochs: [0.3399 0.0776 0.3391 0.5336], Epochs since improvement 2
  6%|▌         | 29/500 [35:50<9:23:56, 71.84s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.02E+06, Train scatter: [0.2405 0.0705 0.3135 0.4799]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2496 0.0698 0.316  0.4792], Lowest was [0.2496 0.0698 0.316  0.4792]
Median for last 10 epochs: [0.2647 0.0758 0.3287 0.5231], Epochs since improvement 0
  6%|▌         | 30/500 [37:26<10:18:10, 78.92s/it]  6%|▌         | 31/500 [38:26<9:32:39, 73.26s/it]   6%|▋         | 32/500 [39:55<10:07:30, 77.89s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.96E+06, Train scatter: [0.2833 0.0706 0.3098 0.4855]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2841 0.0717 0.3188 0.4945], Lowest was [0.2496 0.0698 0.316  0.4792]
Median for last 10 epochs: [0.2647 0.0744 0.3247 0.5171], Epochs since improvement 2
  7%|▋         | 33/500 [40:55<9:24:54, 72.58s/it]   7%|▋         | 34/500 [42:23<9:59:20, 77.17s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.72E+06, Train scatter: [0.2705 0.0696 0.3193 0.5113]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.278  0.07   0.3264 0.516 ], Lowest was [0.2496 0.0698 0.316  0.4792]
Median for last 10 epochs: [0.278  0.0717 0.3264 0.516 ], Epochs since improvement 4
  7%|▋         | 35/500 [43:23<9:18:32, 72.07s/it]  7%|▋         | 36/500 [44:51<9:55:48, 77.05s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.67E+06, Train scatter: [0.2761 0.0685 0.3247 0.4898]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2834 0.0684 0.3288 0.4865], Lowest was [0.2496 0.0684 0.316  0.4792]
Median for last 10 epochs: [0.2834 0.07   0.3264 0.4945], Epochs since improvement 0
  7%|▋         | 37/500 [45:52<9:15:37, 72.00s/it]  8%|▊         | 38/500 [47:21<9:53:32, 77.08s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.59E+06, Train scatter: [0.25   0.0656 0.3069 0.4678]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2636 0.0664 0.3081 0.4693], Lowest was [0.2496 0.0664 0.3081 0.4693]
Median for last 10 epochs: [0.278  0.0698 0.3188 0.4865], Epochs since improvement 0
  8%|▊         | 39/500 [48:21<9:13:11, 72.00s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.58E+06, Train scatter: [0.2814 0.0653 0.3042 0.483 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2803 0.0645 0.3053 0.4821], Lowest was [0.2496 0.0645 0.3053 0.4693]
Median for last 10 epochs: [0.2803 0.0684 0.3188 0.4865], Epochs since improvement 0
  8%|▊         | 40/500 [49:56<10:05:21, 78.96s/it]  8%|▊         | 41/500 [50:56<9:20:51, 73.31s/it]   8%|▊         | 42/500 [52:24<9:53:41, 77.78s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.49E+06, Train scatter: [0.2935 0.0641 0.2961 0.4755]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2946 0.0636 0.3022 0.4784], Lowest was [0.2496 0.0636 0.3022 0.4693]
Median for last 10 epochs: [0.2803 0.0664 0.3081 0.4821], Epochs since improvement 0
  9%|▊         | 43/500 [53:24<9:11:55, 72.46s/it]  9%|▉         | 44/500 [54:52<9:46:00, 77.11s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.40E+06, Train scatter: [0.2755 0.0622 0.2894 0.4672]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.288  0.062  0.2905 0.4695], Lowest was [0.2496 0.062  0.2905 0.4693]
Median for last 10 epochs: [0.2834 0.0645 0.3053 0.4784], Epochs since improvement 0
  9%|▉         | 45/500 [55:52<9:06:08, 72.02s/it]  9%|▉         | 46/500 [57:21<9:41:58, 76.91s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.31E+06, Train scatter: [0.2967 0.0646 0.2868 0.4603]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2974 0.0644 0.2926 0.4605], Lowest was [0.2496 0.062  0.2905 0.4605]
Median for last 10 epochs: [0.288  0.0644 0.3022 0.4695], Epochs since improvement 0
  9%|▉         | 47/500 [58:21<9:02:31, 71.86s/it] 10%|▉         | 48/500 [59:49<9:37:03, 76.60s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.26E+06, Train scatter: [0.2498 0.0662 0.3521 0.4566]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2598 0.066  0.3426 0.4573], Lowest was [0.2496 0.062  0.2905 0.4573]
Median for last 10 epochs: [0.288  0.0644 0.3022 0.4695], Epochs since improvement 0
 10%|▉         | 49/500 [1:00:49<8:58:37, 71.66s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.95E+06, Train scatter: [0.3248 0.0663 0.2873 0.4615]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.324  0.066  0.2924 0.4654], Lowest was [0.2496 0.062  0.2905 0.4573]
Median for last 10 epochs: [0.2946 0.0644 0.2926 0.4654], Epochs since improvement 2
 10%|█         | 50/500 [1:02:24<9:50:58, 78.80s/it] 10%|█         | 51/500 [1:03:24<9:07:56, 73.22s/it] 10%|█         | 52/500 [1:04:53<9:41:50, 77.92s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.89E+06, Train scatter: [0.2567 0.06   0.2831 0.4536]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2555 0.0626 0.2874 0.451 ], Lowest was [0.2496 0.062  0.2874 0.451 ]
Median for last 10 epochs: [0.288  0.0644 0.2924 0.4605], Epochs since improvement 0
 11%|█         | 53/500 [1:05:53<9:00:34, 72.56s/it] 11%|█         | 54/500 [1:07:21<9:33:37, 77.17s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.58E+06, Train scatter: [0.3185 0.0933 0.3873 0.5398]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.32   0.0916 0.3865 0.5388], Lowest was [0.2496 0.062  0.2874 0.451 ]
Median for last 10 epochs: [0.2974 0.066  0.2926 0.4605], Epochs since improvement 2
 11%|█         | 55/500 [1:08:21<8:54:15, 72.03s/it] 11%|█         | 56/500 [1:09:50<9:30:23, 77.08s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.26E+06, Train scatter: [0.46   0.079  0.359  0.4976]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4542 0.0781 0.3576 0.4964], Lowest was [0.2496 0.062  0.2874 0.451 ]
Median for last 10 epochs: [0.32   0.066  0.3426 0.4654], Epochs since improvement 4
 11%|█▏        | 57/500 [1:10:50<8:51:34, 72.00s/it] 12%|█▏        | 58/500 [1:12:18<9:25:48, 76.81s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.04E+06, Train scatter: [0.3798 0.0707 0.3451 0.4792]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3769 0.0716 0.3469 0.4776], Lowest was [0.2496 0.062  0.2874 0.451 ]
Median for last 10 epochs: [0.324  0.0716 0.3469 0.4776], Epochs since improvement 6
 12%|█▏        | 59/500 [1:13:18<8:47:40, 71.79s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.92E+06, Train scatter: [0.3186 0.0759 0.3574 0.4903]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.312  0.0757 0.3595 0.4904], Lowest was [0.2496 0.062  0.2874 0.451 ]
Median for last 10 epochs: [0.32   0.0757 0.3576 0.4904], Epochs since improvement 8
 12%|█▏        | 60/500 [1:14:54<9:38:19, 78.86s/it] 12%|█▏        | 61/500 [1:15:54<8:56:06, 73.27s/it] 12%|█▏        | 62/500 [1:17:22<9:27:07, 77.69s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.81E+06, Train scatter: [0.3474 0.0632 0.3329 0.4766]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3414 0.063  0.3354 0.4759], Lowest was [0.2496 0.062  0.2874 0.451 ]
Median for last 10 epochs: [0.3414 0.0757 0.3576 0.4904], Epochs since improvement 10
 13%|█▎        | 63/500 [1:18:22<8:47:14, 72.39s/it] 13%|█▎        | 64/500 [1:19:50<9:20:27, 77.13s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.77E+06, Train scatter: [0.3002 0.0681 0.3406 0.4727]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.318  0.0694 0.3477 0.4728], Lowest was [0.2496 0.062  0.2874 0.451 ]
Median for last 10 epochs: [0.3414 0.0716 0.3477 0.4776], Epochs since improvement 12
 13%|█▎        | 65/500 [1:20:50<8:41:54, 71.99s/it] 13%|█▎        | 66/500 [1:22:19<9:18:06, 77.16s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.43E+06, Train scatter: [0.3688 0.065  0.3274 0.4542]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3601 0.0674 0.3325 0.451 ], Lowest was [0.2496 0.062  0.2874 0.451 ]
Median for last 10 epochs: [0.3414 0.0694 0.3469 0.4759], Epochs since improvement 14
 13%|█▎        | 67/500 [1:23:19<8:39:28, 71.98s/it] 14%|█▎        | 68/500 [1:24:47<9:12:21, 76.72s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.39E+06, Train scatter: [0.353  0.0629 0.323  0.4636]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3416 0.0618 0.3235 0.4639], Lowest was [0.2496 0.0618 0.2874 0.451 ]
Median for last 10 epochs: [0.3414 0.0674 0.3354 0.4728], Epochs since improvement 0
 14%|█▍        | 69/500 [1:25:47<8:35:18, 71.74s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.18E+06, Train scatter: [0.2481 0.0557 0.3121 0.4413]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2603 0.0574 0.3167 0.4407], Lowest was [0.2496 0.0574 0.2874 0.4407]
Median for last 10 epochs: [0.3414 0.063  0.3325 0.4639], Epochs since improvement 0
 14%|█▍        | 70/500 [1:27:24<9:27:25, 79.18s/it] 14%|█▍        | 71/500 [1:28:24<8:45:19, 73.47s/it] 14%|█▍        | 72/500 [1:29:53<9:17:34, 78.16s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.13E+06, Train scatter: [0.2464 0.0564 0.3163 0.44  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2662 0.0595 0.3235 0.4408], Lowest was [0.2496 0.0574 0.2874 0.4407]
Median for last 10 epochs: [0.318  0.0618 0.3235 0.451 ], Epochs since improvement 2
 15%|█▍        | 73/500 [1:30:53<8:37:41, 72.74s/it] 15%|█▍        | 74/500 [1:32:22<9:10:37, 77.55s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 1.05E+06, Train scatter: [0.402  0.06   0.3236 0.4479]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3916 0.0609 0.3229 0.4459], Lowest was [0.2496 0.0574 0.2874 0.4407]
Median for last 10 epochs: [0.3416 0.0609 0.3235 0.4459], Epochs since improvement 4
 15%|█▌        | 75/500 [1:33:22<8:32:15, 72.32s/it] 15%|█▌        | 76/500 [1:34:50<9:04:04, 76.99s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 9.90E+05, Train scatter: [0.2163 0.0628 0.3274 0.4438]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2461 0.066  0.3359 0.4451], Lowest was [0.2461 0.0574 0.2874 0.4407]
Median for last 10 epochs: [0.2662 0.0609 0.3235 0.4451], Epochs since improvement 0
 15%|█▌        | 77/500 [1:35:50<8:27:22, 71.97s/it] 16%|█▌        | 78/500 [1:37:18<9:00:44, 76.88s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 9.11E+05, Train scatter: [0.2905 0.0559 0.3169 0.4366]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3095 0.0564 0.3207 0.4404], Lowest was [0.2461 0.0564 0.2874 0.4404]
Median for last 10 epochs: [0.2662 0.0595 0.3229 0.4408], Epochs since improvement 0
 16%|█▌        | 79/500 [1:38:18<8:24:00, 71.83s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 8.14E+05, Train scatter: [0.2049 0.0519 0.2991 0.4284]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2085 0.0527 0.3024 0.4337], Lowest was [0.2085 0.0527 0.2874 0.4337]
Median for last 10 epochs: [0.2662 0.0595 0.3229 0.4408], Epochs since improvement 0
 16%|█▌        | 80/500 [1:39:54<9:13:24, 79.06s/it] 16%|█▌        | 81/500 [1:40:55<8:32:32, 73.40s/it] 16%|█▋        | 82/500 [1:42:23<9:03:14, 77.98s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 6.77E+05, Train scatter: [0.2047 0.0529 0.2968 0.4244]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2643 0.0522 0.2967 0.4233], Lowest was [0.2085 0.0522 0.2874 0.4233]
Median for last 10 epochs: [0.2643 0.0564 0.3207 0.4404], Epochs since improvement 0
 17%|█▋        | 83/500 [1:43:23<8:24:26, 72.58s/it] 17%|█▋        | 84/500 [1:44:51<8:54:52, 77.14s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 5.53E+05, Train scatter: [0.3688 0.0528 0.2788 0.4233]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4805 0.0526 0.2806 0.4198], Lowest was [0.2085 0.0522 0.2806 0.4198]
Median for last 10 epochs: [0.2643 0.0527 0.3024 0.4337], Epochs since improvement 0
 17%|█▋        | 85/500 [1:45:51<8:18:34, 72.08s/it] 17%|█▋        | 86/500 [1:47:20<8:51:00, 76.96s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 4.16E+05, Train scatter: [0.1758 0.0484 0.2727 0.4083]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3883 0.049  0.2773 0.4075], Lowest was [0.2085 0.049  0.2773 0.4075]
Median for last 10 epochs: [0.3095 0.0526 0.2967 0.4233], Epochs since improvement 0
 17%|█▋        | 87/500 [1:48:20<8:15:09, 71.94s/it] 18%|█▊        | 88/500 [1:49:48<8:46:40, 76.70s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 1.58E+06, Train scatter: [0.8706 0.1521 0.5404 0.959 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8562 0.1488 0.5319 0.949 ], Lowest was [0.2085 0.049  0.2773 0.4075]
Median for last 10 epochs: [0.3883 0.0526 0.2967 0.4233], Epochs since improvement 2
 18%|█▊        | 89/500 [1:50:48<8:11:16, 71.72s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 1.98E+05, Train scatter: [0.5496 0.0893 0.4716 0.5059]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5253 0.087  0.4753 0.4988], Lowest was [0.2085 0.049  0.2773 0.4075]
Median for last 10 epochs: [0.4805 0.0526 0.2967 0.4233], Epochs since improvement 4
 18%|█▊        | 90/500 [1:52:23<8:58:08, 78.75s/it] 18%|█▊        | 91/500 [1:53:23<8:18:43, 73.16s/it] 18%|█▊        | 92/500 [1:54:51<8:48:17, 77.69s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: -4.08E+04, Train scatter: [0.2671 0.0593 0.3111 0.46  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2742 0.0622 0.3186 0.4604], Lowest was [0.2085 0.049  0.2773 0.4075]
Median for last 10 epochs: [0.4805 0.0622 0.3186 0.4604], Epochs since improvement 6
 19%|█▊        | 93/500 [1:55:51<8:11:04, 72.39s/it] 19%|█▉        | 94/500 [1:57:19<8:41:33, 77.08s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: -1.80E+05, Train scatter: [0.364  0.06   0.2958 0.4503]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3534 0.0602 0.2963 0.4372], Lowest was [0.2085 0.049  0.2773 0.4075]
Median for last 10 epochs: [0.3883 0.0622 0.3186 0.4604], Epochs since improvement 8
 19%|█▉        | 95/500 [1:58:19<8:05:54, 71.99s/it] 19%|█▉        | 96/500 [1:59:48<8:37:26, 76.85s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: -2.36E+05, Train scatter: [0.1774 0.0545 0.269  0.4296]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1899 0.0566 0.2731 0.4272], Lowest was [0.1899 0.049  0.2731 0.4075]
Median for last 10 epochs: [0.3534 0.0622 0.3186 0.4604], Epochs since improvement 0
 19%|█▉        | 97/500 [2:00:48<8:02:22, 71.82s/it] 20%|█▉        | 98/500 [2:02:15<8:31:57, 76.41s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: -2.85E+05, Train scatter: [0.1827 0.0511 0.2678 0.4291]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1909 0.0516 0.2686 0.4239], Lowest was [0.1899 0.049  0.2686 0.4075]
Median for last 10 epochs: [0.2742 0.0602 0.2963 0.4372], Epochs since improvement 0
 20%|█▉        | 99/500 [2:03:15<7:58:11, 71.55s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: -3.18E+05, Train scatter: [0.1749 0.0507 0.2537 0.4324]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1999 0.051  0.2581 0.4272], Lowest was [0.1899 0.049  0.2581 0.4075]
Median for last 10 epochs: [0.1999 0.0566 0.2731 0.4272], Epochs since improvement 0
 20%|██        | 100/500 [2:04:52<8:46:56, 79.04s/it] 20%|██        | 101/500 [2:05:52<8:07:46, 73.35s/it] 20%|██        | 102/500 [2:07:21<8:38:02, 78.10s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: -3.33E+05, Train scatter: [0.1861 0.0507 0.2553 0.4309]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1964 0.0499 0.2567 0.4253], Lowest was [0.1899 0.049  0.2567 0.4075]
Median for last 10 epochs: [0.1964 0.0516 0.2686 0.4272], Epochs since improvement 0
 21%|██        | 103/500 [2:08:21<8:01:15, 72.74s/it] 21%|██        | 104/500 [2:09:49<8:31:03, 77.43s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: -3.32E+05, Train scatter: [0.1568 0.0464 0.2403 0.4204]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2044 0.0464 0.2426 0.411 ], Lowest was [0.1899 0.0464 0.2426 0.4075]
Median for last 10 epochs: [0.1964 0.051  0.2581 0.4253], Epochs since improvement 0
 21%|██        | 105/500 [2:10:49<7:55:26, 72.22s/it] 21%|██        | 106/500 [2:12:18<8:25:25, 76.97s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: -3.56E+05, Train scatter: [0.3374 0.0649 0.2779 0.4615]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3285 0.0647 0.2807 0.4575], Lowest was [0.1899 0.0464 0.2426 0.4075]
Median for last 10 epochs: [0.1999 0.051  0.2581 0.4253], Epochs since improvement 2
 21%|██▏       | 107/500 [2:13:18<7:50:48, 71.88s/it] 22%|██▏       | 108/500 [2:14:46<8:22:20, 76.89s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: -3.70E+05, Train scatter: [0.1937 0.0472 0.2524 0.4336]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1875 0.0475 0.2557 0.4271], Lowest was [0.1875 0.0464 0.2426 0.4075]
Median for last 10 epochs: [0.1999 0.0499 0.2567 0.4271], Epochs since improvement 0
 22%|██▏       | 109/500 [2:15:46<7:48:07, 71.83s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: -3.46E+05, Train scatter: [0.3631 0.0455 0.2562 0.4191]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3558 0.0455 0.2571 0.4098], Lowest was [0.1875 0.0455 0.2426 0.4075]
Median for last 10 epochs: [0.2044 0.0475 0.2567 0.4253], Epochs since improvement 0
 22%|██▏       | 110/500 [2:17:22<8:34:24, 79.14s/it] 22%|██▏       | 111/500 [2:18:22<7:56:10, 73.44s/it] 22%|██▏       | 112/500 [2:19:51<8:23:39, 77.89s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: -3.78E+05, Train scatter: [0.3647 0.0433 0.2282 0.4158]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3547 0.0434 0.2327 0.4052], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.3285 0.0464 0.2557 0.411 ], Epochs since improvement 0
 23%|██▎       | 113/500 [2:20:51<7:47:40, 72.51s/it] 23%|██▎       | 114/500 [2:22:19<8:16:53, 77.24s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 4.93E+04, Train scatter: [0.9066 0.1601 0.5425 0.9546]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.89   0.1562 0.534  0.9436], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.3547 0.0475 0.2571 0.4271], Epochs since improvement 2
 23%|██▎       | 115/500 [2:23:19<7:42:20, 72.05s/it] 23%|██▎       | 116/500 [2:24:48<8:13:24, 77.10s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: -7.86E+04, Train scatter: [0.911  0.1136 0.5405 0.6733]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8957 0.1114 0.532  0.6675], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.3558 0.0475 0.2571 0.4271], Epochs since improvement 4
 23%|██▎       | 117/500 [2:25:48<7:39:39, 72.01s/it] 24%|██▎       | 118/500 [2:27:17<8:10:30, 77.04s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: -1.68E+05, Train scatter: [0.5332 0.0883 0.4674 0.5818]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5146 0.0866 0.4589 0.5736], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.5146 0.0866 0.4589 0.5736], Epochs since improvement 6
 24%|██▍       | 119/500 [2:28:17<7:36:51, 71.95s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: -2.23E+05, Train scatter: [0.4384 0.0735 0.4582 0.5403]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.422  0.0727 0.4471 0.5346], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.5146 0.0866 0.4589 0.5736], Epochs since improvement 8
 24%|██▍       | 120/500 [2:29:52<8:19:43, 78.90s/it] 24%|██▍       | 121/500 [2:30:52<7:42:56, 73.29s/it] 24%|██▍       | 122/500 [2:32:21<8:10:16, 77.82s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: -1.16E+05, Train scatter: [0.8194 0.1055 0.5461 0.7007]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.807  0.1039 0.5374 0.6931], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.807  0.1039 0.532  0.6675], Epochs since improvement 10
 25%|██▍       | 123/500 [2:33:20<7:35:17, 72.46s/it] 25%|██▍       | 124/500 [2:34:48<8:03:10, 77.10s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: -1.90E+05, Train scatter: [0.5242 0.0882 0.4677 0.592 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5305 0.0875 0.4625 0.5868], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.5305 0.0875 0.4625 0.5868], Epochs since improvement 12
 25%|██▌       | 125/500 [2:35:48<7:29:30, 71.92s/it] 25%|██▌       | 126/500 [2:37:17<7:59:26, 76.92s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: -2.33E+05, Train scatter: [0.5913 0.0672 0.3879 0.5154]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6044 0.0669 0.3828 0.5097], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.5305 0.0866 0.4589 0.5736], Epochs since improvement 14
 25%|██▌       | 127/500 [2:38:17<7:26:37, 71.84s/it] 26%|██▌       | 128/500 [2:39:46<7:57:52, 77.08s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -2.87E+05, Train scatter: [0.3934 0.0618 0.3889 0.4986]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3732 0.0617 0.3788 0.4908], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.5305 0.0727 0.4471 0.5346], Epochs since improvement 16
 26%|██▌       | 129/500 [2:40:46<7:24:50, 71.94s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -1.60E+05, Train scatter: [0.6077 0.0833 0.4419 0.5379]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5895 0.0817 0.4335 0.5298], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.5895 0.0817 0.4335 0.5298], Epochs since improvement 18
 26%|██▌       | 130/500 [2:42:23<8:09:06, 79.32s/it] 26%|██▌       | 131/500 [2:43:23<7:32:43, 73.61s/it] 26%|██▋       | 132/500 [2:44:51<7:58:58, 78.09s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -3.01E+05, Train scatter: [0.3519 0.0572 0.3545 0.4894]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.342  0.0565 0.3508 0.4841], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.5305 0.0669 0.3828 0.5097], Epochs since improvement 20
 27%|██▋       | 133/500 [2:45:52<7:24:51, 72.73s/it] 27%|██▋       | 133/500 [2:47:21<7:41:47, 75.50s/it]
Epoch: 134 done with learning rate 9.53E-03, Train loss: -3.29E+05, Train scatter: [0.4029 0.05   0.2867 0.4708]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3887 0.0491 0.2851 0.4654], Lowest was [0.1875 0.0434 0.2327 0.4052]
Median for last 10 epochs: [0.3887 0.0617 0.3788 0.4908], Epochs since improvement 22
Exited after 134 epochs due to early stopping
10041.13 seconds spent training, 20.082 seconds per epoch. Processed 3468 trees per second
[0.38870484 0.04912777 0.2851031  0.46540767]
{'epoch_exit': 133, 'scatter_m_star': 0.38870484, 'lowest_m_star': 0.18750903, 'last20_m_star': 0.52254486, 'last10_m_star': 0.3887174, 'scatter_v_disk': 0.04912777, 'lowest_v_disk': 0.04344977, 'last20_v_disk': 0.07719077, 'last10_v_disk': 0.061729193, 'scatter_m_cold': 0.2851031, 'lowest_m_cold': 0.23271984, 'last20_m_cold': 0.44030353, 'last10_m_cold': 0.37877285, 'scatter_sfr_100': 0.46540767, 'lowest_sfr_100': 0.4051943, 'last20_sfr_100': 0.5321903, 'last10_sfr_100': 0.4908432}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_efbjsw
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:22:41, 53.23s/it]  0%|          | 2/500 [02:12<9:28:22, 68.48s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.1699 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1646 0.5355 0.985 ], Lowest was [0.9196 0.1646 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1646 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:05<8:27:20, 61.25s/it]  1%|          | 4/500 [04:24<9:26:55, 68.58s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 9.05E+07, Train scatter: [0.9352 0.144  0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1395 0.5355 0.9851], Lowest was [0.9196 0.1395 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1395 0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:17<8:38:26, 62.84s/it]  1%|          | 6/500 [06:37<9:24:55, 68.61s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.59E+07, Train scatter: [0.9349 0.1193 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9193 0.1172 0.5355 0.9851], Lowest was [0.9193 0.1172 0.5355 0.985 ]
Median for last 10 epochs: [0.9193 0.1172 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:30<8:41:04, 63.42s/it]  2%|▏         | 8/500 [08:49<9:22:15, 68.57s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.31E+07, Train scatter: [0.9345 0.1045 0.5439 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9189 0.1034 0.5353 0.9851], Lowest was [0.9189 0.1034 0.5353 0.985 ]
Median for last 10 epochs: [0.9191 0.1103 0.5354 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [09:42<8:40:27, 63.60s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.13E+07, Train scatter: [0.8664 0.096  0.5425 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8539 0.0956 0.534  0.9851], Lowest was [0.8539 0.0956 0.534  0.985 ]
Median for last 10 epochs: [0.9189 0.1034 0.5353 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:08<9:35:11, 70.43s/it]  2%|▏         | 11/500 [12:00<8:49:26, 64.96s/it]  2%|▏         | 12/500 [13:20<9:25:08, 69.48s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.00E+07, Train scatter: [0.6358 0.0911 0.5359 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6284 0.0914 0.5279 0.9851], Lowest was [0.6284 0.0914 0.5279 0.985 ]
Median for last 10 epochs: [0.9189 0.1034 0.5353 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:13<8:42:38, 64.39s/it]  3%|▎         | 14/500 [15:33<9:19:29, 69.07s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.92E+07, Train scatter: [0.5483 0.088  0.5314 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5353 0.0884 0.5238 0.985 ], Lowest was [0.5353 0.0884 0.5238 0.985 ]
Median for last 10 epochs: [0.8539 0.0956 0.534  0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [16:25<8:38:20, 64.12s/it]  3%|▎         | 16/500 [17:46<9:16:44, 69.02s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.81E+07, Train scatter: [0.5047 0.0855 0.5302 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5087 0.0859 0.5227 0.985 ], Lowest was [0.5087 0.0859 0.5227 0.985 ]
Median for last 10 epochs: [0.6284 0.0914 0.5279 0.9851], Epochs since improvement 0
  3%|▎         | 17/500 [18:38<8:36:00, 64.10s/it]  4%|▎         | 18/500 [19:58<9:13:06, 68.85s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.74E+07, Train scatter: [0.4618 0.0854 0.5353 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4571 0.0858 0.5271 0.9849], Lowest was [0.4571 0.0858 0.5227 0.9849]
Median for last 10 epochs: [0.5353 0.0884 0.5271 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [20:51<8:32:58, 63.99s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.73E+07, Train scatter: [0.9248 0.1548 0.544  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9086 0.1485 0.5354 0.985 ], Lowest was [0.4571 0.0858 0.5227 0.9849]
Median for last 10 epochs: [0.5353 0.0884 0.5271 0.985 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:17<9:26:01, 70.75s/it]  4%|▍         | 21/500 [23:10<8:41:19, 65.30s/it]  4%|▍         | 22/500 [24:29<9:14:09, 69.56s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.70E+07, Train scatter: [0.893  0.0912 0.543  0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8788 0.0909 0.5345 0.9849], Lowest was [0.4571 0.0858 0.5227 0.9849]
Median for last 10 epochs: [0.5353 0.0884 0.5271 0.985 ], Epochs since improvement 0
  5%|▍         | 23/500 [25:22<8:32:37, 64.48s/it]  5%|▍         | 24/500 [26:42<9:07:27, 69.01s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.62E+07, Train scatter: [0.4972 0.0846 0.5415 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5011 0.0847 0.533  0.9849], Lowest was [0.4571 0.0847 0.5227 0.9849]
Median for last 10 epochs: [0.5087 0.0859 0.533  0.9849], Epochs since improvement 0
  5%|▌         | 25/500 [27:34<8:27:34, 64.11s/it]  5%|▌         | 26/500 [28:54<9:04:10, 68.88s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.52E+07, Train scatter: [0.615  0.0934 0.4289 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5981 0.0927 0.4225 0.9849], Lowest was [0.4571 0.0847 0.4225 0.9849]
Median for last 10 epochs: [0.5981 0.0909 0.533  0.9849], Epochs since improvement 0
  5%|▌         | 27/500 [29:47<8:24:39, 64.02s/it]  6%|▌         | 28/500 [31:07<9:00:50, 68.75s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.41E+07, Train scatter: [0.5299 0.0937 0.3573 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5478 0.0962 0.3592 0.985 ], Lowest was [0.4571 0.0847 0.3592 0.9849]
Median for last 10 epochs: [0.5981 0.0927 0.533  0.9849], Epochs since improvement 0
  6%|▌         | 29/500 [31:59<8:21:59, 63.95s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.33E+07, Train scatter: [0.5767 0.0891 0.3458 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6039 0.0915 0.3535 0.985 ], Lowest was [0.4571 0.0847 0.3535 0.9849]
Median for last 10 epochs: [0.5981 0.0915 0.4225 0.9849], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [33:26<9:12:54, 70.58s/it]  6%|▌         | 31/500 [34:19<8:30:35, 65.32s/it]  6%|▋         | 32/500 [35:38<9:02:52, 69.60s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.30E+07, Train scatter: [0.6931 0.084  0.3445 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6989 0.0866 0.348  0.985 ], Lowest was [0.4571 0.0847 0.348  0.9849]
Median for last 10 epochs: [0.5981 0.0915 0.3592 0.985 ], Epochs since improvement 0
  7%|▋         | 33/500 [36:31<8:22:25, 64.55s/it]  7%|▋         | 34/500 [37:50<8:55:56, 69.01s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.25E+07, Train scatter: [0.4445 0.0856 0.3294 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4642 0.0889 0.3386 0.9851], Lowest was [0.4571 0.0847 0.3386 0.9849]
Median for last 10 epochs: [0.5981 0.0915 0.3535 0.985 ], Epochs since improvement 0
  7%|▋         | 35/500 [38:43<8:17:00, 64.13s/it]  7%|▋         | 36/500 [40:03<8:53:31, 68.99s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 9.12E+07, Train scatter: [0.8979 0.1708 0.5418 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.885  0.1671 0.5335 0.985 ], Lowest was [0.4571 0.0847 0.3386 0.9849]
Median for last 10 epochs: [0.6039 0.0915 0.3535 0.985 ], Epochs since improvement 2
  7%|▋         | 37/500 [40:56<8:14:40, 64.11s/it]  8%|▊         | 38/500 [42:16<8:49:09, 68.72s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 7.21E+07, Train scatter: [0.7244 0.1552 0.5217 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7329 0.1529 0.5156 0.985 ], Lowest was [0.4571 0.0847 0.3386 0.9849]
Median for last 10 epochs: [0.6989 0.0915 0.3535 0.985 ], Epochs since improvement 4
  8%|▊         | 39/500 [43:08<8:11:10, 63.93s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.09E+07, Train scatter: [0.6161 0.1266 0.5249 0.9946]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6108 0.125  0.519  0.9843], Lowest was [0.4571 0.0847 0.3386 0.9843]
Median for last 10 epochs: [0.6989 0.125  0.5156 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [44:35<9:02:21, 70.74s/it]  8%|▊         | 41/500 [45:28<8:20:06, 65.37s/it]  8%|▊         | 42/500 [46:48<8:52:34, 69.77s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.14E+07, Train scatter: [0.431  0.1047 0.4478 0.6769]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4315 0.1034 0.4479 0.6728], Lowest was [0.4315 0.0847 0.3386 0.6728]
Median for last 10 epochs: [0.6108 0.125  0.5156 0.985 ], Epochs since improvement 0
  9%|▊         | 43/500 [47:41<8:12:53, 64.71s/it]  9%|▉         | 44/500 [49:00<8:45:44, 69.18s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 7.23E+06, Train scatter: [0.3784 0.0939 0.4177 0.611 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.379  0.0936 0.4176 0.6081], Lowest was [0.379  0.0847 0.3386 0.6081]
Median for last 10 epochs: [0.6108 0.125  0.5156 0.9843], Epochs since improvement 0
  9%|▉         | 45/500 [49:53<8:07:11, 64.25s/it]  9%|▉         | 46/500 [51:13<8:41:07, 68.87s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 6.98E+06, Train scatter: [0.3938 0.0922 0.4146 0.6178]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3921 0.0921 0.4141 0.6174], Lowest was [0.379  0.0847 0.3386 0.6081]
Median for last 10 epochs: [0.4315 0.1034 0.4479 0.6728], Epochs since improvement 2
  9%|▉         | 47/500 [52:06<8:03:38, 64.06s/it] 10%|▉         | 48/500 [53:27<8:40:38, 69.11s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 5.89E+06, Train scatter: [0.3682 0.0884 0.3888 0.5818]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.362  0.0878 0.389  0.5785], Lowest was [0.362  0.0847 0.3386 0.5785]
Median for last 10 epochs: [0.3921 0.0936 0.4176 0.6174], Epochs since improvement 0
 10%|▉         | 49/500 [54:19<8:02:46, 64.23s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 5.39E+06, Train scatter: [0.3455 0.0834 0.3712 0.559 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3498 0.0835 0.372  0.5579], Lowest was [0.3498 0.0835 0.3386 0.5579]
Median for last 10 epochs: [0.379  0.0921 0.4141 0.6081], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [55:46<8:51:44, 70.90s/it] 10%|█         | 51/500 [56:39<8:10:16, 65.51s/it] 10%|█         | 52/500 [57:58<8:40:37, 69.73s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 5.35E+06, Train scatter: [0.316  0.0824 0.3676 0.5503]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3178 0.0827 0.3729 0.553 ], Lowest was [0.3178 0.0827 0.3386 0.553 ]
Median for last 10 epochs: [0.362  0.0878 0.389  0.5785], Epochs since improvement 0
 11%|█         | 53/500 [58:51<8:01:39, 64.65s/it] 11%|█         | 54/500 [1:00:11<8:33:25, 69.07s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 4.87E+06, Train scatter: [0.3217 0.0808 0.3591 0.5482]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3245 0.0825 0.3655 0.5467], Lowest was [0.3178 0.0825 0.3386 0.5467]
Median for last 10 epochs: [0.3498 0.0835 0.3729 0.5579], Epochs since improvement 0
 11%|█         | 55/500 [1:01:03<7:56:13, 64.21s/it] 11%|█         | 56/500 [1:02:23<8:28:42, 68.75s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.55E+06, Train scatter: [0.3357 0.0764 0.344  0.5309]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3454 0.0773 0.3495 0.5319], Lowest was [0.3178 0.0773 0.3386 0.5319]
Median for last 10 epochs: [0.3454 0.0827 0.372  0.553 ], Epochs since improvement 0
 11%|█▏        | 57/500 [1:03:16<7:52:13, 63.96s/it] 12%|█▏        | 58/500 [1:04:35<8:26:03, 68.70s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 4.46E+06, Train scatter: [0.303  0.0767 0.3438 0.5313]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.317  0.0789 0.3498 0.5325], Lowest was [0.317  0.0773 0.3386 0.5319]
Median for last 10 epochs: [0.3245 0.0825 0.3655 0.5467], Epochs since improvement 0
 12%|█▏        | 59/500 [1:05:28<7:49:59, 63.94s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 4.24E+06, Train scatter: [0.2981 0.0883 0.3512 0.5463]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3109 0.0907 0.3588 0.5534], Lowest was [0.3109 0.0773 0.3386 0.5319]
Median for last 10 epochs: [0.3178 0.0825 0.3588 0.5467], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:06:55<8:40:27, 70.97s/it] 12%|█▏        | 61/500 [1:07:48<7:59:32, 65.54s/it] 12%|█▏        | 62/500 [1:09:08<8:28:34, 69.67s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 4.01E+06, Train scatter: [0.2807 0.0737 0.3308 0.5104]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2939 0.0754 0.3367 0.512 ], Lowest was [0.2939 0.0754 0.3367 0.512 ]
Median for last 10 epochs: [0.317  0.0789 0.3498 0.5325], Epochs since improvement 0
 13%|█▎        | 63/500 [1:10:00<7:50:30, 64.60s/it] 13%|█▎        | 64/500 [1:11:20<8:22:53, 69.20s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.90E+06, Train scatter: [0.2878 0.0751 0.3368 0.5245]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3086 0.0753 0.3406 0.5226], Lowest was [0.2939 0.0753 0.3367 0.512 ]
Median for last 10 epochs: [0.3109 0.0773 0.3495 0.5319], Epochs since improvement 0
 13%|█▎        | 65/500 [1:12:13<7:46:01, 64.28s/it] 13%|█▎        | 66/500 [1:13:33<8:18:15, 68.88s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.83E+06, Train scatter: [0.2619 0.0723 0.3262 0.5094]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2704 0.0731 0.3312 0.5111], Lowest was [0.2704 0.0731 0.3312 0.5111]
Median for last 10 epochs: [0.3086 0.0754 0.3406 0.5226], Epochs since improvement 0
 13%|█▎        | 67/500 [1:14:25<7:42:04, 64.03s/it] 14%|█▎        | 68/500 [1:15:45<8:14:26, 68.67s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.75E+06, Train scatter: [0.3298 0.0792 0.3337 0.5228]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3266 0.0786 0.3348 0.5223], Lowest was [0.2704 0.0731 0.3312 0.5111]
Median for last 10 epochs: [0.3086 0.0754 0.3367 0.5223], Epochs since improvement 2
 14%|█▍        | 69/500 [1:16:38<7:38:57, 63.89s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.45E+06, Train scatter: [0.2762 0.0716 0.3312 0.506 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2845 0.0722 0.3376 0.5064], Lowest was [0.2704 0.0722 0.3312 0.5064]
Median for last 10 epochs: [0.2939 0.0753 0.3367 0.512 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:18:05<8:27:07, 70.76s/it] 14%|█▍        | 71/500 [1:18:57<7:47:14, 65.35s/it] 14%|█▍        | 72/500 [1:20:17<8:17:20, 69.72s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.53E+06, Train scatter: [0.3031 0.0733 0.3104 0.4978]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3081 0.0745 0.3133 0.4985], Lowest was [0.2704 0.0722 0.3133 0.4985]
Median for last 10 epochs: [0.3081 0.0745 0.3348 0.5111], Epochs since improvement 0
 15%|█▍        | 73/500 [1:21:10<7:39:55, 64.63s/it] 15%|█▍        | 74/500 [1:22:29<8:10:25, 69.07s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.38E+06, Train scatter: [0.2599 0.0679 0.3084 0.4944]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2706 0.0683 0.3143 0.492 ], Lowest was [0.2704 0.0683 0.3133 0.492 ]
Median for last 10 epochs: [0.2845 0.0731 0.3312 0.5064], Epochs since improvement 0
 15%|█▌        | 75/500 [1:23:22<7:34:30, 64.17s/it] 15%|█▌        | 76/500 [1:24:42<8:06:12, 68.80s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.37E+06, Train scatter: [0.255  0.0757 0.3051 0.5266]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2615 0.0762 0.3122 0.5297], Lowest was [0.2615 0.0683 0.3122 0.492 ]
Median for last 10 epochs: [0.2845 0.0745 0.3143 0.5064], Epochs since improvement 0
 15%|█▌        | 77/500 [1:25:34<7:30:51, 63.95s/it] 16%|█▌        | 78/500 [1:26:53<8:01:45, 68.50s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.14E+06, Train scatter: [0.2412 0.0662 0.3004 0.4924]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2457 0.0666 0.3069 0.4951], Lowest was [0.2457 0.0666 0.3069 0.492 ]
Median for last 10 epochs: [0.2706 0.0722 0.3133 0.4985], Epochs since improvement 0
 16%|█▌        | 79/500 [1:27:46<7:27:18, 63.75s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.99E+06, Train scatter: [0.2963 0.0683 0.3085 0.4917]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2925 0.0689 0.3125 0.4939], Lowest was [0.2457 0.0666 0.3069 0.492 ]
Median for last 10 epochs: [0.2706 0.0689 0.3125 0.4951], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:29:14<8:16:11, 70.88s/it] 16%|█▌        | 81/500 [1:30:06<7:36:52, 65.42s/it] 16%|█▋        | 82/500 [1:31:25<8:04:20, 69.52s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.84E+06, Train scatter: [0.2386 0.0647 0.2897 0.483 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.248  0.0654 0.298  0.482 ], Lowest was [0.2457 0.0654 0.298  0.482 ]
Median for last 10 epochs: [0.2615 0.0683 0.3122 0.4939], Epochs since improvement 0
 17%|█▋        | 83/500 [1:32:18<7:28:06, 64.48s/it] 17%|█▋        | 84/500 [1:33:38<7:58:38, 69.03s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.72E+06, Train scatter: [0.2974 0.0726 0.3358 0.5511]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2987 0.0728 0.3426 0.5554], Lowest was [0.2457 0.0654 0.298  0.482 ]
Median for last 10 epochs: [0.2615 0.0689 0.3122 0.4951], Epochs since improvement 2
 17%|█▋        | 85/500 [1:34:30<7:23:33, 64.13s/it] 17%|█▋        | 86/500 [1:35:50<7:54:04, 68.71s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.77E+06, Train scatter: [0.2412 0.0686 0.2979 0.4799]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2477 0.0693 0.3037 0.4802], Lowest was [0.2457 0.0654 0.298  0.4802]
Median for last 10 epochs: [0.248  0.0689 0.3069 0.4939], Epochs since improvement 0
 17%|█▋        | 87/500 [1:36:42<7:19:44, 63.89s/it] 18%|█▊        | 88/500 [1:38:02<7:49:59, 68.45s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.54E+06, Train scatter: [0.2695 0.0718 0.3114 0.5046]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2751 0.0718 0.3178 0.5058], Lowest was [0.2457 0.0654 0.298  0.4802]
Median for last 10 epochs: [0.2751 0.0693 0.3125 0.4939], Epochs since improvement 2
 18%|█▊        | 89/500 [1:38:54<7:16:18, 63.69s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.47E+06, Train scatter: [0.2415 0.0629 0.2912 0.4756]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2417 0.0637 0.2966 0.4757], Lowest was [0.2417 0.0637 0.2966 0.4757]
Median for last 10 epochs: [0.248  0.0693 0.3037 0.482 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:40:21<8:02:41, 70.64s/it] 18%|█▊        | 91/500 [1:41:14<7:24:52, 65.26s/it] 18%|█▊        | 92/500 [1:42:34<7:54:18, 69.75s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.39E+06, Train scatter: [0.2467 0.0668 0.2871 0.4908]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2504 0.0659 0.2903 0.4898], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.2504 0.0693 0.3037 0.4898], Epochs since improvement 0
 19%|█▊        | 93/500 [1:43:27<7:18:18, 64.62s/it] 19%|█▉        | 94/500 [1:44:45<7:45:44, 68.83s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 1.06E+07, Train scatter: [0.6948 0.1271 0.5296 0.7304]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6809 0.1247 0.521  0.7232], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.2504 0.0693 0.3037 0.4898], Epochs since improvement 2
 19%|█▉        | 95/500 [1:45:38<7:11:48, 63.97s/it] 19%|█▉        | 96/500 [1:46:58<7:44:16, 68.95s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 6.07E+06, Train scatter: [0.5334 0.1114 0.5267 0.6676]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5265 0.1103 0.5189 0.6604], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.2751 0.0718 0.3178 0.5058], Epochs since improvement 4
 19%|█▉        | 97/500 [1:47:51<7:10:14, 64.06s/it] 20%|█▉        | 98/500 [1:49:10<7:39:30, 68.58s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 5.40E+06, Train scatter: [0.5046 0.1046 0.5052 0.6372]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4996 0.1036 0.499  0.6329], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.4996 0.1036 0.499  0.6329], Epochs since improvement 6
 20%|█▉        | 99/500 [1:50:03<7:06:30, 63.82s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 4.42E+06, Train scatter: [0.3855 0.0932 0.5168 0.5914]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3823 0.093  0.5091 0.589 ], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.4996 0.1036 0.5091 0.6329], Epochs since improvement 8
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:51:29<7:50:06, 70.52s/it] 20%|██        | 101/500 [1:52:22<7:13:22, 65.17s/it] 20%|██        | 102/500 [1:53:41<7:40:32, 69.43s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 3.59E+06, Train scatter: [0.3154 0.082  0.5149 0.5475]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3132 0.0815 0.507  0.5425], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.4996 0.1036 0.5091 0.6329], Epochs since improvement 10
 21%|██        | 103/500 [1:54:34<7:06:22, 64.44s/it] 21%|██        | 104/500 [1:55:53<7:34:16, 68.83s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 3.21E+06, Train scatter: [0.3156 0.0819 0.481  0.532 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.32   0.0821 0.4751 0.53  ], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.3823 0.093  0.507  0.589 ], Epochs since improvement 12
 21%|██        | 105/500 [1:56:46<7:01:17, 63.99s/it] 21%|██        | 106/500 [1:58:06<7:31:31, 68.76s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 2.84E+06, Train scatter: [0.2927 0.078  0.3976 0.5256]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.286  0.0771 0.3939 0.52  ], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.32   0.0821 0.499  0.5425], Epochs since improvement 14
 21%|██▏       | 107/500 [1:58:58<6:58:42, 63.92s/it] 22%|██▏       | 108/500 [2:00:18<7:27:52, 68.55s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 2.59E+06, Train scatter: [0.3304 0.0805 0.3875 0.5118]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3305 0.0783 0.3848 0.5094], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.32   0.0815 0.4751 0.53  ], Epochs since improvement 16
 22%|██▏       | 109/500 [2:01:10<6:55:46, 63.80s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 2.47E+06, Train scatter: [0.4531 0.0833 0.4076 0.5565]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4463 0.0837 0.4092 0.5516], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.32   0.0815 0.4092 0.53  ], Epochs since improvement 18
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:02:37<7:39:04, 70.63s/it] 22%|██▏       | 111/500 [2:03:30<7:03:11, 65.27s/it] 22%|██▏       | 112/500 [2:04:49<7:29:13, 69.47s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 2.38E+06, Train scatter: [0.2643 0.0729 0.3777 0.5001]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.261  0.0722 0.3797 0.4953], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.32   0.0783 0.3939 0.52  ], Epochs since improvement 20
 23%|██▎       | 113/500 [2:05:42<6:55:44, 64.46s/it] 23%|██▎       | 113/500 [2:07:01<7:15:03, 67.45s/it]
Epoch: 114 done with learning rate 9.79E-03, Train loss: 2.24E+06, Train scatter: [0.2481 0.0749 0.3703 0.5079]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2497 0.0738 0.3725 0.5072], Lowest was [0.2417 0.0637 0.2903 0.4757]
Median for last 10 epochs: [0.286  0.0771 0.3848 0.5094], Epochs since improvement 22
Exited after 114 epochs due to early stopping
7621.90 seconds spent training, 15.244 seconds per epoch. Processed 4568 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.24971442 0.07383588 0.3724878  0.50713545]
{'epoch_exit': 113, 'scatter_m_star': 0.24971442, 'lowest_m_star': 0.24166718, 'last20_m_star': 0.32524163, 'last10_m_star': 0.28599298, 'scatter_v_disk': 0.07383588, 'lowest_v_disk': 0.06372465, 'last20_v_disk': 0.08175568, 'last10_v_disk': 0.077066876, 'scatter_m_cold': 0.3724878, 'lowest_m_cold': 0.29026636, 'last20_m_cold': 0.44211346, 'last10_m_cold': 0.3847872, 'scatter_sfr_100': 0.50713545, 'lowest_sfr_100': 0.47565076, 'last20_sfr_100': 0.5362396, 'last10_sfr_100': 0.509405}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
