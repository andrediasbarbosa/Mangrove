Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_vyuwmq
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:31<4:25:12, 31.89s/it]  0%|          | 2/500 [01:21<5:48:59, 42.05s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.21E+07, Train scatter: [0.9353 0.1747 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1817 0.5356 0.9851], Lowest was [0.9198 0.1817 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1817 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:52<5:06:50, 37.04s/it]  1%|          | 4/500 [02:41<5:46:42, 41.94s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 7.46E+06, Train scatter: [0.9352 0.1758 0.544  0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1876 0.5354 0.985 ], Lowest was [0.9197 0.1817 0.5354 0.985 ]
Median for last 10 epochs: [0.9197 0.1847 0.5354 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:12<5:14:28, 38.12s/it]  1%|          | 6/500 [04:02<5:46:17, 42.06s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.65E+06, Train scatter: [0.9347 0.1422 0.5428 0.7273]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9191 0.1452 0.5343 0.7232], Lowest was [0.9191 0.1452 0.5343 0.7232]
Median for last 10 epochs: [0.9191 0.1452 0.5343 0.7232], Epochs since improvement 0
  1%|▏         | 7/500 [04:34<5:18:29, 38.76s/it]  2%|▏         | 8/500 [05:24<5:45:57, 42.19s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.82E+06, Train scatter: [0.9249 0.1258 0.5368 0.6696]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9097 0.1269 0.5285 0.6632], Lowest was [0.9097 0.1269 0.5285 0.6632]
Median for last 10 epochs: [0.9144 0.136  0.5314 0.6932], Epochs since improvement 0
  2%|▏         | 9/500 [05:55<5:18:17, 38.89s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.16E+06, Train scatter: [0.759  0.111  0.5219 0.6263]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7435 0.113  0.5143 0.6285], Lowest was [0.7435 0.113  0.5143 0.6285]
Median for last 10 epochs: [0.9097 0.1269 0.5285 0.6632], Epochs since improvement 0
  2%|▏         | 10/500 [06:50<5:57:24, 43.76s/it]  2%|▏         | 11/500 [07:22<5:27:00, 40.12s/it]  2%|▏         | 12/500 [08:12<5:51:52, 43.26s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.51E+06, Train scatter: [0.6865 0.1088 0.4522 0.6724]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6915 0.1113 0.4505 0.6643], Lowest was [0.6915 0.1113 0.4505 0.6285]
Median for last 10 epochs: [0.9097 0.1269 0.5285 0.6643], Epochs since improvement 0
  3%|▎         | 13/500 [08:44<5:22:38, 39.75s/it]  3%|▎         | 14/500 [09:34<5:46:41, 42.80s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.75E+06, Train scatter: [0.5624 0.1054 0.371  0.6119]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.554  0.1109 0.374  0.6234], Lowest was [0.554  0.1109 0.374  0.6234]
Median for last 10 epochs: [0.7435 0.113  0.5143 0.6632], Epochs since improvement 0
  3%|▎         | 15/500 [10:06<5:19:33, 39.53s/it]  3%|▎         | 16/500 [10:56<5:45:12, 42.79s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.27E+06, Train scatter: [0.527  0.1007 0.3568 0.5991]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5275 0.1064 0.3609 0.6036], Lowest was [0.5275 0.1064 0.3609 0.6036]
Median for last 10 epochs: [0.6915 0.1113 0.4505 0.6285], Epochs since improvement 0
  3%|▎         | 17/500 [11:29<5:20:34, 39.82s/it]  4%|▎         | 18/500 [12:19<5:43:55, 42.81s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.06E+06, Train scatter: [0.5542 0.0944 0.3481 0.5981]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5445 0.0984 0.3527 0.6006], Lowest was [0.5275 0.0984 0.3527 0.6006]
Median for last 10 epochs: [0.554  0.1109 0.374  0.6234], Epochs since improvement 0
  4%|▍         | 19/500 [12:51<5:18:16, 39.70s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.91E+05, Train scatter: [0.6145 0.0918 0.3398 0.5914]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5689 0.0964 0.3455 0.5912], Lowest was [0.5275 0.0964 0.3455 0.5912]
Median for last 10 epochs: [0.554  0.1064 0.3609 0.6036], Epochs since improvement 0
  4%|▍         | 20/500 [13:46<5:54:00, 44.25s/it]  4%|▍         | 21/500 [14:19<5:25:31, 40.78s/it]  4%|▍         | 22/500 [15:08<5:45:45, 43.40s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.91E+05, Train scatter: [0.5046 0.0885 0.3244 0.5674]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5049 0.0916 0.3303 0.567 ], Lowest was [0.5049 0.0916 0.3303 0.567 ]
Median for last 10 epochs: [0.5445 0.0984 0.3527 0.6006], Epochs since improvement 0
  5%|▍         | 23/500 [15:41<5:18:53, 40.11s/it]  5%|▍         | 24/500 [16:30<5:39:00, 42.73s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.60E+05, Train scatter: [0.5144 0.0865 0.3348 0.5754]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5072 0.0888 0.3358 0.5749], Lowest was [0.5049 0.0888 0.3303 0.567 ]
Median for last 10 epochs: [0.5275 0.0964 0.3455 0.5912], Epochs since improvement 0
  5%|▌         | 25/500 [17:02<5:13:35, 39.61s/it]  5%|▌         | 26/500 [17:52<5:37:27, 42.72s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 6.72E+05, Train scatter: [0.4715 0.0864 0.3266 0.5426]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4701 0.0901 0.3365 0.5489], Lowest was [0.4701 0.0888 0.3303 0.5489]
Median for last 10 epochs: [0.5072 0.0916 0.3365 0.5749], Epochs since improvement 0
  5%|▌         | 27/500 [18:23<5:09:46, 39.30s/it]  6%|▌         | 28/500 [19:13<5:34:59, 42.58s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 5.29E+05, Train scatter: [0.4676 0.0816 0.3008 0.5271]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4652 0.0837 0.3083 0.5272], Lowest was [0.4652 0.0837 0.3083 0.5272]
Median for last 10 epochs: [0.5049 0.0901 0.3358 0.567 ], Epochs since improvement 0
  6%|▌         | 29/500 [19:45<5:09:15, 39.40s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 5.69E+05, Train scatter: [0.5606 0.0855 0.3175 0.5757]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.541  0.087  0.3143 0.5613], Lowest was [0.4652 0.0837 0.3083 0.5272]
Median for last 10 epochs: [0.5049 0.0888 0.3303 0.5613], Epochs since improvement 2
  6%|▌         | 30/500 [20:39<5:42:14, 43.69s/it]  6%|▌         | 31/500 [21:11<5:13:14, 40.07s/it]  6%|▋         | 32/500 [22:01<5:36:05, 43.09s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 1.19E+06, Train scatter: [0.6471 0.0989 0.3934 0.6375]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6335 0.1001 0.3914 0.6484], Lowest was [0.4652 0.0837 0.3083 0.5272]
Median for last 10 epochs: [0.5072 0.0888 0.3358 0.5613], Epochs since improvement 4
  7%|▋         | 33/500 [22:33<5:10:39, 39.91s/it]  7%|▋         | 34/500 [23:23<5:33:43, 42.97s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.14E+05, Train scatter: [0.5783 0.0945 0.3558 0.6398]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5713 0.0953 0.355  0.6441], Lowest was [0.4652 0.0837 0.3083 0.5272]
Median for last 10 epochs: [0.541  0.0901 0.3365 0.5613], Epochs since improvement 6
  7%|▋         | 35/500 [23:56<5:07:43, 39.71s/it]  7%|▋         | 36/500 [24:46<5:31:35, 42.88s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 4.91E+05, Train scatter: [0.6853 0.0856 0.3205 0.5482]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6873 0.0862 0.3241 0.5423], Lowest was [0.4652 0.0837 0.3083 0.5272]
Median for last 10 epochs: [0.5713 0.087  0.3241 0.5613], Epochs since improvement 8
  7%|▋         | 37/500 [25:19<5:07:16, 39.82s/it]  8%|▊         | 38/500 [26:07<5:27:36, 42.55s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.86E+05, Train scatter: [0.4575 0.0826 0.3607 0.5835]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4541 0.0832 0.3639 0.588 ], Lowest was [0.4541 0.0832 0.3083 0.5272]
Median for last 10 epochs: [0.5713 0.087  0.355  0.588 ], Epochs since improvement 0
  8%|▊         | 39/500 [26:40<5:04:11, 39.59s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: -2.10E+05, Train scatter: [0.3923 0.0747 0.2989 0.5042]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3901 0.0755 0.3082 0.5024], Lowest was [0.3901 0.0755 0.3082 0.5024]
Median for last 10 epochs: [0.5713 0.0862 0.355  0.588 ], Epochs since improvement 0
  8%|▊         | 40/500 [27:34<5:36:13, 43.86s/it]  8%|▊         | 41/500 [28:06<5:08:05, 40.27s/it]  8%|▊         | 42/500 [28:56<5:29:17, 43.14s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.35E+05, Train scatter: [0.4194 0.0719 0.3002 0.4931]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4068 0.0725 0.309  0.4897], Lowest was [0.3901 0.0725 0.3082 0.4897]
Median for last 10 epochs: [0.4541 0.0832 0.3241 0.5423], Epochs since improvement 0
  9%|▊         | 43/500 [29:28<5:04:10, 39.94s/it]  9%|▉         | 44/500 [30:18<5:27:11, 43.05s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.50E+05, Train scatter: [0.4462 0.0694 0.2989 0.4934]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4457 0.0702 0.3095 0.4931], Lowest was [0.3901 0.0702 0.3082 0.4897]
Median for last 10 epochs: [0.4457 0.0755 0.3095 0.5024], Epochs since improvement 0
  9%|▉         | 45/500 [30:50<5:00:37, 39.64s/it]  9%|▉         | 46/500 [31:39<5:21:31, 42.49s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: -2.61E+05, Train scatter: [0.4188 0.0681 0.2968 0.485 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4148 0.0689 0.3056 0.4826], Lowest was [0.3901 0.0689 0.3056 0.4826]
Median for last 10 epochs: [0.4148 0.0725 0.309  0.4931], Epochs since improvement 0
  9%|▉         | 47/500 [32:12<4:59:27, 39.66s/it] 10%|▉         | 48/500 [33:02<5:21:13, 42.64s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: -2.66E+05, Train scatter: [0.4104 0.0666 0.2927 0.4759]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3999 0.067  0.2989 0.476 ], Lowest was [0.3901 0.067  0.2989 0.476 ]
Median for last 10 epochs: [0.4068 0.0702 0.3082 0.4897], Epochs since improvement 0
 10%|▉         | 49/500 [33:34<4:56:23, 39.43s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: -2.62E+05, Train scatter: [0.4215 0.0687 0.308  0.5129]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4142 0.0692 0.311  0.5072], Lowest was [0.3901 0.067  0.2989 0.476 ]
Median for last 10 epochs: [0.4142 0.0692 0.309  0.4897], Epochs since improvement 2
 10%|█         | 50/500 [34:28<5:29:53, 43.98s/it] 10%|█         | 51/500 [35:00<5:01:19, 40.27s/it] 10%|█         | 52/500 [35:49<5:20:21, 42.91s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: -1.87E+05, Train scatter: [0.3643 0.0736 0.4107 0.4926]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3591 0.0739 0.4065 0.4884], Lowest was [0.3591 0.067  0.2989 0.476 ]
Median for last 10 epochs: [0.4142 0.0692 0.3095 0.4884], Epochs since improvement 0
 11%|█         | 53/500 [36:21<4:54:22, 39.51s/it] 11%|█         | 54/500 [37:11<5:18:06, 42.79s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: -2.42E+05, Train scatter: [0.4139 0.0683 0.3195 0.4755]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4116 0.0688 0.3247 0.4756], Lowest was [0.3591 0.067  0.2989 0.4756]
Median for last 10 epochs: [0.4116 0.0689 0.311  0.4826], Epochs since improvement 0
 11%|█         | 55/500 [37:43<4:52:55, 39.50s/it] 11%|█         | 56/500 [38:32<5:13:42, 42.39s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: -2.64E+05, Train scatter: [0.3778 0.0665 0.2988 0.4706]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3738 0.0664 0.3025 0.4709], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.3999 0.0688 0.311  0.476 ], Epochs since improvement 0
 11%|█▏        | 57/500 [39:04<4:50:39, 39.37s/it] 12%|█▏        | 58/500 [39:54<5:13:19, 42.53s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 9.63E+06, Train scatter: [0.9322 0.1726 0.5444 0.9956]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9168 0.1686 0.5356 0.9852], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.4116 0.0692 0.3247 0.4884], Epochs since improvement 2
 12%|█▏        | 59/500 [40:26<4:48:12, 39.21s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.78E+05, Train scatter: [0.8686 0.1248 0.5424 0.7166]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8539 0.1241 0.5343 0.715 ], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.4116 0.0739 0.4065 0.4884], Epochs since improvement 4
 12%|█▏        | 60/500 [41:22<5:24:11, 44.21s/it] 12%|█▏        | 61/500 [41:53<4:55:27, 40.38s/it] 12%|█▏        | 62/500 [42:42<5:14:16, 43.05s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.37E+05, Train scatter: [0.8234 0.1123 0.4961 0.648 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8108 0.1125 0.4949 0.648 ], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.8108 0.1125 0.4949 0.648 ], Epochs since improvement 6
 13%|█▎        | 63/500 [43:14<4:48:05, 39.56s/it] 13%|█▎        | 64/500 [44:03<5:08:27, 42.45s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: -2.09E+04, Train scatter: [0.5686 0.1026 0.4968 0.6464]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5732 0.1035 0.4933 0.6492], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.8108 0.1125 0.4949 0.6492], Epochs since improvement 8
 13%|█▎        | 65/500 [44:35<4:44:55, 39.30s/it] 13%|█▎        | 66/500 [45:25<5:08:15, 42.62s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: -6.62E+04, Train scatter: [0.6183 0.0925 0.4647 0.5918]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6112 0.0932 0.46   0.5909], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.8108 0.1125 0.4949 0.6492], Epochs since improvement 10
 13%|█▎        | 67/500 [45:58<4:45:43, 39.59s/it] 14%|█▎        | 68/500 [46:50<5:11:15, 43.23s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 4.22E+05, Train scatter: [0.9347 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9191 0.169  0.5355 0.985 ], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.8108 0.1125 0.4949 0.6492], Epochs since improvement 12
 14%|█▍        | 69/500 [47:22<4:46:11, 39.84s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.78E+05, Train scatter: [0.9344 0.1728 0.5441 0.9949]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9189 0.169  0.5355 0.9846], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.8108 0.1125 0.4949 0.6492], Epochs since improvement 14
 14%|█▍        | 70/500 [48:18<5:21:22, 44.84s/it] 14%|█▍        | 71/500 [48:50<4:52:31, 40.91s/it] 14%|█▍        | 72/500 [49:38<5:08:25, 43.24s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.71E+05, Train scatter: [0.9339 0.175  0.544  0.9942]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9184 0.171  0.5354 0.9839], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.9184 0.169  0.5354 0.9839], Epochs since improvement 16
 15%|█▍        | 73/500 [50:11<4:45:19, 40.09s/it] 15%|█▍        | 74/500 [51:02<5:06:32, 43.18s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 7.51E+10, Train scatter: [0.9352 0.1728 0.5441 0.9948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.169  0.5355 0.9845], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.9189 0.169  0.5355 0.9845], Epochs since improvement 18
 15%|█▌        | 75/500 [51:34<4:42:10, 39.84s/it] 15%|█▌        | 76/500 [52:24<5:04:17, 43.06s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 1.67E+05, Train scatter: [0.9351 0.1743 0.5441 0.9947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1704 0.5355 0.9844], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.9191 0.169  0.5355 0.9845], Epochs since improvement 20
 15%|█▌        | 77/500 [52:56<4:40:20, 39.77s/it] 15%|█▌        | 77/500 [53:47<4:55:32, 41.92s/it]
Epoch: 78 done with learning rate 1.00E-02, Train loss: 1.30E+05, Train scatter: [0.9351 0.1739 0.5441 0.9948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.17   0.5355 0.9845], Lowest was [0.3591 0.0664 0.2989 0.4709]
Median for last 10 epochs: [0.9195 0.17   0.5355 0.9845], Epochs since improvement 22
Exited after 78 epochs due to early stopping
3229.14 seconds spent training, 6.458 seconds per epoch. Processed 10782 trees per second
[0.9194574  0.17001398 0.5354636  0.984448  ]
{'epoch_exit': 77, 'scatter_m_star': 0.9194574, 'lowest_m_star': 0.35906348, 'last20_m_star': 0.918625, 'last10_m_star': 0.91946524, 'scatter_v_disk': 0.17001398, 'lowest_v_disk': 0.0663683, 'last20_v_disk': 0.1689994, 'last10_v_disk': 0.1700188, 'scatter_m_cold': 0.5354636, 'lowest_m_cold': 0.29892102, 'last20_m_cold': 0.5354502, 'last10_m_cold': 0.5354787, 'scatter_sfr_100': 0.984448, 'lowest_sfr_100': 0.47093758, 'last20_sfr_100': 0.9841771, 'last10_sfr_100': 0.9844574}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_gieblj
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:29<4:02:20, 29.14s/it]  0%|          | 2/500 [01:13<5:18:00, 38.31s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.45E+07, Train scatter: [0.9354 0.179  0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1877 0.5357 0.9851], Lowest was [0.9198 0.1877 0.5357 0.9851]
Median for last 10 epochs: [0.9198 0.1877 0.5357 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:41<4:37:25, 33.49s/it]  1%|          | 4/500 [02:28<5:20:06, 38.72s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.48E+07, Train scatter: [0.9353 0.174  0.5442 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1771 0.5356 0.9851], Lowest was [0.9198 0.1771 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1771 0.5356 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:56<4:46:36, 34.74s/it]  1%|          | 6/500 [03:42<5:17:39, 38.58s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.08E+07, Train scatter: [0.9354 0.1655 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.168  0.5356 0.9851], Lowest was [0.9198 0.168  0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.168  0.5356 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:10<4:48:21, 35.09s/it]  2%|▏         | 8/500 [04:55<5:14:26, 38.35s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 9.21E+06, Train scatter: [0.9353 0.1463 0.5441 0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1456 0.5355 0.9846], Lowest was [0.9197 0.1456 0.5355 0.9846]
Median for last 10 epochs: [0.9198 0.1568 0.5356 0.9848], Epochs since improvement 0
  2%|▏         | 9/500 [05:22<4:46:26, 35.00s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.74E+06, Train scatter: [0.9352 0.1378 0.5441 0.7257]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1365 0.5355 0.7195], Lowest was [0.9197 0.1365 0.5355 0.7195]
Median for last 10 epochs: [0.9197 0.1456 0.5355 0.9846], Epochs since improvement 0
  2%|▏         | 10/500 [06:14<5:26:39, 40.00s/it]  2%|▏         | 11/500 [06:42<4:56:20, 36.36s/it]  2%|▏         | 12/500 [07:28<5:21:00, 39.47s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.84E+06, Train scatter: [0.9345 0.1251 0.544  0.6615]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.919  0.1233 0.5355 0.6529], Lowest was [0.919  0.1233 0.5355 0.6529]
Median for last 10 epochs: [0.9197 0.1456 0.5355 0.9846], Epochs since improvement 0
  3%|▎         | 13/500 [07:56<4:50:20, 35.77s/it]  3%|▎         | 14/500 [08:42<5:15:37, 38.97s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.65E+06, Train scatter: [0.9203 0.1181 0.544  0.6361]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9063 0.1171 0.5354 0.6287], Lowest was [0.9063 0.1171 0.5354 0.6287]
Median for last 10 epochs: [0.9197 0.1365 0.5355 0.7195], Epochs since improvement 0
  3%|▎         | 15/500 [09:10<4:47:57, 35.62s/it]  3%|▎         | 16/500 [09:55<5:10:20, 38.47s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.39E+06, Train scatter: [0.9289 0.1182 0.5433 0.6898]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9137 0.1175 0.5348 0.6771], Lowest was [0.9063 0.1171 0.5348 0.6287]
Median for last 10 epochs: [0.919  0.1233 0.5355 0.6771], Epochs since improvement 0
  3%|▎         | 17/500 [10:22<4:43:03, 35.16s/it]  4%|▎         | 18/500 [11:07<5:06:01, 38.09s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 6.03E+06, Train scatter: [0.668  0.1078 0.5407 0.6365]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6623 0.108  0.5323 0.6293], Lowest was [0.6623 0.108  0.5323 0.6287]
Median for last 10 epochs: [0.9137 0.1175 0.5354 0.6529], Epochs since improvement 0
  4%|▍         | 19/500 [11:35<4:40:32, 34.99s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.77E+06, Train scatter: [0.5233 0.1038 0.5379 0.6115]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5203 0.1039 0.5296 0.6057], Lowest was [0.5203 0.1039 0.5296 0.6057]
Median for last 10 epochs: [0.9063 0.1171 0.5348 0.6293], Epochs since improvement 0
  4%|▍         | 20/500 [12:25<5:16:01, 39.50s/it]  4%|▍         | 21/500 [12:53<4:48:33, 36.14s/it]  4%|▍         | 22/500 [13:39<5:11:05, 39.05s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.52E+06, Train scatter: [0.5183 0.1005 0.5333 0.5895]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5118 0.101  0.5254 0.587 ], Lowest was [0.5118 0.101  0.5254 0.587 ]
Median for last 10 epochs: [0.6623 0.108  0.5323 0.6287], Epochs since improvement 0
  5%|▍         | 23/500 [14:07<4:44:08, 35.74s/it]  5%|▍         | 24/500 [14:53<5:07:36, 38.77s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 5.29E+06, Train scatter: [0.4487 0.0955 0.5284 0.5742]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4474 0.0961 0.5206 0.571 ], Lowest was [0.4474 0.0961 0.5206 0.571 ]
Median for last 10 epochs: [0.5203 0.1039 0.5296 0.6057], Epochs since improvement 0
  5%|▌         | 25/500 [15:21<4:40:40, 35.45s/it]  5%|▌         | 26/500 [16:06<5:03:32, 38.42s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 5.41E+06, Train scatter: [0.5498 0.111  0.5018 0.7863]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5454 0.1108 0.4962 0.7756], Lowest was [0.4474 0.0961 0.4962 0.571 ]
Median for last 10 epochs: [0.5203 0.1039 0.5254 0.6057], Epochs since improvement 0
  5%|▌         | 27/500 [16:34<4:37:21, 35.18s/it]  6%|▌         | 28/500 [17:20<5:02:01, 38.39s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.27E+06, Train scatter: [0.4968 0.1005 0.4492 0.619 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5068 0.1009 0.4439 0.615 ], Lowest was [0.4474 0.0961 0.4439 0.571 ]
Median for last 10 epochs: [0.5118 0.101  0.5206 0.6057], Epochs since improvement 0
  6%|▌         | 29/500 [17:47<4:36:07, 35.17s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.25E+06, Train scatter: [0.514  0.0962 0.3895 0.5941]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5137 0.0987 0.3798 0.5916], Lowest was [0.4474 0.0961 0.3798 0.571 ]
Median for last 10 epochs: [0.5118 0.1009 0.4962 0.5916], Epochs since improvement 0
  6%|▌         | 30/500 [18:39<5:13:49, 40.06s/it]  6%|▌         | 31/500 [19:07<4:44:57, 36.46s/it]  6%|▋         | 32/500 [19:54<5:08:47, 39.59s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.68E+06, Train scatter: [0.5587 0.0932 0.4542 0.5859]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5351 0.0939 0.4523 0.5813], Lowest was [0.4474 0.0939 0.3798 0.571 ]
Median for last 10 epochs: [0.5137 0.0987 0.4523 0.5916], Epochs since improvement 0
  7%|▋         | 33/500 [20:22<4:41:12, 36.13s/it]  7%|▋         | 34/500 [21:09<5:05:26, 39.33s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.46E+06, Train scatter: [0.3898 0.0939 0.431  0.5857]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3951 0.0963 0.4303 0.5823], Lowest was [0.3951 0.0939 0.3798 0.571 ]
Median for last 10 epochs: [0.5137 0.0987 0.4439 0.5916], Epochs since improvement 0
  7%|▋         | 35/500 [21:37<4:39:34, 36.08s/it]  7%|▋         | 36/500 [22:23<5:02:09, 39.07s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.28E+06, Train scatter: [0.5873 0.0964 0.4119 0.6511]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5914 0.0963 0.4078 0.6593], Lowest was [0.3951 0.0939 0.3798 0.571 ]
Median for last 10 epochs: [0.5137 0.0963 0.4303 0.5916], Epochs since improvement 2
  7%|▋         | 37/500 [22:52<4:37:03, 35.90s/it]  8%|▊         | 38/500 [23:38<5:01:19, 39.13s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.83E+06, Train scatter: [0.7177 0.0936 0.3676 0.5845]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7093 0.0937 0.3641 0.5768], Lowest was [0.3951 0.0937 0.3641 0.571 ]
Median for last 10 epochs: [0.5351 0.0963 0.4078 0.5823], Epochs since improvement 0
  8%|▊         | 39/500 [24:06<4:34:05, 35.67s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.35E+06, Train scatter: [0.3812 0.0925 0.3575 0.5845]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3863 0.0914 0.3544 0.5764], Lowest was [0.3863 0.0914 0.3544 0.571 ]
Median for last 10 epochs: [0.5351 0.0939 0.4078 0.5813], Epochs since improvement 0
  8%|▊         | 40/500 [24:59<5:14:33, 41.03s/it]  8%|▊         | 41/500 [25:27<4:42:28, 36.93s/it]  8%|▊         | 42/500 [26:13<5:04:01, 39.83s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.06E+06, Train scatter: [0.5013 0.1047 0.4333 0.6654]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4946 0.1052 0.4371 0.6588], Lowest was [0.3863 0.0914 0.3544 0.571 ]
Median for last 10 epochs: [0.4946 0.0963 0.4078 0.5823], Epochs since improvement 2
  9%|▊         | 43/500 [26:42<4:37:14, 36.40s/it]  9%|▉         | 44/500 [27:28<5:00:01, 39.48s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.12E+06, Train scatter: [0.4166 0.0931 0.412  0.6241]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4363 0.094  0.4121 0.6198], Lowest was [0.3863 0.0914 0.3544 0.571 ]
Median for last 10 epochs: [0.4946 0.094  0.4078 0.6198], Epochs since improvement 4
  9%|▉         | 45/500 [27:56<4:31:49, 35.84s/it]  9%|▉         | 46/500 [28:43<4:56:42, 39.21s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.03E+06, Train scatter: [0.4927 0.0901 0.3883 0.6605]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.479  0.0887 0.3961 0.6479], Lowest was [0.3863 0.0887 0.3544 0.571 ]
Median for last 10 epochs: [0.479  0.0937 0.3961 0.6198], Epochs since improvement 0
  9%|▉         | 47/500 [29:11<4:30:58, 35.89s/it] 10%|▉         | 48/500 [29:58<4:55:23, 39.21s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.90E+06, Train scatter: [0.354  0.0927 0.3516 0.5548]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3675 0.0933 0.355  0.5576], Lowest was [0.3675 0.0887 0.3544 0.5576]
Median for last 10 epochs: [0.4363 0.0933 0.3961 0.6198], Epochs since improvement 0
 10%|▉         | 49/500 [30:26<4:29:29, 35.85s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.71E+06, Train scatter: [0.3946 0.0884 0.3617 0.6777]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3915 0.0883 0.3602 0.6642], Lowest was [0.3675 0.0883 0.3544 0.5576]
Median for last 10 epochs: [0.4363 0.0933 0.3961 0.6479], Epochs since improvement 0
 10%|█         | 50/500 [31:20<5:10:09, 41.36s/it] 10%|█         | 51/500 [31:48<4:39:16, 37.32s/it] 10%|█         | 52/500 [32:35<4:59:44, 40.14s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.52E+06, Train scatter: [0.3927 0.0859 0.3454 0.576 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3907 0.0872 0.3475 0.5762], Lowest was [0.3675 0.0872 0.3475 0.5576]
Median for last 10 epochs: [0.3915 0.0887 0.3602 0.6198], Epochs since improvement 0
 11%|█         | 53/500 [33:02<4:30:25, 36.30s/it] 11%|█         | 54/500 [33:49<4:53:31, 39.49s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.39E+06, Train scatter: [0.4699 0.0872 0.3376 0.5488]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4626 0.0889 0.3373 0.5455], Lowest was [0.3675 0.0872 0.3373 0.5455]
Median for last 10 epochs: [0.3915 0.0887 0.355  0.5762], Epochs since improvement 0
 11%|█         | 55/500 [34:17<4:27:22, 36.05s/it] 11%|█         | 56/500 [35:03<4:48:35, 39.00s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.36E+06, Train scatter: [0.2987 0.0829 0.3043 0.518 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3074 0.084  0.3062 0.5162], Lowest was [0.3074 0.084  0.3062 0.5162]
Median for last 10 epochs: [0.3907 0.0883 0.3475 0.5576], Epochs since improvement 0
 11%|█▏        | 57/500 [35:31<4:22:59, 35.62s/it] 12%|█▏        | 58/500 [36:17<4:46:01, 38.83s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.25E+06, Train scatter: [0.2973 0.0833 0.3079 0.5142]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3029 0.0842 0.309  0.5134], Lowest was [0.3029 0.084  0.3062 0.5134]
Median for last 10 epochs: [0.3907 0.0872 0.3373 0.5455], Epochs since improvement 0
 12%|█▏        | 59/500 [36:44<4:20:03, 35.38s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.22E+06, Train scatter: [0.3276 0.0818 0.3036 0.5169]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3346 0.0832 0.3015 0.5143], Lowest was [0.3029 0.0832 0.3015 0.5134]
Median for last 10 epochs: [0.3346 0.0842 0.309  0.5162], Epochs since improvement 0
 12%|█▏        | 60/500 [37:37<4:57:33, 40.58s/it] 12%|█▏        | 61/500 [38:05<4:28:54, 36.75s/it] 12%|█▏        | 62/500 [38:52<4:51:21, 39.91s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.21E+06, Train scatter: [0.5607 0.0981 0.3317 0.5864]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5606 0.1001 0.3341 0.5895], Lowest was [0.3029 0.0832 0.3015 0.5134]
Median for last 10 epochs: [0.3346 0.0842 0.309  0.5162], Epochs since improvement 2
 13%|█▎        | 63/500 [39:20<4:24:17, 36.29s/it] 13%|█▎        | 64/500 [40:06<4:44:49, 39.20s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.37E+06, Train scatter: [0.2859 0.0828 0.2938 0.5147]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2891 0.084  0.2944 0.5141], Lowest was [0.2891 0.0832 0.2944 0.5134]
Median for last 10 epochs: [0.3074 0.084  0.3062 0.5143], Epochs since improvement 0
 13%|█▎        | 65/500 [40:34<4:19:35, 35.81s/it] 13%|█▎        | 66/500 [41:21<4:42:33, 39.06s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.11E+06, Train scatter: [0.2811 0.0789 0.2967 0.5063]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2813 0.08   0.2959 0.5057], Lowest was [0.2813 0.08   0.2944 0.5057]
Median for last 10 epochs: [0.3029 0.084  0.3015 0.5141], Epochs since improvement 0
 13%|█▎        | 67/500 [41:48<4:16:33, 35.55s/it] 14%|█▎        | 68/500 [42:34<4:38:43, 38.71s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.02E+06, Train scatter: [0.2758 0.078  0.2892 0.5239]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2797 0.0786 0.2954 0.5227], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.2891 0.0832 0.2959 0.5143], Epochs since improvement 0
 14%|█▍        | 69/500 [43:02<4:14:14, 35.39s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 8.91E+05, Train scatter: [0.3171 0.0791 0.3452 0.5256]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3229 0.08   0.3459 0.5269], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.2891 0.08   0.2959 0.5227], Epochs since improvement 2
 14%|█▍        | 70/500 [43:54<4:49:35, 40.41s/it] 14%|█▍        | 71/500 [44:21<4:21:21, 36.55s/it] 14%|█▍        | 72/500 [45:08<4:41:56, 39.52s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 2.17E+07, Train scatter: [0.9316 0.1633 0.5438 0.9802]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9158 0.159  0.5352 0.9684], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.2891 0.08   0.2959 0.5227], Epochs since improvement 4
 15%|█▍        | 73/500 [45:35<4:15:14, 35.87s/it] 15%|█▍        | 74/500 [46:22<4:38:13, 39.19s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 5.07E+06, Train scatter: [0.9311 0.152  0.5435 0.9755]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9158 0.1493 0.535  0.9663], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.3229 0.08   0.3459 0.5269], Epochs since improvement 6
 15%|█▌        | 75/500 [46:49<4:12:25, 35.64s/it] 15%|█▌        | 76/500 [47:37<4:36:08, 39.08s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.44E+06, Train scatter: [0.9258 0.1347 0.5404 0.8938]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9105 0.1348 0.532  0.8793], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.9105 0.1348 0.532  0.8793], Epochs since improvement 8
 15%|█▌        | 77/500 [48:04<4:10:54, 35.59s/it] 16%|█▌        | 78/500 [48:51<4:34:17, 39.00s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.78E+06, Train scatter: [0.9134 0.1255 0.4861 0.7474]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8975 0.1256 0.491  0.746 ], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.9105 0.1348 0.532  0.8793], Epochs since improvement 10
 16%|█▌        | 79/500 [49:20<4:11:48, 35.89s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 1.74E+06, Train scatter: [0.8951 0.1158 0.4268 0.6714]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.878  0.1181 0.433  0.6755], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.9105 0.1348 0.532  0.8793], Epochs since improvement 12
 16%|█▌        | 80/500 [50:12<4:45:26, 40.78s/it] 16%|█▌        | 81/500 [50:40<4:18:09, 36.97s/it] 16%|█▋        | 82/500 [51:28<4:41:52, 40.46s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 1.31E+06, Train scatter: [0.8695 0.1199 0.4155 0.6963]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8551 0.1311 0.426  0.7193], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.8975 0.1311 0.491  0.746 ], Epochs since improvement 14
 17%|█▋        | 83/500 [51:56<4:14:16, 36.59s/it] 17%|█▋        | 84/500 [52:42<4:32:53, 39.36s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 1.05E+06, Train scatter: [0.7979 0.1067 0.3727 0.6289]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7764 0.1104 0.3829 0.6402], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.878  0.1256 0.433  0.7193], Epochs since improvement 16
 17%|█▋        | 85/500 [53:10<4:09:42, 36.10s/it] 17%|█▋        | 86/500 [53:57<4:31:21, 39.33s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 7.83E+05, Train scatter: [0.6351 0.101  0.3546 0.6105]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6218 0.1033 0.3627 0.6163], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.8551 0.1181 0.426  0.6755], Epochs since improvement 18
 17%|█▋        | 87/500 [54:25<4:05:59, 35.74s/it] 18%|█▊        | 88/500 [55:11<4:28:18, 39.07s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 6.70E+05, Train scatter: [0.5984 0.0959 0.4425 0.5975]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6026 0.0995 0.4457 0.6072], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.7764 0.1104 0.426  0.6402], Epochs since improvement 20
 18%|█▊        | 89/500 [55:39<4:03:25, 35.54s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 7.44E+05, Train scatter: [0.5953 0.092  0.3544 0.6018]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.641  0.0953 0.3682 0.6021], Lowest was [0.2797 0.0786 0.2944 0.5057]
Median for last 10 epochs: [0.641  0.1033 0.3829 0.6163], Epochs since improvement 22
 18%|█▊        | 89/500 [56:30<4:20:57, 38.10s/it]
Exited after 90 epochs due to early stopping
3390.52 seconds spent training, 6.781 seconds per epoch. Processed 10269 trees per second
[0.6409469  0.09527089 0.36817664 0.6020387 ]
{'epoch_exit': 89, 'scatter_m_star': 0.6409469, 'lowest_m_star': 0.27966422, 'last20_m_star': 0.8665781, 'last10_m_star': 0.64096594, 'scatter_v_disk': 0.095270894, 'lowest_v_disk': 0.078621544, 'last20_v_disk': 0.121822655, 'last10_v_disk': 0.103338175, 'scatter_m_cold': 0.36817664, 'lowest_m_cold': 0.2944273, 'last20_m_cold': 0.43937764, 'last10_m_cold': 0.3828993, 'scatter_sfr_100': 0.6020387, 'lowest_sfr_100': 0.5056571, 'last20_sfr_100': 0.6974107, 'last10_sfr_100': 0.6162817}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_wmhmle
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:47<6:36:26, 47.67s/it]  0%|          | 2/500 [01:59<8:35:54, 62.16s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.47E+07, Train scatter: [0.9352 0.1518 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1479 0.5356 0.9851], Lowest was [0.9196 0.1479 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1479 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:46<7:36:34, 55.12s/it]  1%|          | 4/500 [03:59<8:33:18, 62.09s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.65E+07, Train scatter: [0.9342 0.1047 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9186 0.1025 0.5355 0.9848], Lowest was [0.9186 0.1025 0.5355 0.9848]
Median for last 10 epochs: [0.9186 0.1025 0.5355 0.9848], Epochs since improvement 0
  1%|          | 5/500 [04:47<7:51:12, 57.12s/it]  1%|          | 6/500 [06:01<8:35:31, 62.61s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.11E+07, Train scatter: [0.7741 0.0962 0.544  0.6188]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7616 0.0953 0.5355 0.6104], Lowest was [0.7616 0.0953 0.5355 0.6104]
Median for last 10 epochs: [0.7616 0.0953 0.5355 0.6104], Epochs since improvement 0
  1%|▏         | 7/500 [06:48<7:54:29, 57.75s/it]  2%|▏         | 8/500 [08:02<8:34:01, 62.69s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.09E+06, Train scatter: [0.4597 0.0874 0.544  0.5836]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4557 0.088  0.5355 0.576 ], Lowest was [0.4557 0.088  0.5355 0.576 ]
Median for last 10 epochs: [0.6087 0.0916 0.5355 0.5932], Epochs since improvement 0
  2%|▏         | 9/500 [08:49<7:53:57, 57.92s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.98E+06, Train scatter: [0.3409 0.0789 0.544  0.5439]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3478 0.0795 0.5354 0.5381], Lowest was [0.3478 0.0795 0.5354 0.5381]
Median for last 10 epochs: [0.4557 0.088  0.5355 0.576 ], Epochs since improvement 0
  2%|▏         | 10/500 [10:10<8:50:46, 64.99s/it]  2%|▏         | 11/500 [10:58<8:08:16, 59.91s/it]  2%|▏         | 12/500 [12:10<8:37:48, 63.66s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 4.34E+06, Train scatter: [0.355  0.0754 0.5439 0.5315]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3567 0.0752 0.5354 0.5243], Lowest was [0.3478 0.0752 0.5354 0.5243]
Median for last 10 epochs: [0.4557 0.088  0.5355 0.576 ], Epochs since improvement 0
  3%|▎         | 13/500 [12:59<7:58:28, 58.95s/it]  3%|▎         | 14/500 [14:13<8:35:21, 63.62s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 4.07E+06, Train scatter: [0.3203 0.0745 0.544  0.5504]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3315 0.0743 0.5354 0.5513], Lowest was [0.3315 0.0743 0.5354 0.5243]
Median for last 10 epochs: [0.3567 0.0795 0.5354 0.5513], Epochs since improvement 0
  3%|▎         | 15/500 [15:01<7:55:58, 58.88s/it]  3%|▎         | 16/500 [16:13<8:26:03, 62.73s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.96E+06, Train scatter: [0.3306 0.0728 0.544  0.5332]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3347 0.0734 0.5354 0.5311], Lowest was [0.3315 0.0734 0.5354 0.5243]
Median for last 10 epochs: [0.3478 0.0752 0.5354 0.5381], Epochs since improvement 0
  3%|▎         | 17/500 [17:00<7:47:53, 58.12s/it]  4%|▎         | 18/500 [18:14<8:25:42, 62.95s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.91E+06, Train scatter: [0.2352 0.0738 0.5439 0.5209]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.243  0.0745 0.5354 0.5179], Lowest was [0.243  0.0734 0.5354 0.5179]
Median for last 10 epochs: [0.3347 0.0745 0.5354 0.5311], Epochs since improvement 0
  4%|▍         | 19/500 [19:01<7:45:45, 58.10s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.51E+06, Train scatter: [0.2823 0.0753 0.5439 0.5566]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2875 0.076  0.5353 0.5573], Lowest was [0.243  0.0734 0.5353 0.5179]
Median for last 10 epochs: [0.3315 0.0745 0.5354 0.5311], Epochs since improvement 0
  4%|▍         | 20/500 [20:20<8:35:15, 64.41s/it]  4%|▍         | 21/500 [21:07<7:52:37, 59.20s/it]  4%|▍         | 22/500 [22:19<8:21:33, 62.96s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.40E+06, Train scatter: [0.2961 0.0697 0.5438 0.524 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2944 0.0696 0.5353 0.5199], Lowest was [0.243  0.0696 0.5353 0.5179]
Median for last 10 epochs: [0.2944 0.0743 0.5354 0.5311], Epochs since improvement 0
  5%|▍         | 23/500 [23:07<7:45:54, 58.60s/it]  5%|▍         | 24/500 [24:21<8:21:43, 63.24s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.37E+06, Train scatter: [0.2873 0.0752 0.5438 0.5475]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2844 0.0756 0.5352 0.5472], Lowest was [0.243  0.0696 0.5352 0.5179]
Median for last 10 epochs: [0.2875 0.0745 0.5353 0.5311], Epochs since improvement 0
  5%|▌         | 25/500 [25:11<7:47:39, 59.07s/it]  5%|▌         | 26/500 [26:23<8:18:18, 63.08s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.32E+06, Train scatter: [0.2494 0.0753 0.5437 0.5181]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2545 0.0756 0.5352 0.5156], Lowest was [0.243  0.0696 0.5352 0.5156]
Median for last 10 epochs: [0.2844 0.0756 0.5353 0.5199], Epochs since improvement 0
  5%|▌         | 27/500 [27:12<7:43:03, 58.74s/it]  6%|▌         | 28/500 [28:25<8:16:05, 63.06s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.28E+06, Train scatter: [0.2214 0.0699 0.5436 0.5047]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2313 0.0696 0.5351 0.4998], Lowest was [0.2313 0.0696 0.5351 0.4998]
Median for last 10 epochs: [0.2844 0.0756 0.5352 0.5199], Epochs since improvement 0
  6%|▌         | 29/500 [29:12<7:38:03, 58.35s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.26E+06, Train scatter: [0.2317 0.0703 0.5436 0.5123]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2459 0.0703 0.535  0.5075], Lowest was [0.2313 0.0696 0.535  0.4998]
Median for last 10 epochs: [0.2545 0.0703 0.5352 0.5156], Epochs since improvement 0
  6%|▌         | 30/500 [30:31<8:25:32, 64.54s/it]  6%|▌         | 31/500 [31:19<7:44:51, 59.47s/it]  6%|▋         | 32/500 [32:33<8:17:32, 63.79s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.21E+06, Train scatter: [0.2758 0.0725 0.5436 0.5277]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2752 0.0727 0.535  0.5195], Lowest was [0.2313 0.0696 0.535  0.4998]
Median for last 10 epochs: [0.2545 0.0727 0.5351 0.5156], Epochs since improvement 2
  7%|▋         | 33/500 [33:20<7:37:23, 58.77s/it]  7%|▋         | 34/500 [34:31<8:06:03, 62.58s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.15E+06, Train scatter: [0.3981 0.1182 0.5434 0.5115]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3892 0.1152 0.5348 0.5088], Lowest was [0.2313 0.0696 0.5348 0.4998]
Median for last 10 epochs: [0.2545 0.0727 0.535  0.5088], Epochs since improvement 0
  7%|▋         | 35/500 [35:20<7:32:51, 58.43s/it]  7%|▋         | 36/500 [36:31<8:00:09, 62.09s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.11E+06, Train scatter: [0.5566 0.0711 0.543  0.5553]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5433 0.0699 0.5344 0.55  ], Lowest was [0.2313 0.0696 0.5344 0.4998]
Median for last 10 epochs: [0.2752 0.0703 0.535  0.5088], Epochs since improvement 0
  7%|▋         | 37/500 [37:17<7:23:44, 57.51s/it]  8%|▊         | 38/500 [38:30<7:57:18, 61.99s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.09E+06, Train scatter: [0.2352 0.0722 0.5429 0.5086]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.243  0.0722 0.5343 0.5034], Lowest was [0.2313 0.0696 0.5343 0.4998]
Median for last 10 epochs: [0.2752 0.0722 0.5348 0.5088], Epochs since improvement 0
  8%|▊         | 39/500 [39:17<7:21:42, 57.49s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.04E+06, Train scatter: [0.4422 0.0727 0.5426 0.5084]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4326 0.0722 0.534  0.5   ], Lowest was [0.2313 0.0696 0.534  0.4998]
Median for last 10 epochs: [0.3892 0.0722 0.5344 0.5088], Epochs since improvement 0
  8%|▊         | 40/500 [40:35<8:09:14, 63.81s/it]  8%|▊         | 41/500 [41:23<7:31:32, 59.02s/it]  8%|▊         | 42/500 [42:36<8:00:50, 62.99s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.91E+06, Train scatter: [0.4809 0.0902 0.5413 0.5395]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4703 0.089  0.5327 0.5361], Lowest was [0.2313 0.0696 0.5327 0.4998]
Median for last 10 epochs: [0.4326 0.0722 0.5343 0.5088], Epochs since improvement 0
  9%|▊         | 43/500 [43:25<7:28:07, 58.83s/it]  9%|▉         | 44/500 [44:39<8:01:34, 63.36s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.19E+06, Train scatter: [0.9272 0.1731 0.544  0.9898]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9124 0.1691 0.5354 0.9797], Lowest was [0.2313 0.0696 0.5327 0.4998]
Median for last 10 epochs: [0.4703 0.0722 0.5343 0.5361], Epochs since improvement 2
  9%|▉         | 45/500 [45:28<7:28:28, 59.14s/it]  9%|▉         | 46/500 [46:40<7:57:57, 63.17s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.82E+06, Train scatter: [0.9348 0.1225 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9193 0.1217 0.5355 0.9849], Lowest was [0.2313 0.0696 0.5327 0.4998]
Median for last 10 epochs: [0.4703 0.089  0.5343 0.5361], Epochs since improvement 4
  9%|▉         | 47/500 [47:27<7:20:01, 58.28s/it] 10%|▉         | 48/500 [48:42<7:54:55, 63.04s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.96E+06, Train scatter: [0.9172 0.1133 0.5441 0.9895]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9049 0.1122 0.5355 0.9801], Lowest was [0.2313 0.0696 0.5327 0.4998]
Median for last 10 epochs: [0.9049 0.1122 0.5354 0.9797], Epochs since improvement 6
 10%|▉         | 49/500 [49:29<7:18:21, 58.32s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.76E+06, Train scatter: [0.7703 0.1253 0.5441 0.9755]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.781  0.1244 0.5355 0.9672], Lowest was [0.2313 0.0696 0.5327 0.4998]
Median for last 10 epochs: [0.9049 0.1217 0.5355 0.9797], Epochs since improvement 8
 10%|█         | 50/500 [50:49<8:05:58, 64.80s/it] 10%|█         | 51/500 [51:36<7:25:24, 59.52s/it] 10%|█         | 52/500 [52:49<7:55:22, 63.67s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.66E+06, Train scatter: [0.5798 0.1165 0.544  0.8297]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5769 0.1158 0.5355 0.8284], Lowest was [0.2313 0.0696 0.5327 0.4998]
Median for last 10 epochs: [0.9049 0.1217 0.5355 0.9797], Epochs since improvement 10
 11%|█         | 53/500 [53:38<7:20:14, 59.09s/it] 11%|█         | 54/500 [54:50<7:49:50, 63.21s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.60E+06, Train scatter: [0.5447 0.1088 0.544  0.6691]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5437 0.1087 0.5354 0.6707], Lowest was [0.2313 0.0696 0.5327 0.4998]
Median for last 10 epochs: [0.781  0.1158 0.5355 0.9672], Epochs since improvement 12
 11%|█         | 55/500 [55:38<7:14:25, 58.57s/it] 11%|█         | 56/500 [56:52<7:46:03, 62.98s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.58E+06, Train scatter: [0.5501 0.0982 0.5439 0.6319]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5496 0.0992 0.5354 0.637 ], Lowest was [0.2313 0.0696 0.5327 0.4998]
Median for last 10 epochs: [0.5769 0.1122 0.5355 0.8284], Epochs since improvement 14
 11%|█▏        | 57/500 [57:39<7:10:25, 58.30s/it] 12%|█▏        | 58/500 [58:51<7:40:19, 62.49s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.57E+06, Train scatter: [0.4155 0.0968 0.5438 0.6054]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4179 0.0981 0.5352 0.6078], Lowest was [0.2313 0.0696 0.5327 0.4998]
Median for last 10 epochs: [0.5496 0.1087 0.5354 0.6707], Epochs since improvement 16
 12%|█▏        | 59/500 [59:39<7:06:49, 58.07s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.54E+06, Train scatter: [0.3499 0.089  0.5429 0.5781]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3568 0.0912 0.5344 0.5833], Lowest was [0.2313 0.0696 0.5327 0.4998]
Median for last 10 epochs: [0.5437 0.0992 0.5354 0.637 ], Epochs since improvement 18
 12%|█▏        | 60/500 [1:00:59<7:53:10, 64.52s/it] 12%|█▏        | 61/500 [1:01:46<7:13:42, 59.28s/it] 12%|█▏        | 62/500 [1:03:00<7:45:56, 63.83s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.47E+06, Train scatter: [0.3329 0.0858 0.5376 0.5572]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3422 0.0892 0.529  0.5667], Lowest was [0.2313 0.0696 0.529  0.4998]
Median for last 10 epochs: [0.4179 0.0981 0.5352 0.6078], Epochs since improvement 0
 13%|█▎        | 63/500 [1:03:47<7:08:02, 58.77s/it] 13%|█▎        | 64/500 [1:04:59<7:36:26, 62.81s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.40E+06, Train scatter: [0.3455 0.0839 0.5332 0.6573]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3542 0.0865 0.5258 0.6548], Lowest was [0.2313 0.0696 0.5258 0.4998]
Median for last 10 epochs: [0.3568 0.0912 0.5344 0.6078], Epochs since improvement 0
 13%|█▎        | 65/500 [1:05:47<7:02:15, 58.24s/it] 13%|█▎        | 66/500 [1:07:01<7:35:19, 62.95s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.32E+06, Train scatter: [0.3405 0.0786 0.5286 0.5344]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3559 0.0811 0.5205 0.538 ], Lowest was [0.2313 0.0696 0.5205 0.4998]
Median for last 10 epochs: [0.3559 0.0892 0.529  0.5833], Epochs since improvement 0
 13%|█▎        | 67/500 [1:07:48<6:59:43, 58.16s/it] 14%|█▎        | 68/500 [1:09:01<7:32:14, 62.81s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.34E+06, Train scatter: [0.7768 0.1239 0.5443 0.9169]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7688 0.1214 0.5357 0.9131], Lowest was [0.2313 0.0696 0.5205 0.4998]
Median for last 10 epochs: [0.3559 0.0892 0.529  0.5833], Epochs since improvement 2
 14%|█▍        | 69/500 [1:09:49<6:58:14, 58.22s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.41E+06, Train scatter: [0.4607 0.0868 0.5376 0.652 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4607 0.087  0.5293 0.6497], Lowest was [0.2313 0.0696 0.5205 0.4998]
Median for last 10 epochs: [0.3559 0.087  0.529  0.6497], Epochs since improvement 4
 14%|█▍        | 70/500 [1:11:10<7:46:06, 65.04s/it] 14%|█▍        | 71/500 [1:11:59<7:09:57, 60.13s/it] 14%|█▍        | 72/500 [1:13:11<7:36:05, 63.94s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.33E+06, Train scatter: [0.7596 0.1406 0.5441 0.8212]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.753  0.1384 0.5355 0.8227], Lowest was [0.2313 0.0696 0.5205 0.4998]
Median for last 10 epochs: [0.4607 0.087  0.5293 0.6548], Epochs since improvement 6
 15%|█▍        | 73/500 [1:13:59<6:59:49, 58.99s/it] 15%|█▍        | 74/500 [1:15:13<7:30:20, 63.43s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.12E+06, Train scatter: [0.4004 0.0891 0.5363 0.6078]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4029 0.09   0.5281 0.6121], Lowest was [0.2313 0.0696 0.5205 0.4998]
Median for last 10 epochs: [0.4607 0.09   0.5293 0.6497], Epochs since improvement 8
 15%|█▌        | 75/500 [1:16:01<6:56:42, 58.83s/it] 15%|█▌        | 76/500 [1:17:14<7:26:37, 63.20s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.00E+06, Train scatter: [0.4295 0.0847 0.5322 0.5696]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4288 0.0856 0.5242 0.5725], Lowest was [0.2313 0.0696 0.5205 0.4998]
Median for last 10 epochs: [0.4607 0.09   0.5293 0.6497], Epochs since improvement 10
 15%|█▌        | 77/500 [1:18:02<6:53:07, 58.60s/it] 16%|█▌        | 78/500 [1:19:15<7:21:46, 62.81s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.83E+06, Train scatter: [0.3853 0.0833 0.5133 0.5662]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4019 0.0839 0.5061 0.571 ], Lowest was [0.2313 0.0696 0.5061 0.4998]
Median for last 10 epochs: [0.4288 0.087  0.5281 0.6121], Epochs since improvement 0
 16%|█▌        | 79/500 [1:20:03<6:51:02, 58.58s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 1.64E+06, Train scatter: [0.3899 0.1096 0.3856 0.5947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3869 0.1028 0.3828 0.5939], Lowest was [0.2313 0.0696 0.3828 0.4998]
Median for last 10 epochs: [0.4029 0.09   0.5242 0.5939], Epochs since improvement 0
 16%|█▌        | 80/500 [1:21:23<7:33:58, 64.85s/it] 16%|█▌        | 81/500 [1:22:11<6:58:25, 59.92s/it] 16%|█▋        | 82/500 [1:23:23<7:21:51, 63.43s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 1.64E+06, Train scatter: [0.4967 0.0865 0.3848 0.5891]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4783 0.087  0.384  0.5866], Lowest was [0.2313 0.0696 0.3828 0.4998]
Median for last 10 epochs: [0.4029 0.087  0.5061 0.5866], Epochs since improvement 2
 17%|█▋        | 83/500 [1:24:11<6:48:23, 58.76s/it] 17%|█▋        | 84/500 [1:25:23<7:15:06, 62.76s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.19E+06, Train scatter: [0.4249 0.0909 0.4189 0.607 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4374 0.0954 0.4232 0.6158], Lowest was [0.2313 0.0696 0.3828 0.4998]
Median for last 10 epochs: [0.4288 0.087  0.4232 0.5866], Epochs since improvement 4
 17%|█▋        | 85/500 [1:26:11<6:44:28, 58.48s/it] 17%|█▋        | 86/500 [1:27:23<7:10:35, 62.40s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 1.13E+06, Train scatter: [0.3597 0.0801 0.3489 0.5701]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.371  0.0818 0.3561 0.576 ], Lowest was [0.2313 0.0696 0.3561 0.4998]
Median for last 10 epochs: [0.4019 0.087  0.384  0.5866], Epochs since improvement 0
 17%|█▋        | 87/500 [1:28:11<6:40:44, 58.22s/it] 18%|█▊        | 88/500 [1:29:24<7:09:21, 62.53s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 8.77E+05, Train scatter: [0.3545 0.075  0.3266 0.5561]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3808 0.0779 0.3332 0.5682], Lowest was [0.2313 0.0696 0.3332 0.4998]
Median for last 10 epochs: [0.3869 0.087  0.3828 0.5866], Epochs since improvement 0
 18%|█▊        | 89/500 [1:30:12<6:38:22, 58.16s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 7.77E+05, Train scatter: [0.3302 0.0716 0.3073 0.5271]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3533 0.076  0.3184 0.535 ], Lowest was [0.2313 0.0696 0.3184 0.4998]
Median for last 10 epochs: [0.3808 0.0818 0.3561 0.576 ], Epochs since improvement 0
 18%|█▊        | 90/500 [1:31:31<7:19:40, 64.34s/it] 18%|█▊        | 91/500 [1:32:18<6:44:19, 59.31s/it] 18%|█▊        | 92/500 [1:33:32<7:12:03, 63.54s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 7.01E+05, Train scatter: [0.3839 0.0656 0.3004 0.5222]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3873 0.0683 0.3083 0.5295], Lowest was [0.2313 0.0683 0.3083 0.4998]
Median for last 10 epochs: [0.3808 0.0779 0.3332 0.5682], Epochs since improvement 0
 19%|█▊        | 93/500 [1:34:19<6:39:15, 58.86s/it] 19%|█▉        | 94/500 [1:35:32<7:06:33, 63.04s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 6.12E+05, Train scatter: [0.2885 0.0641 0.2919 0.5088]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.309  0.0669 0.3074 0.5189], Lowest was [0.2313 0.0669 0.3074 0.4998]
Median for last 10 epochs: [0.371  0.076  0.3184 0.535 ], Epochs since improvement 0
 19%|█▉        | 95/500 [1:36:21<6:36:43, 58.77s/it] 19%|█▉        | 96/500 [1:37:33<7:02:41, 62.78s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 5.67E+05, Train scatter: [0.2654 0.0593 0.2769 0.4952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2816 0.0626 0.2892 0.5002], Lowest was [0.2313 0.0626 0.2892 0.4998]
Median for last 10 epochs: [0.3533 0.0683 0.3083 0.5295], Epochs since improvement 0
 19%|█▉        | 97/500 [1:38:20<6:30:09, 58.09s/it] 20%|█▉        | 98/500 [1:39:34<7:00:15, 62.72s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 5.32E+05, Train scatter: [0.4566 0.121  0.3463 0.594 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4615 0.1401 0.3641 0.6022], Lowest was [0.2313 0.0626 0.2892 0.4998]
Median for last 10 epochs: [0.3533 0.0683 0.3083 0.5295], Epochs since improvement 2
 20%|█▉        | 99/500 [1:40:22<6:29:30, 58.28s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 5.67E+05, Train scatter: [0.3148 0.0631 0.2944 0.5476]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3241 0.065  0.3017 0.5523], Lowest was [0.2313 0.0626 0.2892 0.4998]
Median for last 10 epochs: [0.3241 0.0669 0.3074 0.5295], Epochs since improvement 4
 20%|██        | 100/500 [1:41:41<7:09:26, 64.42s/it] 20%|██        | 101/500 [1:42:29<6:36:06, 59.56s/it] 20%|██        | 102/500 [1:43:41<7:00:31, 63.40s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 4.14E+05, Train scatter: [0.3425 0.0562 0.2652 0.4836]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3488 0.058  0.2778 0.492 ], Lowest was [0.2313 0.058  0.2778 0.492 ]
Median for last 10 epochs: [0.3241 0.065  0.3017 0.5189], Epochs since improvement 0
 21%|██        | 103/500 [1:44:28<6:27:40, 58.59s/it] 21%|██        | 104/500 [1:45:41<6:53:22, 62.63s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 4.33E+05, Train scatter: [0.2641 0.0585 0.2735 0.4957]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2742 0.0594 0.2841 0.4974], Lowest was [0.2313 0.058  0.2778 0.492 ]
Median for last 10 epochs: [0.3241 0.0626 0.2892 0.5002], Epochs since improvement 2
 21%|██        | 105/500 [1:46:28<6:23:16, 58.22s/it] 21%|██        | 106/500 [1:47:41<6:50:35, 62.53s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 4.36E+05, Train scatter: [0.2405 0.0612 0.2665 0.4834]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.248  0.0624 0.2785 0.4872], Lowest was [0.2313 0.058  0.2778 0.4872]
Median for last 10 epochs: [0.3241 0.0624 0.2841 0.4974], Epochs since improvement 0
 21%|██▏       | 107/500 [1:48:28<6:18:45, 57.83s/it] 22%|██▏       | 108/500 [1:49:40<6:46:01, 62.15s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 3.55E+05, Train scatter: [0.2333 0.0551 0.2516 0.471 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2408 0.0569 0.2647 0.4755], Lowest was [0.2313 0.0569 0.2647 0.4755]
Median for last 10 epochs: [0.2742 0.0594 0.2785 0.492 ], Epochs since improvement 0
 22%|██▏       | 109/500 [1:50:29<6:18:37, 58.10s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 3.17E+05, Train scatter: [0.2309 0.0542 0.2505 0.4744]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2383 0.0551 0.2602 0.4777], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.248  0.058  0.2778 0.4872], Epochs since improvement 0
 22%|██▏       | 110/500 [1:51:47<6:57:18, 64.20s/it] 22%|██▏       | 111/500 [1:52:35<6:24:38, 59.33s/it] 22%|██▏       | 112/500 [1:53:48<6:48:59, 63.25s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 4.04E+06, Train scatter: [0.935  0.1728 0.5439 0.9959]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9194 0.1689 0.5353 0.9856], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.248  0.0594 0.2785 0.4872], Epochs since improvement 2
 23%|██▎       | 113/500 [1:54:35<6:17:11, 58.48s/it] 23%|██▎       | 114/500 [1:55:48<6:44:18, 62.85s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 3.23E+06, Train scatter: [0.9332 0.1284 0.5438 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9177 0.1261 0.5352 0.9848], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.248  0.0624 0.2785 0.4872], Epochs since improvement 4
 23%|██▎       | 115/500 [1:56:37<6:17:03, 58.76s/it] 23%|██▎       | 116/500 [1:57:49<6:40:56, 62.65s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 2.99E+06, Train scatter: [0.6955 0.1203 0.5437 0.9945]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6854 0.1189 0.5352 0.9842], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.6854 0.1189 0.5352 0.9842], Epochs since improvement 6
 23%|██▎       | 117/500 [1:58:36<6:09:28, 57.88s/it] 24%|██▎       | 118/500 [1:59:48<6:35:16, 62.08s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 2.71E+06, Train scatter: [0.8507 0.12   0.5436 0.9939]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8374 0.1186 0.535  0.9836], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.8374 0.1189 0.5352 0.9842], Epochs since improvement 8
 24%|██▍       | 119/500 [2:00:34<6:04:39, 57.43s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 2.39E+06, Train scatter: [0.7674 0.1198 0.5433 0.9934]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7562 0.1183 0.5347 0.9831], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.8374 0.1189 0.5352 0.9842], Epochs since improvement 10
 24%|██▍       | 120/500 [2:01:53<6:45:22, 64.01s/it] 24%|██▍       | 121/500 [2:02:43<6:16:15, 59.57s/it] 24%|██▍       | 122/500 [2:03:55<6:39:23, 63.39s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 2.02E+06, Train scatter: [0.6085 0.1197 0.5418 0.9927]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6003 0.1182 0.5334 0.9824], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.7562 0.1186 0.535  0.9836], Epochs since improvement 12
 25%|██▍       | 123/500 [2:04:42<6:06:55, 58.40s/it] 25%|██▍       | 124/500 [2:05:55<6:34:24, 62.94s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.67E+06, Train scatter: [0.6046 0.1136 0.5432 0.991 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.598  0.1123 0.5346 0.9808], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.6854 0.1183 0.5347 0.9831], Epochs since improvement 14
 25%|██▌       | 125/500 [2:06:43<6:05:02, 58.41s/it] 25%|██▌       | 126/500 [2:07:55<6:28:38, 62.35s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.31E+06, Train scatter: [0.5886 0.1185 0.5429 0.9901]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5828 0.1173 0.5343 0.9798], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.6003 0.1182 0.5346 0.9824], Epochs since improvement 16
 25%|██▌       | 127/500 [2:08:42<5:59:28, 57.82s/it] 26%|██▌       | 128/500 [2:09:54<6:25:13, 62.13s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 9.55E+05, Train scatter: [0.5908 0.1134 0.5425 0.9888]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5848 0.1115 0.5339 0.9786], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.598  0.1173 0.5343 0.9808], Epochs since improvement 18
 26%|██▌       | 129/500 [2:10:43<6:00:15, 58.26s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 5.89E+05, Train scatter: [0.6321 0.1148 0.5419 0.9871]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6239 0.113  0.5334 0.9769], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.598  0.113  0.5339 0.9798], Epochs since improvement 20
 26%|██▌       | 130/500 [2:12:04<6:41:35, 65.12s/it] 26%|██▌       | 131/500 [2:12:52<6:07:23, 59.74s/it] 26%|██▌       | 131/500 [2:14:05<6:17:42, 61.42s/it]
Epoch: 132 done with learning rate 9.56E-03, Train loss: -6.23E+04, Train scatter: [0.5876 0.1207 0.5416 0.9846]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5789 0.119  0.5331 0.9745], Lowest was [0.2313 0.0551 0.2602 0.4755]
Median for last 10 epochs: [0.5848 0.113  0.5339 0.9786], Epochs since improvement 22
Exited after 132 epochs due to early stopping
8045.51 seconds spent training, 16.091 seconds per epoch. Processed 4328 trees per second
[0.5788709  0.11895212 0.5331023  0.97447014]
{'epoch_exit': 131, 'scatter_m_star': 0.5788709, 'lowest_m_star': 0.23130533, 'last20_m_star': 0.6120652, 'last10_m_star': 0.5847518, 'scatter_v_disk': 0.11895212, 'lowest_v_disk': 0.055069935, 'last20_v_disk': 0.11829382, 'last10_v_disk': 0.11297875, 'scatter_m_cold': 0.5331023, 'lowest_m_cold': 0.26018292, 'last20_m_cold': 0.5344599, 'last10_m_cold': 0.53393775, 'scatter_sfr_100': 0.97447014, 'lowest_sfr_100': 0.47549093, 'last20_sfr_100': 0.98159856, 'last10_sfr_100': 0.9786271}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_uihpbm
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:42<5:51:19, 42.24s/it]  0%|          | 2/500 [01:46<7:36:16, 54.97s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.08E+07, Train scatter: [0.9352 0.1714 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1682 0.5355 0.9851], Lowest was [0.9196 0.1682 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1682 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:27<6:44:40, 48.85s/it]  1%|          | 4/500 [03:30<7:29:57, 54.43s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.32E+07, Train scatter: [0.9352 0.1622 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1589 0.5355 0.9851], Lowest was [0.9196 0.1589 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1589 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:12<6:50:40, 49.78s/it]  1%|          | 6/500 [05:15<7:28:24, 54.46s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.86E+07, Train scatter: [0.9351 0.1351 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1319 0.5356 0.9851], Lowest was [0.9196 0.1319 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1319 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [05:56<6:50:09, 49.92s/it]  2%|▏         | 8/500 [07:00<7:26:27, 54.45s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.47E+07, Train scatter: [0.9333 0.1148 0.5441 0.9839]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9177 0.1136 0.5355 0.9733], Lowest was [0.9177 0.1136 0.5355 0.9733]
Median for last 10 epochs: [0.9186 0.1227 0.5355 0.9792], Epochs since improvement 0
  2%|▏         | 9/500 [07:40<6:49:39, 50.06s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 1.14E+07, Train scatter: [0.7548 0.1006 0.5441 0.6331]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7455 0.1007 0.5355 0.6283], Lowest was [0.7455 0.1007 0.5355 0.6283]
Median for last 10 epochs: [0.9177 0.1136 0.5355 0.9733], Epochs since improvement 0
  2%|▏         | 10/500 [08:51<7:41:34, 56.52s/it]  2%|▏         | 11/500 [09:32<7:00:00, 51.53s/it]  2%|▏         | 12/500 [10:35<7:27:37, 55.04s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.29E+06, Train scatter: [0.6929 0.0932 0.544  0.5952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.686  0.0922 0.5355 0.5908], Lowest was [0.686  0.0922 0.5355 0.5908]
Median for last 10 epochs: [0.9177 0.1136 0.5355 0.9733], Epochs since improvement 0
  3%|▎         | 13/500 [11:15<6:51:00, 50.64s/it]  3%|▎         | 14/500 [12:21<7:26:50, 55.17s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.70E+06, Train scatter: [0.5462 0.0889 0.544  0.5532]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5404 0.0886 0.5354 0.5536], Lowest was [0.5404 0.0886 0.5354 0.5536]
Median for last 10 epochs: [0.7455 0.1007 0.5355 0.6283], Epochs since improvement 0
  3%|▎         | 15/500 [13:01<6:50:04, 50.73s/it]  3%|▎         | 16/500 [14:06<7:24:29, 55.10s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 5.54E+06, Train scatter: [0.4727 0.0858 0.5439 0.5362]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4689 0.0854 0.5353 0.5378], Lowest was [0.4689 0.0854 0.5353 0.5378]
Median for last 10 epochs: [0.686  0.0922 0.5355 0.5908], Epochs since improvement 0
  3%|▎         | 17/500 [14:48<6:50:58, 51.05s/it]  4%|▎         | 18/500 [15:53<7:23:33, 55.21s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 5.01E+06, Train scatter: [0.3882 0.0815 0.5439 0.5451]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3888 0.0817 0.5353 0.5436], Lowest was [0.3888 0.0817 0.5353 0.5378]
Median for last 10 epochs: [0.5404 0.0886 0.5354 0.5536], Epochs since improvement 0
  4%|▍         | 19/500 [16:34<6:47:58, 50.89s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 4.75E+06, Train scatter: [0.2699 0.0781 0.5439 0.525 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2767 0.0789 0.5353 0.5233], Lowest was [0.2767 0.0789 0.5353 0.5233]
Median for last 10 epochs: [0.4689 0.0854 0.5353 0.5436], Epochs since improvement 0
  4%|▍         | 20/500 [17:46<7:38:48, 57.35s/it]  4%|▍         | 21/500 [18:27<6:59:02, 52.49s/it]  4%|▍         | 22/500 [19:33<7:28:21, 56.28s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.66E+06, Train scatter: [0.2749 0.0786 0.5439 0.5232]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2802 0.0792 0.5353 0.5233], Lowest was [0.2767 0.0789 0.5353 0.5233]
Median for last 10 epochs: [0.3888 0.0817 0.5353 0.5378], Epochs since improvement 2
  5%|▍         | 23/500 [20:14<6:51:14, 51.73s/it]  5%|▍         | 24/500 [21:18<7:20:20, 55.50s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.22E+06, Train scatter: [0.3086 0.077  0.5439 0.5188]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3151 0.0773 0.5354 0.5197], Lowest was [0.2767 0.0773 0.5353 0.5197]
Median for last 10 epochs: [0.3151 0.0792 0.5353 0.5233], Epochs since improvement 0
  5%|▌         | 25/500 [21:59<6:45:40, 51.24s/it]  5%|▌         | 26/500 [23:03<7:13:20, 54.85s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.13E+06, Train scatter: [0.2601 0.0751 0.5439 0.5171]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2658 0.0756 0.5353 0.5143], Lowest was [0.2658 0.0756 0.5353 0.5143]
Median for last 10 epochs: [0.2802 0.0789 0.5353 0.5233], Epochs since improvement 0
  5%|▌         | 27/500 [23:43<6:38:29, 50.55s/it]  6%|▌         | 28/500 [24:48<7:10:36, 54.74s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.06E+06, Train scatter: [0.2195 0.0749 0.5439 0.5087]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2272 0.0754 0.5353 0.5049], Lowest was [0.2272 0.0754 0.5353 0.5049]
Median for last 10 epochs: [0.2767 0.0773 0.5353 0.5197], Epochs since improvement 0
  6%|▌         | 29/500 [25:29<6:39:13, 50.86s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.00E+06, Train scatter: [0.2745 0.0745 0.5438 0.5481]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2763 0.0747 0.5353 0.5504], Lowest was [0.2272 0.0747 0.5353 0.5049]
Median for last 10 epochs: [0.2763 0.0756 0.5353 0.5197], Epochs since improvement 0
  6%|▌         | 30/500 [26:41<7:26:31, 57.00s/it]  6%|▌         | 31/500 [27:23<6:49:59, 52.45s/it]  6%|▋         | 32/500 [28:27<7:16:45, 55.99s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.98E+06, Train scatter: [0.2731 0.0752 0.5438 0.5379]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2776 0.0753 0.5353 0.5374], Lowest was [0.2272 0.0747 0.5353 0.5049]
Median for last 10 epochs: [0.2763 0.0754 0.5353 0.5197], Epochs since improvement 0
  7%|▋         | 33/500 [29:07<6:39:56, 51.39s/it]  7%|▋         | 34/500 [30:12<7:08:58, 55.23s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.95E+06, Train scatter: [0.243  0.0718 0.5438 0.5142]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2475 0.0722 0.5352 0.5147], Lowest was [0.2272 0.0722 0.5352 0.5049]
Median for last 10 epochs: [0.2658 0.0753 0.5353 0.5147], Epochs since improvement 0
  7%|▋         | 35/500 [30:52<6:33:46, 50.81s/it]  7%|▋         | 36/500 [31:55<7:01:38, 54.52s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.92E+06, Train scatter: [0.2188 0.0708 0.5438 0.5019]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2257 0.0716 0.5352 0.5   ], Lowest was [0.2257 0.0716 0.5352 0.5   ]
Median for last 10 epochs: [0.2475 0.0747 0.5353 0.5147], Epochs since improvement 0
  7%|▋         | 37/500 [32:36<6:28:06, 50.30s/it]  8%|▊         | 38/500 [33:40<6:59:42, 54.51s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.90E+06, Train scatter: [0.2568 0.0786 0.5437 0.5319]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2581 0.0791 0.5352 0.5318], Lowest was [0.2257 0.0716 0.5352 0.5   ]
Median for last 10 epochs: [0.2581 0.0747 0.5352 0.5318], Epochs since improvement 0
  8%|▊         | 39/500 [34:21<6:27:51, 50.48s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.89E+06, Train scatter: [0.2141 0.0692 0.5438 0.5   ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2217 0.0696 0.5352 0.4954], Lowest was [0.2217 0.0696 0.5352 0.4954]
Median for last 10 epochs: [0.2475 0.0722 0.5352 0.5147], Epochs since improvement 0
  8%|▊         | 40/500 [35:31<7:12:17, 56.39s/it]  8%|▊         | 41/500 [36:12<6:36:08, 51.78s/it]  8%|▊         | 42/500 [37:16<7:03:19, 55.46s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.92E+06, Train scatter: [0.2105 0.074  0.5438 0.5033]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2208 0.0733 0.5352 0.5065], Lowest was [0.2208 0.0696 0.5352 0.4954]
Median for last 10 epochs: [0.2257 0.0722 0.5352 0.5065], Epochs since improvement 0
  9%|▊         | 43/500 [37:58<6:31:24, 51.39s/it]  9%|▉         | 44/500 [39:01<6:56:37, 54.82s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.86E+06, Train scatter: [0.2576 0.0742 0.5438 0.5035]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2604 0.0741 0.5352 0.4999], Lowest was [0.2208 0.0696 0.5352 0.4954]
Median for last 10 epochs: [0.2257 0.0733 0.5352 0.5   ], Epochs since improvement 2
  9%|▉         | 45/500 [39:42<6:23:16, 50.54s/it]  9%|▉         | 46/500 [40:46<6:53:58, 54.71s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.75E+06, Train scatter: [0.2839 0.0752 0.5436 0.5597]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2806 0.0739 0.535  0.5555], Lowest was [0.2208 0.0696 0.535  0.4954]
Median for last 10 epochs: [0.2581 0.0739 0.5352 0.5065], Epochs since improvement 0
  9%|▉         | 47/500 [41:28<6:23:42, 50.82s/it] 10%|▉         | 48/500 [42:33<6:54:56, 55.08s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.38E+06, Train scatter: [0.2374 0.0739 0.5435 0.5239]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3135 0.0747 0.5349 0.5237], Lowest was [0.2208 0.0696 0.5349 0.4954]
Median for last 10 epochs: [0.2604 0.0739 0.5352 0.5065], Epochs since improvement 0
 10%|▉         | 49/500 [43:15<6:24:19, 51.13s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.34E+06, Train scatter: [0.2211 0.0691 0.5435 0.5134]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2289 0.0697 0.5349 0.5079], Lowest was [0.2208 0.0696 0.5349 0.4954]
Median for last 10 epochs: [0.2604 0.0739 0.535  0.5079], Epochs since improvement 0
 10%|█         | 50/500 [44:26<7:08:42, 57.16s/it] 10%|█         | 51/500 [45:07<6:32:05, 52.40s/it] 10%|█         | 52/500 [46:13<7:01:13, 56.41s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.31E+06, Train scatter: [0.2218 0.071  0.5435 0.5041]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2238 0.0698 0.5349 0.5029], Lowest was [0.2208 0.0696 0.5349 0.4954]
Median for last 10 epochs: [0.2604 0.0739 0.5349 0.5079], Epochs since improvement 0
 11%|█         | 53/500 [46:54<6:25:30, 51.75s/it] 11%|█         | 54/500 [48:00<6:55:46, 55.93s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.29E+06, Train scatter: [0.2184 0.0691 0.5434 0.5183]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3035 0.0691 0.5348 0.513 ], Lowest was [0.2208 0.0691 0.5348 0.4954]
Median for last 10 epochs: [0.2806 0.0698 0.5349 0.513 ], Epochs since improvement 0
 11%|█         | 55/500 [48:41<6:23:18, 51.68s/it] 11%|█         | 56/500 [49:46<6:50:34, 55.48s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.32E+06, Train scatter: [0.2275 0.0743 0.5434 0.4992]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2281 0.0738 0.5349 0.4979], Lowest was [0.2208 0.0691 0.5348 0.4954]
Median for last 10 epochs: [0.2289 0.0698 0.5349 0.5079], Epochs since improvement 2
 11%|█▏        | 57/500 [50:26<6:16:51, 51.04s/it] 12%|█▏        | 58/500 [51:31<6:45:41, 55.07s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.22E+06, Train scatter: [0.3799 0.078  0.5434 0.499 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3707 0.0773 0.5349 0.4909], Lowest was [0.2208 0.0691 0.5348 0.4909]
Median for last 10 epochs: [0.2289 0.0698 0.5349 0.5029], Epochs since improvement 0
 12%|█▏        | 59/500 [52:11<6:12:07, 50.63s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.17E+06, Train scatter: [0.2471 0.074  0.5434 0.5009]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2581 0.0736 0.5348 0.4933], Lowest was [0.2208 0.0691 0.5348 0.4909]
Median for last 10 epochs: [0.2581 0.0736 0.5349 0.4979], Epochs since improvement 2
 12%|█▏        | 60/500 [53:23<6:58:28, 57.06s/it] 12%|█▏        | 61/500 [54:04<6:21:08, 52.09s/it] 12%|█▏        | 62/500 [55:08<6:47:35, 55.83s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.22E+06, Train scatter: [0.3786 0.0782 0.5434 0.5543]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3712 0.0782 0.5349 0.5544], Lowest was [0.2208 0.0691 0.5348 0.4909]
Median for last 10 epochs: [0.3035 0.0738 0.5349 0.4979], Epochs since improvement 4
 13%|█▎        | 63/500 [55:49<6:13:26, 51.27s/it] 13%|█▎        | 64/500 [56:52<6:37:53, 54.76s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.24E+06, Train scatter: [0.4469 0.0792 0.5435 0.4988]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4332 0.0784 0.5349 0.4928], Lowest was [0.2208 0.0691 0.5348 0.4909]
Median for last 10 epochs: [0.3707 0.0773 0.5349 0.4933], Epochs since improvement 6
 13%|█▎        | 65/500 [57:33<6:08:12, 50.79s/it] 13%|█▎        | 66/500 [58:37<6:36:07, 54.76s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.17E+06, Train scatter: [0.3387 0.0751 0.5434 0.5001]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3301 0.0744 0.5348 0.4939], Lowest was [0.2208 0.0691 0.5348 0.4909]
Median for last 10 epochs: [0.3707 0.0773 0.5349 0.4933], Epochs since improvement 8
 13%|█▎        | 67/500 [59:18<6:03:55, 50.43s/it] 14%|█▎        | 68/500 [1:00:22<6:32:15, 54.48s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.23E+06, Train scatter: [0.4169 0.0826 0.5434 0.541 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4052 0.083  0.5348 0.5379], Lowest was [0.2208 0.0691 0.5348 0.4909]
Median for last 10 epochs: [0.3712 0.0782 0.5348 0.4939], Epochs since improvement 10
 14%|█▍        | 69/500 [1:01:03<6:02:10, 50.42s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.17E+06, Train scatter: [0.4724 0.0799 0.5432 0.5178]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4621 0.0801 0.5347 0.5155], Lowest was [0.2208 0.0691 0.5347 0.4909]
Median for last 10 epochs: [0.4052 0.0784 0.5348 0.5155], Epochs since improvement 0
 14%|█▍        | 70/500 [1:02:13<6:44:41, 56.47s/it] 14%|█▍        | 71/500 [1:02:54<6:09:23, 51.66s/it] 14%|█▍        | 72/500 [1:03:57<6:34:15, 55.27s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.16E+06, Train scatter: [0.5224 0.0858 0.5434 0.7306]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5197 0.0874 0.5349 0.7263], Lowest was [0.2208 0.0691 0.5347 0.4909]
Median for last 10 epochs: [0.4332 0.0801 0.5348 0.5155], Epochs since improvement 2
 15%|█▍        | 73/500 [1:04:38<6:01:34, 50.81s/it] 15%|█▍        | 74/500 [1:05:42<6:29:55, 54.92s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.15E+06, Train scatter: [0.3977 0.0803 0.5432 0.5434]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4034 0.0809 0.5346 0.5432], Lowest was [0.2208 0.0691 0.5346 0.4909]
Median for last 10 epochs: [0.4052 0.0809 0.5348 0.5379], Epochs since improvement 0
 15%|█▌        | 75/500 [1:06:24<6:00:58, 50.96s/it] 15%|█▌        | 76/500 [1:07:28<6:28:30, 54.98s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.07E+06, Train scatter: [0.2509 0.0782 0.5433 0.5086]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2536 0.078  0.5347 0.5056], Lowest was [0.2208 0.0691 0.5346 0.4909]
Median for last 10 epochs: [0.4052 0.0809 0.5347 0.5379], Epochs since improvement 2
 15%|█▌        | 77/500 [1:08:09<5:56:41, 50.60s/it] 16%|█▌        | 78/500 [1:09:12<6:23:01, 54.46s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.04E+06, Train scatter: [0.5494 0.1034 0.5435 0.6002]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5444 0.1016 0.535  0.5975], Lowest was [0.2208 0.0691 0.5346 0.4909]
Median for last 10 epochs: [0.4621 0.0809 0.5347 0.5432], Epochs since improvement 4
 16%|█▌        | 79/500 [1:09:53<5:52:27, 50.23s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.92E+06, Train scatter: [0.4324 0.0755 0.5435 0.5257]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.423  0.0759 0.5349 0.5223], Lowest was [0.2208 0.0691 0.5346 0.4909]
Median for last 10 epochs: [0.423  0.0809 0.5349 0.5432], Epochs since improvement 6
 16%|█▌        | 80/500 [1:11:04<6:36:46, 56.68s/it] 16%|█▌        | 81/500 [1:11:45<6:03:16, 52.02s/it] 16%|█▋        | 82/500 [1:12:49<6:25:48, 55.38s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.93E+06, Train scatter: [0.4161 0.0783 0.5434 0.5233]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4083 0.0783 0.5349 0.5203], Lowest was [0.2208 0.0691 0.5346 0.4909]
Median for last 10 epochs: [0.4083 0.0783 0.5349 0.5223], Epochs since improvement 8
 17%|█▋        | 83/500 [1:13:30<5:56:27, 51.29s/it] 17%|█▋        | 84/500 [1:14:35<6:24:08, 55.40s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.91E+06, Train scatter: [0.4372 0.0706 0.5433 0.5045]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4254 0.0705 0.5347 0.4996], Lowest was [0.2208 0.0691 0.5346 0.4909]
Median for last 10 epochs: [0.423  0.078  0.5349 0.5203], Epochs since improvement 10
 17%|█▋        | 85/500 [1:15:17<5:54:02, 51.19s/it] 17%|█▋        | 86/500 [1:16:20<6:18:46, 54.89s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.90E+06, Train scatter: [0.279  0.0706 0.5433 0.5009]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2778 0.0706 0.5348 0.4967], Lowest was [0.2208 0.0691 0.5346 0.4909]
Median for last 10 epochs: [0.423  0.0759 0.5349 0.5203], Epochs since improvement 12
 17%|█▋        | 87/500 [1:17:02<5:50:44, 50.95s/it] 18%|█▊        | 88/500 [1:18:07<6:17:53, 55.03s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.90E+06, Train scatter: [0.3508 0.0675 0.5433 0.5068]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3452 0.0676 0.5347 0.5012], Lowest was [0.2208 0.0676 0.5346 0.4909]
Median for last 10 epochs: [0.4083 0.0706 0.5348 0.5012], Epochs since improvement 0
 18%|█▊        | 89/500 [1:18:47<5:47:57, 50.80s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.87E+06, Train scatter: [0.4224 0.0668 0.5431 0.499 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.413  0.0673 0.5345 0.4946], Lowest was [0.2208 0.0673 0.5345 0.4909]
Median for last 10 epochs: [0.4083 0.0705 0.5347 0.4996], Epochs since improvement 0
 18%|█▊        | 90/500 [1:19:57<6:26:03, 56.50s/it] 18%|█▊        | 91/500 [1:20:38<5:53:46, 51.90s/it] 18%|█▊        | 92/500 [1:21:43<6:17:47, 55.56s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.88E+06, Train scatter: [0.4582 0.0739 0.5428 0.5224]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4466 0.0741 0.5343 0.5164], Lowest was [0.2208 0.0673 0.5343 0.4909]
Median for last 10 epochs: [0.413  0.0705 0.5347 0.4996], Epochs since improvement 0
 19%|█▊        | 93/500 [1:22:24<5:48:07, 51.32s/it] 19%|█▉        | 94/500 [1:23:27<6:11:55, 54.96s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.85E+06, Train scatter: [0.2125 0.0646 0.5427 0.4916]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2169 0.0649 0.5341 0.4877], Lowest was [0.2169 0.0649 0.5341 0.4877]
Median for last 10 epochs: [0.3452 0.0676 0.5345 0.4967], Epochs since improvement 0
 19%|█▉        | 95/500 [1:24:08<5:41:42, 50.62s/it] 19%|█▉        | 96/500 [1:25:12<6:07:42, 54.61s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.86E+06, Train scatter: [0.3024 0.0626 0.5421 0.4931]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2984 0.063  0.5336 0.4878], Lowest was [0.2169 0.063  0.5336 0.4877]
Median for last 10 epochs: [0.3452 0.0673 0.5343 0.4946], Epochs since improvement 0
 19%|█▉        | 97/500 [1:25:53<5:39:36, 50.56s/it] 20%|█▉        | 98/500 [1:26:58<6:08:35, 55.01s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.85E+06, Train scatter: [0.2184 0.0681 0.5409 0.4941]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2227 0.0681 0.5324 0.4891], Lowest was [0.2169 0.063  0.5324 0.4877]
Median for last 10 epochs: [0.2984 0.0673 0.5341 0.4891], Epochs since improvement 0
 20%|█▉        | 99/500 [1:27:39<5:38:44, 50.69s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 2.64E+06, Train scatter: [0.215  0.0637 0.5391 0.4868]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.22   0.0635 0.5306 0.4822], Lowest was [0.2169 0.063  0.5306 0.4822]
Median for last 10 epochs: [0.2227 0.0649 0.5336 0.4878], Epochs since improvement 0
 20%|██        | 100/500 [1:28:49<6:16:40, 56.50s/it] 20%|██        | 101/500 [1:29:30<5:45:39, 51.98s/it] 20%|██        | 102/500 [1:30:34<6:08:18, 55.52s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 2.66E+06, Train scatter: [0.2283 0.0633 0.5369 0.4998]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2309 0.0632 0.5285 0.4944], Lowest was [0.2169 0.063  0.5285 0.4822]
Median for last 10 epochs: [0.2227 0.0635 0.5324 0.4878], Epochs since improvement 0
 21%|██        | 103/500 [1:31:16<5:39:37, 51.33s/it] 21%|██        | 104/500 [1:32:20<6:04:52, 55.28s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 2.81E+06, Train scatter: [0.8736 0.1709 0.544  0.9671]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.861  0.1672 0.5354 0.9581], Lowest was [0.2169 0.063  0.5285 0.4822]
Median for last 10 epochs: [0.2309 0.0635 0.5324 0.4891], Epochs since improvement 2
 21%|██        | 105/500 [1:33:00<5:34:11, 50.76s/it] 21%|██        | 106/500 [1:34:05<6:00:06, 54.84s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 2.73E+06, Train scatter: [0.5155 0.0972 0.5404 0.5443]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5099 0.0955 0.5317 0.5386], Lowest was [0.2169 0.063  0.5285 0.4822]
Median for last 10 epochs: [0.2309 0.0681 0.5317 0.4944], Epochs since improvement 4
 21%|██▏       | 107/500 [1:34:47<5:33:38, 50.94s/it] 22%|██▏       | 108/500 [1:35:52<6:00:27, 55.17s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 2.66E+06, Train scatter: [0.3894 0.0746 0.5373 0.5235]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3831 0.0739 0.5288 0.5228], Lowest was [0.2169 0.063  0.5285 0.4822]
Median for last 10 epochs: [0.3831 0.0739 0.5306 0.5228], Epochs since improvement 6
 22%|██▏       | 109/500 [1:36:33<5:31:44, 50.91s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 2.53E+06, Train scatter: [0.4032 0.0834 0.4178 0.5703]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3979 0.0835 0.4176 0.5714], Lowest was [0.2169 0.063  0.4176 0.4822]
Median for last 10 epochs: [0.3979 0.0835 0.5288 0.5386], Epochs since improvement 0
 22%|██▏       | 110/500 [1:37:44<6:10:40, 57.03s/it] 22%|██▏       | 111/500 [1:38:25<5:37:54, 52.12s/it] 22%|██▏       | 112/500 [1:39:30<6:02:42, 56.09s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.97E+06, Train scatter: [0.3528 0.0727 0.4361 0.5252]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3447 0.0728 0.4332 0.5268], Lowest was [0.2169 0.063  0.4176 0.4822]
Median for last 10 epochs: [0.3979 0.0835 0.5288 0.5386], Epochs since improvement 2
 23%|██▎       | 113/500 [1:40:12<5:33:43, 51.74s/it] 23%|██▎       | 114/500 [1:41:15<5:55:09, 55.20s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.86E+06, Train scatter: [0.289  0.0679 0.4236 0.5112]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2914 0.0685 0.4242 0.5154], Lowest was [0.2169 0.063  0.4176 0.4822]
Median for last 10 epochs: [0.3831 0.0739 0.4332 0.5268], Epochs since improvement 4
 23%|██▎       | 115/500 [1:41:57<5:28:51, 51.25s/it] 23%|██▎       | 116/500 [1:43:01<5:53:31, 55.24s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.77E+06, Train scatter: [0.2718 0.0631 0.3913 0.4974]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2763 0.0644 0.3958 0.5044], Lowest was [0.2169 0.063  0.3958 0.4822]
Median for last 10 epochs: [0.3447 0.0728 0.4242 0.5228], Epochs since improvement 0
 23%|██▎       | 117/500 [1:43:42<5:23:53, 50.74s/it] 24%|██▎       | 118/500 [1:44:46<5:49:24, 54.88s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.76E+06, Train scatter: [0.2803 0.0665 0.3606 0.4909]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2768 0.0656 0.3655 0.4876], Lowest was [0.2169 0.063  0.3655 0.4822]
Median for last 10 epochs: [0.2914 0.0685 0.4176 0.5154], Epochs since improvement 0
 24%|██▍       | 119/500 [1:45:29<5:24:42, 51.14s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.70E+06, Train scatter: [0.2667 0.0605 0.3613 0.4838]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2594 0.0602 0.3676 0.4832], Lowest was [0.2169 0.0602 0.3655 0.4822]
Median for last 10 epochs: [0.2768 0.0656 0.3958 0.5044], Epochs since improvement 0
 24%|██▍       | 120/500 [1:46:43<6:08:11, 58.14s/it] 24%|██▍       | 121/500 [1:47:24<5:34:33, 52.96s/it] 24%|██▍       | 122/500 [1:48:28<5:55:00, 56.35s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 1.68E+06, Train scatter: [0.3705 0.0774 0.3511 0.6962]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.355  0.0739 0.3544 0.6827], Lowest was [0.2169 0.0602 0.3544 0.4822]
Median for last 10 epochs: [0.2768 0.0656 0.3676 0.5044], Epochs since improvement 0
 25%|██▍       | 123/500 [1:49:09<5:23:50, 51.54s/it] 25%|██▍       | 124/500 [1:50:14<5:48:26, 55.60s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.65E+06, Train scatter: [0.4049 0.0606 0.4279 0.4855]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.391  0.0619 0.4363 0.4886], Lowest was [0.2169 0.0602 0.3544 0.4822]
Median for last 10 epochs: [0.2768 0.0644 0.3676 0.4886], Epochs since improvement 2
 25%|██▌       | 125/500 [1:50:55<5:20:13, 51.24s/it] 25%|██▌       | 126/500 [1:52:00<5:45:06, 55.37s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.63E+06, Train scatter: [0.3157 0.0598 0.3488 0.4845]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3197 0.0599 0.3532 0.4812], Lowest was [0.2169 0.0599 0.3532 0.4812]
Median for last 10 epochs: [0.3197 0.0619 0.3655 0.4876], Epochs since improvement 0
 25%|██▌       | 127/500 [1:52:40<5:16:33, 50.92s/it] 26%|██▌       | 128/500 [1:53:45<5:40:39, 54.95s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 1.64E+06, Train scatter: [0.2518 0.0584 0.3301 0.4798]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2537 0.0573 0.3335 0.4817], Lowest was [0.2169 0.0573 0.3335 0.4812]
Median for last 10 epochs: [0.3197 0.0602 0.3544 0.4832], Epochs since improvement 0
 26%|██▌       | 129/500 [1:54:25<5:13:27, 50.70s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 1.61E+06, Train scatter: [0.3176 0.069  0.3841 0.4905]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.334  0.0717 0.3949 0.5035], Lowest was [0.2169 0.0573 0.3335 0.4812]
Median for last 10 epochs: [0.334  0.0619 0.3544 0.4886], Epochs since improvement 2
 26%|██▌       | 130/500 [1:55:37<5:50:39, 56.86s/it] 26%|██▌       | 131/500 [1:56:18<5:20:21, 52.09s/it] 26%|██▋       | 132/500 [1:57:22<5:42:07, 55.78s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 1.60E+06, Train scatter: [0.2547 0.0615 0.3923 0.5235]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2581 0.0626 0.3988 0.5312], Lowest was [0.2169 0.0573 0.3335 0.4812]
Median for last 10 epochs: [0.3197 0.0619 0.3949 0.4886], Epochs since improvement 4
 27%|██▋       | 133/500 [1:58:02<5:13:07, 51.19s/it] 27%|██▋       | 134/500 [1:59:06<5:34:51, 54.90s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 1.56E+06, Train scatter: [0.2549 0.0588 0.3169 0.4684]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2521 0.0576 0.3185 0.4647], Lowest was [0.2169 0.0573 0.3185 0.4647]
Median for last 10 epochs: [0.2581 0.0599 0.3532 0.4817], Epochs since improvement 0
 27%|██▋       | 135/500 [1:59:47<5:08:24, 50.70s/it] 27%|██▋       | 136/500 [2:00:50<5:30:25, 54.46s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 1.55E+06, Train scatter: [0.2315 0.0556 0.3554 0.4621]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2392 0.0557 0.3602 0.4599], Lowest was [0.2169 0.0557 0.3185 0.4599]
Median for last 10 epochs: [0.2537 0.0576 0.3602 0.4817], Epochs since improvement 0
 27%|██▋       | 137/500 [2:01:30<5:03:31, 50.17s/it] 28%|██▊       | 138/500 [2:02:34<5:27:35, 54.30s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: 1.52E+06, Train scatter: [0.2275 0.055  0.3383 0.4738]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2355 0.0552 0.344  0.4715], Lowest was [0.2169 0.0552 0.3185 0.4599]
Median for last 10 epochs: [0.2521 0.0576 0.3602 0.4715], Epochs since improvement 0
 28%|██▊       | 139/500 [2:03:15<5:02:27, 50.27s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: 1.50E+06, Train scatter: [0.2489 0.061  0.4462 0.4998]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2534 0.062  0.4525 0.4988], Lowest was [0.2169 0.0552 0.3185 0.4599]
Median for last 10 epochs: [0.2521 0.0576 0.3602 0.4715], Epochs since improvement 2
 28%|██▊       | 140/500 [2:04:26<5:38:05, 56.35s/it] 28%|██▊       | 141/500 [2:05:07<5:10:04, 51.82s/it] 28%|██▊       | 142/500 [2:06:11<5:30:34, 55.41s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: 1.47E+06, Train scatter: [0.2222 0.0577 0.4856 0.4709]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2314 0.0595 0.4906 0.4754], Lowest was [0.2169 0.0552 0.3185 0.4599]
Median for last 10 epochs: [0.2392 0.0576 0.3602 0.4715], Epochs since improvement 4
 29%|██▊       | 143/500 [2:06:51<5:02:32, 50.85s/it] 29%|██▉       | 144/500 [2:07:55<5:25:57, 54.94s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 1.41E+06, Train scatter: [0.2137 0.0551 0.3098 0.4567]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2194 0.0542 0.3143 0.4519], Lowest was [0.2169 0.0542 0.3143 0.4519]
Median for last 10 epochs: [0.2355 0.0557 0.3602 0.4715], Epochs since improvement 0
 29%|██▉       | 145/500 [2:08:36<4:59:01, 50.54s/it] 29%|██▉       | 146/500 [2:09:40<5:22:06, 54.60s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 1.86E+06, Train scatter: [0.2228 0.0576 0.3456 0.4599]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2285 0.0581 0.351  0.4574], Lowest was [0.2169 0.0542 0.3143 0.4519]
Median for last 10 epochs: [0.2314 0.0581 0.351  0.4715], Epochs since improvement 2
 29%|██▉       | 147/500 [2:10:21<4:57:59, 50.65s/it] 30%|██▉       | 148/500 [2:11:24<5:18:05, 54.22s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 1.11E+06, Train scatter: [0.2201 0.0539 0.358  0.4643]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2262 0.0546 0.3636 0.4682], Lowest was [0.2169 0.0542 0.3143 0.4519]
Median for last 10 epochs: [0.2285 0.0581 0.3636 0.4682], Epochs since improvement 4
 30%|██▉       | 149/500 [2:12:05<4:53:39, 50.20s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 7.58E+05, Train scatter: [0.2182 0.0536 0.2857 0.4582]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2227 0.053  0.2893 0.4587], Lowest was [0.2169 0.053  0.2893 0.4519]
Median for last 10 epochs: [0.2262 0.0546 0.351  0.4587], Epochs since improvement 0
 30%|███       | 150/500 [2:13:14<5:26:00, 55.89s/it] 30%|███       | 151/500 [2:13:54<4:57:34, 51.16s/it] 30%|███       | 152/500 [2:14:59<5:20:23, 55.24s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 4.81E+05, Train scatter: [0.2572 0.053  0.2853 0.4626]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2539 0.053  0.2887 0.4593], Lowest was [0.2169 0.053  0.2887 0.4519]
Median for last 10 epochs: [0.2262 0.0542 0.3143 0.4587], Epochs since improvement 0
 31%|███       | 153/500 [2:15:39<4:53:48, 50.80s/it] 31%|███       | 154/500 [2:16:42<5:14:47, 54.59s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 4.09E+05, Train scatter: [0.2525 0.0524 0.2665 0.4706]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.248  0.0522 0.2724 0.4745], Lowest was [0.2169 0.0522 0.2724 0.4519]
Median for last 10 epochs: [0.2285 0.053  0.2893 0.4593], Epochs since improvement 0
 31%|███       | 155/500 [2:17:23<4:49:47, 50.40s/it] 31%|███       | 156/500 [2:18:28<5:14:08, 54.79s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 3.55E+05, Train scatter: [0.2417 0.0593 0.2646 0.4825]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2492 0.0596 0.2686 0.4886], Lowest was [0.2169 0.0522 0.2686 0.4519]
Median for last 10 epochs: [0.248  0.053  0.2887 0.4682], Epochs since improvement 0
 31%|███▏      | 157/500 [2:19:08<4:48:14, 50.42s/it] 32%|███▏      | 158/500 [2:20:11<5:09:06, 54.23s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 3.19E+05, Train scatter: [0.2372 0.0521 0.2805 0.4561]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2396 0.0531 0.2901 0.4578], Lowest was [0.2169 0.0522 0.2686 0.4519]
Median for last 10 epochs: [0.248  0.053  0.2887 0.4593], Epochs since improvement 2
 32%|███▏      | 159/500 [2:20:52<4:44:33, 50.07s/it]Epoch: 160 done with learning rate 9.04E-03, Train loss: 2.84E+05, Train scatter: [0.2087 0.0509 0.2718 0.4482]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.217  0.0524 0.2831 0.4475], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [0.248  0.053  0.2831 0.4593], Epochs since improvement 0
 32%|███▏      | 160/500 [2:22:03<5:19:06, 56.31s/it] 32%|███▏      | 161/500 [2:22:44<4:52:52, 51.84s/it] 32%|███▏      | 162/500 [2:23:48<5:13:04, 55.57s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: 3.02E+05, Train scatter: [0.2637 0.0524 0.3194 0.4528]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2709 0.0548 0.3299 0.4529], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [0.248  0.0531 0.2831 0.4578], Epochs since improvement 2
 33%|███▎      | 163/500 [2:24:29<4:47:07, 51.12s/it] 33%|███▎      | 164/500 [2:25:33<5:07:13, 54.86s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: 1.47E+07, Train scatter: [0.9344 0.1724 0.5441 0.9934]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9189 0.1686 0.5355 0.9832], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [0.2492 0.0548 0.2901 0.4578], Epochs since improvement 4
 33%|███▎      | 165/500 [2:26:14<4:43:20, 50.75s/it] 33%|███▎      | 166/500 [2:27:19<5:07:23, 55.22s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: 1.05E+07, Train scatter: [0.9332 0.1678 0.5441 0.9909]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9177 0.1644 0.5355 0.9808], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [0.2709 0.0548 0.3299 0.4578], Epochs since improvement 6
 33%|███▎      | 167/500 [2:28:01<4:43:36, 51.10s/it] 34%|███▎      | 168/500 [2:29:05<5:03:51, 54.91s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: 9.62E+06, Train scatter: [0.9314 0.1528 0.5441 0.988 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9159 0.1505 0.5355 0.978 ], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [0.9159 0.1505 0.5355 0.978 ], Epochs since improvement 8
 34%|███▍      | 169/500 [2:29:46<4:40:39, 50.87s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: 9.16E+06, Train scatter: [0.9269 0.1411 0.5441 0.9769]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9116 0.1391 0.5355 0.967 ], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [0.9159 0.1505 0.5355 0.978 ], Epochs since improvement 10
 34%|███▍      | 170/500 [2:30:58<5:13:41, 57.04s/it] 34%|███▍      | 171/500 [2:31:39<4:46:38, 52.27s/it] 34%|███▍      | 172/500 [2:32:44<5:07:01, 56.16s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: 8.32E+06, Train scatter: [0.8953 0.1257 0.5439 0.9235]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9862 0.1251 0.5354 0.9119], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [0.9177 0.1505 0.5355 0.978 ], Epochs since improvement 12
 35%|███▍      | 173/500 [2:33:25<4:40:36, 51.49s/it] 35%|███▍      | 174/500 [2:34:30<5:02:37, 55.70s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: 7.62E+06, Train scatter: [1.0106 0.1178 0.5438 0.8583]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [1.1954 0.1178 0.5352 0.8444], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [0.9177 0.1391 0.5355 0.967 ], Epochs since improvement 14
 35%|███▌      | 175/500 [2:35:11<4:37:42, 51.27s/it] 35%|███▌      | 176/500 [2:36:14<4:56:19, 54.87s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: 6.98E+06, Train scatter: [1.0959 0.1177 0.5437 0.8315]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [1.3287 0.1169 0.5351 0.8177], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [0.9862 0.1251 0.5354 0.9119], Epochs since improvement 16
 35%|███▌      | 177/500 [2:36:55<4:32:13, 50.57s/it] 36%|███▌      | 178/500 [2:37:59<4:53:17, 54.65s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: 6.52E+06, Train scatter: [0.9521 0.1163 0.5436 0.8264]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [1.0536 0.1125 0.535  0.8145], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [1.0536 0.1178 0.5352 0.8444], Epochs since improvement 18
 36%|███▌      | 179/500 [2:38:40<4:30:46, 50.61s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: 6.16E+06, Train scatter: [1.0713 0.114  0.5435 0.8116]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [1.265  0.1125 0.5349 0.7997], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [1.1954 0.1169 0.5351 0.8177], Epochs since improvement 20
 36%|███▌      | 180/500 [2:39:51<5:01:47, 56.59s/it] 36%|███▌      | 181/500 [2:40:31<4:35:09, 51.76s/it] 36%|███▌      | 181/500 [2:41:35<4:44:48, 53.57s/it]
Epoch: 182 done with learning rate 8.52E-03, Train loss: 5.83E+06, Train scatter: [1.04   0.1115 0.5433 0.8051]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [1.2099 0.1102 0.5347 0.7942], Lowest was [0.2169 0.0522 0.2686 0.4475]
Median for last 10 epochs: [1.2099 0.1125 0.535  0.8145], Epochs since improvement 22
Exited after 182 epochs due to early stopping
9695.73 seconds spent training, 19.391 seconds per epoch. Processed 3591 trees per second
[1.2098273  0.11020073 0.53464234 0.79416746]
{'epoch_exit': 181, 'scatter_m_star': 1.2098273, 'lowest_m_star': 0.216881, 'last20_m_star': 1.0199215, 'last10_m_star': 1.209863, 'scatter_v_disk': 0.11020073, 'lowest_v_disk': 0.05222314, 'last20_v_disk': 0.12142775, 'last10_v_disk': 0.11250392, 'scatter_m_cold': 0.53464234, 'lowest_m_cold': 0.26860663, 'last20_m_cold': 0.5352875, 'last10_m_cold': 0.5350224, 'scatter_sfr_100': 0.79416746, 'lowest_sfr_100': 0.44751635, 'last20_sfr_100': 0.87816674, 'last10_sfr_100': 0.8144548}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_molnpl
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:01<8:31:10, 61.46s/it]  0%|          | 2/500 [02:32<10:53:23, 78.72s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.34E+07, Train scatter: [0.9351 0.1289 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1248 0.5355 0.9851], Lowest was [0.9195 0.1248 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1248 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:34<9:47:56, 70.98s/it]   1%|          | 4/500 [05:05<10:52:52, 78.98s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.34E+07, Train scatter: [0.9307 0.1038 0.5429 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9147 0.1044 0.5342 0.9851], Lowest was [0.9147 0.1044 0.5342 0.9851]
Median for last 10 epochs: [0.9147 0.1044 0.5342 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:06<9:58:41, 72.57s/it]   1%|          | 6/500 [07:40<10:58:36, 79.99s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.09E+07, Train scatter: [0.9167 0.0972 0.5333 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9007 0.0977 0.525  0.985 ], Lowest was [0.9007 0.0977 0.525  0.985 ]
Median for last 10 epochs: [0.9007 0.0977 0.525  0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [08:44<10:13:41, 74.69s/it]  2%|▏         | 8/500 [10:16<10:57:10, 80.14s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.77E+07, Train scatter: [0.7464 0.0992 0.4007 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7337 0.1023 0.3988 0.9849], Lowest was [0.7337 0.0977 0.3988 0.9849]
Median for last 10 epochs: [0.8172 0.1    0.4619 0.985 ], Epochs since improvement 0
  2%|▏         | 9/500 [11:18<10:10:22, 74.59s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.61E+07, Train scatter: [0.604  0.0906 0.3683 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6018 0.0912 0.3708 0.985 ], Lowest was [0.6018 0.0912 0.3708 0.9849]
Median for last 10 epochs: [0.7337 0.0977 0.3988 0.985 ], Epochs since improvement 0
  2%|▏         | 10/500 [12:57<11:09:10, 81.94s/it]  2%|▏         | 11/500 [13:59<10:19:10, 75.97s/it]  2%|▏         | 12/500 [15:30<10:55:42, 80.62s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.52E+07, Train scatter: [0.542  0.085  0.3696 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5403 0.0863 0.3747 0.985 ], Lowest was [0.5403 0.0863 0.3708 0.9849]
Median for last 10 epochs: [0.7337 0.0977 0.3988 0.985 ], Epochs since improvement 0
  3%|▎         | 13/500 [16:33<10:09:56, 75.15s/it]  3%|▎         | 14/500 [18:04<10:46:38, 79.83s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.73E+07, Train scatter: [0.5246 0.0829 0.3285 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.529  0.0839 0.3334 0.9849], Lowest was [0.529  0.0839 0.3334 0.9849]
Median for last 10 epochs: [0.6018 0.0912 0.3747 0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [19:07<10:05:57, 74.96s/it]  3%|▎         | 16/500 [20:40<10:47:10, 80.23s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.66E+07, Train scatter: [0.4631 0.0798 0.3533 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4605 0.0796 0.3551 0.985 ], Lowest was [0.4605 0.0796 0.3334 0.9849]
Median for last 10 epochs: [0.5403 0.0863 0.3708 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [21:41<10:00:57, 74.65s/it]  4%|▎         | 18/500 [23:15<10:45:33, 80.36s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.73E+07, Train scatter: [0.5611 0.0755 0.3181 0.9947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5512 0.0753 0.3196 0.9846], Lowest was [0.4605 0.0753 0.3196 0.9846]
Median for last 10 epochs: [0.5403 0.0839 0.3551 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [24:18<10:02:19, 75.13s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 9.46E+06, Train scatter: [0.5265 0.0837 0.3302 0.6105]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.507  0.0833 0.3321 0.6101], Lowest was [0.4605 0.0753 0.3196 0.6101]
Median for last 10 epochs: [0.529  0.0833 0.3334 0.9849], Epochs since improvement 0
  4%|▍         | 20/500 [25:57<10:58:38, 82.33s/it]  4%|▍         | 21/500 [26:59<10:08:39, 76.24s/it]  4%|▍         | 22/500 [28:33<10:49:26, 81.52s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.98E+06, Train scatter: [0.4299 0.0723 0.309  0.5194]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4194 0.072  0.3136 0.5221], Lowest was [0.4194 0.072  0.3136 0.5221]
Median for last 10 epochs: [0.507  0.0796 0.3321 0.9846], Epochs since improvement 0
  5%|▍         | 23/500 [29:36<10:04:23, 76.02s/it]  5%|▍         | 24/500 [31:10<10:45:07, 81.32s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.65E+06, Train scatter: [0.4382 0.0726 0.3072 0.4977]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4317 0.0721 0.3092 0.496 ], Lowest was [0.4194 0.072  0.3092 0.496 ]
Median for last 10 epochs: [0.4605 0.0753 0.3196 0.6101], Epochs since improvement 0
  5%|▌         | 25/500 [32:12<9:57:36, 75.49s/it]   5%|▌         | 26/500 [33:46<10:40:24, 81.06s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.15E+06, Train scatter: [0.5154 0.0728 0.3052 0.491 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5074 0.073  0.3092 0.4913], Lowest was [0.4194 0.072  0.3092 0.4913]
Median for last 10 epochs: [0.507  0.073  0.3136 0.5221], Epochs since improvement 0
  5%|▌         | 27/500 [34:48<9:53:35, 75.30s/it]   6%|▌         | 28/500 [36:21<10:34:25, 80.65s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.03E+06, Train scatter: [0.4525 0.0719 0.2986 0.4781]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4423 0.0717 0.3059 0.4771], Lowest was [0.4194 0.0717 0.3059 0.4771]
Median for last 10 epochs: [0.4423 0.0721 0.3092 0.496 ], Epochs since improvement 0
  6%|▌         | 29/500 [37:25<9:53:52, 75.65s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.97E+06, Train scatter: [0.4133 0.0699 0.2871 0.4684]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4038 0.0693 0.2918 0.469 ], Lowest was [0.4038 0.0693 0.2918 0.469 ]
Median for last 10 epochs: [0.4317 0.072  0.3092 0.4913], Epochs since improvement 0
  6%|▌         | 30/500 [39:03<10:45:43, 82.43s/it]  6%|▌         | 31/500 [40:07<9:59:57, 76.75s/it]   6%|▋         | 32/500 [41:40<10:37:51, 81.78s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.86E+06, Train scatter: [0.3793 0.0736 0.3048 0.4833]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3724 0.0739 0.3105 0.4863], Lowest was [0.3724 0.0693 0.2918 0.469 ]
Median for last 10 epochs: [0.4317 0.0721 0.3092 0.4863], Epochs since improvement 0
  7%|▋         | 33/500 [42:41<9:48:35, 75.62s/it]   7%|▋         | 34/500 [44:14<10:26:02, 80.61s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.75E+06, Train scatter: [0.3782 0.0702 0.2911 0.472 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3735 0.0695 0.2927 0.4698], Lowest was [0.3724 0.0693 0.2918 0.469 ]
Median for last 10 epochs: [0.4038 0.0717 0.3059 0.4771], Epochs since improvement 2
  7%|▋         | 35/500 [45:16<9:42:13, 75.13s/it]   7%|▋         | 36/500 [46:50<10:25:01, 80.82s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.84E+06, Train scatter: [0.3949 0.0695 0.2885 0.4898]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3916 0.0697 0.2927 0.4928], Lowest was [0.3724 0.0693 0.2918 0.469 ]
Median for last 10 epochs: [0.3916 0.0697 0.2927 0.4771], Epochs since improvement 4
  7%|▋         | 37/500 [47:53<9:42:38, 75.51s/it]   8%|▊         | 38/500 [49:27<10:24:52, 81.15s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.74E+06, Train scatter: [0.3297 0.0674 0.2903 0.4641]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3207 0.0673 0.2971 0.4662], Lowest was [0.3207 0.0673 0.2918 0.4662]
Median for last 10 epochs: [0.3735 0.0695 0.2927 0.4698], Epochs since improvement 0
  8%|▊         | 39/500 [50:29<9:37:30, 75.16s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.55E+06, Train scatter: [0.3415 0.066  0.2861 0.4695]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.346  0.0658 0.2925 0.4709], Lowest was [0.3207 0.0658 0.2918 0.4662]
Median for last 10 epochs: [0.3724 0.0695 0.2927 0.4709], Epochs since improvement 0
  8%|▊         | 40/500 [52:08<10:31:25, 82.36s/it]  8%|▊         | 41/500 [53:11<9:45:20, 76.52s/it]   8%|▊         | 42/500 [54:43<10:19:07, 81.11s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.45E+06, Train scatter: [0.3896 0.0648 0.2897 0.4616]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3898 0.0641 0.2939 0.4655], Lowest was [0.3207 0.0641 0.2918 0.4655]
Median for last 10 epochs: [0.3735 0.0673 0.2927 0.4698], Epochs since improvement 0
  9%|▊         | 43/500 [55:45<9:34:45, 75.46s/it]   9%|▉         | 44/500 [57:15<10:06:54, 79.86s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.41E+06, Train scatter: [0.4081 0.0653 0.2943 0.4737]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4018 0.0656 0.299  0.4756], Lowest was [0.3207 0.0641 0.2918 0.4655]
Median for last 10 epochs: [0.3898 0.0658 0.2939 0.4709], Epochs since improvement 2
  9%|▉         | 45/500 [58:17<9:26:07, 74.65s/it]   9%|▉         | 46/500 [59:50<10:04:28, 79.89s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.31E+06, Train scatter: [0.3151 0.0617 0.2876 0.4599]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3515 0.0615 0.2915 0.4588], Lowest was [0.3207 0.0615 0.2915 0.4588]
Median for last 10 epochs: [0.3515 0.0656 0.2939 0.4662], Epochs since improvement 0
  9%|▉         | 47/500 [1:00:52<9:22:33, 74.51s/it] 10%|▉         | 48/500 [1:02:23<9:59:51, 79.63s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.22E+06, Train scatter: [0.4067 0.0736 0.2742 0.4539]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.401  0.072  0.2762 0.4526], Lowest was [0.3207 0.0615 0.2762 0.4526]
Median for last 10 epochs: [0.3898 0.0656 0.2925 0.4655], Epochs since improvement 0
 10%|▉         | 49/500 [1:03:25<9:19:04, 74.38s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.05E+06, Train scatter: [0.3946 0.0563 0.3063 0.4684]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3937 0.0554 0.303  0.4687], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.3937 0.0641 0.2939 0.4655], Epochs since improvement 0
 10%|█         | 50/500 [1:05:06<10:16:51, 82.25s/it] 10%|█         | 51/500 [1:06:09<9:33:43, 76.67s/it]  10%|█         | 52/500 [1:07:43<10:10:02, 81.70s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.01E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.401  0.0656 0.299  0.4687], Epochs since improvement 2
 11%|█         | 53/500 [1:08:46<9:26:01, 75.98s/it]  11%|█         | 54/500 [1:10:17<9:58:19, 80.49s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.43E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.401  0.072  0.303  0.4687], Epochs since improvement 4
 11%|█         | 55/500 [1:11:17<9:13:16, 74.60s/it] 11%|█         | 56/500 [1:12:49<9:49:03, 79.60s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.25E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 6
 11%|█▏        | 57/500 [1:13:52<9:11:22, 74.68s/it] 12%|█▏        | 58/500 [1:15:25<9:51:31, 80.30s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.06E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 8
 12%|█▏        | 59/500 [1:16:27<9:09:56, 74.82s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.88E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 10
 12%|█▏        | 60/500 [1:18:06<10:00:26, 81.88s/it] 12%|█▏        | 61/500 [1:19:08<9:16:53, 76.11s/it]  12%|█▏        | 62/500 [1:20:41<9:51:03, 80.97s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.69E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 12
 13%|█▎        | 63/500 [1:21:43<9:10:01, 75.52s/it] 13%|█▎        | 64/500 [1:23:16<9:46:44, 80.74s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.51E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 14
 13%|█▎        | 65/500 [1:24:17<9:02:37, 74.84s/it] 13%|█▎        | 66/500 [1:25:50<9:40:11, 80.21s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.33E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 16
 13%|█▎        | 67/500 [1:26:52<8:58:47, 74.66s/it] 14%|█▎        | 68/500 [1:28:24<9:36:08, 80.02s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.17E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 18
 14%|█▍        | 69/500 [1:29:25<8:53:27, 74.26s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.02E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 20
 14%|█▍        | 70/500 [1:31:04<9:45:18, 81.67s/it] 14%|█▍        | 71/500 [1:32:06<9:00:47, 75.64s/it] 14%|█▍        | 71/500 [1:33:38<9:25:49, 79.14s/it]
Epoch: 72 done with learning rate 9.96E-03, Train loss: 8.82E+06, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3207 0.0554 0.2762 0.4526]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 22
Exited after 72 epochs due to early stopping
5618.67 seconds spent training, 11.237 seconds per epoch. Processed 6197 trees per second
[0.9195245  0.16898982 0.5354719  0.98495984]
{'epoch_exit': 71, 'scatter_m_star': 0.9195245, 'lowest_m_star': 0.32074234, 'last20_m_star': 0.9195762, 'last10_m_star': 0.9195743, 'scatter_v_disk': 0.16898982, 'lowest_v_disk': 0.05535602, 'last20_v_disk': 0.16899759, 'last10_v_disk': 0.16899541, 'scatter_m_cold': 0.5354719, 'lowest_m_cold': 0.2762124, 'last20_m_cold': 0.5354856, 'last10_m_cold': 0.5354857, 'scatter_sfr_100': 0.98495984, 'lowest_sfr_100': 0.45261067, 'last20_sfr_100': 0.9849771, 'last10_sfr_100': 0.98496556}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_vocjhq
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:21:28, 53.08s/it]  0%|          | 2/500 [02:13<9:35:33, 69.35s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.17   0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1647 0.5355 0.985 ], Lowest was [0.9196 0.1647 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1647 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:06<8:33:07, 61.95s/it]  1%|          | 4/500 [04:28<9:35:07, 69.57s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 9.06E+07, Train scatter: [0.9352 0.1466 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1416 0.5355 0.9851], Lowest was [0.9196 0.1416 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1416 0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:22<8:49:28, 64.18s/it]  1%|          | 6/500 [06:45<9:41:04, 70.58s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.60E+07, Train scatter: [0.935  0.1256 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9194 0.1238 0.5355 0.9851], Lowest was [0.9194 0.1238 0.5355 0.985 ]
Median for last 10 epochs: [0.9194 0.1238 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:39<8:53:33, 64.94s/it]  2%|▏         | 8/500 [09:01<9:38:54, 70.60s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.31E+07, Train scatter: [0.9324 0.1028 0.5436 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9167 0.1028 0.535  0.9851], Lowest was [0.9167 0.1028 0.535  0.985 ]
Median for last 10 epochs: [0.9181 0.1133 0.5353 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [09:55<8:53:24, 65.18s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.12E+07, Train scatter: [0.8117 0.0948 0.5409 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7995 0.0961 0.5324 0.985 ], Lowest was [0.7995 0.0961 0.5324 0.985 ]
Median for last 10 epochs: [0.9167 0.1028 0.535  0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:24<9:53:06, 72.63s/it]  2%|▏         | 11/500 [12:18<9:04:39, 66.83s/it]  2%|▏         | 12/500 [13:39<9:40:38, 71.39s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.98E+07, Train scatter: [0.6218 0.0896 0.5326 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6156 0.0897 0.5249 0.985 ], Lowest was [0.6156 0.0897 0.5249 0.985 ]
Median for last 10 epochs: [0.9167 0.1028 0.535  0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:34<8:57:48, 66.26s/it]  3%|▎         | 14/500 [15:54<9:31:43, 70.58s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.90E+07, Train scatter: [0.5252 0.0877 0.5322 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5247 0.0886 0.5247 0.985 ], Lowest was [0.5247 0.0886 0.5247 0.985 ]
Median for last 10 epochs: [0.7995 0.0961 0.5324 0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [16:49<8:51:52, 65.80s/it]  3%|▎         | 16/500 [18:13<9:33:51, 71.14s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.89E+07, Train scatter: [0.7911 0.0977 0.544  0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7748 0.0988 0.5354 0.985 ], Lowest was [0.5247 0.0886 0.5247 0.985 ]
Median for last 10 epochs: [0.7748 0.0961 0.5324 0.985 ], Epochs since improvement 2
  3%|▎         | 17/500 [19:07<8:52:47, 66.18s/it]  4%|▎         | 18/500 [20:30<9:31:27, 71.14s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.79E+07, Train scatter: [0.4749 0.0845 0.5246 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4753 0.085  0.517  0.9849], Lowest was [0.4753 0.085  0.517  0.9849]
Median for last 10 epochs: [0.6156 0.0897 0.5249 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [21:24<8:49:42, 66.08s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.65E+07, Train scatter: [0.5569 0.0923 0.4543 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5577 0.0917 0.4525 0.985 ], Lowest was [0.4753 0.085  0.4525 0.9849]
Median for last 10 epochs: [0.5577 0.0897 0.5247 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:53<9:42:08, 72.77s/it]  4%|▍         | 21/500 [23:47<8:56:56, 67.26s/it]  4%|▍         | 22/500 [25:11<9:34:40, 72.13s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.52E+07, Train scatter: [0.5342 0.0905 0.3804 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5507 0.0911 0.3774 0.985 ], Lowest was [0.4753 0.085  0.3774 0.9849]
Median for last 10 epochs: [0.5507 0.0911 0.517  0.985 ], Epochs since improvement 0
  5%|▍         | 23/500 [26:04<8:48:46, 66.51s/it]  5%|▍         | 24/500 [27:28<9:28:22, 71.64s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.46E+07, Train scatter: [0.542  0.0847 0.3513 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5457 0.0867 0.3588 0.9849], Lowest was [0.4753 0.085  0.3588 0.9849]
Median for last 10 epochs: [0.5507 0.0911 0.4525 0.985 ], Epochs since improvement 0
  5%|▌         | 25/500 [28:21<8:43:44, 66.16s/it]  5%|▌         | 26/500 [29:44<9:21:25, 71.07s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.42E+07, Train scatter: [0.5131 0.084  0.3462 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.523  0.0871 0.3526 0.985 ], Lowest was [0.4753 0.085  0.3526 0.9849]
Median for last 10 epochs: [0.5457 0.0871 0.3774 0.985 ], Epochs since improvement 0
  5%|▌         | 27/500 [30:37<8:39:07, 65.85s/it]  6%|▌         | 28/500 [32:01<9:19:36, 71.14s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.38E+07, Train scatter: [0.5694 0.0818 0.3989 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5889 0.0823 0.4038 0.9851], Lowest was [0.4753 0.0823 0.3526 0.9849]
Median for last 10 epochs: [0.5507 0.0871 0.3774 0.985 ], Epochs since improvement 0
  6%|▌         | 29/500 [32:54<8:36:29, 65.79s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.35E+07, Train scatter: [0.5674 0.0827 0.3503 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5659 0.0842 0.3585 0.985 ], Lowest was [0.4753 0.0823 0.3526 0.9849]
Median for last 10 epochs: [0.5507 0.0867 0.3588 0.985 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [34:23<9:30:39, 72.85s/it]  6%|▌         | 31/500 [35:17<8:44:57, 67.16s/it]  6%|▋         | 32/500 [36:39<9:19:14, 71.70s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.31E+07, Train scatter: [0.5476 0.0779 0.3118 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5313 0.0786 0.3133 0.985 ], Lowest was [0.4753 0.0786 0.3133 0.9849]
Median for last 10 epochs: [0.5457 0.0842 0.3585 0.985 ], Epochs since improvement 0
  7%|▋         | 33/500 [37:35<8:39:09, 66.70s/it]  7%|▋         | 34/500 [38:56<9:11:27, 71.00s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.28E+07, Train scatter: [0.4657 0.0808 0.3314 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4689 0.0816 0.3389 0.9851], Lowest was [0.4689 0.0786 0.3133 0.9849]
Median for last 10 epochs: [0.5313 0.0823 0.3526 0.985 ], Epochs since improvement 0
  7%|▋         | 35/500 [39:50<8:31:53, 66.05s/it]  7%|▋         | 36/500 [41:11<9:06:12, 70.63s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.22E+07, Train scatter: [0.5101 0.0902 0.3168 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5019 0.0867 0.3186 0.985 ], Lowest was [0.4689 0.0786 0.3133 0.9849]
Median for last 10 epochs: [0.5313 0.0823 0.3389 0.985 ], Epochs since improvement 2
  7%|▋         | 37/500 [42:06<8:27:20, 65.75s/it]  8%|▊         | 38/500 [43:28<9:03:58, 70.65s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.58E+07, Train scatter: [0.6672 0.0795 0.325  0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6352 0.078  0.3319 0.9849], Lowest was [0.4689 0.078  0.3133 0.9849]
Median for last 10 epochs: [0.5313 0.0816 0.3319 0.985 ], Epochs since improvement 0
  8%|▊         | 39/500 [44:22<8:24:22, 65.65s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.85E+07, Train scatter: [0.4428 0.0749 0.3269 0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.441  0.0754 0.3341 0.9848], Lowest was [0.441  0.0754 0.3133 0.9848]
Median for last 10 epochs: [0.5019 0.0786 0.3319 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:52<9:18:47, 72.88s/it]  8%|▊         | 41/500 [46:45<8:32:57, 67.05s/it]  8%|▊         | 42/500 [48:06<9:03:54, 71.25s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 7.78E+06, Train scatter: [0.5507 0.0884 0.3436 0.5831]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5627 0.0894 0.3527 0.5847], Lowest was [0.441  0.0754 0.3133 0.5847]
Median for last 10 epochs: [0.5019 0.0816 0.3341 0.9849], Epochs since improvement 0
  9%|▊         | 43/500 [49:01<8:25:14, 66.33s/it]  9%|▉         | 44/500 [50:23<9:00:00, 71.05s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.23E+06, Train scatter: [0.425  0.0784 0.3327 0.5568]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4182 0.0789 0.3375 0.5582], Lowest was [0.4182 0.0754 0.3133 0.5582]
Median for last 10 epochs: [0.5019 0.0789 0.3341 0.9848], Epochs since improvement 0
  9%|▉         | 45/500 [51:17<8:20:45, 66.04s/it]  9%|▉         | 46/500 [52:40<8:57:18, 71.01s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.79E+06, Train scatter: [0.4492 0.0771 0.3108 0.5241]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4479 0.0782 0.3167 0.5238], Lowest was [0.4182 0.0754 0.3133 0.5238]
Median for last 10 epochs: [0.4479 0.0782 0.3341 0.5847], Epochs since improvement 0
  9%|▉         | 47/500 [53:35<8:19:39, 66.18s/it] 10%|▉         | 48/500 [54:57<8:53:44, 70.85s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.54E+06, Train scatter: [0.4251 0.0775 0.312  0.542 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4222 0.0778 0.3167 0.5427], Lowest was [0.4182 0.0754 0.3133 0.5238]
Median for last 10 epochs: [0.441  0.0782 0.3341 0.5582], Epochs since improvement 2
 10%|▉         | 49/500 [55:51<8:14:42, 65.81s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.42E+06, Train scatter: [0.3983 0.0796 0.338  0.5087]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3969 0.0816 0.3412 0.5111], Lowest was [0.3969 0.0754 0.3133 0.5111]
Median for last 10 epochs: [0.4222 0.0789 0.3375 0.5427], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [57:20<9:06:04, 72.81s/it] 10%|█         | 51/500 [58:14<8:22:35, 67.16s/it] 10%|█         | 52/500 [59:36<8:55:06, 71.67s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.38E+06, Train scatter: [0.472  0.086  0.3182 0.5195]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4557 0.0843 0.3214 0.5152], Lowest was [0.3969 0.0754 0.3133 0.5111]
Median for last 10 epochs: [0.4222 0.0789 0.3214 0.5238], Epochs since improvement 2
 11%|█         | 53/500 [1:00:31<8:16:50, 66.69s/it] 11%|█         | 54/500 [1:01:52<8:47:28, 70.96s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.15E+06, Train scatter: [0.4287 0.0712 0.3236 0.4895]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4223 0.0714 0.3253 0.4904], Lowest was [0.3969 0.0714 0.3133 0.4904]
Median for last 10 epochs: [0.4223 0.0782 0.3214 0.5152], Epochs since improvement 0
 11%|█         | 55/500 [1:02:45<8:07:04, 65.67s/it] 11%|█         | 56/500 [1:04:07<8:42:23, 70.59s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.86E+06, Train scatter: [0.4075 0.0675 0.2844 0.4725]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4018 0.0687 0.2894 0.473 ], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.4222 0.0778 0.3214 0.5111], Epochs since improvement 0
 11%|█▏        | 57/500 [1:05:02<8:05:31, 65.76s/it] 12%|█▏        | 58/500 [1:06:24<8:41:15, 70.76s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 9.03E+09, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.169  0.5355 0.9851], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.4223 0.0816 0.3253 0.5111], Epochs since improvement 2
 12%|█▏        | 59/500 [1:07:19<8:04:51, 65.97s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 7.17E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.4557 0.0843 0.3253 0.5152], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:08:49<8:56:34, 73.17s/it] 12%|█▏        | 61/500 [1:09:43<8:14:10, 67.54s/it] 12%|█▏        | 62/500 [1:11:07<8:47:30, 72.26s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 5.76E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 6
 13%|█▎        | 63/500 [1:12:00<8:05:17, 66.63s/it] 13%|█▎        | 64/500 [1:13:21<8:35:51, 70.99s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 4.66E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 8
 13%|█▎        | 65/500 [1:14:15<7:56:59, 65.79s/it] 13%|█▎        | 66/500 [1:15:36<8:29:52, 70.49s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.69E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 10
 13%|█▎        | 67/500 [1:16:32<7:55:42, 65.92s/it] 14%|█▎        | 68/500 [1:17:54<8:29:55, 70.82s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.95E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.169  0.5355 0.985 ], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 12
 14%|█▍        | 69/500 [1:18:48<7:52:02, 65.71s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.55E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.169  0.5355 0.985 ], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 14
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:20:16<8:39:49, 72.53s/it] 14%|█▍        | 71/500 [1:21:10<7:59:06, 67.01s/it] 14%|█▍        | 72/500 [1:22:33<8:31:10, 71.66s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 2.38E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.169  0.5355 0.985 ], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 16
 15%|█▍        | 73/500 [1:23:28<7:54:45, 66.71s/it] 15%|█▍        | 74/500 [1:24:50<8:25:45, 71.23s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.31E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.169  0.5355 0.985 ], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 18
 15%|█▌        | 75/500 [1:25:43<7:46:53, 65.91s/it] 15%|█▌        | 76/500 [1:27:05<8:19:05, 70.63s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.28E+07, Train scatter: [0.9352 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.169  0.5355 0.985 ], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 20
 15%|█▌        | 77/500 [1:27:59<7:42:02, 65.54s/it] 15%|█▌        | 77/500 [1:29:21<8:10:51, 69.62s/it]
Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.26E+07, Train scatter: [0.9351 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.169  0.5355 0.985 ], Lowest was [0.3969 0.0687 0.2894 0.473 ]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 22
Exited after 78 epochs due to early stopping
5361.10 seconds spent training, 10.722 seconds per epoch. Processed 6495 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.91951305 0.16896309 0.5354727  0.9849596 ]
{'epoch_exit': 77, 'scatter_m_star': 0.91951305, 'lowest_m_star': 0.3968902, 'last20_m_star': 0.9195478, 'last10_m_star': 0.9195453, 'scatter_v_disk': 0.16896309, 'lowest_v_disk': 0.06869239, 'last20_v_disk': 0.16897765, 'last10_v_disk': 0.1689747, 'scatter_m_cold': 0.5354727, 'lowest_m_cold': 0.2893992, 'last20_m_cold': 0.53548867, 'last10_m_cold': 0.53548867, 'scatter_sfr_100': 0.9849596, 'lowest_sfr_100': 0.4729843, 'last20_sfr_100': 0.9850083, 'last10_sfr_100': 0.9849948}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
