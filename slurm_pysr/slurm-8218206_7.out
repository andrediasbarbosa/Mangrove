Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_cupaay
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:31<4:22:28, 31.56s/it]  0%|          | 2/500 [01:19<5:43:43, 41.41s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.27E+07, Train scatter: [0.9352 0.167  0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.31E-01
Test scatter: [0.9196 0.1662 0.5355 0.9851], Lowest was [0.9196 0.1662 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1662 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:51<5:05:21, 36.86s/it]  1%|          | 4/500 [02:39<5:43:15, 41.52s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 6.54E+06, Train scatter: [0.9352 0.1481 0.5439 0.9954]
L1 regularization loss: 1.53E+00, L2 regularization loss: 3.54E-01
Test scatter: [0.9196 0.1475 0.5354 0.985 ], Lowest was [0.9196 0.1475 0.5354 0.985 ]
Median for last 10 epochs: [0.9196 0.1475 0.5354 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:11<5:12:35, 37.89s/it]  1%|          | 6/500 [04:00<5:42:21, 41.58s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 4.95E+06, Train scatter: [0.9331 0.1181 0.5412 0.668 ]
L1 regularization loss: 1.57E+00, L2 regularization loss: 3.90E-01
Test scatter: [0.9176 0.1167 0.5326 0.6597], Lowest was [0.9176 0.1167 0.5326 0.6597]
Median for last 10 epochs: [0.9176 0.1167 0.5326 0.6597], Epochs since improvement 0
  1%|▏         | 7/500 [04:31<5:14:58, 38.33s/it]  2%|▏         | 8/500 [05:20<5:40:14, 41.49s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.82E+07, Train scatter: [0.9354 0.1943 0.544  0.9929]
L1 regularization loss: 1.61E+00, L2 regularization loss: 4.08E-01
Test scatter: [0.9198 0.1933 0.5355 0.983 ], Lowest was [0.9176 0.1167 0.5326 0.6597]
Median for last 10 epochs: [0.9186 0.1321 0.534  0.8214], Epochs since improvement 2
  2%|▏         | 9/500 [05:51<5:14:29, 38.43s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.06E+06, Train scatter: [0.9344 0.1481 0.5424 0.8036]
L1 regularization loss: 1.63E+00, L2 regularization loss: 4.30E-01
Test scatter: [0.9191 0.1458 0.534  0.7847], Lowest was [0.9176 0.1167 0.5326 0.6597]
Median for last 10 epochs: [0.9191 0.1458 0.534  0.7847], Epochs since improvement 4
  2%|▏         | 10/500 [06:46<5:53:57, 43.34s/it]  2%|▏         | 11/500 [07:17<5:23:27, 39.69s/it]  2%|▏         | 12/500 [08:06<5:44:49, 42.40s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 4.86E+06, Train scatter: [0.7023 0.1152 0.5303 0.6678]
L1 regularization loss: 1.66E+00, L2 regularization loss: 4.50E-01
Test scatter: [0.6996 0.1143 0.5221 0.6556], Lowest was [0.6996 0.1143 0.5221 0.6556]
Median for last 10 epochs: [0.9191 0.1458 0.534  0.7847], Epochs since improvement 0
  3%|▎         | 13/500 [08:37<5:17:12, 39.08s/it]  3%|▎         | 14/500 [09:26<5:39:56, 41.97s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 2.62E+06, Train scatter: [0.5159 0.1043 0.4387 0.6207]
L1 regularization loss: 1.68E+00, L2 regularization loss: 4.68E-01
Test scatter: [0.5072 0.1058 0.4354 0.6108], Lowest was [0.5072 0.1058 0.4354 0.6108]
Median for last 10 epochs: [0.9176 0.1167 0.5326 0.6597], Epochs since improvement 0
  3%|▎         | 15/500 [09:57<5:13:52, 38.83s/it]  3%|▎         | 16/500 [10:46<5:37:47, 41.88s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.83E+06, Train scatter: [0.5423 0.0993 0.3846 0.5995]
L1 regularization loss: 1.69E+00, L2 regularization loss: 4.76E-01
Test scatter: [0.5362 0.1016 0.3968 0.6027], Lowest was [0.5072 0.1016 0.3968 0.6027]
Median for last 10 epochs: [0.6996 0.1143 0.5221 0.6556], Epochs since improvement 0
  3%|▎         | 17/500 [11:18<5:12:07, 38.77s/it]  4%|▎         | 18/500 [12:06<5:34:38, 41.66s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.40E+06, Train scatter: [0.5127 0.0936 0.3602 0.5769]
L1 regularization loss: 1.71E+00, L2 regularization loss: 4.84E-01
Test scatter: [0.5041 0.0945 0.3703 0.5775], Lowest was [0.5041 0.0945 0.3703 0.5775]
Median for last 10 epochs: [0.5362 0.1058 0.4354 0.6108], Epochs since improvement 0
  4%|▍         | 19/500 [12:38<5:10:16, 38.70s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 1.05E+06, Train scatter: [0.3942 0.0895 0.3408 0.5695]
L1 regularization loss: 1.72E+00, L2 regularization loss: 4.92E-01
Test scatter: [0.3971 0.0904 0.3494 0.5734], Lowest was [0.3971 0.0904 0.3494 0.5734]
Median for last 10 epochs: [0.5072 0.1016 0.3968 0.6027], Epochs since improvement 0
  4%|▍         | 20/500 [13:32<5:45:47, 43.22s/it]  4%|▍         | 21/500 [14:03<5:16:58, 39.70s/it]  4%|▍         | 22/500 [14:52<5:37:10, 42.32s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 9.14E+05, Train scatter: [0.3997 0.0862 0.3393 0.5878]
L1 regularization loss: 1.74E+00, L2 regularization loss: 5.03E-01
Test scatter: [0.4127 0.0884 0.3532 0.5912], Lowest was [0.3971 0.0884 0.3494 0.5734]
Median for last 10 epochs: [0.5041 0.0945 0.3703 0.5912], Epochs since improvement 0
  5%|▍         | 23/500 [15:23<5:10:47, 39.09s/it]  5%|▍         | 24/500 [16:12<5:32:27, 41.91s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 8.11E+05, Train scatter: [0.4138 0.0854 0.3496 0.5965]
L1 regularization loss: 1.76E+00, L2 regularization loss: 5.13E-01
Test scatter: [0.4237 0.0863 0.3611 0.6005], Lowest was [0.3971 0.0863 0.3494 0.5734]
Median for last 10 epochs: [0.4237 0.0904 0.3611 0.5912], Epochs since improvement 0
  5%|▌         | 25/500 [16:43<5:07:05, 38.79s/it]  5%|▌         | 26/500 [17:32<5:29:48, 41.75s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 8.38E+05, Train scatter: [0.35   0.0842 0.3122 0.5449]
L1 regularization loss: 1.79E+00, L2 regularization loss: 5.24E-01
Test scatter: [0.3586 0.0857 0.3187 0.546 ], Lowest was [0.3586 0.0857 0.3187 0.546 ]
Median for last 10 epochs: [0.4127 0.0884 0.3532 0.5775], Epochs since improvement 0
  5%|▌         | 27/500 [18:03<5:04:52, 38.67s/it]  6%|▌         | 28/500 [18:52<5:27:09, 41.59s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 6.43E+05, Train scatter: [0.4537 0.1038 0.3331 0.6173]
L1 regularization loss: 1.81E+00, L2 regularization loss: 5.35E-01
Test scatter: [0.4914 0.1151 0.3474 0.6385], Lowest was [0.3586 0.0857 0.3187 0.546 ]
Median for last 10 epochs: [0.4127 0.0884 0.3494 0.5912], Epochs since improvement 2
  6%|▌         | 29/500 [19:23<5:02:53, 38.59s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 6.64E+05, Train scatter: [0.387  0.081  0.3092 0.549 ]
L1 regularization loss: 1.83E+00, L2 regularization loss: 5.47E-01
Test scatter: [0.3878 0.0821 0.3194 0.5503], Lowest was [0.3586 0.0821 0.3187 0.546 ]
Median for last 10 epochs: [0.4127 0.0863 0.3474 0.5912], Epochs since improvement 0
  6%|▌         | 30/500 [20:17<5:38:37, 43.23s/it]  6%|▌         | 31/500 [20:49<5:10:32, 39.73s/it]  6%|▋         | 32/500 [21:38<5:30:37, 42.39s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 5.12E+05, Train scatter: [0.3468 0.0797 0.2853 0.532 ]
L1 regularization loss: 1.85E+00, L2 regularization loss: 5.62E-01
Test scatter: [0.354  0.0818 0.299  0.532 ], Lowest was [0.354  0.0818 0.299  0.532 ]
Median for last 10 epochs: [0.3878 0.0857 0.3194 0.5503], Epochs since improvement 0
  7%|▋         | 33/500 [22:09<5:04:38, 39.14s/it]  7%|▋         | 34/500 [22:58<5:26:05, 41.99s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 4.83E+05, Train scatter: [0.3241 0.0747 0.2818 0.5134]
L1 regularization loss: 1.87E+00, L2 regularization loss: 5.77E-01
Test scatter: [0.3277 0.0766 0.2919 0.5158], Lowest was [0.3277 0.0766 0.2919 0.5158]
Median for last 10 epochs: [0.3586 0.0821 0.3187 0.546 ], Epochs since improvement 0
  7%|▋         | 35/500 [23:29<5:01:03, 38.85s/it]  7%|▋         | 36/500 [24:18<5:23:23, 41.82s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 4.17E+05, Train scatter: [0.3446 0.0792 0.2972 0.5399]
L1 regularization loss: 1.90E+00, L2 regularization loss: 5.96E-01
Test scatter: [0.3526 0.0816 0.3029 0.5386], Lowest was [0.3277 0.0766 0.2919 0.5158]
Median for last 10 epochs: [0.354  0.0818 0.3029 0.5386], Epochs since improvement 2
  7%|▋         | 37/500 [24:50<4:58:54, 38.74s/it]  8%|▊         | 38/500 [25:39<5:21:59, 41.82s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.86E+05, Train scatter: [0.3322 0.0757 0.2948 0.5338]
L1 regularization loss: 1.93E+00, L2 regularization loss: 6.15E-01
Test scatter: [0.3347 0.0755 0.2989 0.5317], Lowest was [0.3277 0.0755 0.2919 0.5158]
Median for last 10 epochs: [0.3526 0.0816 0.299  0.532 ], Epochs since improvement 0
  8%|▊         | 39/500 [26:10<4:57:30, 38.72s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: -3.64E+04, Train scatter: [0.3079 0.0681 0.2715 0.4999]
L1 regularization loss: 1.94E+00, L2 regularization loss: 6.37E-01
Test scatter: [0.3044 0.0694 0.2794 0.4997], Lowest was [0.3044 0.0694 0.2794 0.4997]
Median for last 10 epochs: [0.3347 0.0766 0.2989 0.5317], Epochs since improvement 0
  8%|▊         | 40/500 [27:04<5:32:31, 43.37s/it]  8%|▊         | 41/500 [27:36<5:04:35, 39.82s/it]  8%|▊         | 42/500 [28:25<5:25:10, 42.60s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.56E+05, Train scatter: [0.291  0.0651 0.2743 0.499 ]
L1 regularization loss: 1.97E+00, L2 regularization loss: 6.58E-01
Test scatter: [0.3028 0.0662 0.2853 0.4978], Lowest was [0.3028 0.0662 0.2794 0.4978]
Median for last 10 epochs: [0.3277 0.0755 0.2919 0.5158], Epochs since improvement 0
  9%|▊         | 43/500 [28:57<4:59:25, 39.31s/it]  9%|▉         | 44/500 [29:45<5:20:37, 42.19s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.76E+05, Train scatter: [0.2391 0.0639 0.2779 0.4861]
L1 regularization loss: 1.98E+00, L2 regularization loss: 6.74E-01
Test scatter: [0.2466 0.0655 0.2879 0.4861], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.3044 0.0694 0.2879 0.4997], Epochs since improvement 0
  9%|▉         | 45/500 [30:17<4:55:45, 39.00s/it]  9%|▉         | 46/500 [31:06<5:17:53, 42.01s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 7.91E+07, Train scatter: [0.9345 0.1722 0.5441 0.9906]
L1 regularization loss: 3.12E+00, L2 regularization loss: 1.03E+00
Test scatter: [0.919  0.1685 0.5355 0.9806], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.3044 0.0694 0.2879 0.4997], Epochs since improvement 2
  9%|▉         | 47/500 [31:38<4:53:27, 38.87s/it] 10%|▉         | 48/500 [32:27<5:16:05, 41.96s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.51E+06, Train scatter: [0.9344 0.1709 0.5439 0.9814]
L1 regularization loss: 3.14E+00, L2 regularization loss: 1.15E+00
Test scatter: [0.9189 0.1672 0.5353 0.9715], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.3044 0.0694 0.2879 0.4997], Epochs since improvement 4
 10%|▉         | 49/500 [32:58<4:51:41, 38.81s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 9.96E+05, Train scatter: [0.9294 0.1338 0.5422 0.7578]
L1 regularization loss: 3.20E+00, L2 regularization loss: 1.43E+00
Test scatter: [0.9141 0.1305 0.5337 0.7504], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.9141 0.1305 0.5337 0.7504], Epochs since improvement 6
 10%|█         | 50/500 [33:52<5:24:52, 43.32s/it] 10%|█         | 51/500 [34:24<4:57:46, 39.79s/it] 10%|█         | 52/500 [35:12<5:17:24, 42.51s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 4.19E+05, Train scatter: [0.9194 0.1104 0.5194 0.6892]
L1 regularization loss: 3.23E+00, L2 regularization loss: 1.53E+00
Test scatter: [0.9049 0.1092 0.5127 0.6901], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.9141 0.1305 0.5337 0.7504], Epochs since improvement 8
 11%|█         | 53/500 [35:44<4:52:04, 39.21s/it] 11%|█         | 54/500 [36:33<5:13:59, 42.24s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.75E+05, Train scatter: [0.8994 0.1027 0.5007 0.6569]
L1 regularization loss: 3.27E+00, L2 regularization loss: 1.65E+00
Test scatter: [0.8863 0.1022 0.4934 0.6579], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.9141 0.1305 0.5337 0.7504], Epochs since improvement 10
 11%|█         | 55/500 [37:05<4:49:33, 39.04s/it] 11%|█         | 56/500 [37:54<5:10:56, 42.02s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.91E+05, Train scatter: [0.5806 0.1014 0.4578 0.6507]
L1 regularization loss: 3.30E+00, L2 regularization loss: 1.75E+00
Test scatter: [0.5562 0.0996 0.4529 0.6411], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.9049 0.1092 0.5127 0.6901], Epochs since improvement 12
 11%|█▏        | 57/500 [38:25<4:47:04, 38.88s/it] 12%|█▏        | 58/500 [39:15<5:09:19, 41.99s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.38E+05, Train scatter: [0.4943 0.0972 0.4522 0.6345]
L1 regularization loss: 3.31E+00, L2 regularization loss: 1.79E+00
Test scatter: [0.487  0.097  0.4523 0.6346], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.8863 0.1022 0.4934 0.6579], Epochs since improvement 14
 12%|█▏        | 59/500 [39:46<4:45:32, 38.85s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 8.52E+04, Train scatter: [0.4758 0.097  0.4462 0.6355]
L1 regularization loss: 3.32E+00, L2 regularization loss: 1.83E+00
Test scatter: [0.4791 0.0974 0.4477 0.638 ], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.5562 0.0996 0.4529 0.6411], Epochs since improvement 16
 12%|█▏        | 60/500 [40:40<5:18:48, 43.47s/it] 12%|█▏        | 61/500 [41:12<4:51:54, 39.90s/it] 12%|█▏        | 62/500 [42:01<5:12:02, 42.75s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.06E+04, Train scatter: [0.417  0.0872 0.4259 0.5846]
L1 regularization loss: 3.33E+00, L2 regularization loss: 1.88E+00
Test scatter: [0.4084 0.0871 0.4278 0.5794], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.487  0.0974 0.4523 0.638 ], Epochs since improvement 18
 13%|█▎        | 63/500 [42:33<4:46:37, 39.35s/it] 13%|█▎        | 64/500 [43:22<5:08:11, 42.41s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: -1.74E+04, Train scatter: [0.4857 0.084  0.4168 0.5765]
L1 regularization loss: 3.33E+00, L2 regularization loss: 1.91E+00
Test scatter: [0.4599 0.0839 0.4208 0.5671], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.4791 0.097  0.4477 0.6346], Epochs since improvement 20
 13%|█▎        | 65/500 [43:54<4:43:49, 39.15s/it] 13%|█▎        | 65/500 [44:43<4:59:19, 41.29s/it]
Epoch: 66 done with learning rate 9.66E-03, Train loss: -4.89E+04, Train scatter: [0.5342 0.0868 0.4318 0.5992]
L1 regularization loss: 3.34E+00, L2 regularization loss: 1.94E+00
Test scatter: [0.4924 0.0857 0.4317 0.5849], Lowest was [0.2466 0.0655 0.2794 0.4861]
Median for last 10 epochs: [0.4791 0.0871 0.4317 0.5849], Epochs since improvement 22
Exited after 66 epochs due to early stopping
2684.56 seconds spent training, 5.369 seconds per epoch. Processed 12970 trees per second
[0.49234882 0.0857287  0.4316576  0.5849296 ]
{'epoch_exit': 65, 'scatter_m_star': 0.49234882, 'lowest_m_star': 0.24657314, 'last20_m_star': 0.5242975, 'last10_m_star': 0.4791498, 'scatter_v_disk': 0.0857287, 'lowest_v_disk': 0.065521255, 'last20_v_disk': 0.09846605, 'last10_v_disk': 0.08705849, 'scatter_m_cold': 0.4316576, 'lowest_m_cold': 0.2793781, 'last20_m_cold': 0.45256022, 'last10_m_cold': 0.43167025, 'scatter_sfr_100': 0.5849296, 'lowest_sfr_100': 0.48611963, 'last20_sfr_100': 0.6395206, 'last10_sfr_100': 0.584947}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_xkzvzf
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:54:48, 28.23s/it]  0%|          | 2/500 [01:12<5:13:32, 37.78s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.36E+07, Train scatter: [0.9353 0.1639 0.5442 0.9954]
L1 regularization loss: 1.51E+00, L2 regularization loss: 3.26E-01
Test scatter: [0.9197 0.1661 0.5356 0.9851], Lowest was [0.9197 0.1661 0.5356 0.9851]
Median for last 10 epochs: [0.9197 0.1661 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:40<4:33:28, 33.01s/it]  1%|          | 4/500 [02:26<5:16:44, 38.32s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.19E+07, Train scatter: [0.9353 0.177  0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.32E-01
Test scatter: [0.9197 0.1784 0.5355 0.9851], Lowest was [0.9197 0.1661 0.5355 0.9851]
Median for last 10 epochs: [0.9197 0.1723 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:53<4:43:47, 34.40s/it]  1%|          | 6/500 [03:40<5:16:37, 38.46s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.54E+06, Train scatter: [0.9352 0.171  0.5441 0.9954]
L1 regularization loss: 1.53E+00, L2 regularization loss: 3.43E-01
Test scatter: [0.9196 0.1668 0.5356 0.9851], Lowest was [0.9196 0.1661 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1668 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:07<4:46:50, 34.91s/it]  2%|▏         | 8/500 [04:53<5:15:10, 38.44s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.53E+06, Train scatter: [0.9352 0.1505 0.5441 0.995 ]
L1 regularization loss: 1.55E+00, L2 regularization loss: 3.65E-01
Test scatter: [0.9196 0.144  0.5355 0.9847], Lowest was [0.9196 0.144  0.5355 0.9847]
Median for last 10 epochs: [0.9196 0.1554 0.5355 0.9849], Epochs since improvement 0
  2%|▏         | 9/500 [05:21<4:46:36, 35.02s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.99E+06, Train scatter: [0.935  0.1366 0.5441 0.6906]
L1 regularization loss: 1.58E+00, L2 regularization loss: 3.94E-01
Test scatter: [0.9194 0.1321 0.5355 0.6955], Lowest was [0.9194 0.1321 0.5355 0.6955]
Median for last 10 epochs: [0.9196 0.144  0.5355 0.9847], Epochs since improvement 0
  2%|▏         | 10/500 [06:14<5:30:43, 40.50s/it]  2%|▏         | 11/500 [06:41<4:57:46, 36.54s/it]  2%|▏         | 12/500 [07:28<5:21:34, 39.54s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.46E+06, Train scatter: [0.9311 0.1238 0.544  0.6373]
L1 regularization loss: 1.60E+00, L2 regularization loss: 4.04E-01
Test scatter: [0.9154 0.1197 0.5354 0.6292], Lowest was [0.9154 0.1197 0.5354 0.6292]
Median for last 10 epochs: [0.9196 0.144  0.5355 0.9847], Epochs since improvement 0
  3%|▎         | 13/500 [07:55<4:51:06, 35.87s/it]  3%|▎         | 14/500 [08:40<5:13:27, 38.70s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.81E+06, Train scatter: [0.9006 0.1165 0.5428 0.6156]
L1 regularization loss: 1.61E+00, L2 regularization loss: 4.12E-01
Test scatter: [0.8858 0.1124 0.5342 0.6084], Lowest was [0.8858 0.1124 0.5342 0.6084]
Median for last 10 epochs: [0.9194 0.1321 0.5355 0.6955], Epochs since improvement 0
  3%|▎         | 15/500 [09:08<4:45:41, 35.34s/it]  3%|▎         | 16/500 [09:52<5:07:33, 38.13s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 5.69E+07, Train scatter: [0.9349 0.1898 0.5441 0.9948]
L1 regularization loss: 1.69E+00, L2 regularization loss: 4.39E-01
Test scatter: [0.9193 0.1822 0.5355 0.9844], Lowest was [0.8858 0.1124 0.5342 0.6084]
Median for last 10 epochs: [0.9193 0.1321 0.5355 0.6955], Epochs since improvement 2
  3%|▎         | 17/500 [10:20<4:41:19, 34.95s/it]  4%|▎         | 18/500 [11:06<5:07:16, 38.25s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.08E+07, Train scatter: [0.9349 0.1814 0.544  0.9899]
L1 regularization loss: 1.69E+00, L2 regularization loss: 4.47E-01
Test scatter: [0.9193 0.179  0.5355 0.9797], Lowest was [0.8858 0.1124 0.5342 0.6084]
Median for last 10 epochs: [0.9193 0.1321 0.5355 0.6955], Epochs since improvement 4
  4%|▍         | 19/500 [11:33<4:40:37, 35.00s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.32E+07, Train scatter: [0.9352 0.1653 0.544  0.9396]
L1 regularization loss: 1.70E+00, L2 regularization loss: 4.53E-01
Test scatter: [0.9196 0.1641 0.5354 0.9329], Lowest was [0.8858 0.1124 0.5342 0.6084]
Median for last 10 epochs: [0.9193 0.1641 0.5354 0.9329], Epochs since improvement 6
  4%|▍         | 20/500 [12:24<5:17:11, 39.65s/it]  4%|▍         | 21/500 [12:51<4:47:35, 36.02s/it]  4%|▍         | 22/500 [13:37<5:11:04, 39.05s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.03E+07, Train scatter: [0.9352 0.1447 0.5404 0.7709]
L1 regularization loss: 1.71E+00, L2 regularization loss: 4.70E-01
Test scatter: [0.9196 0.147  0.5321 0.7882], Lowest was [0.8858 0.1124 0.5321 0.6084]
Median for last 10 epochs: [0.9193 0.1641 0.5354 0.9329], Epochs since improvement 0
  5%|▍         | 23/500 [14:05<4:43:00, 35.60s/it]  5%|▍         | 24/500 [14:51<5:07:08, 38.72s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 2.82E+07, Train scatter: [0.9348 0.1266 0.5304 0.7424]
L1 regularization loss: 1.73E+00, L2 regularization loss: 4.88E-01
Test scatter: [0.9192 0.1282 0.5233 0.7404], Lowest was [0.8858 0.1124 0.5233 0.6084]
Median for last 10 epochs: [0.9193 0.1641 0.5354 0.9329], Epochs since improvement 0
  5%|▌         | 25/500 [15:19<4:39:59, 35.37s/it]  5%|▌         | 26/500 [16:05<5:04:42, 38.57s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 2.43E+07, Train scatter: [0.9325 0.1217 0.4995 0.7146]
L1 regularization loss: 1.73E+00, L2 regularization loss: 4.99E-01
Test scatter: [0.917  0.1233 0.5059 0.7322], Lowest was [0.8858 0.1124 0.5059 0.6084]
Median for last 10 epochs: [0.9193 0.147  0.5321 0.7882], Epochs since improvement 0
  5%|▌         | 27/500 [16:32<4:38:22, 35.31s/it]  6%|▌         | 28/500 [17:18<5:01:57, 38.38s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 1.41E+07, Train scatter: [0.9184 0.1197 0.4923 0.6796]
L1 regularization loss: 1.74E+00, L2 regularization loss: 5.16E-01
Test scatter: [0.9039 0.1208 0.4995 0.6871], Lowest was [0.8858 0.1124 0.4995 0.6084]
Median for last 10 epochs: [0.9192 0.1282 0.5233 0.7404], Epochs since improvement 0
  6%|▌         | 29/500 [17:45<4:35:42, 35.12s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 1.21E+07, Train scatter: [0.8676 0.1178 0.4967 0.6634]
L1 regularization loss: 1.75E+00, L2 regularization loss: 5.31E-01
Test scatter: [0.8557 0.1194 0.4983 0.6624], Lowest was [0.8557 0.1124 0.4983 0.6084]
Median for last 10 epochs: [0.917  0.1233 0.5059 0.7322], Epochs since improvement 0
  6%|▌         | 30/500 [18:37<5:13:49, 40.06s/it]  6%|▌         | 31/500 [19:04<4:43:31, 36.27s/it]  6%|▋         | 32/500 [19:51<5:05:54, 39.22s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 1.01E+07, Train scatter: [0.7221 0.1193 0.4588 0.6608]
L1 regularization loss: 1.76E+00, L2 regularization loss: 5.52E-01
Test scatter: [0.7128 0.1233 0.4635 0.6572], Lowest was [0.7128 0.1124 0.4635 0.6084]
Median for last 10 epochs: [0.9039 0.1233 0.4995 0.6871], Epochs since improvement 0
  7%|▋         | 33/500 [20:18<4:37:55, 35.71s/it]  7%|▋         | 34/500 [21:04<5:02:02, 38.89s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 6.95E+06, Train scatter: [0.527  0.1166 0.4516 0.6614]
L1 regularization loss: 1.78E+00, L2 regularization loss: 5.88E-01
Test scatter: [0.5168 0.1207 0.4503 0.6542], Lowest was [0.5168 0.1124 0.4503 0.6084]
Median for last 10 epochs: [0.8557 0.1208 0.4983 0.6624], Epochs since improvement 0
  7%|▋         | 35/500 [21:32<4:35:09, 35.50s/it]  7%|▋         | 36/500 [22:18<5:00:05, 38.80s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 5.51E+06, Train scatter: [0.4621 0.1129 0.4423 0.6612]
L1 regularization loss: 1.79E+00, L2 regularization loss: 6.12E-01
Test scatter: [0.4697 0.116  0.4409 0.6447], Lowest was [0.4697 0.1124 0.4409 0.6084]
Median for last 10 epochs: [0.7128 0.1207 0.4635 0.6572], Epochs since improvement 0
  7%|▋         | 37/500 [22:46<4:33:28, 35.44s/it]  8%|▊         | 38/500 [23:33<4:58:43, 38.80s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 4.94E+06, Train scatter: [0.4266 0.1095 0.4392 0.6311]
L1 regularization loss: 1.80E+00, L2 regularization loss: 6.38E-01
Test scatter: [0.4352 0.1117 0.4373 0.6197], Lowest was [0.4352 0.1117 0.4373 0.6084]
Median for last 10 epochs: [0.5168 0.1194 0.4503 0.6542], Epochs since improvement 0
  8%|▊         | 39/500 [24:00<4:32:11, 35.43s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 4.53E+06, Train scatter: [0.3943 0.1069 0.4256 0.606 ]
L1 regularization loss: 1.81E+00, L2 regularization loss: 6.58E-01
Test scatter: [0.4065 0.1087 0.4259 0.5978], Lowest was [0.4065 0.1087 0.4259 0.5978]
Median for last 10 epochs: [0.4697 0.116  0.4409 0.6447], Epochs since improvement 0
  8%|▊         | 40/500 [24:52<5:09:26, 40.36s/it]  8%|▊         | 41/500 [25:20<4:39:21, 36.52s/it]  8%|▊         | 42/500 [26:07<5:03:04, 39.70s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 4.33E+06, Train scatter: [0.3882 0.1055 0.4275 0.605 ]
L1 regularization loss: 1.82E+00, L2 regularization loss: 6.78E-01
Test scatter: [0.4006 0.1069 0.4284 0.5985], Lowest was [0.4006 0.1069 0.4259 0.5978]
Median for last 10 epochs: [0.4352 0.1117 0.4373 0.6197], Epochs since improvement 0
  9%|▊         | 43/500 [26:34<4:34:29, 36.04s/it]  9%|▉         | 44/500 [27:21<4:59:03, 39.35s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.04E+06, Train scatter: [0.3726 0.1028 0.4176 0.5764]
L1 regularization loss: 1.84E+00, L2 regularization loss: 6.96E-01
Test scatter: [0.3933 0.1041 0.4169 0.5754], Lowest was [0.3933 0.1041 0.4169 0.5754]
Median for last 10 epochs: [0.4065 0.1087 0.4284 0.5985], Epochs since improvement 0
  9%|▉         | 45/500 [27:49<4:31:26, 35.79s/it]  9%|▉         | 46/500 [28:36<4:56:07, 39.14s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.89E+06, Train scatter: [0.3737 0.1009 0.4203 0.5688]
L1 regularization loss: 1.85E+00, L2 regularization loss: 7.16E-01
Test scatter: [0.4021 0.1022 0.4208 0.5681], Lowest was [0.3933 0.1022 0.4169 0.5681]
Median for last 10 epochs: [0.4021 0.1069 0.4259 0.5978], Epochs since improvement 0
  9%|▉         | 47/500 [29:03<4:29:15, 35.66s/it] 10%|▉         | 48/500 [29:51<4:54:48, 39.13s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.66E+06, Train scatter: [0.4065 0.1009 0.4218 0.5817]
L1 regularization loss: 1.86E+00, L2 regularization loss: 7.35E-01
Test scatter: [0.4274 0.1048 0.4246 0.6063], Lowest was [0.3933 0.1022 0.4169 0.5681]
Median for last 10 epochs: [0.4021 0.1048 0.4246 0.5978], Epochs since improvement 2
 10%|▉         | 49/500 [30:18<4:27:49, 35.63s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.50E+06, Train scatter: [0.3723 0.0979 0.4142 0.6291]
L1 regularization loss: 1.87E+00, L2 regularization loss: 7.54E-01
Test scatter: [0.3969 0.0997 0.4143 0.6292], Lowest was [0.3933 0.0997 0.4143 0.5681]
Median for last 10 epochs: [0.4006 0.1041 0.4208 0.5985], Epochs since improvement 0
 10%|█         | 50/500 [31:11<5:07:04, 40.94s/it] 10%|█         | 51/500 [31:39<4:36:24, 36.94s/it] 10%|█         | 52/500 [32:26<4:59:01, 40.05s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.21E+06, Train scatter: [0.3326 0.0953 0.3922 0.548 ]
L1 regularization loss: 1.89E+00, L2 regularization loss: 7.78E-01
Test scatter: [0.3512 0.0965 0.3969 0.5477], Lowest was [0.3512 0.0965 0.3969 0.5477]
Median for last 10 epochs: [0.3969 0.1022 0.4169 0.5754], Epochs since improvement 0
 11%|█         | 53/500 [32:54<4:30:07, 36.26s/it] 11%|█         | 54/500 [33:40<4:52:03, 39.29s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.05E+06, Train scatter: [0.335  0.0932 0.3899 0.5386]
L1 regularization loss: 1.90E+00, L2 regularization loss: 8.03E-01
Test scatter: [0.3599 0.0958 0.3923 0.5447], Lowest was [0.3512 0.0958 0.3923 0.5447]
Median for last 10 epochs: [0.3969 0.0997 0.4143 0.5681], Epochs since improvement 0
 11%|█         | 55/500 [34:08<4:25:12, 35.76s/it] 11%|█         | 56/500 [34:54<4:48:14, 38.95s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.94E+06, Train scatter: [0.3189 0.0913 0.3859 0.5463]
L1 regularization loss: 1.92E+00, L2 regularization loss: 8.34E-01
Test scatter: [0.3382 0.0931 0.3898 0.5478], Lowest was [0.3382 0.0931 0.3898 0.5447]
Median for last 10 epochs: [0.3599 0.0965 0.3969 0.5478], Epochs since improvement 0
 11%|█▏        | 57/500 [35:21<4:22:10, 35.51s/it] 12%|█▏        | 58/500 [36:08<4:46:53, 38.94s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.79E+06, Train scatter: [0.3263 0.09   0.3947 0.5586]
L1 regularization loss: 1.93E+00, L2 regularization loss: 8.65E-01
Test scatter: [0.3583 0.0931 0.4082 0.5734], Lowest was [0.3382 0.0931 0.3898 0.5447]
Median for last 10 epochs: [0.3583 0.0958 0.3969 0.5478], Epochs since improvement 0
 12%|█▏        | 59/500 [36:36<4:21:04, 35.52s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.75E+06, Train scatter: [0.3678 0.089  0.3836 0.5302]
L1 regularization loss: 1.97E+00, L2 regularization loss: 9.10E-01
Test scatter: [0.3691 0.092  0.3861 0.5305], Lowest was [0.3382 0.092  0.3861 0.5305]
Median for last 10 epochs: [0.3583 0.0931 0.3923 0.5477], Epochs since improvement 0
 12%|█▏        | 60/500 [37:28<4:57:28, 40.57s/it] 12%|█▏        | 61/500 [37:56<4:28:19, 36.67s/it] 12%|█▏        | 62/500 [38:42<4:49:13, 39.62s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.45E+06, Train scatter: [0.3175 0.0866 0.3756 0.5219]
L1 regularization loss: 1.98E+00, L2 regularization loss: 9.42E-01
Test scatter: [0.3246 0.0891 0.3763 0.5256], Lowest was [0.3246 0.0891 0.3763 0.5256]
Median for last 10 epochs: [0.3583 0.0931 0.3898 0.5447], Epochs since improvement 0
 13%|█▎        | 63/500 [39:10<4:21:59, 35.97s/it] 13%|█▎        | 64/500 [39:57<4:45:34, 39.30s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.97E+06, Train scatter: [0.3636 0.0958 0.3886 0.573 ]
L1 regularization loss: 2.03E+00, L2 regularization loss: 9.98E-01
Test scatter: [0.3694 0.0967 0.3911 0.5691], Lowest was [0.3246 0.0891 0.3763 0.5256]
Median for last 10 epochs: [0.3583 0.0931 0.3898 0.5478], Epochs since improvement 2
 13%|█▎        | 65/500 [40:24<4:19:06, 35.74s/it] 13%|█▎        | 66/500 [41:11<4:42:06, 39.00s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.22E+06, Train scatter: [0.3165 0.0849 0.3621 0.5174]
L1 regularization loss: 2.03E+00, L2 regularization loss: 1.04E+00
Test scatter: [0.329  0.0872 0.365  0.5205], Lowest was [0.3246 0.0872 0.365  0.5205]
Median for last 10 epochs: [0.3583 0.092  0.3861 0.5305], Epochs since improvement 0
 13%|█▎        | 67/500 [41:39<4:17:24, 35.67s/it] 14%|█▎        | 68/500 [42:24<4:37:55, 38.60s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.00E+06, Train scatter: [0.2962 0.0832 0.359  0.5172]
L1 regularization loss: 2.03E+00, L2 regularization loss: 1.07E+00
Test scatter: [0.3133 0.086  0.3654 0.5224], Lowest was [0.3133 0.086  0.365  0.5205]
Median for last 10 epochs: [0.329  0.0891 0.3763 0.5256], Epochs since improvement 0
 14%|█▍        | 69/500 [42:52<4:13:20, 35.27s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.95E+06, Train scatter: [0.2963 0.0834 0.3612 0.5123]
L1 regularization loss: 2.05E+00, L2 regularization loss: 1.10E+00
Test scatter: [0.3084 0.0858 0.3696 0.5197], Lowest was [0.3084 0.0858 0.365  0.5197]
Median for last 10 epochs: [0.3246 0.0872 0.3696 0.5224], Epochs since improvement 0
 14%|█▍        | 70/500 [43:45<4:50:34, 40.54s/it] 14%|█▍        | 71/500 [44:12<4:22:14, 36.68s/it] 14%|█▍        | 72/500 [44:59<4:43:40, 39.77s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.81E+06, Train scatter: [0.3035 0.0811 0.3452 0.5131]
L1 regularization loss: 2.06E+00, L2 regularization loss: 1.13E+00
Test scatter: [0.314  0.0836 0.3554 0.5178], Lowest was [0.3084 0.0836 0.3554 0.5178]
Median for last 10 epochs: [0.314  0.086  0.3654 0.5205], Epochs since improvement 0
 15%|█▍        | 73/500 [45:27<4:17:03, 36.12s/it] 15%|█▍        | 74/500 [46:13<4:38:08, 39.18s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 1.78E+06, Train scatter: [0.2912 0.0809 0.356  0.5094]
L1 regularization loss: 2.08E+00, L2 regularization loss: 1.18E+00
Test scatter: [0.3051 0.0828 0.3658 0.5151], Lowest was [0.3051 0.0828 0.3554 0.5151]
Median for last 10 epochs: [0.3133 0.0858 0.3654 0.5197], Epochs since improvement 0
 15%|█▌        | 75/500 [46:41<4:12:43, 35.68s/it] 15%|█▌        | 76/500 [47:28<4:36:57, 39.19s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 1.60E+06, Train scatter: [0.2886 0.0794 0.3592 0.5177]
L1 regularization loss: 2.08E+00, L2 regularization loss: 1.21E+00
Test scatter: [0.2987 0.0815 0.3753 0.5286], Lowest was [0.2987 0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.3084 0.0836 0.3658 0.5197], Epochs since improvement 0
 15%|█▌        | 77/500 [47:56<4:11:50, 35.72s/it] 16%|█▌        | 78/500 [48:43<4:36:06, 39.26s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 4.08E+06, Train scatter: [0.2869 0.0848 0.5389 0.6601]
L1 regularization loss: 2.34E+00, L2 regularization loss: 1.36E+00
Test scatter: [0.294  0.0857 0.5305 0.6706], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.3051 0.0836 0.3696 0.5197], Epochs since improvement 0
 16%|█▌        | 79/500 [49:11<4:10:39, 35.72s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 1.04E+07, Train scatter: [0.5782 0.1739 0.538  0.9462]
L1 regularization loss: 3.18E+00, L2 regularization loss: 1.91E+00
Test scatter: [0.5708 0.1702 0.5296 0.9361], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.3051 0.0836 0.3753 0.5286], Epochs since improvement 2
 16%|█▌        | 80/500 [50:03<4:44:49, 40.69s/it] 16%|█▌        | 81/500 [50:31<4:16:50, 36.78s/it] 16%|█▋        | 82/500 [51:18<4:37:48, 39.88s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 6.07E+06, Train scatter: [0.5123 0.1734 0.5356 0.8386]
L1 regularization loss: 3.20E+00, L2 regularization loss: 1.94E+00
Test scatter: [0.5027 0.1697 0.5272 0.831 ], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.3051 0.0857 0.5272 0.6706], Epochs since improvement 4
 17%|█▋        | 83/500 [51:45<4:11:29, 36.19s/it] 17%|█▋        | 84/500 [52:32<4:32:23, 39.29s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 5.01E+06, Train scatter: [0.4868 0.1731 0.5268 0.7547]
L1 regularization loss: 3.23E+00, L2 regularization loss: 1.98E+00
Test scatter: [0.4802 0.1693 0.5188 0.7514], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.4802 0.1693 0.5272 0.7514], Epochs since improvement 6
 17%|█▋        | 85/500 [52:59<4:07:26, 35.77s/it] 17%|█▋        | 86/500 [53:46<4:29:46, 39.10s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 4.07E+06, Train scatter: [0.5089 0.1725 0.5242 0.7179]
L1 regularization loss: 3.25E+00, L2 regularization loss: 2.03E+00
Test scatter: [0.4978 0.1687 0.5163 0.7174], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.4978 0.1693 0.5272 0.7514], Epochs since improvement 8
 17%|█▋        | 87/500 [54:14<4:05:34, 35.68s/it] 18%|█▊        | 88/500 [55:02<4:29:39, 39.27s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 3.46E+06, Train scatter: [0.4413 0.1722 0.5115 0.6915]
L1 regularization loss: 3.27E+00, L2 regularization loss: 2.07E+00
Test scatter: [0.4344 0.1685 0.5041 0.6901], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.4978 0.1693 0.5188 0.7514], Epochs since improvement 10
 18%|█▊        | 89/500 [55:29<4:05:05, 35.78s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 3.07E+06, Train scatter: [0.4085 0.1717 0.5086 0.6527]
L1 regularization loss: 3.28E+00, L2 regularization loss: 2.10E+00
Test scatter: [0.4052 0.168  0.5013 0.645 ], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.4802 0.1687 0.5163 0.7174], Epochs since improvement 12
 18%|█▊        | 90/500 [56:21<4:37:53, 40.67s/it] 18%|█▊        | 91/500 [56:49<4:10:41, 36.78s/it] 18%|█▊        | 92/500 [57:37<4:32:17, 40.04s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 3.51E+06, Train scatter: [0.4886 0.1713 0.48   0.6523]
L1 regularization loss: 3.30E+00, L2 regularization loss: 2.12E+00
Test scatter: [0.4777 0.1676 0.4799 0.6439], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.4777 0.1685 0.5041 0.6901], Epochs since improvement 14
 19%|█▊        | 93/500 [58:04<4:06:33, 36.35s/it] 19%|█▉        | 94/500 [58:52<4:27:52, 39.59s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.89E+06, Train scatter: [0.4021 0.1694 0.4968 0.643 ]
L1 regularization loss: 3.31E+00, L2 regularization loss: 2.15E+00
Test scatter: [0.3975 0.1658 0.4905 0.6341], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.4344 0.168  0.5013 0.645 ], Epochs since improvement 16
 19%|█▉        | 95/500 [59:19<4:03:13, 36.03s/it] 19%|█▉        | 96/500 [1:00:07<4:26:01, 39.51s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.55E+06, Train scatter: [0.3923 0.1675 0.4793 0.6358]
L1 regularization loss: 3.31E+00, L2 regularization loss: 2.17E+00
Test scatter: [0.3887 0.1638 0.4686 0.6274], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.4052 0.1676 0.4905 0.6439], Epochs since improvement 18
 19%|█▉        | 97/500 [1:00:35<4:01:44, 35.99s/it] 20%|█▉        | 98/500 [1:01:22<4:24:34, 39.49s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.27E+06, Train scatter: [0.3849 0.165  0.4918 0.6295]
L1 regularization loss: 3.32E+00, L2 regularization loss: 2.19E+00
Test scatter: [0.38   0.1614 0.4864 0.6207], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.3975 0.1658 0.4864 0.6341], Epochs since improvement 20
 20%|█▉        | 99/500 [1:01:50<4:00:21, 35.96s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 2.22E+06, Train scatter: [0.3814 0.1615 0.4882 0.6304]
L1 regularization loss: 3.33E+00, L2 regularization loss: 2.21E+00
Test scatter: [0.3794 0.158  0.4833 0.6226], Lowest was [0.294  0.0815 0.3554 0.5151]
Median for last 10 epochs: [0.3887 0.1638 0.4833 0.6274], Epochs since improvement 22
 20%|█▉        | 99/500 [1:02:43<4:14:02, 38.01s/it]
Exited after 100 epochs due to early stopping
3763.04 seconds spent training, 7.526 seconds per epoch. Processed 9253 trees per second
[0.37936673 0.15802819 0.48323548 0.6226121 ]
{'epoch_exit': 99, 'scatter_m_star': 0.37936673, 'lowest_m_star': 0.2940428, 'last20_m_star': 0.41982156, 'last10_m_star': 0.38874143, 'scatter_v_disk': 0.15802819, 'lowest_v_disk': 0.08148298, 'last20_v_disk': 0.16779986, 'last10_v_disk': 0.16384968, 'scatter_m_cold': 0.48323548, 'lowest_m_cold': 0.35535622, 'last20_m_cold': 0.49590462, 'last10_m_cold': 0.48325008, 'scatter_sfr_100': 0.6226121, 'lowest_sfr_100': 0.51507634, 'last20_sfr_100': 0.6444432, 'last10_sfr_100': 0.6273613}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_kzjctp
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:48<6:41:14, 48.24s/it]  0%|          | 2/500 [02:00<8:35:35, 62.12s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.30E+07, Train scatter: [0.9351 0.1345 0.544  0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.83E-01
Test scatter: [0.9195 0.1321 0.5354 0.9851], Lowest was [0.9195 0.1321 0.5354 0.9851]
Median for last 10 epochs: [0.9195 0.1321 0.5354 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:47<7:38:20, 55.33s/it]  1%|          | 4/500 [03:59<8:31:21, 61.86s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.47E+07, Train scatter: [0.9227 0.0897 0.5439 0.9928]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.11E-01
Test scatter: [0.9068 0.0901 0.5354 0.9824], Lowest was [0.9068 0.0901 0.5354 0.9824]
Median for last 10 epochs: [0.9068 0.0901 0.5354 0.9824], Epochs since improvement 0
  1%|          | 5/500 [04:46<7:47:45, 56.70s/it]  1%|          | 6/500 [05:58<8:28:01, 61.70s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.14E+06, Train scatter: [0.801  0.0909 0.5438 0.6063]
L1 regularization loss: 2.05E+00, L2 regularization loss: 4.53E-01
Test scatter: [0.7878 0.0904 0.5352 0.6006], Lowest was [0.7878 0.0901 0.5352 0.6006]
Median for last 10 epochs: [0.7878 0.0901 0.5352 0.6006], Epochs since improvement 0
  1%|▏         | 7/500 [06:45<7:48:48, 57.05s/it]  2%|▏         | 8/500 [07:57<8:25:34, 61.66s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 5.42E+06, Train scatter: [0.4866 0.0774 0.5438 0.548 ]
L1 regularization loss: 2.06E+00, L2 regularization loss: 4.67E-01
Test scatter: [0.4851 0.0785 0.5352 0.5443], Lowest was [0.4851 0.0785 0.5352 0.5443]
Median for last 10 epochs: [0.6365 0.0843 0.5352 0.5725], Epochs since improvement 0
  2%|▏         | 9/500 [08:44<7:47:40, 57.15s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.10E+06, Train scatter: [0.3164 0.0742 0.5437 0.5323]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.75E-01
Test scatter: [0.3227 0.075  0.5352 0.5257], Lowest was [0.3227 0.075  0.5352 0.5257]
Median for last 10 epochs: [0.4851 0.0785 0.5352 0.5443], Epochs since improvement 0
  2%|▏         | 10/500 [10:03<8:42:51, 64.02s/it]  2%|▏         | 11/500 [10:51<8:00:49, 59.00s/it]  2%|▏         | 12/500 [12:03<8:31:51, 62.93s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 3.69E+06, Train scatter: [0.2833 0.0729 0.5437 0.5171]
L1 regularization loss: 2.08E+00, L2 regularization loss: 4.82E-01
Test scatter: [0.2855 0.0731 0.5352 0.5122], Lowest was [0.2855 0.0731 0.5352 0.5122]
Median for last 10 epochs: [0.4851 0.0785 0.5352 0.5443], Epochs since improvement 0
  3%|▎         | 13/500 [12:50<7:52:36, 58.23s/it]  3%|▎         | 14/500 [14:03<8:26:24, 62.52s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 3.48E+06, Train scatter: [0.2431 0.0715 0.5437 0.5078]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.86E-01
Test scatter: [0.2503 0.0722 0.5351 0.5041], Lowest was [0.2503 0.0722 0.5351 0.5041]
Median for last 10 epochs: [0.3227 0.075  0.5352 0.5257], Epochs since improvement 0
  3%|▎         | 15/500 [14:50<7:48:40, 57.98s/it]  3%|▎         | 16/500 [16:03<8:23:26, 62.41s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.42E+06, Train scatter: [0.2199 0.0693 0.5436 0.507 ]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.91E-01
Test scatter: [0.2225 0.07   0.5351 0.5021], Lowest was [0.2225 0.07   0.5351 0.5021]
Median for last 10 epochs: [0.2855 0.0731 0.5352 0.5122], Epochs since improvement 0
  3%|▎         | 17/500 [16:50<7:46:26, 57.94s/it]  4%|▎         | 18/500 [18:03<8:20:07, 62.26s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.36E+06, Train scatter: [0.2424 0.0691 0.5436 0.5014]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.96E-01
Test scatter: [0.2502 0.0694 0.5351 0.4969], Lowest was [0.2225 0.0694 0.5351 0.4969]
Median for last 10 epochs: [0.2503 0.0722 0.5351 0.5041], Epochs since improvement 0
  4%|▍         | 19/500 [18:50<7:42:54, 57.74s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.33E+06, Train scatter: [0.3231 0.0836 0.5437 0.5804]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.01E-01
Test scatter: [0.3276 0.0847 0.5351 0.5837], Lowest was [0.2225 0.0694 0.5351 0.4969]
Median for last 10 epochs: [0.2503 0.0722 0.5351 0.5041], Epochs since improvement 2
  4%|▍         | 20/500 [20:09<8:33:24, 64.18s/it]  4%|▍         | 21/500 [20:57<7:52:16, 59.16s/it]  4%|▍         | 22/500 [22:09<8:22:07, 63.03s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.29E+06, Train scatter: [0.233  0.0675 0.5436 0.5071]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.08E-01
Test scatter: [0.2352 0.0687 0.5351 0.5044], Lowest was [0.2225 0.0687 0.5351 0.4969]
Median for last 10 epochs: [0.2502 0.07   0.5351 0.5041], Epochs since improvement 0
  5%|▍         | 23/500 [22:56<7:44:20, 58.41s/it]  5%|▍         | 24/500 [24:09<8:17:26, 62.70s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.25E+06, Train scatter: [0.2046 0.0624 0.5436 0.4943]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.15E-01
Test scatter: [0.2104 0.0639 0.5351 0.4926], Lowest was [0.2104 0.0639 0.5351 0.4926]
Median for last 10 epochs: [0.2352 0.0694 0.5351 0.5021], Epochs since improvement 0
  5%|▌         | 25/500 [24:56<7:40:05, 58.12s/it]  5%|▌         | 26/500 [26:08<8:11:52, 62.26s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.21E+06, Train scatter: [0.203  0.0631 0.5436 0.4932]
L1 regularization loss: 2.17E+00, L2 regularization loss: 5.24E-01
Test scatter: [0.2129 0.0636 0.535  0.4869], Lowest was [0.2104 0.0636 0.535  0.4869]
Median for last 10 epochs: [0.2352 0.0687 0.5351 0.4969], Epochs since improvement 0
  5%|▌         | 27/500 [26:55<7:35:09, 57.74s/it]  6%|▌         | 28/500 [28:08<8:08:28, 62.09s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.13E+06, Train scatter: [0.2086 0.0599 0.5437 0.4926]
L1 regularization loss: 2.19E+00, L2 regularization loss: 5.34E-01
Test scatter: [0.214  0.0603 0.5352 0.4851], Lowest was [0.2104 0.0603 0.535  0.4851]
Median for last 10 epochs: [0.214  0.0639 0.5351 0.4926], Epochs since improvement 0
  6%|▌         | 29/500 [28:55<7:32:25, 57.63s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.13E+06, Train scatter: [0.2468 0.082  0.5438 0.5379]
L1 regularization loss: 2.24E+00, L2 regularization loss: 5.51E-01
Test scatter: [0.2486 0.0804 0.5352 0.5275], Lowest was [0.2104 0.0603 0.535  0.4851]
Median for last 10 epochs: [0.214  0.0639 0.5351 0.4926], Epochs since improvement 2
  6%|▌         | 30/500 [30:14<8:21:37, 64.04s/it]  6%|▌         | 31/500 [31:01<7:41:22, 59.02s/it]  6%|▋         | 32/500 [32:14<8:13:18, 63.24s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.07E+06, Train scatter: [0.2358 0.0657 0.5437 0.5089]
L1 regularization loss: 2.25E+00, L2 regularization loss: 5.56E-01
Test scatter: [0.2391 0.0649 0.5351 0.5051], Lowest was [0.2104 0.0603 0.535  0.4851]
Median for last 10 epochs: [0.214  0.0639 0.5351 0.4926], Epochs since improvement 4
  7%|▋         | 33/500 [33:02<7:35:07, 58.47s/it]  7%|▋         | 34/500 [34:13<8:05:01, 62.45s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.06E+06, Train scatter: [0.2237 0.064  0.5436 0.484 ]
L1 regularization loss: 2.26E+00, L2 regularization loss: 5.65E-01
Test scatter: [0.2277 0.0636 0.5351 0.4739], Lowest was [0.2104 0.0603 0.535  0.4739]
Median for last 10 epochs: [0.2277 0.0636 0.5351 0.4869], Epochs since improvement 0
  7%|▋         | 35/500 [35:01<7:28:53, 57.92s/it]  7%|▋         | 36/500 [36:12<7:59:32, 62.01s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.04E+06, Train scatter: [0.2379 0.0599 0.5436 0.4839]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.74E-01
Test scatter: [0.2429 0.0597 0.535  0.4727], Lowest was [0.2104 0.0597 0.535  0.4727]
Median for last 10 epochs: [0.2391 0.0636 0.5351 0.4851], Epochs since improvement 0
  7%|▋         | 37/500 [37:00<7:24:30, 57.60s/it]  8%|▊         | 38/500 [38:11<7:55:41, 61.78s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.05E+06, Train scatter: [0.1995 0.0616 0.5435 0.4861]
L1 regularization loss: 2.29E+00, L2 regularization loss: 5.89E-01
Test scatter: [0.2044 0.0609 0.5349 0.4798], Lowest was [0.2044 0.0597 0.5349 0.4727]
Median for last 10 epochs: [0.2391 0.0636 0.5351 0.4798], Epochs since improvement 0
  8%|▊         | 39/500 [38:59<7:21:22, 57.45s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.06E+06, Train scatter: [0.3445 0.0629 0.5435 0.4862]
L1 regularization loss: 2.34E+00, L2 regularization loss: 6.14E-01
Test scatter: [0.3449 0.0633 0.5349 0.4861], Lowest was [0.2044 0.0597 0.5349 0.4727]
Median for last 10 epochs: [0.2391 0.0633 0.535  0.4798], Epochs since improvement 0
  8%|▊         | 40/500 [40:17<8:09:11, 63.81s/it]  8%|▊         | 41/500 [41:05<7:30:30, 58.89s/it]  8%|▊         | 42/500 [42:16<7:58:09, 62.64s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.04E+06, Train scatter: [0.4142 0.0693 0.5436 0.515 ]
L1 regularization loss: 2.45E+00, L2 regularization loss: 6.54E-01
Test scatter: [0.4067 0.0682 0.535  0.5092], Lowest was [0.2044 0.0597 0.5349 0.4727]
Median for last 10 epochs: [0.2429 0.0633 0.535  0.4798], Epochs since improvement 2
  9%|▊         | 43/500 [43:04<7:22:37, 58.11s/it]  9%|▉         | 44/500 [44:16<7:53:56, 62.36s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.92E+06, Train scatter: [0.4143 0.0712 0.5434 0.504 ]
L1 regularization loss: 2.46E+00, L2 regularization loss: 6.78E-01
Test scatter: [0.4038 0.0693 0.5348 0.4996], Lowest was [0.2044 0.0597 0.5348 0.4727]
Median for last 10 epochs: [0.3449 0.0633 0.5349 0.4861], Epochs since improvement 0
  9%|▉         | 45/500 [45:03<7:19:08, 57.91s/it]  9%|▉         | 46/500 [46:15<7:50:29, 62.18s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.89E+06, Train scatter: [0.272  0.0624 0.5431 0.4957]
L1 regularization loss: 2.48E+00, L2 regularization loss: 6.96E-01
Test scatter: [0.2746 0.0621 0.5346 0.4951], Lowest was [0.2044 0.0597 0.5346 0.4727]
Median for last 10 epochs: [0.3449 0.0633 0.5349 0.4951], Epochs since improvement 0
  9%|▉         | 47/500 [47:03<7:15:48, 57.72s/it] 10%|▉         | 48/500 [48:15<7:47:04, 62.00s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.87E+06, Train scatter: [0.2735 0.0664 0.5404 0.4832]
L1 regularization loss: 2.50E+00, L2 regularization loss: 7.19E-01
Test scatter: [0.2799 0.0673 0.5319 0.4786], Lowest was [0.2044 0.0597 0.5319 0.4727]
Median for last 10 epochs: [0.3449 0.0673 0.5348 0.4951], Epochs since improvement 0
 10%|▉         | 49/500 [49:02<7:13:27, 57.67s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.83E+06, Train scatter: [0.2339 0.0753 0.5352 0.5231]
L1 regularization loss: 2.55E+00, L2 regularization loss: 7.61E-01
Test scatter: [0.243  0.0757 0.5269 0.5252], Lowest was [0.2044 0.0597 0.5269 0.4727]
Median for last 10 epochs: [0.2799 0.0682 0.5346 0.4996], Epochs since improvement 0
 10%|█         | 50/500 [50:20<7:58:35, 63.81s/it] 10%|█         | 51/500 [51:08<7:21:17, 58.97s/it] 10%|█         | 52/500 [52:20<7:48:55, 62.80s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 2.79E+06, Train scatter: [0.2231 0.0593 0.5319 0.4788]
L1 regularization loss: 2.61E+00, L2 regularization loss: 8.09E-01
Test scatter: [0.22   0.0589 0.5237 0.4741], Lowest was [0.2044 0.0589 0.5237 0.4727]
Median for last 10 epochs: [0.2746 0.0673 0.5319 0.4951], Epochs since improvement 0
 11%|█         | 53/500 [53:07<7:13:49, 58.23s/it] 11%|█         | 54/500 [54:19<7:42:22, 62.20s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.34E+06, Train scatter: [0.8855 0.1291 0.5439 0.8413]
L1 regularization loss: 3.08E+00, L2 regularization loss: 1.02E+00
Test scatter: [0.8736 0.1275 0.5354 0.8388], Lowest was [0.2044 0.0589 0.5237 0.4727]
Median for last 10 epochs: [0.2746 0.0673 0.5319 0.4951], Epochs since improvement 2
 11%|█         | 55/500 [55:06<7:08:45, 57.81s/it] 11%|█         | 56/500 [56:18<7:38:46, 62.00s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.03E+06, Train scatter: [0.4659 0.1016 0.5436 0.6647]
L1 regularization loss: 3.08E+00, L2 regularization loss: 1.08E+00
Test scatter: [0.4657 0.1001 0.5351 0.654 ], Lowest was [0.2044 0.0589 0.5237 0.4727]
Median for last 10 epochs: [0.2799 0.0757 0.5319 0.5252], Epochs since improvement 4
 11%|█▏        | 57/500 [57:06<7:05:33, 57.64s/it] 12%|█▏        | 58/500 [58:18<7:36:03, 61.91s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.90E+06, Train scatter: [0.4172 0.0821 0.5354 0.5459]
L1 regularization loss: 3.08E+00, L2 regularization loss: 1.14E+00
Test scatter: [0.4132 0.0814 0.5269 0.5379], Lowest was [0.2044 0.0589 0.5237 0.4727]
Median for last 10 epochs: [0.4132 0.0814 0.5269 0.5379], Epochs since improvement 6
 12%|█▏        | 59/500 [59:05<7:03:37, 57.64s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.92E+06, Train scatter: [0.588  0.0963 0.5338 0.5938]
L1 regularization loss: 3.13E+00, L2 regularization loss: 1.23E+00
Test scatter: [0.58   0.0941 0.5255 0.5811], Lowest was [0.2044 0.0589 0.5237 0.4727]
Median for last 10 epochs: [0.4657 0.0941 0.5269 0.5811], Epochs since improvement 8
 12%|█▏        | 60/500 [1:00:24<7:48:14, 63.85s/it] 12%|█▏        | 61/500 [1:01:11<7:11:37, 58.99s/it] 12%|█▏        | 62/500 [1:02:23<7:37:35, 62.68s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.81E+06, Train scatter: [0.5193 0.0884 0.5358 0.5608]
L1 regularization loss: 3.21E+00, L2 regularization loss: 1.32E+00
Test scatter: [0.51   0.0866 0.5275 0.5514], Lowest was [0.2044 0.0589 0.5237 0.4727]
Median for last 10 epochs: [0.51   0.0941 0.5275 0.5811], Epochs since improvement 10
 13%|█▎        | 63/500 [1:03:10<7:03:21, 58.13s/it] 13%|█▎        | 64/500 [1:04:21<7:30:38, 62.02s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.97E+06, Train scatter: [0.4794 0.0797 0.4089 0.5743]
L1 regularization loss: 3.30E+00, L2 regularization loss: 1.43E+00
Test scatter: [0.4725 0.0798 0.4118 0.5701], Lowest was [0.2044 0.0589 0.4118 0.4727]
Median for last 10 epochs: [0.4725 0.0866 0.5269 0.5701], Epochs since improvement 0
 13%|█▎        | 65/500 [1:05:09<6:58:34, 57.73s/it] 13%|█▎        | 66/500 [1:06:20<7:26:47, 61.77s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.11E+07, Train scatter: [0.9335 0.1727 0.5441 0.9955]
L1 regularization loss: 5.05E+00, L2 regularization loss: 2.39E+00
Test scatter: [0.9177 0.1689 0.5355 0.9851], Lowest was [0.2044 0.0589 0.4118 0.4727]
Median for last 10 epochs: [0.51   0.0866 0.5269 0.5701], Epochs since improvement 2
 13%|█▎        | 67/500 [1:07:08<6:54:59, 57.50s/it] 14%|█▎        | 68/500 [1:08:19<7:24:58, 61.80s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 6.39E+06, Train scatter: [0.9264 0.1413 0.5441 0.9963]
L1 regularization loss: 5.05E+00, L2 regularization loss: 2.51E+00
Test scatter: [0.9123 0.138  0.5355 0.9858], Lowest was [0.2044 0.0589 0.4118 0.4727]
Median for last 10 epochs: [0.58   0.0941 0.5275 0.5811], Epochs since improvement 4
 14%|█▍        | 69/500 [1:09:07<6:53:27, 57.56s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 5.12E+06, Train scatter: [0.7725 0.1306 0.544  0.9957]
L1 regularization loss: 5.05E+00, L2 regularization loss: 2.60E+00
Test scatter: [0.7677 0.1284 0.5354 0.9854], Lowest was [0.2044 0.0589 0.4118 0.4727]
Median for last 10 epochs: [0.7677 0.1284 0.5354 0.9851], Epochs since improvement 6
 14%|█▍        | 70/500 [1:10:26<7:39:09, 64.07s/it] 14%|█▍        | 71/500 [1:11:14<7:03:01, 59.16s/it] 14%|█▍        | 72/500 [1:12:26<7:28:24, 62.86s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 4.62E+06, Train scatter: [0.6978 0.1262 0.5436 0.9944]
L1 regularization loss: 5.08E+00, L2 regularization loss: 2.71E+00
Test scatter: [0.6952 0.1245 0.535  0.9841], Lowest was [0.2044 0.0589 0.4118 0.4727]
Median for last 10 epochs: [0.7677 0.1284 0.5354 0.9851], Epochs since improvement 8
 15%|█▍        | 73/500 [1:13:13<6:54:58, 58.31s/it] 15%|█▍        | 74/500 [1:14:25<7:22:28, 62.32s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 4.25E+06, Train scatter: [0.9084 0.14   0.5379 0.9945]
L1 regularization loss: 5.12E+00, L2 regularization loss: 2.87E+00
Test scatter: [0.8943 0.1383 0.53   0.9843], Lowest was [0.2044 0.0589 0.4118 0.4727]
Median for last 10 epochs: [0.8943 0.138  0.5354 0.9851], Epochs since improvement 10
 15%|█▌        | 75/500 [1:15:13<6:50:34, 57.96s/it] 15%|█▌        | 76/500 [1:16:25<7:19:26, 62.18s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.54E+06, Train scatter: [0.8265 0.123  0.5024 0.9916]
L1 regularization loss: 5.16E+00, L2 regularization loss: 3.06E+00
Test scatter: [0.8151 0.1195 0.4956 0.9814], Lowest was [0.2044 0.0589 0.4118 0.4727]
Median for last 10 epochs: [0.8151 0.1284 0.535  0.9843], Epochs since improvement 12
 15%|█▌        | 77/500 [1:17:12<6:47:31, 57.80s/it] 16%|█▌        | 78/500 [1:18:23<7:14:28, 61.77s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.93E+06, Train scatter: [0.5058 0.1158 0.4475 0.9698]
L1 regularization loss: 5.19E+00, L2 regularization loss: 3.23E+00
Test scatter: [0.4988 0.1124 0.4431 0.9588], Lowest was [0.2044 0.0589 0.4118 0.4727]
Median for last 10 epochs: [0.7677 0.1245 0.53   0.9841], Epochs since improvement 14
 16%|█▌        | 79/500 [1:19:11<6:43:19, 57.48s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.22E+06, Train scatter: [0.4707 0.0934 0.4159 0.9636]
L1 regularization loss: 5.20E+00, L2 regularization loss: 3.36E+00
Test scatter: [0.4671 0.0914 0.4148 0.9542], Lowest was [0.2044 0.0589 0.4118 0.4727]
Median for last 10 epochs: [0.6952 0.1195 0.4956 0.9814], Epochs since improvement 16
 16%|█▌        | 80/500 [1:20:29<7:26:15, 63.75s/it] 16%|█▌        | 81/500 [1:21:17<6:51:03, 58.86s/it] 16%|█▋        | 82/500 [1:22:28<7:16:11, 62.61s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 1.92E+06, Train scatter: [0.4989 0.0925 0.3986 0.9577]
L1 regularization loss: 5.23E+00, L2 regularization loss: 3.51E+00
Test scatter: [0.4872 0.0909 0.3957 0.9485], Lowest was [0.2044 0.0589 0.3957 0.4727]
Median for last 10 epochs: [0.4988 0.1124 0.4431 0.9588], Epochs since improvement 0
 17%|█▋        | 83/500 [1:23:15<6:43:12, 58.02s/it] 17%|█▋        | 84/500 [1:24:27<7:10:08, 62.04s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 1.64E+06, Train scatter: [0.4585 0.0836 0.3728 0.9246]
L1 regularization loss: 5.23E+00, L2 regularization loss: 3.63E+00
Test scatter: [0.4512 0.0829 0.3705 0.9175], Lowest was [0.2044 0.0589 0.3705 0.4727]
Median for last 10 epochs: [0.4872 0.0914 0.4148 0.9542], Epochs since improvement 0
 17%|█▋        | 85/500 [1:25:14<6:38:54, 57.67s/it] 17%|█▋        | 86/500 [1:26:26<7:07:24, 61.94s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 1.40E+06, Train scatter: [0.4558 0.0731 0.3539 0.7845]
L1 regularization loss: 5.26E+00, L2 regularization loss: 3.84E+00
Test scatter: [0.443  0.0729 0.3503 0.7799], Lowest was [0.2044 0.0589 0.3503 0.4727]
Median for last 10 epochs: [0.4671 0.0909 0.3957 0.9485], Epochs since improvement 0
 17%|█▋        | 87/500 [1:27:14<6:37:06, 57.69s/it] 18%|█▊        | 88/500 [1:28:25<7:04:28, 61.82s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 1.24E+06, Train scatter: [0.4921 0.0724 0.3508 0.7179]
L1 regularization loss: 5.28E+00, L2 regularization loss: 4.07E+00
Test scatter: [0.472  0.072  0.3474 0.7123], Lowest was [0.2044 0.0589 0.3474 0.4727]
Median for last 10 epochs: [0.4671 0.0829 0.3705 0.9175], Epochs since improvement 0
 18%|█▊        | 89/500 [1:29:13<6:33:48, 57.49s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 1.15E+06, Train scatter: [0.5337 0.0695 0.3385 0.6529]
L1 regularization loss: 5.34E+00, L2 regularization loss: 4.28E+00
Test scatter: [0.5106 0.0687 0.3347 0.6479], Lowest was [0.2044 0.0589 0.3347 0.4727]
Median for last 10 epochs: [0.472  0.0729 0.3503 0.7799], Epochs since improvement 0
 18%|█▊        | 90/500 [1:30:32<7:16:48, 63.92s/it] 18%|█▊        | 91/500 [1:31:19<6:41:54, 58.96s/it] 18%|█▊        | 92/500 [1:32:32<7:08:57, 63.08s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 9.84E+05, Train scatter: [0.4583 0.0658 0.3273 0.6153]
L1 regularization loss: 5.30E+00, L2 regularization loss: 4.39E+00
Test scatter: [0.44   0.0656 0.3265 0.6143], Lowest was [0.2044 0.0589 0.3265 0.4727]
Median for last 10 epochs: [0.4512 0.072  0.3474 0.7123], Epochs since improvement 0
 19%|█▊        | 93/500 [1:33:19<6:35:34, 58.32s/it] 19%|█▉        | 94/500 [1:34:31<7:02:09, 62.39s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 9.05E+05, Train scatter: [0.4234 0.0681 0.3272 0.5991]
L1 regularization loss: 5.27E+00, L2 regularization loss: 4.48E+00
Test scatter: [0.4129 0.0689 0.3241 0.601 ], Lowest was [0.2044 0.0589 0.3241 0.4727]
Median for last 10 epochs: [0.443  0.0689 0.3347 0.6479], Epochs since improvement 0
 19%|█▉        | 95/500 [1:35:18<6:30:35, 57.87s/it] 19%|█▉        | 96/500 [1:36:30<6:56:51, 61.91s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 8.49E+05, Train scatter: [0.4135 0.0653 0.3219 0.5691]
L1 regularization loss: 5.25E+00, L2 regularization loss: 4.57E+00
Test scatter: [0.4008 0.0654 0.3185 0.568 ], Lowest was [0.2044 0.0589 0.3185 0.4727]
Median for last 10 epochs: [0.44   0.0687 0.3265 0.6143], Epochs since improvement 0
 19%|█▉        | 97/500 [1:37:17<6:26:23, 57.53s/it] 20%|█▉        | 98/500 [1:38:29<6:54:11, 61.82s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 8.11E+05, Train scatter: [0.3996 0.0645 0.3286 0.5562]
L1 regularization loss: 5.20E+00, L2 regularization loss: 4.62E+00
Test scatter: [0.4007 0.0653 0.3318 0.5565], Lowest was [0.2044 0.0589 0.3185 0.4727]
Median for last 10 epochs: [0.4129 0.0656 0.3265 0.601 ], Epochs since improvement 2
 20%|█▉        | 99/500 [1:39:16<6:23:51, 57.43s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 8.24E+05, Train scatter: [0.4528 0.0649 0.3179 0.5665]
L1 regularization loss: 5.17E+00, L2 regularization loss: 4.70E+00
Test scatter: [0.434  0.0644 0.3168 0.5647], Lowest was [0.2044 0.0589 0.3168 0.4727]
Median for last 10 epochs: [0.4129 0.0654 0.3241 0.568 ], Epochs since improvement 0
 20%|██        | 100/500 [1:40:34<7:04:13, 63.63s/it] 20%|██        | 101/500 [1:41:21<6:30:34, 58.73s/it] 20%|██        | 102/500 [1:42:33<6:54:53, 62.55s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 7.37E+05, Train scatter: [0.3268 0.0655 0.3104 0.5532]
L1 regularization loss: 5.16E+00, L2 regularization loss: 4.76E+00
Test scatter: [0.3201 0.0653 0.31   0.5525], Lowest was [0.2044 0.0589 0.31   0.4727]
Median for last 10 epochs: [0.4008 0.0653 0.3185 0.5647], Epochs since improvement 0
 21%|██        | 103/500 [1:43:20<6:23:19, 57.93s/it] 21%|██        | 104/500 [1:44:31<6:48:34, 61.91s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 7.37E+05, Train scatter: [0.4431 0.079  0.346  0.6167]
L1 regularization loss: 5.20E+00, L2 regularization loss: 4.88E+00
Test scatter: [0.4334 0.0795 0.3453 0.6178], Lowest was [0.2044 0.0589 0.31   0.4727]
Median for last 10 epochs: [0.4008 0.0653 0.3185 0.5647], Epochs since improvement 2
 21%|██        | 105/500 [1:45:18<6:18:39, 57.52s/it] 21%|██        | 106/500 [1:46:30<6:45:20, 61.73s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 6.47E+05, Train scatter: [0.3574 0.0632 0.3148 0.5722]
L1 regularization loss: 5.33E+00, L2 regularization loss: 5.07E+00
Test scatter: [0.3442 0.0634 0.3168 0.5734], Lowest was [0.2044 0.0589 0.31   0.4727]
Median for last 10 epochs: [0.4007 0.0653 0.3168 0.5647], Epochs since improvement 4
 21%|██▏       | 107/500 [1:47:17<6:15:41, 57.36s/it] 22%|██▏       | 108/500 [1:48:29<6:42:20, 61.58s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 5.25E+05, Train scatter: [0.4451 0.0591 0.3118 0.5677]
L1 regularization loss: 5.26E+00, L2 regularization loss: 5.13E+00
Test scatter: [0.4236 0.059  0.314  0.5647], Lowest was [0.2044 0.0589 0.31   0.4727]
Median for last 10 epochs: [0.4236 0.0644 0.3168 0.5647], Epochs since improvement 6
 22%|██▏       | 109/500 [1:49:16<6:13:28, 57.31s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 4.99E+05, Train scatter: [0.2953 0.0645 0.29   0.5303]
L1 regularization loss: 5.21E+00, L2 regularization loss: 5.21E+00
Test scatter: [0.2864 0.0636 0.291  0.5247], Lowest was [0.2044 0.0589 0.291  0.4727]
Median for last 10 epochs: [0.3442 0.0636 0.314  0.5647], Epochs since improvement 0
 22%|██▏       | 110/500 [1:50:34<6:52:54, 63.53s/it] 22%|██▏       | 111/500 [1:51:21<6:20:06, 58.63s/it] 22%|██▏       | 112/500 [1:52:32<6:43:32, 62.40s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 4.08E+05, Train scatter: [0.2791 0.0575 0.2861 0.5364]
L1 regularization loss: 5.22E+00, L2 regularization loss: 5.30E+00
Test scatter: [0.2712 0.0572 0.2872 0.5312], Lowest was [0.2044 0.0572 0.2872 0.4727]
Median for last 10 epochs: [0.3442 0.0634 0.314  0.5647], Epochs since improvement 0
 23%|██▎       | 113/500 [1:53:19<6:13:04, 57.84s/it] 23%|██▎       | 114/500 [1:54:31<6:37:55, 61.85s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 3.45E+05, Train scatter: [0.2375 0.0568 0.2707 0.5232]
L1 regularization loss: 5.18E+00, L2 regularization loss: 5.39E+00
Test scatter: [0.2321 0.0567 0.2714 0.5201], Lowest was [0.2044 0.0567 0.2714 0.4727]
Median for last 10 epochs: [0.2864 0.059  0.291  0.5312], Epochs since improvement 0
 23%|██▎       | 115/500 [1:55:18<6:08:59, 57.50s/it] 23%|██▎       | 116/500 [1:56:29<6:34:45, 61.68s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 3.66E+05, Train scatter: [0.4111 0.0573 0.2844 0.5384]
L1 regularization loss: 5.43E+00, L2 regularization loss: 5.58E+00
Test scatter: [0.3985 0.0574 0.2864 0.5341], Lowest was [0.2044 0.0567 0.2714 0.4727]
Median for last 10 epochs: [0.2864 0.0574 0.2872 0.5312], Epochs since improvement 2
 23%|██▎       | 117/500 [1:57:17<6:06:18, 57.39s/it] 24%|██▎       | 118/500 [1:58:28<6:32:29, 61.65s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 6.77E+05, Train scatter: [0.5686 0.0817 0.53   0.57  ]
L1 regularization loss: 5.72E+00, L2 regularization loss: 5.92E+00
Test scatter: [0.5519 0.0812 0.522  0.5709], Lowest was [0.2044 0.0567 0.2714 0.4727]
Median for last 10 epochs: [0.2864 0.0574 0.2872 0.5312], Epochs since improvement 4
 24%|██▍       | 119/500 [1:59:16<6:04:11, 57.35s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 4.06E+05, Train scatter: [0.2437 0.057  0.2689 0.5251]
L1 regularization loss: 5.61E+00, L2 regularization loss: 5.99E+00
Test scatter: [0.2381 0.0567 0.2708 0.5216], Lowest was [0.2044 0.0567 0.2708 0.4727]
Median for last 10 epochs: [0.2712 0.0572 0.2864 0.5312], Epochs since improvement 0
 24%|██▍       | 120/500 [2:00:33<6:41:52, 63.45s/it] 24%|██▍       | 121/500 [2:01:21<6:10:04, 58.59s/it] 24%|██▍       | 122/500 [2:02:32<6:32:20, 62.28s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 2.14E+05, Train scatter: [0.2859 0.0602 0.2873 0.5278]
L1 regularization loss: 5.50E+00, L2 regularization loss: 6.04E+00
Test scatter: [0.2748 0.0602 0.2878 0.5238], Lowest was [0.2044 0.0567 0.2708 0.4727]
Median for last 10 epochs: [0.2748 0.0574 0.2864 0.5238], Epochs since improvement 2
 25%|██▍       | 123/500 [2:03:19<6:02:51, 57.75s/it] 25%|██▍       | 124/500 [2:04:30<6:28:01, 61.92s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.54E+05, Train scatter: [0.5326 0.0529 0.2642 0.5099]
L1 regularization loss: 5.50E+00, L2 regularization loss: 6.17E+00
Test scatter: [0.4964 0.0524 0.2658 0.505 ], Lowest was [0.2044 0.0524 0.2658 0.4727]
Median for last 10 epochs: [0.3985 0.0574 0.2864 0.5238], Epochs since improvement 0
 25%|██▌       | 125/500 [2:05:18<5:59:30, 57.52s/it] 25%|██▌       | 126/500 [2:06:29<6:23:47, 61.57s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 2.05E+04, Train scatter: [0.2793 0.0758 0.364  0.5419]
L1 regularization loss: 5.56E+00, L2 regularization loss: 6.26E+00
Test scatter: [0.2671 0.0737 0.3644 0.537 ], Lowest was [0.2044 0.0524 0.2658 0.4727]
Median for last 10 epochs: [0.2748 0.0602 0.2878 0.5238], Epochs since improvement 2
 25%|██▌       | 127/500 [2:07:16<5:56:20, 57.32s/it] 26%|██▌       | 128/500 [2:08:27<6:20:21, 61.35s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -1.04E+05, Train scatter: [0.3685 0.0495 0.2437 0.4948]
L1 regularization loss: 5.49E+00, L2 regularization loss: 6.29E+00
Test scatter: [0.3577 0.0492 0.2463 0.4905], Lowest was [0.2044 0.0492 0.2463 0.4727]
Median for last 10 epochs: [0.2748 0.0567 0.2708 0.5216], Epochs since improvement 0
 26%|██▌       | 129/500 [2:09:14<5:53:03, 57.10s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -2.27E+05, Train scatter: [0.2143 0.0508 0.2368 0.4872]
L1 regularization loss: 5.45E+00, L2 regularization loss: 6.29E+00
Test scatter: [0.2133 0.0501 0.2394 0.4825], Lowest was [0.2044 0.0492 0.2394 0.4727]
Median for last 10 epochs: [0.2748 0.0524 0.2658 0.505 ], Epochs since improvement 0
 26%|██▌       | 130/500 [2:10:33<6:31:58, 63.56s/it] 26%|██▌       | 131/500 [2:11:20<6:00:30, 58.62s/it] 26%|██▋       | 132/500 [2:12:32<6:24:29, 62.69s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -2.81E+05, Train scatter: [0.1969 0.0463 0.2346 0.4775]
L1 regularization loss: 5.46E+00, L2 regularization loss: 6.32E+00
Test scatter: [0.194  0.0456 0.238  0.472 ], Lowest was [0.194  0.0456 0.238  0.472 ]
Median for last 10 epochs: [0.2671 0.0501 0.2463 0.4905], Epochs since improvement 0
 27%|██▋       | 133/500 [2:13:19<5:54:52, 58.02s/it] 27%|██▋       | 134/500 [2:14:30<6:18:18, 62.02s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: -3.10E+05, Train scatter: [0.2579 0.0468 0.2363 0.4693]
L1 regularization loss: 5.44E+00, L2 regularization loss: 6.34E+00
Test scatter: [0.2517 0.0466 0.238  0.4637], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.2517 0.0492 0.2394 0.4825], Epochs since improvement 0
 27%|██▋       | 135/500 [2:15:18<5:50:08, 57.56s/it] 27%|██▋       | 136/500 [2:16:29<6:13:49, 61.62s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 1.12E+05, Train scatter: [0.8869 0.1707 0.5441 0.831 ]
L1 regularization loss: 6.52E+00, L2 regularization loss: 7.29E+00
Test scatter: [0.8726 0.1669 0.5355 0.8257], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.2517 0.0492 0.2394 0.4825], Epochs since improvement 2
 27%|██▋       | 137/500 [2:17:16<5:46:30, 57.27s/it] 28%|██▊       | 138/500 [2:18:29<6:13:31, 61.91s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -9.17E+03, Train scatter: [0.8165 0.1563 0.544  0.7629]
L1 regularization loss: 7.13E+00, L2 regularization loss: 8.44E+00
Test scatter: [0.803  0.1529 0.5355 0.7611], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.2517 0.0501 0.2394 0.4825], Epochs since improvement 4
 28%|██▊       | 139/500 [2:19:16<5:45:53, 57.49s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -7.77E+04, Train scatter: [0.675  0.1224 0.544  0.7136]
L1 regularization loss: 6.93E+00, L2 regularization loss: 8.46E+00
Test scatter: [0.6635 0.121  0.5354 0.7089], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.6635 0.121  0.5354 0.7089], Epochs since improvement 6
 28%|██▊       | 140/500 [2:20:36<6:25:09, 64.19s/it] 28%|██▊       | 141/500 [2:21:23<5:53:12, 59.03s/it] 28%|██▊       | 142/500 [2:22:34<6:15:14, 62.89s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -9.07E+04, Train scatter: [0.7463 0.1136 0.544  0.6763]
L1 regularization loss: 6.97E+00, L2 regularization loss: 8.79E+00
Test scatter: [0.7311 0.1123 0.5354 0.6698], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.7311 0.121  0.5354 0.7089], Epochs since improvement 8
 29%|██▊       | 143/500 [2:23:22<5:46:09, 58.18s/it] 29%|██▉       | 144/500 [2:24:34<6:10:38, 62.47s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: -1.18E+05, Train scatter: [0.5349 0.1071 0.5439 0.6441]
L1 regularization loss: 6.83E+00, L2 regularization loss: 8.66E+00
Test scatter: [0.5253 0.1053 0.5353 0.6379], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.7311 0.121  0.5354 0.7089], Epochs since improvement 10
 29%|██▉       | 145/500 [2:25:21<5:42:25, 57.87s/it] 29%|██▉       | 146/500 [2:26:33<6:06:55, 62.19s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: -1.49E+05, Train scatter: [0.3704 0.1007 0.5439 0.5968]
L1 regularization loss: 6.70E+00, L2 regularization loss: 8.55E+00
Test scatter: [0.3685 0.0983 0.5353 0.5897], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.6635 0.1123 0.5354 0.6698], Epochs since improvement 12
 29%|██▉       | 147/500 [2:27:21<5:39:13, 57.66s/it] 30%|██▉       | 148/500 [2:28:33<6:03:34, 61.97s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: -1.64E+05, Train scatter: [0.4224 0.0955 0.5438 0.6113]
L1 regularization loss: 6.55E+00, L2 regularization loss: 8.43E+00
Test scatter: [0.4191 0.0938 0.5352 0.601 ], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.5253 0.1053 0.5353 0.6379], Epochs since improvement 14
 30%|██▉       | 149/500 [2:29:20<5:36:21, 57.50s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: -1.66E+05, Train scatter: [0.473  0.0949 0.5437 0.5806]
L1 regularization loss: 6.39E+00, L2 regularization loss: 8.33E+00
Test scatter: [0.4643 0.0936 0.5351 0.5754], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.4643 0.0983 0.5353 0.601 ], Epochs since improvement 16
 30%|███       | 150/500 [2:30:37<6:10:54, 63.58s/it] 30%|███       | 151/500 [2:31:24<5:40:52, 58.60s/it] 30%|███       | 152/500 [2:32:37<6:04:08, 62.78s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: -1.72E+05, Train scatter: [0.3948 0.091  0.5435 0.5553]
L1 regularization loss: 6.26E+00, L2 regularization loss: 8.26E+00
Test scatter: [0.3878 0.0891 0.5349 0.5468], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.4191 0.0938 0.5352 0.5897], Epochs since improvement 18
 31%|███       | 153/500 [2:33:24<5:35:59, 58.10s/it] 31%|███       | 154/500 [2:34:37<5:59:51, 62.40s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: -1.85E+05, Train scatter: [0.371  0.086  0.5428 0.5339]
L1 regularization loss: 6.12E+00, L2 regularization loss: 8.20E+00
Test scatter: [0.3651 0.0846 0.5343 0.5265], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.3878 0.0936 0.5351 0.5754], Epochs since improvement 20
 31%|███       | 155/500 [2:35:24<5:32:31, 57.83s/it] 31%|███       | 155/500 [2:36:36<5:48:34, 60.62s/it]
Epoch: 156 done with learning rate 9.13E-03, Train loss: -1.96E+05, Train scatter: [0.3684 0.0841 0.5396 0.5445]
L1 regularization loss: 5.97E+00, L2 regularization loss: 8.15E+00
Test scatter: [0.3629 0.0829 0.5312 0.5393], Lowest was [0.194  0.0456 0.238  0.4637]
Median for last 10 epochs: [0.3878 0.0891 0.5349 0.5468], Epochs since improvement 22
Exited after 156 epochs due to early stopping
9396.30 seconds spent training, 18.793 seconds per epoch. Processed 3705 trees per second
[0.36284953 0.08288993 0.5311956  0.5392677 ]
{'epoch_exit': 155, 'scatter_m_star': 0.36284953, 'lowest_m_star': 0.19396499, 'last20_m_star': 0.44169554, 'last10_m_star': 0.38775247, 'scatter_v_disk': 0.08288993, 'lowest_v_disk': 0.04559995, 'last20_v_disk': 0.09608118, 'last10_v_disk': 0.089079246, 'scatter_m_cold': 0.5311956, 'lowest_m_cold': 0.23799822, 'last20_m_cold': 0.5352627, 'last10_m_cold': 0.5349091, 'scatter_sfr_100': 0.5392677, 'lowest_sfr_100': 0.4637147, 'last20_sfr_100': 0.5953559, 'last10_sfr_100': 0.5467558}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_ouowem
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:41<5:45:26, 41.54s/it]  0%|          | 2/500 [01:45<7:32:58, 54.58s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.01E+07, Train scatter: [0.9352 0.1707 0.5441 0.9954]
L1 regularization loss: 1.98E+00, L2 regularization loss: 3.76E-01
Test scatter: [0.9196 0.1669 0.5356 0.9851], Lowest was [0.9196 0.1669 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1669 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:25<6:39:16, 48.20s/it]  1%|          | 4/500 [03:29<7:28:33, 54.26s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.21E+07, Train scatter: [0.9352 0.1537 0.5441 0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.85E-01
Test scatter: [0.9196 0.1501 0.5355 0.9851], Lowest was [0.9196 0.1501 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1501 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:10<6:47:02, 49.34s/it]  1%|          | 6/500 [05:13<7:24:48, 54.02s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.72E+07, Train scatter: [0.9348 0.114  0.544  0.9954]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.01E-01
Test scatter: [0.9193 0.1125 0.5355 0.985 ], Lowest was [0.9193 0.1125 0.5355 0.985 ]
Median for last 10 epochs: [0.9193 0.1125 0.5355 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [05:53<6:47:31, 49.60s/it]  2%|▏         | 8/500 [06:57<7:23:07, 54.04s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.32E+07, Train scatter: [0.9211 0.0939 0.5439 0.8334]
L1 regularization loss: 2.04E+00, L2 regularization loss: 4.27E-01
Test scatter: [0.906  0.0939 0.5354 0.8305], Lowest was [0.906  0.0939 0.5354 0.8305]
Median for last 10 epochs: [0.9127 0.1032 0.5354 0.9078], Epochs since improvement 0
  2%|▏         | 9/500 [07:37<6:47:49, 49.84s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 9.79E+06, Train scatter: [0.7782 0.0962 0.5438 0.6282]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.59E-01
Test scatter: [0.7667 0.0956 0.5353 0.6264], Lowest was [0.7667 0.0939 0.5353 0.6264]
Median for last 10 epochs: [0.906  0.0956 0.5354 0.8305], Epochs since improvement 0
  2%|▏         | 10/500 [08:48<7:38:51, 56.19s/it]  2%|▏         | 11/500 [09:28<6:59:11, 51.44s/it]  2%|▏         | 12/500 [10:31<7:27:06, 54.97s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.76E+06, Train scatter: [0.698  0.0861 0.5438 0.5879]
L1 regularization loss: 2.08E+00, L2 regularization loss: 4.71E-01
Test scatter: [0.6946 0.0863 0.5353 0.5938], Lowest was [0.6946 0.0863 0.5353 0.5938]
Median for last 10 epochs: [0.906  0.0956 0.5354 0.8305], Epochs since improvement 0
  3%|▎         | 13/500 [11:12<6:51:09, 50.66s/it]  3%|▎         | 14/500 [12:17<7:24:50, 54.92s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 5.18E+06, Train scatter: [0.5511 0.0851 0.5438 0.5504]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.82E-01
Test scatter: [0.5476 0.0862 0.5352 0.5503], Lowest was [0.5476 0.0862 0.5352 0.5503]
Median for last 10 epochs: [0.7667 0.0939 0.5353 0.6264], Epochs since improvement 0
  3%|▎         | 15/500 [12:58<6:49:37, 50.68s/it]  3%|▎         | 16/500 [14:01<7:20:25, 54.60s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.44E+06, Train scatter: [0.5403 0.0929 0.5438 0.6241]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.90E-01
Test scatter: [0.5367 0.0915 0.5352 0.6258], Lowest was [0.5367 0.0862 0.5352 0.5503]
Median for last 10 epochs: [0.6946 0.0915 0.5353 0.6258], Epochs since improvement 0
  3%|▎         | 17/500 [14:43<6:46:50, 50.54s/it]  4%|▎         | 18/500 [15:47<7:19:06, 54.66s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.73E+06, Train scatter: [0.2922 0.079  0.5438 0.5483]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.99E-01
Test scatter: [0.2985 0.0791 0.5352 0.5408], Lowest was [0.2985 0.0791 0.5352 0.5408]
Median for last 10 epochs: [0.5476 0.0863 0.5352 0.5938], Epochs since improvement 0
  4%|▍         | 19/500 [16:28<6:45:25, 50.57s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.56E+06, Train scatter: [0.3746 0.0806 0.5438 0.5519]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.06E-01
Test scatter: [0.3765 0.0805 0.5352 0.547 ], Lowest was [0.2985 0.0791 0.5352 0.5408]
Median for last 10 epochs: [0.5367 0.0862 0.5352 0.5503], Epochs since improvement 2
  4%|▍         | 20/500 [17:38<7:30:48, 56.35s/it]  4%|▍         | 21/500 [18:19<6:52:42, 51.70s/it]  4%|▍         | 22/500 [19:23<7:21:34, 55.43s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.44E+06, Train scatter: [0.2449 0.0766 0.5438 0.518 ]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.13E-01
Test scatter: [0.2508 0.0771 0.5352 0.5191], Lowest was [0.2508 0.0771 0.5352 0.5191]
Median for last 10 epochs: [0.3765 0.0805 0.5352 0.547 ], Epochs since improvement 0
  5%|▍         | 23/500 [20:03<6:45:41, 51.03s/it]  5%|▍         | 24/500 [21:07<7:15:14, 54.86s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.40E+06, Train scatter: [0.2579 0.0781 0.5438 0.5395]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.18E-01
Test scatter: [0.2616 0.0795 0.5352 0.5424], Lowest was [0.2508 0.0771 0.5352 0.5191]
Median for last 10 epochs: [0.2985 0.0795 0.5352 0.5424], Epochs since improvement 2
  5%|▌         | 25/500 [21:48<6:40:33, 50.60s/it]  5%|▌         | 26/500 [22:52<7:12:05, 54.69s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.38E+06, Train scatter: [0.3333 0.074  0.5438 0.5893]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.22E-01
Test scatter: [0.3354 0.0762 0.5352 0.5959], Lowest was [0.2508 0.0762 0.5352 0.5191]
Median for last 10 epochs: [0.2985 0.0791 0.5352 0.5424], Epochs since improvement 0
  5%|▌         | 27/500 [23:33<6:38:06, 50.50s/it]  6%|▌         | 28/500 [24:38<7:11:42, 54.88s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.31E+06, Train scatter: [0.2202 0.0728 0.5437 0.5086]
L1 regularization loss: 2.16E+00, L2 regularization loss: 5.27E-01
Test scatter: [0.2279 0.0736 0.5351 0.5041], Lowest was [0.2279 0.0736 0.5351 0.5041]
Median for last 10 epochs: [0.2616 0.0771 0.5352 0.5424], Epochs since improvement 0
  6%|▌         | 29/500 [25:19<6:37:44, 50.67s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.31E+06, Train scatter: [0.2272 0.072  0.5437 0.5178]
L1 regularization loss: 2.17E+00, L2 regularization loss: 5.32E-01
Test scatter: [0.2323 0.0728 0.5351 0.5089], Lowest was [0.2279 0.0728 0.5351 0.5041]
Median for last 10 epochs: [0.2508 0.0762 0.5352 0.5191], Epochs since improvement 0
  6%|▌         | 30/500 [26:29<7:23:47, 56.65s/it]  6%|▌         | 31/500 [27:10<6:45:18, 51.85s/it]  6%|▋         | 32/500 [28:13<7:11:36, 55.33s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.28E+06, Train scatter: [0.216  0.069  0.5437 0.5059]
L1 regularization loss: 2.18E+00, L2 regularization loss: 5.38E-01
Test scatter: [0.2198 0.0699 0.5351 0.4984], Lowest was [0.2198 0.0699 0.5351 0.4984]
Median for last 10 epochs: [0.2323 0.0736 0.5351 0.5089], Epochs since improvement 0
  7%|▋         | 33/500 [28:54<6:36:40, 50.96s/it]  7%|▋         | 34/500 [29:58<7:06:32, 54.92s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.25E+06, Train scatter: [0.2387 0.0694 0.5437 0.5189]
L1 regularization loss: 2.20E+00, L2 regularization loss: 5.45E-01
Test scatter: [0.2448 0.0707 0.5351 0.5207], Lowest was [0.2198 0.0699 0.5351 0.4984]
Median for last 10 epochs: [0.2323 0.0728 0.5351 0.5089], Epochs since improvement 0
  7%|▋         | 35/500 [30:39<6:33:18, 50.75s/it]  7%|▋         | 36/500 [31:42<7:00:38, 54.39s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.59E+06, Train scatter: [0.2365 0.0824 0.5437 0.5117]
L1 regularization loss: 2.24E+00, L2 regularization loss: 5.65E-01
Test scatter: [0.2404 0.0817 0.5351 0.5062], Lowest was [0.2198 0.0699 0.5351 0.4984]
Median for last 10 epochs: [0.2323 0.0728 0.5351 0.5062], Epochs since improvement 2
  7%|▋         | 37/500 [32:23<6:28:22, 50.33s/it]  8%|▊         | 38/500 [33:28<7:00:25, 54.60s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.22E+06, Train scatter: [0.2076 0.0719 0.5436 0.5069]
L1 regularization loss: 2.25E+00, L2 regularization loss: 5.71E-01
Test scatter: [0.2097 0.0722 0.535  0.5058], Lowest was [0.2097 0.0699 0.535  0.4984]
Median for last 10 epochs: [0.2323 0.0722 0.5351 0.5062], Epochs since improvement 0
  8%|▊         | 39/500 [34:08<6:27:35, 50.45s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.23E+06, Train scatter: [0.1983 0.0701 0.5435 0.4995]
L1 regularization loss: 2.26E+00, L2 regularization loss: 5.78E-01
Test scatter: [0.2039 0.0702 0.535  0.4917], Lowest was [0.2039 0.0699 0.535  0.4917]
Median for last 10 epochs: [0.2198 0.0707 0.5351 0.5058], Epochs since improvement 0
  8%|▊         | 40/500 [35:18<7:10:08, 56.11s/it]  8%|▊         | 41/500 [35:59<6:34:01, 51.51s/it]  8%|▊         | 42/500 [37:03<7:02:07, 55.30s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.19E+06, Train scatter: [0.2052 0.0682 0.5435 0.5045]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.86E-01
Test scatter: [0.2101 0.0686 0.535  0.4997], Lowest was [0.2039 0.0686 0.535  0.4917]
Median for last 10 epochs: [0.2101 0.0707 0.535  0.5058], Epochs since improvement 0
  9%|▊         | 43/500 [37:43<6:27:55, 50.93s/it]  9%|▉         | 44/500 [38:47<6:56:33, 54.81s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.19E+06, Train scatter: [0.2558 0.0683 0.5435 0.4971]
L1 regularization loss: 2.28E+00, L2 regularization loss: 5.93E-01
Test scatter: [0.2601 0.0691 0.5349 0.4939], Lowest was [0.2039 0.0686 0.5349 0.4917]
Median for last 10 epochs: [0.2101 0.0702 0.535  0.4997], Epochs since improvement 0
  9%|▉         | 45/500 [39:28<6:23:29, 50.57s/it]  9%|▉         | 46/500 [40:33<6:56:17, 55.02s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.16E+06, Train scatter: [0.2116 0.0691 0.5435 0.5027]
L1 regularization loss: 2.29E+00, L2 regularization loss: 5.99E-01
Test scatter: [0.2156 0.0693 0.5349 0.5   ], Lowest was [0.2039 0.0686 0.5349 0.4917]
Median for last 10 epochs: [0.2101 0.0693 0.535  0.4997], Epochs since improvement 2
  9%|▉         | 47/500 [41:14<6:23:18, 50.77s/it] 10%|▉         | 48/500 [42:20<6:55:39, 55.18s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.15E+06, Train scatter: [0.1997 0.0667 0.5434 0.4962]
L1 regularization loss: 2.30E+00, L2 regularization loss: 6.05E-01
Test scatter: [0.2036 0.0673 0.5349 0.4892], Lowest was [0.2036 0.0673 0.5349 0.4892]
Median for last 10 epochs: [0.2101 0.0691 0.5349 0.4939], Epochs since improvement 0
 10%|▉         | 49/500 [43:00<6:22:00, 50.82s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.23E+06, Train scatter: [0.3603 0.0811 0.5435 0.513 ]
L1 regularization loss: 2.34E+00, L2 regularization loss: 6.24E-01
Test scatter: [0.3619 0.08   0.5349 0.5056], Lowest was [0.2036 0.0673 0.5349 0.4892]
Median for last 10 epochs: [0.2156 0.0691 0.5349 0.4997], Epochs since improvement 2
 10%|█         | 50/500 [44:13<7:10:50, 57.45s/it] 10%|█         | 51/500 [44:54<6:32:34, 52.46s/it] 10%|█         | 52/500 [45:58<6:57:59, 55.98s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.16E+06, Train scatter: [0.2548 0.0739 0.5434 0.521 ]
L1 regularization loss: 2.39E+00, L2 regularization loss: 6.42E-01
Test scatter: [0.3009 0.074  0.5348 0.5205], Lowest was [0.2036 0.0673 0.5348 0.4892]
Median for last 10 epochs: [0.2601 0.0693 0.5349 0.5   ], Epochs since improvement 0
 11%|█         | 53/500 [46:39<6:23:34, 51.49s/it] 11%|█         | 54/500 [47:43<6:50:19, 55.20s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.19E+06, Train scatter: [0.4106 0.0785 0.5432 0.4961]
L1 regularization loss: 2.41E+00, L2 regularization loss: 6.50E-01
Test scatter: [0.4055 0.0776 0.5346 0.4911], Lowest was [0.2036 0.0673 0.5346 0.4892]
Median for last 10 epochs: [0.3009 0.074  0.5349 0.5   ], Epochs since improvement 0
 11%|█         | 55/500 [48:24<6:17:42, 50.93s/it] 11%|█         | 56/500 [49:28<6:46:30, 54.93s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.16E+06, Train scatter: [0.3441 0.0692 0.5431 0.5052]
L1 regularization loss: 2.41E+00, L2 regularization loss: 6.54E-01
Test scatter: [0.3411 0.069  0.5345 0.5023], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.3411 0.074  0.5348 0.5023], Epochs since improvement 0
 11%|█▏        | 57/500 [50:09<6:14:25, 50.71s/it] 12%|█▏        | 58/500 [51:14<6:44:19, 54.89s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.13E+06, Train scatter: [0.3413 0.0693 0.543  0.5447]
L1 regularization loss: 2.42E+00, L2 regularization loss: 6.63E-01
Test scatter: [0.3447 0.0693 0.5345 0.5505], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.3447 0.074  0.5346 0.5056], Epochs since improvement 2
 12%|█▏        | 59/500 [51:55<6:12:22, 50.66s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 6.88E+06, Train scatter: [0.9302 0.1689 0.544  0.9947]
L1 regularization loss: 3.46E+00, L2 regularization loss: 1.10E+00
Test scatter: [0.9151 0.1655 0.5355 0.9845], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.3447 0.074  0.5346 0.5205], Epochs since improvement 4
 12%|█▏        | 60/500 [53:06<6:57:08, 56.88s/it] 12%|█▏        | 61/500 [53:47<6:20:29, 52.00s/it] 12%|█▏        | 62/500 [54:52<6:48:54, 56.01s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 4.95E+06, Train scatter: [0.832  0.1532 0.5441 0.9939]
L1 regularization loss: 3.47E+00, L2 regularization loss: 1.12E+00
Test scatter: [0.8633 0.1523 0.5355 0.9838], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.4055 0.0776 0.5346 0.5505], Epochs since improvement 6
 13%|█▎        | 63/500 [55:33<6:14:33, 51.43s/it] 13%|█▎        | 64/500 [56:37<6:40:28, 55.11s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 4.48E+06, Train scatter: [0.7174 0.1413 0.5441 0.9915]
L1 regularization loss: 3.48E+00, L2 regularization loss: 1.13E+00
Test scatter: [0.7109 0.1417 0.5355 0.9816], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.7109 0.1417 0.5355 0.9816], Epochs since improvement 8
 13%|█▎        | 65/500 [57:17<6:08:17, 50.80s/it] 13%|█▎        | 66/500 [58:22<6:38:06, 55.04s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 4.35E+06, Train scatter: [0.7163 0.124  0.5441 0.9857]
L1 regularization loss: 3.48E+00, L2 regularization loss: 1.14E+00
Test scatter: [0.7279 0.1239 0.5355 0.9758], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.7279 0.1417 0.5355 0.9816], Epochs since improvement 10
 13%|█▎        | 67/500 [59:03<6:06:21, 50.76s/it] 14%|█▎        | 68/500 [1:00:06<6:33:03, 54.59s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 4.06E+06, Train scatter: [0.6852 0.1205 0.544  0.9331]
L1 regularization loss: 3.49E+00, L2 regularization loss: 1.17E+00
Test scatter: [0.6841 0.1198 0.5354 0.9242], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.7279 0.1417 0.5355 0.9816], Epochs since improvement 12
 14%|█▍        | 69/500 [1:00:47<6:02:19, 50.44s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.98E+06, Train scatter: [0.9071 0.1175 0.544  0.9501]
L1 regularization loss: 3.50E+00, L2 regularization loss: 1.22E+00
Test scatter: [0.8927 0.1161 0.5354 0.9417], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.7279 0.1239 0.5355 0.9758], Epochs since improvement 14
 14%|█▍        | 70/500 [1:01:57<6:41:57, 56.09s/it] 14%|█▍        | 71/500 [1:02:37<6:08:07, 51.49s/it] 14%|█▍        | 72/500 [1:03:41<6:33:51, 55.21s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.85E+06, Train scatter: [0.6688 0.1172 0.544  0.747 ]
L1 regularization loss: 3.52E+00, L2 regularization loss: 1.28E+00
Test scatter: [0.6638 0.1155 0.5354 0.7478], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.7109 0.1198 0.5354 0.9417], Epochs since improvement 16
 15%|█▍        | 73/500 [1:04:22<6:02:33, 50.94s/it] 15%|█▍        | 74/500 [1:05:27<6:31:49, 55.19s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.77E+06, Train scatter: [0.5822 0.1142 0.544  0.73  ]
L1 regularization loss: 3.53E+00, L2 regularization loss: 1.30E+00
Test scatter: [0.5853 0.1123 0.5354 0.7274], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.6841 0.1161 0.5354 0.9242], Epochs since improvement 18
 15%|█▌        | 75/500 [1:06:08<6:01:03, 50.97s/it] 15%|█▌        | 76/500 [1:07:13<6:28:26, 54.97s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.74E+06, Train scatter: [0.4858 0.1125 0.544  0.7023]
L1 regularization loss: 3.53E+00, L2 regularization loss: 1.30E+00
Test scatter: [0.4848 0.1107 0.5354 0.6964], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.6638 0.1155 0.5354 0.7478], Epochs since improvement 20
 15%|█▌        | 77/500 [1:07:53<5:57:33, 50.72s/it] 15%|█▌        | 77/500 [1:08:56<6:18:46, 53.73s/it]
Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.72E+06, Train scatter: [0.5192 0.1161 0.5439 0.7144]
L1 regularization loss: 3.53E+00, L2 regularization loss: 1.30E+00
Test scatter: [0.5159 0.1144 0.5354 0.7091], Lowest was [0.2036 0.0673 0.5345 0.4892]
Median for last 10 epochs: [0.5853 0.1144 0.5354 0.7274], Epochs since improvement 22
Exited after 78 epochs due to early stopping
4136.92 seconds spent training, 8.274 seconds per epoch. Processed 8416 trees per second
[0.5158491  0.11437783 0.53535    0.70909125]
{'epoch_exit': 77, 'scatter_m_star': 0.5158491, 'lowest_m_star': 0.20362082, 'last20_m_star': 0.6974709, 'last10_m_star': 0.58534646, 'scatter_v_disk': 0.114377834, 'lowest_v_disk': 0.06731048, 'last20_v_disk': 0.11792511, 'last10_v_disk': 0.11438127, 'scatter_m_cold': 0.53535, 'lowest_m_cold': 0.5345102, 'last20_m_cold': 0.5354121, 'last10_m_cold': 0.535379, 'scatter_sfr_100': 0.70909125, 'lowest_sfr_100': 0.4892485, 'last20_sfr_100': 0.93298095, 'last10_sfr_100': 0.72736275}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_tzwxbk
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:01<8:34:19, 61.84s/it]  0%|          | 2/500 [02:32<10:51:54, 78.54s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.22E+07, Train scatter: [0.9352 0.143  0.5441 0.9954]
L1 regularization loss: 2.45E+00, L2 regularization loss: 4.24E-01
Test scatter: [0.9196 0.1391 0.5355 0.9851], Lowest was [0.9196 0.1391 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1391 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:33<9:47:32, 70.93s/it]   1%|          | 4/500 [05:04<10:51:51, 78.85s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.10E+07, Train scatter: [0.9342 0.1096 0.5441 0.9954]
L1 regularization loss: 2.46E+00, L2 regularization loss: 4.29E-01
Test scatter: [0.9186 0.1087 0.5355 0.9851], Lowest was [0.9186 0.1087 0.5355 0.9851]
Median for last 10 epochs: [0.9186 0.1087 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:07<10:01:19, 72.89s/it]  1%|          | 6/500 [07:38<10:52:03, 79.20s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 7.42E+07, Train scatter: [0.8404 0.0914 0.5408 0.9954]
L1 regularization loss: 2.48E+00, L2 regularization loss: 4.37E-01
Test scatter: [0.8333 0.0913 0.5324 0.9851], Lowest was [0.8333 0.0913 0.5324 0.9851]
Median for last 10 epochs: [0.8333 0.0913 0.5324 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [08:40<10:04:27, 73.56s/it]  2%|▏         | 8/500 [10:12<10:49:56, 79.26s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.12E+07, Train scatter: [0.6883 0.0978 0.4286 0.9954]
L1 regularization loss: 2.50E+00, L2 regularization loss: 4.53E-01
Test scatter: [0.6865 0.0978 0.4236 0.985 ], Lowest was [0.6865 0.0913 0.4236 0.985 ]
Median for last 10 epochs: [0.7599 0.0945 0.478  0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [11:13<10:03:23, 73.73s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 6.93E+07, Train scatter: [0.7288 0.098  0.3745 0.9953]
L1 regularization loss: 2.51E+00, L2 regularization loss: 4.61E-01
Test scatter: [0.7192 0.0985 0.379  0.985 ], Lowest was [0.6865 0.0913 0.379  0.985 ]
Median for last 10 epochs: [0.7192 0.0978 0.4236 0.985 ], Epochs since improvement 0
  2%|▏         | 10/500 [12:52<11:04:23, 81.35s/it]  2%|▏         | 11/500 [13:54<10:15:08, 75.48s/it]  2%|▏         | 12/500 [15:24<10:50:39, 80.00s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.85E+07, Train scatter: [0.6031 0.0819 0.3365 0.9953]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.66E-01
Test scatter: [0.6019 0.0829 0.3372 0.985 ], Lowest was [0.6019 0.0829 0.3372 0.985 ]
Median for last 10 epochs: [0.7192 0.0978 0.4236 0.985 ], Epochs since improvement 0
  3%|▎         | 13/500 [16:26<10:05:24, 74.59s/it]  3%|▎         | 14/500 [17:58<10:45:32, 79.70s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.77E+07, Train scatter: [0.5394 0.0808 0.3677 0.9954]
L1 regularization loss: 2.53E+00, L2 regularization loss: 4.71E-01
Test scatter: [0.5423 0.0823 0.3675 0.985 ], Lowest was [0.5423 0.0823 0.3372 0.985 ]
Median for last 10 epochs: [0.6865 0.0913 0.379  0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [19:00<10:01:00, 74.35s/it]  3%|▎         | 16/500 [20:31<10:40:09, 79.36s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.61E+07, Train scatter: [0.4975 0.0768 0.3135 0.9954]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.77E-01
Test scatter: [0.5089 0.0793 0.3186 0.9851], Lowest was [0.5089 0.0793 0.3186 0.985 ]
Median for last 10 epochs: [0.6019 0.0829 0.3675 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [21:33<9:57:04, 74.17s/it]   4%|▎         | 18/500 [23:04<10:37:16, 79.33s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.27E+07, Train scatter: [0.4778 0.0755 0.3554 0.9811]
L1 regularization loss: 2.57E+00, L2 regularization loss: 4.87E-01
Test scatter: [0.4768 0.0756 0.3504 0.9728], Lowest was [0.4768 0.0756 0.3186 0.9728]
Median for last 10 epochs: [0.5423 0.0823 0.3504 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [24:06<9:54:39, 74.18s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.05E+06, Train scatter: [0.4443 0.0761 0.3627 0.6414]
L1 regularization loss: 2.59E+00, L2 regularization loss: 4.98E-01
Test scatter: [0.4427 0.0756 0.3688 0.6471], Lowest was [0.4427 0.0756 0.3186 0.6471]
Median for last 10 epochs: [0.5089 0.0793 0.3504 0.985 ], Epochs since improvement 0
  4%|▍         | 20/500 [25:45<10:51:52, 81.48s/it]  4%|▍         | 21/500 [26:47<10:03:37, 75.61s/it]  4%|▍         | 22/500 [28:18<10:40:07, 80.35s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.58E+06, Train scatter: [0.437  0.0715 0.3042 0.5347]
L1 regularization loss: 2.62E+00, L2 regularization loss: 5.08E-01
Test scatter: [0.4299 0.0713 0.3073 0.5371], Lowest was [0.4299 0.0713 0.3073 0.5371]
Median for last 10 epochs: [0.4768 0.0756 0.3504 0.9728], Epochs since improvement 0
  5%|▍         | 23/500 [29:20<9:55:00, 74.84s/it]   5%|▍         | 24/500 [30:52<10:33:57, 79.91s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.16E+06, Train scatter: [0.4054 0.0725 0.3009 0.5073]
L1 regularization loss: 2.64E+00, L2 regularization loss: 5.18E-01
Test scatter: [0.3993 0.0732 0.3036 0.51  ], Lowest was [0.3993 0.0713 0.3036 0.51  ]
Median for last 10 epochs: [0.4427 0.0756 0.3186 0.6471], Epochs since improvement 0
  5%|▌         | 25/500 [31:54<9:50:58, 74.65s/it]   5%|▌         | 26/500 [33:25<10:28:15, 79.53s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 2.90E+06, Train scatter: [0.3751 0.0704 0.3065 0.5731]
L1 regularization loss: 2.67E+00, L2 regularization loss: 5.29E-01
Test scatter: [0.3678 0.069  0.3049 0.5768], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.4299 0.0732 0.3073 0.5768], Epochs since improvement 0
  5%|▌         | 27/500 [34:27<9:45:48, 74.31s/it]   6%|▌         | 28/500 [35:59<10:25:12, 79.48s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.79E+07, Train scatter: [0.9343 0.1732 0.5442 0.9911]
L1 regularization loss: 4.76E+00, L2 regularization loss: 9.50E-01
Test scatter: [0.9188 0.1693 0.5356 0.981 ], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.4299 0.0732 0.3073 0.5768], Epochs since improvement 2
  6%|▌         | 29/500 [37:01<9:42:10, 74.16s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 1.56E+07, Train scatter: [0.9264 0.1481 0.5445 0.7781]
L1 regularization loss: 4.78E+00, L2 regularization loss: 9.86E-01
Test scatter: [0.911  0.1452 0.5359 0.7742], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.4299 0.0732 0.3073 0.5768], Epochs since improvement 4
  6%|▌         | 30/500 [38:39<10:38:38, 81.53s/it]  6%|▌         | 31/500 [39:41<9:51:51, 75.72s/it]   6%|▋         | 32/500 [41:13<10:26:52, 80.37s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 1.22E+07, Train scatter: [0.9274 0.1143 0.541  0.7472]
L1 regularization loss: 4.80E+00, L2 regularization loss: 1.01E+00
Test scatter: [0.912  0.1129 0.5326 0.7406], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.911  0.1129 0.5326 0.7406], Epochs since improvement 6
  7%|▋         | 33/500 [42:15<9:43:06, 74.92s/it]   7%|▋         | 34/500 [43:47<10:21:26, 80.01s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 1.06E+07, Train scatter: [0.9285 0.1104 0.5332 0.7124]
L1 regularization loss: 4.82E+00, L2 regularization loss: 1.06E+00
Test scatter: [0.9131 0.1083 0.525  0.7048], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.912  0.1129 0.5326 0.7406], Epochs since improvement 8
  7%|▋         | 35/500 [44:49<9:37:49, 74.56s/it]   7%|▋         | 36/500 [46:21<10:17:18, 79.82s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 9.36E+06, Train scatter: [0.9282 0.1057 0.52   0.6995]
L1 regularization loss: 4.85E+00, L2 regularization loss: 1.11E+00
Test scatter: [0.9127 0.1037 0.5122 0.6908], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.9127 0.1129 0.5326 0.7406], Epochs since improvement 10
  7%|▋         | 37/500 [47:23<9:35:04, 74.52s/it]   8%|▊         | 38/500 [48:55<10:13:44, 79.71s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 8.26E+06, Train scatter: [0.9278 0.1002 0.4983 0.6115]
L1 regularization loss: 4.87E+00, L2 regularization loss: 1.15E+00
Test scatter: [0.9123 0.098  0.4909 0.6021], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.9123 0.1083 0.525  0.7048], Epochs since improvement 12
  8%|▊         | 39/500 [49:56<9:30:36, 74.27s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 7.89E+06, Train scatter: [0.9251 0.0983 0.4811 0.6123]
L1 regularization loss: 4.89E+00, L2 regularization loss: 1.18E+00
Test scatter: [0.9096 0.0963 0.4736 0.6048], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.9123 0.1037 0.5122 0.6908], Epochs since improvement 14
  8%|▊         | 40/500 [51:35<10:26:22, 81.70s/it]  8%|▊         | 41/500 [52:37<9:39:59, 75.82s/it]   8%|▊         | 42/500 [54:08<10:12:51, 80.29s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 6.91E+06, Train scatter: [0.9216 0.0974 0.4825 0.6013]
L1 regularization loss: 4.91E+00, L2 regularization loss: 1.21E+00
Test scatter: [0.9063 0.0954 0.4746 0.5937], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.9123 0.098  0.4909 0.6048], Epochs since improvement 16
  9%|▊         | 43/500 [55:10<9:29:37, 74.79s/it]   9%|▉         | 44/500 [56:42<10:08:11, 80.03s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 6.69E+06, Train scatter: [0.9183 0.0938 0.4535 0.5775]
L1 regularization loss: 4.93E+00, L2 regularization loss: 1.25E+00
Test scatter: [0.9029 0.0919 0.4458 0.5703], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.9096 0.0963 0.4746 0.6021], Epochs since improvement 18
  9%|▉         | 45/500 [57:44<9:25:56, 74.63s/it]   9%|▉         | 46/500 [59:15<10:01:45, 79.53s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 6.46E+06, Train scatter: [0.9123 0.0941 0.4546 0.5764]
L1 regularization loss: 4.95E+00, L2 regularization loss: 1.30E+00
Test scatter: [0.8971 0.092  0.4465 0.5682], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.9063 0.0954 0.4736 0.5937], Epochs since improvement 20
  9%|▉         | 47/500 [1:00:17<9:20:38, 74.26s/it]  9%|▉         | 47/500 [1:01:49<9:55:54, 78.93s/it]
Epoch: 48 done with learning rate 7.24E-03, Train loss: 6.17E+06, Train scatter: [0.9073 0.0913 0.4679 0.5594]
L1 regularization loss: 4.97E+00, L2 regularization loss: 1.35E+00
Test scatter: [0.8922 0.0894 0.4598 0.5522], Lowest was [0.3678 0.069  0.3036 0.51  ]
Median for last 10 epochs: [0.9029 0.092  0.4598 0.5703], Epochs since improvement 22
Exited after 48 epochs due to early stopping
3709.66 seconds spent training, 7.419 seconds per epoch. Processed 9386 trees per second
[0.8921925  0.08937304 0.4597781  0.5521641 ]
{'epoch_exit': 47, 'scatter_m_star': 0.8921925, 'lowest_m_star': 0.36782968, 'last20_m_star': 0.91030884, 'last10_m_star': 0.90294844, 'scatter_v_disk': 0.08937304, 'lowest_v_disk': 0.06898176, 'last20_v_disk': 0.09714523, 'last10_v_disk': 0.09202021, 'scatter_m_cold': 0.4597781, 'lowest_m_cold': 0.30359602, 'last20_m_cold': 0.4827504, 'last10_m_cold': 0.45979166, 'scatter_sfr_100': 0.5521641, 'lowest_sfr_100': 0.50999755, 'last20_sfr_100': 0.60345364, 'last10_sfr_100': 0.5702996}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_qaquhh
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:54<7:31:27, 54.28s/it]  0%|          | 2/500 [02:16<9:44:49, 70.46s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.1725 0.5441 0.9953]
L1 regularization loss: 2.44E+00, L2 regularization loss: 4.23E-01
Test scatter: [0.9196 0.168  0.5355 0.985 ], Lowest was [0.9196 0.168  0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.168  0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:10<8:41:13, 62.92s/it]  1%|          | 4/500 [04:32<9:42:39, 70.48s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.76E+07, Train scatter: [0.9352 0.135  0.5441 0.9954]
L1 regularization loss: 2.46E+00, L2 regularization loss: 4.25E-01
Test scatter: [0.9196 0.1319 0.5355 0.9851], Lowest was [0.9196 0.1319 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1319 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [05:25<8:51:56, 64.48s/it]  1%|          | 6/500 [06:47<9:40:03, 70.45s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.21E+07, Train scatter: [0.9348 0.1113 0.5441 0.9955]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.28E-01
Test scatter: [0.9192 0.1081 0.5355 0.9851], Lowest was [0.9192 0.1081 0.5355 0.985 ]
Median for last 10 epochs: [0.9192 0.1081 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:41<8:53:53, 64.98s/it]  2%|▏         | 8/500 [09:03<9:37:58, 70.48s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.39E+08, Train scatter: [0.9351 0.1621 0.5441 0.9954]
L1 regularization loss: 2.49E+00, L2 regularization loss: 4.35E-01
Test scatter: [0.9196 0.157  0.5355 0.985 ], Lowest was [0.9192 0.1081 0.5355 0.985 ]
Median for last 10 epochs: [0.9194 0.12   0.5355 0.9851], Epochs since improvement 2
  2%|▏         | 9/500 [09:57<8:54:25, 65.31s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 9.26E+07, Train scatter: [0.9351 0.141  0.544  0.9954]
L1 regularization loss: 2.50E+00, L2 regularization loss: 4.43E-01
Test scatter: [0.9195 0.1382 0.5355 0.985 ], Lowest was [0.9192 0.1081 0.5355 0.985 ]
Median for last 10 epochs: [0.9195 0.1319 0.5355 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:27<9:54:43, 72.82s/it]  2%|▏         | 11/500 [12:21<9:06:28, 67.05s/it]  2%|▏         | 12/500 [13:43<9:42:03, 71.56s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.53E+07, Train scatter: [0.9126 0.1271 0.544  0.9954]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.56E-01
Test scatter: [0.8998 0.1253 0.5354 0.9851], Lowest was [0.8998 0.1081 0.5354 0.985 ]
Median for last 10 epochs: [0.9195 0.1319 0.5355 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:37<8:57:31, 66.23s/it]  3%|▎         | 14/500 [15:58<9:33:01, 70.74s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 8.05E+07, Train scatter: [0.6005 0.1131 0.5439 0.9954]
L1 regularization loss: 2.54E+00, L2 regularization loss: 4.74E-01
Test scatter: [0.5894 0.1125 0.5354 0.9851], Lowest was [0.5894 0.1081 0.5354 0.985 ]
Median for last 10 epochs: [0.9192 0.1253 0.5355 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [16:52<8:51:22, 65.74s/it]  3%|▎         | 16/500 [18:13<9:26:59, 70.29s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.85E+07, Train scatter: [0.5095 0.101  0.5437 0.9954]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.82E-01
Test scatter: [0.5053 0.1    0.5351 0.9851], Lowest was [0.5053 0.1    0.5351 0.985 ]
Median for last 10 epochs: [0.8998 0.1253 0.5354 0.9851], Epochs since improvement 0
  3%|▎         | 17/500 [19:07<8:46:44, 65.43s/it]  4%|▎         | 18/500 [20:30<9:27:39, 70.66s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.74E+07, Train scatter: [0.3435 0.096  0.5392 0.9954]
L1 regularization loss: 2.56E+00, L2 regularization loss: 4.91E-01
Test scatter: [0.3475 0.0945 0.5312 0.9851], Lowest was [0.3475 0.0945 0.5312 0.985 ]
Median for last 10 epochs: [0.5894 0.1125 0.5354 0.9851], Epochs since improvement 0
  4%|▍         | 19/500 [21:24<8:46:08, 65.63s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.66E+07, Train scatter: [0.5069 0.0964 0.5432 0.9954]
L1 regularization loss: 2.57E+00, L2 regularization loss: 4.99E-01
Test scatter: [0.5148 0.0952 0.5347 0.9851], Lowest was [0.3475 0.0945 0.5312 0.985 ]
Median for last 10 epochs: [0.5148 0.1    0.5351 0.9851], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:54<9:42:42, 72.84s/it]  4%|▍         | 21/500 [23:47<8:56:04, 67.15s/it]  4%|▍         | 22/500 [25:10<9:30:56, 71.67s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.57E+07, Train scatter: [0.2984 0.0886 0.5367 0.9954]
L1 regularization loss: 2.58E+00, L2 regularization loss: 5.05E-01
Test scatter: [0.3033 0.0881 0.5284 0.985 ], Lowest was [0.3033 0.0881 0.5284 0.985 ]
Median for last 10 epochs: [0.5053 0.0952 0.5347 0.9851], Epochs since improvement 0
  5%|▍         | 23/500 [26:04<8:47:55, 66.41s/it]  5%|▍         | 24/500 [27:25<9:22:27, 70.90s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.48E+07, Train scatter: [0.3267 0.0871 0.5064 0.9954]
L1 regularization loss: 2.59E+00, L2 regularization loss: 5.18E-01
Test scatter: [0.3323 0.0857 0.4993 0.985 ], Lowest was [0.3033 0.0857 0.4993 0.985 ]
Median for last 10 epochs: [0.3475 0.0945 0.5312 0.9851], Epochs since improvement 0
  5%|▌         | 25/500 [28:19<8:41:05, 65.82s/it]  5%|▌         | 26/500 [29:41<9:17:25, 70.56s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.38E+07, Train scatter: [0.5481 0.0874 0.4155 0.9953]
L1 regularization loss: 2.60E+00, L2 regularization loss: 5.29E-01
Test scatter: [0.5183 0.0866 0.4125 0.985 ], Lowest was [0.3033 0.0857 0.4125 0.985 ]
Median for last 10 epochs: [0.3475 0.0881 0.5284 0.985 ], Epochs since improvement 0
  5%|▌         | 27/500 [30:35<8:36:51, 65.56s/it]  6%|▌         | 28/500 [31:56<9:13:49, 70.40s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.30E+07, Train scatter: [0.2932 0.0816 0.3831 0.9954]
L1 regularization loss: 2.61E+00, L2 regularization loss: 5.38E-01
Test scatter: [0.2962 0.0808 0.3806 0.985 ], Lowest was [0.2962 0.0808 0.3806 0.985 ]
Median for last 10 epochs: [0.3323 0.0866 0.4993 0.985 ], Epochs since improvement 0
  6%|▌         | 29/500 [32:50<8:34:15, 65.51s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.20E+07, Train scatter: [0.308  0.08   0.3762 0.9954]
L1 regularization loss: 2.62E+00, L2 regularization loss: 5.49E-01
Test scatter: [0.3067 0.0796 0.3737 0.985 ], Lowest was [0.2962 0.0796 0.3737 0.985 ]
Median for last 10 epochs: [0.3067 0.0857 0.4125 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [34:19<9:27:15, 72.42s/it]  6%|▌         | 31/500 [35:13<8:42:56, 66.90s/it]  6%|▋         | 32/500 [36:35<9:17:06, 71.42s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.23E+07, Train scatter: [0.2982 0.08   0.3569 0.9954]
L1 regularization loss: 2.63E+00, L2 regularization loss: 5.61E-01
Test scatter: [0.3004 0.0794 0.3574 0.985 ], Lowest was [0.2962 0.0794 0.3574 0.985 ]
Median for last 10 epochs: [0.3067 0.0808 0.3806 0.985 ], Epochs since improvement 0
  7%|▋         | 33/500 [37:29<8:34:45, 66.14s/it]  7%|▋         | 34/500 [38:51<9:10:24, 70.87s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.11E+07, Train scatter: [0.4424 0.0786 0.3443 0.9954]
L1 regularization loss: 2.65E+00, L2 regularization loss: 5.74E-01
Test scatter: [0.4383 0.0783 0.3448 0.985 ], Lowest was [0.2962 0.0783 0.3448 0.985 ]
Median for last 10 epochs: [0.3067 0.0796 0.3737 0.985 ], Epochs since improvement 0
  7%|▋         | 35/500 [39:45<8:30:09, 65.83s/it]  7%|▋         | 36/500 [41:05<9:03:45, 70.31s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.06E+07, Train scatter: [0.3185 0.0821 0.3574 0.9954]
L1 regularization loss: 2.67E+00, L2 regularization loss: 5.87E-01
Test scatter: [0.321  0.0807 0.3568 0.9851], Lowest was [0.2962 0.0783 0.3448 0.985 ]
Median for last 10 epochs: [0.3067 0.0796 0.3574 0.985 ], Epochs since improvement 2
  7%|▋         | 37/500 [42:00<8:25:08, 65.46s/it]  8%|▊         | 38/500 [43:21<8:59:41, 70.09s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.95E+07, Train scatter: [0.4243 0.0786 0.3796 0.9954]
L1 regularization loss: 2.68E+00, L2 regularization loss: 6.01E-01
Test scatter: [0.4205 0.0776 0.3827 0.9851], Lowest was [0.2962 0.0776 0.3448 0.985 ]
Median for last 10 epochs: [0.321  0.0794 0.3574 0.985 ], Epochs since improvement 0
  8%|▊         | 39/500 [44:14<8:21:02, 65.21s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 4.96E+07, Train scatter: [0.3053 0.0761 0.3197 0.9953]
L1 regularization loss: 2.70E+00, L2 regularization loss: 6.19E-01
Test scatter: [0.3085 0.0753 0.3232 0.985 ], Lowest was [0.2962 0.0753 0.3232 0.985 ]
Median for last 10 epochs: [0.321  0.0783 0.3568 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:43<9:12:49, 72.11s/it]  8%|▊         | 41/500 [46:37<8:30:11, 66.69s/it]  8%|▊         | 42/500 [47:59<9:05:12, 71.42s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.14E+07, Train scatter: [0.3677 0.0898 0.3643 0.6995]
L1 regularization loss: 2.72E+00, L2 regularization loss: 6.40E-01
Test scatter: [0.36   0.0895 0.367  0.6946], Lowest was [0.2962 0.0753 0.3232 0.6946]
Median for last 10 epochs: [0.36   0.0783 0.3568 0.985 ], Epochs since improvement 0
  9%|▊         | 43/500 [48:53<8:24:14, 66.20s/it]  9%|▉         | 44/500 [50:15<8:58:00, 70.79s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.67E+06, Train scatter: [0.3157 0.0791 0.3622 0.5872]
L1 regularization loss: 2.74E+00, L2 regularization loss: 6.64E-01
Test scatter: [0.3278 0.0784 0.3612 0.5826], Lowest was [0.2962 0.0753 0.3232 0.5826]
Median for last 10 epochs: [0.3278 0.0784 0.3612 0.985 ], Epochs since improvement 0
  9%|▉         | 45/500 [51:09<8:18:26, 65.73s/it]  9%|▉         | 46/500 [52:30<8:53:21, 70.49s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.95E+06, Train scatter: [0.2614 0.0749 0.3387 0.5501]
L1 regularization loss: 2.76E+00, L2 regularization loss: 6.80E-01
Test scatter: [0.2713 0.0744 0.3385 0.5435], Lowest was [0.2713 0.0744 0.3232 0.5435]
Median for last 10 epochs: [0.3278 0.0776 0.3612 0.6946], Epochs since improvement 0
  9%|▉         | 47/500 [53:24<8:14:33, 65.50s/it] 10%|▉         | 48/500 [54:47<8:51:57, 70.61s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.82E+06, Train scatter: [0.3073 0.0772 0.3297 0.5633]
L1 regularization loss: 2.78E+00, L2 regularization loss: 6.99E-01
Test scatter: [0.3142 0.0762 0.3303 0.5592], Lowest was [0.2713 0.0744 0.3232 0.5435]
Median for last 10 epochs: [0.3142 0.0762 0.3385 0.5826], Epochs since improvement 2
 10%|▉         | 49/500 [55:41<8:13:25, 65.64s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.63E+06, Train scatter: [0.2524 0.073  0.3074 0.505 ]
L1 regularization loss: 2.79E+00, L2 regularization loss: 7.19E-01
Test scatter: [0.2673 0.0733 0.3135 0.505 ], Lowest was [0.2673 0.0733 0.3135 0.505 ]
Median for last 10 epochs: [0.3142 0.0762 0.3385 0.5592], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [57:09<9:04:32, 72.61s/it] 10%|█         | 51/500 [58:04<8:22:14, 67.11s/it] 10%|█         | 52/500 [59:25<8:51:59, 71.25s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.52E+06, Train scatter: [0.2536 0.0731 0.3117 0.5087]
L1 regularization loss: 2.81E+00, L2 regularization loss: 7.39E-01
Test scatter: [0.2674 0.0721 0.3148 0.5065], Lowest was [0.2673 0.0721 0.3135 0.505 ]
Median for last 10 epochs: [0.2713 0.0744 0.3303 0.5435], Epochs since improvement 0
 11%|█         | 53/500 [1:00:18<8:11:54, 66.03s/it] 11%|█         | 54/500 [1:01:39<8:44:16, 70.53s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.31E+06, Train scatter: [0.2432 0.0722 0.3143 0.4955]
L1 regularization loss: 2.83E+00, L2 regularization loss: 7.55E-01
Test scatter: [0.254  0.0711 0.3197 0.4919], Lowest was [0.254  0.0711 0.3135 0.4919]
Median for last 10 epochs: [0.2674 0.0733 0.3197 0.5065], Epochs since improvement 0
 11%|█         | 55/500 [1:02:33<8:05:49, 65.50s/it] 11%|█         | 56/500 [1:03:55<8:40:47, 70.38s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.33E+06, Train scatter: [0.244  0.0723 0.31   0.487 ]
L1 regularization loss: 2.85E+00, L2 regularization loss: 7.73E-01
Test scatter: [0.2488 0.0723 0.3163 0.4877], Lowest was [0.2488 0.0711 0.3135 0.4877]
Median for last 10 epochs: [0.2673 0.0723 0.3163 0.505 ], Epochs since improvement 0
 11%|█▏        | 57/500 [1:04:49<8:03:19, 65.46s/it] 12%|█▏        | 58/500 [1:06:10<8:36:46, 70.15s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.04E+06, Train scatter: [0.3577 0.0743 0.3363 0.5427]
L1 regularization loss: 2.87E+00, L2 regularization loss: 7.93E-01
Test scatter: [0.3524 0.0736 0.3368 0.5407], Lowest was [0.2488 0.0711 0.3135 0.4877]
Median for last 10 epochs: [0.2673 0.0723 0.3163 0.505 ], Epochs since improvement 2
 12%|█▏        | 59/500 [1:07:04<7:59:42, 65.27s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.02E+06, Train scatter: [0.2582 0.0736 0.302  0.4992]
L1 regularization loss: 2.88E+00, L2 regularization loss: 8.10E-01
Test scatter: [0.2609 0.0729 0.3023 0.4977], Lowest was [0.2488 0.0711 0.3023 0.4877]
Median for last 10 epochs: [0.2609 0.0723 0.3163 0.4977], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:08:33<8:50:36, 72.36s/it] 12%|█▏        | 61/500 [1:09:27<8:09:30, 66.90s/it] 12%|█▏        | 62/500 [1:10:49<8:41:18, 71.41s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.00E+06, Train scatter: [0.2582 0.0723 0.3134 0.5254]
L1 regularization loss: 2.90E+00, L2 regularization loss: 8.30E-01
Test scatter: [0.2644 0.0719 0.3156 0.5241], Lowest was [0.2488 0.0711 0.3023 0.4877]
Median for last 10 epochs: [0.2609 0.0723 0.3163 0.4977], Epochs since improvement 2
 13%|█▎        | 63/500 [1:11:43<8:02:14, 66.21s/it] 13%|█▎        | 64/500 [1:13:04<8:32:11, 70.48s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.87E+06, Train scatter: [0.2532 0.0744 0.3107 0.4873]
L1 regularization loss: 2.92E+00, L2 regularization loss: 8.56E-01
Test scatter: [0.2675 0.0741 0.3154 0.4881], Lowest was [0.2488 0.0711 0.3023 0.4877]
Median for last 10 epochs: [0.2644 0.0729 0.3156 0.4977], Epochs since improvement 4
 13%|█▎        | 65/500 [1:13:58<7:55:12, 65.55s/it] 13%|█▎        | 66/500 [1:15:19<8:29:38, 70.46s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.75E+06, Train scatter: [0.2329 0.0714 0.3034 0.4799]
L1 regularization loss: 2.94E+00, L2 regularization loss: 8.80E-01
Test scatter: [0.2412 0.0713 0.3038 0.4803], Lowest was [0.2412 0.0711 0.3023 0.4803]
Median for last 10 epochs: [0.2644 0.0729 0.3154 0.4977], Epochs since improvement 0
 13%|█▎        | 67/500 [1:16:13<7:52:25, 65.46s/it] 14%|█▎        | 68/500 [1:17:35<8:26:46, 70.39s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.73E+06, Train scatter: [0.2559 0.0712 0.3135 0.4955]
L1 regularization loss: 2.96E+00, L2 regularization loss: 9.04E-01
Test scatter: [0.2637 0.0707 0.3155 0.4934], Lowest was [0.2412 0.0707 0.3023 0.4803]
Median for last 10 epochs: [0.2637 0.0719 0.3154 0.4934], Epochs since improvement 0
 14%|█▍        | 69/500 [1:18:29<7:49:49, 65.41s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.65E+06, Train scatter: [0.2485 0.0676 0.2913 0.4743]
L1 regularization loss: 3.01E+00, L2 regularization loss: 9.44E-01
Test scatter: [0.2546 0.0669 0.2936 0.4699], Lowest was [0.2412 0.0669 0.2936 0.4699]
Median for last 10 epochs: [0.2637 0.0713 0.3154 0.4881], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:19:58<8:38:59, 72.42s/it] 14%|█▍        | 71/500 [1:20:51<7:57:50, 66.83s/it] 14%|█▍        | 72/500 [1:22:13<8:28:44, 71.32s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 2.83E+06, Train scatter: [0.2332 0.0681 0.2925 0.4765]
L1 regularization loss: 3.03E+00, L2 regularization loss: 9.77E-01
Test scatter: [0.2505 0.0682 0.2973 0.4773], Lowest was [0.2412 0.0669 0.2936 0.4699]
Median for last 10 epochs: [0.2546 0.0707 0.3038 0.4803], Epochs since improvement 2
 15%|█▍        | 73/500 [1:23:07<7:49:55, 66.03s/it] 15%|█▍        | 74/500 [1:24:29<8:22:52, 70.83s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.60E+06, Train scatter: [0.2895 0.0664 0.2834 0.4706]
L1 regularization loss: 3.07E+00, L2 regularization loss: 1.01E+00
Test scatter: [0.2874 0.0663 0.2866 0.4725], Lowest was [0.2412 0.0663 0.2866 0.4699]
Median for last 10 epochs: [0.2546 0.0682 0.2973 0.4773], Epochs since improvement 0
 15%|█▌        | 75/500 [1:25:23<7:45:34, 65.73s/it] 15%|█▌        | 76/500 [1:26:44<8:18:04, 70.48s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.74E+06, Train scatter: [0.2213 0.0667 0.285  0.4641]
L1 regularization loss: 3.11E+00, L2 regularization loss: 1.05E+00
Test scatter: [0.2418 0.0668 0.2873 0.4646], Lowest was [0.2412 0.0663 0.2866 0.4646]
Median for last 10 epochs: [0.2546 0.0669 0.2936 0.4725], Epochs since improvement 0
 15%|█▌        | 77/500 [1:27:38<7:41:21, 65.44s/it] 16%|█▌        | 78/500 [1:29:00<8:14:57, 70.37s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.60E+06, Train scatter: [0.2449 0.0678 0.2946 0.4819]
L1 regularization loss: 3.15E+00, L2 regularization loss: 1.08E+00
Test scatter: [0.2636 0.0682 0.3017 0.4815], Lowest was [0.2412 0.0663 0.2866 0.4646]
Median for last 10 epochs: [0.2546 0.0669 0.2936 0.4725], Epochs since improvement 2
 16%|█▌        | 79/500 [1:29:54<7:39:12, 65.45s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.44E+06, Train scatter: [0.229  0.0643 0.2819 0.4615]
L1 regularization loss: 3.17E+00, L2 regularization loss: 1.12E+00
Test scatter: [0.2466 0.0646 0.2855 0.4626], Lowest was [0.2412 0.0646 0.2855 0.4626]
Median for last 10 epochs: [0.2505 0.0668 0.2873 0.4725], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:31:25<8:31:16, 73.04s/it] 16%|█▌        | 81/500 [1:32:19<7:50:03, 67.31s/it] 16%|█▋        | 82/500 [1:33:40<8:18:16, 71.52s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.56E+06, Train scatter: [0.3321 0.0654 0.2891 0.4577]
L1 regularization loss: 3.21E+00, L2 regularization loss: 1.16E+00
Test scatter: [0.3264 0.0657 0.2943 0.459 ], Lowest was [0.2412 0.0646 0.2855 0.459 ]
Median for last 10 epochs: [0.2636 0.0663 0.2873 0.4646], Epochs since improvement 0
 17%|█▋        | 83/500 [1:34:34<7:40:36, 66.28s/it] 17%|█▋        | 84/500 [1:35:56<8:11:25, 70.88s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.36E+06, Train scatter: [0.3413 0.0672 0.341  0.5814]
L1 regularization loss: 3.26E+00, L2 regularization loss: 1.21E+00
Test scatter: [0.3415 0.0678 0.3448 0.5868], Lowest was [0.2412 0.0646 0.2855 0.459 ]
Median for last 10 epochs: [0.2636 0.0668 0.2943 0.4646], Epochs since improvement 2
 17%|█▋        | 85/500 [1:36:50<7:35:12, 65.81s/it] 17%|█▋        | 86/500 [1:38:11<8:06:05, 70.45s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.71E+06, Train scatter: [0.402  0.0648 0.2915 0.4702]
L1 regularization loss: 3.30E+00, L2 regularization loss: 1.26E+00
Test scatter: [0.3937 0.0665 0.2937 0.4729], Lowest was [0.2412 0.0646 0.2855 0.459 ]
Median for last 10 epochs: [0.3264 0.0665 0.2943 0.4729], Epochs since improvement 4
 17%|█▋        | 87/500 [1:39:05<7:30:37, 65.47s/it] 18%|█▊        | 88/500 [1:40:26<8:01:55, 70.18s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.42E+06, Train scatter: [0.2826 0.0633 0.2869 0.4719]
L1 regularization loss: 3.33E+00, L2 regularization loss: 1.29E+00
Test scatter: [0.3064 0.0643 0.291  0.4723], Lowest was [0.2412 0.0643 0.2855 0.459 ]
Median for last 10 epochs: [0.3264 0.0657 0.2937 0.4723], Epochs since improvement 0
 18%|█▊        | 89/500 [1:41:20<7:27:23, 65.31s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.25E+06, Train scatter: [0.3683 0.0589 0.2736 0.4498]
L1 regularization loss: 3.36E+00, L2 regularization loss: 1.33E+00
Test scatter: [0.3674 0.0604 0.2772 0.4518], Lowest was [0.2412 0.0604 0.2772 0.4518]
Median for last 10 epochs: [0.3415 0.0657 0.2937 0.4723], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:42:49<8:16:04, 72.60s/it] 18%|█▊        | 91/500 [1:43:43<7:36:36, 66.98s/it] 18%|█▊        | 92/500 [1:45:05<8:05:52, 71.45s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.17E+06, Train scatter: [0.3161 0.0612 0.2929 0.4613]
L1 regularization loss: 3.38E+00, L2 regularization loss: 1.37E+00
Test scatter: [0.3116 0.0607 0.2925 0.4585], Lowest was [0.2412 0.0604 0.2772 0.4518]
Median for last 10 epochs: [0.3415 0.0643 0.2925 0.4723], Epochs since improvement 2
 19%|█▊        | 93/500 [1:45:59<7:29:03, 66.20s/it] 19%|█▉        | 94/500 [1:47:21<7:59:15, 70.83s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.09E+06, Train scatter: [0.2084 0.0574 0.2726 0.448 ]
L1 regularization loss: 3.40E+00, L2 regularization loss: 1.41E+00
Test scatter: [0.2181 0.0581 0.2807 0.4515], Lowest was [0.2181 0.0581 0.2772 0.4515]
Median for last 10 epochs: [0.3116 0.0607 0.291  0.4585], Epochs since improvement 0
 19%|█▉        | 95/500 [1:48:15<7:23:49, 65.75s/it] 19%|█▉        | 96/500 [1:49:36<7:54:22, 70.45s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 7.47E+06, Train scatter: [0.6293 0.1465 0.5393 0.6828]
L1 regularization loss: 3.64E+00, L2 regularization loss: 1.62E+00
Test scatter: [0.615  0.1437 0.5308 0.6801], Lowest was [0.2181 0.0581 0.2772 0.4515]
Median for last 10 epochs: [0.3116 0.0607 0.291  0.4585], Epochs since improvement 2
 19%|█▉        | 97/500 [1:50:30<7:20:17, 65.55s/it] 20%|█▉        | 98/500 [1:51:52<7:51:23, 70.36s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 3.91E+06, Train scatter: [0.3025 0.0801 0.5277 0.5311]
L1 regularization loss: 3.68E+00, L2 regularization loss: 1.68E+00
Test scatter: [0.3027 0.0796 0.5203 0.5264], Lowest was [0.2181 0.0581 0.2772 0.4515]
Median for last 10 epochs: [0.3116 0.0607 0.2925 0.4585], Epochs since improvement 4
 20%|█▉        | 99/500 [1:52:46<7:17:11, 65.42s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 3.06E+06, Train scatter: [0.3185 0.0783 0.4847 0.5318]
L1 regularization loss: 3.70E+00, L2 regularization loss: 1.74E+00
Test scatter: [0.3105 0.079  0.4802 0.5238], Lowest was [0.2181 0.0581 0.2772 0.4515]
Median for last 10 epochs: [0.3105 0.079  0.4802 0.5238], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:54:14<8:01:41, 72.25s/it] 20%|██        | 101/500 [1:55:08<7:24:12, 66.80s/it] 20%|██        | 102/500 [1:56:30<7:52:50, 71.28s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 2.63E+06, Train scatter: [0.2437 0.0727 0.4625 0.5063]
L1 regularization loss: 3.72E+00, L2 regularization loss: 1.78E+00
Test scatter: [0.2538 0.0724 0.4616 0.5016], Lowest was [0.2181 0.0581 0.2772 0.4515]
Median for last 10 epochs: [0.3027 0.079  0.4802 0.5238], Epochs since improvement 8
 21%|██        | 103/500 [1:57:24<7:17:18, 66.09s/it] 21%|██        | 104/500 [1:58:45<7:46:53, 70.74s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 2.31E+06, Train scatter: [0.2495 0.0686 0.4294 0.4869]
L1 regularization loss: 3.74E+00, L2 regularization loss: 1.81E+00
Test scatter: [0.2603 0.0684 0.4327 0.4791], Lowest was [0.2181 0.0581 0.2772 0.4515]
Median for last 10 epochs: [0.3027 0.079  0.4802 0.5238], Epochs since improvement 10
 21%|██        | 105/500 [1:59:39<7:13:00, 65.77s/it] 21%|██        | 106/500 [2:01:00<7:41:32, 70.28s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 2.16E+06, Train scatter: [0.2811 0.0702 0.4713 0.4935]
L1 regularization loss: 3.76E+00, L2 regularization loss: 1.84E+00
Test scatter: [0.3019 0.0715 0.4712 0.4924], Lowest was [0.2181 0.0581 0.2772 0.4515]
Median for last 10 epochs: [0.3019 0.0724 0.4712 0.5016], Epochs since improvement 12
 21%|██▏       | 107/500 [2:01:54<7:08:00, 65.34s/it] 22%|██▏       | 108/500 [2:03:15<7:37:22, 70.01s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 1.80E+06, Train scatter: [0.2383 0.0709 0.4486 0.4747]
L1 regularization loss: 3.77E+00, L2 regularization loss: 1.86E+00
Test scatter: [0.25   0.0725 0.4486 0.4769], Lowest was [0.2181 0.0581 0.2772 0.4515]
Median for last 10 epochs: [0.2603 0.0724 0.4616 0.4924], Epochs since improvement 14
 22%|██▏       | 109/500 [2:04:09<7:04:33, 65.15s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 1.78E+06, Train scatter: [0.4502 0.072  0.4654 0.5107]
L1 regularization loss: 3.79E+00, L2 regularization loss: 1.89E+00
Test scatter: [0.4511 0.073  0.4577 0.5076], Lowest was [0.2181 0.0581 0.2772 0.4515]
Median for last 10 epochs: [0.2603 0.0724 0.4577 0.4924], Epochs since improvement 16
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:05:38<7:49:43, 72.27s/it] 22%|██▏       | 111/500 [2:06:32<7:12:52, 66.77s/it] 22%|██▏       | 112/500 [2:07:53<7:40:18, 71.18s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.46E+06, Train scatter: [0.2252 0.0645 0.338  0.4534]
L1 regularization loss: 3.81E+00, L2 regularization loss: 1.91E+00
Test scatter: [0.2318 0.0656 0.3466 0.4508], Lowest was [0.2181 0.0581 0.2772 0.4508]
Median for last 10 epochs: [0.2603 0.0715 0.4486 0.4791], Epochs since improvement 0
 23%|██▎       | 113/500 [2:08:47<7:05:30, 65.97s/it] 23%|██▎       | 114/500 [2:10:08<7:33:44, 70.53s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.32E+06, Train scatter: [0.2142 0.0648 0.3282 0.4507]
L1 regularization loss: 3.82E+00, L2 regularization loss: 1.93E+00
Test scatter: [0.2222 0.0668 0.3348 0.4517], Lowest was [0.2181 0.0581 0.2772 0.4508]
Median for last 10 epochs: [0.25   0.0715 0.4486 0.4769], Epochs since improvement 2
 23%|██▎       | 115/500 [2:11:02<7:00:30, 65.53s/it] 23%|██▎       | 116/500 [2:12:23<7:28:41, 70.11s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.32E+06, Train scatter: [0.2076 0.0626 0.3344 0.4443]
L1 regularization loss: 3.83E+00, L2 regularization loss: 1.94E+00
Test scatter: [0.2165 0.0634 0.3421 0.4442], Lowest was [0.2165 0.0581 0.2772 0.4442]
Median for last 10 epochs: [0.2318 0.0668 0.3466 0.4517], Epochs since improvement 0
 23%|██▎       | 117/500 [2:13:17<6:56:45, 65.29s/it] 24%|██▎       | 118/500 [2:14:38<7:26:11, 70.08s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.22E+06, Train scatter: [0.2051 0.0624 0.3299 0.4464]
L1 regularization loss: 3.85E+00, L2 regularization loss: 1.96E+00
Test scatter: [0.2122 0.062  0.3386 0.4495], Lowest was [0.2122 0.0581 0.2772 0.4442]
Median for last 10 epochs: [0.2222 0.0656 0.3421 0.4508], Epochs since improvement 0
 24%|██▍       | 119/500 [2:15:32<6:54:46, 65.32s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.22E+06, Train scatter: [0.2287 0.0612 0.3334 0.4534]
L1 regularization loss: 3.87E+00, L2 regularization loss: 1.99E+00
Test scatter: [0.2314 0.0636 0.3431 0.4542], Lowest was [0.2122 0.0581 0.2772 0.4442]
Median for last 10 epochs: [0.2222 0.0636 0.3421 0.4508], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 24%|██▍       | 120/500 [2:17:00<7:36:58, 72.15s/it] 24%|██▍       | 121/500 [2:17:55<7:01:47, 66.77s/it] 24%|██▍       | 122/500 [2:19:16<7:27:44, 71.07s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 1.26E+06, Train scatter: [0.2126 0.0599 0.3249 0.4463]
L1 regularization loss: 3.90E+00, L2 regularization loss: 2.03E+00
Test scatter: [0.2206 0.0626 0.3366 0.4486], Lowest was [0.2122 0.0581 0.2772 0.4442]
Median for last 10 epochs: [0.2206 0.0634 0.3386 0.4495], Epochs since improvement 4
 25%|██▍       | 123/500 [2:20:10<6:54:10, 65.92s/it] 25%|██▍       | 124/500 [2:21:31<7:21:56, 70.52s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.16E+06, Train scatter: [0.1922 0.057  0.3083 0.4376]
L1 regularization loss: 3.92E+00, L2 regularization loss: 2.06E+00
Test scatter: [0.1996 0.0577 0.3165 0.4388], Lowest was [0.1996 0.0577 0.2772 0.4388]
Median for last 10 epochs: [0.2165 0.0626 0.3386 0.4486], Epochs since improvement 0
 25%|██▌       | 125/500 [2:22:25<6:49:28, 65.52s/it] 25%|██▌       | 126/500 [2:23:46<7:17:31, 70.19s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 2.18E+06, Train scatter: [0.4555 0.0932 0.3445 0.5126]
L1 regularization loss: 4.26E+00, L2 regularization loss: 2.28E+00
Test scatter: [0.4448 0.0896 0.3436 0.5047], Lowest was [0.1996 0.0577 0.2772 0.4388]
Median for last 10 epochs: [0.2206 0.0626 0.3386 0.4495], Epochs since improvement 2
 25%|██▌       | 127/500 [2:24:40<6:45:45, 65.27s/it] 26%|██▌       | 128/500 [2:26:01<7:15:13, 70.20s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 1.30E+06, Train scatter: [0.3723 0.0681 0.3081 0.4478]
L1 regularization loss: 4.28E+00, L2 regularization loss: 2.39E+00
Test scatter: [0.3731 0.0676 0.3138 0.4465], Lowest was [0.1996 0.0577 0.2772 0.4388]
Median for last 10 epochs: [0.2314 0.0636 0.3366 0.4486], Epochs since improvement 4
 26%|██▌       | 129/500 [2:26:55<6:43:32, 65.26s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 1.46E+06, Train scatter: [0.4166 0.0758 0.3454 0.4594]
L1 regularization loss: 4.59E+00, L2 regularization loss: 2.70E+00
Test scatter: [0.4087 0.0747 0.3505 0.4537], Lowest was [0.1996 0.0577 0.2772 0.4388]
Median for last 10 epochs: [0.3731 0.0676 0.3366 0.4486], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 26%|██▌       | 130/500 [2:28:24<7:26:40, 72.43s/it] 26%|██▌       | 131/500 [2:29:18<6:51:06, 66.85s/it] 26%|██▋       | 132/500 [2:30:39<7:16:49, 71.22s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 1.22E+06, Train scatter: [0.3801 0.0678 0.3033 0.4428]
L1 regularization loss: 4.60E+00, L2 regularization loss: 2.76E+00
Test scatter: [0.381  0.0669 0.3079 0.4398], Lowest was [0.1996 0.0577 0.2772 0.4388]
Median for last 10 epochs: [0.381  0.0676 0.3165 0.4465], Epochs since improvement 8
 27%|██▋       | 133/500 [2:31:33<6:43:48, 66.02s/it] 27%|██▋       | 134/500 [2:32:55<7:12:21, 70.88s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 1.19E+06, Train scatter: [0.3866 0.064  0.3262 0.4399]
L1 regularization loss: 4.60E+00, L2 regularization loss: 2.75E+00
Test scatter: [0.3818 0.0637 0.3223 0.4364], Lowest was [0.1996 0.0577 0.2772 0.4364]
Median for last 10 epochs: [0.3818 0.0676 0.3223 0.4465], Epochs since improvement 0
 27%|██▋       | 135/500 [2:33:49<6:40:19, 65.81s/it] 27%|██▋       | 136/500 [2:35:11<7:08:26, 70.62s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 1.06E+06, Train scatter: [0.307  0.059  0.2962 0.4361]
L1 regularization loss: 4.62E+00, L2 regularization loss: 2.84E+00
Test scatter: [0.2935 0.0587 0.3012 0.4329], Lowest was [0.1996 0.0577 0.2772 0.4329]
Median for last 10 epochs: [0.381  0.0669 0.3138 0.4398], Epochs since improvement 0
 27%|██▋       | 137/500 [2:36:05<6:37:10, 65.65s/it] 28%|██▊       | 138/500 [2:37:26<7:03:53, 70.26s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: 1.03E+06, Train scatter: [0.2509 0.0573 0.3194 0.4417]
L1 regularization loss: 4.63E+00, L2 regularization loss: 2.85E+00
Test scatter: [0.2452 0.0571 0.3232 0.4373], Lowest was [0.1996 0.0571 0.2772 0.4329]
Median for last 10 epochs: [0.381  0.0637 0.3223 0.4373], Epochs since improvement 0
 28%|██▊       | 139/500 [2:38:20<6:33:36, 65.42s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: 9.78E+05, Train scatter: [0.3031 0.0592 0.3069 0.4402]
L1 regularization loss: 4.64E+00, L2 regularization loss: 2.89E+00
Test scatter: [0.3027 0.0615 0.3125 0.4374], Lowest was [0.1996 0.0571 0.2772 0.4329]
Median for last 10 epochs: [0.3027 0.0615 0.3125 0.4373], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 28%|██▊       | 140/500 [2:39:49<7:13:46, 72.30s/it] 28%|██▊       | 141/500 [2:40:43<6:39:33, 66.78s/it] 28%|██▊       | 142/500 [2:42:05<7:05:22, 71.29s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: 8.94E+05, Train scatter: [0.2067 0.0556 0.3116 0.4334]
L1 regularization loss: 4.65E+00, L2 regularization loss: 2.92E+00
Test scatter: [0.2101 0.0556 0.3112 0.427 ], Lowest was [0.1996 0.0556 0.2772 0.427 ]
Median for last 10 epochs: [0.2935 0.0587 0.3125 0.4364], Epochs since improvement 0
 29%|██▊       | 143/500 [2:42:58<6:33:07, 66.07s/it] 29%|██▉       | 144/500 [2:44:20<6:59:35, 70.72s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 8.95E+05, Train scatter: [0.3694 0.0541 0.2986 0.4321]
L1 regularization loss: 4.65E+00, L2 regularization loss: 2.89E+00
Test scatter: [0.3699 0.0545 0.3017 0.4327], Lowest was [0.1996 0.0545 0.2772 0.427 ]
Median for last 10 epochs: [0.2935 0.0571 0.3112 0.4329], Epochs since improvement 0
 29%|██▉       | 145/500 [2:45:14<6:28:05, 65.59s/it] 29%|██▉       | 146/500 [2:46:36<6:56:14, 70.55s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 9.07E+05, Train scatter: [0.2172 0.0539 0.296  0.4246]
L1 regularization loss: 4.67E+00, L2 regularization loss: 2.98E+00
Test scatter: [0.2311 0.0542 0.296  0.419 ], Lowest was [0.1996 0.0542 0.2772 0.419 ]
Median for last 10 epochs: [0.2452 0.0556 0.3112 0.4327], Epochs since improvement 0
 29%|██▉       | 147/500 [2:47:30<6:25:45, 65.57s/it] 30%|██▉       | 148/500 [2:48:51<6:52:15, 70.27s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 7.75E+05, Train scatter: [0.2127 0.0592 0.3132 0.4293]
L1 regularization loss: 4.68E+00, L2 regularization loss: 3.01E+00
Test scatter: [0.229  0.0596 0.3191 0.431 ], Lowest was [0.1996 0.0542 0.2772 0.419 ]
Median for last 10 epochs: [0.2311 0.0556 0.3112 0.431 ], Epochs since improvement 2
 30%|██▉       | 149/500 [2:49:45<6:22:12, 65.34s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 6.71E+05, Train scatter: [0.1998 0.0547 0.3148 0.4272]
L1 regularization loss: 4.69E+00, L2 regularization loss: 3.03E+00
Test scatter: [0.245  0.0548 0.3297 0.4232], Lowest was [0.1996 0.0542 0.2772 0.419 ]
Median for last 10 epochs: [0.2311 0.0548 0.3112 0.427 ], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 30%|███       | 150/500 [2:51:13<7:01:30, 72.26s/it] 30%|███       | 151/500 [2:52:07<6:28:45, 66.83s/it] 30%|███       | 152/500 [2:53:28<6:52:14, 71.08s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 6.60E+05, Train scatter: [0.1994 0.0536 0.28   0.4314]
L1 regularization loss: 4.71E+00, L2 regularization loss: 3.07E+00
Test scatter: [0.2239 0.0546 0.2839 0.4339], Lowest was [0.1996 0.0542 0.2772 0.419 ]
Median for last 10 epochs: [0.2311 0.0546 0.3017 0.431 ], Epochs since improvement 6
 31%|███       | 153/500 [2:54:22<6:21:18, 65.93s/it] 31%|███       | 154/500 [2:55:45<6:48:58, 70.92s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 5.82E+05, Train scatter: [0.2105 0.0559 0.2794 0.4246]
L1 regularization loss: 4.72E+00, L2 regularization loss: 3.09E+00
Test scatter: [0.2462 0.0558 0.2803 0.4188], Lowest was [0.1996 0.0542 0.2772 0.4188]
Median for last 10 epochs: [0.2311 0.0548 0.296  0.4232], Epochs since improvement 0
 31%|███       | 155/500 [2:56:39<6:18:22, 65.80s/it] 31%|███       | 156/500 [2:58:00<6:43:42, 70.41s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 5.10E+05, Train scatter: [0.1913 0.051  0.2755 0.4135]
L1 regularization loss: 4.73E+00, L2 regularization loss: 3.13E+00
Test scatter: [0.2281 0.0504 0.2797 0.4069], Lowest was [0.1996 0.0504 0.2772 0.4069]
Median for last 10 epochs: [0.229  0.0548 0.2839 0.4232], Epochs since improvement 0
 31%|███▏      | 157/500 [2:58:54<6:14:10, 65.45s/it] 32%|███▏      | 158/500 [3:00:15<6:40:32, 70.27s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 5.09E+05, Train scatter: [0.1666 0.0515 0.2782 0.4101]
L1 regularization loss: 4.74E+00, L2 regularization loss: 3.16E+00
Test scatter: [0.1809 0.0505 0.2791 0.405 ], Lowest was [0.1809 0.0504 0.2772 0.405 ]
Median for last 10 epochs: [0.2281 0.0546 0.2803 0.4188], Epochs since improvement 0
 32%|███▏      | 159/500 [3:01:09<6:11:42, 65.40s/it]Epoch: 160 done with learning rate 9.04E-03, Train loss: 4.10E+05, Train scatter: [0.1701 0.0517 0.2649 0.4167]
L1 regularization loss: 4.76E+00, L2 regularization loss: 3.21E+00
Test scatter: [0.2048 0.0504 0.2687 0.4079], Lowest was [0.1809 0.0504 0.2687 0.405 ]
Median for last 10 epochs: [0.2239 0.0505 0.2797 0.4079], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 32%|███▏      | 160/500 [3:02:40<6:53:31, 72.98s/it] 32%|███▏      | 161/500 [3:03:34<6:19:56, 67.25s/it] 32%|███▏      | 162/500 [3:04:56<6:44:11, 71.75s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: 3.34E+05, Train scatter: [0.1683 0.0481 0.275  0.4067]
L1 regularization loss: 4.78E+00, L2 regularization loss: 3.27E+00
Test scatter: [0.1896 0.0484 0.2815 0.4086], Lowest was [0.1809 0.0484 0.2687 0.405 ]
Median for last 10 epochs: [0.2048 0.0504 0.2797 0.4079], Epochs since improvement 0
 33%|███▎      | 163/500 [3:05:50<6:12:53, 66.39s/it] 33%|███▎      | 164/500 [3:07:11<6:36:48, 70.86s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: 2.83E+05, Train scatter: [0.161  0.0536 0.2705 0.4124]
L1 regularization loss: 4.82E+00, L2 regularization loss: 3.35E+00
Test scatter: [0.1814 0.0532 0.2739 0.4087], Lowest was [0.1809 0.0484 0.2687 0.405 ]
Median for last 10 epochs: [0.1896 0.0504 0.2791 0.4079], Epochs since improvement 2
 33%|███▎      | 165/500 [3:08:05<6:07:12, 65.77s/it] 33%|███▎      | 166/500 [3:09:26<6:31:59, 70.42s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: 1.91E+05, Train scatter: [0.1575 0.0466 0.2546 0.3959]
L1 regularization loss: 4.84E+00, L2 regularization loss: 3.41E+00
Test scatter: [0.1785 0.0466 0.2584 0.3937], Lowest was [0.1785 0.0466 0.2584 0.3937]
Median for last 10 epochs: [0.1814 0.0504 0.2739 0.4079], Epochs since improvement 0
 33%|███▎      | 167/500 [3:10:20<6:03:17, 65.46s/it] 34%|███▎      | 168/500 [3:11:43<6:30:06, 70.50s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: 8.41E+04, Train scatter: [0.1667 0.0499 0.257  0.3986]
L1 regularization loss: 4.86E+00, L2 regularization loss: 3.46E+00
Test scatter: [0.1958 0.0498 0.2612 0.3983], Lowest was [0.1785 0.0466 0.2584 0.3937]
Median for last 10 epochs: [0.1896 0.0498 0.2687 0.4079], Epochs since improvement 2
 34%|███▍      | 169/500 [3:12:36<6:01:21, 65.50s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: 1.91E+04, Train scatter: [0.1616 0.0476 0.26   0.3985]
L1 regularization loss: 4.86E+00, L2 regularization loss: 3.49E+00
Test scatter: [0.19   0.0477 0.2635 0.398 ], Lowest was [0.1785 0.0466 0.2584 0.3937]
Median for last 10 epochs: [0.1896 0.0484 0.2635 0.3983], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 34%|███▍      | 170/500 [3:14:04<6:37:30, 72.27s/it] 34%|███▍      | 171/500 [3:14:59<6:06:17, 66.80s/it] 34%|███▍      | 172/500 [3:16:20<6:28:49, 71.13s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -4.97E+04, Train scatter: [0.1588 0.0482 0.2541 0.3924]
L1 regularization loss: 4.87E+00, L2 regularization loss: 3.53E+00
Test scatter: [0.2096 0.049  0.2586 0.3903], Lowest was [0.1785 0.0466 0.2584 0.3903]
Median for last 10 epochs: [0.19   0.049  0.2612 0.398 ], Epochs since improvement 0
 35%|███▍      | 173/500 [3:17:14<5:59:21, 65.94s/it] 35%|███▍      | 174/500 [3:18:35<6:23:37, 70.60s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -1.05E+05, Train scatter: [0.1922 0.0505 0.2453 0.3925]
L1 regularization loss: 4.88E+00, L2 regularization loss: 3.55E+00
Test scatter: [0.2411 0.0496 0.2477 0.3881], Lowest was [0.1785 0.0466 0.2477 0.3881]
Median for last 10 epochs: [0.1958 0.049  0.2586 0.3937], Epochs since improvement 0
 35%|███▌      | 175/500 [3:19:29<5:55:19, 65.60s/it] 35%|███▌      | 176/500 [3:20:51<6:21:20, 70.62s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -1.47E+05, Train scatter: [0.1413 0.0474 0.2731 0.3998]
L1 regularization loss: 4.89E+00, L2 regularization loss: 3.59E+00
Test scatter: [0.1436 0.0467 0.275  0.3927], Lowest was [0.1436 0.0466 0.2477 0.3881]
Median for last 10 epochs: [0.1958 0.049  0.2612 0.3927], Epochs since improvement 0
 35%|███▌      | 177/500 [3:21:45<5:53:32, 65.67s/it] 36%|███▌      | 178/500 [3:23:07<6:18:08, 70.46s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -1.93E+05, Train scatter: [0.1897 0.048  0.2446 0.3967]
L1 regularization loss: 4.90E+00, L2 regularization loss: 3.62E+00
Test scatter: [0.193  0.0478 0.2474 0.3945], Lowest was [0.1436 0.0466 0.2474 0.3881]
Median for last 10 epochs: [0.193  0.0478 0.2586 0.3927], Epochs since improvement 0
 36%|███▌      | 179/500 [3:24:01<5:50:27, 65.50s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -2.42E+05, Train scatter: [0.1417 0.0436 0.2425 0.3915]
L1 regularization loss: 4.90E+00, L2 regularization loss: 3.65E+00
Test scatter: [0.1466 0.0439 0.2447 0.3891], Lowest was [0.1436 0.0439 0.2447 0.3881]
Median for last 10 epochs: [0.193  0.0478 0.2477 0.3903], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 36%|███▌      | 180/500 [3:25:29<6:25:47, 72.34s/it] 36%|███▌      | 181/500 [3:26:23<5:55:30, 66.87s/it] 36%|███▋      | 182/500 [3:27:44<6:16:48, 71.09s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -2.60E+05, Train scatter: [0.1482 0.043  0.2366 0.3892]
L1 regularization loss: 4.90E+00, L2 regularization loss: 3.67E+00
Test scatter: [0.152  0.0432 0.241  0.3868], Lowest was [0.1436 0.0432 0.241  0.3868]
Median for last 10 epochs: [0.152  0.0467 0.2474 0.3891], Epochs since improvement 0
 37%|███▋      | 183/500 [3:28:38<5:48:08, 65.89s/it] 37%|███▋      | 184/500 [3:30:00<6:12:54, 70.81s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -2.99E+05, Train scatter: [0.1343 0.0438 0.2448 0.3932]
L1 regularization loss: 4.90E+00, L2 regularization loss: 3.70E+00
Test scatter: [0.1409 0.0436 0.2494 0.3907], Lowest was [0.1409 0.0432 0.241  0.3868]
Median for last 10 epochs: [0.1466 0.0439 0.2474 0.3907], Epochs since improvement 0
 37%|███▋      | 185/500 [3:30:54<5:45:02, 65.72s/it] 37%|███▋      | 186/500 [3:32:15<6:07:36, 70.25s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -3.16E+05, Train scatter: [0.1272 0.0414 0.2274 0.3856]
L1 regularization loss: 4.90E+00, L2 regularization loss: 3.73E+00
Test scatter: [0.1306 0.0414 0.2315 0.3827], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.1466 0.0436 0.2447 0.3891], Epochs since improvement 0
 37%|███▋      | 187/500 [3:33:09<5:40:43, 65.32s/it] 38%|███▊      | 188/500 [3:34:30<6:04:34, 70.11s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -3.08E+05, Train scatter: [0.131  0.0442 0.2318 0.3901]
L1 regularization loss: 4.90E+00, L2 regularization loss: 3.75E+00
Test scatter: [0.1367 0.044  0.2338 0.3858], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.1409 0.0436 0.241  0.3868], Epochs since improvement 2
 38%|███▊      | 189/500 [3:35:24<5:38:30, 65.31s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -3.33E+05, Train scatter: [0.1484 0.0443 0.2316 0.4005]
L1 regularization loss: 4.93E+00, L2 regularization loss: 3.80E+00
Test scatter: [0.1518 0.0442 0.2374 0.4024], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.1409 0.0436 0.2374 0.3868], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 38%|███▊      | 190/500 [3:36:53<6:13:12, 72.24s/it] 38%|███▊      | 191/500 [3:37:47<5:44:06, 66.82s/it] 38%|███▊      | 192/500 [3:39:08<6:04:44, 71.05s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -3.47E+05, Train scatter: [0.1328 0.0426 0.2307 0.3934]
L1 regularization loss: 4.95E+00, L2 regularization loss: 3.84E+00
Test scatter: [0.1346 0.0427 0.2324 0.3899], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.1367 0.0436 0.2338 0.3899], Epochs since improvement 6
 39%|███▊      | 193/500 [3:40:02<5:37:35, 65.98s/it] 39%|███▉      | 194/500 [3:41:23<6:00:05, 70.61s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -3.66E+05, Train scatter: [0.196  0.0457 0.2341 0.3901]
L1 regularization loss: 4.95E+00, L2 regularization loss: 3.87E+00
Test scatter: [0.2034 0.0449 0.2376 0.3889], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.1367 0.044  0.2338 0.3889], Epochs since improvement 8
 39%|███▉      | 195/500 [3:42:18<5:34:00, 65.71s/it] 39%|███▉      | 196/500 [3:43:40<5:57:54, 70.64s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: 3.20E+05, Train scatter: [0.9343 0.1737 0.5435 0.9935]
L1 regularization loss: 6.04E+00, L2 regularization loss: 4.54E+00
Test scatter: [0.9187 0.1697 0.535  0.9832], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.1518 0.0442 0.2374 0.3899], Epochs since improvement 10
 39%|███▉      | 197/500 [3:44:34<5:31:41, 65.68s/it] 40%|███▉      | 198/500 [3:45:56<5:55:26, 70.62s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: 1.47E+05, Train scatter: [0.9334 0.1695 0.5433 0.9835]
L1 regularization loss: 6.03E+00, L2 regularization loss: 4.60E+00
Test scatter: [0.9178 0.1658 0.5347 0.9738], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.2034 0.0449 0.2376 0.4024], Epochs since improvement 12
 40%|███▉      | 199/500 [3:46:50<5:29:30, 65.68s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: 3.22E+04, Train scatter: [0.9304 0.1098 0.5412 0.9069]
L1 regularization loss: 6.02E+00, L2 regularization loss: 4.69E+00
Test scatter: [0.9148 0.1086 0.5328 0.8986], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.9148 0.1086 0.5328 0.8986], Epochs since improvement 14
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 40%|████      | 200/500 [3:48:19<6:03:00, 72.60s/it] 40%|████      | 201/500 [3:49:13<5:34:20, 67.09s/it] 40%|████      | 202/500 [3:50:34<5:54:21, 71.35s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -5.23E+04, Train scatter: [0.924  0.1002 0.5033 0.7209]
L1 regularization loss: 6.06E+00, L2 regularization loss: 4.87E+00
Test scatter: [0.9085 0.0983 0.4938 0.7138], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.9148 0.1086 0.5328 0.8986], Epochs since improvement 16
 41%|████      | 203/500 [3:51:28<5:27:26, 66.15s/it] 41%|████      | 204/500 [3:52:49<5:48:21, 70.61s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -1.21E+05, Train scatter: [0.907  0.0912 0.4573 0.5985]
L1 regularization loss: 6.07E+00, L2 regularization loss: 5.06E+00
Test scatter: [0.8917 0.09   0.4528 0.5912], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.9148 0.1086 0.5328 0.8986], Epochs since improvement 18
 41%|████      | 205/500 [3:53:44<5:23:04, 65.71s/it] 41%|████      | 206/500 [3:55:05<5:45:05, 70.43s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -1.62E+05, Train scatter: [0.8948 0.0849 0.4568 0.5766]
L1 regularization loss: 6.09E+00, L2 regularization loss: 5.20E+00
Test scatter: [0.8796 0.0833 0.4533 0.5681], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.9085 0.0983 0.4938 0.7138], Epochs since improvement 20
 41%|████▏     | 207/500 [3:55:59<5:20:05, 65.55s/it] 41%|████▏     | 207/500 [3:57:21<5:35:57, 68.80s/it]
Epoch: 208 done with learning rate 7.77E-03, Train loss: -1.58E+05, Train scatter: [0.8871 0.0888 0.4115 0.6015]
L1 regularization loss: 6.08E+00, L2 regularization loss: 5.27E+00
Test scatter: [0.8721 0.0871 0.4048 0.5897], Lowest was [0.1306 0.0414 0.2315 0.3827]
Median for last 10 epochs: [0.8917 0.09   0.4533 0.5912], Epochs since improvement 22
Exited after 208 epochs due to early stopping
14241.04 seconds spent training, 28.482 seconds per epoch. Processed 2445 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.87208575 0.08705532 0.4047488  0.58968925]
{'epoch_exit': 207, 'scatter_m_star': 0.87208575, 'lowest_m_star': 0.13064432, 'last20_m_star': 0.8856933, 'last10_m_star': 0.8917483, 'scatter_v_disk': 0.08705532, 'lowest_v_disk': 0.041394375, 'last20_v_disk': 0.088526994, 'last10_v_disk': 0.08999618, 'scatter_m_cold': 0.4047488, 'lowest_m_cold': 0.23150575, 'last20_m_cold': 0.4530542, 'last10_m_cold': 0.45328543, 'scatter_sfr_100': 0.58968925, 'lowest_sfr_100': 0.3826871, 'last20_sfr_100': 0.59043235, 'last10_sfr_100': 0.5911587}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
