Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_jtzlfc
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:31<4:21:22, 31.43s/it]  0%|          | 2/500 [01:19<5:43:04, 41.33s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.21E+07, Train scatter: [0.9353 0.1747 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1818 0.5356 0.9851], Lowest was [0.9198 0.1818 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1818 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:51<5:04:57, 36.82s/it]  1%|          | 4/500 [02:40<5:44:34, 41.68s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 7.46E+06, Train scatter: [0.9352 0.1758 0.544  0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1877 0.5354 0.985 ], Lowest was [0.9197 0.1818 0.5354 0.985 ]
Median for last 10 epochs: [0.9197 0.1847 0.5354 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:11<5:13:07, 37.95s/it]  1%|          | 6/500 [04:00<5:43:02, 41.67s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.68E+06, Train scatter: [0.9346 0.1421 0.5429 0.7269]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9191 0.1452 0.5343 0.7216], Lowest was [0.9191 0.1452 0.5343 0.7216]
Median for last 10 epochs: [0.9191 0.1452 0.5343 0.7216], Epochs since improvement 0
  1%|▏         | 7/500 [04:31<5:14:59, 38.34s/it]  2%|▏         | 8/500 [05:20<5:42:12, 41.73s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.85E+06, Train scatter: [0.9247 0.1258 0.5369 0.6734]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9096 0.1269 0.5285 0.6653], Lowest was [0.9096 0.1269 0.5285 0.6653]
Median for last 10 epochs: [0.9143 0.1361 0.5314 0.6935], Epochs since improvement 0
  2%|▏         | 9/500 [05:52<5:15:21, 38.54s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.24E+06, Train scatter: [0.7516 0.1158 0.5217 0.6257]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.736  0.1168 0.514  0.6265], Lowest was [0.736  0.1168 0.514  0.6265]
Median for last 10 epochs: [0.9096 0.1269 0.5285 0.6653], Epochs since improvement 0
  2%|▏         | 10/500 [06:46<5:54:25, 43.40s/it]  2%|▏         | 11/500 [07:18<5:23:51, 39.74s/it]  2%|▏         | 12/500 [08:07<5:45:41, 42.50s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.60E+06, Train scatter: [0.5886 0.1129 0.4142 0.61  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5856 0.1144 0.4128 0.6107], Lowest was [0.5856 0.1144 0.4128 0.6107]
Median for last 10 epochs: [0.9096 0.1269 0.5285 0.6653], Epochs since improvement 0
  3%|▎         | 13/500 [08:38<5:17:57, 39.17s/it]  3%|▎         | 14/500 [09:27<5:41:50, 42.20s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.62E+06, Train scatter: [0.5648 0.1077 0.3638 0.6007]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.553  0.111  0.3728 0.6074], Lowest was [0.553  0.111  0.3728 0.6074]
Median for last 10 epochs: [0.736  0.1168 0.514  0.6265], Epochs since improvement 0
  3%|▎         | 15/500 [09:59<5:14:45, 38.94s/it]  3%|▎         | 16/500 [10:48<5:38:34, 41.97s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.17E+06, Train scatter: [0.542  0.1003 0.3418 0.5963]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5295 0.1026 0.3479 0.597 ], Lowest was [0.5295 0.1026 0.3479 0.597 ]
Median for last 10 epochs: [0.5856 0.1144 0.4128 0.6107], Epochs since improvement 0
  3%|▎         | 17/500 [11:19<5:12:23, 38.81s/it]  4%|▎         | 18/500 [12:08<5:36:45, 41.92s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 9.19E+05, Train scatter: [0.6235 0.0952 0.4233 0.5999]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5878 0.0962 0.4255 0.5971], Lowest was [0.5295 0.0962 0.3479 0.597 ]
Median for last 10 epochs: [0.5856 0.111  0.4128 0.6074], Epochs since improvement 0
  4%|▍         | 19/500 [12:40<5:10:34, 38.74s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.00E+05, Train scatter: [0.9164 0.091  0.3322 0.5845]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8073 0.095  0.3415 0.5907], Lowest was [0.5295 0.095  0.3415 0.5907]
Median for last 10 epochs: [0.5856 0.1026 0.3728 0.5971], Epochs since improvement 0
  4%|▍         | 20/500 [13:34<5:46:21, 43.30s/it]  4%|▍         | 21/500 [14:05<5:17:22, 39.76s/it]  4%|▍         | 22/500 [14:54<5:38:25, 42.48s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.38E+05, Train scatter: [0.6898 0.0915 0.3235 0.5854]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6768 0.0957 0.3372 0.5911], Lowest was [0.5295 0.095  0.3372 0.5907]
Median for last 10 epochs: [0.5878 0.0962 0.3479 0.597 ], Epochs since improvement 0
  5%|▍         | 23/500 [15:25<5:11:34, 39.19s/it]  5%|▍         | 24/500 [16:14<5:33:55, 42.09s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.02E+05, Train scatter: [0.4978 0.0905 0.3527 0.5627]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4886 0.0937 0.3553 0.557 ], Lowest was [0.4886 0.0937 0.3372 0.557 ]
Median for last 10 epochs: [0.5878 0.0957 0.3479 0.5911], Epochs since improvement 0
  5%|▌         | 25/500 [16:46<5:08:34, 38.98s/it]  5%|▌         | 26/500 [17:34<5:30:36, 41.85s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 6.19E+05, Train scatter: [0.4673 0.0843 0.3034 0.5405]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.476  0.088  0.3103 0.5441], Lowest was [0.476  0.088  0.3103 0.5441]
Median for last 10 epochs: [0.5878 0.095  0.3415 0.5907], Epochs since improvement 0
  5%|▌         | 27/500 [18:06<5:05:21, 38.73s/it]  6%|▌         | 28/500 [18:55<5:28:55, 41.81s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 5.15E+05, Train scatter: [0.487  0.082  0.3021 0.5995]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4861 0.086  0.3141 0.5946], Lowest was [0.476  0.086  0.3103 0.5441]
Median for last 10 epochs: [0.4886 0.0937 0.3372 0.5907], Epochs since improvement 0
  6%|▌         | 29/500 [19:26<5:03:50, 38.71s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 1.49E+08, Train scatter: [0.9378 0.1689 0.544  0.9748]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9223 0.1649 0.5354 0.9651], Lowest was [0.476  0.086  0.3103 0.5441]
Median for last 10 epochs: [0.4886 0.0937 0.3372 0.5911], Epochs since improvement 2
  6%|▌         | 30/500 [20:20<5:37:31, 43.09s/it]  6%|▌         | 31/500 [20:51<5:09:42, 39.62s/it]  6%|▋         | 32/500 [21:40<5:29:55, 42.30s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.87E+06, Train scatter: [0.8317 0.1484 0.5427 0.8055]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8201 0.1453 0.5341 0.7981], Lowest was [0.476  0.086  0.3103 0.5441]
Median for last 10 epochs: [0.4886 0.0937 0.3553 0.5946], Epochs since improvement 4
  7%|▋         | 33/500 [22:11<5:03:55, 39.05s/it]  7%|▋         | 34/500 [23:00<5:26:34, 42.05s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.84E+06, Train scatter: [0.5993 0.1217 0.5358 0.7272]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6003 0.1203 0.5273 0.7244], Lowest was [0.476  0.086  0.3103 0.5441]
Median for last 10 epochs: [0.6003 0.1203 0.5273 0.7244], Epochs since improvement 6
  7%|▋         | 35/500 [23:32<5:01:10, 38.86s/it]  7%|▋         | 36/500 [24:21<5:24:03, 41.90s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 1.83E+06, Train scatter: [0.5397 0.1128 0.533  0.6798]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5362 0.1115 0.5245 0.6746], Lowest was [0.476  0.086  0.3103 0.5441]
Median for last 10 epochs: [0.6003 0.1203 0.5273 0.7244], Epochs since improvement 8
  7%|▋         | 37/500 [24:52<4:59:12, 38.77s/it]  8%|▊         | 38/500 [25:41<5:22:06, 41.83s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.49E+06, Train scatter: [0.5417 0.1051 0.5295 0.6594]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.547  0.1043 0.5212 0.6554], Lowest was [0.476  0.086  0.3103 0.5441]
Median for last 10 epochs: [0.6003 0.1203 0.5273 0.7244], Epochs since improvement 10
  8%|▊         | 39/500 [26:13<4:57:38, 38.74s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.22E+06, Train scatter: [0.5333 0.1031 0.5235 0.6303]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5178 0.1016 0.5148 0.6182], Lowest was [0.476  0.086  0.3103 0.5441]
Median for last 10 epochs: [0.547  0.1115 0.5245 0.6746], Epochs since improvement 12
  8%|▊         | 40/500 [27:07<5:32:32, 43.37s/it]  8%|▊         | 41/500 [27:38<5:04:36, 39.82s/it]  8%|▊         | 42/500 [28:28<5:25:15, 42.61s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 8.01E+05, Train scatter: [0.3905 0.0909 0.5214 0.5911]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3996 0.0899 0.5127 0.5802], Lowest was [0.3996 0.086  0.3103 0.5441]
Median for last 10 epochs: [0.5362 0.1043 0.5212 0.6554], Epochs since improvement 0
  9%|▊         | 43/500 [28:59<4:59:16, 39.29s/it]  9%|▉         | 44/500 [29:47<5:19:08, 41.99s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 6.38E+05, Train scatter: [0.3547 0.0875 0.5137 0.576 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3592 0.0866 0.5047 0.5656], Lowest was [0.3592 0.086  0.3103 0.5441]
Median for last 10 epochs: [0.5178 0.1016 0.5148 0.6182], Epochs since improvement 0
  9%|▉         | 45/500 [30:19<4:54:38, 38.85s/it]  9%|▉         | 46/500 [31:08<5:16:35, 41.84s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.91E+05, Train scatter: [0.3129 0.085  0.4966 0.5615]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3143 0.0838 0.486  0.5495], Lowest was [0.3143 0.0838 0.3103 0.5441]
Median for last 10 epochs: [0.3996 0.0899 0.5127 0.5802], Epochs since improvement 0
  9%|▉         | 47/500 [31:39<4:52:20, 38.72s/it] 10%|▉         | 48/500 [32:28<5:15:33, 41.89s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 4.47E+05, Train scatter: [0.3445 0.0838 0.4817 0.5558]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3554 0.0829 0.4735 0.5454], Lowest was [0.3143 0.0829 0.3103 0.5441]
Median for last 10 epochs: [0.3592 0.0866 0.5047 0.5656], Epochs since improvement 0
 10%|▉         | 49/500 [33:00<4:51:29, 38.78s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.55E+05, Train scatter: [0.298  0.0812 0.4187 0.5572]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3012 0.08   0.417  0.5455], Lowest was [0.3012 0.08   0.3103 0.5441]
Median for last 10 epochs: [0.3554 0.0838 0.486  0.5495], Epochs since improvement 0
 10%|█         | 50/500 [33:55<5:26:41, 43.56s/it] 10%|█         | 51/500 [34:26<4:58:55, 39.95s/it] 10%|█         | 52/500 [35:15<5:19:05, 42.73s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.59E+05, Train scatter: [0.3395 0.0789 0.415  0.5441]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.333  0.0777 0.4129 0.5321], Lowest was [0.3012 0.0777 0.3103 0.5321]
Median for last 10 epochs: [0.333  0.0829 0.4735 0.5455], Epochs since improvement 0
 11%|█         | 53/500 [35:47<4:53:12, 39.36s/it] 11%|█         | 54/500 [36:36<5:15:06, 42.39s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 9.61E+04, Train scatter: [0.3261 0.0836 0.4201 0.5738]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3382 0.0846 0.4177 0.5749], Lowest was [0.3012 0.0777 0.3103 0.5321]
Median for last 10 epochs: [0.333  0.0829 0.4177 0.5455], Epochs since improvement 2
 11%|█         | 55/500 [37:08<4:50:13, 39.13s/it] 11%|█         | 56/500 [37:57<5:11:02, 42.03s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 7.95E+04, Train scatter: [0.2511 0.0773 0.4028 0.536 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2539 0.0769 0.4045 0.5288], Lowest was [0.2539 0.0769 0.3103 0.5288]
Median for last 10 epochs: [0.333  0.08   0.417  0.5454], Epochs since improvement 0
 11%|█▏        | 57/500 [38:28<4:47:09, 38.89s/it] 12%|█▏        | 58/500 [39:17<5:07:52, 41.79s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.18E+05, Train scatter: [0.2683 0.0773 0.4022 0.5298]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2739 0.0762 0.3995 0.5238], Lowest was [0.2539 0.0762 0.3103 0.5238]
Median for last 10 epochs: [0.3012 0.0777 0.4129 0.5321], Epochs since improvement 0
 12%|█▏        | 59/500 [39:48<4:44:38, 38.73s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 6.47E+02, Train scatter: [0.3358 0.0805 0.3983 0.5443]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3346 0.0789 0.3966 0.5366], Lowest was [0.2539 0.0762 0.3103 0.5238]
Median for last 10 epochs: [0.333  0.0777 0.4045 0.5321], Epochs since improvement 2
 12%|█▏        | 60/500 [40:43<5:18:47, 43.47s/it] 12%|█▏        | 61/500 [41:14<4:51:45, 39.88s/it] 12%|█▏        | 62/500 [42:03<5:11:04, 42.61s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: -5.64E+04, Train scatter: [0.2491 0.0737 0.3903 0.5224]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2569 0.0731 0.389  0.5161], Lowest was [0.2539 0.0731 0.3103 0.5161]
Median for last 10 epochs: [0.2739 0.0769 0.3995 0.5288], Epochs since improvement 0
 13%|█▎        | 63/500 [42:35<4:46:06, 39.28s/it] 13%|█▎        | 64/500 [43:24<5:07:25, 42.31s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: -6.73E+04, Train scatter: [0.3113 0.0749 0.3858 0.5203]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3083 0.0753 0.3856 0.515 ], Lowest was [0.2539 0.0731 0.3103 0.515 ]
Median for last 10 epochs: [0.2739 0.0762 0.3966 0.5238], Epochs since improvement 0
 13%|█▎        | 65/500 [43:56<4:43:43, 39.13s/it] 13%|█▎        | 66/500 [44:45<5:04:40, 42.12s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: -6.89E+04, Train scatter: [0.2821 0.0781 0.411  0.5405]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.28   0.078  0.4179 0.5376], Lowest was [0.2539 0.0731 0.3103 0.515 ]
Median for last 10 epochs: [0.28   0.0762 0.3966 0.5238], Epochs since improvement 2
 13%|█▎        | 67/500 [45:17<4:41:59, 39.08s/it] 14%|█▎        | 68/500 [46:07<5:04:08, 42.24s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: -1.25E+05, Train scatter: [0.2751 0.0735 0.378  0.526 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2724 0.0734 0.3817 0.5194], Lowest was [0.2539 0.0731 0.3103 0.515 ]
Median for last 10 epochs: [0.28   0.0753 0.389  0.5194], Epochs since improvement 4
 14%|█▍        | 69/500 [46:38<4:40:51, 39.10s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: -1.46E+05, Train scatter: [0.2867 0.0768 0.4556 0.5474]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.285  0.0754 0.4499 0.5338], Lowest was [0.2539 0.0731 0.3103 0.515 ]
Median for last 10 epochs: [0.28   0.0753 0.389  0.5194], Epochs since improvement 6
 14%|█▍        | 70/500 [47:34<5:15:43, 44.06s/it] 14%|█▍        | 71/500 [48:06<4:48:40, 40.37s/it] 14%|█▍        | 72/500 [48:55<5:07:29, 43.11s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: -1.79E+05, Train scatter: [0.2241 0.0839 0.3754 0.5426]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2245 0.0815 0.3752 0.536 ], Lowest was [0.2245 0.0731 0.3103 0.515 ]
Median for last 10 epochs: [0.28   0.0754 0.3856 0.5338], Epochs since improvement 0
 15%|█▍        | 73/500 [49:27<4:42:08, 39.65s/it] 15%|█▍        | 74/500 [50:17<5:03:28, 42.74s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: -2.03E+05, Train scatter: [0.2072 0.0685 0.4146 0.4948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2094 0.0683 0.4119 0.491 ], Lowest was [0.2094 0.0683 0.3103 0.491 ]
Median for last 10 epochs: [0.2724 0.0754 0.4119 0.5338], Epochs since improvement 0
 15%|█▌        | 75/500 [50:49<4:39:05, 39.40s/it] 15%|█▌        | 76/500 [51:38<4:59:51, 42.43s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: -2.34E+05, Train scatter: [0.2356 0.0731 0.3658 0.5223]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2383 0.0719 0.3647 0.5209], Lowest was [0.2094 0.0683 0.3103 0.491 ]
Median for last 10 epochs: [0.2383 0.0734 0.3817 0.5209], Epochs since improvement 2
 15%|█▌        | 77/500 [52:10<4:36:29, 39.22s/it] 16%|█▌        | 78/500 [53:00<4:58:16, 42.41s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: -2.56E+05, Train scatter: [0.2321 0.0668 0.3579 0.4963]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2349 0.0659 0.3591 0.4934], Lowest was [0.2094 0.0659 0.3103 0.491 ]
Median for last 10 epochs: [0.2349 0.0719 0.3752 0.5209], Epochs since improvement 0
 16%|█▌        | 79/500 [53:31<4:34:54, 39.18s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: -2.65E+05, Train scatter: [0.1956 0.0631 0.3401 0.4847]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1971 0.0627 0.3439 0.4797], Lowest was [0.1971 0.0627 0.3103 0.4797]
Median for last 10 epochs: [0.2245 0.0683 0.3647 0.4934], Epochs since improvement 0
 16%|█▌        | 80/500 [54:25<5:05:54, 43.70s/it] 16%|█▌        | 81/500 [54:57<4:40:29, 40.17s/it] 16%|█▋        | 82/500 [55:46<4:58:01, 42.78s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: -2.76E+05, Train scatter: [0.2094 0.0643 0.3534 0.4942]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2078 0.064  0.3525 0.4876], Lowest was [0.1971 0.0627 0.3103 0.4797]
Median for last 10 epochs: [0.2094 0.0659 0.3591 0.491 ], Epochs since improvement 2
 17%|█▋        | 83/500 [56:18<4:34:48, 39.54s/it] 17%|█▋        | 84/500 [57:08<4:54:52, 42.53s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: -2.81E+05, Train scatter: [0.2541 0.0674 0.3274 0.4878]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2497 0.0673 0.3306 0.4844], Lowest was [0.1971 0.0627 0.3103 0.4797]
Median for last 10 epochs: [0.2349 0.0659 0.3525 0.4876], Epochs since improvement 4
 17%|█▋        | 85/500 [57:40<4:32:07, 39.34s/it] 17%|█▋        | 86/500 [58:30<4:53:09, 42.49s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: -2.90E+05, Train scatter: [0.2733 0.0683 0.356  0.5236]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2846 0.0692 0.3605 0.5203], Lowest was [0.1971 0.0627 0.3103 0.4797]
Median for last 10 epochs: [0.2349 0.0659 0.3525 0.4876], Epochs since improvement 6
 17%|█▋        | 87/500 [59:01<4:30:29, 39.30s/it] 18%|█▊        | 88/500 [59:52<4:52:19, 42.57s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: -2.45E+05, Train scatter: [0.2586 0.0739 0.3629 0.532 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2574 0.0732 0.3639 0.5218], Lowest was [0.1971 0.0627 0.3103 0.4797]
Median for last 10 epochs: [0.2497 0.0673 0.3525 0.4876], Epochs since improvement 8
 18%|█▊        | 89/500 [1:00:23<4:29:12, 39.30s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: -2.99E+05, Train scatter: [0.3386 0.0759 0.3147 0.49  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.336  0.0736 0.3162 0.4821], Lowest was [0.1971 0.0627 0.3103 0.4797]
Median for last 10 epochs: [0.2574 0.0692 0.3525 0.4876], Epochs since improvement 10
 18%|█▊        | 90/500 [1:01:18<4:59:29, 43.83s/it] 18%|█▊        | 91/500 [1:01:49<4:33:50, 40.17s/it] 18%|█▊        | 92/500 [1:02:39<4:52:17, 42.98s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: -3.06E+05, Train scatter: [0.2203 0.0552 0.3124 0.4707]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2156 0.0546 0.3154 0.4646], Lowest was [0.1971 0.0546 0.3103 0.4646]
Median for last 10 epochs: [0.2574 0.0692 0.3306 0.4844], Epochs since improvement 0
 19%|█▊        | 93/500 [1:03:11<4:28:35, 39.60s/it] 19%|█▉        | 94/500 [1:04:00<4:47:57, 42.56s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: -2.60E+05, Train scatter: [0.2003 0.0555 0.3032 0.4708]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2123 0.0553 0.3057 0.4705], Lowest was [0.1971 0.0546 0.3057 0.4646]
Median for last 10 epochs: [0.2574 0.0692 0.3162 0.4821], Epochs since improvement 0
 19%|█▉        | 95/500 [1:04:32<4:25:02, 39.26s/it] 19%|█▉        | 96/500 [1:05:22<4:46:03, 42.48s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: -2.82E+05, Train scatter: [0.2009 0.0573 0.2963 0.4662]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2035 0.0576 0.3027 0.4626], Lowest was [0.1971 0.0546 0.3027 0.4626]
Median for last 10 epochs: [0.2156 0.0576 0.3154 0.4705], Epochs since improvement 0
 19%|█▉        | 97/500 [1:05:53<4:23:34, 39.24s/it] 20%|█▉        | 98/500 [1:06:43<4:44:20, 42.44s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: -3.21E+05, Train scatter: [0.1841 0.0525 0.2883 0.4581]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1907 0.0525 0.2927 0.4542], Lowest was [0.1907 0.0525 0.2927 0.4542]
Median for last 10 epochs: [0.2123 0.0553 0.3057 0.4646], Epochs since improvement 0
 20%|█▉        | 99/500 [1:07:15<4:22:38, 39.30s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: -3.19E+05, Train scatter: [0.1704 0.0524 0.2851 0.4548]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1733 0.0518 0.2868 0.4476], Lowest was [0.1733 0.0518 0.2868 0.4476]
Median for last 10 epochs: [0.2035 0.0546 0.3027 0.4626], Epochs since improvement 0
 20%|██        | 100/500 [1:08:10<4:52:57, 43.94s/it] 20%|██        | 101/500 [1:08:42<4:28:50, 40.43s/it] 20%|██        | 102/500 [1:09:32<4:46:20, 43.17s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: -3.38E+05, Train scatter: [0.1604 0.0503 0.27   0.4544]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2247 0.05   0.2704 0.4503], Lowest was [0.1733 0.05   0.2704 0.4476]
Median for last 10 epochs: [0.2035 0.0525 0.2927 0.4542], Epochs since improvement 0
 21%|██        | 103/500 [1:10:03<4:23:04, 39.76s/it] 21%|██        | 104/500 [1:10:53<4:41:30, 42.65s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: -3.19E+05, Train scatter: [0.1752 0.0514 0.2758 0.4551]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1762 0.0513 0.2763 0.4487], Lowest was [0.1733 0.05   0.2704 0.4476]
Median for last 10 epochs: [0.1907 0.0518 0.2868 0.4503], Epochs since improvement 2
 21%|██        | 105/500 [1:11:25<4:19:04, 39.35s/it] 21%|██        | 106/500 [1:12:14<4:38:13, 42.37s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: -3.20E+05, Train scatter: [0.1675 0.0527 0.2813 0.4567]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1687 0.0517 0.2889 0.4519], Lowest was [0.1687 0.05   0.2704 0.4476]
Median for last 10 epochs: [0.1762 0.0517 0.2868 0.4503], Epochs since improvement 0
 21%|██▏       | 107/500 [1:12:46<4:16:32, 39.17s/it] 22%|██▏       | 108/500 [1:13:35<4:36:44, 42.36s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: -1.52E+05, Train scatter: [0.5053 0.0843 0.4752 0.5974]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4903 0.0844 0.4718 0.5935], Lowest was [0.1687 0.05   0.2704 0.4476]
Median for last 10 epochs: [0.1762 0.0517 0.2868 0.4503], Epochs since improvement 2
 22%|██▏       | 109/500 [1:14:07<4:15:07, 39.15s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: -2.77E+05, Train scatter: [0.2941 0.0654 0.438  0.4966]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2899 0.0646 0.4328 0.4926], Lowest was [0.1687 0.05   0.2704 0.4476]
Median for last 10 epochs: [0.2247 0.0517 0.2889 0.4519], Epochs since improvement 4
 22%|██▏       | 110/500 [1:15:02<4:45:32, 43.93s/it] 22%|██▏       | 111/500 [1:15:34<4:21:03, 40.27s/it] 22%|██▏       | 112/500 [1:16:24<4:39:19, 43.20s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: -3.17E+05, Train scatter: [0.1993 0.0595 0.2975 0.4727]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2033 0.0602 0.305  0.4713], Lowest was [0.1687 0.05   0.2704 0.4476]
Median for last 10 epochs: [0.2033 0.0602 0.305  0.4713], Epochs since improvement 6
 23%|██▎       | 113/500 [1:16:55<4:16:00, 39.69s/it] 23%|██▎       | 114/500 [1:17:45<4:34:43, 42.70s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: -3.33E+05, Train scatter: [0.4221 0.0542 0.3147 0.4609]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4101 0.0535 0.3138 0.4566], Lowest was [0.1687 0.05   0.2704 0.4476]
Median for last 10 epochs: [0.2899 0.0602 0.3138 0.4713], Epochs since improvement 8
 23%|██▎       | 115/500 [1:18:17<4:12:48, 39.40s/it] 23%|██▎       | 116/500 [1:19:07<4:32:54, 42.64s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: -3.51E+05, Train scatter: [0.206  0.0483 0.2722 0.445 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2055 0.0484 0.2757 0.439 ], Lowest was [0.1687 0.0484 0.2704 0.439 ]
Median for last 10 epochs: [0.2899 0.0602 0.3138 0.4713], Epochs since improvement 0
 23%|██▎       | 117/500 [1:19:39<4:11:44, 39.44s/it] 24%|██▎       | 118/500 [1:20:28<4:29:43, 42.36s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: -3.64E+05, Train scatter: [0.172  0.0463 0.2551 0.4361]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1727 0.0463 0.2564 0.4311], Lowest was [0.1687 0.0463 0.2564 0.4311]
Median for last 10 epochs: [0.2055 0.0535 0.305  0.4566], Epochs since improvement 0
 24%|██▍       | 119/500 [1:21:00<4:09:15, 39.25s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: -3.28E+05, Train scatter: [0.2271 0.0469 0.2527 0.4421]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2193 0.0466 0.2542 0.4361], Lowest was [0.1687 0.0463 0.2542 0.4311]
Median for last 10 epochs: [0.2055 0.0484 0.2757 0.439 ], Epochs since improvement 0
 24%|██▍       | 120/500 [1:21:54<4:36:58, 43.73s/it] 24%|██▍       | 121/500 [1:22:26<4:13:50, 40.19s/it] 24%|██▍       | 122/500 [1:23:16<4:31:21, 43.07s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: -3.68E+05, Train scatter: [0.1389 0.0452 0.2538 0.437 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1398 0.0444 0.2542 0.4277], Lowest was [0.1398 0.0444 0.2542 0.4277]
Median for last 10 epochs: [0.2055 0.0466 0.2564 0.4361], Epochs since improvement 0
 25%|██▍       | 123/500 [1:23:48<4:09:09, 39.65s/it] 25%|██▍       | 124/500 [1:24:37<4:26:57, 42.60s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: -3.78E+05, Train scatter: [0.1876 0.0457 0.242  0.4355]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1898 0.0452 0.2442 0.4309], Lowest was [0.1398 0.0444 0.2442 0.4277]
Median for last 10 epochs: [0.1898 0.0463 0.2542 0.4311], Epochs since improvement 0
 25%|██▌       | 125/500 [1:25:09<4:05:57, 39.35s/it] 25%|██▌       | 126/500 [1:25:59<4:25:23, 42.58s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: -3.32E+05, Train scatter: [0.1834 0.0569 0.2647 0.4585]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1859 0.0562 0.2684 0.4542], Lowest was [0.1398 0.0444 0.2442 0.4277]
Median for last 10 epochs: [0.1859 0.0463 0.2542 0.4311], Epochs since improvement 2
 25%|██▌       | 127/500 [1:26:31<4:04:22, 39.31s/it] 26%|██▌       | 128/500 [1:27:21<4:24:26, 42.65s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -3.59E+05, Train scatter: [0.1425 0.045  0.2313 0.4289]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.142  0.0441 0.2316 0.423 ], Lowest was [0.1398 0.0441 0.2316 0.423 ]
Median for last 10 epochs: [0.1859 0.0452 0.2542 0.4309], Epochs since improvement 0
 26%|██▌       | 129/500 [1:27:53<4:03:23, 39.36s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -3.87E+05, Train scatter: [0.1673 0.0448 0.2353 0.4365]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1638 0.0445 0.2361 0.428 ], Lowest was [0.1398 0.0441 0.2316 0.423 ]
Median for last 10 epochs: [0.1638 0.0445 0.2442 0.428 ], Epochs since improvement 2
 26%|██▌       | 130/500 [1:28:48<4:32:36, 44.21s/it] 26%|██▌       | 131/500 [1:29:20<4:08:53, 40.47s/it] 26%|██▋       | 132/500 [1:30:10<4:25:55, 43.36s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -3.96E+05, Train scatter: [0.1591 0.0478 0.2777 0.4437]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1616 0.0474 0.278  0.4431], Lowest was [0.1398 0.0441 0.2316 0.423 ]
Median for last 10 epochs: [0.1638 0.0452 0.2442 0.4309], Epochs since improvement 4
 27%|██▋       | 133/500 [1:30:42<4:03:59, 39.89s/it] 27%|██▋       | 134/500 [1:31:32<4:21:04, 42.80s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: -4.01E+05, Train scatter: [0.266  0.049  0.2445 0.4251]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2588 0.0481 0.246  0.4158], Lowest was [0.1398 0.0441 0.2316 0.4158]
Median for last 10 epochs: [0.1638 0.0474 0.246  0.428 ], Epochs since improvement 0
 27%|██▋       | 135/500 [1:32:04<4:00:18, 39.50s/it] 27%|██▋       | 136/500 [1:32:54<4:19:11, 42.72s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: -3.97E+05, Train scatter: [0.1715 0.0431 0.2262 0.4287]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1711 0.0425 0.2273 0.4194], Lowest was [0.1398 0.0425 0.2273 0.4158]
Median for last 10 epochs: [0.1638 0.0445 0.2361 0.423 ], Epochs since improvement 0
 27%|██▋       | 137/500 [1:33:26<3:59:05, 39.52s/it] 28%|██▊       | 138/500 [1:34:16<4:17:10, 42.63s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -4.15E+05, Train scatter: [0.1391 0.0414 0.2193 0.4147]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1418 0.041  0.2209 0.4075], Lowest was [0.1398 0.041  0.2209 0.4075]
Median for last 10 epochs: [0.1638 0.0445 0.2361 0.4194], Epochs since improvement 0
 28%|██▊       | 139/500 [1:34:48<3:57:09, 39.42s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -4.17E+05, Train scatter: [0.14   0.0424 0.2229 0.4358]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1383 0.0417 0.224  0.4339], Lowest was [0.1383 0.041  0.2209 0.4075]
Median for last 10 epochs: [0.1616 0.0425 0.2273 0.4194], Epochs since improvement 0
 28%|██▊       | 140/500 [1:35:44<4:27:08, 44.52s/it] 28%|██▊       | 141/500 [1:36:16<4:03:42, 40.73s/it] 28%|██▊       | 142/500 [1:37:05<4:18:28, 43.32s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -4.18E+05, Train scatter: [0.125  0.0412 0.2185 0.4173]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1266 0.0408 0.221  0.4115], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.1418 0.0417 0.224  0.4158], Epochs since improvement 0
 29%|██▊       | 143/500 [1:37:37<3:57:07, 39.85s/it] 29%|██▉       | 144/500 [1:38:26<4:13:29, 42.72s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 1.13E+06, Train scatter: [0.9074 0.1401 0.5443 1.0017]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8922 0.1383 0.5357 0.9914], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.1418 0.0417 0.224  0.4194], Epochs since improvement 2
 29%|██▉       | 145/500 [1:38:58<3:53:13, 39.42s/it] 29%|██▉       | 146/500 [1:39:48<4:10:47, 42.51s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 6.12E+05, Train scatter: [0.9277 0.1174 0.5443 0.9824]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9123 0.1174 0.5357 0.9726], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.1418 0.0417 0.224  0.4339], Epochs since improvement 4
 29%|██▉       | 147/500 [1:40:20<3:50:58, 39.26s/it] 30%|██▉       | 148/500 [1:41:09<4:08:51, 42.42s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 5.06E+05, Train scatter: [0.772  0.1053 0.5421 0.9193]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7611 0.1039 0.5336 0.91  ], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.7611 0.1039 0.5336 0.91  ], Epochs since improvement 6
 30%|██▉       | 149/500 [1:41:41<3:49:16, 39.19s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 1.76E+05, Train scatter: [0.5546 0.0987 0.5041 0.6749]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5385 0.0978 0.4971 0.6725], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.7611 0.1039 0.5336 0.91  ], Epochs since improvement 8
 30%|███       | 150/500 [1:42:37<4:17:28, 44.14s/it] 30%|███       | 151/500 [1:43:08<3:54:52, 40.38s/it] 30%|███       | 152/500 [1:43:58<4:10:57, 43.27s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 1.24E+04, Train scatter: [0.4403 0.0846 0.4735 0.5916]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4412 0.0852 0.4674 0.5856], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.7611 0.1039 0.5336 0.91  ], Epochs since improvement 10
 31%|███       | 153/500 [1:44:30<3:50:11, 39.80s/it] 31%|███       | 154/500 [1:45:21<4:08:08, 43.03s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: -2.71E+04, Train scatter: [0.4271 0.0787 0.4681 0.5671]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4261 0.0784 0.4605 0.5632], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.5385 0.0978 0.4971 0.6725], Epochs since improvement 12
 31%|███       | 155/500 [1:45:53<3:48:18, 39.70s/it] 31%|███       | 156/500 [1:46:43<4:06:17, 42.96s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: -4.78E+04, Train scatter: [0.3549 0.0796 0.4477 0.5528]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3508 0.079  0.4408 0.5478], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.4412 0.0852 0.4674 0.5856], Epochs since improvement 14
 31%|███▏      | 157/500 [1:47:15<3:46:47, 39.67s/it] 32%|███▏      | 158/500 [1:48:05<4:02:59, 42.63s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: -6.62E+04, Train scatter: [0.4108 0.0748 0.4532 0.5426]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4089 0.0745 0.4442 0.537 ], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.4261 0.079  0.4605 0.5632], Epochs since improvement 16
 32%|███▏      | 159/500 [1:48:37<3:44:14, 39.46s/it]Epoch: 160 done with learning rate 9.05E-03, Train loss: -7.81E+04, Train scatter: [0.3968 0.075  0.3997 0.5406]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3939 0.0756 0.4008 0.5356], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.4089 0.0784 0.4442 0.5478], Epochs since improvement 18
 32%|███▏      | 160/500 [1:49:32<4:10:09, 44.15s/it] 32%|███▏      | 161/500 [1:50:04<3:48:31, 40.45s/it] 32%|███▏      | 162/500 [1:50:54<4:04:47, 43.45s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: -9.03E+04, Train scatter: [0.7364 0.0727 0.398  0.5354]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7348 0.072  0.3961 0.5302], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.4089 0.0756 0.4408 0.537 ], Epochs since improvement 20
 33%|███▎      | 163/500 [1:51:26<3:44:23, 39.95s/it] 33%|███▎      | 163/500 [1:52:16<3:52:06, 41.33s/it]
Epoch: 164 done with learning rate 8.96E-03, Train loss: -1.02E+05, Train scatter: [0.3911 0.071  0.3927 0.5284]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3851 0.0704 0.3908 0.5209], Lowest was [0.1266 0.0408 0.2209 0.4075]
Median for last 10 epochs: [0.3939 0.0745 0.4008 0.5356], Epochs since improvement 22
Exited after 164 epochs due to early stopping
6738.23 seconds spent training, 13.476 seconds per epoch. Processed 5167 trees per second
[0.3850803  0.07039257 0.3907392  0.52087784]
{'epoch_exit': 163, 'scatter_m_star': 0.3850803, 'lowest_m_star': 0.12660123, 'last20_m_star': 0.43368143, 'last10_m_star': 0.39394516, 'scatter_v_disk': 0.07039257, 'lowest_v_disk': 0.040767502, 'last20_v_disk': 0.078702025, 'last10_v_disk': 0.07447689, 'scatter_m_cold': 0.3907392, 'lowest_m_cold': 0.22094268, 'last20_m_cold': 0.4523571, 'last10_m_cold': 0.40079904, 'scatter_sfr_100': 0.52087784, 'lowest_sfr_100': 0.40748662, 'last20_sfr_100': 0.55554247, 'last10_sfr_100': 0.5356329}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_wwhvdx
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:56:40, 28.46s/it]  0%|          | 2/500 [01:12<5:13:37, 37.79s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.45E+07, Train scatter: [0.9354 0.179  0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1876 0.5357 0.9851], Lowest was [0.9198 0.1876 0.5357 0.9851]
Median for last 10 epochs: [0.9198 0.1876 0.5357 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:40<4:34:09, 33.10s/it]  1%|          | 4/500 [02:26<5:14:58, 38.10s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.47E+07, Train scatter: [0.9354 0.1725 0.5442 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.1747 0.5356 0.9851], Lowest was [0.9198 0.1747 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1747 0.5356 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:53<4:42:07, 34.20s/it]  1%|          | 6/500 [03:39<5:14:06, 38.15s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.08E+07, Train scatter: [0.9354 0.1698 0.5442 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.172  0.5356 0.9851], Lowest was [0.9198 0.172  0.5356 0.9851]
Median for last 10 epochs: [0.9199 0.172  0.5356 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:06<4:44:21, 34.61s/it]  2%|▏         | 8/500 [04:52<5:13:17, 38.21s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 9.77E+06, Train scatter: [0.9353 0.1517 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1501 0.5355 0.9848], Lowest was [0.9197 0.1501 0.5355 0.9848]
Median for last 10 epochs: [0.9198 0.161  0.5356 0.9849], Epochs since improvement 0
  2%|▏         | 9/500 [05:19<4:45:28, 34.89s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.59E+06, Train scatter: [0.9354 0.1449 0.544  0.7632]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1458 0.5354 0.7595], Lowest was [0.9197 0.1458 0.5354 0.7595]
Median for last 10 epochs: [0.9198 0.1501 0.5355 0.9848], Epochs since improvement 0
  2%|▏         | 10/500 [06:10<5:23:14, 39.58s/it]  2%|▏         | 11/500 [06:37<4:52:37, 35.90s/it]  2%|▏         | 12/500 [07:23<5:16:46, 38.95s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.93E+06, Train scatter: [0.9344 0.1273 0.5439 0.6746]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9189 0.1259 0.5353 0.6651], Lowest was [0.9189 0.1259 0.5353 0.6651]
Median for last 10 epochs: [0.9198 0.1501 0.5355 0.9848], Epochs since improvement 0
  3%|▎         | 13/500 [07:51<4:48:07, 35.50s/it]  3%|▎         | 14/500 [08:37<5:13:47, 38.74s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.74E+06, Train scatter: [0.9183 0.1194 0.5439 0.6429]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9044 0.1186 0.5353 0.635 ], Lowest was [0.9044 0.1186 0.5353 0.635 ]
Median for last 10 epochs: [0.9197 0.1458 0.5354 0.7595], Epochs since improvement 0
  3%|▎         | 15/500 [09:04<4:45:49, 35.36s/it]  3%|▎         | 16/500 [09:50<5:10:10, 38.45s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.57E+06, Train scatter: [0.8021 0.1143 0.5421 0.6105]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7962 0.1135 0.5337 0.6043], Lowest was [0.7962 0.1135 0.5337 0.6043]
Median for last 10 epochs: [0.9189 0.1259 0.5353 0.6651], Epochs since improvement 0
  3%|▎         | 17/500 [10:17<4:43:01, 35.16s/it]  4%|▎         | 18/500 [11:03<5:07:07, 38.23s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 6.20E+06, Train scatter: [0.6103 0.1055 0.5388 0.5945]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6012 0.1054 0.5305 0.5836], Lowest was [0.6012 0.1054 0.5305 0.5836]
Median for last 10 epochs: [0.9044 0.1186 0.5353 0.635 ], Epochs since improvement 0
  4%|▍         | 19/500 [11:31<4:41:19, 35.09s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.83E+06, Train scatter: [0.483  0.1006 0.5363 0.6097]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4922 0.1014 0.5281 0.6153], Lowest was [0.4922 0.1014 0.5281 0.5836]
Median for last 10 epochs: [0.7962 0.1135 0.5337 0.6153], Epochs since improvement 0
  4%|▍         | 20/500 [12:22<5:19:21, 39.92s/it]  4%|▍         | 21/500 [12:49<4:49:09, 36.22s/it]  4%|▍         | 22/500 [13:35<5:11:26, 39.09s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.56E+06, Train scatter: [0.5143 0.0978 0.5298 0.5957]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5212 0.0999 0.5216 0.5987], Lowest was [0.4922 0.0999 0.5216 0.5836]
Median for last 10 epochs: [0.6012 0.1054 0.5305 0.6043], Epochs since improvement 0
  5%|▍         | 23/500 [14:03<4:43:19, 35.64s/it]  5%|▍         | 24/500 [14:49<5:06:49, 38.68s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 5.31E+06, Train scatter: [0.4734 0.0933 0.524  0.5717]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4838 0.0953 0.5158 0.575 ], Lowest was [0.4838 0.0953 0.5158 0.575 ]
Median for last 10 epochs: [0.5212 0.1014 0.5281 0.5987], Epochs since improvement 0
  5%|▌         | 25/500 [15:16<4:39:47, 35.34s/it]  5%|▌         | 26/500 [16:02<5:03:12, 38.38s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 5.45E+06, Train scatter: [0.5148 0.1153 0.532  0.6918]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5214 0.1147 0.5241 0.6885], Lowest was [0.4838 0.0953 0.5158 0.575 ]
Median for last 10 epochs: [0.5212 0.1014 0.5241 0.5987], Epochs since improvement 2
  5%|▌         | 27/500 [16:29<4:37:03, 35.15s/it]  6%|▌         | 28/500 [17:15<5:02:11, 38.41s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.93E+06, Train scatter: [0.5145 0.104  0.5145 0.6187]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5104 0.1039 0.5077 0.6098], Lowest was [0.4838 0.0953 0.5077 0.575 ]
Median for last 10 epochs: [0.5104 0.1014 0.5216 0.6098], Epochs since improvement 0
  6%|▌         | 29/500 [17:43<4:36:27, 35.22s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.43E+06, Train scatter: [0.6247 0.1095 0.5058 0.6659]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6143 0.1112 0.4989 0.6537], Lowest was [0.4838 0.0953 0.4989 0.575 ]
Median for last 10 epochs: [0.5212 0.1039 0.5158 0.6098], Epochs since improvement 0
  6%|▌         | 30/500 [18:34<5:12:42, 39.92s/it]  6%|▌         | 31/500 [19:02<4:43:23, 36.26s/it]  6%|▋         | 32/500 [19:47<5:04:56, 39.09s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.09E+06, Train scatter: [0.4769 0.1013 0.4276 0.6434]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4652 0.1033 0.4162 0.6259], Lowest was [0.4652 0.0953 0.4162 0.575 ]
Median for last 10 epochs: [0.5104 0.1039 0.5077 0.6259], Epochs since improvement 0
  7%|▋         | 33/500 [20:15<4:37:25, 35.64s/it]  7%|▋         | 34/500 [21:01<5:00:56, 38.75s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.12E+06, Train scatter: [0.5035 0.0969 0.428  0.6291]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4989 0.1005 0.42   0.6285], Lowest was [0.4652 0.0953 0.4162 0.575 ]
Median for last 10 epochs: [0.5104 0.1039 0.4989 0.6285], Epochs since improvement 2
  7%|▋         | 35/500 [21:28<4:34:22, 35.40s/it]  7%|▋         | 36/500 [22:14<4:58:04, 38.54s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.34E+06, Train scatter: [0.5379 0.1012 0.5036 0.6861]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5445 0.1026 0.4975 0.6905], Lowest was [0.4652 0.0953 0.4162 0.575 ]
Median for last 10 epochs: [0.5104 0.1033 0.4975 0.6285], Epochs since improvement 4
  7%|▋         | 37/500 [22:42<4:32:01, 35.25s/it]  8%|▊         | 38/500 [23:28<4:56:07, 38.46s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.44E+06, Train scatter: [0.4026 0.0967 0.4402 0.6149]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.406  0.0973 0.4396 0.6136], Lowest was [0.406  0.0953 0.4162 0.575 ]
Median for last 10 epochs: [0.4989 0.1026 0.4396 0.6285], Epochs since improvement 0
  8%|▊         | 39/500 [23:56<4:30:32, 35.21s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.96E+06, Train scatter: [0.4053 0.0956 0.3838 0.62  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4102 0.0961 0.3774 0.6192], Lowest was [0.406  0.0953 0.3774 0.575 ]
Median for last 10 epochs: [0.4652 0.1005 0.42   0.6259], Epochs since improvement 0
  8%|▊         | 40/500 [24:47<5:08:31, 40.24s/it]  8%|▊         | 41/500 [25:15<4:38:46, 36.44s/it]  8%|▊         | 42/500 [26:02<5:01:53, 39.55s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.76E+06, Train scatter: [0.4863 0.1014 0.367  0.7194]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4848 0.1001 0.3675 0.7049], Lowest was [0.406  0.0953 0.3675 0.575 ]
Median for last 10 epochs: [0.4848 0.1001 0.42   0.6285], Epochs since improvement 0
  9%|▊         | 43/500 [26:29<4:33:50, 35.95s/it]  9%|▉         | 44/500 [27:16<4:56:23, 39.00s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.86E+06, Train scatter: [0.4764 0.0971 0.3705 0.6051]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4744 0.0975 0.377  0.6025], Lowest was [0.406  0.0953 0.3675 0.575 ]
Median for last 10 epochs: [0.4744 0.0975 0.3774 0.6192], Epochs since improvement 2
  9%|▉         | 45/500 [27:43<4:29:55, 35.60s/it]  9%|▉         | 46/500 [28:30<4:55:08, 39.00s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.68E+06, Train scatter: [0.3649 0.0924 0.3961 0.5964]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.372  0.0934 0.3979 0.5937], Lowest was [0.372  0.0934 0.3675 0.575 ]
Median for last 10 epochs: [0.4102 0.0973 0.3774 0.6136], Epochs since improvement 0
  9%|▉         | 47/500 [28:58<4:28:34, 35.57s/it] 10%|▉         | 48/500 [29:44<4:52:32, 38.83s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.00E+06, Train scatter: [0.3568 0.0927 0.3452 0.5725]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3628 0.0962 0.3544 0.5751], Lowest was [0.3628 0.0934 0.3544 0.575 ]
Median for last 10 epochs: [0.4102 0.0962 0.377  0.6025], Epochs since improvement 0
 10%|▉         | 49/500 [30:12<4:26:46, 35.49s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.69E+06, Train scatter: [0.3586 0.0902 0.3305 0.5686]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3714 0.093  0.3323 0.572 ], Lowest was [0.3628 0.093  0.3323 0.572 ]
Median for last 10 epochs: [0.372  0.0962 0.3675 0.5937], Epochs since improvement 0
 10%|█         | 50/500 [31:04<5:02:53, 40.39s/it] 10%|█         | 51/500 [31:31<4:33:30, 36.55s/it] 10%|█         | 52/500 [32:18<4:56:40, 39.73s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.54E+06, Train scatter: [0.321  0.0859 0.321  0.5403]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3316 0.0873 0.3259 0.5408], Lowest was [0.3316 0.0873 0.3259 0.5408]
Median for last 10 epochs: [0.3714 0.0934 0.3544 0.5751], Epochs since improvement 0
 11%|█         | 53/500 [32:46<4:28:51, 36.09s/it] 11%|█         | 54/500 [33:32<4:50:58, 39.15s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.35E+06, Train scatter: [0.3215 0.0868 0.3228 0.5497]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3335 0.0897 0.3307 0.5555], Lowest was [0.3316 0.0873 0.3259 0.5408]
Median for last 10 epochs: [0.3628 0.093  0.3323 0.572 ], Epochs since improvement 2
 11%|█         | 55/500 [34:00<4:24:45, 35.70s/it] 11%|█         | 56/500 [34:46<4:48:11, 38.95s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.23E+06, Train scatter: [0.2964 0.0827 0.3102 0.5357]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3055 0.084  0.3174 0.5322], Lowest was [0.3055 0.084  0.3174 0.5322]
Median for last 10 epochs: [0.3335 0.0897 0.3307 0.5555], Epochs since improvement 0
 11%|█▏        | 57/500 [35:14<4:22:21, 35.53s/it] 12%|█▏        | 58/500 [36:02<4:49:13, 39.26s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.17E+06, Train scatter: [0.3257 0.0843 0.3107 0.5414]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3325 0.0854 0.3162 0.5451], Lowest was [0.3055 0.084  0.3162 0.5322]
Median for last 10 epochs: [0.3325 0.0873 0.3259 0.5451], Epochs since improvement 0
 12%|█▏        | 59/500 [36:30<4:22:55, 35.77s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.27E+06, Train scatter: [0.2876 0.0816 0.2941 0.5152]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2962 0.0827 0.2987 0.5166], Lowest was [0.2962 0.0827 0.2987 0.5166]
Median for last 10 epochs: [0.3316 0.0854 0.3174 0.5408], Epochs since improvement 0
 12%|█▏        | 60/500 [37:21<4:57:38, 40.59s/it] 12%|█▏        | 61/500 [37:49<4:28:24, 36.69s/it] 12%|█▏        | 62/500 [38:36<4:50:40, 39.82s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.08E+06, Train scatter: [0.2959 0.0803 0.2887 0.5136]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3054 0.0824 0.2948 0.5143], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.3055 0.084  0.3162 0.5322], Epochs since improvement 0
 13%|█▎        | 63/500 [39:04<4:23:07, 36.13s/it] 13%|█▎        | 64/500 [39:50<4:45:38, 39.31s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 8.64E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.3055 0.084  0.3162 0.5322], Epochs since improvement 2
 13%|█▎        | 65/500 [40:18<4:19:25, 35.78s/it] 13%|█▎        | 66/500 [41:05<4:43:20, 39.17s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 8.57E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.3325 0.0854 0.3162 0.5451], Epochs since improvement 4
 13%|█▎        | 67/500 [41:33<4:17:33, 35.69s/it] 14%|█▎        | 68/500 [42:20<4:43:10, 39.33s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 8.52E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 6
 14%|█▍        | 69/500 [42:48<4:17:10, 35.80s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 8.47E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 8
 14%|█▍        | 70/500 [43:42<4:55:18, 41.21s/it] 14%|█▍        | 71/500 [44:09<4:25:15, 37.10s/it] 14%|█▍        | 72/500 [44:56<4:45:12, 39.98s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 8.43E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 10
 15%|█▍        | 73/500 [45:24<4:18:08, 36.27s/it] 15%|█▍        | 74/500 [46:10<4:38:50, 39.27s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 8.38E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 12
 15%|█▌        | 75/500 [46:37<4:12:54, 35.71s/it] 15%|█▌        | 76/500 [47:24<4:35:10, 38.94s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 8.32E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 14
 15%|█▌        | 77/500 [47:51<4:10:31, 35.53s/it] 16%|█▌        | 78/500 [48:38<4:33:07, 38.83s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 8.27E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 16
 16%|█▌        | 79/500 [49:06<4:08:56, 35.48s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 8.20E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 18
 16%|█▌        | 80/500 [49:58<4:44:19, 40.62s/it] 16%|█▌        | 81/500 [50:26<4:16:25, 36.72s/it] 16%|█▋        | 82/500 [51:12<4:35:49, 39.59s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 8.13E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 20
 17%|█▋        | 83/500 [51:40<4:10:06, 35.99s/it] 17%|█▋        | 83/500 [52:26<4:23:28, 37.91s/it]
Epoch: 84 done with learning rate 9.99E-03, Train loss: 8.04E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2962 0.0824 0.2948 0.5143]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 22
Exited after 84 epochs due to early stopping
3146.51 seconds spent training, 6.293 seconds per epoch. Processed 11066 trees per second
[0.91955584 0.16899292 0.53547376 0.9850921 ]
{'epoch_exit': 83, 'scatter_m_star': 0.91955584, 'lowest_m_star': 0.2961834, 'last20_m_star': 0.9195826, 'last10_m_star': 0.9195827, 'scatter_v_disk': 0.16899292, 'lowest_v_disk': 0.08240242, 'last20_v_disk': 0.16899593, 'last10_v_disk': 0.16899647, 'scatter_m_cold': 0.53547376, 'lowest_m_cold': 0.29476142, 'last20_m_cold': 0.53548867, 'last10_m_cold': 0.53548867, 'scatter_sfr_100': 0.9850921, 'lowest_sfr_100': 0.51428694, 'last20_sfr_100': 0.9851078, 'last10_sfr_100': 0.98511463}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_nkbwze
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:48<6:39:27, 48.03s/it]  0%|          | 2/500 [01:59<8:32:37, 61.76s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.47E+07, Train scatter: [0.9352 0.1517 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1478 0.5356 0.9851], Lowest was [0.9196 0.1478 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1478 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:46<7:36:59, 55.17s/it]  1%|          | 4/500 [03:57<8:27:41, 61.41s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.65E+07, Train scatter: [0.9343 0.1057 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9187 0.1041 0.5355 0.9848], Lowest was [0.9187 0.1041 0.5355 0.9848]
Median for last 10 epochs: [0.9187 0.1041 0.5355 0.9848], Epochs since improvement 0
  1%|          | 5/500 [04:44<7:44:36, 56.32s/it]  1%|          | 6/500 [05:55<8:24:35, 61.29s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.17E+07, Train scatter: [0.9261 0.1341 0.5441 0.991 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9114 0.131  0.5355 0.981 ], Lowest was [0.9114 0.1041 0.5355 0.981 ]
Median for last 10 epochs: [0.9114 0.1041 0.5355 0.981 ], Epochs since improvement 0
  1%|▏         | 7/500 [06:43<7:46:07, 56.73s/it]  2%|▏         | 8/500 [07:54<8:23:04, 61.35s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.99E+06, Train scatter: [0.7136 0.0998 0.544  0.6421]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6998 0.0992 0.5354 0.6345], Lowest was [0.6998 0.0992 0.5354 0.6345]
Median for last 10 epochs: [0.8056 0.1017 0.5355 0.8078], Epochs since improvement 0
  2%|▏         | 9/500 [08:41<7:46:07, 56.96s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 5.88E+06, Train scatter: [0.5515 0.0882 0.544  0.5648]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5442 0.0875 0.5354 0.559 ], Lowest was [0.5442 0.0875 0.5354 0.559 ]
Median for last 10 epochs: [0.6998 0.0992 0.5354 0.6345], Epochs since improvement 0
  2%|▏         | 10/500 [10:00<8:40:47, 63.77s/it]  2%|▏         | 11/500 [10:48<7:58:21, 58.69s/it]  2%|▏         | 12/500 [11:59<8:29:26, 62.64s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 5.10E+06, Train scatter: [0.4715 0.0807 0.544  0.5374]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.465  0.0806 0.5354 0.5314], Lowest was [0.465  0.0806 0.5354 0.5314]
Median for last 10 epochs: [0.6998 0.0992 0.5354 0.6345], Epochs since improvement 0
  3%|▎         | 13/500 [12:47<7:51:10, 58.05s/it]  3%|▎         | 14/500 [13:59<8:25:05, 62.36s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 4.67E+06, Train scatter: [0.3124 0.0789 0.544  0.5377]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3163 0.079  0.5354 0.5311], Lowest was [0.3163 0.079  0.5354 0.5311]
Median for last 10 epochs: [0.5442 0.0875 0.5354 0.559 ], Epochs since improvement 0
  3%|▎         | 15/500 [14:46<7:46:57, 57.77s/it]  3%|▎         | 16/500 [15:57<8:18:48, 61.84s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.48E+06, Train scatter: [0.2921 0.0761 0.544  0.5377]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.295  0.0754 0.5354 0.5283], Lowest was [0.295  0.0754 0.5354 0.5283]
Median for last 10 epochs: [0.465  0.0806 0.5354 0.5314], Epochs since improvement 0
  3%|▎         | 17/500 [16:45<7:42:51, 57.50s/it]  4%|▎         | 18/500 [17:57<8:17:04, 61.88s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.92E+06, Train scatter: [0.2738 0.0745 0.544  0.5193]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2795 0.0735 0.5354 0.5103], Lowest was [0.2795 0.0735 0.5354 0.5103]
Median for last 10 epochs: [0.3163 0.079  0.5354 0.5311], Epochs since improvement 0
  4%|▍         | 19/500 [18:44<7:41:25, 57.56s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.44E+06, Train scatter: [0.2459 0.077  0.5439 0.5341]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2479 0.0782 0.5354 0.5316], Lowest was [0.2479 0.0735 0.5354 0.5103]
Median for last 10 epochs: [0.295  0.0782 0.5354 0.5311], Epochs since improvement 0
  4%|▍         | 20/500 [20:03<8:31:32, 63.94s/it]  4%|▍         | 21/500 [20:50<7:50:16, 58.91s/it]  4%|▍         | 22/500 [22:03<8:21:18, 62.93s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.38E+06, Train scatter: [0.2199 0.0695 0.5439 0.5182]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2244 0.0697 0.5353 0.5134], Lowest was [0.2244 0.0697 0.5353 0.5103]
Median for last 10 epochs: [0.2795 0.0754 0.5354 0.5283], Epochs since improvement 0
  5%|▍         | 23/500 [22:50<7:43:26, 58.29s/it]  5%|▍         | 24/500 [24:02<8:14:52, 62.38s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.36E+06, Train scatter: [0.2271 0.0668 0.5439 0.521 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.231  0.0667 0.5353 0.515 ], Lowest was [0.2244 0.0667 0.5353 0.5103]
Median for last 10 epochs: [0.2479 0.0735 0.5354 0.515 ], Epochs since improvement 0
  5%|▌         | 25/500 [24:49<7:38:14, 57.88s/it]  5%|▌         | 26/500 [26:02<8:11:07, 62.17s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.33E+06, Train scatter: [0.2532 0.0686 0.5439 0.5049]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.257  0.0695 0.5353 0.4973], Lowest was [0.2244 0.0667 0.5353 0.4973]
Median for last 10 epochs: [0.2479 0.0697 0.5353 0.5134], Epochs since improvement 0
  5%|▌         | 27/500 [26:49<7:35:19, 57.76s/it]  6%|▌         | 28/500 [28:01<8:08:36, 62.11s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.32E+06, Train scatter: [0.3082 0.073  0.5438 0.5081]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3115 0.0722 0.5352 0.5019], Lowest was [0.2244 0.0667 0.5352 0.4973]
Median for last 10 epochs: [0.2479 0.0697 0.5353 0.5134], Epochs since improvement 0
  6%|▌         | 29/500 [28:49<7:32:59, 57.71s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.14E+06, Train scatter: [0.2261 0.0714 0.5439 0.5079]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2274 0.0713 0.5353 0.5012], Lowest was [0.2244 0.0667 0.5352 0.4973]
Median for last 10 epochs: [0.231  0.0697 0.5353 0.5019], Epochs since improvement 2
  6%|▌         | 30/500 [30:07<8:20:48, 63.93s/it]  6%|▌         | 31/500 [30:55<7:41:03, 58.98s/it]  6%|▋         | 32/500 [32:06<8:09:30, 62.76s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.99E+06, Train scatter: [0.4525 0.0704 0.5439 0.5251]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.442  0.0702 0.5353 0.516 ], Lowest was [0.2244 0.0667 0.5352 0.4973]
Median for last 10 epochs: [0.257  0.0702 0.5353 0.5019], Epochs since improvement 4
  7%|▋         | 33/500 [32:54<7:32:52, 58.19s/it]  7%|▋         | 34/500 [34:05<8:02:08, 62.08s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.91E+06, Train scatter: [0.3785 0.0732 0.5439 0.5139]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3756 0.0731 0.5353 0.5109], Lowest was [0.2244 0.0667 0.5352 0.4973]
Median for last 10 epochs: [0.3115 0.0713 0.5353 0.5019], Epochs since improvement 6
  7%|▋         | 35/500 [34:52<7:27:17, 57.72s/it]  7%|▋         | 36/500 [36:04<7:58:51, 61.92s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.90E+06, Train scatter: [0.233  0.0671 0.5439 0.4929]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2342 0.0665 0.5353 0.4854], Lowest was [0.2244 0.0665 0.5352 0.4854]
Median for last 10 epochs: [0.3115 0.0713 0.5353 0.5019], Epochs since improvement 0
  7%|▋         | 37/500 [36:51<7:23:54, 57.53s/it]  8%|▊         | 38/500 [38:04<7:56:44, 61.91s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.89E+06, Train scatter: [0.2617 0.0718 0.5438 0.5482]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2729 0.0717 0.5352 0.5483], Lowest was [0.2244 0.0665 0.5352 0.4854]
Median for last 10 epochs: [0.2729 0.0713 0.5353 0.5109], Epochs since improvement 0
  8%|▊         | 39/500 [38:51<7:22:45, 57.63s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.89E+06, Train scatter: [0.2851 0.0651 0.5438 0.4937]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2877 0.0648 0.5352 0.4881], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.2877 0.0702 0.5353 0.5109], Epochs since improvement 0
  8%|▊         | 40/500 [40:09<8:08:14, 63.68s/it]  8%|▊         | 41/500 [40:57<7:30:05, 58.84s/it]  8%|▊         | 42/500 [42:07<7:55:58, 62.35s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 8.35E+07, Train scatter: [0.9347 0.1721 0.5441 0.997 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9192 0.1683 0.5355 0.9867], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.2877 0.0717 0.5353 0.5109], Epochs since improvement 2
  9%|▊         | 43/500 [42:55<7:20:42, 57.86s/it]  9%|▉         | 44/500 [44:07<7:53:04, 62.25s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.82E+06, Train scatter: [0.9336 0.1525 0.5441 0.9965]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9181 0.1495 0.5355 0.9862], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.2877 0.0717 0.5353 0.5483], Epochs since improvement 4
  9%|▉         | 45/500 [44:54<7:18:21, 57.81s/it]  9%|▉         | 46/500 [46:06<7:48:57, 61.98s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.66E+06, Train scatter: [0.9334 0.1318 0.5441 0.9963]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9179 0.1298 0.5355 0.9859], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.9179 0.1298 0.5355 0.9859], Epochs since improvement 6
  9%|▉         | 47/500 [46:53<7:14:26, 57.54s/it] 10%|▉         | 48/500 [48:04<7:43:49, 61.57s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 4.54E+06, Train scatter: [0.9332 0.1211 0.5441 0.9961]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9176 0.1196 0.5355 0.9858], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.9179 0.1298 0.5355 0.9859], Epochs since improvement 8
 10%|▉         | 49/500 [48:52<7:11:14, 57.37s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 4.43E+06, Train scatter: [0.9328 0.1241 0.5441 0.996 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9173 0.1226 0.5355 0.9856], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.9179 0.1298 0.5355 0.9859], Epochs since improvement 10
 10%|█         | 50/500 [50:10<7:55:49, 63.44s/it] 10%|█         | 51/500 [50:57<7:19:04, 58.67s/it] 10%|█         | 52/500 [52:09<7:48:14, 62.71s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 4.33E+06, Train scatter: [0.9322 0.1212 0.5441 0.9958]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9167 0.1199 0.5355 0.9854], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.9176 0.1226 0.5355 0.9858], Epochs since improvement 12
 11%|█         | 53/500 [52:56<7:12:32, 58.06s/it] 11%|█         | 54/500 [54:07<7:40:15, 61.92s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 4.19E+06, Train scatter: [0.9313 0.1188 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9157 0.1175 0.5355 0.985 ], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.9173 0.1199 0.5355 0.9856], Epochs since improvement 14
 11%|█         | 55/500 [54:55<7:07:15, 57.61s/it] 11%|█         | 56/500 [56:07<7:37:54, 61.88s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.03E+06, Train scatter: [0.9267 0.1195 0.5441 0.9948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9111 0.1182 0.5355 0.9844], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.9167 0.1196 0.5355 0.9854], Epochs since improvement 16
 11%|█▏        | 57/500 [56:54<7:04:49, 57.54s/it] 12%|█▏        | 58/500 [58:06<7:36:05, 61.91s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.88E+06, Train scatter: [0.9068 0.1125 0.544  0.9938]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8913 0.1126 0.5354 0.9834], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.9157 0.1182 0.5355 0.985 ], Epochs since improvement 18
 12%|█▏        | 59/500 [58:54<7:03:09, 57.57s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 4.11E+06, Train scatter: [0.9323 0.1636 0.544  0.9937]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9169 0.1601 0.5355 0.9832], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.9157 0.1182 0.5355 0.9844], Epochs since improvement 20
 12%|█▏        | 60/500 [1:00:12<7:48:17, 63.86s/it] 12%|█▏        | 61/500 [1:01:00<7:11:18, 58.95s/it] 12%|█▏        | 61/500 [1:02:11<7:27:38, 61.18s/it]
Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.68E+06, Train scatter: [0.9092 0.1252 0.544  0.9902]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8942 0.1249 0.5354 0.9798], Lowest was [0.2244 0.0648 0.5352 0.4854]
Median for last 10 epochs: [0.9111 0.1182 0.5355 0.9834], Epochs since improvement 22
Exited after 62 epochs due to early stopping
3731.99 seconds spent training, 7.464 seconds per epoch. Processed 9330 trees per second
[0.8941432  0.12490573 0.5353932  0.9797233 ]
{'epoch_exit': 61, 'scatter_m_star': 0.8941432, 'lowest_m_star': 0.22435814, 'last20_m_star': 0.9168008, 'last10_m_star': 0.91113096, 'scatter_v_disk': 0.12490573, 'lowest_v_disk': 0.06483215, 'last20_v_disk': 0.12125019, 'last10_v_disk': 0.11816376, 'scatter_m_cold': 0.5353932, 'lowest_m_cold': 0.5351726, 'last20_m_cold': 0.535468, 'last10_m_cold': 0.5354512, 'scatter_sfr_100': 0.9797233, 'lowest_sfr_100': 0.48536906, 'last20_sfr_100': 0.9852097, 'last10_sfr_100': 0.98343253}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_evurxj
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:41<5:43:41, 41.32s/it]  0%|          | 2/500 [01:43<7:26:58, 53.85s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.08E+07, Train scatter: [0.9352 0.1715 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1684 0.5355 0.9851], Lowest was [0.9196 0.1684 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1684 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:24<6:36:05, 47.82s/it]  1%|          | 4/500 [03:28<7:27:01, 54.08s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.32E+07, Train scatter: [0.9352 0.1613 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1579 0.5355 0.9851], Lowest was [0.9196 0.1579 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1579 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:08<6:46:06, 49.22s/it]  1%|          | 6/500 [05:11<7:24:04, 53.94s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.86E+07, Train scatter: [0.9351 0.1344 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1314 0.5356 0.9851], Lowest was [0.9196 0.1314 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1314 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [05:52<6:47:36, 49.61s/it]  2%|▏         | 8/500 [06:56<7:24:54, 54.26s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.47E+07, Train scatter: [0.9334 0.1152 0.5441 0.9839]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9178 0.1142 0.5355 0.9736], Lowest was [0.9178 0.1142 0.5355 0.9736]
Median for last 10 epochs: [0.9187 0.1228 0.5355 0.9793], Epochs since improvement 0
  2%|▏         | 9/500 [07:37<6:49:20, 50.02s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 1.13E+07, Train scatter: [0.7601 0.102  0.5441 0.6452]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7524 0.103  0.5355 0.641 ], Lowest was [0.7524 0.103  0.5355 0.641 ]
Median for last 10 epochs: [0.9178 0.1142 0.5355 0.9736], Epochs since improvement 0
  2%|▏         | 10/500 [08:48<7:40:48, 56.43s/it]  2%|▏         | 11/500 [09:29<7:00:43, 51.62s/it]  2%|▏         | 12/500 [10:32<7:29:17, 55.24s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.18E+06, Train scatter: [0.6651 0.0983 0.544  0.6034]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6587 0.0975 0.5354 0.6001], Lowest was [0.6587 0.0975 0.5354 0.6001]
Median for last 10 epochs: [0.9178 0.1142 0.5355 0.9736], Epochs since improvement 0
  3%|▎         | 13/500 [11:13<6:52:53, 50.87s/it]  3%|▎         | 14/500 [12:18<7:27:31, 55.25s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.01E+06, Train scatter: [0.5556 0.0922 0.544  0.5777]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5499 0.0924 0.5354 0.5773], Lowest was [0.5499 0.0924 0.5354 0.5773]
Median for last 10 epochs: [0.7524 0.103  0.5355 0.641 ], Epochs since improvement 0
  3%|▎         | 15/500 [12:59<6:51:24, 50.90s/it]  3%|▎         | 16/500 [14:03<7:23:14, 54.95s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.99E+06, Train scatter: [0.5005 0.0882 0.544  0.5648]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4925 0.0881 0.5354 0.5613], Lowest was [0.4925 0.0881 0.5354 0.5613]
Median for last 10 epochs: [0.6587 0.0975 0.5354 0.6001], Epochs since improvement 0
  3%|▎         | 17/500 [14:44<6:48:02, 50.69s/it]  4%|▎         | 18/500 [15:47<7:17:18, 54.44s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.86E+06, Train scatter: [0.4846 0.0915 0.544  0.5624]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4766 0.0907 0.5354 0.5593], Lowest was [0.4766 0.0881 0.5354 0.5593]
Median for last 10 epochs: [0.5499 0.0924 0.5354 0.5773], Epochs since improvement 0
  4%|▍         | 19/500 [16:28<6:44:04, 50.41s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 4.27E+06, Train scatter: [0.325  0.085  0.5439 0.5627]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.334  0.0852 0.5354 0.557 ], Lowest was [0.334  0.0852 0.5354 0.557 ]
Median for last 10 epochs: [0.4925 0.0907 0.5354 0.5613], Epochs since improvement 0
  4%|▍         | 20/500 [17:39<7:32:16, 56.53s/it]  4%|▍         | 21/500 [18:20<6:53:54, 51.85s/it]  4%|▍         | 22/500 [19:24<7:21:17, 55.39s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.08E+06, Train scatter: [0.3839 0.0831 0.5439 0.5505]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3859 0.0832 0.5354 0.5519], Lowest was [0.334  0.0832 0.5354 0.5519]
Median for last 10 epochs: [0.4766 0.0881 0.5354 0.5593], Epochs since improvement 0
  5%|▍         | 23/500 [20:04<6:45:17, 50.98s/it]  5%|▍         | 24/500 [21:08<7:14:56, 54.82s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.63E+06, Train scatter: [0.4108 0.0899 0.5439 0.5401]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4085 0.0887 0.5353 0.5397], Lowest was [0.334  0.0832 0.5353 0.5397]
Median for last 10 epochs: [0.4085 0.0881 0.5354 0.557 ], Epochs since improvement 0
  5%|▌         | 25/500 [21:49<6:40:23, 50.58s/it]  5%|▌         | 26/500 [22:53<7:10:24, 54.48s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.01E+06, Train scatter: [0.4696 0.0833 0.5438 0.6155]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4699 0.0831 0.5353 0.6188], Lowest was [0.334  0.0831 0.5353 0.5397]
Median for last 10 epochs: [0.4085 0.0852 0.5354 0.557 ], Epochs since improvement 0
  5%|▌         | 27/500 [23:33<6:36:33, 50.30s/it]  6%|▌         | 28/500 [24:37<7:07:44, 54.37s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.96E+06, Train scatter: [0.2529 0.079  0.5438 0.5304]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2641 0.0793 0.5353 0.5287], Lowest was [0.2641 0.0793 0.5353 0.5287]
Median for last 10 epochs: [0.3859 0.0832 0.5353 0.5519], Epochs since improvement 0
  6%|▌         | 29/500 [25:18<6:34:42, 50.28s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.84E+06, Train scatter: [0.2312 0.0782 0.5438 0.52  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2404 0.0787 0.5353 0.5198], Lowest was [0.2404 0.0787 0.5353 0.5198]
Median for last 10 epochs: [0.3859 0.0831 0.5353 0.5397], Epochs since improvement 0
  6%|▌         | 30/500 [26:27<7:18:40, 56.00s/it]  6%|▌         | 31/500 [27:08<6:41:53, 51.42s/it]  6%|▋         | 32/500 [28:11<7:08:53, 54.99s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.64E+06, Train scatter: [0.2343 0.0772 0.5439 0.5182]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2418 0.0767 0.5353 0.519 ], Lowest was [0.2404 0.0767 0.5353 0.519 ]
Median for last 10 epochs: [0.2641 0.0793 0.5353 0.5287], Epochs since improvement 0
  7%|▋         | 33/500 [28:52<6:35:16, 50.78s/it]  7%|▋         | 34/500 [29:56<7:04:11, 54.62s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.60E+06, Train scatter: [0.2229 0.075  0.5439 0.5121]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2333 0.075  0.5353 0.5131], Lowest was [0.2333 0.075  0.5353 0.5131]
Median for last 10 epochs: [0.2418 0.0787 0.5353 0.5198], Epochs since improvement 0
  7%|▋         | 35/500 [30:37<6:31:25, 50.51s/it]  7%|▋         | 36/500 [31:40<7:00:51, 54.42s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.57E+06, Train scatter: [0.2764 0.0773 0.5439 0.5137]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.362  0.077  0.5353 0.5156], Lowest was [0.2333 0.075  0.5353 0.5131]
Median for last 10 epochs: [0.2418 0.077  0.5353 0.519 ], Epochs since improvement 2
  7%|▋         | 37/500 [32:21<6:28:44, 50.38s/it]  8%|▊         | 38/500 [33:25<6:59:13, 54.45s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.55E+06, Train scatter: [0.3465 0.0841 0.5439 0.5693]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3412 0.0825 0.5353 0.5675], Lowest was [0.2333 0.075  0.5353 0.5131]
Median for last 10 epochs: [0.2418 0.077  0.5353 0.519 ], Epochs since improvement 4
  8%|▊         | 39/500 [34:06<6:26:52, 50.35s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.52E+06, Train scatter: [0.2354 0.0872 0.5438 0.5434]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2364 0.0856 0.5353 0.5348], Lowest was [0.2333 0.075  0.5353 0.5131]
Median for last 10 epochs: [0.2418 0.077  0.5353 0.519 ], Epochs since improvement 6
  8%|▊         | 40/500 [35:15<7:09:42, 56.05s/it]  8%|▊         | 41/500 [35:56<6:33:09, 51.39s/it]  8%|▊         | 42/500 [37:00<7:01:31, 55.22s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.46E+06, Train scatter: [0.2421 0.0752 0.5439 0.5234]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2479 0.0754 0.5353 0.5233], Lowest was [0.2333 0.075  0.5353 0.5131]
Median for last 10 epochs: [0.2479 0.077  0.5353 0.5233], Epochs since improvement 8
  9%|▊         | 43/500 [37:40<6:27:11, 50.83s/it]  9%|▉         | 44/500 [38:44<6:54:53, 54.59s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.45E+06, Train scatter: [0.3591 0.0912 0.5438 0.5954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3569 0.0894 0.5353 0.59  ], Lowest was [0.2333 0.075  0.5353 0.5131]
Median for last 10 epochs: [0.3412 0.0825 0.5353 0.5348], Epochs since improvement 10
  9%|▉         | 45/500 [39:24<6:22:30, 50.44s/it]  9%|▉         | 46/500 [40:28<6:50:54, 54.30s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.69E+06, Train scatter: [0.393  0.0825 0.5438 0.8597]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3886 0.0818 0.5352 0.8496], Lowest was [0.2333 0.075  0.5352 0.5131]
Median for last 10 epochs: [0.3412 0.0825 0.5353 0.5675], Epochs since improvement 0
  9%|▉         | 47/500 [41:08<6:19:07, 50.21s/it] 10%|▉         | 48/500 [42:12<6:48:47, 54.27s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.62E+06, Train scatter: [0.2394 0.0788 0.5438 0.9185]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2463 0.0783 0.5352 0.9097], Lowest was [0.2333 0.075  0.5352 0.5131]
Median for last 10 epochs: [0.2479 0.0818 0.5353 0.59  ], Epochs since improvement 0
 10%|▉         | 49/500 [42:53<6:17:51, 50.27s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.54E+06, Train scatter: [0.2595 0.0829 0.5437 0.899 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.328  0.0808 0.5351 0.8902], Lowest was [0.2333 0.075  0.5351 0.5131]
Median for last 10 epochs: [0.328  0.0808 0.5352 0.8496], Epochs since improvement 0
 10%|█         | 50/500 [44:03<7:01:28, 56.20s/it] 10%|█         | 51/500 [44:44<6:25:45, 51.55s/it] 10%|█         | 52/500 [45:48<6:53:35, 55.39s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.45E+06, Train scatter: [0.4336 0.091  0.5438 0.591 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4377 0.0891 0.5353 0.5812], Lowest was [0.2333 0.075  0.5351 0.5131]
Median for last 10 epochs: [0.3569 0.0818 0.5352 0.8496], Epochs since improvement 2
 11%|█         | 53/500 [46:30<6:21:09, 51.16s/it] 11%|█         | 54/500 [47:33<6:48:45, 54.99s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.29E+06, Train scatter: [0.4613 0.0774 0.5436 0.521 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4591 0.077  0.535  0.5177], Lowest was [0.2333 0.075  0.535  0.5131]
Median for last 10 epochs: [0.3886 0.0808 0.5352 0.8496], Epochs since improvement 0
 11%|█         | 55/500 [48:14<6:16:24, 50.75s/it] 11%|█         | 56/500 [49:19<6:45:53, 54.85s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.22E+06, Train scatter: [0.4091 0.0816 0.5436 0.5384]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.403  0.0813 0.535  0.539 ], Lowest was [0.2333 0.075  0.535  0.5131]
Median for last 10 epochs: [0.403  0.0808 0.5351 0.5812], Epochs since improvement 0
 11%|█▏        | 57/500 [49:59<6:13:43, 50.62s/it] 12%|█▏        | 58/500 [51:04<6:42:49, 54.68s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.18E+06, Train scatter: [0.3913 0.0814 0.5434 0.533 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3864 0.0814 0.5349 0.5329], Lowest was [0.2333 0.075  0.5349 0.5131]
Median for last 10 epochs: [0.403  0.0813 0.535  0.539 ], Epochs since improvement 0
 12%|█▏        | 59/500 [51:44<6:10:35, 50.42s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.16E+06, Train scatter: [0.3315 0.0763 0.5434 0.5547]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.351  0.0736 0.5348 0.5449], Lowest was [0.2333 0.0736 0.5348 0.5131]
Median for last 10 epochs: [0.403  0.0813 0.535  0.539 ], Epochs since improvement 0
 12%|█▏        | 60/500 [52:54<6:52:33, 56.26s/it] 12%|█▏        | 61/500 [53:35<6:17:12, 51.55s/it] 12%|█▏        | 62/500 [54:38<6:42:56, 55.20s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.17E+06, Train scatter: [0.4051 0.0743 0.5435 0.5083]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.395  0.0735 0.5349 0.5061], Lowest was [0.2333 0.0735 0.5348 0.5061]
Median for last 10 epochs: [0.395  0.077  0.5349 0.5329], Epochs since improvement 0
 13%|█▎        | 63/500 [55:19<6:10:08, 50.82s/it] 13%|█▎        | 64/500 [56:23<6:37:41, 54.73s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.19E+06, Train scatter: [0.4172 0.0736 0.5434 0.5025]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4074 0.073  0.5349 0.4993], Lowest was [0.2333 0.073  0.5348 0.4993]
Median for last 10 epochs: [0.395  0.0736 0.5349 0.5329], Epochs since improvement 0
 13%|█▎        | 65/500 [57:03<6:05:54, 50.47s/it] 13%|█▎        | 66/500 [58:07<6:34:12, 54.50s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.21E+06, Train scatter: [0.5872 0.0993 0.5438 0.785 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5734 0.0969 0.5352 0.7793], Lowest was [0.2333 0.073  0.5348 0.4993]
Median for last 10 epochs: [0.395  0.0736 0.5349 0.5329], Epochs since improvement 2
 13%|█▎        | 67/500 [58:48<6:03:20, 50.35s/it] 14%|█▎        | 68/500 [59:53<6:34:23, 54.78s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.20E+06, Train scatter: [0.455  0.0997 0.5437 0.5689]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4517 0.0982 0.5352 0.5599], Lowest was [0.2333 0.073  0.5348 0.4993]
Median for last 10 epochs: [0.4074 0.0736 0.5349 0.5449], Epochs since improvement 4
 14%|█▍        | 69/500 [1:00:34<6:03:08, 50.55s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.15E+06, Train scatter: [0.3838 0.0838 0.5437 0.5971]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.383  0.0831 0.5351 0.6   ], Lowest was [0.2333 0.073  0.5348 0.4993]
Median for last 10 epochs: [0.4074 0.0831 0.5351 0.5599], Epochs since improvement 6
 14%|█▍        | 70/500 [1:01:44<6:45:32, 56.59s/it] 14%|█▍        | 71/500 [1:02:25<6:10:44, 51.85s/it] 14%|█▍        | 72/500 [1:03:28<6:33:31, 55.17s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.14E+06, Train scatter: [0.3959 0.0785 0.5435 0.5694]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3927 0.0782 0.535  0.5728], Lowest was [0.2333 0.073  0.5348 0.4993]
Median for last 10 epochs: [0.4074 0.0831 0.5351 0.5728], Epochs since improvement 8
 15%|█▍        | 73/500 [1:04:09<6:02:17, 50.91s/it] 15%|█▍        | 74/500 [1:05:13<6:28:51, 54.77s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.15E+06, Train scatter: [0.4694 0.074  0.5433 0.5271]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4612 0.0737 0.5348 0.522 ], Lowest was [0.2333 0.073  0.5348 0.4993]
Median for last 10 epochs: [0.4517 0.0831 0.5351 0.5728], Epochs since improvement 0
 15%|█▌        | 75/500 [1:05:54<5:58:12, 50.57s/it] 15%|█▌        | 76/500 [1:06:57<6:25:46, 54.59s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.12E+06, Train scatter: [0.4575 0.0757 0.5433 0.5261]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4498 0.076  0.5348 0.5245], Lowest was [0.2333 0.073  0.5348 0.4993]
Median for last 10 epochs: [0.4498 0.0782 0.535  0.5599], Epochs since improvement 0
 15%|█▌        | 77/500 [1:07:38<5:55:14, 50.39s/it] 16%|█▌        | 78/500 [1:08:41<6:20:43, 54.13s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.12E+06, Train scatter: [0.2655 0.073  0.5433 0.5166]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2706 0.0726 0.5347 0.5126], Lowest was [0.2333 0.0726 0.5347 0.4993]
Median for last 10 epochs: [0.3927 0.076  0.5348 0.5245], Epochs since improvement 0
 16%|█▌        | 79/500 [1:09:21<5:51:12, 50.05s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 3.11E+06, Train scatter: [0.2513 0.0686 0.5431 0.5221]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2581 0.0686 0.5346 0.5166], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.3927 0.0737 0.5348 0.522 ], Epochs since improvement 0
 16%|█▌        | 80/500 [1:10:33<6:36:09, 56.59s/it] 16%|█▌        | 81/500 [1:11:14<6:01:36, 51.78s/it] 16%|█▋        | 82/500 [1:12:18<6:25:41, 55.36s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 3.14E+06, Train scatter: [0.8684 0.1725 0.5436 0.887 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8572 0.1687 0.5351 0.8817], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.4498 0.0737 0.5348 0.522 ], Epochs since improvement 2
 17%|█▋        | 83/500 [1:12:58<5:53:59, 50.93s/it] 17%|█▋        | 84/500 [1:14:01<6:18:49, 54.64s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 8.12E+06, Train scatter: [0.9344 0.1736 0.544  0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9188 0.1698 0.5355 0.9847], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.4498 0.076  0.5348 0.5245], Epochs since improvement 4
 17%|█▋        | 85/500 [1:14:42<5:48:26, 50.38s/it] 17%|█▋        | 86/500 [1:15:45<6:14:50, 54.32s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 4.75E+06, Train scatter: [0.9352 0.1724 0.5441 0.9958]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1686 0.5355 0.9854], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.8572 0.1686 0.5351 0.8817], Epochs since improvement 6
 17%|█▋        | 87/500 [1:16:26<5:45:29, 50.19s/it] 18%|█▊        | 88/500 [1:17:29<6:11:51, 54.15s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 4.49E+06, Train scatter: [0.9348 0.1689 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9191 0.1652 0.5355 0.985 ], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.9188 0.1686 0.5355 0.9847], Epochs since improvement 8
 18%|█▊        | 89/500 [1:18:10<5:43:33, 50.15s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 4.42E+06, Train scatter: [0.9355 0.1537 0.5441 0.9969]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1506 0.5355 0.9864], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.9191 0.1686 0.5355 0.985 ], Epochs since improvement 10
 18%|█▊        | 90/500 [1:19:20<6:23:52, 56.18s/it] 18%|█▊        | 91/500 [1:20:01<5:51:35, 51.58s/it] 18%|█▊        | 92/500 [1:21:06<6:16:57, 55.44s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 4.31E+06, Train scatter: [0.9285 0.1259 0.5441 0.9958]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9129 0.1243 0.5355 0.9853], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.9191 0.1652 0.5355 0.9853], Epochs since improvement 12
 19%|█▊        | 93/500 [1:21:46<5:46:07, 51.03s/it] 19%|█▉        | 94/500 [1:22:50<6:11:02, 54.83s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 4.19E+06, Train scatter: [0.7518 0.1191 0.5441 0.9942]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7431 0.1181 0.5355 0.9838], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.9191 0.1506 0.5355 0.9853], Epochs since improvement 14
 19%|█▉        | 95/500 [1:23:31<5:41:12, 50.55s/it] 19%|█▉        | 96/500 [1:24:34<6:06:35, 54.45s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 4.15E+06, Train scatter: [0.9326 0.1183 0.5441 0.9909]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9171 0.1173 0.5355 0.9806], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.9171 0.1243 0.5355 0.985 ], Epochs since improvement 16
 19%|█▉        | 97/500 [1:25:15<5:38:00, 50.32s/it] 20%|█▉        | 98/500 [1:26:18<6:03:17, 54.22s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 4.11E+06, Train scatter: [0.9116 0.1177 0.5441 0.9845]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8967 0.1166 0.5355 0.9744], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.9129 0.1181 0.5355 0.9838], Epochs since improvement 18
 20%|█▉        | 99/500 [1:26:59<5:35:07, 50.14s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 4.08E+06, Train scatter: [0.8195 0.1119 0.5441 0.9665]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8078 0.111  0.5355 0.9571], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.8967 0.1173 0.5355 0.9806], Epochs since improvement 20
 20%|██        | 100/500 [1:28:09<6:13:11, 55.98s/it] 20%|██        | 101/500 [1:28:49<5:41:40, 51.38s/it] 20%|██        | 101/500 [1:29:52<5:55:04, 53.40s/it]
Epoch: 102 done with learning rate 9.90E-03, Train loss: 3.95E+06, Train scatter: [0.9174 0.1074 0.5441 0.8974]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9025 0.1067 0.5355 0.8914], Lowest was [0.2333 0.0686 0.5346 0.4993]
Median for last 10 epochs: [0.8967 0.1166 0.5355 0.9744], Epochs since improvement 22
Exited after 102 epochs due to early stopping
5393.00 seconds spent training, 10.786 seconds per epoch. Processed 6456 trees per second
[0.9024243  0.10673918 0.5354722  0.89137775]
{'epoch_exit': 101, 'scatter_m_star': 0.9024243, 'lowest_m_star': 0.23333389, 'last20_m_star': 0.9149734, 'last10_m_star': 0.8967242, 'scatter_v_disk': 0.10673918, 'lowest_v_disk': 0.06862043, 'last20_v_disk': 0.12119965, 'last10_v_disk': 0.116582796, 'scatter_m_cold': 0.5354722, 'lowest_m_cold': 0.5345533, 'last20_m_cold': 0.53550243, 'last10_m_cold': 0.5355037, 'scatter_sfr_100': 0.89137775, 'lowest_sfr_100': 0.49933282, 'last20_sfr_100': 0.9842564, 'last10_sfr_100': 0.974443}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_isfepd
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:02<8:36:44, 62.13s/it]  0%|          | 2/500 [02:32<10:53:04, 78.68s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.33E+07, Train scatter: [0.9351 0.1291 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.125  0.5355 0.9851], Lowest was [0.9195 0.125  0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.125  0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:34<9:47:59, 70.99s/it]   1%|          | 4/500 [05:05<10:53:57, 79.11s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 9.06E+07, Train scatter: [0.9335 0.1806 0.5438 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9181 0.1778 0.5352 0.985 ], Lowest was [0.9181 0.125  0.5352 0.985 ]
Median for last 10 epochs: [0.9181 0.1514 0.5352 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [06:07<10:00:51, 72.83s/it]  1%|          | 6/500 [07:39<10:53:03, 79.32s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.14E+07, Train scatter: [0.935  0.1386 0.5438 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9194 0.1335 0.5352 0.985 ], Lowest was [0.9181 0.125  0.5352 0.985 ]
Median for last 10 epochs: [0.9181 0.1335 0.5352 0.985 ], Epochs since improvement 2
  1%|▏         | 7/500 [08:41<10:04:42, 73.60s/it]  2%|▏         | 8/500 [10:11<10:47:05, 78.91s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.42E+07, Train scatter: [0.8813 0.1106 0.5365 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8618 0.1104 0.5279 0.985 ], Lowest was [0.8618 0.1104 0.5279 0.985 ]
Median for last 10 epochs: [0.8899 0.1219 0.5315 0.985 ], Epochs since improvement 0
  2%|▏         | 9/500 [11:13<10:02:07, 73.58s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.89E+07, Train scatter: [0.5716 0.0984 0.4284 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5654 0.0982 0.426  0.985 ], Lowest was [0.5654 0.0982 0.426  0.985 ]
Median for last 10 epochs: [0.8618 0.1104 0.5279 0.985 ], Epochs since improvement 0
  2%|▏         | 10/500 [12:51<11:02:29, 81.12s/it]  2%|▏         | 11/500 [13:53<10:12:57, 75.21s/it]  2%|▏         | 12/500 [15:24<10:50:30, 79.98s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.75E+07, Train scatter: [0.5142 0.0922 0.3943 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.514  0.0929 0.3975 0.985 ], Lowest was [0.514  0.0929 0.3975 0.985 ]
Median for last 10 epochs: [0.8618 0.1104 0.5279 0.985 ], Epochs since improvement 0
  3%|▎         | 13/500 [16:26<10:05:07, 74.55s/it]  3%|▎         | 14/500 [17:56<10:43:38, 79.46s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.13E+07, Train scatter: [0.4019 0.0862 0.3629 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4149 0.0877 0.3704 0.9849], Lowest was [0.4149 0.0877 0.3704 0.9849]
Median for last 10 epochs: [0.5654 0.0982 0.426  0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [18:58<9:59:52, 74.21s/it]   3%|▎         | 16/500 [20:29<10:38:49, 79.19s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.95E+07, Train scatter: [0.4026 0.0815 0.3492 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4113 0.0823 0.3533 0.9849], Lowest was [0.4113 0.0823 0.3533 0.9849]
Median for last 10 epochs: [0.514  0.0929 0.3975 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [21:31<9:56:00, 74.04s/it]   4%|▎         | 18/500 [23:03<10:38:17, 79.45s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.84E+07, Train scatter: [0.338  0.0765 0.3221 0.9949]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3419 0.0769 0.3246 0.9847], Lowest was [0.3419 0.0769 0.3246 0.9847]
Median for last 10 epochs: [0.4149 0.0877 0.3704 0.9849], Epochs since improvement 0
  4%|▍         | 19/500 [24:05<9:54:46, 74.19s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.99E+06, Train scatter: [0.3371 0.0794 0.3438 0.7285]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3416 0.0797 0.3475 0.7349], Lowest was [0.3416 0.0769 0.3246 0.7349]
Median for last 10 epochs: [0.4113 0.0823 0.3533 0.9849], Epochs since improvement 0
  4%|▍         | 20/500 [25:44<10:51:52, 81.48s/it]  4%|▍         | 21/500 [26:46<10:04:20, 75.70s/it]  4%|▍         | 22/500 [28:17<10:40:26, 80.39s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.42E+06, Train scatter: [0.2711 0.075  0.3363 0.5489]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2748 0.0739 0.3431 0.5525], Lowest was [0.2748 0.0739 0.3246 0.5525]
Median for last 10 epochs: [0.3419 0.0797 0.3475 0.9847], Epochs since improvement 0
  5%|▍         | 23/500 [29:19<9:55:30, 74.91s/it]   5%|▍         | 24/500 [30:50<10:32:09, 79.68s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.88E+06, Train scatter: [0.2591 0.0744 0.3135 0.5155]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.265  0.0741 0.3165 0.5146], Lowest was [0.265  0.0739 0.3165 0.5146]
Median for last 10 epochs: [0.3416 0.0769 0.3431 0.7349], Epochs since improvement 0
  5%|▌         | 25/500 [31:52<9:48:06, 74.29s/it]   5%|▌         | 26/500 [33:23<10:27:38, 79.45s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.40E+06, Train scatter: [0.2825 0.0811 0.3401 0.5252]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.283  0.0806 0.3437 0.5258], Lowest was [0.265  0.0739 0.3165 0.5146]
Median for last 10 epochs: [0.283  0.0769 0.3431 0.5525], Epochs since improvement 2
  5%|▌         | 27/500 [34:26<9:45:20, 74.25s/it]   6%|▌         | 28/500 [35:57<10:24:29, 79.39s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.32E+06, Train scatter: [0.2533 0.0705 0.3102 0.4887]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2579 0.0701 0.3167 0.4859], Lowest was [0.2579 0.0701 0.3165 0.4859]
Median for last 10 epochs: [0.2748 0.0741 0.3431 0.5258], Epochs since improvement 0
  6%|▌         | 29/500 [36:59<9:42:49, 74.25s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.21E+06, Train scatter: [0.2868 0.0729 0.3215 0.5002]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2916 0.0721 0.3222 0.4968], Lowest was [0.2579 0.0701 0.3165 0.4859]
Median for last 10 epochs: [0.2748 0.0739 0.3222 0.5146], Epochs since improvement 2
  6%|▌         | 30/500 [38:37<10:37:50, 81.43s/it]  6%|▌         | 31/500 [39:39<9:50:41, 75.57s/it]   6%|▋         | 32/500 [41:11<10:27:09, 80.41s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.23E+06, Train scatter: [0.2478 0.0723 0.3045 0.4894]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2556 0.0722 0.3094 0.4905], Lowest was [0.2556 0.0701 0.3094 0.4859]
Median for last 10 epochs: [0.265  0.0722 0.3167 0.4968], Epochs since improvement 0
  7%|▋         | 33/500 [42:13<9:42:53, 74.89s/it]   7%|▋         | 34/500 [43:44<10:19:22, 79.75s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.92E+06, Train scatter: [0.2527 0.07   0.2981 0.514 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2565 0.0702 0.3034 0.5141], Lowest was [0.2556 0.0701 0.3034 0.4859]
Median for last 10 epochs: [0.2579 0.0721 0.3167 0.4968], Epochs since improvement 0
  7%|▋         | 35/500 [44:46<9:36:44, 74.42s/it]   7%|▋         | 36/500 [46:17<10:14:51, 79.51s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.80E+06, Train scatter: [0.25   0.0684 0.3076 0.4791]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2537 0.0684 0.3155 0.4806], Lowest was [0.2537 0.0684 0.3034 0.4806]
Median for last 10 epochs: [0.2565 0.0702 0.3155 0.4905], Epochs since improvement 0
  7%|▋         | 37/500 [47:19<9:32:56, 74.25s/it]   8%|▊         | 38/500 [48:51<10:12:03, 79.49s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.89E+06, Train scatter: [0.2553 0.0688 0.3124 0.4799]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2707 0.0683 0.3188 0.4795], Lowest was [0.2537 0.0683 0.3034 0.4795]
Median for last 10 epochs: [0.2565 0.0702 0.3155 0.4905], Epochs since improvement 0
  8%|▊         | 39/500 [49:53<9:29:58, 74.18s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.78E+06, Train scatter: [0.241  0.0683 0.3045 0.484 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2518 0.0678 0.3104 0.4851], Lowest was [0.2518 0.0678 0.3034 0.4795]
Median for last 10 epochs: [0.2556 0.0684 0.3104 0.4851], Epochs since improvement 0
  8%|▊         | 40/500 [51:32<10:25:53, 81.64s/it]  8%|▊         | 41/500 [52:34<9:39:58, 75.81s/it]   8%|▊         | 42/500 [54:05<10:13:13, 80.34s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.60E+06, Train scatter: [0.2642 0.0667 0.3107 0.4838]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2712 0.0659 0.311  0.4803], Lowest was [0.2518 0.0659 0.3034 0.4795]
Median for last 10 epochs: [0.2565 0.0683 0.311  0.4806], Epochs since improvement 0
  9%|▊         | 43/500 [55:07<9:29:48, 74.81s/it]   9%|▉         | 44/500 [56:38<10:06:03, 79.74s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.46E+06, Train scatter: [0.3259 0.0658 0.3012 0.4685]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3207 0.0655 0.3018 0.4701], Lowest was [0.2518 0.0655 0.3018 0.4701]
Median for last 10 epochs: [0.2707 0.0678 0.311  0.4803], Epochs since improvement 0
  9%|▉         | 45/500 [57:40<9:23:42, 74.33s/it]   9%|▉         | 46/500 [59:11<10:00:14, 79.33s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.36E+06, Train scatter: [0.2658 0.0669 0.295  0.4682]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.271 0.067 0.298 0.47 ], Lowest was [0.2518 0.0655 0.298  0.47  ]
Median for last 10 epochs: [0.271  0.067  0.3104 0.4795], Epochs since improvement 0
  9%|▉         | 47/500 [1:00:13<9:19:26, 74.10s/it] 10%|▉         | 48/500 [1:01:44<9:56:06, 79.13s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.37E+06, Train scatter: [0.2391 0.0635 0.2822 0.4583]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2406 0.0639 0.2884 0.4564], Lowest was [0.2406 0.0639 0.2884 0.4564]
Median for last 10 epochs: [0.271  0.0659 0.3018 0.4701], Epochs since improvement 0
 10%|▉         | 49/500 [1:02:46<9:16:32, 74.04s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.03E+06, Train scatter: [0.2134 0.061  0.2823 0.4549]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2189 0.0613 0.2852 0.4551], Lowest was [0.2189 0.0613 0.2852 0.4551]
Median for last 10 epochs: [0.271  0.0655 0.298  0.47  ], Epochs since improvement 0
 10%|█         | 50/500 [1:04:25<10:11:14, 81.50s/it] 10%|█         | 51/500 [1:05:27<9:25:56, 75.63s/it]  10%|█         | 52/500 [1:06:57<9:58:36, 80.17s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.88E+06, Train scatter: [0.2381 0.0575 0.2736 0.4422]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.238  0.0573 0.2778 0.4383], Lowest was [0.2189 0.0573 0.2778 0.4383]
Median for last 10 epochs: [0.2406 0.0639 0.2884 0.4564], Epochs since improvement 0
 11%|█         | 53/500 [1:08:00<9:16:55, 74.76s/it] 11%|█         | 54/500 [1:09:30<9:51:12, 79.53s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.86E+06, Train scatter: [0.2119 0.0606 0.2828 0.441 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2183 0.06   0.2824 0.4399], Lowest was [0.2183 0.0573 0.2778 0.4383]
Median for last 10 epochs: [0.238  0.0613 0.2852 0.4551], Epochs since improvement 0
 11%|█         | 55/500 [1:10:32<9:11:00, 74.29s/it] 11%|█         | 56/500 [1:12:04<9:48:45, 79.56s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.67E+06, Train scatter: [0.2084 0.0545 0.2716 0.4296]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2116 0.0554 0.2772 0.4283], Lowest was [0.2116 0.0554 0.2772 0.4283]
Median for last 10 epochs: [0.2189 0.06   0.2824 0.4399], Epochs since improvement 0
 11%|█▏        | 57/500 [1:13:06<9:08:17, 74.26s/it] 12%|█▏        | 58/500 [1:14:37<9:43:38, 79.23s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.57E+06, Train scatter: [0.2106 0.0627 0.2796 0.4401]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2196 0.0638 0.2845 0.4431], Lowest was [0.2116 0.0554 0.2772 0.4283]
Median for last 10 epochs: [0.2189 0.06   0.2824 0.4399], Epochs since improvement 2
 12%|█▏        | 59/500 [1:15:39<9:04:37, 74.10s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.57E+06, Train scatter: [0.2029 0.0607 0.276  0.4284]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.21   0.0598 0.2781 0.4264], Lowest was [0.21   0.0554 0.2772 0.4264]
Median for last 10 epochs: [0.2183 0.0598 0.2781 0.4383], Epochs since improvement 0
 12%|█▏        | 60/500 [1:17:17<9:56:58, 81.41s/it] 12%|█▏        | 61/500 [1:18:20<9:13:15, 75.62s/it] 12%|█▏        | 62/500 [1:19:51<9:45:29, 80.20s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.25E+06, Train scatter: [0.2219 0.0542 0.2679 0.4373]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.231  0.0544 0.2704 0.4391], Lowest was [0.21   0.0544 0.2704 0.4264]
Median for last 10 epochs: [0.2183 0.0598 0.2781 0.4391], Epochs since improvement 0
 13%|█▎        | 63/500 [1:20:53<9:04:29, 74.76s/it] 13%|█▎        | 64/500 [1:22:24<9:40:12, 79.85s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.16E+06, Train scatter: [0.1912 0.0542 0.2688 0.4188]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2008 0.0547 0.2716 0.4171], Lowest was [0.2008 0.0544 0.2704 0.4171]
Median for last 10 epochs: [0.2116 0.0554 0.2772 0.4283], Epochs since improvement 0
 13%|█▎        | 65/500 [1:23:26<8:59:43, 74.44s/it] 13%|█▎        | 66/500 [1:24:57<9:34:51, 79.47s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.15E+06, Train scatter: [0.2126 0.0541 0.2651 0.4273]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2139 0.0546 0.2665 0.4201], Lowest was [0.2008 0.0544 0.2665 0.4171]
Median for last 10 epochs: [0.2139 0.0547 0.2716 0.4264], Epochs since improvement 0
 13%|█▎        | 67/500 [1:26:00<8:56:12, 74.30s/it] 14%|█▎        | 68/500 [1:27:30<9:30:42, 79.27s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.11E+06, Train scatter: [0.2149 0.0642 0.2761 0.4491]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2234 0.0629 0.2739 0.4492], Lowest was [0.2008 0.0544 0.2665 0.4171]
Median for last 10 epochs: [0.2139 0.0547 0.2716 0.4264], Epochs since improvement 2
 14%|█▍        | 69/500 [1:28:32<8:52:17, 74.10s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.03E+06, Train scatter: [0.1956 0.0516 0.2631 0.4189]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2008 0.0516 0.2649 0.4132], Lowest was [0.2008 0.0516 0.2649 0.4132]
Median for last 10 epochs: [0.2139 0.0546 0.2704 0.4201], Epochs since improvement 0
 14%|█▍        | 70/500 [1:30:12<9:44:58, 81.62s/it] 14%|█▍        | 71/500 [1:31:13<9:00:56, 75.66s/it] 14%|█▍        | 72/500 [1:32:45<9:33:11, 80.35s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 9.75E+05, Train scatter: [0.1858 0.0522 0.2693 0.4471]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1965 0.0518 0.2732 0.4436], Lowest was [0.1965 0.0516 0.2649 0.4132]
Median for last 10 epochs: [0.2008 0.0546 0.2716 0.4201], Epochs since improvement 0
 15%|█▍        | 73/500 [1:33:47<8:52:43, 74.85s/it] 15%|█▍        | 74/500 [1:35:18<9:26:13, 79.75s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 8.77E+05, Train scatter: [0.2081 0.0592 0.2831 0.4353]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2121 0.0593 0.2886 0.4342], Lowest was [0.1965 0.0516 0.2649 0.4132]
Median for last 10 epochs: [0.2121 0.0546 0.2732 0.4342], Epochs since improvement 2
 15%|█▌        | 75/500 [1:36:20<8:47:36, 74.49s/it] 15%|█▌        | 76/500 [1:37:51<9:20:35, 79.33s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 8.19E+05, Train scatter: [0.1891 0.0502 0.2671 0.4137]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1963 0.0503 0.2676 0.4109], Lowest was [0.1963 0.0503 0.2649 0.4109]
Median for last 10 epochs: [0.2008 0.0518 0.2732 0.4342], Epochs since improvement 0
 15%|█▌        | 77/500 [1:38:53<8:42:13, 74.07s/it] 16%|█▌        | 78/500 [1:40:23<9:16:25, 79.11s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 8.27E+05, Train scatter: [0.1824 0.05   0.2796 0.421 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1894 0.0497 0.2819 0.4197], Lowest was [0.1894 0.0497 0.2649 0.4109]
Median for last 10 epochs: [0.1965 0.0516 0.2732 0.4197], Epochs since improvement 0
 16%|█▌        | 79/500 [1:41:26<8:39:46, 74.08s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 6.76E+05, Train scatter: [0.2001 0.0604 0.2736 0.4471]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2058 0.0616 0.2789 0.4428], Lowest was [0.1894 0.0497 0.2649 0.4109]
Median for last 10 epochs: [0.1965 0.0518 0.2789 0.4342], Epochs since improvement 2
 16%|█▌        | 80/500 [1:43:03<9:27:48, 81.12s/it] 16%|█▌        | 81/500 [1:44:05<8:46:29, 75.39s/it] 16%|█▋        | 82/500 [1:45:36<9:18:02, 80.10s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 6.09E+05, Train scatter: [0.1707 0.0502 0.2504 0.3977]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1803 0.0503 0.2544 0.3949], Lowest was [0.1803 0.0497 0.2544 0.3949]
Median for last 10 epochs: [0.1963 0.0503 0.2789 0.4197], Epochs since improvement 0
 17%|█▋        | 83/500 [1:46:38<8:39:01, 74.68s/it] 17%|█▋        | 84/500 [1:48:10<9:12:01, 79.62s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 4.79E+05, Train scatter: [0.1889 0.0483 0.2443 0.4015]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1913 0.0483 0.248  0.3985], Lowest was [0.1803 0.0483 0.248  0.3949]
Median for last 10 epochs: [0.1913 0.0503 0.2676 0.4109], Epochs since improvement 0
 17%|█▋        | 85/500 [1:49:11<8:33:32, 74.25s/it] 17%|█▋        | 86/500 [1:50:42<9:06:54, 79.26s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 3.71E+05, Train scatter: [0.1631 0.0478 0.2518 0.3996]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1692 0.0478 0.2575 0.3998], Lowest was [0.1692 0.0478 0.248  0.3949]
Median for last 10 epochs: [0.1894 0.0497 0.2575 0.3998], Epochs since improvement 0
 17%|█▋        | 87/500 [1:51:44<8:30:02, 74.10s/it] 18%|█▊        | 88/500 [1:53:14<9:01:55, 78.92s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.16E+05, Train scatter: [0.1947 0.0549 0.2835 0.4363]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.208  0.0544 0.2828 0.4323], Lowest was [0.1692 0.0478 0.248  0.3949]
Median for last 10 epochs: [0.1913 0.0503 0.2575 0.3998], Epochs since improvement 2
 18%|█▊        | 89/500 [1:54:17<8:26:15, 73.91s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 7.90E+04, Train scatter: [0.1883 0.0496 0.2601 0.4234]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1924 0.0498 0.262  0.4191], Lowest was [0.1692 0.0478 0.248  0.3949]
Median for last 10 epochs: [0.1913 0.0498 0.2575 0.3998], Epochs since improvement 4
 18%|█▊        | 90/500 [1:55:55<9:15:02, 81.23s/it] 18%|█▊        | 91/500 [1:56:57<8:33:56, 75.39s/it] 18%|█▊        | 92/500 [1:58:29<9:07:05, 80.45s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: -4.87E+04, Train scatter: [0.1417 0.0469 0.2451 0.402 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1498 0.0466 0.2489 0.3965], Lowest was [0.1498 0.0466 0.248  0.3949]
Median for last 10 epochs: [0.1913 0.0483 0.2575 0.3998], Epochs since improvement 0
 19%|█▊        | 93/500 [1:59:31<8:28:17, 74.93s/it] 19%|█▉        | 94/500 [2:01:03<9:01:20, 80.00s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: -1.65E+05, Train scatter: [0.236  0.046  0.2306 0.3875]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2394 0.0465 0.2335 0.3858], Lowest was [0.1498 0.0465 0.2335 0.3858]
Median for last 10 epochs: [0.1924 0.0478 0.2575 0.3998], Epochs since improvement 0
 19%|█▉        | 95/500 [2:02:05<8:23:58, 74.66s/it] 19%|█▉        | 96/500 [2:03:36<8:55:14, 79.49s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: -2.49E+05, Train scatter: [0.1318 0.0464 0.256  0.395 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1847 0.0469 0.2581 0.3947], Lowest was [0.1498 0.0465 0.2335 0.3858]
Median for last 10 epochs: [0.1924 0.0469 0.2581 0.3965], Epochs since improvement 2
 19%|█▉        | 97/500 [2:04:38<8:18:17, 74.19s/it] 20%|█▉        | 98/500 [2:06:08<8:50:30, 79.18s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: -3.07E+05, Train scatter: [0.1664 0.0498 0.2801 0.4078]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1896 0.0495 0.2787 0.4063], Lowest was [0.1498 0.0465 0.2335 0.3858]
Median for last 10 epochs: [0.1896 0.0469 0.2581 0.3965], Epochs since improvement 4
 20%|█▉        | 99/500 [2:07:10<8:14:20, 73.97s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: -3.37E+05, Train scatter: [0.1278 0.0424 0.2476 0.3848]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1349 0.0427 0.2505 0.3831], Lowest was [0.1349 0.0427 0.2335 0.3831]
Median for last 10 epochs: [0.1847 0.0466 0.2505 0.3947], Epochs since improvement 0
 20%|██        | 100/500 [2:08:50<9:05:00, 81.75s/it] 20%|██        | 101/500 [2:09:53<8:24:55, 75.93s/it] 20%|██        | 102/500 [2:11:24<8:54:58, 80.65s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: -3.40E+05, Train scatter: [0.2462 0.0533 0.3053 0.4116]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2406 0.0538 0.3091 0.4022], Lowest was [0.1349 0.0427 0.2335 0.3831]
Median for last 10 epochs: [0.1896 0.0469 0.2581 0.3947], Epochs since improvement 2
 21%|██        | 103/500 [2:12:26<8:16:55, 75.10s/it] 21%|██        | 104/500 [2:13:57<8:47:04, 79.86s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: -3.79E+05, Train scatter: [0.1405 0.0432 0.2184 0.3826]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2322 0.0427 0.2225 0.3798], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.1896 0.0469 0.2581 0.3947], Epochs since improvement 0
 21%|██        | 105/500 [2:14:59<8:10:27, 74.50s/it] 21%|██        | 106/500 [2:16:31<8:43:27, 79.72s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: -3.87E+05, Train scatter: [0.1508 0.0487 0.3901 0.4016]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2146 0.0484 0.3825 0.3966], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.2146 0.0484 0.2787 0.3966], Epochs since improvement 2
 21%|██▏       | 107/500 [2:17:33<8:07:27, 74.42s/it] 22%|██▏       | 108/500 [2:19:04<8:37:51, 79.26s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: -1.43E+05, Train scatter: [0.4732 0.0992 0.4192 0.6187]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4693 0.0974 0.4152 0.6145], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.2322 0.0484 0.3091 0.3966], Epochs since improvement 4
 22%|██▏       | 109/500 [2:20:06<8:03:02, 74.13s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: -2.57E+05, Train scatter: [0.3767 0.0545 0.2798 0.4491]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3658 0.0538 0.2874 0.4422], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.2406 0.0538 0.3091 0.4022], Epochs since improvement 6
 22%|██▏       | 110/500 [2:21:46<8:51:29, 81.77s/it] 22%|██▏       | 111/500 [2:22:48<8:11:35, 75.82s/it] 22%|██▏       | 112/500 [2:24:19<8:39:50, 80.39s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: -3.10E+05, Train scatter: [0.2067 0.0504 0.3884 0.437 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1987 0.0504 0.3808 0.4284], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.2322 0.0504 0.3808 0.4284], Epochs since improvement 8
 23%|██▎       | 113/500 [2:25:21<8:03:23, 74.94s/it] 23%|██▎       | 114/500 [2:26:52<8:34:16, 79.94s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: -3.16E+05, Train scatter: [0.3947 0.0502 0.2552 0.4431]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.386  0.0498 0.2578 0.4379], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.3658 0.0504 0.3808 0.4379], Epochs since improvement 10
 23%|██▎       | 115/500 [2:27:55<7:58:44, 74.61s/it] 23%|██▎       | 116/500 [2:29:26<8:30:16, 79.73s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: -3.54E+05, Train scatter: [0.1789 0.0461 0.239  0.4236]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1721 0.0456 0.2418 0.4152], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.3658 0.0504 0.2874 0.4379], Epochs since improvement 12
 23%|██▎       | 117/500 [2:30:28<7:54:44, 74.37s/it] 24%|██▎       | 118/500 [2:32:00<8:26:43, 79.59s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: -3.72E+05, Train scatter: [0.2072 0.0453 0.2341 0.4206]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2065 0.0441 0.2358 0.4114], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.2065 0.0498 0.2578 0.4284], Epochs since improvement 14
 24%|██▍       | 119/500 [2:33:02<7:51:51, 74.31s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: -3.73E+05, Train scatter: [0.1405 0.0511 0.2415 0.4262]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2101 0.0505 0.2453 0.4178], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.2065 0.0498 0.2453 0.4178], Epochs since improvement 16
 24%|██▍       | 120/500 [2:34:41<8:36:59, 81.63s/it] 24%|██▍       | 121/500 [2:35:43<7:58:51, 75.81s/it] 24%|██▍       | 122/500 [2:37:14<8:26:23, 80.38s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: -3.70E+05, Train scatter: [0.3347 0.0433 0.2398 0.4192]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3286 0.0429 0.2433 0.4116], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.2101 0.0456 0.2433 0.4152], Epochs since improvement 18
 25%|██▍       | 123/500 [2:38:16<7:50:27, 74.87s/it] 25%|██▍       | 124/500 [2:39:47<8:19:38, 79.73s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: -3.56E+05, Train scatter: [0.1855 0.0449 0.2462 0.4206]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1799 0.0448 0.2485 0.4134], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.2065 0.0448 0.2433 0.4134], Epochs since improvement 20
 25%|██▌       | 125/500 [2:40:49<7:44:43, 74.36s/it] 25%|██▌       | 125/500 [2:42:20<8:07:02, 77.93s/it]
Epoch: 126 done with learning rate 9.65E-03, Train loss: -9.13E+04, Train scatter: [0.8822 0.1029 0.3862 0.6488]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8675 0.1001 0.3822 0.6427], Lowest was [0.1349 0.0427 0.2225 0.3798]
Median for last 10 epochs: [0.2101 0.0448 0.2453 0.4134], Epochs since improvement 22
Exited after 126 epochs due to early stopping
9741.00 seconds spent training, 19.482 seconds per epoch. Processed 3574 trees per second
[0.86744136 0.10010495 0.38219085 0.6426434 ]
{'epoch_exit': 125, 'scatter_m_star': 0.86744136, 'lowest_m_star': 0.13487074, 'last20_m_star': 0.26934183, 'last10_m_star': 0.21010426, 'scatter_v_disk': 0.10010495, 'lowest_v_disk': 0.04266728, 'last20_v_disk': 0.050104104, 'last10_v_disk': 0.044809625, 'scatter_m_cold': 0.38219085, 'lowest_m_cold': 0.22252446, 'last20_m_cold': 0.25315535, 'last10_m_cold': 0.24533571, 'scatter_sfr_100': 0.6426434, 'lowest_sfr_100': 0.379809, 'last20_sfr_100': 0.42311662, 'last10_sfr_100': 0.4134276}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_diaqdp
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:27:28, 53.81s/it]  0%|          | 2/500 [02:14<9:40:15, 69.91s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.17   0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1647 0.5355 0.985 ], Lowest was [0.9196 0.1647 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1647 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:08<8:37:18, 62.45s/it]  1%|          | 4/500 [04:30<9:39:38, 70.12s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 9.06E+07, Train scatter: [0.9352 0.1467 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1417 0.5355 0.9851], Lowest was [0.9196 0.1417 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1417 0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:24<8:49:18, 64.16s/it]  1%|          | 6/500 [06:45<9:37:33, 70.15s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.60E+07, Train scatter: [0.9351 0.1266 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1246 0.5355 0.9851], Lowest was [0.9195 0.1246 0.5355 0.985 ]
Median for last 10 epochs: [0.9195 0.1246 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:39<8:53:04, 64.88s/it]  2%|▏         | 8/500 [09:00<9:33:40, 69.96s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.31E+07, Train scatter: [0.9305 0.1005 0.5436 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9151 0.1    0.5351 0.9851], Lowest was [0.9151 0.1    0.5351 0.985 ]
Median for last 10 epochs: [0.9173 0.1123 0.5353 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [09:54<8:51:10, 64.91s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.05E+07, Train scatter: [0.7996 0.0941 0.5402 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7916 0.0952 0.5319 0.985 ], Lowest was [0.7916 0.0952 0.5319 0.985 ]
Median for last 10 epochs: [0.9151 0.1    0.5351 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:22<9:49:26, 72.18s/it]  2%|▏         | 11/500 [12:16<9:02:47, 66.60s/it]  2%|▏         | 12/500 [13:38<9:40:00, 71.31s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.93E+07, Train scatter: [0.6404 0.089  0.532  0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6325 0.0897 0.5243 0.985 ], Lowest was [0.6325 0.0897 0.5243 0.985 ]
Median for last 10 epochs: [0.9151 0.1    0.5351 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:32<8:56:01, 66.04s/it]  3%|▎         | 14/500 [15:55<9:35:35, 71.06s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.86E+07, Train scatter: [0.5456 0.0874 0.5304 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5496 0.0884 0.5231 0.9849], Lowest was [0.5496 0.0884 0.5231 0.9849]
Median for last 10 epochs: [0.7916 0.0952 0.5319 0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [16:49<8:51:44, 65.78s/it]  3%|▎         | 16/500 [18:12<9:34:16, 71.19s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.81E+07, Train scatter: [0.4822 0.0855 0.5285 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4816 0.0859 0.5208 0.9849], Lowest was [0.4816 0.0859 0.5208 0.9849]
Median for last 10 epochs: [0.6325 0.0897 0.5243 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [19:06<8:50:51, 65.94s/it]  4%|▎         | 18/500 [20:29<9:29:32, 70.90s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.73E+07, Train scatter: [0.5045 0.0879 0.4167 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5079 0.0886 0.411  0.9849], Lowest was [0.4816 0.0859 0.411  0.9849]
Median for last 10 epochs: [0.5496 0.0886 0.5231 0.9849], Epochs since improvement 0
  4%|▍         | 19/500 [21:23<8:47:52, 65.85s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.59E+07, Train scatter: [0.5353 0.0873 0.4139 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5446 0.0885 0.4111 0.985 ], Lowest was [0.4816 0.0859 0.411  0.9849]
Median for last 10 epochs: [0.5446 0.0885 0.5208 0.9849], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:55<9:50:56, 73.87s/it]  4%|▍         | 21/500 [23:49<9:01:43, 67.86s/it]  4%|▍         | 22/500 [25:10<9:31:46, 71.77s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.49E+07, Train scatter: [0.5852 0.0878 0.4933 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5975 0.0888 0.4976 0.985 ], Lowest was [0.4816 0.0859 0.411  0.9849]
Median for last 10 epochs: [0.5446 0.0885 0.4976 0.9849], Epochs since improvement 4
  5%|▍         | 23/500 [26:04<8:47:37, 66.37s/it]  5%|▍         | 24/500 [27:25<9:22:12, 70.87s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.44E+07, Train scatter: [0.5787 0.093  0.3728 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5873 0.093  0.3749 0.985 ], Lowest was [0.4816 0.0859 0.3749 0.9849]
Median for last 10 epochs: [0.5446 0.0886 0.4111 0.985 ], Epochs since improvement 0
  5%|▌         | 25/500 [28:19<8:40:14, 65.71s/it]  5%|▌         | 26/500 [29:40<9:15:22, 70.30s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.41E+07, Train scatter: [0.5436 0.086  0.3507 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5582 0.0869 0.3484 0.985 ], Lowest was [0.4816 0.0859 0.3484 0.9849]
Median for last 10 epochs: [0.5582 0.0886 0.411  0.985 ], Epochs since improvement 0
  5%|▌         | 27/500 [30:33<8:34:44, 65.29s/it]  6%|▌         | 28/500 [31:54<9:10:39, 70.00s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.37E+07, Train scatter: [0.509  0.0808 0.3235 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5142 0.0825 0.333  0.985 ], Lowest was [0.4816 0.0825 0.333  0.9849]
Median for last 10 epochs: [0.5582 0.0885 0.3749 0.985 ], Epochs since improvement 0
  6%|▌         | 29/500 [32:48<8:31:03, 65.10s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.25E+07, Train scatter: [0.5566 0.081  0.3181 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5497 0.0823 0.3284 0.985 ], Lowest was [0.4816 0.0823 0.3284 0.9849]
Median for last 10 epochs: [0.5582 0.0869 0.3484 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [34:17<9:25:19, 72.17s/it]  6%|▌         | 31/500 [35:11<8:41:31, 66.72s/it]  6%|▋         | 32/500 [36:32<9:14:05, 71.04s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.14E+07, Train scatter: [0.525  0.0825 0.3137 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.531  0.0829 0.3181 0.985 ], Lowest was [0.4816 0.0823 0.3181 0.9849]
Median for last 10 epochs: [0.5497 0.0829 0.333  0.985 ], Epochs since improvement 0
  7%|▋         | 33/500 [37:26<8:33:16, 65.95s/it]  7%|▋         | 34/500 [38:47<9:08:26, 70.62s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.09E+07, Train scatter: [0.4834 0.0832 0.3054 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4869 0.0843 0.3129 0.985 ], Lowest was [0.4816 0.0823 0.3129 0.9849]
Median for last 10 epochs: [0.531  0.0829 0.3284 0.985 ], Epochs since improvement 0
  7%|▋         | 35/500 [39:41<8:28:36, 65.63s/it]  7%|▋         | 36/500 [41:03<9:05:28, 70.54s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.03E+07, Train scatter: [0.5119 0.0778 0.3148 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5042 0.0783 0.3157 0.985 ], Lowest was [0.4816 0.0783 0.3129 0.9849]
Median for last 10 epochs: [0.5142 0.0825 0.3181 0.985 ], Epochs since improvement 0
  7%|▋         | 37/500 [41:57<8:25:54, 65.56s/it]  8%|▊         | 38/500 [43:20<9:03:51, 70.63s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.52E+07, Train scatter: [0.545  0.0783 0.2947 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5443 0.0793 0.3027 0.985 ], Lowest was [0.4816 0.0783 0.3027 0.9849]
Median for last 10 epochs: [0.531  0.0823 0.3157 0.985 ], Epochs since improvement 0
  8%|▊         | 39/500 [44:14<8:23:54, 65.58s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.93E+07, Train scatter: [0.6085 0.0871 0.3093 0.9944]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6014 0.0876 0.3141 0.9841], Lowest was [0.4816 0.0783 0.3027 0.9841]
Median for last 10 epochs: [0.531  0.0829 0.3141 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:42<9:15:06, 72.40s/it]  8%|▊         | 41/500 [46:36<8:31:37, 66.88s/it]  8%|▊         | 42/500 [47:58<9:04:31, 71.33s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 5.30E+06, Train scatter: [0.4798 0.0841 0.3311 0.577 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4726 0.0841 0.3337 0.575 ], Lowest was [0.4726 0.0783 0.3027 0.575 ]
Median for last 10 epochs: [0.5042 0.0841 0.3141 0.985 ], Epochs since improvement 0
  9%|▊         | 43/500 [48:51<8:23:32, 66.11s/it]  9%|▉         | 44/500 [50:14<8:59:13, 70.95s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.96E+06, Train scatter: [0.59   0.0768 0.3075 0.5715]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5982 0.0774 0.3133 0.5682], Lowest was [0.4726 0.0774 0.3027 0.5682]
Median for last 10 epochs: [0.5443 0.0793 0.3141 0.9841], Epochs since improvement 0
  9%|▉         | 45/500 [51:08<8:19:32, 65.87s/it]  9%|▉         | 46/500 [52:29<8:54:11, 70.60s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.03E+06, Train scatter: [0.4831 0.0786 0.3166 0.5707]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4732 0.0784 0.3222 0.5737], Lowest was [0.4726 0.0774 0.3027 0.5682]
Median for last 10 epochs: [0.5443 0.0793 0.3141 0.575 ], Epochs since improvement 2
  9%|▉         | 47/500 [53:23<8:15:38, 65.65s/it] 10%|▉         | 48/500 [54:45<8:50:53, 70.47s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.58E+06, Train scatter: [0.3992 0.0738 0.2989 0.5371]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3943 0.0746 0.3051 0.5426], Lowest was [0.3943 0.0746 0.3027 0.5426]
Median for last 10 epochs: [0.4732 0.0784 0.3141 0.5737], Epochs since improvement 0
 10%|▉         | 49/500 [55:39<8:12:41, 65.55s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.34E+06, Train scatter: [0.4453 0.0758 0.3294 0.5723]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4425 0.0753 0.3304 0.5751], Lowest was [0.3943 0.0746 0.3027 0.5426]
Median for last 10 epochs: [0.4726 0.0774 0.3222 0.5737], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [57:08<9:04:19, 72.58s/it] 10%|█         | 51/500 [58:02<8:21:17, 66.99s/it] 10%|█         | 52/500 [59:24<8:52:24, 71.30s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.11E+06, Train scatter: [0.396  0.069  0.293  0.4864]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3892 0.0686 0.297  0.4847], Lowest was [0.3892 0.0686 0.297  0.4847]
Median for last 10 epochs: [0.4425 0.0753 0.3133 0.5682], Epochs since improvement 0
 11%|█         | 53/500 [1:00:17<8:11:57, 66.03s/it] 11%|█         | 54/500 [1:01:38<8:44:38, 70.58s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.95E+06, Train scatter: [0.5301 0.0696 0.2949 0.494 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5207 0.0701 0.3028 0.4932], Lowest was [0.3892 0.0686 0.297  0.4847]
Median for last 10 epochs: [0.4425 0.0746 0.3051 0.5426], Epochs since improvement 2
 11%|█         | 55/500 [1:02:32<8:05:58, 65.53s/it] 11%|█         | 56/500 [1:03:53<8:39:28, 70.20s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.83E+06, Train scatter: [0.4205 0.0657 0.2836 0.4784]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4103 0.0657 0.2893 0.4776], Lowest was [0.3892 0.0657 0.2893 0.4776]
Median for last 10 epochs: [0.4103 0.0701 0.3028 0.4932], Epochs since improvement 0
 11%|█▏        | 57/500 [1:04:47<8:02:17, 65.32s/it] 12%|█▏        | 58/500 [1:06:08<8:35:49, 70.02s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.91E+06, Train scatter: [0.3804 0.0667 0.2828 0.4744]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3743 0.0667 0.287  0.4713], Lowest was [0.3743 0.0657 0.287  0.4713]
Median for last 10 epochs: [0.4103 0.0686 0.297  0.4847], Epochs since improvement 0
 12%|█▏        | 59/500 [1:07:02<7:59:12, 65.20s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.80E+06, Train scatter: [0.4248 0.0646 0.2835 0.4703]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.419  0.0652 0.29   0.4726], Lowest was [0.3743 0.0652 0.287  0.4713]
Median for last 10 epochs: [0.4103 0.0667 0.29   0.4776], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:08:31<8:50:52, 72.39s/it] 12%|█▏        | 61/500 [1:09:26<8:09:34, 66.91s/it] 12%|█▏        | 62/500 [1:10:47<8:39:22, 71.15s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.84E+06, Train scatter: [0.3265 0.0646 0.2771 0.4975]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3201 0.0649 0.28   0.4989], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.4103 0.0657 0.2893 0.4776], Epochs since improvement 0
 13%|█▎        | 63/500 [1:11:40<8:00:33, 65.98s/it] 13%|█▎        | 64/500 [1:13:02<8:33:41, 70.69s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.50E+06, Train scatter: [0.5253 0.0649 0.2869 0.4772]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5172 0.0652 0.2889 0.4793], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.4103 0.0652 0.2889 0.4776], Epochs since improvement 2
 13%|█▎        | 65/500 [1:13:56<7:55:57, 65.65s/it] 13%|█▎        | 66/500 [1:15:17<8:28:43, 70.33s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.45E+07, Train scatter: [0.9336 0.1646 0.543  0.9783]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.918  0.1609 0.5345 0.9682], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.419  0.0652 0.2889 0.4793], Epochs since improvement 4
 13%|█▎        | 67/500 [1:16:11<7:51:53, 65.39s/it] 14%|█▎        | 68/500 [1:17:32<8:24:07, 70.02s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.11E+07, Train scatter: [0.8022 0.1291 0.4992 0.7188]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7884 0.1263 0.4917 0.7082], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.5172 0.0652 0.29   0.4989], Epochs since improvement 6
 14%|█▍        | 69/500 [1:18:26<7:47:34, 65.09s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 8.26E+06, Train scatter: [0.6215 0.1122 0.479  0.6527]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6096 0.1096 0.4756 0.6435], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.6096 0.1096 0.4756 0.6435], Epochs since improvement 8
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:19:53<8:35:33, 71.94s/it] 14%|█▍        | 71/500 [1:20:47<7:55:40, 66.53s/it] 14%|█▍        | 72/500 [1:22:08<8:24:58, 70.79s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 7.27E+06, Train scatter: [0.614  0.1127 0.4508 0.6701]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6067 0.1103 0.4456 0.6616], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.6096 0.1103 0.4756 0.6616], Epochs since improvement 10
 15%|█▍        | 73/500 [1:23:02<7:47:32, 65.70s/it] 15%|█▍        | 74/500 [1:24:23<8:19:45, 70.39s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 6.56E+06, Train scatter: [0.5936 0.1086 0.4247 0.6147]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5845 0.1059 0.421  0.6067], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.6096 0.1103 0.4756 0.6616], Epochs since improvement 12
 15%|█▌        | 75/500 [1:25:17<7:43:54, 65.49s/it] 15%|█▌        | 76/500 [1:26:38<8:15:22, 70.10s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 8.96E+06, Train scatter: [0.608  0.1183 0.4992 0.6874]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5963 0.1155 0.4919 0.6779], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.6067 0.1103 0.4756 0.6616], Epochs since improvement 14
 15%|█▌        | 77/500 [1:27:32<7:39:58, 65.24s/it] 16%|█▌        | 78/500 [1:28:54<8:14:42, 70.34s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 6.65E+06, Train scatter: [0.6033 0.109  0.4347 0.6183]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6002 0.1063 0.4318 0.6075], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.6002 0.1096 0.4456 0.6435], Epochs since improvement 16
 16%|█▌        | 79/500 [1:29:48<7:38:33, 65.35s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 5.74E+06, Train scatter: [0.5339 0.0999 0.4091 0.5933]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5289 0.0974 0.406  0.5822], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.5963 0.1063 0.4318 0.6075], Epochs since improvement 18
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:31:18<8:28:57, 72.71s/it] 16%|█▌        | 81/500 [1:32:12<7:48:12, 67.05s/it] 16%|█▋        | 82/500 [1:33:33<8:15:44, 71.16s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 5.41E+06, Train scatter: [0.4855 0.0948 0.4096 0.6036]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.478  0.0925 0.4055 0.5908], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.5845 0.1059 0.421  0.6067], Epochs since improvement 20
 17%|█▋        | 83/500 [1:34:26<7:38:34, 65.98s/it] 17%|█▋        | 83/500 [1:35:48<8:01:19, 69.25s/it]
Epoch: 84 done with learning rate 9.99E-03, Train loss: 4.89E+06, Train scatter: [0.4694 0.0942 0.395  0.6186]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4613 0.0918 0.3925 0.6053], Lowest was [0.3201 0.0649 0.28   0.4713]
Median for last 10 epochs: [0.5289 0.0974 0.406  0.6053], Epochs since improvement 22
Exited after 84 epochs due to early stopping
5748.11 seconds spent training, 11.496 seconds per epoch. Processed 6057 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.4613139  0.09180745 0.39244425 0.6053152 ]
{'epoch_exit': 83, 'scatter_m_star': 0.4613139, 'lowest_m_star': 0.32009083, 'last20_m_star': 0.59824204, 'last10_m_star': 0.52889, 'scatter_v_disk': 0.09180745, 'lowest_v_disk': 0.06486288, 'last20_v_disk': 0.10797633, 'last10_v_disk': 0.09741777, 'scatter_m_cold': 0.39244425, 'lowest_m_cold': 0.2800351, 'last20_m_cold': 0.43868965, 'last10_m_cold': 0.40597647, 'scatter_sfr_100': 0.6053152, 'lowest_sfr_100': 0.47134212, 'last20_sfr_100': 0.62549734, 'last10_sfr_100': 0.60533255}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
