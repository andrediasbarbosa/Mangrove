Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_doufrh
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:33<4:35:03, 33.07s/it]  0%|          | 2/500 [01:19<5:39:32, 40.91s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.21E+07, Train scatter: [0.9353 0.1747 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1817 0.5356 0.9851], Lowest was [0.9198 0.1817 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1817 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:49<4:59:33, 36.16s/it]  1%|          | 4/500 [02:36<5:34:21, 40.45s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 7.46E+06, Train scatter: [0.9352 0.1758 0.544  0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1877 0.5354 0.985 ], Lowest was [0.9197 0.1817 0.5354 0.985 ]
Median for last 10 epochs: [0.9197 0.1847 0.5354 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:07<5:04:20, 36.89s/it]  1%|          | 6/500 [03:54<5:32:22, 40.37s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.65E+06, Train scatter: [0.9346 0.142  0.5429 0.7261]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9191 0.145  0.5343 0.7205], Lowest was [0.9191 0.145  0.5343 0.7205]
Median for last 10 epochs: [0.9191 0.145  0.5343 0.7205], Epochs since improvement 0
  1%|▏         | 7/500 [04:25<5:05:16, 37.15s/it]  2%|▏         | 8/500 [05:12<5:31:31, 40.43s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.85E+06, Train scatter: [0.9247 0.126  0.5369 0.6689]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9097 0.1271 0.5286 0.66  ], Lowest was [0.9097 0.1271 0.5286 0.66  ]
Median for last 10 epochs: [0.9144 0.1361 0.5315 0.6902], Epochs since improvement 0
  2%|▏         | 9/500 [05:43<5:05:28, 37.33s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.24E+06, Train scatter: [0.7845 0.1162 0.5222 0.6197]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7722 0.1173 0.5141 0.6142], Lowest was [0.7722 0.1173 0.5141 0.6142]
Median for last 10 epochs: [0.9097 0.1271 0.5286 0.66  ], Epochs since improvement 0
  2%|▏         | 10/500 [06:35<5:43:16, 42.03s/it]  2%|▏         | 11/500 [07:06<5:13:41, 38.49s/it]  2%|▏         | 12/500 [07:53<5:34:28, 41.12s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.73E+06, Train scatter: [0.6579 0.113  0.4376 0.6316]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6578 0.1142 0.4353 0.6241], Lowest was [0.6578 0.1142 0.4353 0.6142]
Median for last 10 epochs: [0.9097 0.1271 0.5286 0.66  ], Epochs since improvement 0
  3%|▎         | 13/500 [08:23<5:07:49, 37.93s/it]  3%|▎         | 14/500 [09:10<5:29:19, 40.66s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.78E+06, Train scatter: [0.5328 0.1064 0.3898 0.6069]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5251 0.1083 0.3881 0.6086], Lowest was [0.5251 0.1083 0.3881 0.6086]
Median for last 10 epochs: [0.7722 0.1173 0.5141 0.6241], Epochs since improvement 0
  3%|▎         | 15/500 [09:41<5:04:01, 37.61s/it]  3%|▎         | 16/500 [10:28<5:25:40, 40.37s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.33E+06, Train scatter: [0.5184 0.1013 0.3532 0.5947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5154 0.1036 0.3553 0.5947], Lowest was [0.5154 0.1036 0.3553 0.5947]
Median for last 10 epochs: [0.6578 0.1142 0.4353 0.6142], Epochs since improvement 0
  3%|▎         | 17/500 [10:58<5:01:24, 37.44s/it]  4%|▎         | 18/500 [11:46<5:24:21, 40.38s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.00E+06, Train scatter: [0.5538 0.0961 0.3657 0.596 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5419 0.0979 0.3654 0.5933], Lowest was [0.5154 0.0979 0.3553 0.5933]
Median for last 10 epochs: [0.5419 0.1083 0.3881 0.6086], Epochs since improvement 0
  4%|▍         | 19/500 [12:16<4:59:52, 37.41s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.14E+05, Train scatter: [0.5315 0.0909 0.327  0.5923]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5322 0.0939 0.3324 0.5937], Lowest was [0.5154 0.0939 0.3324 0.5933]
Median for last 10 epochs: [0.5322 0.1036 0.3654 0.5947], Epochs since improvement 0
  4%|▍         | 20/500 [13:08<5:34:14, 41.78s/it]  4%|▍         | 21/500 [13:39<5:06:52, 38.44s/it]  4%|▍         | 22/500 [14:26<5:26:26, 40.98s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.38E+05, Train scatter: [0.5146 0.0889 0.3184 0.5626]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5143 0.0934 0.3293 0.5701], Lowest was [0.5143 0.0934 0.3293 0.5701]
Median for last 10 epochs: [0.5251 0.0979 0.3553 0.5937], Epochs since improvement 0
  5%|▍         | 23/500 [14:56<5:01:02, 37.87s/it]  5%|▍         | 24/500 [15:43<5:22:46, 40.69s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.03E+05, Train scatter: [0.4954 0.087  0.3066 0.5546]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4989 0.0906 0.3119 0.5593], Lowest was [0.4989 0.0906 0.3119 0.5593]
Median for last 10 epochs: [0.5154 0.0939 0.3324 0.5933], Epochs since improvement 0
  5%|▌         | 25/500 [16:14<4:57:56, 37.63s/it]  5%|▌         | 26/500 [17:01<5:19:31, 40.45s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 6.83E+05, Train scatter: [0.5213 0.0846 0.3223 0.5519]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5186 0.0873 0.3271 0.5532], Lowest was [0.4989 0.0873 0.3119 0.5532]
Median for last 10 epochs: [0.5186 0.0934 0.3293 0.5701], Epochs since improvement 0
  5%|▌         | 27/500 [17:31<4:55:15, 37.45s/it]  6%|▌         | 28/500 [18:18<5:16:54, 40.28s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 9.01E+05, Train scatter: [0.6967 0.0846 0.3188 0.5494]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7419 0.0858 0.3289 0.5507], Lowest was [0.4989 0.0858 0.3119 0.5507]
Median for last 10 epochs: [0.5186 0.0906 0.3289 0.5593], Epochs since improvement 0
  6%|▌         | 29/500 [18:49<4:53:27, 37.38s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 5.22E+05, Train scatter: [0.4661 0.0829 0.316  0.5397]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4652 0.0875 0.331  0.5506], Lowest was [0.4652 0.0858 0.3119 0.5506]
Median for last 10 epochs: [0.5143 0.0875 0.3289 0.5532], Epochs since improvement 0
  6%|▌         | 30/500 [19:41<5:26:17, 41.65s/it]  6%|▌         | 31/500 [20:11<4:59:49, 38.36s/it]  6%|▋         | 32/500 [20:58<5:19:42, 40.99s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.21E+05, Train scatter: [0.4469 0.081  0.2924 0.5308]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.446  0.0836 0.3015 0.5341], Lowest was [0.446  0.0836 0.3015 0.5341]
Median for last 10 epochs: [0.4989 0.0873 0.3271 0.5507], Epochs since improvement 0
  7%|▋         | 33/500 [21:29<4:54:15, 37.81s/it]  7%|▋         | 34/500 [22:16<5:15:38, 40.64s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 1.48E+06, Train scatter: [0.5339 0.1012 0.4591 0.7177]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5175 0.1019 0.45   0.6965], Lowest was [0.446  0.0836 0.3015 0.5341]
Median for last 10 epochs: [0.5175 0.0873 0.3289 0.5507], Epochs since improvement 2
  7%|▋         | 35/500 [22:47<4:51:33, 37.62s/it]  7%|▋         | 36/500 [23:34<5:13:46, 40.57s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.39E+05, Train scatter: [0.4582 0.0785 0.2947 0.5227]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4594 0.0796 0.3019 0.5187], Lowest was [0.446  0.0796 0.3015 0.5187]
Median for last 10 epochs: [0.4652 0.0858 0.3289 0.5506], Epochs since improvement 0
  7%|▋         | 37/500 [24:05<4:49:53, 37.57s/it]  8%|▊         | 38/500 [24:52<5:11:30, 40.46s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 4.17E+05, Train scatter: [0.5942 0.1044 0.4245 0.6109]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5801 0.1019 0.4235 0.602 ], Lowest was [0.446  0.0796 0.3015 0.5187]
Median for last 10 epochs: [0.4652 0.0875 0.331  0.5506], Epochs since improvement 2
  8%|▊         | 39/500 [25:22<4:48:04, 37.49s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: -1.95E+05, Train scatter: [0.2738 0.0732 0.2831 0.4943]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2759 0.0743 0.2929 0.492 ], Lowest was [0.2759 0.0743 0.2929 0.492 ]
Median for last 10 epochs: [0.4594 0.0836 0.3019 0.5341], Epochs since improvement 0
  8%|▊         | 40/500 [26:15<5:21:26, 41.93s/it]  8%|▊         | 41/500 [26:45<4:54:58, 38.56s/it]  8%|▊         | 42/500 [27:33<5:15:13, 41.30s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.51E+05, Train scatter: [0.3791 0.0693 0.2785 0.4938]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3664 0.0702 0.2881 0.4913], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.4594 0.0796 0.3019 0.5187], Epochs since improvement 0
  9%|▊         | 43/500 [28:04<4:50:06, 38.09s/it]  9%|▉         | 44/500 [28:50<5:08:56, 40.65s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 7.52E+10, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.4594 0.0796 0.3019 0.5187], Epochs since improvement 2
  9%|▉         | 45/500 [29:21<4:45:25, 37.64s/it]  9%|▉         | 46/500 [30:08<5:06:34, 40.52s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.33E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.5801 0.1019 0.4235 0.602 ], Epochs since improvement 4
  9%|▉         | 47/500 [30:39<4:43:25, 37.54s/it] 10%|▉         | 48/500 [31:26<5:05:06, 40.50s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.12E+07, Train scatter: [0.9353 0.1728 0.5441 0.9947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.9843], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9843], Epochs since improvement 6
 10%|▉         | 49/500 [31:57<4:42:15, 37.55s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 5.66E+06, Train scatter: [0.9326 0.1698 0.5425 0.9964]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9171 0.1661 0.534  0.986 ], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 8
 10%|█         | 50/500 [32:49<5:14:47, 41.97s/it] 10%|█         | 51/500 [33:20<4:48:20, 38.53s/it] 10%|█         | 52/500 [34:07<5:07:56, 41.24s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.77E+06, Train scatter: [0.9195 0.111  0.5438 0.6992]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9044 0.1104 0.5352 0.6953], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 10
 11%|█         | 53/500 [34:38<4:43:28, 38.05s/it] 11%|█         | 54/500 [35:25<5:03:37, 40.85s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.42E+06, Train scatter: [0.9139 0.1086 0.5434 0.8084]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.899  0.108  0.5348 0.8051], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.9171 0.1661 0.5352 0.9843], Epochs since improvement 12
 11%|█         | 55/500 [35:56<4:40:15, 37.79s/it] 11%|█         | 56/500 [36:44<5:02:12, 40.84s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.05E+06, Train scatter: [0.9017 0.1052 0.4836 0.6762]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8871 0.104  0.4784 0.6697], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.9044 0.1104 0.5348 0.8051], Epochs since improvement 14
 11%|█▏        | 57/500 [37:14<4:39:01, 37.79s/it] 12%|█▏        | 58/500 [38:02<4:59:32, 40.66s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.81E+06, Train scatter: [0.8852 0.104  0.4703 0.6751]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8708 0.1023 0.4652 0.6688], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.899  0.108  0.534  0.6953], Epochs since improvement 16
 12%|█▏        | 59/500 [38:32<4:36:57, 37.68s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 7.11E+06, Train scatter: [0.875  0.1153 0.526  0.9963]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8612 0.1143 0.5185 0.986 ], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.8871 0.108  0.5185 0.6953], Epochs since improvement 18
 12%|█▏        | 60/500 [39:25<5:08:57, 42.13s/it] 12%|█▏        | 61/500 [39:56<4:42:46, 38.65s/it] 12%|█▏        | 62/500 [40:43<5:02:05, 41.38s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 4.99E+06, Train scatter: [0.8602 0.1125 0.51   0.9889]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8467 0.1114 0.5033 0.9787], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.8708 0.108  0.5033 0.8051], Epochs since improvement 20
 13%|█▎        | 63/500 [41:14<4:37:57, 38.16s/it] 13%|█▎        | 63/500 [42:01<4:51:31, 40.03s/it]
Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.62E+06, Train scatter: [0.7462 0.1134 0.4874 0.9797]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7362 0.1121 0.4817 0.9698], Lowest was [0.2759 0.0702 0.2881 0.4913]
Median for last 10 epochs: [0.8612 0.1114 0.4817 0.9698], Epochs since improvement 22
Exited after 64 epochs due to early stopping
2522.07 seconds spent training, 5.044 seconds per epoch. Processed 13805 trees per second
[0.73615354 0.11208755 0.4816366  0.96980095]
{'epoch_exit': 63, 'scatter_m_star': 0.73615354, 'lowest_m_star': 0.2758825, 'last20_m_star': 0.8930206, 'last10_m_star': 0.86122185, 'scatter_v_disk': 0.11208755, 'lowest_v_disk': 0.07020595, 'last20_v_disk': 0.11175201, 'last10_v_disk': 0.11141308, 'scatter_m_cold': 0.4816366, 'lowest_m_cold': 0.2880864, 'last20_m_cold': 0.5262375, 'last10_m_cold': 0.48165035, 'scatter_sfr_100': 0.96980095, 'lowest_sfr_100': 0.4912523, 'last20_sfr_100': 0.9742576, 'last10_sfr_100': 0.96982855}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_plbylz
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:27<3:47:39, 27.37s/it]  0%|          | 2/500 [01:11<5:06:37, 36.94s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.45E+07, Train scatter: [0.9354 0.179  0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1876 0.5357 0.9851], Lowest was [0.9198 0.1876 0.5357 0.9851]
Median for last 10 epochs: [0.9198 0.1876 0.5357 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:37<4:27:40, 32.31s/it]  1%|          | 4/500 [02:23<5:10:19, 37.54s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.48E+07, Train scatter: [0.9354 0.1757 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1792 0.5356 0.9851], Lowest was [0.9198 0.1792 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1792 0.5356 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:50<4:37:37, 33.65s/it]  1%|          | 6/500 [03:35<5:09:26, 37.58s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.08E+07, Train scatter: [0.9354 0.164  0.5442 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.1665 0.5356 0.9851], Lowest was [0.9198 0.1665 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1665 0.5356 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:02<4:39:31, 34.02s/it]  2%|▏         | 8/500 [04:47<5:07:56, 37.55s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 9.73E+06, Train scatter: [0.9353 0.1468 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1453 0.5355 0.9847], Lowest was [0.9197 0.1453 0.5355 0.9847]
Median for last 10 epochs: [0.9198 0.1559 0.5356 0.9849], Epochs since improvement 0
  2%|▏         | 9/500 [05:14<4:39:59, 34.21s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.05E+06, Train scatter: [0.9352 0.1355 0.5441 0.7236]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1345 0.5355 0.7181], Lowest was [0.9196 0.1345 0.5355 0.7181]
Median for last 10 epochs: [0.9197 0.1453 0.5355 0.9847], Epochs since improvement 0
  2%|▏         | 10/500 [06:03<5:19:08, 39.08s/it]  2%|▏         | 11/500 [06:30<4:48:15, 35.37s/it]  2%|▏         | 12/500 [07:15<5:09:20, 38.03s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.00E+06, Train scatter: [0.9343 0.1244 0.544  0.6667]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9188 0.1222 0.5355 0.6558], Lowest was [0.9188 0.1222 0.5355 0.6558]
Median for last 10 epochs: [0.9197 0.1453 0.5355 0.9847], Epochs since improvement 0
  3%|▎         | 13/500 [07:41<4:41:17, 34.66s/it]  3%|▎         | 14/500 [08:26<5:04:47, 37.63s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.64E+06, Train scatter: [0.9143 0.1168 0.5439 0.631 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9008 0.1149 0.5353 0.6205], Lowest was [0.9008 0.1149 0.5353 0.6205]
Median for last 10 epochs: [0.9196 0.1345 0.5355 0.7181], Epochs since improvement 0
  3%|▎         | 15/500 [08:53<4:38:05, 34.40s/it]  3%|▎         | 16/500 [09:37<5:01:05, 37.33s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.48E+06, Train scatter: [0.7644 0.1123 0.5421 0.614 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7561 0.1113 0.5338 0.6061], Lowest was [0.7561 0.1113 0.5338 0.6061]
Median for last 10 epochs: [0.9188 0.1222 0.5355 0.6558], Epochs since improvement 0
  3%|▎         | 17/500 [10:04<4:35:01, 34.16s/it]  4%|▎         | 18/500 [10:48<4:58:49, 37.20s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 6.26E+06, Train scatter: [0.5584 0.107  0.5391 0.5967]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5538 0.1069 0.5309 0.5887], Lowest was [0.5538 0.1069 0.5309 0.5887]
Median for last 10 epochs: [0.9008 0.1149 0.5353 0.6205], Epochs since improvement 0
  4%|▍         | 19/500 [11:15<4:33:04, 34.06s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 6.03E+06, Train scatter: [0.5038 0.1024 0.5361 0.5919]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5036 0.1029 0.5279 0.5863], Lowest was [0.5036 0.1029 0.5279 0.5863]
Median for last 10 epochs: [0.7561 0.1113 0.5338 0.6061], Epochs since improvement 0
  4%|▍         | 20/500 [12:04<5:08:37, 38.58s/it]  4%|▍         | 21/500 [12:31<4:39:59, 35.07s/it]  4%|▍         | 22/500 [13:15<5:01:53, 37.89s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.79E+06, Train scatter: [0.4838 0.0983 0.53   0.5779]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4855 0.0988 0.5219 0.5757], Lowest was [0.4855 0.0988 0.5219 0.5757]
Median for last 10 epochs: [0.5538 0.1069 0.5309 0.5887], Epochs since improvement 0
  5%|▍         | 23/500 [13:42<4:35:17, 34.63s/it]  5%|▍         | 24/500 [14:27<4:58:30, 37.63s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 5.45E+06, Train scatter: [0.5171 0.095  0.5168 0.5885]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5054 0.097  0.5093 0.5913], Lowest was [0.4855 0.097  0.5093 0.5757]
Median for last 10 epochs: [0.5054 0.1029 0.5279 0.5887], Epochs since improvement 0
  5%|▌         | 25/500 [14:54<4:32:30, 34.42s/it]  5%|▌         | 26/500 [15:38<4:55:30, 37.41s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.31E+06, Train scatter: [0.4978 0.0967 0.4155 0.5973]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4974 0.0965 0.4106 0.5891], Lowest was [0.4855 0.0965 0.4106 0.5757]
Median for last 10 epochs: [0.5036 0.0988 0.5219 0.5887], Epochs since improvement 0
  5%|▌         | 27/500 [16:05<4:30:06, 34.26s/it]  6%|▌         | 28/500 [16:50<4:53:23, 37.29s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.13E+06, Train scatter: [0.5443 0.0956 0.366  0.5946]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5582 0.0984 0.375  0.6002], Lowest was [0.4855 0.0965 0.375  0.5757]
Median for last 10 epochs: [0.5036 0.0984 0.5093 0.5891], Epochs since improvement 0
  6%|▌         | 29/500 [17:16<4:28:13, 34.17s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.49E+06, Train scatter: [0.4777 0.093  0.3508 0.5844]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4755 0.0964 0.3589 0.5853], Lowest was [0.4755 0.0964 0.3589 0.5757]
Median for last 10 epochs: [0.4974 0.097  0.4106 0.5891], Epochs since improvement 0
  6%|▌         | 30/500 [18:07<5:06:17, 39.10s/it]  6%|▌         | 31/500 [18:34<4:37:12, 35.46s/it]  6%|▋         | 32/500 [19:18<4:57:25, 38.13s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.32E+06, Train scatter: [0.4389 0.0931 0.3378 0.5811]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4464 0.0949 0.3459 0.5746], Lowest was [0.4464 0.0949 0.3459 0.5746]
Median for last 10 epochs: [0.4974 0.0965 0.375  0.5891], Epochs since improvement 0
  7%|▋         | 33/500 [19:45<4:30:32, 34.76s/it]  7%|▋         | 34/500 [20:30<4:53:34, 37.80s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.13E+06, Train scatter: [0.3644 0.0895 0.3403 0.551 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3686 0.0907 0.3489 0.5489], Lowest was [0.3686 0.0907 0.3459 0.5489]
Median for last 10 epochs: [0.4755 0.0964 0.3589 0.5853], Epochs since improvement 0
  7%|▋         | 35/500 [20:57<4:27:42, 34.54s/it]  7%|▋         | 36/500 [21:41<4:49:49, 37.48s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 1.78E+06, Train scatter: [0.3446 0.0889 0.332  0.5703]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3434 0.0902 0.3325 0.5639], Lowest was [0.3434 0.0902 0.3325 0.5489]
Median for last 10 epochs: [0.4464 0.0949 0.3489 0.5746], Epochs since improvement 0
  7%|▋         | 37/500 [22:08<4:24:49, 34.32s/it]  8%|▊         | 38/500 [22:53<4:48:04, 37.41s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.93E+06, Train scatter: [0.3224 0.0872 0.3193 0.5342]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3321 0.0891 0.3273 0.5366], Lowest was [0.3321 0.0891 0.3273 0.5366]
Median for last 10 epochs: [0.3686 0.0907 0.3459 0.5639], Epochs since improvement 0
  8%|▊         | 39/500 [23:20<4:23:18, 34.27s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.69E+06, Train scatter: [0.309  0.0858 0.3124 0.5302]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3148 0.0872 0.3186 0.5313], Lowest was [0.3148 0.0872 0.3186 0.5313]
Median for last 10 epochs: [0.3434 0.0902 0.3325 0.5489], Epochs since improvement 0
  8%|▊         | 40/500 [24:10<4:58:28, 38.93s/it]  8%|▊         | 41/500 [24:37<4:30:33, 35.37s/it]  8%|▊         | 42/500 [25:21<4:51:02, 38.13s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.53E+06, Train scatter: [0.3169 0.0854 0.325  0.5156]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.313  0.0859 0.3354 0.5171], Lowest was [0.313  0.0859 0.3186 0.5171]
Median for last 10 epochs: [0.3321 0.0891 0.3325 0.5366], Epochs since improvement 0
  9%|▊         | 43/500 [25:48<4:24:42, 34.75s/it]  9%|▉         | 44/500 [26:33<4:47:33, 37.84s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.51E+06, Train scatter: [0.33   0.0845 0.3015 0.5146]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.342  0.0858 0.308  0.5112], Lowest was [0.313  0.0858 0.308  0.5112]
Median for last 10 epochs: [0.3321 0.0872 0.3273 0.5313], Epochs since improvement 0
  9%|▉         | 45/500 [27:00<4:21:55, 34.54s/it]  9%|▉         | 46/500 [27:44<4:43:35, 37.48s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.40E+06, Train scatter: [0.2847 0.083  0.3296 0.5171]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4161 0.0851 0.3353 0.5156], Lowest was [0.313  0.0851 0.308  0.5112]
Median for last 10 epochs: [0.3321 0.0859 0.3273 0.5171], Epochs since improvement 0
  9%|▉         | 47/500 [28:11<4:19:09, 34.33s/it] 10%|▉         | 48/500 [28:56<4:42:35, 37.51s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.40E+06, Train scatter: [0.339  0.0835 0.2929 0.5593]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3505 0.0848 0.2976 0.5572], Lowest was [0.313  0.0848 0.2976 0.5112]
Median for last 10 epochs: [0.342  0.0858 0.3186 0.5171], Epochs since improvement 0
 10%|▉         | 49/500 [29:23<4:18:02, 34.33s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.41E+06, Train scatter: [0.3057 0.0821 0.3095 0.52  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.311  0.0842 0.3155 0.517 ], Lowest was [0.311  0.0842 0.2976 0.5112]
Median for last 10 epochs: [0.342  0.0851 0.3155 0.517 ], Epochs since improvement 0
 10%|█         | 50/500 [30:13<4:52:47, 39.04s/it] 10%|█         | 51/500 [30:40<4:25:06, 35.43s/it] 10%|█         | 52/500 [31:25<4:45:41, 38.26s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.34E+06, Train scatter: [0.2953 0.0839 0.3618 0.5323]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2928 0.0854 0.3641 0.5314], Lowest was [0.2928 0.0842 0.2976 0.5112]
Median for last 10 epochs: [0.342  0.0851 0.3155 0.517 ], Epochs since improvement 0
 11%|█         | 53/500 [31:52<4:19:26, 34.83s/it] 11%|█         | 54/500 [32:37<4:41:54, 37.92s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.31E+06, Train scatter: [0.2807 0.0797 0.2861 0.5103]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2842 0.0818 0.2977 0.5128], Lowest was [0.2842 0.0818 0.2976 0.5112]
Median for last 10 epochs: [0.311  0.0848 0.3155 0.517 ], Epochs since improvement 0
 11%|█         | 55/500 [33:04<4:16:48, 34.63s/it] 11%|█         | 56/500 [33:49<4:39:13, 37.73s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.14E+06, Train scatter: [0.296  0.0793 0.3297 0.5066]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.293  0.081  0.3367 0.5047], Lowest was [0.2842 0.081  0.2976 0.5047]
Median for last 10 epochs: [0.293  0.0842 0.3155 0.517 ], Epochs since improvement 0
 11%|█▏        | 57/500 [34:16<4:14:50, 34.52s/it] 12%|█▏        | 58/500 [35:02<4:39:28, 37.94s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.46E+06, Train scatter: [0.2661 0.0787 0.2803 0.4927]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2687 0.0802 0.2911 0.4951], Lowest was [0.2687 0.0802 0.2911 0.4951]
Median for last 10 epochs: [0.2928 0.0818 0.3155 0.5128], Epochs since improvement 0
 12%|█▏        | 59/500 [35:29<4:14:44, 34.66s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.06E+06, Train scatter: [0.2824 0.0772 0.2773 0.49  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2819 0.0789 0.2844 0.4912], Lowest was [0.2687 0.0789 0.2844 0.4912]
Median for last 10 epochs: [0.2842 0.081  0.2977 0.5047], Epochs since improvement 0
 12%|█▏        | 60/500 [36:19<4:48:03, 39.28s/it] 12%|█▏        | 61/500 [36:46<4:20:05, 35.55s/it] 12%|█▏        | 62/500 [37:31<4:40:15, 38.39s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.14E+06, Train scatter: [0.2943 0.0769 0.2738 0.4893]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2958 0.0786 0.2831 0.4902], Lowest was [0.2687 0.0786 0.2831 0.4902]
Median for last 10 epochs: [0.2842 0.0802 0.2911 0.4951], Epochs since improvement 0
 13%|█▎        | 63/500 [37:58<4:14:20, 34.92s/it] 13%|█▎        | 64/500 [38:43<4:35:48, 37.95s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 9.29E+05, Train scatter: [0.3007 0.0749 0.3097 0.5265]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3022 0.0761 0.32   0.5211], Lowest was [0.2687 0.0761 0.2831 0.4902]
Median for last 10 epochs: [0.293  0.0789 0.2911 0.4951], Epochs since improvement 0
 13%|█▎        | 65/500 [39:10<4:11:12, 34.65s/it] 13%|█▎        | 66/500 [39:55<4:33:23, 37.80s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.18E+06, Train scatter: [0.2995 0.0756 0.2781 0.8799]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2928 0.0768 0.2832 0.8703], Lowest was [0.2687 0.0761 0.2831 0.4902]
Median for last 10 epochs: [0.2928 0.0786 0.2844 0.4951], Epochs since improvement 2
 13%|█▎        | 67/500 [40:22<4:09:18, 34.55s/it] 14%|█▎        | 68/500 [41:08<4:33:02, 37.92s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 8.84E+05, Train scatter: [0.3368 0.0768 0.3281 0.5553]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3392 0.079  0.341  0.5604], Lowest was [0.2687 0.0761 0.2831 0.4902]
Median for last 10 epochs: [0.2958 0.0786 0.2844 0.5211], Epochs since improvement 4
 14%|█▍        | 69/500 [41:35<4:08:53, 34.65s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 7.84E+05, Train scatter: [0.2693 0.0755 0.2821 0.5942]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2738 0.0761 0.2951 0.6029], Lowest was [0.2687 0.0761 0.2831 0.4902]
Median for last 10 epochs: [0.2958 0.0768 0.2951 0.5604], Epochs since improvement 6
 14%|█▍        | 70/500 [42:25<4:42:13, 39.38s/it] 14%|█▍        | 71/500 [42:52<4:14:43, 35.63s/it] 14%|█▍        | 72/500 [43:37<4:33:59, 38.41s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 7.10E+05, Train scatter: [0.2574 0.0746 0.3125 0.5374]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.26   0.0772 0.3209 0.5365], Lowest was [0.26   0.0761 0.2831 0.4902]
Median for last 10 epochs: [0.2928 0.0768 0.32   0.5604], Epochs since improvement 0
 15%|█▍        | 73/500 [44:04<4:08:55, 34.98s/it] 15%|█▍        | 74/500 [44:49<4:29:29, 37.96s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 5.59E+05, Train scatter: [0.2855 0.0721 0.3122 0.5131]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2854 0.0739 0.3154 0.512 ], Lowest was [0.26   0.0739 0.2831 0.4902]
Median for last 10 epochs: [0.2854 0.0768 0.3154 0.5604], Epochs since improvement 0
 15%|█▌        | 75/500 [45:16<4:05:09, 34.61s/it] 15%|█▌        | 76/500 [46:01<4:26:51, 37.76s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 4.85E+05, Train scatter: [0.2491 0.0715 0.2618 0.5077]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.252  0.0734 0.2713 0.5092], Lowest was [0.252  0.0734 0.2713 0.4902]
Median for last 10 epochs: [0.2738 0.0761 0.3154 0.5365], Epochs since improvement 0
 15%|█▌        | 77/500 [46:28<4:03:15, 34.50s/it] 16%|█▌        | 78/500 [47:13<4:25:56, 37.81s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 4.73E+05, Train scatter: [0.246  0.0704 0.2621 0.4984]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2498 0.0719 0.2721 0.4972], Lowest was [0.2498 0.0719 0.2713 0.4902]
Median for last 10 epochs: [0.26   0.0739 0.2951 0.512 ], Epochs since improvement 0
 16%|█▌        | 79/500 [47:40<4:02:14, 34.52s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 5.19E+05, Train scatter: [0.2484 0.0692 0.2734 0.4981]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2527 0.0715 0.2865 0.4973], Lowest was [0.2498 0.0715 0.2713 0.4902]
Median for last 10 epochs: [0.2527 0.0734 0.2865 0.5092], Epochs since improvement 0
 16%|█▌        | 80/500 [48:31<4:35:53, 39.41s/it] 16%|█▌        | 81/500 [48:58<4:09:07, 35.67s/it] 16%|█▋        | 82/500 [49:42<4:27:38, 38.42s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 3.93E+05, Train scatter: [0.2698 0.0702 0.2718 0.5078]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2721 0.072  0.2792 0.5087], Lowest was [0.2498 0.0715 0.2713 0.4902]
Median for last 10 epochs: [0.2527 0.072  0.2792 0.5087], Epochs since improvement 2
 17%|█▋        | 83/500 [50:09<4:03:05, 34.98s/it] 17%|█▋        | 84/500 [50:54<4:23:18, 37.98s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 3.46E+05, Train scatter: [0.2386 0.0682 0.2615 0.486 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2469 0.0699 0.2705 0.4854], Lowest was [0.2469 0.0699 0.2705 0.4854]
Median for last 10 epochs: [0.252  0.0719 0.2721 0.4973], Epochs since improvement 0
 17%|█▋        | 85/500 [51:21<3:59:29, 34.62s/it] 17%|█▋        | 86/500 [52:07<4:22:10, 38.00s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 3.19E+05, Train scatter: [0.2508 0.0692 0.2599 0.6216]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2562 0.0712 0.2702 0.6141], Lowest was [0.2469 0.0699 0.2702 0.4854]
Median for last 10 epochs: [0.2527 0.0715 0.2721 0.4973], Epochs since improvement 0
 17%|█▋        | 87/500 [52:34<3:58:51, 34.70s/it] 18%|█▊        | 88/500 [53:20<4:20:44, 37.97s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 3.16E+05, Train scatter: [0.2761 0.0678 0.2657 0.4981]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2742 0.0697 0.2776 0.4999], Lowest was [0.2469 0.0697 0.2702 0.4854]
Median for last 10 epochs: [0.2562 0.0712 0.2776 0.4999], Epochs since improvement 0
 18%|█▊        | 89/500 [53:47<3:57:14, 34.63s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 1.99E+05, Train scatter: [0.2376 0.0658 0.2593 0.4937]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.242  0.0671 0.2706 0.4963], Lowest was [0.242  0.0671 0.2702 0.4854]
Median for last 10 epochs: [0.2562 0.0699 0.2706 0.4999], Epochs since improvement 0
 18%|█▊        | 90/500 [54:38<4:31:45, 39.77s/it] 18%|█▊        | 91/500 [55:05<4:05:09, 35.96s/it] 18%|█▊        | 92/500 [55:50<4:21:43, 38.49s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.02E+05, Train scatter: [0.2584 0.0646 0.2628 0.4898]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.261  0.0663 0.2729 0.4892], Lowest was [0.242  0.0663 0.2702 0.4854]
Median for last 10 epochs: [0.2562 0.0697 0.2706 0.4963], Epochs since improvement 0
 19%|█▊        | 93/500 [56:17<3:57:28, 35.01s/it] 19%|█▉        | 94/500 [57:02<4:17:28, 38.05s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 1.30E+05, Train scatter: [0.2306 0.0672 0.2562 0.4812]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2356 0.0689 0.2662 0.482 ], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.2562 0.0689 0.2706 0.4963], Epochs since improvement 0
 19%|█▉        | 95/500 [57:29<3:54:31, 34.74s/it] 19%|█▉        | 96/500 [58:14<4:14:39, 37.82s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 8.17E+06, Train scatter: [0.9266 0.1682 0.5438 0.9783]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9114 0.1647 0.5353 0.97  ], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.261  0.0689 0.2729 0.4963], Epochs since improvement 2
 19%|█▉        | 97/500 [58:41<3:52:05, 34.56s/it] 20%|█▉        | 98/500 [59:26<4:12:30, 37.69s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 1.78E+06, Train scatter: [0.9217 0.1543 0.5413 0.9505]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.906  0.1516 0.533  0.9427], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.261  0.0689 0.2729 0.4963], Epochs since improvement 4
 20%|█▉        | 99/500 [59:53<3:50:26, 34.48s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 1.18E+06, Train scatter: [0.9195 0.1429 0.5367 0.9506]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9043 0.1428 0.5287 0.9425], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.9043 0.1428 0.5287 0.9425], Epochs since improvement 6
 20%|██        | 100/500 [1:00:43<4:21:07, 39.17s/it] 20%|██        | 101/500 [1:01:10<3:56:07, 35.51s/it] 20%|██        | 102/500 [1:01:55<4:14:30, 38.37s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 9.26E+05, Train scatter: [0.9181 0.1385 0.5158 0.9493]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9029 0.1395 0.5091 0.9407], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.9043 0.1428 0.5287 0.9425], Epochs since improvement 8
 21%|██        | 103/500 [1:02:22<3:50:59, 34.91s/it] 21%|██        | 104/500 [1:03:07<4:10:16, 37.92s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 7.61E+05, Train scatter: [0.9164 0.134  0.5104 0.9457]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9013 0.1347 0.505  0.9365], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.9043 0.1428 0.5287 0.9425], Epochs since improvement 10
 21%|██        | 105/500 [1:03:34<3:47:53, 34.62s/it] 21%|██        | 106/500 [1:04:19<4:09:26, 37.99s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 6.43E+05, Train scatter: [0.9151 0.1293 0.5001 0.9395]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8997 0.1294 0.4938 0.9296], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.9029 0.1395 0.5091 0.9407], Epochs since improvement 12
 21%|██▏       | 107/500 [1:04:46<3:47:14, 34.69s/it] 22%|██▏       | 108/500 [1:05:32<4:07:02, 37.81s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 5.41E+05, Train scatter: [0.9135 0.1266 0.4974 0.929 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8979 0.1277 0.4915 0.919 ], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.9013 0.1347 0.505  0.9365], Epochs since improvement 14
 22%|██▏       | 109/500 [1:05:58<3:45:03, 34.54s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 4.50E+05, Train scatter: [0.9113 0.1222 0.4922 0.9083]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8956 0.1236 0.4898 0.8992], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.8997 0.1294 0.4938 0.9296], Epochs since improvement 16
 22%|██▏       | 110/500 [1:06:49<4:15:08, 39.25s/it] 22%|██▏       | 111/500 [1:07:16<3:50:38, 35.58s/it] 22%|██▏       | 112/500 [1:08:01<4:09:04, 38.52s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 3.77E+05, Train scatter: [0.9079 0.1199 0.4885 0.8632]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8921 0.1207 0.4862 0.8581], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.8979 0.1277 0.4915 0.919 ], Epochs since improvement 18
 23%|██▎       | 113/500 [1:08:28<3:45:56, 35.03s/it] 23%|██▎       | 114/500 [1:09:13<4:04:39, 38.03s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 3.01E+05, Train scatter: [0.903  0.1167 0.4613 0.807 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8874 0.1193 0.4637 0.8135], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.8956 0.1236 0.4898 0.8992], Epochs since improvement 20
 23%|██▎       | 115/500 [1:09:40<3:42:52, 34.73s/it] 23%|██▎       | 115/500 [1:10:25<3:55:46, 36.74s/it]
Epoch: 116 done with learning rate 9.77E-03, Train loss: 2.37E+05, Train scatter: [0.8968 0.1126 0.4806 0.7753]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8813 0.1149 0.4808 0.7865], Lowest was [0.2356 0.0663 0.2662 0.482 ]
Median for last 10 epochs: [0.8921 0.1207 0.4862 0.8581], Epochs since improvement 22
Exited after 116 epochs due to early stopping
4225.61 seconds spent training, 8.451 seconds per epoch. Processed 8240 trees per second
[0.8813108  0.11492895 0.48082924 0.7864335 ]
{'epoch_exit': 115, 'scatter_m_star': 0.8813108, 'lowest_m_star': 0.23563191, 'last20_m_star': 0.8988141, 'last10_m_star': 0.89208305, 'scatter_v_disk': 0.114928946, 'lowest_v_disk': 0.066259146, 'last20_v_disk': 0.12854913, 'last10_v_disk': 0.12074363, 'scatter_m_cold': 0.48082924, 'lowest_m_cold': 0.26615876, 'last20_m_cold': 0.492613, 'last10_m_cold': 0.486233, 'scatter_sfr_100': 0.7864335, 'lowest_sfr_100': 0.4819957, 'last20_sfr_100': 0.9243071, 'last10_sfr_100': 0.85806894}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_scwnds
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:46<6:27:24, 46.58s/it]  0%|          | 2/500 [01:55<8:16:30, 59.82s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.47E+07, Train scatter: [0.9352 0.1517 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1478 0.5356 0.9851], Lowest was [0.9196 0.1478 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1478 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:41<7:22:05, 53.37s/it]  1%|          | 4/500 [03:50<8:13:31, 59.70s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.65E+07, Train scatter: [0.9337 0.1006 0.5441 0.9945]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9181 0.0995 0.5355 0.9841], Lowest was [0.9181 0.0995 0.5355 0.9841]
Median for last 10 epochs: [0.9181 0.0995 0.5355 0.9841], Epochs since improvement 0
  1%|          | 5/500 [04:36<7:31:25, 54.72s/it]  1%|          | 6/500 [05:45<8:11:16, 59.67s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.09E+07, Train scatter: [0.7429 0.0964 0.544  0.6681]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7362 0.0963 0.5354 0.6656], Lowest was [0.7362 0.0963 0.5354 0.6656]
Median for last 10 epochs: [0.7362 0.0963 0.5354 0.6656], Epochs since improvement 0
  1%|▏         | 7/500 [06:31<7:33:37, 55.21s/it]  2%|▏         | 8/500 [07:41<8:09:08, 59.65s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 6.96E+06, Train scatter: [0.4925 0.0855 0.544  0.5782]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4918 0.0852 0.5354 0.5697], Lowest was [0.4918 0.0852 0.5354 0.5697]
Median for last 10 epochs: [0.614  0.0907 0.5354 0.6177], Epochs since improvement 0
  2%|▏         | 9/500 [08:26<7:32:13, 55.26s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 5.41E+06, Train scatter: [0.3107 0.0802 0.544  0.5514]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3152 0.0799 0.5354 0.5434], Lowest was [0.3152 0.0799 0.5354 0.5434]
Median for last 10 epochs: [0.4918 0.0852 0.5354 0.5697], Epochs since improvement 0
  2%|▏         | 10/500 [09:42<8:23:14, 61.62s/it]  2%|▏         | 11/500 [10:28<7:42:37, 56.76s/it]  2%|▏         | 12/500 [11:37<8:11:15, 60.40s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 4.89E+06, Train scatter: [0.3027 0.0777 0.544  0.5284]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3072 0.0783 0.5354 0.5241], Lowest was [0.3072 0.0783 0.5354 0.5241]
Median for last 10 epochs: [0.4918 0.0852 0.5354 0.5697], Epochs since improvement 0
  3%|▎         | 13/500 [12:22<7:34:04, 55.94s/it]  3%|▎         | 14/500 [13:32<8:06:40, 60.08s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 4.68E+06, Train scatter: [0.2916 0.0745 0.5439 0.5232]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2932 0.0751 0.5354 0.5212], Lowest was [0.2932 0.0751 0.5354 0.5212]
Median for last 10 epochs: [0.3152 0.0799 0.5354 0.5434], Epochs since improvement 0
  3%|▎         | 15/500 [14:18<7:30:35, 55.74s/it]  3%|▎         | 16/500 [15:27<8:02:44, 59.84s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.66E+06, Train scatter: [0.3391 0.0726 0.5439 0.5292]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3406 0.0731 0.5353 0.5286], Lowest was [0.2932 0.0731 0.5353 0.5212]
Median for last 10 epochs: [0.3152 0.0783 0.5354 0.5286], Epochs since improvement 0
  3%|▎         | 17/500 [16:13<7:27:23, 55.58s/it]  4%|▎         | 18/500 [17:22<7:59:49, 59.73s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.55E+06, Train scatter: [0.2274 0.0703 0.5439 0.5061]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2333 0.0708 0.5353 0.5021], Lowest was [0.2333 0.0708 0.5353 0.5021]
Median for last 10 epochs: [0.3072 0.0751 0.5354 0.5241], Epochs since improvement 0
  4%|▍         | 19/500 [18:08<7:24:42, 55.47s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 4.50E+06, Train scatter: [0.2157 0.0681 0.5439 0.5215]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.22   0.0687 0.5353 0.5225], Lowest was [0.22   0.0687 0.5353 0.5021]
Median for last 10 epochs: [0.2932 0.0731 0.5353 0.5225], Epochs since improvement 0
  4%|▍         | 20/500 [19:23<8:12:15, 61.53s/it]  4%|▍         | 21/500 [20:09<7:33:33, 56.81s/it]  4%|▍         | 22/500 [21:19<8:03:25, 60.68s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.47E+06, Train scatter: [0.208  0.0672 0.5438 0.5144]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2139 0.0677 0.5352 0.5114], Lowest was [0.2139 0.0677 0.5352 0.5021]
Median for last 10 epochs: [0.2333 0.0708 0.5353 0.5212], Epochs since improvement 0
  5%|▍         | 23/500 [22:04<7:26:38, 56.18s/it]  5%|▍         | 24/500 [23:14<7:57:48, 60.23s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.41E+06, Train scatter: [0.2309 0.0663 0.5437 0.5231]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2357 0.0665 0.5352 0.5172], Lowest was [0.2139 0.0665 0.5352 0.5021]
Median for last 10 epochs: [0.2333 0.0687 0.5353 0.5172], Epochs since improvement 0
  5%|▌         | 25/500 [24:00<7:22:33, 55.90s/it]  5%|▌         | 26/500 [25:09<7:52:38, 59.83s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.85E+06, Train scatter: [0.2286 0.0662 0.5438 0.5078]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2302 0.0658 0.5352 0.4996], Lowest was [0.2139 0.0658 0.5352 0.4996]
Median for last 10 epochs: [0.2302 0.0677 0.5352 0.5114], Epochs since improvement 0
  5%|▌         | 27/500 [25:55<7:18:17, 55.60s/it]  6%|▌         | 28/500 [27:04<7:49:18, 59.66s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.64E+06, Train scatter: [0.2059 0.0664 0.5437 0.506 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2096 0.0662 0.5351 0.5009], Lowest was [0.2096 0.0658 0.5351 0.4996]
Median for last 10 epochs: [0.22   0.0665 0.5352 0.5114], Epochs since improvement 0
  6%|▌         | 29/500 [27:49<7:15:36, 55.49s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.64E+06, Train scatter: [0.2054 0.0632 0.5437 0.5065]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2164 0.0633 0.5351 0.5021], Lowest was [0.2096 0.0633 0.5351 0.4996]
Median for last 10 epochs: [0.2164 0.0662 0.5352 0.5021], Epochs since improvement 0
  6%|▌         | 30/500 [29:05<8:01:49, 61.51s/it]  6%|▌         | 31/500 [29:51<7:23:49, 56.78s/it]  6%|▋         | 32/500 [31:01<7:53:30, 60.71s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.41E+06, Train scatter: [0.2767 0.0718 0.5437 0.5088]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2761 0.0713 0.5351 0.4997], Lowest was [0.2096 0.0633 0.5351 0.4996]
Median for last 10 epochs: [0.2302 0.0662 0.5351 0.5009], Epochs since improvement 0
  7%|▋         | 33/500 [31:46<7:17:38, 56.23s/it]  7%|▋         | 34/500 [32:56<7:47:14, 60.16s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.39E+06, Train scatter: [0.2158 0.0651 0.5435 0.4994]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2205 0.0646 0.535  0.491 ], Lowest was [0.2096 0.0633 0.535  0.491 ]
Median for last 10 epochs: [0.2205 0.0658 0.5351 0.4997], Epochs since improvement 0
  7%|▋         | 35/500 [33:41<7:12:40, 55.83s/it]  7%|▋         | 36/500 [34:50<7:41:26, 59.67s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.40E+06, Train scatter: [0.4147 0.0654 0.5434 0.5037]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4049 0.0647 0.5349 0.4993], Lowest was [0.2096 0.0633 0.5349 0.491 ]
Median for last 10 epochs: [0.2205 0.0647 0.5351 0.4997], Epochs since improvement 0
  7%|▋         | 37/500 [35:36<7:07:53, 55.45s/it]  8%|▊         | 38/500 [36:45<7:38:27, 59.54s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.27E+06, Train scatter: [0.4617 0.0672 0.5435 0.5105]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.453  0.0663 0.5349 0.5038], Lowest was [0.2096 0.0633 0.5349 0.491 ]
Median for last 10 epochs: [0.2761 0.0647 0.535  0.4997], Epochs since improvement 2
  8%|▊         | 39/500 [37:30<7:05:25, 55.37s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.29E+06, Train scatter: [0.4679 0.0701 0.5434 0.4923]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4615 0.0694 0.5348 0.4841], Lowest was [0.2096 0.0633 0.5348 0.4841]
Median for last 10 epochs: [0.4049 0.0663 0.5349 0.4993], Epochs since improvement 0
  8%|▊         | 40/500 [38:46<7:51:00, 61.44s/it]  8%|▊         | 41/500 [39:32<7:14:33, 56.80s/it]  8%|▊         | 42/500 [40:41<7:42:16, 60.56s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.23E+06, Train scatter: [0.2681 0.0704 0.5432 0.5127]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2672 0.0695 0.5347 0.5076], Lowest was [0.2096 0.0633 0.5347 0.4841]
Median for last 10 epochs: [0.4049 0.0663 0.5349 0.4993], Epochs since improvement 0
  9%|▊         | 43/500 [41:27<7:07:50, 56.17s/it]  9%|▉         | 44/500 [42:37<7:38:29, 60.33s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.23E+06, Train scatter: [0.2553 0.0747 0.543  0.4995]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2539 0.0746 0.5345 0.4978], Lowest was [0.2096 0.0633 0.5345 0.4841]
Median for last 10 epochs: [0.4049 0.0694 0.5348 0.4993], Epochs since improvement 0
  9%|▉         | 45/500 [43:23<7:04:22, 55.96s/it]  9%|▉         | 46/500 [44:32<7:32:38, 59.82s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.94E+06, Train scatter: [0.2392 0.0688 0.5431 0.5006]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2519 0.0687 0.5346 0.4965], Lowest was [0.2096 0.0633 0.5345 0.4841]
Median for last 10 epochs: [0.2672 0.0694 0.5347 0.4978], Epochs since improvement 2
  9%|▉         | 47/500 [45:18<6:59:24, 55.55s/it] 10%|▉         | 48/500 [46:26<7:28:16, 59.50s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.92E+06, Train scatter: [0.3035 0.0692 0.5426 0.5048]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3115 0.0688 0.5341 0.5016], Lowest was [0.2096 0.0633 0.5341 0.4841]
Median for last 10 epochs: [0.2672 0.0694 0.5346 0.4978], Epochs since improvement 0
 10%|▉         | 49/500 [47:12<6:55:53, 55.33s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.88E+06, Train scatter: [0.2932 0.0642 0.5379 0.4915]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2887 0.0646 0.5294 0.4878], Lowest was [0.2096 0.0633 0.5294 0.4841]
Median for last 10 epochs: [0.2672 0.0688 0.5345 0.4978], Epochs since improvement 0
 10%|█         | 50/500 [48:27<7:39:33, 61.27s/it] 10%|█         | 51/500 [49:13<7:03:32, 56.60s/it] 10%|█         | 52/500 [50:22<7:31:31, 60.47s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.08E+06, Train scatter: [0.7359 0.1188 0.5406 0.9294]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7323 0.1179 0.5321 0.9223], Lowest was [0.2096 0.0633 0.5294 0.4841]
Median for last 10 epochs: [0.2887 0.0688 0.5341 0.4978], Epochs since improvement 2
 11%|█         | 53/500 [51:08<6:57:29, 56.04s/it] 11%|█         | 54/500 [52:16<7:24:22, 59.78s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.47E+06, Train scatter: [0.5795 0.1125 0.544  0.8394]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5751 0.1105 0.5355 0.8334], Lowest was [0.2096 0.0633 0.5294 0.4841]
Median for last 10 epochs: [0.3115 0.0688 0.5341 0.5016], Epochs since improvement 4
 11%|█         | 55/500 [53:02<6:52:06, 55.57s/it] 11%|█         | 56/500 [54:12<7:21:55, 59.72s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.38E+06, Train scatter: [0.4894 0.0993 0.5439 0.6401]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4788 0.0972 0.5353 0.6332], Lowest was [0.2096 0.0633 0.5294 0.4841]
Median for last 10 epochs: [0.4788 0.0972 0.5341 0.6332], Epochs since improvement 6
 11%|█▏        | 57/500 [54:57<6:50:06, 55.54s/it] 12%|█▏        | 58/500 [56:07<7:20:26, 59.79s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.33E+06, Train scatter: [0.4951 0.0945 0.5438 0.6073]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4839 0.0929 0.5352 0.5992], Lowest was [0.2096 0.0633 0.5294 0.4841]
Median for last 10 epochs: [0.4839 0.0972 0.5352 0.6332], Epochs since improvement 8
 12%|█▏        | 59/500 [56:53<6:48:29, 55.58s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.36E+06, Train scatter: [0.9212 0.1233 0.544  0.7484]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9063 0.1219 0.5354 0.7435], Lowest was [0.2096 0.0633 0.5294 0.4841]
Median for last 10 epochs: [0.5751 0.1105 0.5353 0.7435], Epochs since improvement 10
 12%|█▏        | 60/500 [58:09<7:31:59, 61.63s/it] 12%|█▏        | 61/500 [58:54<6:56:04, 56.87s/it] 12%|█▏        | 62/500 [1:00:04<7:23:12, 60.71s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.35E+06, Train scatter: [0.9048 0.1056 0.5439 0.6989]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8908 0.1047 0.5353 0.6935], Lowest was [0.2096 0.0633 0.5294 0.4841]
Median for last 10 epochs: [0.5751 0.1047 0.5353 0.6935], Epochs since improvement 12
 13%|█▎        | 63/500 [1:00:50<6:49:19, 56.20s/it] 13%|█▎        | 64/500 [1:01:58<7:14:58, 59.86s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.31E+06, Train scatter: [0.7704 0.1001 0.5436 0.6737]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7607 0.0996 0.5351 0.6739], Lowest was [0.2096 0.0633 0.5294 0.4841]
Median for last 10 epochs: [0.7607 0.0996 0.5353 0.6739], Epochs since improvement 14
 13%|█▎        | 65/500 [1:02:44<6:43:17, 55.63s/it] 13%|█▎        | 66/500 [1:03:52<7:10:09, 59.47s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.12E+06, Train scatter: [0.5137 0.1003 0.5411 0.6705]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5149 0.0983 0.5325 0.6605], Lowest was [0.2096 0.0633 0.5294 0.4841]
Median for last 10 epochs: [0.7607 0.0996 0.5352 0.6739], Epochs since improvement 16
 13%|█▎        | 67/500 [1:04:38<6:39:12, 55.32s/it] 14%|█▎        | 68/500 [1:05:47<7:08:05, 59.46s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.01E+06, Train scatter: [0.4775 0.0822 0.5339 0.5857]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4605 0.0812 0.5256 0.5769], Lowest was [0.2096 0.0633 0.5256 0.4841]
Median for last 10 epochs: [0.7607 0.0996 0.5351 0.6739], Epochs since improvement 0
 14%|█▍        | 69/500 [1:06:33<6:37:40, 55.36s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.97E+06, Train scatter: [0.4739 0.091  0.5364 0.6147]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4811 0.0915 0.5281 0.6096], Lowest was [0.2096 0.0633 0.5256 0.4841]
Median for last 10 epochs: [0.5149 0.0983 0.5325 0.6605], Epochs since improvement 2
 14%|█▍        | 70/500 [1:07:49<7:21:00, 61.54s/it] 14%|█▍        | 71/500 [1:08:34<6:46:09, 56.81s/it] 14%|█▍        | 72/500 [1:09:43<7:10:34, 60.36s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 2.87E+06, Train scatter: [0.4591 0.077  0.5256 0.5548]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.442  0.0776 0.5178 0.5517], Lowest was [0.2096 0.0633 0.5178 0.4841]
Median for last 10 epochs: [0.4811 0.0915 0.5281 0.6096], Epochs since improvement 0
 15%|█▍        | 73/500 [1:10:29<6:38:21, 55.97s/it] 15%|█▍        | 74/500 [1:11:38<7:06:02, 60.01s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.01E+06, Train scatter: [0.6811 0.0906 0.542  0.6783]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6517 0.0876 0.5335 0.667 ], Lowest was [0.2096 0.0633 0.5178 0.4841]
Median for last 10 epochs: [0.4811 0.0876 0.5281 0.6096], Epochs since improvement 2
 15%|█▌        | 75/500 [1:12:24<6:34:38, 55.71s/it] 15%|█▌        | 76/500 [1:13:33<7:02:17, 59.76s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.92E+06, Train scatter: [0.8569 0.078  0.537  0.5825]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8414 0.0785 0.5285 0.577 ], Lowest was [0.2096 0.0633 0.5178 0.4841]
Median for last 10 epochs: [0.4811 0.0812 0.5281 0.577 ], Epochs since improvement 4
 15%|█▌        | 77/500 [1:14:19<6:31:22, 55.52s/it] 16%|█▌        | 78/500 [1:15:28<6:58:33, 59.51s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.72E+06, Train scatter: [0.5625 0.0771 0.5182 0.5804]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5379 0.0756 0.5103 0.5734], Lowest was [0.2096 0.0633 0.5103 0.4841]
Median for last 10 epochs: [0.5379 0.0785 0.5281 0.577 ], Epochs since improvement 0
 16%|█▌        | 79/500 [1:16:13<6:28:17, 55.34s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 1.41E+06, Train scatter: [0.4649 0.0764 0.3824 0.5805]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4649 0.0774 0.3843 0.5839], Lowest was [0.2096 0.0633 0.3843 0.4841]
Median for last 10 epochs: [0.5379 0.0776 0.5178 0.577 ], Epochs since improvement 0
 16%|█▌        | 80/500 [1:17:29<7:10:00, 61.43s/it] 16%|█▌        | 81/500 [1:18:15<6:36:12, 56.74s/it] 16%|█▋        | 82/500 [1:19:24<7:02:07, 60.59s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 8.70E+05, Train scatter: [0.3303 0.0689 0.3428 0.5499]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3367 0.0703 0.3492 0.5454], Lowest was [0.2096 0.0633 0.3492 0.4841]
Median for last 10 epochs: [0.5379 0.0774 0.5103 0.577 ], Epochs since improvement 0
 17%|█▋        | 83/500 [1:20:10<6:29:53, 56.10s/it] 17%|█▋        | 84/500 [1:21:19<6:55:01, 59.86s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 6.76E+05, Train scatter: [0.3985 0.0646 0.311  0.527 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3765 0.0665 0.3217 0.529 ], Lowest was [0.2096 0.0633 0.3217 0.4841]
Median for last 10 epochs: [0.4649 0.0756 0.3843 0.5734], Epochs since improvement 0
 17%|█▋        | 85/500 [1:22:04<6:24:19, 55.56s/it] 17%|█▋        | 86/500 [1:23:13<6:50:26, 59.49s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 5.89E+05, Train scatter: [0.3804 0.0618 0.3025 0.5245]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3866 0.0632 0.3044 0.5238], Lowest was [0.2096 0.0632 0.3044 0.4841]
Median for last 10 epochs: [0.3866 0.0703 0.3492 0.5454], Epochs since improvement 0
 17%|█▋        | 87/500 [1:23:58<6:21:11, 55.38s/it] 18%|█▊        | 88/500 [1:25:07<6:47:50, 59.39s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 4.78E+05, Train scatter: [0.2978 0.0611 0.2701 0.5229]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2937 0.0615 0.278  0.5181], Lowest was [0.2096 0.0615 0.278  0.4841]
Median for last 10 epochs: [0.3765 0.0665 0.3217 0.529 ], Epochs since improvement 0
 18%|█▊        | 89/500 [1:25:53<6:18:34, 55.27s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 4.85E+05, Train scatter: [0.4712 0.0685 0.292  0.5121]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4658 0.0699 0.299  0.51  ], Lowest was [0.2096 0.0615 0.278  0.4841]
Median for last 10 epochs: [0.3765 0.0665 0.3044 0.5238], Epochs since improvement 2
 18%|█▊        | 90/500 [1:27:08<6:57:49, 61.15s/it] 18%|█▊        | 91/500 [1:27:53<6:25:05, 56.49s/it] 18%|█▊        | 92/500 [1:29:03<6:50:38, 60.39s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 3.71E+05, Train scatter: [0.305  0.0562 0.2603 0.5082]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.317  0.0582 0.2699 0.5116], Lowest was [0.2096 0.0582 0.2699 0.4841]
Median for last 10 epochs: [0.3765 0.0632 0.299  0.5181], Epochs since improvement 0
 19%|█▊        | 93/500 [1:29:49<6:20:15, 56.06s/it] 19%|█▉        | 94/500 [1:30:58<6:46:41, 60.10s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 3.45E+05, Train scatter: [0.2623 0.0553 0.2605 0.5082]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2723 0.0567 0.2698 0.5126], Lowest was [0.2096 0.0567 0.2698 0.4841]
Median for last 10 epochs: [0.317  0.0615 0.278  0.5126], Epochs since improvement 0
 19%|█▉        | 95/500 [1:31:44<6:17:00, 55.85s/it] 19%|█▉        | 96/500 [1:32:54<6:43:10, 59.88s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 3.72E+05, Train scatter: [0.2819 0.0597 0.3138 0.5079]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2794 0.0574 0.3112 0.4946], Lowest was [0.2096 0.0567 0.2698 0.4841]
Median for last 10 epochs: [0.2937 0.0582 0.278  0.5116], Epochs since improvement 2
 19%|█▉        | 97/500 [1:33:39<6:13:48, 55.65s/it] 20%|█▉        | 98/500 [1:34:48<6:40:00, 59.70s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.93E+05, Train scatter: [0.2894 0.0634 0.2708 0.4937]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2841 0.0627 0.2734 0.4865], Lowest was [0.2096 0.0567 0.2698 0.4841]
Median for last 10 epochs: [0.2841 0.0582 0.2734 0.51  ], Epochs since improvement 4
 20%|█▉        | 99/500 [1:35:35<6:11:54, 55.65s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 9.60E+05, Train scatter: [0.2254 0.0535 0.268  0.4828]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2292 0.0531 0.275  0.4766], Lowest was [0.2096 0.0531 0.2698 0.4766]
Median for last 10 epochs: [0.2794 0.0574 0.2734 0.4946], Epochs since improvement 0
 20%|██        | 100/500 [1:36:51<6:51:46, 61.77s/it] 20%|██        | 101/500 [1:37:37<6:19:24, 57.05s/it] 20%|██        | 102/500 [1:38:47<6:43:41, 60.86s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 3.45E+05, Train scatter: [0.2233 0.0518 0.25   0.481 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2289 0.0524 0.2565 0.4749], Lowest was [0.2096 0.0524 0.2565 0.4749]
Median for last 10 epochs: [0.2723 0.0567 0.2734 0.4865], Epochs since improvement 0
 21%|██        | 103/500 [1:39:33<6:13:15, 56.41s/it] 21%|██        | 104/500 [1:40:42<6:37:25, 60.22s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 1.14E+06, Train scatter: [0.8081 0.121  0.4747 0.7005]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7948 0.1167 0.4659 0.6814], Lowest was [0.2096 0.0524 0.2565 0.4749]
Median for last 10 epochs: [0.2794 0.0574 0.275  0.4865], Epochs since improvement 2
 21%|██        | 105/500 [1:41:28<6:08:10, 55.93s/it] 21%|██        | 106/500 [1:42:37<6:33:14, 59.89s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 1.29E+06, Train scatter: [0.4742 0.0898 0.3167 0.5581]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4764 0.0892 0.3179 0.5606], Lowest was [0.2096 0.0524 0.2565 0.4749]
Median for last 10 epochs: [0.2841 0.0627 0.275  0.4865], Epochs since improvement 4
 21%|██▏       | 107/500 [1:43:22<6:04:33, 55.66s/it] 22%|██▏       | 108/500 [1:44:32<6:30:41, 59.80s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 5.46E+05, Train scatter: [0.3633 0.0694 0.2633 0.5014]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3516 0.0676 0.2688 0.4954], Lowest was [0.2096 0.0524 0.2565 0.4749]
Median for last 10 epochs: [0.3516 0.0676 0.275  0.4954], Epochs since improvement 6
 22%|██▏       | 109/500 [1:45:18<6:02:34, 55.64s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 3.97E+05, Train scatter: [0.4406 0.0686 0.2538 0.5064]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4328 0.0679 0.2607 0.498 ], Lowest was [0.2096 0.0524 0.2565 0.4749]
Median for last 10 epochs: [0.4328 0.0679 0.2688 0.498 ], Epochs since improvement 8
 22%|██▏       | 110/500 [1:46:33<6:40:01, 61.54s/it] 22%|██▏       | 111/500 [1:47:19<6:08:58, 56.91s/it] 22%|██▏       | 112/500 [1:48:29<6:31:54, 60.60s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 3.03E+05, Train scatter: [0.4876 0.0925 0.4391 0.5412]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4644 0.0888 0.4306 0.5291], Lowest was [0.2096 0.0524 0.2565 0.4749]
Median for last 10 epochs: [0.4644 0.0888 0.3179 0.5291], Epochs since improvement 10
 23%|██▎       | 113/500 [1:49:14<6:02:25, 56.19s/it] 23%|██▎       | 114/500 [1:50:24<6:27:11, 60.18s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 2.37E+05, Train scatter: [0.4317 0.0616 0.2416 0.4951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4298 0.0623 0.2514 0.4918], Lowest was [0.2096 0.0524 0.2514 0.4749]
Median for last 10 epochs: [0.4328 0.0679 0.2688 0.498 ], Epochs since improvement 0
 23%|██▎       | 115/500 [1:51:10<5:58:34, 55.88s/it] 23%|██▎       | 116/500 [1:52:19<6:23:20, 59.90s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 2.55E+05, Train scatter: [0.278  0.0633 0.245  0.4873]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2738 0.0634 0.2507 0.4825], Lowest was [0.2096 0.0524 0.2507 0.4749]
Median for last 10 epochs: [0.4298 0.0676 0.2607 0.4954], Epochs since improvement 0
 23%|██▎       | 117/500 [1:53:05<5:55:49, 55.74s/it] 24%|██▎       | 118/500 [1:54:14<6:20:17, 59.73s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.68E+05, Train scatter: [0.4178 0.0543 0.2312 0.4921]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.412  0.0564 0.2387 0.4921], Lowest was [0.2096 0.0524 0.2387 0.4749]
Median for last 10 epochs: [0.4298 0.0634 0.2514 0.4921], Epochs since improvement 0
 24%|██▍       | 119/500 [1:55:00<5:53:06, 55.61s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.30E+05, Train scatter: [0.3771 0.0543 0.2314 0.485 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.372  0.0537 0.2396 0.4843], Lowest was [0.2096 0.0524 0.2387 0.4749]
Median for last 10 epochs: [0.412  0.0623 0.2507 0.4918], Epochs since improvement 2
 24%|██▍       | 120/500 [1:56:17<6:31:58, 61.89s/it] 24%|██▍       | 121/500 [1:57:02<6:00:28, 57.07s/it] 24%|██▍       | 122/500 [1:58:13<6:24:53, 61.09s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 3.71E+05, Train scatter: [0.4007 0.0527 0.2441 0.4865]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3931 0.0529 0.2486 0.4823], Lowest was [0.2096 0.0524 0.2387 0.4749]
Median for last 10 epochs: [0.3931 0.0564 0.2486 0.4843], Epochs since improvement 4
 25%|██▍       | 123/500 [1:58:59<5:55:42, 56.61s/it] 25%|██▍       | 124/500 [2:00:08<6:17:29, 60.24s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.10E+04, Train scatter: [0.3953 0.0522 0.2319 0.4761]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3866 0.052  0.2373 0.4716], Lowest was [0.2096 0.052  0.2373 0.4716]
Median for last 10 epochs: [0.3866 0.0537 0.2396 0.4825], Epochs since improvement 0
 25%|██▌       | 125/500 [2:00:54<5:50:05, 56.01s/it] 25%|██▌       | 126/500 [2:02:04<6:15:56, 60.31s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: -3.19E+03, Train scatter: [0.2098 0.0494 0.2237 0.4802]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2166 0.0493 0.2325 0.4767], Lowest was [0.2096 0.0493 0.2325 0.4716]
Median for last 10 epochs: [0.3866 0.0529 0.2387 0.4823], Epochs since improvement 0
 25%|██▌       | 127/500 [2:02:50<5:48:01, 55.98s/it] 26%|██▌       | 128/500 [2:04:01<6:15:03, 60.49s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -8.40E+04, Train scatter: [0.3306 0.0748 0.3093 0.5334]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3181 0.0735 0.3113 0.529 ], Lowest was [0.2096 0.0493 0.2325 0.4716]
Median for last 10 epochs: [0.372  0.0529 0.2396 0.4823], Epochs since improvement 2
 26%|██▌       | 129/500 [2:04:47<5:47:15, 56.16s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -2.06E+05, Train scatter: [0.2335 0.0532 0.2221 0.4648]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2353 0.0543 0.2305 0.4632], Lowest was [0.2096 0.0493 0.2305 0.4632]
Median for last 10 epochs: [0.3181 0.0529 0.2373 0.4767], Epochs since improvement 0
 26%|██▌       | 130/500 [2:06:03<6:23:17, 62.15s/it] 26%|██▌       | 131/500 [2:06:50<5:52:59, 57.40s/it] 26%|██▋       | 132/500 [2:08:00<6:16:00, 61.30s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -2.83E+05, Train scatter: [0.1846 0.0457 0.217  0.4604]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1843 0.0457 0.2244 0.4561], Lowest was [0.1843 0.0457 0.2244 0.4561]
Median for last 10 epochs: [0.2353 0.052  0.2325 0.4716], Epochs since improvement 0
 27%|██▋       | 133/500 [2:08:46<5:47:06, 56.75s/it] 27%|██▋       | 134/500 [2:09:57<6:12:00, 60.99s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: -3.21E+05, Train scatter: [0.1719 0.045  0.2179 0.4562]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1737 0.0451 0.2235 0.4536], Lowest was [0.1737 0.0451 0.2235 0.4536]
Median for last 10 epochs: [0.2166 0.0493 0.2305 0.4632], Epochs since improvement 0
 27%|██▋       | 135/500 [2:10:43<5:43:41, 56.50s/it] 27%|██▋       | 136/500 [2:11:53<6:07:37, 60.60s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: -3.54E+05, Train scatter: [0.1767 0.0469 0.2241 0.4548]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1813 0.048  0.2344 0.4528], Lowest was [0.1737 0.0451 0.2235 0.4528]
Median for last 10 epochs: [0.1843 0.048  0.2305 0.4561], Epochs since improvement 0
 27%|██▋       | 137/500 [2:12:39<5:40:25, 56.27s/it] 28%|██▊       | 138/500 [2:13:50<6:05:31, 60.58s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -3.72E+05, Train scatter: [0.1545 0.0438 0.2167 0.447 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.155  0.0437 0.2211 0.4441], Lowest was [0.155  0.0437 0.2211 0.4441]
Median for last 10 epochs: [0.1813 0.0457 0.2244 0.4536], Epochs since improvement 0
 28%|██▊       | 139/500 [2:14:36<5:38:32, 56.27s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -3.84E+05, Train scatter: [0.1533 0.0438 0.2172 0.4469]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.153  0.0437 0.2226 0.4446], Lowest was [0.153  0.0437 0.2211 0.4441]
Median for last 10 epochs: [0.1737 0.0451 0.2235 0.4528], Epochs since improvement 0
 28%|██▊       | 140/500 [2:15:53<6:13:30, 62.25s/it] 28%|██▊       | 141/500 [2:16:39<5:43:23, 57.39s/it] 28%|██▊       | 142/500 [2:17:49<6:05:15, 61.22s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -3.79E+05, Train scatter: [0.1823 0.0455 0.2155 0.4456]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1933 0.0466 0.2215 0.4452], Lowest was [0.153  0.0437 0.2211 0.4441]
Median for last 10 epochs: [0.1737 0.0451 0.2226 0.4452], Epochs since improvement 2
 29%|██▊       | 143/500 [2:18:35<5:37:14, 56.68s/it] 29%|██▉       | 144/500 [2:19:45<6:00:02, 60.68s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: -3.83E+05, Train scatter: [0.1518 0.0419 0.2278 0.4424]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1585 0.0424 0.2349 0.4411], Lowest was [0.153  0.0424 0.2211 0.4411]
Median for last 10 epochs: [0.1585 0.0437 0.2226 0.4446], Epochs since improvement 0
 29%|██▉       | 145/500 [2:20:31<5:33:21, 56.34s/it] 29%|██▉       | 146/500 [2:21:40<5:54:17, 60.05s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: -4.04E+05, Train scatter: [0.1577 0.0437 0.226  0.4318]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1599 0.0443 0.2329 0.4255], Lowest was [0.153  0.0424 0.2211 0.4255]
Median for last 10 epochs: [0.1585 0.0437 0.2226 0.4441], Epochs since improvement 0
 29%|██▉       | 147/500 [2:22:26<5:28:13, 55.79s/it] 30%|██▉       | 148/500 [2:23:35<5:51:12, 59.86s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: -3.86E+05, Train scatter: [0.1539 0.0465 0.2325 0.4358]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1564 0.0467 0.2358 0.4297], Lowest was [0.153  0.0424 0.2211 0.4255]
Median for last 10 epochs: [0.1585 0.0443 0.2329 0.4411], Epochs since improvement 2
 30%|██▉       | 149/500 [2:24:21<5:26:06, 55.75s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: -3.92E+05, Train scatter: [0.1612 0.0445 0.2174 0.44  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1606 0.0438 0.2215 0.4273], Lowest was [0.153  0.0424 0.2211 0.4255]
Median for last 10 epochs: [0.1599 0.0443 0.2329 0.4297], Epochs since improvement 4
 30%|███       | 150/500 [2:25:37<6:00:29, 61.80s/it] 30%|███       | 151/500 [2:26:23<5:32:06, 57.10s/it] 30%|███       | 152/500 [2:27:32<5:51:54, 60.68s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: -3.98E+05, Train scatter: [0.1546 0.0419 0.2455 0.4225]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.157  0.0423 0.249  0.4145], Lowest was [0.153  0.0423 0.2211 0.4145]
Median for last 10 epochs: [0.1585 0.0438 0.2349 0.4273], Epochs since improvement 0
 31%|███       | 153/500 [2:28:18<5:25:28, 56.28s/it] 31%|███       | 154/500 [2:29:29<5:48:55, 60.51s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: -2.44E+05, Train scatter: [0.382  0.0673 0.3325 0.5261]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3739 0.067  0.332  0.5224], Lowest was [0.153  0.0423 0.2211 0.4145]
Median for last 10 epochs: [0.1599 0.0443 0.2358 0.4273], Epochs since improvement 2
 31%|███       | 155/500 [2:30:15<5:23:09, 56.20s/it] 31%|███       | 156/500 [2:31:24<5:45:27, 60.25s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: -3.49E+05, Train scatter: [0.1649 0.0472 0.2581 0.4395]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1611 0.0467 0.2592 0.4311], Lowest was [0.153  0.0423 0.2211 0.4145]
Median for last 10 epochs: [0.1606 0.0467 0.249  0.4297], Epochs since improvement 4
 31%|███▏      | 157/500 [2:32:10<5:20:07, 56.00s/it] 32%|███▏      | 158/500 [2:33:20<5:42:14, 60.04s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: -3.85E+05, Train scatter: [0.1546 0.0464 0.2372 0.4411]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.154  0.0461 0.242  0.4367], Lowest was [0.153  0.0423 0.2211 0.4145]
Median for last 10 epochs: [0.1606 0.0461 0.249  0.4311], Epochs since improvement 6
 32%|███▏      | 159/500 [2:34:06<5:17:24, 55.85s/it]Epoch: 160 done with learning rate 9.05E-03, Train loss: -3.93E+05, Train scatter: [0.1345 0.0421 0.2241 0.4269]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1342 0.0414 0.2259 0.416 ], Lowest was [0.1342 0.0414 0.2211 0.4145]
Median for last 10 epochs: [0.157  0.0461 0.249  0.4311], Epochs since improvement 0
 32%|███▏      | 160/500 [2:35:23<5:52:01, 62.12s/it] 32%|███▏      | 161/500 [2:36:09<5:23:47, 57.31s/it] 32%|███▏      | 162/500 [2:37:19<5:44:56, 61.23s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: -4.11E+05, Train scatter: [0.1355 0.041  0.2212 0.4367]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.139  0.0404 0.2244 0.4283], Lowest was [0.1342 0.0404 0.2211 0.4145]
Median for last 10 epochs: [0.154  0.0461 0.242  0.4311], Epochs since improvement 0
 33%|███▎      | 163/500 [2:38:05<5:18:09, 56.65s/it] 33%|███▎      | 164/500 [2:39:14<5:37:32, 60.28s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: -4.12E+05, Train scatter: [0.1488 0.0452 0.2226 0.4237]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1486 0.0445 0.2252 0.4126], Lowest was [0.1342 0.0404 0.2211 0.4126]
Median for last 10 epochs: [0.1486 0.0445 0.2259 0.4283], Epochs since improvement 0
 33%|███▎      | 165/500 [2:40:00<5:12:39, 56.00s/it] 33%|███▎      | 166/500 [2:41:10<5:34:23, 60.07s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: -4.18E+05, Train scatter: [0.1505 0.0419 0.246  0.4237]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.151  0.0413 0.2493 0.4093], Lowest was [0.1342 0.0404 0.2211 0.4093]
Median for last 10 epochs: [0.1486 0.0414 0.2259 0.416 ], Epochs since improvement 0
 33%|███▎      | 167/500 [2:41:56<5:10:19, 55.91s/it] 34%|███▎      | 168/500 [2:43:06<5:32:44, 60.14s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: -4.17E+05, Train scatter: [0.2244 0.0428 0.2258 0.4284]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2282 0.0426 0.2276 0.4205], Lowest was [0.1342 0.0404 0.2211 0.4093]
Median for last 10 epochs: [0.1486 0.0414 0.2259 0.416 ], Epochs since improvement 2
 34%|███▍      | 169/500 [2:43:52<5:08:36, 55.94s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -4.31E+05, Train scatter: [0.1408 0.0437 0.2203 0.4245]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1442 0.043  0.2229 0.4144], Lowest was [0.1342 0.0404 0.2211 0.4093]
Median for last 10 epochs: [0.1486 0.0426 0.2252 0.4144], Epochs since improvement 4
 34%|███▍      | 170/500 [2:45:09<5:42:10, 62.21s/it] 34%|███▍      | 171/500 [2:45:55<5:14:47, 57.41s/it] 34%|███▍      | 172/500 [2:47:04<5:33:26, 60.99s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -4.32E+05, Train scatter: [0.1285 0.0405 0.2257 0.4181]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1326 0.0405 0.2298 0.4109], Lowest was [0.1326 0.0404 0.2211 0.4093]
Median for last 10 epochs: [0.1486 0.0426 0.2276 0.4126], Epochs since improvement 0
 35%|███▍      | 173/500 [2:47:50<5:08:08, 56.54s/it] 35%|███▍      | 174/500 [2:49:01<5:29:15, 60.60s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -4.32E+05, Train scatter: [0.1647 0.0422 0.2209 0.4198]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1721 0.0419 0.2237 0.4099], Lowest was [0.1326 0.0404 0.2211 0.4093]
Median for last 10 epochs: [0.151  0.0419 0.2276 0.4109], Epochs since improvement 2
 35%|███▌      | 175/500 [2:49:47<5:04:32, 56.22s/it] 35%|███▌      | 176/500 [2:50:55<5:24:10, 60.03s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -4.25E+05, Train scatter: [0.1676 0.0425 0.2202 0.4193]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.165  0.0422 0.2225 0.4093], Lowest was [0.1326 0.0404 0.2211 0.4093]
Median for last 10 epochs: [0.165  0.0422 0.2237 0.4109], Epochs since improvement 0
 35%|███▌      | 177/500 [2:51:42<5:00:40, 55.85s/it] 36%|███▌      | 178/500 [2:52:51<5:22:07, 60.02s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -4.36E+05, Train scatter: [0.13   0.0401 0.2165 0.4118]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1315 0.0396 0.219  0.4007], Lowest was [0.1315 0.0396 0.219  0.4007]
Median for last 10 epochs: [0.1442 0.0419 0.2229 0.4099], Epochs since improvement 0
 36%|███▌      | 179/500 [2:53:37<4:58:47, 55.85s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -4.48E+05, Train scatter: [0.1442 0.0423 0.218  0.4096]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1397 0.0415 0.22   0.3972], Lowest was [0.1315 0.0396 0.219  0.3972]
Median for last 10 epochs: [0.1397 0.0415 0.2225 0.4093], Epochs since improvement 0
 36%|███▌      | 180/500 [2:54:53<5:28:56, 61.68s/it] 36%|███▌      | 181/500 [2:55:39<5:03:05, 57.01s/it] 36%|███▋      | 182/500 [2:56:49<5:22:44, 60.90s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -4.55E+05, Train scatter: [0.1215 0.0398 0.2128 0.4116]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.122  0.0391 0.2139 0.4016], Lowest was [0.122  0.0391 0.2139 0.3972]
Median for last 10 epochs: [0.1397 0.0415 0.22   0.4016], Epochs since improvement 0
 37%|███▋      | 183/500 [2:57:35<4:58:06, 56.43s/it] 37%|███▋      | 184/500 [2:58:45<5:19:30, 60.67s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -4.48E+05, Train scatter: [0.119  0.0413 0.23   0.4138]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1207 0.0412 0.233  0.4093], Lowest was [0.1207 0.0391 0.2139 0.3972]
Median for last 10 epochs: [0.1315 0.0412 0.22   0.4016], Epochs since improvement 0
 37%|███▋      | 185/500 [2:59:31<4:55:36, 56.31s/it] 37%|███▋      | 186/500 [3:00:41<5:14:46, 60.15s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -4.68E+05, Train scatter: [0.1519 0.0451 0.2177 0.4223]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1552 0.0452 0.2202 0.4158], Lowest was [0.1207 0.0391 0.2139 0.3972]
Median for last 10 epochs: [0.1315 0.0412 0.22   0.4016], Epochs since improvement 2
 37%|███▋      | 187/500 [3:01:27<4:51:41, 55.91s/it] 38%|███▊      | 188/500 [3:02:36<5:11:30, 59.90s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -4.72E+05, Train scatter: [0.1233 0.0383 0.2065 0.3966]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1227 0.0378 0.209  0.3875], Lowest was [0.1207 0.0378 0.209  0.3875]
Median for last 10 epochs: [0.1227 0.0412 0.22   0.4016], Epochs since improvement 0
 38%|███▊      | 189/500 [3:03:22<4:49:10, 55.79s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -4.64E+05, Train scatter: [0.1266 0.0399 0.2258 0.4018]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1226 0.0396 0.2253 0.3915], Lowest was [0.1207 0.0378 0.209  0.3875]
Median for last 10 epochs: [0.1226 0.0396 0.2202 0.4016], Epochs since improvement 2
 38%|███▊      | 190/500 [3:04:39<5:21:35, 62.24s/it] 38%|███▊      | 191/500 [3:05:25<4:55:33, 57.39s/it] 38%|███▊      | 192/500 [3:06:36<5:14:20, 61.23s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -4.78E+05, Train scatter: [0.1277 0.0438 0.2247 0.4087]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1279 0.0433 0.228  0.3998], Lowest was [0.1207 0.0378 0.209  0.3875]
Median for last 10 epochs: [0.1227 0.0412 0.2253 0.3998], Epochs since improvement 4
 39%|███▊      | 193/500 [3:07:22<4:50:03, 56.69s/it] 39%|███▉      | 194/500 [3:08:32<5:09:46, 60.74s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -4.73E+05, Train scatter: [0.1247 0.0379 0.214  0.396 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1226 0.0377 0.2165 0.3871], Lowest was [0.1207 0.0377 0.209  0.3871]
Median for last 10 epochs: [0.1227 0.0396 0.2202 0.3915], Epochs since improvement 0
 39%|███▉      | 195/500 [3:09:18<4:46:37, 56.38s/it] 39%|███▉      | 196/500 [3:10:29<5:07:55, 60.77s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -4.80E+05, Train scatter: [0.1274 0.0402 0.2205 0.4027]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1286 0.0399 0.2232 0.3946], Lowest was [0.1207 0.0377 0.209  0.3871]
Median for last 10 epochs: [0.1227 0.0396 0.2232 0.3915], Epochs since improvement 2
 39%|███▉      | 197/500 [3:11:15<4:44:26, 56.33s/it] 40%|███▉      | 198/500 [3:12:25<5:04:38, 60.53s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -4.85E+05, Train scatter: [0.1212 0.0366 0.2011 0.3915]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1195 0.0364 0.205  0.3827], Lowest was [0.1195 0.0364 0.205  0.3827]
Median for last 10 epochs: [0.1226 0.0396 0.2232 0.3915], Epochs since improvement 0
 40%|███▉      | 199/500 [3:13:11<4:41:53, 56.19s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -4.91E+05, Train scatter: [0.1176 0.0368 0.2017 0.3881]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1174 0.0365 0.2045 0.3792], Lowest was [0.1174 0.0364 0.2045 0.3792]
Median for last 10 epochs: [0.1226 0.0377 0.2165 0.3871], Epochs since improvement 0
 40%|████      | 200/500 [3:14:28<5:11:34, 62.32s/it] 40%|████      | 201/500 [3:15:14<4:46:14, 57.44s/it] 40%|████      | 202/500 [3:16:24<5:03:28, 61.10s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -4.92E+05, Train scatter: [0.1106 0.0366 0.2045 0.3959]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1094 0.0364 0.2069 0.3885], Lowest was [0.1094 0.0364 0.2045 0.3792]
Median for last 10 epochs: [0.1195 0.0365 0.2069 0.3871], Epochs since improvement 0
 41%|████      | 203/500 [3:17:10<4:40:16, 56.62s/it] 41%|████      | 204/500 [3:18:20<4:59:41, 60.75s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -4.98E+05, Train scatter: [0.1168 0.0374 0.2071 0.3981]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1188 0.0372 0.2099 0.3901], Lowest was [0.1094 0.0364 0.2045 0.3792]
Median for last 10 epochs: [0.1188 0.0365 0.2069 0.3885], Epochs since improvement 2
 41%|████      | 205/500 [3:19:06<4:37:10, 56.37s/it] 41%|████      | 206/500 [3:20:16<4:56:06, 60.43s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -5.00E+05, Train scatter: [0.1071 0.0364 0.1994 0.3825]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.109  0.0361 0.2027 0.3737], Lowest was [0.109  0.0361 0.2027 0.3737]
Median for last 10 epochs: [0.1174 0.0364 0.205  0.3827], Epochs since improvement 0
 41%|████▏     | 207/500 [3:21:02<4:33:57, 56.10s/it] 42%|████▏     | 208/500 [3:22:12<4:52:10, 60.03s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -4.94E+05, Train scatter: [0.1139 0.0364 0.2048 0.3841]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1161 0.0363 0.2082 0.3762], Lowest was [0.109  0.0361 0.2027 0.3737]
Median for last 10 epochs: [0.1161 0.0364 0.2069 0.3792], Epochs since improvement 2
 42%|████▏     | 209/500 [3:22:58<4:30:43, 55.82s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -5.05E+05, Train scatter: [0.1159 0.0363 0.2004 0.3829]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1167 0.0359 0.2033 0.3728], Lowest was [0.109  0.0359 0.2027 0.3728]
Median for last 10 epochs: [0.1161 0.0363 0.2069 0.3762], Epochs since improvement 0
 42%|████▏     | 210/500 [3:24:14<5:00:02, 62.08s/it] 42%|████▏     | 211/500 [3:25:00<4:36:07, 57.33s/it] 42%|████▏     | 212/500 [3:26:10<4:52:42, 60.98s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -4.58E+05, Train scatter: [0.1156 0.0377 0.2059 0.396 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.115  0.0374 0.2077 0.3869], Lowest was [0.109  0.0359 0.2027 0.3728]
Median for last 10 epochs: [0.1161 0.0363 0.2077 0.3762], Epochs since improvement 2
 43%|████▎     | 213/500 [3:26:56<4:30:33, 56.56s/it] 43%|████▎     | 214/500 [3:28:06<4:48:29, 60.52s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: -5.01E+05, Train scatter: [0.1088 0.0367 0.2039 0.3832]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1106 0.0364 0.2069 0.3737], Lowest was [0.109  0.0359 0.2027 0.3728]
Median for last 10 epochs: [0.115  0.0363 0.2069 0.3737], Epochs since improvement 4
 43%|████▎     | 215/500 [3:28:52<4:27:03, 56.22s/it] 43%|████▎     | 216/500 [3:30:02<4:45:39, 60.35s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -5.12E+05, Train scatter: [0.1088 0.0368 0.2022 0.3815]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1095 0.0367 0.2053 0.3731], Lowest was [0.109  0.0359 0.2027 0.3728]
Median for last 10 epochs: [0.115  0.0364 0.2069 0.3737], Epochs since improvement 6
 43%|████▎     | 217/500 [3:30:49<4:25:39, 56.32s/it] 44%|████▎     | 218/500 [3:32:00<4:44:35, 60.55s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -5.15E+05, Train scatter: [0.1226 0.0379 0.2036 0.3874]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1249 0.0377 0.206  0.38  ], Lowest was [0.109  0.0359 0.2027 0.3728]
Median for last 10 epochs: [0.115  0.0367 0.206  0.3737], Epochs since improvement 8
 44%|████▍     | 219/500 [3:32:46<4:23:17, 56.22s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -5.20E+05, Train scatter: [0.1275 0.0394 0.2071 0.3943]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1264 0.039  0.2082 0.3815], Lowest was [0.109  0.0359 0.2027 0.3728]
Median for last 10 epochs: [0.115  0.0374 0.2069 0.38  ], Epochs since improvement 10
 44%|████▍     | 220/500 [3:34:02<4:51:12, 62.40s/it] 44%|████▍     | 221/500 [3:34:48<4:27:17, 57.48s/it] 44%|████▍     | 222/500 [3:35:58<4:43:04, 61.10s/it]Epoch: 222 done with learning rate 7.33E-03, Train loss: -5.20E+05, Train scatter: [0.105  0.0359 0.1991 0.3769]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1072 0.0357 0.2015 0.369 ], Lowest was [0.1072 0.0357 0.2015 0.369 ]
Median for last 10 epochs: [0.1106 0.0367 0.206  0.3737], Epochs since improvement 0
 45%|████▍     | 223/500 [3:36:44<4:21:12, 56.58s/it] 45%|████▍     | 224/500 [3:37:54<4:38:45, 60.60s/it]Epoch: 224 done with learning rate 7.26E-03, Train loss: -5.24E+05, Train scatter: [0.1036 0.0354 0.1988 0.3784]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1063 0.0354 0.2014 0.3699], Lowest was [0.1063 0.0354 0.2014 0.369 ]
Median for last 10 epochs: [0.1095 0.0367 0.2053 0.3731], Epochs since improvement 0
 45%|████▌     | 225/500 [3:38:40<4:17:47, 56.25s/it] 45%|████▌     | 226/500 [3:39:50<4:35:50, 60.40s/it]Epoch: 226 done with learning rate 7.20E-03, Train loss: -4.85E+05, Train scatter: [0.1095 0.0366 0.2031 0.3801]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1109 0.0366 0.2058 0.3703], Lowest was [0.1063 0.0354 0.2014 0.369 ]
Median for last 10 epochs: [0.1109 0.0366 0.2058 0.3703], Epochs since improvement 2
 45%|████▌     | 227/500 [3:40:36<4:15:20, 56.12s/it] 46%|████▌     | 228/500 [3:41:46<4:32:54, 60.20s/it]Epoch: 228 done with learning rate 7.13E-03, Train loss: -5.24E+05, Train scatter: [0.1015 0.0356 0.2002 0.3749]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1038 0.0355 0.2042 0.3667], Lowest was [0.1038 0.0354 0.2014 0.3667]
Median for last 10 epochs: [0.1072 0.0357 0.2042 0.3699], Epochs since improvement 0
 46%|████▌     | 229/500 [3:42:32<4:12:56, 56.00s/it]Epoch: 230 done with learning rate 7.06E-03, Train loss: -5.26E+05, Train scatter: [0.1015 0.0349 0.2    0.3719]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1045 0.0348 0.2038 0.3641], Lowest was [0.1038 0.0348 0.2014 0.3641]
Median for last 10 epochs: [0.1063 0.0355 0.2038 0.369 ], Epochs since improvement 0
 46%|████▌     | 230/500 [3:43:47<4:37:54, 61.76s/it] 46%|████▌     | 231/500 [3:44:34<4:15:53, 57.08s/it] 46%|████▋     | 232/500 [3:45:44<4:32:25, 60.99s/it]Epoch: 232 done with learning rate 6.99E-03, Train loss: -5.33E+05, Train scatter: [0.0988 0.0349 0.1984 0.3726]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1013 0.035  0.2012 0.3635], Lowest was [0.1013 0.0348 0.2012 0.3635]
Median for last 10 epochs: [0.1045 0.0354 0.2038 0.3667], Epochs since improvement 0
 47%|████▋     | 233/500 [3:46:30<4:11:34, 56.54s/it] 47%|████▋     | 234/500 [3:47:40<4:28:41, 60.61s/it]Epoch: 234 done with learning rate 6.93E-03, Train loss: -5.27E+05, Train scatter: [0.1016 0.0356 0.1947 0.3707]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1042 0.0356 0.1974 0.3639], Lowest was [0.1013 0.0348 0.1974 0.3635]
Median for last 10 epochs: [0.1042 0.0355 0.2038 0.3641], Epochs since improvement 0
 47%|████▋     | 235/500 [3:48:26<4:08:34, 56.28s/it] 47%|████▋     | 236/500 [3:49:36<4:25:05, 60.25s/it]Epoch: 236 done with learning rate 6.86E-03, Train loss: -5.36E+05, Train scatter: [0.1098 0.0347 0.1946 0.3774]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1095 0.0347 0.1991 0.3712], Lowest was [0.1013 0.0347 0.1974 0.3635]
Median for last 10 epochs: [0.1042 0.035  0.2012 0.3641], Epochs since improvement 0
 47%|████▋     | 237/500 [3:50:22<4:05:33, 56.02s/it] 48%|████▊     | 238/500 [3:51:32<4:22:58, 60.22s/it]Epoch: 238 done with learning rate 6.79E-03, Train loss: -5.38E+05, Train scatter: [0.1082 0.0371 0.2133 0.3793]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1069 0.037  0.2161 0.3699], Lowest was [0.1013 0.0347 0.1974 0.3635]
Median for last 10 epochs: [0.1045 0.035  0.2012 0.3641], Epochs since improvement 2
 48%|████▊     | 239/500 [3:52:18<4:03:38, 56.01s/it]Epoch: 240 done with learning rate 6.72E-03, Train loss: -5.35E+05, Train scatter: [0.0989 0.0354 0.1988 0.3737]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1017 0.0353 0.2026 0.3661], Lowest was [0.1013 0.0347 0.1974 0.3635]
Median for last 10 epochs: [0.1042 0.0353 0.2012 0.3661], Epochs since improvement 4
 48%|████▊     | 240/500 [3:53:34<4:28:22, 61.93s/it] 48%|████▊     | 241/500 [3:54:20<4:06:58, 57.21s/it] 48%|████▊     | 242/500 [3:55:30<4:22:42, 61.10s/it]Epoch: 242 done with learning rate 6.65E-03, Train loss: -5.48E+05, Train scatter: [0.0984 0.0348 0.1982 0.3689]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1026 0.0348 0.2013 0.3618], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.1042 0.0353 0.2013 0.3661], Epochs since improvement 0
 49%|████▊     | 243/500 [3:56:16<4:02:21, 56.58s/it] 49%|████▉     | 244/500 [3:57:27<4:19:13, 60.75s/it]Epoch: 244 done with learning rate 6.58E-03, Train loss: -5.31E+05, Train scatter: [0.0997 0.0349 0.1954 0.3753]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.103  0.0349 0.1989 0.3701], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.103  0.0349 0.2013 0.3699], Epochs since improvement 2
 49%|████▉     | 245/500 [3:58:13<3:59:21, 56.32s/it] 49%|████▉     | 246/500 [3:59:22<4:14:54, 60.22s/it]Epoch: 246 done with learning rate 6.51E-03, Train loss: -4.23E+05, Train scatter: [0.5621 0.1186 0.5333 0.6689]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5599 0.1165 0.5248 0.6681], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.103  0.0353 0.2026 0.3699], Epochs since improvement 4
 49%|████▉     | 247/500 [4:00:08<3:55:57, 55.96s/it] 50%|████▉     | 248/500 [4:01:17<4:11:21, 59.85s/it]Epoch: 248 done with learning rate 6.44E-03, Train loss: -3.26E+05, Train scatter: [0.3937 0.0504 0.2625 0.4536]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3861 0.0496 0.2617 0.4488], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.103  0.0353 0.2026 0.3701], Epochs since improvement 6
 50%|████▉     | 249/500 [4:02:03<3:52:59, 55.70s/it]Epoch: 250 done with learning rate 6.37E-03, Train loss: -3.96E+05, Train scatter: [0.1372 0.0459 0.2401 0.4263]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1393 0.0448 0.241  0.4198], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.1393 0.0448 0.241  0.4198], Epochs since improvement 8
 50%|█████     | 250/500 [4:03:19<4:17:05, 61.70s/it] 50%|█████     | 251/500 [4:04:05<3:56:31, 57.00s/it] 50%|█████     | 252/500 [4:05:15<4:12:24, 61.07s/it]Epoch: 252 done with learning rate 6.30E-03, Train loss: -4.29E+05, Train scatter: [0.1868 0.0471 0.2277 0.4178]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1766 0.0463 0.2293 0.4108], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.1766 0.0463 0.241  0.4198], Epochs since improvement 10
 51%|█████     | 253/500 [4:06:01<3:52:42, 56.53s/it] 51%|█████     | 254/500 [4:07:11<4:08:13, 60.54s/it]Epoch: 254 done with learning rate 6.23E-03, Train loss: -4.54E+05, Train scatter: [0.1229 0.0397 0.215  0.4049]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1207 0.0391 0.2168 0.3957], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.1766 0.0463 0.241  0.4198], Epochs since improvement 12
 51%|█████     | 255/500 [4:07:57<3:49:40, 56.25s/it] 51%|█████     | 256/500 [4:09:06<4:03:54, 59.98s/it]Epoch: 256 done with learning rate 6.15E-03, Train loss: -4.67E+05, Train scatter: [0.1136 0.0398 0.2215 0.401 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.115  0.0393 0.2234 0.3926], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.1393 0.0448 0.2293 0.4108], Epochs since improvement 14
 51%|█████▏    | 257/500 [4:09:52<3:46:06, 55.83s/it] 52%|█████▏    | 258/500 [4:11:02<4:01:48, 59.95s/it]Epoch: 258 done with learning rate 6.08E-03, Train loss: -4.74E+05, Train scatter: [0.1151 0.0393 0.2122 0.3953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1135 0.0385 0.215  0.3852], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.1207 0.0393 0.2234 0.3957], Epochs since improvement 16
 52%|█████▏    | 259/500 [4:11:48<3:44:08, 55.80s/it]Epoch: 260 done with learning rate 6.01E-03, Train loss: -4.78E+05, Train scatter: [0.1121 0.0379 0.2082 0.3895]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1118 0.0373 0.2099 0.3802], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.115  0.0391 0.2168 0.3926], Epochs since improvement 18
 52%|█████▏    | 260/500 [4:13:05<4:08:55, 62.23s/it] 52%|█████▏    | 261/500 [4:13:51<3:48:33, 57.38s/it] 52%|█████▏    | 262/500 [4:15:01<4:02:59, 61.26s/it]Epoch: 262 done with learning rate 5.94E-03, Train loss: -4.97E+05, Train scatter: [0.1205 0.0385 0.2172 0.3857]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1207 0.038  0.2197 0.3757], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.115  0.0385 0.2168 0.3852], Epochs since improvement 20
 53%|█████▎    | 263/500 [4:15:47<3:43:58, 56.70s/it] 53%|█████▎    | 263/500 [4:16:58<3:51:34, 58.63s/it]
Epoch: 264 done with learning rate 5.86E-03, Train loss: -5.06E+05, Train scatter: [0.1089 0.0377 0.2063 0.3857]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1106 0.0371 0.2087 0.3771], Lowest was [0.1013 0.0347 0.1974 0.3618]
Median for last 10 epochs: [0.1135 0.038  0.215  0.3802], Epochs since improvement 22
Exited after 264 epochs due to early stopping
15418.75 seconds spent training, 30.837 seconds per epoch. Processed 2258 trees per second
[0.11064426 0.03713241 0.20871109 0.37705675]
{'epoch_exit': 263, 'scatter_m_star': 0.11064426, 'lowest_m_star': 0.10125039, 'last20_m_star': 0.120729, 'last10_m_star': 0.113463245, 'scatter_v_disk': 0.037132412, 'lowest_v_disk': 0.03474831, 'last20_v_disk': 0.039212104, 'last10_v_disk': 0.037978757, 'scatter_m_cold': 0.20871109, 'lowest_m_cold': 0.1974388, 'last20_m_cold': 0.22157246, 'last10_m_cold': 0.2149659, 'scatter_sfr_100': 0.37705675, 'lowest_sfr_100': 0.36183497, 'last20_sfr_100': 0.39416146, 'last10_sfr_100': 0.38017118}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_swjchi
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:40<5:37:28, 40.58s/it]  0%|          | 2/500 [01:42<7:22:02, 53.26s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.08E+07, Train scatter: [0.9352 0.1715 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1684 0.5355 0.9851], Lowest was [0.9196 0.1684 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1684 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:22<6:30:46, 47.18s/it]  1%|          | 4/500 [03:24<7:17:36, 52.94s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.32E+07, Train scatter: [0.9352 0.1612 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1579 0.5355 0.9851], Lowest was [0.9196 0.1579 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1579 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:04<6:37:28, 48.18s/it]  1%|          | 6/500 [05:06<7:16:00, 52.96s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.86E+07, Train scatter: [0.9351 0.1366 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1335 0.5355 0.985 ], Lowest was [0.9196 0.1335 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1335 0.5355 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [05:46<6:39:37, 48.64s/it]  2%|▏         | 8/500 [06:48<7:14:55, 53.04s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.49E+07, Train scatter: [0.9328 0.1113 0.5441 0.9378]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9173 0.1102 0.5355 0.9311], Lowest was [0.9173 0.1102 0.5355 0.9311]
Median for last 10 epochs: [0.9184 0.1219 0.5355 0.9581], Epochs since improvement 0
  2%|▏         | 9/500 [07:28<6:40:49, 48.98s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 1.10E+07, Train scatter: [0.7879 0.1092 0.5441 0.6426]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7798 0.1111 0.5355 0.6397], Lowest was [0.7798 0.1102 0.5355 0.6397]
Median for last 10 epochs: [0.9173 0.1111 0.5355 0.9311], Epochs since improvement 0
  2%|▏         | 10/500 [08:37<7:30:42, 55.19s/it]  2%|▏         | 11/500 [09:17<6:52:20, 50.59s/it]  2%|▏         | 12/500 [10:20<7:20:19, 54.14s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.47E+06, Train scatter: [0.662  0.0952 0.544  0.5917]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6579 0.0946 0.5354 0.5898], Lowest was [0.6579 0.0946 0.5354 0.5898]
Median for last 10 epochs: [0.9173 0.1111 0.5355 0.9311], Epochs since improvement 0
  3%|▎         | 13/500 [11:00<6:44:27, 49.83s/it]  3%|▎         | 14/500 [12:03<7:17:12, 53.98s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 5.68E+06, Train scatter: [0.5699 0.0896 0.544  0.5631]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5676 0.09   0.5354 0.5626], Lowest was [0.5676 0.09   0.5354 0.5626]
Median for last 10 epochs: [0.7798 0.1102 0.5355 0.6397], Epochs since improvement 0
  3%|▎         | 15/500 [12:43<6:42:28, 49.79s/it]  3%|▎         | 16/500 [13:46<7:12:52, 53.66s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.90E+06, Train scatter: [0.5213 0.0888 0.544  0.5615]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5117 0.0881 0.5355 0.5581], Lowest was [0.5117 0.0881 0.5354 0.5581]
Median for last 10 epochs: [0.6579 0.0946 0.5355 0.5898], Epochs since improvement 0
  3%|▎         | 17/500 [14:26<6:38:18, 49.48s/it]  4%|▎         | 18/500 [15:28<7:08:46, 53.38s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.74E+06, Train scatter: [0.4583 0.0874 0.544  0.5545]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4576 0.0872 0.5354 0.5514], Lowest was [0.4576 0.0872 0.5354 0.5514]
Median for last 10 epochs: [0.5676 0.09   0.5354 0.5626], Epochs since improvement 0
  4%|▍         | 19/500 [16:08<6:35:25, 49.32s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 4.13E+06, Train scatter: [0.294  0.0798 0.544  0.5614]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.307  0.0803 0.5354 0.5569], Lowest was [0.307  0.0803 0.5354 0.5514]
Median for last 10 epochs: [0.5117 0.0881 0.5354 0.5581], Epochs since improvement 0
  4%|▍         | 20/500 [17:17<7:21:44, 55.22s/it]  4%|▍         | 21/500 [17:57<6:44:32, 50.67s/it]  4%|▍         | 22/500 [19:00<7:13:26, 54.41s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.97E+06, Train scatter: [0.3388 0.0789 0.544  0.5342]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3381 0.0792 0.5354 0.5331], Lowest was [0.307  0.0792 0.5354 0.5331]
Median for last 10 epochs: [0.4576 0.0872 0.5354 0.5569], Epochs since improvement 0
  5%|▍         | 23/500 [19:40<6:38:04, 50.07s/it]  5%|▍         | 24/500 [20:42<7:06:18, 53.74s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.90E+06, Train scatter: [0.3133 0.0784 0.544  0.5377]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3124 0.0788 0.5354 0.5397], Lowest was [0.307  0.0788 0.5354 0.5331]
Median for last 10 epochs: [0.3381 0.0803 0.5354 0.5514], Epochs since improvement 0
  5%|▌         | 25/500 [21:22<6:32:58, 49.64s/it]  5%|▌         | 26/500 [22:25<7:01:59, 53.42s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.88E+06, Train scatter: [0.4575 0.0806 0.5439 0.6463]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4498 0.0809 0.5353 0.6427], Lowest was [0.307  0.0788 0.5353 0.5331]
Median for last 10 epochs: [0.3381 0.0803 0.5354 0.5514], Epochs since improvement 0
  5%|▌         | 27/500 [23:05<6:29:36, 49.42s/it]  6%|▌         | 28/500 [24:07<6:59:43, 53.36s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.82E+06, Train scatter: [0.2676 0.0781 0.5439 0.5187]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.274  0.0776 0.5353 0.5137], Lowest was [0.274  0.0776 0.5353 0.5137]
Median for last 10 epochs: [0.3124 0.0792 0.5354 0.5397], Epochs since improvement 0
  6%|▌         | 29/500 [24:47<6:27:20, 49.34s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.82E+06, Train scatter: [0.2377 0.0743 0.5438 0.5097]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2422 0.0749 0.5353 0.5061], Lowest was [0.2422 0.0749 0.5353 0.5061]
Median for last 10 epochs: [0.3124 0.0788 0.5353 0.5331], Epochs since improvement 0
  6%|▌         | 30/500 [25:56<7:10:56, 55.01s/it]  6%|▌         | 31/500 [26:36<6:35:09, 50.55s/it]  6%|▋         | 32/500 [27:39<7:03:02, 54.24s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.79E+06, Train scatter: [0.2186 0.074  0.5438 0.5177]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2268 0.0741 0.5352 0.5158], Lowest was [0.2268 0.0741 0.5352 0.5061]
Median for last 10 epochs: [0.274  0.0776 0.5353 0.5158], Epochs since improvement 0
  7%|▋         | 33/500 [28:19<6:28:57, 49.97s/it]  7%|▋         | 34/500 [29:20<6:54:40, 53.39s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.75E+06, Train scatter: [0.2381 0.0723 0.5438 0.5094]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2504 0.0727 0.5352 0.5042], Lowest was [0.2268 0.0727 0.5352 0.5042]
Median for last 10 epochs: [0.2504 0.0749 0.5353 0.5137], Epochs since improvement 0
  7%|▋         | 35/500 [30:00<6:22:25, 49.34s/it]  7%|▋         | 36/500 [31:02<6:51:35, 53.22s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.74E+06, Train scatter: [0.4116 0.0762 0.5438 0.5799]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4153 0.0762 0.5352 0.5782], Lowest was [0.2268 0.0727 0.5352 0.5042]
Median for last 10 epochs: [0.2504 0.0749 0.5352 0.5137], Epochs since improvement 2
  7%|▋         | 37/500 [31:42<6:20:20, 49.29s/it]  8%|▊         | 38/500 [32:45<6:50:55, 53.37s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.71E+06, Train scatter: [0.2061 0.0706 0.5437 0.5047]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.218  0.0707 0.5351 0.5036], Lowest was [0.218  0.0707 0.5351 0.5036]
Median for last 10 epochs: [0.2422 0.0741 0.5352 0.5061], Epochs since improvement 0
  8%|▊         | 39/500 [33:25<6:19:05, 49.34s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.71E+06, Train scatter: [0.204  0.0696 0.5436 0.5128]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2361 0.0696 0.5351 0.5084], Lowest was [0.218  0.0696 0.5351 0.5036]
Median for last 10 epochs: [0.2361 0.0727 0.5352 0.5084], Epochs since improvement 0
  8%|▊         | 40/500 [34:34<7:03:12, 55.20s/it]  8%|▊         | 41/500 [35:14<6:27:29, 50.65s/it]  8%|▊         | 42/500 [36:17<6:54:15, 54.27s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.69E+06, Train scatter: [0.2055 0.0703 0.5436 0.5079]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2922 0.0704 0.535  0.509 ], Lowest was [0.218  0.0696 0.535  0.5036]
Median for last 10 epochs: [0.2504 0.0707 0.5351 0.5084], Epochs since improvement 0
  9%|▊         | 43/500 [36:57<6:20:51, 50.00s/it]  9%|▉         | 44/500 [38:00<6:49:21, 53.86s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.68E+06, Train scatter: [0.3156 0.0717 0.5435 0.5056]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5044 0.0717 0.5349 0.5004], Lowest was [0.218  0.0696 0.5349 0.5004]
Median for last 10 epochs: [0.2922 0.0707 0.5351 0.5084], Epochs since improvement 0
  9%|▉         | 45/500 [38:40<6:17:17, 49.75s/it]  9%|▉         | 46/500 [39:44<6:48:24, 53.98s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.66E+06, Train scatter: [0.2001 0.0691 0.5434 0.4972]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4591 0.0693 0.5349 0.493 ], Lowest was [0.218  0.0693 0.5349 0.493 ]
Median for last 10 epochs: [0.2922 0.0704 0.535  0.5036], Epochs since improvement 0
  9%|▉         | 47/500 [40:24<6:16:16, 49.84s/it] 10%|▉         | 48/500 [41:27<6:45:52, 53.88s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.65E+06, Train scatter: [0.2031 0.0699 0.5433 0.5065]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3402 0.0699 0.5348 0.4995], Lowest was [0.218  0.0693 0.5348 0.493 ]
Median for last 10 epochs: [0.3402 0.0699 0.5349 0.5004], Epochs since improvement 0
 10%|▉         | 49/500 [42:07<6:13:40, 49.71s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.69E+06, Train scatter: [0.295  0.0748 0.5433 0.5411]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3044 0.075  0.5347 0.5437], Lowest was [0.218  0.0693 0.5347 0.493 ]
Median for last 10 epochs: [0.3402 0.0704 0.5349 0.5004], Epochs since improvement 0
 10%|█         | 50/500 [43:16<6:55:53, 55.45s/it] 10%|█         | 51/500 [43:56<6:20:32, 50.85s/it] 10%|█         | 52/500 [44:59<6:46:55, 54.50s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.63E+06, Train scatter: [0.2326 0.0682 0.5431 0.4962]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2324 0.0684 0.5345 0.4946], Lowest was [0.218  0.0684 0.5345 0.493 ]
Median for last 10 epochs: [0.3402 0.0699 0.5348 0.4995], Epochs since improvement 0
 11%|█         | 53/500 [45:39<6:13:45, 50.17s/it] 11%|█         | 54/500 [46:42<6:42:09, 54.10s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.62E+06, Train scatter: [0.4345 0.0673 0.5428 0.5154]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.423  0.0675 0.5343 0.51  ], Lowest was [0.218  0.0675 0.5343 0.493 ]
Median for last 10 epochs: [0.3402 0.0693 0.5347 0.4995], Epochs since improvement 0
 11%|█         | 55/500 [47:22<6:09:54, 49.87s/it] 11%|█         | 56/500 [48:25<6:37:46, 53.75s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.54E+06, Train scatter: [0.2703 0.0788 0.5428 0.5439]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2719 0.0775 0.5343 0.5467], Lowest was [0.218  0.0675 0.5343 0.493 ]
Median for last 10 epochs: [0.3044 0.0699 0.5345 0.51  ], Epochs since improvement 2
 11%|█▏        | 57/500 [49:05<6:06:33, 49.65s/it] 12%|█▏        | 58/500 [50:08<6:34:36, 53.57s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.47E+06, Train scatter: [0.4211 0.0692 0.5424 0.4944]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4112 0.069  0.5339 0.4915], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.3044 0.069  0.5343 0.51  ], Epochs since improvement 0
 12%|█▏        | 59/500 [50:48<6:03:57, 49.52s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.22E+12, Train scatter: [0.9355 0.1731 0.5441 0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.1692 0.5355 0.9847], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.4112 0.069  0.5343 0.51  ], Epochs since improvement 2
 12%|█▏        | 60/500 [51:58<6:47:15, 55.54s/it] 12%|█▏        | 61/500 [52:38<6:12:30, 50.91s/it] 12%|█▏        | 62/500 [53:41<6:38:46, 54.63s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.73E+07, Train scatter: [0.9357 0.1732 0.5441 0.9945]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.92   0.1694 0.5355 0.9841], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.423  0.0775 0.5343 0.5467], Epochs since improvement 4
 13%|█▎        | 63/500 [54:21<6:06:17, 50.29s/it] 13%|█▎        | 64/500 [55:24<6:32:09, 53.97s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.84E+07, Train scatter: [0.9355 0.1729 0.5441 0.9948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.1691 0.5355 0.9845], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.9199 0.1691 0.5355 0.9841], Epochs since improvement 6
 13%|█▎        | 65/500 [56:04<6:00:59, 49.79s/it] 13%|█▎        | 66/500 [57:06<6:27:59, 53.64s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.55E+07, Train scatter: [0.9354 0.1728 0.5441 0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.169  0.5355 0.9847], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.9199 0.1691 0.5355 0.9845], Epochs since improvement 8
 13%|█▎        | 67/500 [57:46<5:57:25, 49.53s/it] 14%|█▎        | 68/500 [58:50<6:26:14, 53.65s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.32E+07, Train scatter: [0.9354 0.1728 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.169  0.5355 0.9848], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.9199 0.1691 0.5355 0.9847], Epochs since improvement 10
 14%|█▍        | 69/500 [59:30<5:55:54, 49.55s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.12E+07, Train scatter: [0.9355 0.1728 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.169  0.5355 0.9849], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.9199 0.169  0.5355 0.9847], Epochs since improvement 12
 14%|█▍        | 70/500 [1:00:38<6:36:26, 55.32s/it] 14%|█▍        | 71/500 [1:01:19<6:03:03, 50.78s/it] 14%|█▍        | 72/500 [1:02:21<6:26:34, 54.19s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.96E+07, Train scatter: [0.9355 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.169  0.5355 0.9849], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.9199 0.169  0.5355 0.9848], Epochs since improvement 14
 15%|█▍        | 73/500 [1:03:01<5:55:12, 49.91s/it] 15%|█▍        | 74/500 [1:04:05<6:24:24, 54.14s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 1.83E+07, Train scatter: [0.9354 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1689 0.5355 0.9849], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.9198 0.169  0.5355 0.9849], Epochs since improvement 16
 15%|█▌        | 75/500 [1:04:45<5:53:36, 49.92s/it] 15%|█▌        | 76/500 [1:05:47<6:18:39, 53.58s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 1.71E+07, Train scatter: [0.9353 0.1726 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1688 0.5355 0.9849], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.9198 0.169  0.5355 0.9849], Epochs since improvement 18
 15%|█▌        | 77/500 [1:06:27<5:49:12, 49.53s/it] 16%|█▌        | 78/500 [1:07:28<6:13:06, 53.05s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 1.58E+07, Train scatter: [0.935  0.1722 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9194 0.1683 0.5355 0.9848], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.9198 0.1689 0.5355 0.9849], Epochs since improvement 20
 16%|█▌        | 79/500 [1:08:08<5:44:40, 49.12s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 1.47E+07, Train scatter: [0.9343 0.1708 0.5441 0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9187 0.1669 0.5355 0.9847], Lowest was [0.218  0.0675 0.5339 0.4915]
Median for last 10 epochs: [0.9197 0.1688 0.5355 0.9849], Epochs since improvement 22
 16%|█▌        | 79/500 [1:09:16<6:09:12, 52.62s/it]
Exited after 80 epochs due to early stopping
4156.91 seconds spent training, 8.314 seconds per epoch. Processed 8376 trees per second
[0.9186536  0.16693151 0.5354716  0.9846329 ]
{'epoch_exit': 79, 'scatter_m_star': 0.9186536, 'lowest_m_star': 0.21801423, 'last20_m_star': 0.9198295, 'last10_m_star': 0.91970617, 'scatter_v_disk': 0.16693151, 'lowest_v_disk': 0.06745544, 'last20_v_disk': 0.16897547, 'last10_v_disk': 0.16881335, 'scatter_m_cold': 0.5354716, 'lowest_m_cold': 0.53390735, 'last20_m_cold': 0.535488, 'last10_m_cold': 0.53548783, 'scatter_sfr_100': 0.9846329, 'lowest_sfr_100': 0.49152866, 'last20_sfr_100': 0.98482096, 'last10_sfr_100': 0.98486793}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_favrcf
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:00<8:23:45, 60.57s/it]  0%|          | 2/500 [02:28<10:36:48, 76.72s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.37E+07, Train scatter: [0.9351 0.1292 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1249 0.5355 0.9851], Lowest was [0.9195 0.1249 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1249 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:29<9:33:54, 69.28s/it]   1%|          | 4/500 [04:58<10:39:17, 77.33s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.28E+07, Train scatter: [0.9309 0.1033 0.5429 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9149 0.1043 0.5342 0.9851], Lowest was [0.9149 0.1043 0.5342 0.9851]
Median for last 10 epochs: [0.9149 0.1043 0.5342 0.9851], Epochs since improvement 0
  1%|          | 5/500 [05:59<9:47:58, 71.27s/it]   1%|          | 6/500 [07:29<10:39:01, 77.61s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.06E+07, Train scatter: [0.8121 0.0946 0.5312 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8028 0.0949 0.5231 0.9851], Lowest was [0.8028 0.0949 0.5231 0.9851]
Median for last 10 epochs: [0.8028 0.0949 0.5231 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [08:29<9:50:46, 71.90s/it]   2%|▏         | 8/500 [09:58<10:34:55, 77.43s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.77E+07, Train scatter: [0.7057 0.1001 0.4065 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6996 0.0997 0.4017 0.985 ], Lowest was [0.6996 0.0949 0.4017 0.985 ]
Median for last 10 epochs: [0.7512 0.0973 0.4624 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [10:59<9:50:13, 72.12s/it] Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.60E+07, Train scatter: [0.6054 0.0904 0.3666 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6081 0.0918 0.3651 0.985 ], Lowest was [0.6081 0.0918 0.3651 0.985 ]
Median for last 10 epochs: [0.6996 0.0949 0.4017 0.985 ], Epochs since improvement 0
  2%|▏         | 10/500 [12:35<10:49:29, 79.53s/it]  2%|▏         | 11/500 [13:35<10:00:42, 73.71s/it]  2%|▏         | 12/500 [15:05<10:38:54, 78.56s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.48E+07, Train scatter: [0.6215 0.087  0.3473 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6284 0.0884 0.3514 0.985 ], Lowest was [0.6081 0.0884 0.3514 0.985 ]
Median for last 10 epochs: [0.6996 0.0949 0.4017 0.985 ], Epochs since improvement 0
  3%|▎         | 13/500 [16:05<9:52:52, 73.04s/it]   3%|▎         | 14/500 [17:35<10:32:08, 78.04s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.06E+07, Train scatter: [0.5534 0.0861 0.3265 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5547 0.0863 0.3293 0.985 ], Lowest was [0.5547 0.0863 0.3293 0.985 ]
Median for last 10 epochs: [0.6284 0.0918 0.3651 0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [18:35<9:47:40, 72.70s/it]   3%|▎         | 16/500 [20:04<10:27:02, 77.73s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.98E+07, Train scatter: [0.5422 0.0795 0.312  0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5419 0.0796 0.3165 0.985 ], Lowest was [0.5419 0.0796 0.3165 0.985 ]
Median for last 10 epochs: [0.6081 0.0884 0.3514 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [21:05<9:43:58, 72.54s/it]   4%|▎         | 18/500 [22:35<10:24:41, 77.76s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.84E+07, Train scatter: [0.6012 0.0773 0.3063 0.9949]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.596  0.0771 0.3109 0.9847], Lowest was [0.5419 0.0771 0.3109 0.9847]
Median for last 10 epochs: [0.596  0.0863 0.3293 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [23:35<9:41:39, 72.56s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.56E+06, Train scatter: [0.4926 0.079  0.3083 0.7106]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4819 0.0794 0.3131 0.721 ], Lowest was [0.4819 0.0771 0.3109 0.721 ]
Median for last 10 epochs: [0.5547 0.0796 0.3165 0.985 ], Epochs since improvement 0
  4%|▍         | 20/500 [25:12<10:37:36, 79.70s/it]  4%|▍         | 21/500 [26:12<9:49:49, 73.88s/it]   4%|▍         | 22/500 [27:40<10:23:30, 78.26s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.16E+06, Train scatter: [0.4639 0.078  0.315  0.5761]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4627 0.0772 0.3176 0.5831], Lowest was [0.4627 0.0771 0.3109 0.5831]
Median for last 10 epochs: [0.5419 0.0794 0.3165 0.9847], Epochs since improvement 0
  5%|▍         | 23/500 [28:41<9:39:43, 72.92s/it]   5%|▍         | 24/500 [30:10<10:16:56, 77.77s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.43E+06, Train scatter: [0.4806 0.0798 0.3122 0.5179]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4781 0.0809 0.3186 0.5181], Lowest was [0.4627 0.0771 0.3109 0.5181]
Median for last 10 epochs: [0.4819 0.0794 0.3165 0.721 ], Epochs since improvement 0
  5%|▌         | 25/500 [31:10<9:34:21, 72.55s/it]   5%|▌         | 26/500 [32:40<10:13:41, 77.68s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.12E+06, Train scatter: [0.4468 0.0759 0.3025 0.5073]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4401 0.0752 0.3075 0.5076], Lowest was [0.4401 0.0752 0.3075 0.5076]
Median for last 10 epochs: [0.4781 0.0772 0.3131 0.5831], Epochs since improvement 0
  5%|▌         | 27/500 [33:40<9:31:39, 72.51s/it]   6%|▌         | 28/500 [35:10<10:09:59, 77.54s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.01E+06, Train scatter: [0.4453 0.0744 0.2874 0.5172]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4372 0.0741 0.2908 0.516 ], Lowest was [0.4372 0.0741 0.2908 0.5076]
Median for last 10 epochs: [0.4627 0.0772 0.3131 0.5181], Epochs since improvement 0
  6%|▌         | 29/500 [36:10<9:28:35, 72.43s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.96E+06, Train scatter: [0.4018 0.0702 0.2987 0.4761]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3911 0.069  0.3019 0.4731], Lowest was [0.3911 0.069  0.2908 0.4731]
Median for last 10 epochs: [0.4401 0.0752 0.3075 0.516 ], Epochs since improvement 0
  6%|▌         | 30/500 [37:46<10:23:13, 79.56s/it]  6%|▌         | 31/500 [38:47<9:37:14, 73.85s/it]   6%|▋         | 32/500 [40:16<10:12:36, 78.54s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.78E+06, Train scatter: [0.4184 0.0696 0.2877 0.4691]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4056 0.0686 0.2908 0.4673], Lowest was [0.3911 0.0686 0.2908 0.4673]
Median for last 10 epochs: [0.4372 0.0741 0.3019 0.5076], Epochs since improvement 0
  7%|▋         | 33/500 [41:17<9:28:47, 73.08s/it]   7%|▋         | 34/500 [42:46<10:05:18, 77.94s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.68E+06, Train scatter: [0.3952 0.0726 0.297  0.4916]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3833 0.071  0.2981 0.4915], Lowest was [0.3833 0.0686 0.2908 0.4673]
Median for last 10 epochs: [0.4056 0.071  0.2981 0.4915], Epochs since improvement 0
  7%|▋         | 35/500 [43:46<9:22:55, 72.63s/it]   7%|▋         | 36/500 [45:15<9:59:39, 77.54s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.92E+06, Train scatter: [0.4189 0.0747 0.3235 0.4805]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4059 0.0732 0.3255 0.4811], Lowest was [0.3833 0.0686 0.2908 0.4673]
Median for last 10 epochs: [0.4056 0.071  0.2981 0.4811], Epochs since improvement 2
  7%|▋         | 37/500 [46:16<9:18:56, 72.43s/it]  8%|▊         | 38/500 [47:46<9:57:58, 77.66s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.70E+06, Train scatter: [0.4706 0.0667 0.2992 0.4841]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4651 0.0661 0.3042 0.4793], Lowest was [0.3833 0.0661 0.2908 0.4673]
Median for last 10 epochs: [0.4056 0.069  0.3019 0.4793], Epochs since improvement 0
  8%|▊         | 39/500 [48:46<9:16:56, 72.49s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.71E+06, Train scatter: [0.4214 0.07   0.3047 0.4896]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4137 0.0695 0.3105 0.4888], Lowest was [0.3833 0.0661 0.2908 0.4673]
Median for last 10 epochs: [0.4059 0.0695 0.3042 0.4811], Epochs since improvement 2
  8%|▊         | 40/500 [50:22<10:10:28, 79.63s/it]  8%|▊         | 41/500 [51:23<9:25:38, 73.94s/it]   8%|▊         | 42/500 [52:52<9:59:17, 78.51s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.49E+06, Train scatter: [0.446  0.065  0.2798 0.458 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4425 0.0648 0.2818 0.459 ], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.4137 0.0695 0.3042 0.4811], Epochs since improvement 0
  9%|▊         | 43/500 [53:53<9:16:24, 73.05s/it]  9%|▉         | 44/500 [55:22<9:51:49, 77.87s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.13E+07, Train scatter: [0.9327 0.1361 0.5443 0.7355]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.917  0.135  0.5355 0.7286], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.4425 0.0695 0.3105 0.4811], Epochs since improvement 2
  9%|▉         | 45/500 [56:22<9:11:28, 72.72s/it]  9%|▉         | 46/500 [57:51<9:46:46, 77.55s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 5.58E+06, Train scatter: [0.9133 0.0993 0.4563 0.6423]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9002 0.1011 0.4529 0.6443], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.4651 0.0695 0.3105 0.4888], Epochs since improvement 4
  9%|▉         | 47/500 [58:52<9:07:05, 72.46s/it] 10%|▉         | 48/500 [1:00:21<9:44:38, 77.61s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.80E+06, Train scatter: [0.8852 0.0882 0.4116 0.5775]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8756 0.0899 0.416  0.581 ], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.8756 0.0899 0.416  0.581 ], Epochs since improvement 6
 10%|▉         | 49/500 [1:01:22<9:04:41, 72.46s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.06E+06, Train scatter: [0.6114 0.079  0.3828 0.5321]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6292 0.081  0.3864 0.5359], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.8756 0.0899 0.416  0.581 ], Epochs since improvement 8
 10%|█         | 50/500 [1:02:58<9:56:15, 79.50s/it] 10%|█         | 51/500 [1:03:58<9:12:10, 73.79s/it] 10%|█         | 52/500 [1:05:27<9:45:33, 78.42s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 2.71E+06, Train scatter: [0.6346 0.0766 0.3744 0.5187]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6368 0.0804 0.3798 0.521 ], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.8756 0.0899 0.416  0.581 ], Epochs since improvement 10
 11%|█         | 53/500 [1:06:28<9:04:43, 73.12s/it] 11%|█         | 54/500 [1:07:57<9:38:48, 77.87s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.48E+06, Train scatter: [0.5695 0.08   0.3822 0.5361]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5724 0.0808 0.3803 0.5369], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.6368 0.081  0.3864 0.5369], Epochs since improvement 12
 11%|█         | 55/500 [1:08:58<8:58:58, 72.67s/it] 11%|█         | 56/500 [1:10:27<9:34:22, 77.62s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.45E+06, Train scatter: [0.5431 0.0732 0.3691 0.5219]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5341 0.0752 0.3755 0.5224], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.6292 0.0808 0.3803 0.5359], Epochs since improvement 14
 11%|█▏        | 57/500 [1:11:27<8:54:53, 72.45s/it] 12%|█▏        | 58/500 [1:12:56<9:29:45, 77.34s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.31E+06, Train scatter: [0.5237 0.0731 0.3557 0.4933]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5203 0.0768 0.3636 0.4922], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.5724 0.0804 0.3798 0.5224], Epochs since improvement 16
 12%|█▏        | 59/500 [1:13:57<8:51:34, 72.32s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.12E+06, Train scatter: [0.4793 0.0664 0.3574 0.4899]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4652 0.0678 0.3627 0.4899], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.5341 0.0768 0.3755 0.521 ], Epochs since improvement 18
 12%|█▏        | 60/500 [1:15:33<9:42:44, 79.47s/it] 12%|█▏        | 61/500 [1:16:33<8:59:34, 73.74s/it] 12%|█▏        | 62/500 [1:18:02<9:31:31, 78.29s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.04E+06, Train scatter: [0.4664 0.0651 0.3494 0.484 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4543 0.066  0.3552 0.4837], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.5203 0.0752 0.3636 0.4922], Epochs since improvement 20
 13%|█▎        | 63/500 [1:19:03<8:51:43, 73.01s/it] 13%|█▎        | 63/500 [1:20:32<9:18:42, 76.71s/it]
Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.93E+06, Train scatter: [0.6456 0.139  0.5132 0.69  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.641  0.1357 0.5079 0.6941], Lowest was [0.3833 0.0648 0.2818 0.459 ]
Median for last 10 epochs: [0.5203 0.0752 0.3636 0.4922], Epochs since improvement 22
Exited after 64 epochs due to early stopping
4832.70 seconds spent training, 9.665 seconds per epoch. Processed 7205 trees per second
[0.64097834 0.13565846 0.50786096 0.6940551 ]
{'epoch_exit': 63, 'scatter_m_star': 0.64097834, 'lowest_m_star': 0.3833235, 'last20_m_star': 0.60084033, 'last10_m_star': 0.52032727, 'scatter_v_disk': 0.13565846, 'lowest_v_disk': 0.06483565, 'last20_v_disk': 0.080619484, 'last10_v_disk': 0.07520999, 'scatter_m_cold': 0.50786096, 'lowest_m_cold': 0.28176293, 'last20_m_cold': 0.38008136, 'last10_m_cold': 0.36363608, 'scatter_sfr_100': 0.6940551, 'lowest_sfr_100': 0.4589584, 'last20_sfr_100': 0.5291338, 'last10_sfr_100': 0.492166}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_rbpmmq
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:24:12, 53.41s/it]  0%|          | 2/500 [02:13<9:33:45, 69.13s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.17   0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1648 0.5355 0.985 ], Lowest was [0.9196 0.1648 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1648 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:06<8:32:00, 61.81s/it]  1%|          | 4/500 [04:27<9:32:23, 69.24s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 9.08E+07, Train scatter: [0.9352 0.1462 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.141  0.5355 0.9851], Lowest was [0.9196 0.141  0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.141  0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:20<8:43:13, 63.42s/it]  1%|          | 6/500 [06:40<9:29:29, 69.17s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.60E+07, Train scatter: [0.935  0.126  0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9194 0.1237 0.5355 0.9851], Lowest was [0.9194 0.1237 0.5355 0.985 ]
Median for last 10 epochs: [0.9194 0.1237 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:33<8:45:20, 63.94s/it]  2%|▏         | 8/500 [08:53<9:26:03, 69.03s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.31E+07, Train scatter: [0.9325 0.1037 0.5436 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.917  0.1037 0.535  0.9851], Lowest was [0.917  0.1037 0.535  0.985 ]
Median for last 10 epochs: [0.9182 0.1137 0.5353 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [09:46<8:44:06, 64.04s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.11E+07, Train scatter: [0.8511 0.0942 0.541  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8411 0.0957 0.5326 0.9851], Lowest was [0.8411 0.0957 0.5326 0.985 ]
Median for last 10 epochs: [0.917  0.1037 0.535  0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:14<9:41:18, 71.18s/it]  2%|▏         | 11/500 [12:07<8:55:09, 65.66s/it]  2%|▏         | 12/500 [13:27<9:30:22, 70.13s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.96E+07, Train scatter: [0.5999 0.0893 0.5322 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6021 0.0897 0.5245 0.985 ], Lowest was [0.6021 0.0897 0.5245 0.985 ]
Median for last 10 epochs: [0.917  0.1037 0.535  0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:20<8:47:43, 65.02s/it]  3%|▎         | 14/500 [15:40<9:23:17, 69.54s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.87E+07, Train scatter: [0.4963 0.0858 0.5299 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4937 0.0864 0.5224 0.9849], Lowest was [0.4937 0.0864 0.5224 0.9849]
Median for last 10 epochs: [0.8411 0.0957 0.5326 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [16:33<8:42:12, 64.60s/it]  3%|▎         | 16/500 [17:53<9:18:02, 69.18s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.81E+07, Train scatter: [0.47   0.0839 0.5338 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4721 0.0841 0.526  0.9849], Lowest was [0.4721 0.0841 0.5224 0.9849]
Median for last 10 epochs: [0.6021 0.0897 0.526  0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [18:46<8:38:17, 64.38s/it]  4%|▎         | 18/500 [20:08<9:17:46, 69.43s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.73E+07, Train scatter: [0.4611 0.082  0.5238 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4645 0.0825 0.5161 0.9849], Lowest was [0.4645 0.0825 0.5161 0.9849]
Median for last 10 epochs: [0.4937 0.0864 0.5245 0.9849], Epochs since improvement 0
  4%|▍         | 19/500 [21:01<8:37:55, 64.61s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.61E+07, Train scatter: [0.5823 0.091  0.5067 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.588  0.0903 0.4997 0.985 ], Lowest was [0.4645 0.0825 0.4997 0.9849]
Median for last 10 epochs: [0.4937 0.0864 0.5224 0.9849], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:29<9:32:08, 71.52s/it]  4%|▍         | 21/500 [23:22<8:47:02, 66.02s/it]  4%|▍         | 22/500 [24:43<9:21:19, 70.46s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.48E+07, Train scatter: [0.5896 0.0872 0.3764 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5786 0.0883 0.3769 0.9849], Lowest was [0.4645 0.0825 0.3769 0.9849]
Median for last 10 epochs: [0.4937 0.0864 0.5161 0.9849], Epochs since improvement 0
  5%|▍         | 23/500 [25:36<8:38:59, 65.28s/it]  5%|▍         | 24/500 [26:56<9:12:07, 69.60s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.46E+07, Train scatter: [0.5231 0.0852 0.3794 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5401 0.086  0.3815 0.985 ], Lowest was [0.4645 0.0825 0.3769 0.9849]
Median for last 10 epochs: [0.5401 0.086  0.4997 0.9849], Epochs since improvement 2
  5%|▌         | 25/500 [27:49<8:32:01, 64.68s/it]  5%|▌         | 26/500 [29:09<9:08:24, 69.42s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.39E+07, Train scatter: [0.5315 0.082  0.3345 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5312 0.0829 0.336  0.985 ], Lowest was [0.4645 0.0825 0.336  0.9849]
Median for last 10 epochs: [0.5401 0.086  0.3815 0.985 ], Epochs since improvement 0
  5%|▌         | 27/500 [30:03<8:29:12, 64.59s/it]  6%|▌         | 28/500 [31:23<9:05:53, 69.39s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.37E+07, Train scatter: [0.5119 0.0803 0.3471 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5075 0.0812 0.3527 0.985 ], Lowest was [0.4645 0.0812 0.336  0.9849]
Median for last 10 epochs: [0.5401 0.086  0.3769 0.985 ], Epochs since improvement 0
  6%|▌         | 29/500 [32:17<8:26:57, 64.58s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.34E+07, Train scatter: [0.5487 0.0803 0.3207 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5433 0.0812 0.3248 0.985 ], Lowest was [0.4645 0.0812 0.3248 0.9849]
Median for last 10 epochs: [0.5401 0.0829 0.3527 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [33:44<9:19:12, 71.39s/it]  6%|▌         | 31/500 [34:37<8:35:13, 65.91s/it]  6%|▋         | 32/500 [35:57<9:06:53, 70.11s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.30E+07, Train scatter: [0.4837 0.0853 0.331  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.479  0.0849 0.334  0.9851], Lowest was [0.4645 0.0812 0.3248 0.9849]
Median for last 10 epochs: [0.5312 0.0829 0.336  0.985 ], Epochs since improvement 2
  7%|▋         | 33/500 [36:50<8:26:27, 65.07s/it]  7%|▋         | 34/500 [38:10<9:00:12, 69.56s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.28E+07, Train scatter: [0.8893 0.0798 0.3316 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8744 0.0807 0.3345 0.9851], Lowest was [0.4645 0.0807 0.3248 0.9849]
Median for last 10 epochs: [0.5312 0.0812 0.3345 0.985 ], Epochs since improvement 0
  7%|▋         | 35/500 [39:03<8:20:53, 64.63s/it]  7%|▋         | 36/500 [40:23<8:54:14, 69.08s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.22E+07, Train scatter: [0.8732 0.0788 0.2951 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.859  0.0801 0.3001 0.9851], Lowest was [0.4645 0.0801 0.3001 0.9849]
Median for last 10 epochs: [0.5433 0.0812 0.334  0.9851], Epochs since improvement 0
  7%|▋         | 37/500 [41:16<8:15:55, 64.27s/it]  8%|▊         | 38/500 [42:37<8:52:50, 69.20s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.56E+07, Train scatter: [0.8063 0.1438 0.3602 0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7899 0.1419 0.3678 0.9847], Lowest was [0.4645 0.0801 0.3001 0.9847]
Median for last 10 epochs: [0.7899 0.0812 0.334  0.9851], Epochs since improvement 0
  8%|▊         | 39/500 [43:30<8:15:17, 64.46s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.22E+07, Train scatter: [0.7814 0.0821 0.3247 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7683 0.0828 0.3279 0.9849], Lowest was [0.4645 0.0801 0.3001 0.9847]
Median for last 10 epochs: [0.7899 0.0828 0.334  0.9851], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [44:57<9:05:21, 71.13s/it]  8%|▊         | 41/500 [45:50<8:22:57, 65.75s/it]  8%|▊         | 42/500 [47:10<8:54:55, 70.08s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.17E+07, Train scatter: [0.9196 0.1734 0.5439 0.979 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.904  0.1693 0.5353 0.9696], Lowest was [0.4645 0.0801 0.3001 0.9696]
Median for last 10 epochs: [0.859  0.0828 0.3345 0.9849], Epochs since improvement 0
  9%|▊         | 43/500 [48:03<8:15:24, 65.04s/it]  9%|▉         | 44/500 [49:23<8:48:11, 69.50s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 7.99E+06, Train scatter: [0.5179 0.1035 0.436  0.6897]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5084 0.1025 0.432  0.6752], Lowest was [0.4645 0.0801 0.3001 0.6752]
Median for last 10 epochs: [0.7899 0.1025 0.3678 0.9847], Epochs since improvement 0
  9%|▉         | 45/500 [50:16<8:09:50, 64.60s/it]  9%|▉         | 46/500 [51:36<8:43:48, 69.23s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 5.90E+06, Train scatter: [0.4388 0.0944 0.3973 0.5906]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4347 0.0939 0.3957 0.5856], Lowest was [0.4347 0.0801 0.3001 0.5856]
Median for last 10 epochs: [0.7683 0.1025 0.3957 0.9696], Epochs since improvement 0
  9%|▉         | 47/500 [52:30<8:06:15, 64.40s/it] 10%|▉         | 48/500 [53:50<8:40:34, 69.10s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 5.28E+06, Train scatter: [0.4817 0.09   0.3797 0.577 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4799 0.0898 0.3795 0.573 ], Lowest was [0.4347 0.0801 0.3001 0.573 ]
Median for last 10 epochs: [0.5084 0.0939 0.3957 0.6752], Epochs since improvement 0
 10%|▉         | 49/500 [54:43<8:03:41, 64.35s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 4.66E+06, Train scatter: [0.458  0.087  0.3749 0.5906]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4553 0.0868 0.3751 0.5812], Lowest was [0.4347 0.0801 0.3001 0.573 ]
Median for last 10 epochs: [0.4799 0.0939 0.3957 0.5856], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [56:10<8:53:47, 71.17s/it] 10%|█         | 51/500 [57:03<8:12:08, 65.76s/it] 10%|█         | 52/500 [58:23<8:43:16, 70.08s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 4.44E+06, Train scatter: [0.3288 0.0832 0.3598 0.533 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3445 0.0833 0.3602 0.5312], Lowest was [0.3445 0.0801 0.3001 0.5312]
Median for last 10 epochs: [0.4553 0.0898 0.3795 0.5812], Epochs since improvement 0
 11%|█         | 53/500 [59:16<8:04:19, 65.01s/it] 11%|█         | 54/500 [1:00:36<8:35:54, 69.40s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 4.15E+06, Train scatter: [0.3013 0.0806 0.3469 0.5284]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3168 0.0809 0.3484 0.5263], Lowest was [0.3168 0.0801 0.3001 0.5263]
Median for last 10 epochs: [0.4347 0.0868 0.3751 0.573 ], Epochs since improvement 0
 11%|█         | 55/500 [1:01:29<7:58:54, 64.57s/it] 11%|█         | 56/500 [1:02:50<8:33:12, 69.35s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.16E+06, Train scatter: [0.3707 0.0787 0.3447 0.5314]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3581 0.0797 0.3511 0.5316], Lowest was [0.3168 0.0797 0.3001 0.5263]
Median for last 10 epochs: [0.3581 0.0833 0.3602 0.5316], Epochs since improvement 0
 11%|█▏        | 57/500 [1:03:43<7:55:57, 64.46s/it] 12%|█▏        | 58/500 [1:05:03<8:29:54, 69.22s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.91E+06, Train scatter: [0.4349 0.0795 0.3494 0.5132]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4268 0.0795 0.3516 0.5116], Lowest was [0.3168 0.0795 0.3001 0.5116]
Median for last 10 epochs: [0.3581 0.0809 0.3516 0.5312], Epochs since improvement 0
 12%|█▏        | 59/500 [1:05:56<7:53:24, 64.41s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 4.20E+06, Train scatter: [0.2888 0.0752 0.3262 0.5088]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2912 0.0753 0.3294 0.5064], Lowest was [0.2912 0.0753 0.3001 0.5064]
Median for last 10 epochs: [0.3445 0.0797 0.3511 0.5263], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:07:23<8:42:10, 71.21s/it] 12%|█▏        | 61/500 [1:08:17<8:01:21, 65.79s/it] 12%|█▏        | 62/500 [1:09:37<8:31:19, 70.04s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.80E+06, Train scatter: [0.2984 0.0737 0.319  0.4987]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3078 0.0741 0.3275 0.4978], Lowest was [0.2912 0.0741 0.3001 0.4978]
Median for last 10 epochs: [0.3168 0.0795 0.3484 0.5116], Epochs since improvement 0
 13%|█▎        | 63/500 [1:10:30<7:53:10, 64.97s/it] 13%|█▎        | 64/500 [1:11:50<8:26:33, 69.71s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.70E+06, Train scatter: [0.3602 0.0994 0.3746 0.5468]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3675 0.1029 0.3851 0.5456], Lowest was [0.2912 0.0741 0.3001 0.4978]
Median for last 10 epochs: [0.3581 0.0795 0.3511 0.5116], Epochs since improvement 2
 13%|█▎        | 65/500 [1:12:44<7:49:06, 64.71s/it] 13%|█▎        | 66/500 [1:14:04<8:23:14, 69.57s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.24E+06, Train scatter: [0.2587 0.0701 0.3145 0.4978]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2673 0.0714 0.3224 0.4975], Lowest was [0.2673 0.0714 0.3001 0.4975]
Median for last 10 epochs: [0.3078 0.0753 0.3294 0.5064], Epochs since improvement 0
 13%|█▎        | 67/500 [1:14:57<7:46:10, 64.60s/it] 14%|█▎        | 68/500 [1:16:17<8:18:07, 69.18s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.29E+06, Train scatter: [0.255  0.0716 0.3214 0.4948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.27   0.0723 0.3268 0.4969], Lowest was [0.2673 0.0714 0.3001 0.4969]
Median for last 10 epochs: [0.2912 0.0741 0.3275 0.4978], Epochs since improvement 0
 14%|█▍        | 69/500 [1:17:11<7:42:39, 64.41s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.15E+06, Train scatter: [0.2646 0.0677 0.3118 0.4932]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2728 0.0684 0.3176 0.4933], Lowest was [0.2673 0.0684 0.3001 0.4933]
Median for last 10 epochs: [0.2728 0.0723 0.3268 0.4975], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:18:37<8:29:46, 71.13s/it] 14%|█▍        | 71/500 [1:19:31<7:49:58, 65.73s/it] 14%|█▍        | 72/500 [1:20:53<8:23:49, 70.63s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.06E+06, Train scatter: [0.3109 0.0737 0.318  0.5282]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3148 0.0743 0.3209 0.522 ], Lowest was [0.2673 0.0684 0.3001 0.4933]
Median for last 10 epochs: [0.2728 0.0723 0.3224 0.4975], Epochs since improvement 2
 15%|█▍        | 73/500 [1:21:46<7:46:03, 65.49s/it] 15%|█▍        | 74/500 [1:23:09<8:21:25, 70.62s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.02E+06, Train scatter: [0.2434 0.0686 0.2983 0.4872]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2546 0.0701 0.3056 0.4876], Lowest was [0.2546 0.0684 0.3001 0.4876]
Median for last 10 epochs: [0.27   0.0714 0.3209 0.4969], Epochs since improvement 0
 15%|█▌        | 75/500 [1:24:03<7:45:06, 65.66s/it] 15%|█▌        | 76/500 [1:25:26<8:20:49, 70.87s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.86E+06, Train scatter: [0.2273 0.0661 0.2889 0.4777]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2398 0.0669 0.2977 0.4774], Lowest was [0.2398 0.0669 0.2977 0.4774]
Median for last 10 epochs: [0.27   0.0701 0.3176 0.4933], Epochs since improvement 0
 15%|█▌        | 77/500 [1:26:20<7:43:24, 65.73s/it] 16%|█▌        | 78/500 [1:27:44<8:22:33, 71.45s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.09E+06, Train scatter: [0.2298 0.0648 0.2919 0.4797]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2412 0.0653 0.2983 0.4823], Lowest was [0.2398 0.0653 0.2977 0.4774]
Median for last 10 epochs: [0.2546 0.0684 0.3056 0.4876], Epochs since improvement 0
 16%|█▌        | 79/500 [1:28:38<7:43:29, 66.06s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.70E+06, Train scatter: [0.2339 0.0636 0.2858 0.4731]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2432 0.0644 0.2901 0.4733], Lowest was [0.2398 0.0644 0.2901 0.4733]
Median for last 10 epochs: [0.2432 0.0669 0.2983 0.4823], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:30:07<8:30:44, 72.96s/it] 16%|█▌        | 81/500 [1:31:00<7:47:40, 66.97s/it] 16%|█▋        | 82/500 [1:32:20<8:13:33, 70.85s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.69E+06, Train scatter: [0.2191 0.0638 0.2774 0.4678]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2306 0.0635 0.2816 0.4681], Lowest was [0.2306 0.0635 0.2816 0.4681]
Median for last 10 epochs: [0.2412 0.0653 0.2977 0.4774], Epochs since improvement 0
 17%|█▋        | 83/500 [1:33:13<7:35:22, 65.52s/it] 17%|█▋        | 84/500 [1:34:33<8:05:39, 70.05s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.66E+06, Train scatter: [0.2853 0.0653 0.2872 0.5113]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.296  0.0657 0.2928 0.519 ], Lowest was [0.2306 0.0635 0.2816 0.4681]
Median for last 10 epochs: [0.2412 0.0653 0.2928 0.4774], Epochs since improvement 2
 17%|█▋        | 85/500 [1:35:26<7:29:06, 64.93s/it] 17%|█▋        | 86/500 [1:36:47<8:00:43, 69.67s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.57E+06, Train scatter: [0.2574 0.0629 0.2758 0.4667]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2675 0.0636 0.2842 0.4704], Lowest was [0.2306 0.0635 0.2816 0.4681]
Median for last 10 epochs: [0.2432 0.0644 0.2901 0.4733], Epochs since improvement 4
 17%|█▋        | 87/500 [1:37:40<7:25:05, 64.66s/it] 18%|█▊        | 88/500 [1:39:00<7:55:24, 69.24s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.39E+06, Train scatter: [0.2999 0.062  0.2937 0.4688]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3023 0.062  0.2991 0.4704], Lowest was [0.2306 0.062  0.2816 0.4681]
Median for last 10 epochs: [0.2675 0.0636 0.2901 0.4704], Epochs since improvement 0
 18%|█▊        | 89/500 [1:39:53<7:20:45, 64.34s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.42E+06, Train scatter: [0.2335 0.0603 0.2698 0.4543]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2404 0.0608 0.2743 0.4568], Lowest was [0.2306 0.0608 0.2743 0.4568]
Median for last 10 epochs: [0.2675 0.0635 0.2842 0.4704], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:41:21<8:09:05, 71.57s/it] 18%|█▊        | 91/500 [1:42:15<7:30:13, 66.05s/it] 18%|█▊        | 92/500 [1:43:35<7:58:23, 70.35s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.33E+06, Train scatter: [0.2313 0.0651 0.304  0.4637]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2422 0.0652 0.3064 0.4628], Lowest was [0.2306 0.0608 0.2743 0.4568]
Median for last 10 epochs: [0.2675 0.0636 0.2928 0.4704], Epochs since improvement 2
 19%|█▊        | 93/500 [1:44:28<7:22:11, 65.19s/it] 19%|█▉        | 94/500 [1:45:48<7:51:12, 69.64s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.36E+06, Train scatter: [0.2025 0.0604 0.2752 0.4509]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2143 0.0608 0.2808 0.4513], Lowest was [0.2143 0.0608 0.2743 0.4513]
Median for last 10 epochs: [0.2422 0.062  0.2842 0.4628], Epochs since improvement 0
 19%|█▉        | 95/500 [1:46:41<7:16:38, 64.69s/it] 19%|█▉        | 96/500 [1:48:00<7:44:02, 68.92s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.29E+06, Train scatter: [0.2523 0.0596 0.2701 0.4481]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2542 0.0603 0.2777 0.4512], Lowest was [0.2143 0.0603 0.2743 0.4512]
Median for last 10 epochs: [0.2422 0.0608 0.2808 0.4568], Epochs since improvement 0
 19%|█▉        | 97/500 [1:48:53<7:11:08, 64.19s/it] 20%|█▉        | 98/500 [1:50:13<7:40:59, 68.81s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.20E+06, Train scatter: [0.2119 0.0579 0.2686 0.4693]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2304 0.0587 0.2759 0.4681], Lowest was [0.2143 0.0587 0.2743 0.4512]
Median for last 10 epochs: [0.2404 0.0608 0.2777 0.4568], Epochs since improvement 0
 20%|█▉        | 99/500 [1:51:06<7:08:54, 64.18s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 2.07E+06, Train scatter: [0.213  0.0587 0.2673 0.4464]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2293 0.0593 0.2741 0.4528], Lowest was [0.2143 0.0587 0.2741 0.4512]
Median for last 10 epochs: [0.2304 0.0603 0.2777 0.4528], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:52:33<7:53:39, 71.05s/it] 20%|██        | 101/500 [1:53:27<7:16:55, 65.70s/it] 20%|██        | 102/500 [1:54:47<7:44:33, 70.03s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 1.89E+06, Train scatter: [0.2327 0.058  0.272  0.4582]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2416 0.059  0.2803 0.4695], Lowest was [0.2143 0.0587 0.2741 0.4512]
Median for last 10 epochs: [0.2304 0.0593 0.2777 0.4528], Epochs since improvement 2
 21%|██        | 103/500 [1:55:40<7:10:10, 65.01s/it] 21%|██        | 104/500 [1:57:00<7:38:57, 69.54s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 1.84E+06, Train scatter: [0.2457 0.0614 0.2685 0.4526]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2492 0.0623 0.2766 0.4576], Lowest was [0.2143 0.0587 0.2741 0.4512]
Median for last 10 epochs: [0.2416 0.0593 0.2766 0.4576], Epochs since improvement 4
 21%|██        | 105/500 [1:57:53<7:05:46, 64.67s/it] 21%|██        | 106/500 [1:59:13<7:33:54, 69.12s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 1.76E+06, Train scatter: [0.1973 0.0547 0.2568 0.4348]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2071 0.0547 0.2603 0.4367], Lowest was [0.2071 0.0547 0.2603 0.4367]
Median for last 10 epochs: [0.2304 0.059  0.2759 0.4576], Epochs since improvement 0
 21%|██▏       | 107/500 [2:00:06<7:01:23, 64.34s/it] 22%|██▏       | 108/500 [2:01:26<7:30:06, 68.89s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 1.72E+06, Train scatter: [0.2152 0.0708 0.2893 0.449 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2241 0.0688 0.294  0.4527], Lowest was [0.2071 0.0547 0.2603 0.4367]
Median for last 10 epochs: [0.2293 0.0593 0.2766 0.4528], Epochs since improvement 2
 22%|██▏       | 109/500 [2:02:19<6:58:32, 64.23s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 1.63E+06, Train scatter: [0.2197 0.0618 0.2676 0.4505]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2299 0.0617 0.2715 0.4551], Lowest was [0.2071 0.0547 0.2603 0.4367]
Median for last 10 epochs: [0.2299 0.0617 0.2766 0.4551], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:03:45<7:40:08, 70.79s/it] 22%|██▏       | 111/500 [2:04:38<7:04:58, 65.55s/it] 22%|██▏       | 112/500 [2:05:58<7:31:55, 69.89s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.61E+06, Train scatter: [0.1898 0.0545 0.2495 0.4275]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2    0.055  0.2541 0.4313], Lowest was [0.2    0.0547 0.2541 0.4313]
Median for last 10 epochs: [0.2241 0.0617 0.2715 0.4527], Epochs since improvement 0
 23%|██▎       | 113/500 [2:06:51<6:58:22, 64.87s/it] 23%|██▎       | 114/500 [2:08:12<7:27:41, 69.59s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.46E+06, Train scatter: [0.1868 0.053  0.2478 0.4348]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1975 0.0539 0.2533 0.4411], Lowest was [0.1975 0.0539 0.2533 0.4313]
Median for last 10 epochs: [0.2071 0.055  0.2603 0.4411], Epochs since improvement 0
 23%|██▎       | 115/500 [2:09:05<6:54:59, 64.67s/it] 23%|██▎       | 116/500 [2:10:25<7:22:52, 69.20s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.48E+06, Train scatter: [0.1988 0.0578 0.2514 0.4263]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2109 0.0581 0.2568 0.4308], Lowest was [0.1975 0.0539 0.2533 0.4308]
Median for last 10 epochs: [0.2109 0.0581 0.2568 0.4411], Epochs since improvement 0
 23%|██▎       | 117/500 [2:11:18<6:51:12, 64.42s/it] 24%|██▎       | 118/500 [2:12:39<7:20:14, 69.15s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.35E+06, Train scatter: [0.1856 0.0527 0.2512 0.4269]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1932 0.0531 0.2578 0.4304], Lowest was [0.1932 0.0531 0.2533 0.4304]
Median for last 10 epochs: [0.2    0.055  0.2568 0.4313], Epochs since improvement 0
 24%|██▍       | 119/500 [2:13:32<6:48:53, 64.39s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.32E+06, Train scatter: [0.1977 0.0544 0.2643 0.437 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2035 0.0548 0.2674 0.4361], Lowest was [0.1932 0.0531 0.2533 0.4304]
Median for last 10 epochs: [0.2    0.0548 0.2568 0.4313], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 24%|██▍       | 120/500 [2:14:59<7:30:29, 71.13s/it] 24%|██▍       | 121/500 [2:15:52<6:55:25, 65.77s/it] 24%|██▍       | 122/500 [2:17:13<7:22:46, 70.28s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 1.11E+06, Train scatter: [0.1865 0.054  0.2526 0.42  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1957 0.0541 0.2578 0.4242], Lowest was [0.1932 0.0531 0.2533 0.4242]
Median for last 10 epochs: [0.1975 0.0541 0.2578 0.4308], Epochs since improvement 0
 25%|██▍       | 123/500 [2:18:06<6:49:08, 65.11s/it] 25%|██▍       | 124/500 [2:19:27<7:17:56, 69.88s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.21E+06, Train scatter: [0.1769 0.052  0.247  0.421 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1852 0.0528 0.2545 0.421 ], Lowest was [0.1852 0.0528 0.2533 0.421 ]
Median for last 10 epochs: [0.1957 0.0541 0.2578 0.4304], Epochs since improvement 0
 25%|██▌       | 125/500 [2:20:20<6:45:37, 64.90s/it] 25%|██▌       | 126/500 [2:21:41<7:14:15, 69.67s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.17E+06, Train scatter: [0.2027 0.053  0.2527 0.4285]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2043 0.0532 0.2581 0.4315], Lowest was [0.1852 0.0528 0.2533 0.421 ]
Median for last 10 epochs: [0.1957 0.0532 0.2578 0.4304], Epochs since improvement 2
 25%|██▌       | 127/500 [2:22:34<6:41:55, 64.65s/it] 26%|██▌       | 128/500 [2:23:56<7:12:59, 69.84s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 1.06E+06, Train scatter: [0.1812 0.0528 0.25   0.4255]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1904 0.053  0.2543 0.4242], Lowest was [0.1852 0.0528 0.2533 0.421 ]
Median for last 10 epochs: [0.1957 0.0532 0.2578 0.4242], Epochs since improvement 4
 26%|██▌       | 129/500 [2:24:49<6:40:53, 64.83s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 1.03E+06, Train scatter: [0.1746 0.0509 0.2497 0.4188]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1814 0.0511 0.2545 0.42  ], Lowest was [0.1814 0.0511 0.2533 0.42  ]
Median for last 10 epochs: [0.1904 0.053  0.2545 0.4242], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 26%|██▌       | 130/500 [2:26:18<7:24:23, 72.06s/it] 26%|██▌       | 131/500 [2:27:11<6:48:21, 66.40s/it] 26%|██▋       | 132/500 [2:28:31<7:12:38, 70.54s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 1.01E+06, Train scatter: [0.1843 0.0552 0.2665 0.4442]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1901 0.0556 0.2722 0.4436], Lowest was [0.1814 0.0511 0.2533 0.42  ]
Median for last 10 epochs: [0.1901 0.053  0.2545 0.4242], Epochs since improvement 2
 27%|██▋       | 133/500 [2:29:24<6:39:36, 65.33s/it] 27%|██▋       | 134/500 [2:30:45<7:06:54, 69.98s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 9.93E+05, Train scatter: [0.2018 0.0516 0.2535 0.4205]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2533 0.0527 0.2584 0.4219], Lowest was [0.1814 0.0511 0.2533 0.42  ]
Median for last 10 epochs: [0.1904 0.053  0.2581 0.4242], Epochs since improvement 4
 27%|██▋       | 135/500 [2:31:38<6:35:02, 64.94s/it] 27%|██▋       | 136/500 [2:32:59<7:02:47, 69.69s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 9.19E+05, Train scatter: [0.1821 0.0494 0.2473 0.4082]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.336  0.0496 0.2508 0.4099], Lowest was [0.1814 0.0496 0.2508 0.4099]
Median for last 10 epochs: [0.1904 0.0527 0.2545 0.4219], Epochs since improvement 0
 27%|██▋       | 137/500 [2:33:52<6:31:33, 64.72s/it] 28%|██▊       | 138/500 [2:35:14<7:00:50, 69.75s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: 9.19E+05, Train scatter: [0.1838 0.0484 0.2445 0.4116]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2191 0.0485 0.2496 0.4134], Lowest was [0.1814 0.0485 0.2496 0.4099]
Median for last 10 epochs: [0.2191 0.0511 0.2545 0.42  ], Epochs since improvement 0
 28%|██▊       | 139/500 [2:36:07<6:29:34, 64.75s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: 9.13E+05, Train scatter: [0.196  0.0573 0.2824 0.432 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.217  0.0584 0.2927 0.433 ], Lowest was [0.1814 0.0485 0.2496 0.4099]
Median for last 10 epochs: [0.2191 0.0527 0.2584 0.4219], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 28%|██▊       | 140/500 [2:37:35<7:11:14, 71.87s/it] 28%|██▊       | 141/500 [2:38:28<6:36:09, 66.21s/it] 28%|██▊       | 142/500 [2:39:48<6:58:46, 70.19s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: 8.11E+05, Train scatter: [0.1875 0.0573 0.2512 0.4244]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2211 0.0572 0.2554 0.4196], Lowest was [0.1814 0.0485 0.2496 0.4099]
Median for last 10 epochs: [0.2211 0.0527 0.2554 0.4196], Epochs since improvement 4
 29%|██▊       | 143/500 [2:40:41<6:27:01, 65.04s/it] 29%|██▉       | 144/500 [2:42:01<6:52:56, 69.60s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 8.20E+05, Train scatter: [0.1707 0.0515 0.2682 0.4276]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2484 0.0526 0.2733 0.4345], Lowest was [0.1814 0.0485 0.2496 0.4099]
Median for last 10 epochs: [0.2211 0.0526 0.2554 0.4196], Epochs since improvement 6
 29%|██▉       | 145/500 [2:42:54<6:22:41, 64.68s/it] 29%|██▉       | 146/500 [2:44:15<6:49:52, 69.47s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 7.58E+05, Train scatter: [0.154  0.0486 0.2435 0.4115]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2433 0.0489 0.2485 0.41  ], Lowest was [0.1814 0.0485 0.2485 0.4099]
Median for last 10 epochs: [0.2211 0.0526 0.2554 0.4196], Epochs since improvement 0
 29%|██▉       | 147/500 [2:45:08<6:20:31, 64.68s/it] 30%|██▉       | 148/500 [2:46:29<6:46:32, 69.30s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 7.75E+05, Train scatter: [0.1648 0.0492 0.2421 0.4063]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2106 0.0495 0.244  0.4084], Lowest was [0.1814 0.0485 0.244  0.4084]
Median for last 10 epochs: [0.2211 0.0526 0.2554 0.4196], Epochs since improvement 0
 30%|██▉       | 149/500 [2:47:22<6:17:23, 64.51s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 6.72E+05, Train scatter: [0.17   0.05   0.2477 0.4145]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2568 0.0504 0.2548 0.4141], Lowest was [0.1814 0.0485 0.244  0.4084]
Median for last 10 epochs: [0.2433 0.0504 0.2548 0.4141], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 30%|███       | 150/500 [2:48:50<6:58:03, 71.67s/it] 30%|███       | 151/500 [2:49:43<6:24:31, 66.11s/it] 30%|███       | 152/500 [2:51:04<6:48:09, 70.37s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 6.13E+05, Train scatter: [0.1758 0.0492 0.2385 0.4121]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3378 0.0497 0.2437 0.4145], Lowest was [0.1814 0.0485 0.2437 0.4084]
Median for last 10 epochs: [0.2484 0.0497 0.2485 0.4141], Epochs since improvement 0
 31%|███       | 153/500 [2:51:57<6:17:09, 65.21s/it] 31%|███       | 154/500 [2:53:17<6:41:34, 69.64s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 5.28E+05, Train scatter: [0.1649 0.0513 0.241  0.4015]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3355 0.051  0.243  0.4004], Lowest was [0.1814 0.0485 0.243  0.4004]
Median for last 10 epochs: [0.2568 0.0497 0.244  0.41  ], Epochs since improvement 0
 31%|███       | 155/500 [2:54:10<6:11:53, 64.68s/it] 31%|███       | 156/500 [2:55:30<6:37:37, 69.35s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 4.96E+05, Train scatter: [0.169  0.0471 0.2398 0.4037]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2885 0.0474 0.2443 0.4055], Lowest was [0.1814 0.0474 0.243  0.4004]
Median for last 10 epochs: [0.2885 0.0497 0.244  0.4084], Epochs since improvement 0
 31%|███▏      | 157/500 [2:56:23<6:08:30, 64.46s/it] 32%|███▏      | 158/500 [2:57:44<6:34:48, 69.27s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 4.11E+05, Train scatter: [0.1528 0.0478 0.2769 0.4105]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2729 0.0484 0.2799 0.4142], Lowest was [0.1814 0.0474 0.243  0.4004]
Median for last 10 epochs: [0.2885 0.0497 0.2443 0.4141], Epochs since improvement 2
 32%|███▏      | 159/500 [2:58:37<6:06:12, 64.44s/it]Epoch: 160 done with learning rate 9.04E-03, Train loss: 3.60E+05, Train scatter: [0.1561 0.0451 0.233  0.3976]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2573 0.0452 0.2363 0.3962], Lowest was [0.1814 0.0452 0.2363 0.3962]
Median for last 10 epochs: [0.2885 0.0484 0.2437 0.4055], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 32%|███▏      | 160/500 [3:00:04<6:44:20, 71.36s/it] 32%|███▏      | 161/500 [3:00:58<6:12:28, 65.93s/it] 32%|███▏      | 162/500 [3:02:18<6:35:11, 70.15s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: 2.47E+05, Train scatter: [0.1444 0.0471 0.2586 0.3958]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2983 0.0471 0.2602 0.397 ], Lowest was [0.1814 0.0452 0.2363 0.3962]
Median for last 10 epochs: [0.2885 0.0474 0.2443 0.4004], Epochs since improvement 2
 33%|███▎      | 163/500 [3:03:11<6:05:38, 65.10s/it] 33%|███▎      | 164/500 [3:04:32<6:30:58, 69.82s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: 2.09E+05, Train scatter: [0.1527 0.0463 0.2369 0.395 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2778 0.0464 0.2416 0.397 ], Lowest was [0.1814 0.0452 0.2363 0.3962]
Median for last 10 epochs: [0.2778 0.0471 0.2443 0.397 ], Epochs since improvement 4
 33%|███▎      | 165/500 [3:05:25<6:01:46, 64.80s/it] 33%|███▎      | 166/500 [3:06:46<6:28:45, 69.84s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: 1.48E+05, Train scatter: [0.1504 0.0442 0.233  0.3867]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2568 0.0443 0.2381 0.3894], Lowest was [0.1814 0.0443 0.2363 0.3894]
Median for last 10 epochs: [0.2729 0.0464 0.2416 0.397 ], Epochs since improvement 0
 33%|███▎      | 167/500 [3:07:40<5:59:54, 64.85s/it] 34%|███▎      | 168/500 [3:09:01<6:26:17, 69.81s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: 5.28E+04, Train scatter: [0.1411 0.0456 0.256  0.3998]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2612 0.0461 0.2605 0.405 ], Lowest was [0.1814 0.0443 0.2363 0.3894]
Median for last 10 epochs: [0.2612 0.0461 0.2416 0.397 ], Epochs since improvement 2
 34%|███▍      | 169/500 [3:09:54<5:57:26, 64.79s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -6.73E+03, Train scatter: [0.1788 0.0537 0.2541 0.4235]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2305 0.0542 0.2582 0.4279], Lowest was [0.1814 0.0443 0.2363 0.3894]
Median for last 10 epochs: [0.2612 0.0464 0.2582 0.397 ], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 34%|███▍      | 170/500 [3:11:21<6:33:31, 71.55s/it] 34%|███▍      | 171/500 [3:12:15<6:01:57, 66.01s/it] 34%|███▍      | 172/500 [3:13:35<6:25:19, 70.49s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -6.88E+04, Train scatter: [0.1393 0.0436 0.2233 0.3947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2647 0.0438 0.2291 0.3917], Lowest was [0.1814 0.0438 0.2291 0.3894]
Median for last 10 epochs: [0.2612 0.0461 0.2416 0.397 ], Epochs since improvement 0
 35%|███▍      | 173/500 [3:14:29<5:56:12, 65.36s/it] 35%|███▍      | 174/500 [3:15:49<6:19:54, 69.92s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -1.27E+05, Train scatter: [0.1371 0.0455 0.2264 0.3832]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2544 0.0456 0.2319 0.3854], Lowest was [0.1814 0.0438 0.2291 0.3854]
Median for last 10 epochs: [0.2568 0.0456 0.2381 0.3917], Epochs since improvement 0
 35%|███▌      | 175/500 [3:16:43<5:51:32, 64.90s/it] 35%|███▌      | 176/500 [3:18:03<6:16:11, 69.66s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -1.77E+05, Train scatter: [0.1471 0.0462 0.2744 0.3874]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2263 0.0462 0.2738 0.3902], Lowest was [0.1814 0.0438 0.2291 0.3854]
Median for last 10 epochs: [0.2544 0.0461 0.2582 0.3917], Epochs since improvement 2
 35%|███▌      | 177/500 [3:18:57<5:48:39, 64.77s/it] 36%|███▌      | 178/500 [3:20:17<6:12:13, 69.36s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -2.21E+05, Train scatter: [0.1283 0.0444 0.2268 0.3874]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3272 0.0446 0.2334 0.3884], Lowest was [0.1814 0.0438 0.2291 0.3854]
Median for last 10 epochs: [0.2544 0.0456 0.2334 0.3902], Epochs since improvement 4
 36%|███▌      | 179/500 [3:21:10<5:44:57, 64.48s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -2.67E+05, Train scatter: [0.1376 0.0459 0.22   0.3807]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3441 0.0458 0.2263 0.3823], Lowest was [0.1814 0.0438 0.2263 0.3823]
Median for last 10 epochs: [0.2647 0.0456 0.2319 0.3884], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 36%|███▌      | 180/500 [3:22:37<6:19:17, 71.12s/it] 36%|███▌      | 181/500 [3:23:30<5:49:36, 65.76s/it] 36%|███▋      | 182/500 [3:24:50<6:10:52, 69.98s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -2.88E+05, Train scatter: [0.1398 0.0423 0.2223 0.3881]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2082 0.0424 0.2287 0.3899], Lowest was [0.1814 0.0424 0.2263 0.3823]
Median for last 10 epochs: [0.2544 0.0456 0.2319 0.3884], Epochs since improvement 0
 37%|███▋      | 183/500 [3:25:43<5:43:13, 64.97s/it] 37%|███▋      | 184/500 [3:27:03<6:06:07, 69.52s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -3.13E+05, Train scatter: [0.1253 0.042  0.2206 0.383 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1702 0.0423 0.2268 0.3856], Lowest was [0.1702 0.0423 0.2263 0.3823]
Median for last 10 epochs: [0.2263 0.0446 0.2287 0.3884], Epochs since improvement 0
 37%|███▋      | 185/500 [3:27:56<5:39:15, 64.62s/it] 37%|███▋      | 186/500 [3:29:16<6:01:59, 69.17s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -3.37E+05, Train scatter: [0.1257 0.041  0.2152 0.3769]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1665 0.0411 0.2212 0.3797], Lowest was [0.1665 0.0411 0.2212 0.3797]
Median for last 10 epochs: [0.2082 0.0424 0.2268 0.3856], Epochs since improvement 0
 37%|███▋      | 187/500 [3:30:09<5:35:49, 64.38s/it] 38%|███▊      | 188/500 [3:31:30<6:00:41, 69.36s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -3.16E+05, Train scatter: [0.35   0.048  0.2276 0.3888]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3411 0.0483 0.2305 0.3884], Lowest was [0.1665 0.0411 0.2212 0.3797]
Median for last 10 epochs: [0.2082 0.0424 0.2268 0.3856], Epochs since improvement 2
 38%|███▊      | 189/500 [3:32:23<5:34:19, 64.50s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -3.46E+05, Train scatter: [0.1532 0.0486 0.2528 0.4275]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2063 0.0485 0.2572 0.4269], Lowest was [0.1665 0.0411 0.2212 0.3797]
Median for last 10 epochs: [0.2063 0.0424 0.2287 0.3884], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 38%|███▊      | 190/500 [3:33:52<6:10:04, 71.63s/it] 38%|███▊      | 191/500 [3:34:45<5:40:27, 66.11s/it] 38%|███▊      | 192/500 [3:36:06<6:02:36, 70.64s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -3.67E+05, Train scatter: [0.128  0.0434 0.2222 0.3923]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1337 0.0431 0.2283 0.391 ], Lowest was [0.1337 0.0411 0.2212 0.3797]
Median for last 10 epochs: [0.1702 0.0431 0.2283 0.3884], Epochs since improvement 0
 39%|███▊      | 193/500 [3:36:59<5:34:40, 65.41s/it] 39%|███▉      | 194/500 [3:38:20<5:57:03, 70.01s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -3.54E+05, Train scatter: [0.1286 0.0417 0.212  0.3803]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1334 0.0419 0.2167 0.382 ], Lowest was [0.1334 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1665 0.0431 0.2283 0.3884], Epochs since improvement 0
 39%|███▉      | 195/500 [3:39:13<5:30:19, 64.98s/it] 39%|███▉      | 196/500 [3:40:34<5:53:55, 69.85s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -3.97E+05, Train scatter: [0.1272 0.0472 0.2646 0.4076]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1347 0.0471 0.269  0.4105], Lowest was [0.1334 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1347 0.0471 0.2305 0.391 ], Epochs since improvement 2
 39%|███▉      | 197/500 [3:41:28<5:27:41, 64.89s/it] 40%|███▉      | 198/500 [3:42:48<5:49:56, 69.52s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -2.56E+05, Train scatter: [0.153  0.0569 0.2884 0.4254]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1589 0.0552 0.2898 0.4181], Lowest was [0.1334 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1347 0.0471 0.2572 0.4105], Epochs since improvement 4
 40%|███▉      | 199/500 [3:43:41<5:24:16, 64.64s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -3.46E+05, Train scatter: [0.1523 0.0512 0.2564 0.4014]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1531 0.0501 0.2598 0.3955], Lowest was [0.1334 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1347 0.0471 0.2598 0.3955], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 40%|████      | 200/500 [3:45:09<5:57:31, 71.50s/it] 40%|████      | 201/500 [3:46:02<5:29:00, 66.02s/it] 40%|████      | 202/500 [3:47:22<5:48:57, 70.26s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -3.66E+05, Train scatter: [0.1276 0.047  0.2277 0.3996]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1312 0.0459 0.2314 0.3939], Lowest was [0.1312 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1347 0.0471 0.2598 0.3955], Epochs since improvement 0
 41%|████      | 203/500 [3:48:16<5:22:38, 65.18s/it] 41%|████      | 204/500 [3:49:36<5:43:48, 69.69s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -4.03E+05, Train scatter: [0.1258 0.0418 0.2208 0.3926]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1287 0.0414 0.2233 0.3888], Lowest was [0.1287 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1347 0.0471 0.2598 0.3955], Epochs since improvement 0
 41%|████      | 205/500 [3:50:29<5:18:20, 64.75s/it] 41%|████      | 206/500 [3:51:49<5:40:18, 69.45s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -4.02E+05, Train scatter: [0.1444 0.0474 0.2195 0.3969]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1464 0.0466 0.2228 0.3915], Lowest was [0.1287 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1464 0.0466 0.2314 0.3939], Epochs since improvement 2
 41%|████▏     | 207/500 [3:52:43<5:15:28, 64.60s/it] 42%|████▏     | 208/500 [3:54:03<5:37:06, 69.27s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -3.96E+05, Train scatter: [0.131  0.0429 0.2147 0.4027]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1355 0.0425 0.2186 0.3974], Lowest was [0.1287 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1355 0.0459 0.2233 0.3939], Epochs since improvement 4
 42%|████▏     | 209/500 [3:54:56<5:12:32, 64.44s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -3.44E+05, Train scatter: [0.1384 0.0458 0.263  0.4193]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1405 0.0453 0.2664 0.4084], Lowest was [0.1287 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1355 0.0453 0.2233 0.3939], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 42%|████▏     | 210/500 [3:56:23<5:43:56, 71.16s/it] 42%|████▏     | 211/500 [3:57:16<5:16:54, 65.79s/it] 42%|████▏     | 212/500 [3:58:36<5:36:04, 70.02s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -4.13E+05, Train scatter: [0.1517 0.0441 0.2255 0.4116]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1563 0.0454 0.2307 0.4125], Lowest was [0.1287 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1405 0.0453 0.2233 0.3974], Epochs since improvement 8
 43%|████▎     | 213/500 [3:59:29<5:10:52, 64.99s/it] 43%|████▎     | 214/500 [4:00:51<5:33:45, 70.02s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: -4.11E+05, Train scatter: [0.1517 0.0452 0.2202 0.3988]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1544 0.0465 0.2242 0.394 ], Lowest was [0.1287 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1464 0.0454 0.2242 0.3974], Epochs since improvement 10
 43%|████▎     | 215/500 [4:01:44<5:08:23, 64.92s/it] 43%|████▎     | 216/500 [4:03:05<5:29:41, 69.65s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -4.11E+05, Train scatter: [0.1366 0.0502 0.2807 0.4179]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1408 0.051  0.2845 0.4181], Lowest was [0.1287 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1408 0.0454 0.2307 0.4084], Epochs since improvement 12
 43%|████▎     | 217/500 [4:03:58<5:05:33, 64.78s/it] 44%|████▎     | 218/500 [4:05:19<5:26:48, 69.53s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -3.79E+05, Train scatter: [0.1458 0.0424 0.2167 0.3959]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1458 0.0423 0.2223 0.394 ], Lowest was [0.1287 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1458 0.0454 0.2307 0.4084], Epochs since improvement 14
 44%|████▍     | 219/500 [4:06:12<5:02:50, 64.66s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -3.86E+05, Train scatter: [0.1541 0.0468 0.25   0.4301]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1544 0.0464 0.2564 0.4291], Lowest was [0.1287 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1544 0.0464 0.2307 0.4125], Epochs since improvement 16
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 44%|████▍     | 220/500 [4:07:40<5:33:35, 71.48s/it] 44%|████▍     | 221/500 [4:08:33<5:06:51, 65.99s/it] 44%|████▍     | 222/500 [4:09:53<5:25:19, 70.21s/it]Epoch: 222 done with learning rate 7.33E-03, Train loss: -3.97E+05, Train scatter: [0.1961 0.0488 0.3085 0.4164]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1982 0.0482 0.3108 0.4085], Lowest was [0.1287 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1544 0.0465 0.2564 0.4085], Epochs since improvement 18
 45%|████▍     | 223/500 [4:10:46<5:00:35, 65.11s/it] 45%|████▍     | 224/500 [4:12:06<5:20:21, 69.64s/it]Epoch: 224 done with learning rate 7.26E-03, Train loss: -2.74E+05, Train scatter: [0.1926 0.0444 0.235  0.4245]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1926 0.044  0.2387 0.4187], Lowest was [0.1287 0.0411 0.2167 0.3797]
Median for last 10 epochs: [0.1544 0.0464 0.2564 0.4181], Epochs since improvement 20
 45%|████▌     | 225/500 [4:13:00<4:56:45, 64.75s/it] 45%|████▌     | 226/500 [4:14:21<5:18:15, 69.69s/it]Epoch: 226 done with learning rate 7.20E-03, Train loss: -4.08E+05, Train scatter: [0.1235 0.041  0.2182 0.4065]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1255 0.0406 0.22   0.3978], Lowest was [0.1255 0.0406 0.2167 0.3797]
Median for last 10 epochs: [0.1544 0.044  0.2387 0.4085], Epochs since improvement 0
 45%|████▌     | 227/500 [4:15:14<4:54:21, 64.69s/it] 46%|████▌     | 228/500 [4:16:35<5:15:06, 69.51s/it]Epoch: 228 done with learning rate 7.13E-03, Train loss: -4.12E+05, Train scatter: [0.1349 0.0416 0.2152 0.4177]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1379 0.041  0.2192 0.4141], Lowest was [0.1255 0.0406 0.2167 0.3797]
Median for last 10 epochs: [0.1544 0.044  0.2387 0.4141], Epochs since improvement 2
 46%|████▌     | 229/500 [4:17:28<4:51:56, 64.64s/it]Epoch: 230 done with learning rate 7.06E-03, Train loss: -4.19E+05, Train scatter: [0.1293 0.0409 0.2118 0.4008]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1325 0.0404 0.2155 0.3952], Lowest was [0.1255 0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1379 0.041  0.22   0.4085], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 46%|████▌     | 230/500 [4:18:57<5:24:27, 72.10s/it] 46%|████▌     | 231/500 [4:19:51<4:57:52, 66.44s/it] 46%|████▋     | 232/500 [4:21:11<5:15:26, 70.62s/it]Epoch: 232 done with learning rate 6.99E-03, Train loss: -4.11E+05, Train scatter: [0.2133 0.0603 0.2841 0.4576]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.213  0.0595 0.2872 0.4585], Lowest was [0.1255 0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1379 0.041  0.22   0.4141], Epochs since improvement 2
 47%|████▋     | 233/500 [4:22:04<4:51:14, 65.45s/it] 47%|████▋     | 234/500 [4:23:25<5:10:15, 69.98s/it]Epoch: 234 done with learning rate 6.93E-03, Train loss: -3.94E+05, Train scatter: [0.3642 0.0467 0.2488 0.4165]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3528 0.0458 0.2516 0.4108], Lowest was [0.1255 0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1379 0.041  0.22   0.4108], Epochs since improvement 4
 47%|████▋     | 235/500 [4:24:18<4:46:56, 64.97s/it] 47%|████▋     | 236/500 [4:25:39<5:06:37, 69.69s/it]Epoch: 236 done with learning rate 6.86E-03, Train loss: -4.24E+05, Train scatter: [0.1236 0.0411 0.2187 0.4004]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.124  0.0408 0.2226 0.3962], Lowest was [0.124  0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1379 0.041  0.2226 0.4108], Epochs since improvement 0
 47%|████▋     | 237/500 [4:26:32<4:43:57, 64.78s/it] 48%|████▊     | 238/500 [4:27:52<5:03:13, 69.44s/it]Epoch: 238 done with learning rate 6.79E-03, Train loss: -4.25E+05, Train scatter: [0.1557 0.0428 0.217  0.4007]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1526 0.0426 0.2209 0.3976], Lowest was [0.124  0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1526 0.0426 0.2226 0.3976], Epochs since improvement 2
 48%|████▊     | 239/500 [4:28:46<4:40:45, 64.54s/it]Epoch: 240 done with learning rate 6.72E-03, Train loss: -4.12E+05, Train scatter: [0.4073 0.1045 0.4656 0.479 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3965 0.1021 0.4564 0.4753], Lowest was [0.124  0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.213  0.0458 0.2516 0.4108], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 48%|████▊     | 240/500 [4:30:14<5:10:22, 71.62s/it] 48%|████▊     | 241/500 [4:31:07<4:45:23, 66.12s/it] 48%|████▊     | 242/500 [4:32:27<5:02:24, 70.33s/it]Epoch: 242 done with learning rate 6.65E-03, Train loss: -4.14E+05, Train scatter: [0.1252 0.0413 0.2592 0.4009]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1263 0.0408 0.2584 0.3926], Lowest was [0.124  0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1526 0.0426 0.2516 0.3976], Epochs since improvement 6
 49%|████▊     | 243/500 [4:33:20<4:39:12, 65.19s/it] 49%|████▉     | 244/500 [4:34:40<4:56:53, 69.58s/it]Epoch: 244 done with learning rate 6.58E-03, Train loss: -4.26E+05, Train scatter: [0.1824 0.0464 0.2358 0.4201]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1791 0.0456 0.2371 0.4097], Lowest was [0.124  0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1526 0.0426 0.2371 0.3976], Epochs since improvement 8
 49%|████▉     | 245/500 [4:35:33<4:34:48, 64.66s/it] 49%|████▉     | 246/500 [4:36:54<4:53:28, 69.32s/it]Epoch: 246 done with learning rate 6.51E-03, Train loss: -4.45E+05, Train scatter: [0.1472 0.0431 0.2113 0.3985]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1465 0.0424 0.2157 0.3911], Lowest was [0.124  0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1526 0.0426 0.2371 0.3976], Epochs since improvement 10
 49%|████▉     | 247/500 [4:37:47<4:32:01, 64.51s/it] 50%|████▉     | 248/500 [4:39:07<4:50:38, 69.20s/it]Epoch: 248 done with learning rate 6.44E-03, Train loss: -4.43E+05, Train scatter: [0.2128 0.0441 0.2245 0.4087]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2126 0.0435 0.2268 0.4058], Lowest was [0.124  0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1791 0.0435 0.2371 0.4058], Epochs since improvement 12
 50%|████▉     | 249/500 [4:40:00<4:29:27, 64.41s/it]Epoch: 250 done with learning rate 6.37E-03, Train loss: -4.33E+05, Train scatter: [0.1931 0.0496 0.2227 0.4053]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1918 0.0485 0.2246 0.3988], Lowest was [0.124  0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1791 0.0435 0.2268 0.3988], Epochs since improvement 14
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 50%|█████     | 250/500 [4:41:27<4:56:33, 71.17s/it] 50%|█████     | 251/500 [4:42:20<4:32:59, 65.78s/it] 50%|█████     | 252/500 [4:43:40<4:49:22, 70.01s/it]Epoch: 252 done with learning rate 6.30E-03, Train loss: -4.47E+05, Train scatter: [0.1787 0.0415 0.215  0.399 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1789 0.0412 0.2188 0.3915], Lowest was [0.124  0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1791 0.0435 0.2246 0.3988], Epochs since improvement 16
 51%|█████     | 253/500 [4:44:33<4:27:21, 64.94s/it] 51%|█████     | 254/500 [4:45:53<4:44:49, 69.47s/it]Epoch: 254 done with learning rate 6.23E-03, Train loss: -4.55E+05, Train scatter: [0.1267 0.0422 0.2133 0.3983]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1282 0.042  0.2167 0.3928], Lowest was [0.124  0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1789 0.0424 0.2188 0.3928], Epochs since improvement 18
 51%|█████     | 255/500 [4:46:47<4:23:44, 64.59s/it] 51%|█████     | 256/500 [4:48:07<4:42:31, 69.48s/it]Epoch: 256 done with learning rate 6.15E-03, Train loss: -4.52E+05, Train scatter: [0.1224 0.0426 0.2269 0.4012]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1239 0.0425 0.2328 0.3979], Lowest was [0.1239 0.0404 0.2155 0.3797]
Median for last 10 epochs: [0.1789 0.0425 0.2246 0.3979], Epochs since improvement 0
 51%|█████▏    | 257/500 [4:49:01<4:21:29, 64.56s/it] 52%|█████▏    | 258/500 [4:50:20<4:38:54, 69.15s/it]Epoch: 258 done with learning rate 6.08E-03, Train loss: -4.57E+05, Train scatter: [0.1192 0.0404 0.2246 0.4003]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1245 0.0401 0.2277 0.3923], Lowest was [0.1239 0.0401 0.2155 0.3797]
Median for last 10 epochs: [0.1282 0.042  0.2246 0.3928], Epochs since improvement 0
 52%|█████▏    | 259/500 [4:51:14<4:18:41, 64.40s/it]Epoch: 260 done with learning rate 6.01E-03, Train loss: -4.52E+05, Train scatter: [0.1558 0.0413 0.2233 0.4476]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1592 0.0408 0.2244 0.4379], Lowest was [0.1239 0.0401 0.2155 0.3797]
Median for last 10 epochs: [0.1282 0.0412 0.2244 0.3928], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 52%|█████▏    | 260/500 [4:52:40<4:43:40, 70.92s/it] 52%|█████▏    | 261/500 [4:53:33<4:21:22, 65.62s/it] 52%|█████▏    | 262/500 [4:54:55<4:39:06, 70.36s/it]Epoch: 262 done with learning rate 5.94E-03, Train loss: -4.72E+05, Train scatter: [0.1507 0.0412 0.2216 0.4207]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1523 0.0409 0.2252 0.4113], Lowest was [0.1239 0.0401 0.2155 0.3797]
Median for last 10 epochs: [0.1282 0.0409 0.2252 0.3979], Epochs since improvement 4
 53%|█████▎    | 263/500 [4:55:48<4:17:36, 65.22s/it] 53%|█████▎    | 264/500 [4:57:09<4:35:53, 70.14s/it]Epoch: 264 done with learning rate 5.86E-03, Train loss: -4.35E+05, Train scatter: [0.1247 0.0404 0.2734 0.3963]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1303 0.04   0.2728 0.3888], Lowest was [0.1239 0.04   0.2155 0.3797]
Median for last 10 epochs: [0.1303 0.0408 0.2277 0.3979], Epochs since improvement 0
 53%|█████▎    | 265/500 [4:58:03<4:14:47, 65.05s/it] 53%|█████▎    | 266/500 [4:59:23<4:31:17, 69.56s/it]Epoch: 266 done with learning rate 5.79E-03, Train loss: -4.18E+05, Train scatter: [0.1206 0.039  0.226  0.3967]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1274 0.0389 0.2293 0.3898], Lowest was [0.1239 0.0389 0.2155 0.3797]
Median for last 10 epochs: [0.1303 0.0401 0.2277 0.3923], Epochs since improvement 0
 53%|█████▎    | 267/500 [5:00:16<4:11:02, 64.65s/it] 54%|█████▎    | 268/500 [5:01:37<4:29:00, 69.57s/it]Epoch: 268 done with learning rate 5.72E-03, Train loss: -4.49E+05, Train scatter: [0.1256 0.0425 0.2285 0.4123]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1317 0.0422 0.2316 0.4067], Lowest was [0.1239 0.0389 0.2155 0.3797]
Median for last 10 epochs: [0.1317 0.0408 0.2293 0.4067], Epochs since improvement 2
 54%|█████▍    | 269/500 [5:02:30<4:08:52, 64.64s/it]Epoch: 270 done with learning rate 5.64E-03, Train loss: -4.83E+05, Train scatter: [0.1146 0.0387 0.2053 0.3915]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1209 0.0388 0.2097 0.3859], Lowest was [0.1209 0.0388 0.2097 0.3797]
Median for last 10 epochs: [0.1303 0.04   0.2293 0.3898], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 54%|█████▍    | 270/500 [5:03:58<4:34:18, 71.56s/it] 54%|█████▍    | 271/500 [5:04:51<4:12:08, 66.06s/it] 54%|█████▍    | 272/500 [5:06:12<4:28:18, 70.61s/it]Epoch: 272 done with learning rate 5.57E-03, Train loss: -4.78E+05, Train scatter: [0.1993 0.0434 0.2174 0.403 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2029 0.0431 0.2216 0.3992], Lowest was [0.1209 0.0388 0.2097 0.3797]
Median for last 10 epochs: [0.1303 0.04   0.2293 0.3898], Epochs since improvement 2
 55%|█████▍    | 273/500 [5:07:05<4:07:25, 65.40s/it] 55%|█████▍    | 274/500 [5:08:27<4:24:58, 70.35s/it]Epoch: 274 done with learning rate 5.50E-03, Train loss: -4.88E+05, Train scatter: [0.1401 0.043  0.2223 0.4065]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1434 0.0425 0.2246 0.4024], Lowest was [0.1209 0.0388 0.2097 0.3797]
Median for last 10 epochs: [0.1317 0.0422 0.2246 0.3992], Epochs since improvement 4
 55%|█████▌    | 275/500 [5:09:21<4:04:32, 65.21s/it] 55%|█████▌    | 276/500 [5:10:43<4:22:15, 70.25s/it]Epoch: 276 done with learning rate 5.42E-03, Train loss: -4.89E+05, Train scatter: [0.13   0.0407 0.2177 0.3969]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1332 0.04   0.219  0.3884], Lowest was [0.1209 0.0388 0.2097 0.3797]
Median for last 10 epochs: [0.1332 0.0422 0.2216 0.3992], Epochs since improvement 6
 55%|█████▌    | 277/500 [5:11:36<4:02:09, 65.15s/it] 56%|█████▌    | 278/500 [5:12:57<4:19:07, 70.03s/it]Epoch: 278 done with learning rate 5.35E-03, Train loss: -4.89E+05, Train scatter: [0.1174 0.0378 0.2054 0.3949]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.12   0.0377 0.2101 0.3894], Lowest was [0.12   0.0377 0.2097 0.3797]
Median for last 10 epochs: [0.1332 0.04   0.219  0.3894], Epochs since improvement 0
 56%|█████▌    | 279/500 [5:13:51<3:59:43, 65.08s/it]Epoch: 280 done with learning rate 5.28E-03, Train loss: -4.90E+05, Train scatter: [0.116  0.0382 0.207  0.3866]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1267 0.0382 0.2119 0.3817], Lowest was [0.12   0.0377 0.2097 0.3797]
Median for last 10 epochs: [0.1332 0.04   0.219  0.3894], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 56%|█████▌    | 280/500 [5:15:18<4:22:48, 71.68s/it] 56%|█████▌    | 281/500 [5:16:11<4:01:36, 66.20s/it] 56%|█████▋    | 282/500 [5:17:33<4:17:06, 70.76s/it]Epoch: 282 done with learning rate 5.20E-03, Train loss: -4.91E+05, Train scatter: [0.1472 0.0406 0.2086 0.3969]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1509 0.0402 0.2122 0.3873], Lowest was [0.12   0.0377 0.2097 0.3797]
Median for last 10 epochs: [0.1332 0.04   0.2122 0.3884], Epochs since improvement 4
 57%|█████▋    | 283/500 [5:18:26<3:57:00, 65.53s/it] 57%|█████▋    | 284/500 [5:19:46<4:12:03, 70.02s/it]Epoch: 284 done with learning rate 5.13E-03, Train loss: -4.93E+05, Train scatter: [0.1134 0.0375 0.2026 0.3854]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1188 0.0375 0.2071 0.38  ], Lowest was [0.1188 0.0375 0.2071 0.3797]
Median for last 10 epochs: [0.1267 0.0382 0.2119 0.3873], Epochs since improvement 0
 57%|█████▋    | 285/500 [5:20:40<3:52:55, 65.00s/it] 57%|█████▋    | 286/500 [5:22:00<4:08:23, 69.64s/it]Epoch: 286 done with learning rate 5.06E-03, Train loss: -5.01E+05, Train scatter: [0.1217 0.0377 0.2068 0.389 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1275 0.0378 0.2114 0.3852], Lowest was [0.1188 0.0375 0.2071 0.3797]
Median for last 10 epochs: [0.1267 0.0378 0.2114 0.3852], Epochs since improvement 2
 57%|█████▋    | 287/500 [5:22:53<3:49:39, 64.69s/it] 58%|█████▊    | 288/500 [5:24:15<4:06:15, 69.70s/it]Epoch: 288 done with learning rate 4.98E-03, Train loss: -4.96E+05, Train scatter: [0.1201 0.0402 0.2084 0.3959]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1244 0.0403 0.2135 0.3911], Lowest was [0.1188 0.0375 0.2071 0.3797]
Median for last 10 epochs: [0.1267 0.0382 0.2119 0.3852], Epochs since improvement 4
 58%|█████▊    | 289/500 [5:25:08<3:47:52, 64.80s/it]Epoch: 290 done with learning rate 4.91E-03, Train loss: -5.02E+05, Train scatter: [0.1217 0.0428 0.2261 0.3976]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1245 0.0427 0.2291 0.3926], Lowest was [0.1188 0.0375 0.2071 0.3797]
Median for last 10 epochs: [0.1245 0.0402 0.2122 0.3873], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 58%|█████▊    | 290/500 [5:26:36<4:10:32, 71.58s/it] 58%|█████▊    | 291/500 [5:27:29<3:50:07, 66.06s/it] 58%|█████▊    | 292/500 [5:28:50<4:04:20, 70.48s/it]Epoch: 292 done with learning rate 4.83E-03, Train loss: -5.01E+05, Train scatter: [0.1201 0.0379 0.2029 0.3828]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1245 0.0382 0.2087 0.3785], Lowest was [0.1188 0.0375 0.2071 0.3785]
Median for last 10 epochs: [0.1245 0.0382 0.2114 0.3852], Epochs since improvement 0
 59%|█████▊    | 293/500 [5:29:43<3:45:30, 65.36s/it] 59%|█████▉    | 294/500 [5:31:05<4:01:10, 70.25s/it]Epoch: 294 done with learning rate 4.76E-03, Train loss: -5.09E+05, Train scatter: [0.1891 0.04   0.2128 0.4029]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1879 0.0399 0.2164 0.3941], Lowest was [0.1188 0.0375 0.2071 0.3785]
Median for last 10 epochs: [0.1245 0.0399 0.2135 0.3911], Epochs since improvement 2
 59%|█████▉    | 295/500 [5:31:58<3:42:31, 65.13s/it] 59%|█████▉    | 296/500 [5:33:19<3:57:52, 69.96s/it]Epoch: 296 done with learning rate 4.69E-03, Train loss: -5.14E+05, Train scatter: [0.125  0.041  0.2079 0.3819]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1346 0.0414 0.2117 0.379 ], Lowest was [0.1188 0.0375 0.2071 0.3785]
Median for last 10 epochs: [0.1245 0.0403 0.2135 0.3911], Epochs since improvement 4
 59%|█████▉    | 297/500 [5:34:12<3:39:38, 64.92s/it] 60%|█████▉    | 298/500 [5:35:33<3:55:00, 69.81s/it]Epoch: 298 done with learning rate 4.61E-03, Train loss: -5.11E+05, Train scatter: [0.1101 0.0367 0.1993 0.3826]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1225 0.0371 0.2035 0.3779], Lowest was [0.1188 0.0371 0.2035 0.3779]
Median for last 10 epochs: [0.1245 0.0399 0.2117 0.379 ], Epochs since improvement 0
 60%|█████▉    | 299/500 [5:36:27<3:37:09, 64.82s/it]Epoch: 300 done with learning rate 4.54E-03, Train loss: -5.14E+05, Train scatter: [0.1063 0.0362 0.2001 0.3821]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1201 0.0363 0.2045 0.377 ], Lowest was [0.1188 0.0363 0.2035 0.377 ]
Median for last 10 epochs: [0.1245 0.0382 0.2087 0.3785], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 60%|██████    | 300/500 [5:37:55<3:59:42, 71.91s/it] 60%|██████    | 301/500 [5:38:48<3:39:56, 66.31s/it] 60%|██████    | 302/500 [5:40:10<3:53:39, 70.81s/it]Epoch: 302 done with learning rate 4.47E-03, Train loss: -5.11E+05, Train scatter: [0.1092 0.037  0.2029 0.3782]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.136  0.037  0.2076 0.374 ], Lowest was [0.1188 0.0363 0.2035 0.374 ]
Median for last 10 epochs: [0.1346 0.0371 0.2076 0.3779], Epochs since improvement 0
 61%|██████    | 303/500 [5:41:03<3:35:04, 65.51s/it] 61%|██████    | 304/500 [5:42:24<3:49:45, 70.33s/it]Epoch: 304 done with learning rate 4.39E-03, Train loss: -5.24E+05, Train scatter: [0.108  0.0364 0.1964 0.3754]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.114  0.0366 0.201  0.3715], Lowest was [0.114  0.0363 0.201  0.3715]
Median for last 10 epochs: [0.1225 0.037  0.2045 0.377 ], Epochs since improvement 0
 61%|██████    | 305/500 [5:43:17<3:31:51, 65.19s/it] 61%|██████    | 306/500 [5:44:38<3:45:34, 69.77s/it]Epoch: 306 done with learning rate 4.32E-03, Train loss: -5.26E+05, Train scatter: [0.1058 0.0361 0.2045 0.381 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1138 0.0362 0.2087 0.3733], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.1201 0.0366 0.2045 0.374 ], Epochs since improvement 0
 61%|██████▏   | 307/500 [5:45:31<3:28:32, 64.83s/it] 62%|██████▏   | 308/500 [5:46:52<3:42:47, 69.62s/it]Epoch: 308 done with learning rate 4.25E-03, Train loss: -3.96E+05, Train scatter: [0.9168 0.1631 0.5354 0.9696]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9014 0.1597 0.5273 0.9601], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.1201 0.0366 0.2076 0.374 ], Epochs since improvement 2
 62%|██████▏   | 309/500 [5:47:45<3:25:52, 64.67s/it]Epoch: 310 done with learning rate 4.17E-03, Train loss: -2.67E+05, Train scatter: [0.9067 0.1712 0.5436 0.985 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8923 0.1674 0.535  0.9751], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.136  0.037  0.2087 0.374 ], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 62%|██████▏   | 310/500 [5:49:16<3:49:14, 72.39s/it] 62%|██████▏   | 311/500 [5:50:09<3:29:58, 66.66s/it] 62%|██████▏   | 312/500 [5:51:29<3:41:49, 70.79s/it]Epoch: 312 done with learning rate 4.10E-03, Train loss: -6.06E+04, Train scatter: [0.5967 0.1619 0.5214 0.7936]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5896 0.1585 0.5142 0.7872], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.5896 0.1585 0.5142 0.7872], Epochs since improvement 6
 63%|██████▎   | 313/500 [5:52:23<3:24:18, 65.55s/it] 63%|██████▎   | 314/500 [5:53:42<3:36:10, 69.73s/it]Epoch: 314 done with learning rate 4.03E-03, Train loss: -2.15E+05, Train scatter: [0.2759 0.0813 0.3837 0.5471]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2788 0.0802 0.3821 0.5427], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.5896 0.1585 0.5142 0.7872], Epochs since improvement 8
 63%|██████▎   | 315/500 [5:54:35<3:19:37, 64.74s/it] 63%|██████▎   | 316/500 [5:55:55<3:32:30, 69.30s/it]Epoch: 316 done with learning rate 3.95E-03, Train loss: -3.30E+05, Train scatter: [0.1687 0.0508 0.279  0.4712]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1658 0.0505 0.2793 0.46  ], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.5896 0.1585 0.5142 0.7872], Epochs since improvement 10
 63%|██████▎   | 317/500 [5:56:48<3:16:43, 64.50s/it] 64%|██████▎   | 318/500 [5:58:09<3:30:02, 69.25s/it]Epoch: 318 done with learning rate 3.88E-03, Train loss: -3.41E+05, Train scatter: [0.1563 0.0476 0.2759 0.4611]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1528 0.0472 0.2764 0.4523], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.2788 0.0802 0.3821 0.5427], Epochs since improvement 12
 64%|██████▍   | 319/500 [5:59:02<3:14:28, 64.47s/it]Epoch: 320 done with learning rate 3.81E-03, Train loss: -3.91E+05, Train scatter: [0.1592 0.0462 0.2534 0.4441]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1568 0.0457 0.2554 0.4334], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.1658 0.0505 0.2793 0.46  ], Epochs since improvement 14
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 64%|██████▍   | 320/500 [6:00:29<3:33:28, 71.16s/it] 64%|██████▍   | 321/500 [6:01:22<3:16:20, 65.81s/it] 64%|██████▍   | 322/500 [6:02:42<3:27:52, 70.07s/it]Epoch: 322 done with learning rate 3.74E-03, Train loss: -4.13E+05, Train scatter: [0.1289 0.0435 0.2363 0.4325]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1273 0.043  0.2385 0.4227], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.1568 0.0472 0.2764 0.4523], Epochs since improvement 16
 65%|██████▍   | 323/500 [6:03:35<3:11:50, 65.03s/it] 65%|██████▍   | 324/500 [6:04:56<3:24:01, 69.55s/it]Epoch: 324 done with learning rate 3.67E-03, Train loss: -4.26E+05, Train scatter: [0.1316 0.0411 0.228  0.4228]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1312 0.0408 0.2309 0.4133], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.1528 0.0457 0.2554 0.4334], Epochs since improvement 18
 65%|██████▌   | 325/500 [6:05:49<3:08:33, 64.65s/it] 65%|██████▌   | 326/500 [6:07:09<3:21:22, 69.44s/it]Epoch: 326 done with learning rate 3.60E-03, Train loss: -4.19E+05, Train scatter: [0.1344 0.0415 0.2296 0.4227]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1349 0.0411 0.2324 0.415 ], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.1349 0.043  0.2385 0.4227], Epochs since improvement 20
 65%|██████▌   | 327/500 [6:08:03<3:06:10, 64.57s/it] 65%|██████▌   | 327/500 [6:09:23<3:15:25, 67.78s/it]
Epoch: 328 done with learning rate 3.53E-03, Train loss: -4.41E+05, Train scatter: [0.1244 0.0407 0.2201 0.4134]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1242 0.0402 0.2233 0.4038], Lowest was [0.1138 0.0362 0.201  0.3715]
Median for last 10 epochs: [0.1312 0.0411 0.2324 0.415 ], Epochs since improvement 22
Exited after 328 epochs due to early stopping
22163.48 seconds spent training, 44.327 seconds per epoch. Processed 1571 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.1241579  0.04022238 0.22325471 0.40380815]
{'epoch_exit': 327, 'scatter_m_star': 0.1241579, 'lowest_m_star': 0.11383682, 'last20_m_star': 0.15482187, 'last10_m_star': 0.1312326, 'scatter_v_disk': 0.040222384, 'lowest_v_disk': 0.03615818, 'last20_v_disk': 0.04645808, 'last10_v_disk': 0.04112641, 'scatter_m_cold': 0.22325471, 'lowest_m_cold': 0.20103586, 'last20_m_cold': 0.26592064, 'last10_m_cold': 0.23241553, 'scatter_sfr_100': 0.40380815, 'lowest_sfr_100': 0.37154523, 'last20_sfr_100': 0.44283807, 'last10_sfr_100': 0.41499227}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
