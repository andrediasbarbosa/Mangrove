Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_lqzdqp
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:32<4:28:29, 32.28s/it]  0%|          | 2/500 [01:20<5:47:48, 41.91s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.21E+07, Train scatter: [0.9353 0.1747 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1818 0.5356 0.9851], Lowest was [0.9198 0.1818 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1818 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:52<5:07:59, 37.18s/it]  1%|          | 4/500 [02:41<5:47:19, 42.02s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 7.46E+06, Train scatter: [0.9352 0.1758 0.544  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1877 0.5354 0.985 ], Lowest was [0.9197 0.1818 0.5354 0.985 ]
Median for last 10 epochs: [0.9197 0.1848 0.5354 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:13<5:15:52, 38.29s/it]  1%|          | 6/500 [04:02<5:46:11, 42.05s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.68E+06, Train scatter: [0.9347 0.1421 0.5428 0.729 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9191 0.1451 0.5343 0.7251], Lowest was [0.9191 0.1451 0.5343 0.7251]
Median for last 10 epochs: [0.9191 0.1451 0.5343 0.7251], Epochs since improvement 0
  1%|▏         | 7/500 [04:34<5:17:42, 38.67s/it]  2%|▏         | 8/500 [05:24<5:45:08, 42.09s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.83E+06, Train scatter: [0.9251 0.1259 0.5368 0.6708]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9098 0.127  0.5284 0.6646], Lowest was [0.9098 0.127  0.5284 0.6646]
Median for last 10 epochs: [0.9145 0.1361 0.5314 0.6948], Epochs since improvement 0
  2%|▏         | 9/500 [05:55<5:17:50, 38.84s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.15E+06, Train scatter: [0.7491 0.1113 0.5219 0.6319]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7341 0.1133 0.5143 0.6354], Lowest was [0.7341 0.1133 0.5143 0.6354]
Median for last 10 epochs: [0.9098 0.127  0.5284 0.6646], Epochs since improvement 0
  2%|▏         | 10/500 [06:50<5:57:33, 43.78s/it]  2%|▏         | 11/500 [07:22<5:26:41, 40.08s/it]  2%|▏         | 12/500 [08:12<5:50:06, 43.05s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.52E+06, Train scatter: [0.5978 0.1088 0.4288 0.6246]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5983 0.1112 0.4231 0.6146], Lowest was [0.5983 0.1112 0.4231 0.6146]
Median for last 10 epochs: [0.9098 0.127  0.5284 0.6646], Epochs since improvement 0
  3%|▎         | 13/500 [08:43<5:21:23, 39.60s/it]  3%|▎         | 14/500 [09:33<5:45:50, 42.70s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.72E+06, Train scatter: [0.554  0.1023 0.376  0.6007]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5241 0.1059 0.3747 0.5999], Lowest was [0.5241 0.1059 0.3747 0.5999]
Median for last 10 epochs: [0.7341 0.1133 0.5143 0.6354], Epochs since improvement 0
  3%|▎         | 15/500 [10:05<5:18:16, 39.37s/it]  3%|▎         | 16/500 [10:55<5:42:51, 42.50s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.27E+06, Train scatter: [0.5401 0.0993 0.3552 0.5923]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5244 0.1046 0.3553 0.5937], Lowest was [0.5241 0.1046 0.3553 0.5937]
Median for last 10 epochs: [0.5983 0.1112 0.4231 0.6146], Epochs since improvement 0
  3%|▎         | 17/500 [11:26<5:16:07, 39.27s/it]  4%|▎         | 18/500 [12:16<5:40:13, 42.35s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.03E+06, Train scatter: [0.553  0.0956 0.3611 0.614 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.534  0.0989 0.3565 0.6144], Lowest was [0.5241 0.0989 0.3553 0.5937]
Median for last 10 epochs: [0.534  0.1059 0.3747 0.6144], Epochs since improvement 0
  4%|▍         | 19/500 [12:48<5:13:50, 39.15s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.77E+05, Train scatter: [0.651  0.0939 0.3418 0.6003]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6012 0.0998 0.3515 0.6004], Lowest was [0.5241 0.0989 0.3515 0.5937]
Median for last 10 epochs: [0.534  0.1046 0.3565 0.6004], Epochs since improvement 0
  4%|▍         | 20/500 [13:42<5:49:51, 43.73s/it]  4%|▍         | 21/500 [14:14<5:20:13, 40.11s/it]  4%|▍         | 22/500 [15:03<5:41:50, 42.91s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.72E+05, Train scatter: [0.4919 0.0876 0.3193 0.5575]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4859 0.0906 0.3247 0.5567], Lowest was [0.4859 0.0906 0.3247 0.5567]
Median for last 10 epochs: [0.5244 0.0998 0.3553 0.5999], Epochs since improvement 0
  5%|▍         | 23/500 [15:35<5:14:12, 39.52s/it]  5%|▍         | 24/500 [16:24<5:37:50, 42.59s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 6.81E+05, Train scatter: [0.4856 0.0862 0.3323 0.602 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.483  0.088  0.3343 0.6024], Lowest was [0.483  0.088  0.3247 0.5567]
Median for last 10 epochs: [0.5244 0.0989 0.3515 0.6004], Epochs since improvement 0
  5%|▌         | 25/500 [16:56<5:11:42, 39.37s/it]  5%|▌         | 26/500 [17:45<5:34:04, 42.29s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 6.33E+05, Train scatter: [0.475  0.0828 0.3045 0.5385]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4584 0.0847 0.3083 0.5366], Lowest was [0.4584 0.0847 0.3083 0.5366]
Median for last 10 epochs: [0.4859 0.0906 0.3343 0.6004], Epochs since improvement 0
  5%|▌         | 27/500 [18:17<5:08:55, 39.19s/it]  6%|▌         | 28/500 [19:07<5:32:10, 42.22s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 6.18E+05, Train scatter: [0.5075 0.0898 0.3295 0.5728]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5361 0.0936 0.3386 0.5794], Lowest was [0.4584 0.0847 0.3083 0.5366]
Median for last 10 epochs: [0.4859 0.0906 0.3343 0.5794], Epochs since improvement 2
  6%|▌         | 29/500 [19:38<5:06:38, 39.06s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 5.64E+05, Train scatter: [0.5672 0.0848 0.3154 0.5393]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6185 0.0902 0.3249 0.5419], Lowest was [0.4584 0.0847 0.3083 0.5366]
Median for last 10 epochs: [0.4859 0.0902 0.3249 0.5567], Epochs since improvement 4
  6%|▌         | 30/500 [20:33<5:42:59, 43.79s/it]  6%|▌         | 31/500 [21:05<5:13:47, 40.14s/it]  6%|▋         | 32/500 [21:54<5:35:28, 43.01s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 5.09E+05, Train scatter: [0.4032 0.0781 0.2949 0.5313]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4027 0.0791 0.3026 0.5286], Lowest was [0.4027 0.0791 0.3026 0.5286]
Median for last 10 epochs: [0.483  0.088  0.3249 0.5419], Epochs since improvement 0
  7%|▋         | 33/500 [22:26<5:08:26, 39.63s/it]  7%|▋         | 34/500 [23:15<5:30:04, 42.50s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 4.81E+05, Train scatter: [0.3608 0.08   0.3043 0.5448]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3761 0.082  0.3077 0.5443], Lowest was [0.3761 0.0791 0.3026 0.5286]
Median for last 10 epochs: [0.4584 0.0847 0.3083 0.5419], Epochs since improvement 0
  7%|▋         | 35/500 [23:47<5:04:28, 39.29s/it]  7%|▋         | 36/500 [24:37<5:27:31, 42.35s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.99E+05, Train scatter: [0.2923 0.0769 0.3058 0.5233]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2993 0.0778 0.3066 0.5186], Lowest was [0.2993 0.0778 0.3026 0.5186]
Median for last 10 epochs: [0.4027 0.082  0.3077 0.5419], Epochs since improvement 0
  7%|▋         | 37/500 [25:08<5:02:10, 39.16s/it]  8%|▊         | 38/500 [25:58<5:25:08, 42.23s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.66E+05, Train scatter: [0.3059 0.0747 0.2947 0.5215]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2971 0.0758 0.2978 0.5184], Lowest was [0.2971 0.0758 0.2978 0.5184]
Median for last 10 epochs: [0.3761 0.0791 0.3066 0.5286], Epochs since improvement 0
  8%|▊         | 39/500 [26:30<5:00:15, 39.08s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: -5.04E+04, Train scatter: [0.3299 0.07   0.2765 0.4894]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3268 0.0718 0.2895 0.4907], Lowest was [0.2971 0.0718 0.2895 0.4907]
Median for last 10 epochs: [0.3268 0.0778 0.3026 0.5186], Epochs since improvement 0
  8%|▊         | 40/500 [27:25<5:36:15, 43.86s/it]  8%|▊         | 41/500 [27:56<5:07:47, 40.23s/it]  8%|▊         | 42/500 [28:46<5:28:48, 43.08s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.62E+05, Train scatter: [0.2314 0.068  0.2752 0.4839]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2405 0.069  0.2888 0.4861], Lowest was [0.2405 0.069  0.2888 0.4861]
Median for last 10 epochs: [0.2993 0.0758 0.2978 0.5184], Epochs since improvement 0
  9%|▊         | 43/500 [29:18<5:02:18, 39.69s/it]  9%|▉         | 44/500 [30:07<5:23:32, 42.57s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.72E+05, Train scatter: [0.2604 0.0678 0.2757 0.4839]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2626 0.0699 0.2831 0.482 ], Lowest was [0.2405 0.069  0.2831 0.482 ]
Median for last 10 epochs: [0.2971 0.0718 0.2895 0.4907], Epochs since improvement 0
  9%|▉         | 45/500 [30:39<4:57:58, 39.29s/it]  9%|▉         | 46/500 [31:28<5:19:48, 42.27s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: -2.76E+05, Train scatter: [0.2376 0.0645 0.2755 0.4816]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2436 0.0658 0.2852 0.4784], Lowest was [0.2405 0.0658 0.2831 0.4784]
Median for last 10 epochs: [0.2626 0.0699 0.2888 0.4861], Epochs since improvement 0
  9%|▉         | 47/500 [32:00<4:55:12, 39.10s/it] 10%|▉         | 48/500 [32:50<5:19:31, 42.42s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: -2.80E+05, Train scatter: [0.2164 0.0643 0.2817 0.4759]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.232  0.0657 0.2884 0.4737], Lowest was [0.232  0.0657 0.2831 0.4737]
Median for last 10 epochs: [0.2436 0.069  0.2884 0.482 ], Epochs since improvement 0
 10%|▉         | 49/500 [33:22<4:54:53, 39.23s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: -2.79E+05, Train scatter: [0.2667 0.0639 0.2752 0.4769]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2796 0.0651 0.2817 0.4744], Lowest was [0.232  0.0651 0.2817 0.4737]
Median for last 10 epochs: [0.2436 0.0658 0.2852 0.4784], Epochs since improvement 0
 10%|█         | 50/500 [34:17<5:29:28, 43.93s/it] 10%|█         | 51/500 [34:48<5:01:32, 40.29s/it] 10%|█         | 52/500 [35:38<5:22:09, 43.15s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: -2.87E+05, Train scatter: [0.2704 0.0612 0.2791 0.4741]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2769 0.0626 0.2866 0.4729], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.2626 0.0657 0.2852 0.4744], Epochs since improvement 0
 11%|█         | 53/500 [36:10<4:55:45, 39.70s/it] 11%|█         | 54/500 [37:00<5:18:18, 42.82s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.37E+06, Train scatter: [0.9253 0.1723 0.5441 0.9961]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9103 0.1684 0.5354 0.9856], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.2769 0.0657 0.2866 0.4744], Epochs since improvement 2
 11%|█         | 55/500 [37:32<4:53:08, 39.52s/it] 11%|█         | 56/500 [38:22<5:15:41, 42.66s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.58E+06, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.2796 0.0657 0.2884 0.4744], Epochs since improvement 4
 11%|█▏        | 57/500 [38:53<4:50:44, 39.38s/it] 12%|█▏        | 58/500 [39:43<5:13:02, 42.49s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.27E+06, Train scatter: [0.9352 0.1728 0.5441 0.9956]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.169  0.5355 0.9852], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.9103 0.1684 0.5354 0.9851], Epochs since improvement 6
 12%|█▏        | 59/500 [40:15<4:49:00, 39.32s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 9.88E+05, Train scatter: [0.9351 0.1728 0.5441 0.9958]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.169  0.5355 0.9855], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.9852], Epochs since improvement 8
 12%|█▏        | 60/500 [41:10<5:21:53, 43.90s/it] 12%|█▏        | 61/500 [41:42<4:54:58, 40.31s/it] 12%|█▏        | 62/500 [42:32<5:15:31, 43.22s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 7.88E+05, Train scatter: [0.9357 0.1728 0.5441 0.9917]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.92   0.169  0.5355 0.9815], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.9852], Epochs since improvement 10
 13%|█▎        | 63/500 [43:04<4:50:06, 39.83s/it] 13%|█▎        | 64/500 [43:54<5:11:50, 42.91s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 5.80E+05, Train scatter: [0.9374 0.1701 0.5441 0.9777]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9217 0.1664 0.5355 0.9677], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 12
 13%|█▎        | 65/500 [44:26<4:47:01, 39.59s/it] 13%|█▎        | 66/500 [45:16<5:08:55, 42.71s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.70E+05, Train scatter: [0.9248 0.1265 0.5437 0.9472]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9092 0.125  0.5352 0.9381], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.9815], Epochs since improvement 14
 13%|█▎        | 67/500 [45:47<4:44:45, 39.46s/it] 14%|█▎        | 68/500 [46:37<5:06:08, 42.52s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.68E+05, Train scatter: [0.7991 0.1248 0.5191 0.937 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7784 0.1236 0.511  0.9291], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.9195 0.1664 0.5355 0.9677], Epochs since improvement 16
 14%|█▍        | 69/500 [47:09<4:42:09, 39.28s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.57E+05, Train scatter: [0.5508 0.1225 0.5167 0.9311]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5539 0.1217 0.5088 0.9249], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.9092 0.125  0.5352 0.9381], Epochs since improvement 18
 14%|█▍        | 70/500 [48:05<5:17:32, 44.31s/it] 14%|█▍        | 71/500 [48:37<4:50:29, 40.63s/it] 14%|█▍        | 72/500 [49:33<5:23:17, 45.32s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.12E+05, Train scatter: [0.5078 0.1192 0.5179 0.9243]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5068 0.1179 0.5094 0.9171], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.7784 0.1236 0.511  0.9291], Epochs since improvement 20
 15%|█▍        | 73/500 [50:05<4:54:29, 41.38s/it] 15%|█▍        | 73/500 [50:54<4:57:49, 41.85s/it]
Epoch: 74 done with learning rate 1.00E-02, Train loss: 8.35E+04, Train scatter: [0.5103 0.1143 0.4976 0.9116]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5056 0.1125 0.4903 0.9036], Lowest was [0.232  0.0626 0.2817 0.4729]
Median for last 10 epochs: [0.5539 0.1217 0.5094 0.9249], Epochs since improvement 22
Exited after 74 epochs due to early stopping
3056.18 seconds spent training, 6.112 seconds per epoch. Processed 11393 trees per second
[0.5055465  0.11251785 0.4902882  0.903574  ]
{'epoch_exit': 73, 'scatter_m_star': 0.5055465, 'lowest_m_star': 0.2319559, 'last20_m_star': 0.91436505, 'last10_m_star': 0.55386186, 'scatter_v_disk': 0.11251785, 'lowest_v_disk': 0.06262966, 'last20_v_disk': 0.14572364, 'last10_v_disk': 0.121695645, 'scatter_m_cold': 0.4902882, 'lowest_m_cold': 0.2816592, 'last20_m_cold': 0.5353244, 'last10_m_cold': 0.50942457, 'scatter_sfr_100': 0.903574, 'lowest_sfr_100': 0.47293985, 'last20_sfr_100': 0.95288324, 'last10_sfr_100': 0.9248672}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_wwjskb
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:56:47, 28.47s/it]  0%|          | 2/500 [01:13<5:14:52, 37.94s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.45E+07, Train scatter: [0.9354 0.1791 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1876 0.5357 0.9851], Lowest was [0.9198 0.1876 0.5357 0.9851]
Median for last 10 epochs: [0.9198 0.1876 0.5357 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:40<4:35:41, 33.28s/it]  1%|          | 4/500 [02:26<5:16:17, 38.26s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.48E+07, Train scatter: [0.9354 0.1756 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1791 0.5356 0.9851], Lowest was [0.9198 0.1791 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1791 0.5356 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:54<4:44:19, 34.46s/it]  1%|          | 6/500 [03:40<5:17:11, 38.53s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.08E+07, Train scatter: [0.9354 0.166  0.5442 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.1685 0.5356 0.9851], Lowest was [0.9198 0.1685 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1685 0.5356 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:08<4:48:16, 35.08s/it]  2%|▏         | 8/500 [04:55<5:18:41, 38.87s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 9.70E+06, Train scatter: [0.9353 0.1512 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1506 0.5355 0.9848], Lowest was [0.9197 0.1506 0.5355 0.9848]
Median for last 10 epochs: [0.9198 0.1596 0.5356 0.9849], Epochs since improvement 0
  2%|▏         | 9/500 [05:23<4:49:47, 35.41s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.08E+06, Train scatter: [0.9352 0.1373 0.544  0.7207]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1354 0.5355 0.7164], Lowest was [0.9196 0.1354 0.5355 0.7164]
Median for last 10 epochs: [0.9197 0.1506 0.5355 0.9848], Epochs since improvement 0
  2%|▏         | 10/500 [06:14<5:29:21, 40.33s/it]  2%|▏         | 11/500 [06:42<4:57:43, 36.53s/it]  2%|▏         | 12/500 [07:28<5:20:02, 39.35s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.08E+06, Train scatter: [0.9343 0.1261 0.544  0.6757]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9189 0.1238 0.5355 0.6691], Lowest was [0.9189 0.1238 0.5355 0.6691]
Median for last 10 epochs: [0.9197 0.1506 0.5355 0.9848], Epochs since improvement 0
  3%|▎         | 13/500 [07:56<4:51:12, 35.88s/it]  3%|▎         | 14/500 [08:42<5:15:55, 39.00s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.71E+06, Train scatter: [0.9146 0.1198 0.5435 0.6372]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.901  0.1183 0.535  0.6295], Lowest was [0.901  0.1183 0.535  0.6295]
Median for last 10 epochs: [0.9196 0.1354 0.5355 0.7164], Epochs since improvement 0
  3%|▎         | 15/500 [09:10<4:48:08, 35.65s/it]  3%|▎         | 16/500 [09:56<5:12:50, 38.78s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.55E+06, Train scatter: [0.7839 0.1151 0.5415 0.6198]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7779 0.1138 0.5332 0.6096], Lowest was [0.7779 0.1138 0.5332 0.6096]
Median for last 10 epochs: [0.9189 0.1238 0.5355 0.6691], Epochs since improvement 0
  3%|▎         | 17/500 [10:24<4:45:38, 35.48s/it]  4%|▎         | 18/500 [11:10<5:10:34, 38.66s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 6.33E+06, Train scatter: [0.5833 0.1094 0.5388 0.6017]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.578  0.1087 0.5307 0.5944], Lowest was [0.578  0.1087 0.5307 0.5944]
Median for last 10 epochs: [0.901  0.1183 0.535  0.6295], Epochs since improvement 0
  4%|▍         | 19/500 [11:38<4:44:55, 35.54s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 6.12E+06, Train scatter: [0.5198 0.1046 0.5358 0.5829]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5165 0.1049 0.5277 0.5787], Lowest was [0.5165 0.1049 0.5277 0.5787]
Median for last 10 epochs: [0.7779 0.1138 0.5332 0.6096], Epochs since improvement 0
  4%|▍         | 20/500 [12:29<5:21:01, 40.13s/it]  4%|▍         | 21/500 [12:57<4:51:38, 36.53s/it]  4%|▍         | 22/500 [13:43<5:14:02, 39.42s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.89E+06, Train scatter: [0.5077 0.0994 0.5301 0.5726]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5087 0.0997 0.5222 0.5736], Lowest was [0.5087 0.0997 0.5222 0.5736]
Median for last 10 epochs: [0.578  0.1087 0.5307 0.5944], Epochs since improvement 0
  5%|▍         | 23/500 [14:11<4:45:32, 35.92s/it]  5%|▍         | 24/500 [14:57<5:09:08, 38.97s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 5.53E+06, Train scatter: [0.5728 0.1    0.518  0.6039]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.551  0.101  0.5103 0.6109], Lowest was [0.5087 0.0997 0.5103 0.5736]
Median for last 10 epochs: [0.551  0.1049 0.5277 0.5944], Epochs since improvement 0
  5%|▌         | 25/500 [15:25<4:42:22, 35.67s/it]  5%|▌         | 26/500 [16:12<5:08:25, 39.04s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 6.16E+06, Train scatter: [0.5696 0.1278 0.5273 0.7169]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5744 0.1286 0.5197 0.7132], Lowest was [0.5087 0.0997 0.5103 0.5736]
Median for last 10 epochs: [0.551  0.1049 0.5222 0.5944], Epochs since improvement 2
  5%|▌         | 27/500 [16:40<4:41:43, 35.74s/it]  6%|▌         | 28/500 [17:27<5:06:06, 38.91s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.41E+06, Train scatter: [0.4968 0.1022 0.3935 0.6102]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5104 0.1034 0.3973 0.612 ], Lowest was [0.5087 0.0997 0.3973 0.5736]
Median for last 10 epochs: [0.5165 0.1034 0.5197 0.6109], Epochs since improvement 0
  6%|▌         | 29/500 [17:54<4:39:30, 35.61s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.62E+06, Train scatter: [0.4601 0.0972 0.3827 0.6183]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4717 0.0975 0.3876 0.6201], Lowest was [0.4717 0.0975 0.3876 0.5736]
Median for last 10 epochs: [0.5104 0.101  0.5103 0.612 ], Epochs since improvement 0
  6%|▌         | 30/500 [18:46<5:16:47, 40.44s/it]  6%|▌         | 31/500 [19:14<4:47:04, 36.73s/it]  6%|▋         | 32/500 [20:00<5:08:40, 39.57s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.38E+06, Train scatter: [0.4328 0.0976 0.3379 0.5975]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4418 0.0984 0.3461 0.5981], Lowest was [0.4418 0.0975 0.3461 0.5736]
Median for last 10 epochs: [0.5104 0.101  0.3973 0.612 ], Epochs since improvement 0
  7%|▋         | 33/500 [20:28<4:41:04, 36.11s/it]  7%|▋         | 34/500 [21:15<5:04:03, 39.15s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.04E+06, Train scatter: [0.4929 0.1015 0.3513 0.6346]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4936 0.1007 0.3509 0.6326], Lowest was [0.4418 0.0975 0.3461 0.5736]
Median for last 10 epochs: [0.4936 0.1007 0.3876 0.6201], Epochs since improvement 2
  7%|▋         | 35/500 [21:43<4:37:32, 35.81s/it]  7%|▋         | 36/500 [22:29<5:01:25, 38.98s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 1.77E+06, Train scatter: [0.5226 0.0937 0.3377 0.5785]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5282 0.096  0.3411 0.5834], Lowest was [0.4418 0.096  0.3411 0.5736]
Median for last 10 epochs: [0.4936 0.0984 0.3509 0.612 ], Epochs since improvement 0
  7%|▋         | 37/500 [22:57<4:35:13, 35.67s/it]  8%|▊         | 38/500 [23:43<4:59:06, 38.85s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.27E+06, Train scatter: [0.4327 0.0896 0.3643 0.6025]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4422 0.0915 0.371  0.6026], Lowest was [0.4418 0.0915 0.3411 0.5736]
Median for last 10 epochs: [0.4717 0.0975 0.3509 0.6026], Epochs since improvement 0
  8%|▊         | 39/500 [24:11<4:33:26, 35.59s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.64E+06, Train scatter: [0.3299 0.0887 0.3272 0.5458]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3362 0.0905 0.3253 0.5438], Lowest was [0.3362 0.0905 0.3253 0.5438]
Median for last 10 epochs: [0.4422 0.096  0.3461 0.5981], Epochs since improvement 0
  8%|▊         | 40/500 [25:03<5:10:46, 40.54s/it]  8%|▊         | 41/500 [25:32<4:42:21, 36.91s/it]  8%|▊         | 42/500 [26:20<5:06:37, 40.17s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.52E+06, Train scatter: [0.3531 0.0868 0.3279 0.5436]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3663 0.0874 0.3397 0.5488], Lowest was [0.3362 0.0874 0.3253 0.5438]
Median for last 10 epochs: [0.4422 0.0915 0.3411 0.5834], Epochs since improvement 0
  9%|▊         | 43/500 [26:47<4:37:48, 36.47s/it]  9%|▉         | 44/500 [27:34<5:01:09, 39.63s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.49E+06, Train scatter: [0.2925 0.0854 0.3026 0.5265]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3057 0.0867 0.3136 0.526 ], Lowest was [0.3057 0.0867 0.3136 0.526 ]
Median for last 10 epochs: [0.3663 0.0905 0.3397 0.5488], Epochs since improvement 0
  9%|▉         | 45/500 [28:02<4:33:40, 36.09s/it]  9%|▉         | 46/500 [28:49<4:57:11, 39.28s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.35E+06, Train scatter: [0.3539 0.0843 0.2932 0.5428]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3538 0.0863 0.3064 0.5412], Lowest was [0.3057 0.0863 0.3064 0.526 ]
Median for last 10 epochs: [0.3538 0.0874 0.3253 0.5438], Epochs since improvement 0
  9%|▉         | 47/500 [29:17<4:31:00, 35.90s/it] 10%|▉         | 48/500 [30:04<4:55:12, 39.19s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.34E+06, Train scatter: [0.32   0.0842 0.3235 0.5168]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3257 0.0852 0.3298 0.5208], Lowest was [0.3057 0.0852 0.3064 0.5208]
Median for last 10 epochs: [0.3362 0.0867 0.3253 0.5412], Epochs since improvement 0
 10%|▉         | 49/500 [30:32<4:29:15, 35.82s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.29E+06, Train scatter: [0.4419 0.0919 0.3586 0.6157]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4436 0.092  0.3694 0.6156], Lowest was [0.3057 0.0852 0.3064 0.5208]
Median for last 10 epochs: [0.3538 0.0867 0.3298 0.5412], Epochs since improvement 2
 10%|█         | 50/500 [31:26<5:09:14, 41.23s/it] 10%|█         | 51/500 [31:54<4:38:54, 37.27s/it] 10%|█         | 52/500 [32:40<4:59:36, 40.13s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.18E+06, Train scatter: [0.2806 0.0825 0.3215 0.5118]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2841 0.0835 0.3296 0.5128], Lowest was [0.2841 0.0835 0.3064 0.5128]
Median for last 10 epochs: [0.3257 0.0863 0.3296 0.526 ], Epochs since improvement 0
 11%|█         | 53/500 [33:08<4:31:47, 36.48s/it] 11%|█         | 54/500 [33:55<4:54:39, 39.64s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.06E+06, Train scatter: [0.3005 0.0805 0.2975 0.5076]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3131 0.0813 0.3088 0.5127], Lowest was [0.2841 0.0813 0.3064 0.5127]
Median for last 10 epochs: [0.3257 0.0852 0.3296 0.5208], Epochs since improvement 0
 11%|█         | 55/500 [34:24<4:28:16, 36.17s/it] 11%|█         | 56/500 [35:10<4:50:54, 39.31s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.05E+06, Train scatter: [0.3104 0.0817 0.3384 0.5517]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3104 0.084  0.3388 0.5406], Lowest was [0.2841 0.0813 0.3064 0.5127]
Median for last 10 epochs: [0.3131 0.084  0.3298 0.5208], Epochs since improvement 2
 11%|█▏        | 57/500 [35:38<4:24:40, 35.85s/it] 12%|█▏        | 58/500 [36:26<4:51:50, 39.62s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.09E+06, Train scatter: [0.3385 0.0793 0.2903 0.5104]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3358 0.0815 0.3064 0.5139], Lowest was [0.2841 0.0813 0.3064 0.5127]
Median for last 10 epochs: [0.3131 0.0835 0.3296 0.5139], Epochs since improvement 4
 12%|█▏        | 59/500 [36:54<4:24:29, 35.99s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.25E+06, Train scatter: [0.2657 0.0789 0.3038 0.4941]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2746 0.081  0.3113 0.5006], Lowest was [0.2746 0.081  0.3064 0.5006]
Median for last 10 epochs: [0.3104 0.0815 0.3113 0.5128], Epochs since improvement 0
 12%|█▏        | 60/500 [37:46<5:00:23, 40.96s/it] 12%|█▏        | 61/500 [38:14<4:30:38, 36.99s/it] 12%|█▏        | 62/500 [39:01<4:52:07, 40.02s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 9.33E+05, Train scatter: [0.285  0.0758 0.272  0.4937]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2952 0.0774 0.2835 0.4959], Lowest was [0.2746 0.0774 0.2835 0.4959]
Median for last 10 epochs: [0.3104 0.0813 0.3088 0.5127], Epochs since improvement 0
 13%|█▎        | 63/500 [39:29<4:24:45, 36.35s/it] 13%|█▎        | 64/500 [40:15<4:46:11, 39.38s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 9.49E+05, Train scatter: [0.271  0.0769 0.2854 0.4936]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2783 0.0786 0.2883 0.4983], Lowest was [0.2746 0.0774 0.2835 0.4959]
Median for last 10 epochs: [0.2952 0.081  0.3064 0.5006], Epochs since improvement 2
 13%|█▎        | 65/500 [40:43<4:19:38, 35.81s/it] 13%|█▎        | 66/500 [41:30<4:44:26, 39.32s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 8.58E+05, Train scatter: [0.3831 0.0748 0.2826 0.4941]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3885 0.0765 0.2909 0.5009], Lowest was [0.2746 0.0765 0.2835 0.4959]
Median for last 10 epochs: [0.2952 0.0786 0.2909 0.5006], Epochs since improvement 0
 13%|█▎        | 67/500 [41:58<4:18:31, 35.82s/it] 14%|█▎        | 68/500 [42:44<4:40:24, 38.95s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 8.89E+05, Train scatter: [0.2674 0.0738 0.2735 0.4878]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2737 0.0753 0.284  0.4931], Lowest was [0.2737 0.0753 0.2835 0.4931]
Median for last 10 epochs: [0.2783 0.0774 0.2883 0.4983], Epochs since improvement 0
 14%|█▍        | 69/500 [43:12<4:15:30, 35.57s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 8.32E+05, Train scatter: [0.3124 0.0724 0.3331 0.5232]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3164 0.0743 0.3421 0.5228], Lowest was [0.2737 0.0743 0.2835 0.4931]
Median for last 10 epochs: [0.2952 0.0765 0.2883 0.4983], Epochs since improvement 0
 14%|█▍        | 70/500 [44:05<4:51:29, 40.67s/it] 14%|█▍        | 71/500 [44:32<4:22:56, 36.78s/it] 14%|█▍        | 72/500 [45:19<4:43:41, 39.77s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 6.41E+05, Train scatter: [0.2795 0.0804 0.2883 0.5164]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2892 0.0832 0.3007 0.5277], Lowest was [0.2737 0.0743 0.2835 0.4931]
Median for last 10 epochs: [0.2892 0.0765 0.2909 0.5009], Epochs since improvement 2
 15%|█▍        | 73/500 [45:47<4:17:17, 36.15s/it] 15%|█▍        | 74/500 [46:33<4:38:52, 39.28s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 6.65E+05, Train scatter: [0.2485 0.0713 0.3122 0.4889]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2539 0.0734 0.3177 0.4923], Lowest was [0.2539 0.0734 0.2835 0.4923]
Median for last 10 epochs: [0.2892 0.0753 0.3007 0.5009], Epochs since improvement 0
 15%|█▌        | 75/500 [47:01<4:13:47, 35.83s/it] 15%|█▌        | 76/500 [47:48<4:37:03, 39.21s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 5.86E+05, Train scatter: [0.2492 0.0714 0.2749 0.4978]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2599 0.0728 0.2885 0.5067], Lowest was [0.2539 0.0728 0.2835 0.4923]
Median for last 10 epochs: [0.2737 0.0743 0.3007 0.5067], Epochs since improvement 0
 15%|█▌        | 77/500 [48:16<4:11:56, 35.74s/it] 16%|█▌        | 78/500 [49:03<4:35:58, 39.24s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 5.30E+05, Train scatter: [0.2636 0.071  0.2748 0.5249]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2697 0.0733 0.2861 0.5227], Lowest was [0.2539 0.0728 0.2835 0.4923]
Median for last 10 epochs: [0.2697 0.0734 0.3007 0.5227], Epochs since improvement 2
 16%|█▌        | 79/500 [49:31<4:11:15, 35.81s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 4.08E+05, Train scatter: [0.2588 0.0681 0.2806 0.4954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2687 0.07   0.2976 0.5035], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.2687 0.0733 0.2976 0.5067], Epochs since improvement 0
 16%|█▌        | 80/500 [50:23<4:44:58, 40.71s/it] 16%|█▌        | 81/500 [50:51<4:16:53, 36.79s/it] 16%|█▋        | 82/500 [51:38<4:38:18, 39.95s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 8.76E+06, Train scatter: [0.9124 0.1712 0.5437 0.9379]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8986 0.1667 0.5352 0.9307], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.2687 0.0733 0.2976 0.5067], Epochs since improvement 2
 17%|█▋        | 83/500 [52:06<4:12:00, 36.26s/it] 17%|█▋        | 84/500 [52:52<4:32:37, 39.32s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 7.71E+06, Train scatter: [0.9311 0.1599 0.5432 0.9764]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9162 0.1579 0.5347 0.9676], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.2697 0.0733 0.2976 0.5227], Epochs since improvement 4
 17%|█▋        | 85/500 [53:20<4:08:34, 35.94s/it] 17%|█▋        | 86/500 [54:08<4:31:36, 39.36s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 4.32E+06, Train scatter: [0.9303 0.1441 0.5247 0.9737]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9155 0.1435 0.5219 0.9657], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.8986 0.1435 0.5219 0.9307], Epochs since improvement 6
 17%|█▋        | 87/500 [54:35<4:06:27, 35.80s/it] 18%|█▊        | 88/500 [55:23<4:29:52, 39.30s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 3.03E+06, Train scatter: [0.9294 0.1368 0.5189 0.9735]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9147 0.137  0.516  0.9661], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.9147 0.1435 0.5219 0.9657], Epochs since improvement 8
 18%|█▊        | 89/500 [55:50<4:05:12, 35.80s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.32E+06, Train scatter: [0.9283 0.1328 0.5139 0.9715]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9136 0.1332 0.5093 0.9649], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.9147 0.1435 0.5219 0.9657], Epochs since improvement 10
 18%|█▊        | 90/500 [56:43<4:39:01, 40.83s/it] 18%|█▊        | 91/500 [57:11<4:11:38, 36.92s/it] 18%|█▊        | 92/500 [57:58<4:32:10, 40.02s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 1.86E+06, Train scatter: [0.9266 0.1298 0.5096 0.9707]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9119 0.1294 0.5043 0.9656], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.9147 0.137  0.516  0.9657], Epochs since improvement 12
 19%|█▊        | 93/500 [58:26<4:06:13, 36.30s/it] 19%|█▉        | 94/500 [59:13<4:28:22, 39.66s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 1.59E+06, Train scatter: [0.9241 0.1269 0.5052 0.9709]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9096 0.1266 0.4941 0.966 ], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.9136 0.1332 0.5093 0.9657], Epochs since improvement 14
 19%|█▉        | 95/500 [59:41<4:03:36, 36.09s/it] 19%|█▉        | 96/500 [1:00:28<4:24:45, 39.32s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 1.38E+06, Train scatter: [0.9202 0.1253 0.508  0.9717]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9058 0.1249 0.5012 0.9666], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.9119 0.1294 0.5043 0.966 ], Epochs since improvement 16
 19%|█▉        | 97/500 [1:00:55<4:00:16, 35.77s/it] 20%|█▉        | 98/500 [1:01:43<4:23:16, 39.29s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 1.25E+06, Train scatter: [0.9126 0.1229 0.5062 0.9729]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8984 0.1236 0.5003 0.9676], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.9096 0.1266 0.5012 0.966 ], Epochs since improvement 18
 20%|█▉        | 99/500 [1:02:10<3:59:15, 35.80s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 1.10E+06, Train scatter: [0.8956 0.1202 0.4917 0.975 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8817 0.1202 0.4857 0.9693], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.9058 0.1249 0.5003 0.9666], Epochs since improvement 20
 20%|██        | 100/500 [1:03:03<4:32:38, 40.90s/it] 20%|██        | 101/500 [1:03:31<4:06:00, 36.99s/it] 20%|██        | 101/500 [1:04:18<4:14:02, 38.20s/it]
Epoch: 102 done with learning rate 9.90E-03, Train loss: 9.63E+05, Train scatter: [0.8526 0.118  0.4957 0.9756]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8404 0.1188 0.4916 0.9696], Lowest was [0.2539 0.07   0.2835 0.4923]
Median for last 10 epochs: [0.8984 0.1236 0.4941 0.9676], Epochs since improvement 22
Exited after 102 epochs due to early stopping
3858.47 seconds spent training, 7.717 seconds per epoch. Processed 9024 trees per second
[0.84034777 0.11881804 0.491561   0.9696193 ]
{'epoch_exit': 101, 'scatter_m_star': 0.84034777, 'lowest_m_star': 0.25392896, 'last20_m_star': 0.9107588, 'last10_m_star': 0.8983658, 'scatter_v_disk': 0.118818045, 'lowest_v_disk': 0.06998466, 'last20_v_disk': 0.12800351, 'last10_v_disk': 0.12360667, 'scatter_m_cold': 0.491561, 'lowest_m_cold': 0.28349546, 'last20_m_cold': 0.50277066, 'last10_m_cold': 0.49406055, 'scatter_sfr_100': 0.9696193, 'lowest_sfr_100': 0.49233386, 'last20_sfr_100': 0.9663334, 'last10_sfr_100': 0.96756446}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_esonoo
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:48<6:39:30, 48.04s/it]  0%|          | 2/500 [01:59<8:33:47, 61.90s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.47E+07, Train scatter: [0.9352 0.1517 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1478 0.5356 0.9851], Lowest was [0.9196 0.1478 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1478 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:47<7:38:15, 55.32s/it]  1%|          | 4/500 [03:58<8:30:06, 61.71s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.65E+07, Train scatter: [0.9343 0.1065 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9187 0.1049 0.5355 0.9848], Lowest was [0.9187 0.1049 0.5355 0.9848]
Median for last 10 epochs: [0.9187 0.1049 0.5355 0.9848], Epochs since improvement 0
  1%|          | 5/500 [04:46<7:46:37, 56.56s/it]  1%|          | 6/500 [05:57<8:27:37, 61.66s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.10E+07, Train scatter: [0.6709 0.0989 0.544  0.6602]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6707 0.0981 0.5355 0.6528], Lowest was [0.6707 0.0981 0.5355 0.6528]
Median for last 10 epochs: [0.6707 0.0981 0.5355 0.6528], Epochs since improvement 0
  1%|▏         | 7/500 [06:44<7:48:10, 56.98s/it]  2%|▏         | 8/500 [07:57<8:26:44, 61.80s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.22E+06, Train scatter: [0.4633 0.0878 0.544  0.5871]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4567 0.0884 0.5354 0.5778], Lowest was [0.4567 0.0884 0.5354 0.5778]
Median for last 10 epochs: [0.5637 0.0932 0.5354 0.6153], Epochs since improvement 0
  2%|▏         | 9/500 [08:44<7:49:18, 57.35s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 5.56E+06, Train scatter: [0.3979 0.0806 0.544  0.5439]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4024 0.0806 0.5354 0.5367], Lowest was [0.4024 0.0806 0.5354 0.5367]
Median for last 10 epochs: [0.4567 0.0884 0.5354 0.5778], Epochs since improvement 0
  2%|▏         | 10/500 [10:04<8:44:56, 64.28s/it]  2%|▏         | 11/500 [10:51<8:01:42, 59.10s/it]  2%|▏         | 12/500 [12:03<8:31:43, 62.92s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 4.91E+06, Train scatter: [0.2564 0.0763 0.544  0.5307]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2615 0.077  0.5354 0.5254], Lowest was [0.2615 0.077  0.5354 0.5254]
Median for last 10 epochs: [0.4567 0.0884 0.5354 0.5778], Epochs since improvement 0
  3%|▎         | 13/500 [12:51<7:53:07, 58.29s/it]  3%|▎         | 14/500 [14:03<8:27:05, 62.60s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 4.65E+06, Train scatter: [0.2682 0.0736 0.5439 0.5198]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2709 0.0744 0.5354 0.5166], Lowest was [0.2615 0.0744 0.5354 0.5166]
Median for last 10 epochs: [0.4024 0.0806 0.5354 0.5367], Epochs since improvement 0
  3%|▎         | 15/500 [14:51<7:50:06, 58.16s/it]  3%|▎         | 16/500 [16:03<8:22:42, 62.32s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.28E+06, Train scatter: [0.2549 0.0726 0.5439 0.5132]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2565 0.0733 0.5354 0.5098], Lowest was [0.2565 0.0733 0.5354 0.5098]
Median for last 10 epochs: [0.2709 0.077  0.5354 0.5254], Epochs since improvement 0
  3%|▎         | 17/500 [16:51<7:45:54, 57.88s/it]  4%|▎         | 18/500 [18:03<8:20:28, 62.30s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.74E+06, Train scatter: [0.2573 0.075  0.5438 0.5223]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.264  0.0751 0.5353 0.5156], Lowest was [0.2565 0.0733 0.5353 0.5098]
Median for last 10 epochs: [0.264  0.0751 0.5354 0.5166], Epochs since improvement 0
  4%|▍         | 19/500 [18:51<7:43:40, 57.84s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.59E+06, Train scatter: [0.4901 0.0914 0.5438 0.6116]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4902 0.0923 0.5353 0.6143], Lowest was [0.2565 0.0733 0.5353 0.5098]
Median for last 10 epochs: [0.264  0.0751 0.5354 0.5166], Epochs since improvement 2
  4%|▍         | 20/500 [20:10<8:35:24, 64.43s/it]  4%|▍         | 21/500 [20:58<7:53:36, 59.32s/it]  4%|▍         | 22/500 [22:10<8:24:28, 63.32s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.52E+06, Train scatter: [0.2271 0.0699 0.5438 0.5088]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2301 0.0704 0.5353 0.5051], Lowest was [0.2301 0.0704 0.5353 0.5051]
Median for last 10 epochs: [0.264  0.0744 0.5353 0.5156], Epochs since improvement 0
  5%|▍         | 23/500 [22:58<7:45:24, 58.54s/it]  5%|▍         | 24/500 [24:10<8:16:29, 62.58s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.50E+06, Train scatter: [0.2164 0.0679 0.5438 0.5007]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2193 0.0679 0.5353 0.4947], Lowest was [0.2193 0.0679 0.5353 0.4947]
Median for last 10 epochs: [0.2565 0.0733 0.5353 0.5098], Epochs since improvement 0
  5%|▌         | 25/500 [24:57<7:39:53, 58.09s/it]  5%|▌         | 26/500 [26:10<8:12:51, 62.39s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.48E+06, Train scatter: [0.2042 0.0662 0.5438 0.5056]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2122 0.0668 0.5352 0.5036], Lowest was [0.2122 0.0668 0.5352 0.4947]
Median for last 10 epochs: [0.2301 0.0704 0.5353 0.5051], Epochs since improvement 0
  5%|▌         | 27/500 [26:57<7:36:37, 57.92s/it]  6%|▌         | 28/500 [28:10<8:10:47, 62.39s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.46E+06, Train scatter: [0.2209 0.067  0.5437 0.5198]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2261 0.0666 0.5352 0.5178], Lowest was [0.2122 0.0666 0.5352 0.4947]
Median for last 10 epochs: [0.2261 0.0679 0.5353 0.5051], Epochs since improvement 0
  6%|▌         | 29/500 [28:58<7:34:27, 57.89s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.44E+06, Train scatter: [0.1977 0.0623 0.5437 0.4876]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2034 0.063  0.5351 0.4842], Lowest was [0.2034 0.063  0.5351 0.4842]
Median for last 10 epochs: [0.2193 0.0668 0.5352 0.5036], Epochs since improvement 0
  6%|▌         | 30/500 [30:16<8:21:42, 64.05s/it]  6%|▌         | 31/500 [31:03<7:41:35, 59.05s/it]  6%|▋         | 32/500 [32:16<8:11:17, 62.99s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.44E+06, Train scatter: [0.2962 0.0787 0.5437 0.5303]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2946 0.0784 0.5351 0.5295], Lowest was [0.2034 0.063  0.5351 0.4842]
Median for last 10 epochs: [0.2193 0.0668 0.5352 0.5036], Epochs since improvement 0
  7%|▋         | 33/500 [33:03<7:33:28, 58.26s/it]  7%|▋         | 34/500 [34:15<8:04:33, 62.39s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 5.82E+08, Train scatter: [0.8923 0.1588 0.544  0.9608]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8771 0.1554 0.5355 0.9513], Lowest was [0.2034 0.063  0.5351 0.4842]
Median for last 10 epochs: [0.2261 0.0668 0.5352 0.5178], Epochs since improvement 2
  7%|▋         | 35/500 [35:02<7:28:35, 57.88s/it]  7%|▋         | 36/500 [36:15<8:01:50, 62.31s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.61E+06, Train scatter: [0.5504 0.1293 0.5437 0.9211]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5458 0.127  0.5351 0.912 ], Lowest was [0.2034 0.063  0.5351 0.4842]
Median for last 10 epochs: [0.2946 0.0784 0.5351 0.5295], Epochs since improvement 0
  7%|▋         | 37/500 [37:02<7:26:18, 57.84s/it]  8%|▊         | 38/500 [38:15<7:58:43, 62.17s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.07E+06, Train scatter: [0.8242 0.1058 0.5436 0.6789]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8114 0.1052 0.535  0.6815], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.5458 0.1052 0.5351 0.6815], Epochs since improvement 0
  8%|▊         | 39/500 [39:02<7:23:32, 57.73s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 5.25E+06, Train scatter: [0.5339 0.0964 0.5437 0.604 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.53   0.0955 0.5351 0.6006], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.5458 0.1052 0.5351 0.6815], Epochs since improvement 2
  8%|▊         | 40/500 [40:22<8:14:26, 64.49s/it]  8%|▊         | 41/500 [41:10<7:34:37, 59.43s/it]  8%|▊         | 42/500 [42:22<8:02:14, 63.18s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 4.86E+06, Train scatter: [0.3845 0.0915 0.5437 0.5727]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3905 0.0922 0.5352 0.5677], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.5458 0.1052 0.5351 0.6815], Epochs since improvement 4
  9%|▊         | 43/500 [43:09<7:25:15, 58.46s/it]  9%|▉         | 44/500 [44:22<7:57:03, 62.77s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.62E+06, Train scatter: [0.4271 0.0837 0.5438 0.5468]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4231 0.0832 0.5352 0.5433], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.53   0.0955 0.5351 0.6006], Epochs since improvement 6
  9%|▉         | 45/500 [45:09<7:20:57, 58.15s/it]  9%|▉         | 46/500 [46:23<7:54:28, 62.71s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.45E+06, Train scatter: [0.4389 0.078  0.5438 0.5291]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4302 0.0786 0.5352 0.525 ], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.4302 0.0922 0.5352 0.5677], Epochs since improvement 8
  9%|▉         | 47/500 [47:10<7:19:21, 58.19s/it] 10%|▉         | 48/500 [48:22<7:49:39, 62.35s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 4.33E+06, Train scatter: [0.3181 0.0772 0.5438 0.5178]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3244 0.0768 0.5352 0.5155], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.4231 0.0832 0.5352 0.5433], Epochs since improvement 10
 10%|▉         | 49/500 [49:10<7:15:18, 57.91s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 4.22E+06, Train scatter: [0.3542 0.0772 0.5438 0.5241]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3476 0.0784 0.5352 0.5233], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.3905 0.0786 0.5352 0.525 ], Epochs since improvement 12
 10%|█         | 50/500 [50:29<8:00:53, 64.12s/it] 10%|█         | 51/500 [51:16<7:22:33, 59.14s/it] 10%|█         | 52/500 [52:29<7:51:32, 63.15s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 4.18E+06, Train scatter: [0.4005 0.0719 0.5439 0.5115]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3887 0.0728 0.5353 0.5082], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.3887 0.0784 0.5352 0.5233], Epochs since improvement 14
 11%|█         | 53/500 [53:16<7:15:25, 58.45s/it] 11%|█         | 54/500 [54:27<7:43:01, 62.29s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 4.15E+06, Train scatter: [0.3789 0.0747 0.5439 0.5159]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3736 0.0745 0.5353 0.5175], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.3736 0.0768 0.5352 0.5175], Epochs since improvement 16
 11%|█         | 55/500 [55:15<7:09:03, 57.85s/it] 11%|█         | 56/500 [56:28<7:41:28, 62.36s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.07E+06, Train scatter: [0.2993 0.0704 0.5439 0.5027]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3115 0.0707 0.5353 0.5014], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.3476 0.0745 0.5353 0.5155], Epochs since improvement 18
 11%|█▏        | 57/500 [57:15<7:07:32, 57.91s/it] 12%|█▏        | 58/500 [58:27<7:38:11, 62.20s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.96E+06, Train scatter: [0.2726 0.0752 0.5439 0.5218]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3186 0.0752 0.5353 0.519 ], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.3476 0.0745 0.5353 0.5175], Epochs since improvement 20
 12%|█▏        | 59/500 [59:15<7:05:11, 57.85s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.86E+06, Train scatter: [0.4293 0.0707 0.5437 0.5119]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4637 0.071  0.5351 0.5127], Lowest was [0.2034 0.063  0.535  0.4842]
Median for last 10 epochs: [0.3736 0.0728 0.5353 0.5127], Epochs since improvement 22
 12%|█▏        | 59/500 [1:00:34<7:32:46, 61.60s/it]
Exited after 60 epochs due to early stopping
3634.61 seconds spent training, 7.269 seconds per epoch. Processed 9580 trees per second
[0.46367922 0.07103743 0.5350731  0.5127217 ]
{'epoch_exit': 59, 'scatter_m_star': 0.46367922, 'lowest_m_star': 0.2033539, 'last20_m_star': 0.38115683, 'last10_m_star': 0.37358844, 'scatter_v_disk': 0.07103743, 'lowest_v_disk': 0.06295647, 'last20_v_disk': 0.0760013, 'last10_v_disk': 0.072805166, 'scatter_m_cold': 0.5350731, 'lowest_m_cold': 0.53498244, 'last20_m_cold': 0.53523064, 'last10_m_cold': 0.5352781, 'scatter_sfr_100': 0.5127217, 'lowest_sfr_100': 0.48419806, 'last20_sfr_100': 0.51823795, 'last10_sfr_100': 0.51273656}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_aiupim
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:41<5:47:01, 41.73s/it]  0%|          | 2/500 [01:45<7:35:18, 54.86s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.08E+07, Train scatter: [0.9352 0.1715 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1683 0.5355 0.9851], Lowest was [0.9196 0.1683 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1683 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:26<6:41:06, 48.42s/it]  1%|          | 4/500 [03:30<7:30:54, 54.55s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.32E+07, Train scatter: [0.9352 0.1613 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.158  0.5355 0.9851], Lowest was [0.9196 0.158  0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.158  0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:11<6:48:48, 49.55s/it]  1%|          | 6/500 [05:15<7:28:06, 54.43s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.86E+07, Train scatter: [0.9351 0.135  0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1321 0.5356 0.985 ], Lowest was [0.9195 0.1321 0.5355 0.985 ]
Median for last 10 epochs: [0.9195 0.1321 0.5355 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [05:55<6:50:30, 49.96s/it]  2%|▏         | 8/500 [06:59<7:26:46, 54.49s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.49E+07, Train scatter: [0.9335 0.1111 0.5441 0.9702]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.918  0.1095 0.5355 0.9616], Lowest was [0.918  0.1095 0.5355 0.9616]
Median for last 10 epochs: [0.9188 0.1208 0.5355 0.9733], Epochs since improvement 0
  2%|▏         | 9/500 [07:40<6:50:40, 50.18s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 1.12E+07, Train scatter: [0.6633 0.1015 0.5441 0.6834]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.665  0.1021 0.5355 0.6805], Lowest was [0.665  0.1021 0.5355 0.6805]
Median for last 10 epochs: [0.918  0.1095 0.5355 0.9616], Epochs since improvement 0
  2%|▏         | 10/500 [08:51<7:41:51, 56.55s/it]  2%|▏         | 11/500 [09:32<7:02:13, 51.81s/it]  2%|▏         | 12/500 [10:36<7:32:22, 55.62s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.03E+06, Train scatter: [0.4393 0.0883 0.544  0.6017]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4444 0.0899 0.5354 0.5983], Lowest was [0.4444 0.0899 0.5354 0.5983]
Median for last 10 epochs: [0.918  0.1095 0.5355 0.9616], Epochs since improvement 0
  3%|▎         | 13/500 [11:17<6:55:22, 51.18s/it]  3%|▎         | 14/500 [12:23<7:28:39, 55.39s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.55E+06, Train scatter: [0.3546 0.0821 0.544  0.5628]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3605 0.0836 0.5354 0.5576], Lowest was [0.3605 0.0836 0.5354 0.5576]
Median for last 10 epochs: [0.665  0.1021 0.5355 0.6805], Epochs since improvement 0
  3%|▎         | 15/500 [13:03<6:52:28, 51.03s/it]  3%|▎         | 16/500 [14:08<7:24:12, 55.07s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 5.87E+06, Train scatter: [0.3174 0.0838 0.5439 0.5482]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3244 0.0861 0.5354 0.5471], Lowest was [0.3244 0.0836 0.5354 0.5471]
Median for last 10 epochs: [0.4444 0.0899 0.5354 0.5983], Epochs since improvement 0
  3%|▎         | 17/500 [14:49<6:48:57, 50.80s/it]  4%|▎         | 18/500 [15:53<7:21:21, 54.94s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 5.57E+06, Train scatter: [0.2754 0.0777 0.5439 0.5352]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2826 0.0788 0.5353 0.5329], Lowest was [0.2826 0.0788 0.5353 0.5329]
Median for last 10 epochs: [0.3605 0.0861 0.5354 0.5576], Epochs since improvement 0
  4%|▍         | 19/500 [16:34<6:46:38, 50.72s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.41E+06, Train scatter: [0.2777 0.0783 0.5438 0.5213]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2829 0.0788 0.5353 0.5205], Lowest was [0.2826 0.0788 0.5353 0.5205]
Median for last 10 epochs: [0.3244 0.0836 0.5354 0.5471], Epochs since improvement 0
  4%|▍         | 20/500 [17:45<7:33:48, 56.73s/it]  4%|▍         | 21/500 [18:26<6:55:03, 51.99s/it]  4%|▍         | 22/500 [19:30<7:23:38, 55.69s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.32E+06, Train scatter: [0.2588 0.0768 0.5439 0.515 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2643 0.0773 0.5353 0.513 ], Lowest was [0.2643 0.0773 0.5353 0.513 ]
Median for last 10 epochs: [0.2829 0.0788 0.5353 0.5329], Epochs since improvement 0
  5%|▍         | 23/500 [20:11<6:47:25, 51.25s/it]  5%|▍         | 24/500 [21:16<7:18:59, 55.34s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.85E+06, Train scatter: [0.2375 0.0754 0.5439 0.5079]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2416 0.076  0.5353 0.5035], Lowest was [0.2416 0.076  0.5353 0.5035]
Median for last 10 epochs: [0.2826 0.0788 0.5353 0.5205], Epochs since improvement 0
  5%|▌         | 25/500 [21:57<6:43:55, 51.02s/it]  5%|▌         | 26/500 [23:01<7:13:42, 54.90s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.65E+06, Train scatter: [0.3975 0.0805 0.5439 0.5968]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4027 0.0802 0.5353 0.5995], Lowest was [0.2416 0.076  0.5353 0.5035]
Median for last 10 epochs: [0.2826 0.0788 0.5353 0.5205], Epochs since improvement 2
  5%|▌         | 27/500 [23:42<6:39:29, 50.68s/it]  6%|▌         | 28/500 [24:46<7:10:53, 54.77s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.79E+06, Train scatter: [0.2923 0.0812 0.544  0.5662]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2954 0.0804 0.5354 0.5613], Lowest was [0.2416 0.076  0.5353 0.5035]
Median for last 10 epochs: [0.2829 0.0788 0.5353 0.5205], Epochs since improvement 4
  6%|▌         | 29/500 [25:27<6:37:54, 50.69s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.41E+06, Train scatter: [0.2527 0.0765 0.5439 0.5141]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2571 0.0771 0.5353 0.5136], Lowest was [0.2416 0.076  0.5353 0.5035]
Median for last 10 epochs: [0.2643 0.0773 0.5353 0.5136], Epochs since improvement 6
  6%|▌         | 30/500 [26:37<7:21:53, 56.41s/it]  6%|▌         | 31/500 [27:18<6:44:54, 51.80s/it]  6%|▋         | 32/500 [28:22<7:12:30, 55.45s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.52E+06, Train scatter: [0.4138 0.0721 0.5439 0.5111]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4029 0.0727 0.5353 0.507 ], Lowest was [0.2416 0.0727 0.5353 0.5035]
Median for last 10 epochs: [0.2954 0.0771 0.5353 0.5136], Epochs since improvement 0
  7%|▋         | 33/500 [29:03<6:37:59, 51.13s/it]  7%|▋         | 34/500 [30:07<7:06:03, 54.86s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 4.30E+06, Train scatter: [0.232  0.0724 0.5439 0.5059]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2369 0.0725 0.5353 0.504 ], Lowest was [0.2369 0.0725 0.5353 0.5035]
Median for last 10 epochs: [0.2954 0.0771 0.5353 0.5136], Epochs since improvement 0
  7%|▋         | 35/500 [30:48<6:33:13, 50.74s/it]  7%|▋         | 36/500 [31:51<7:02:27, 54.63s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 4.27E+06, Train scatter: [0.2421 0.0725 0.5439 0.5203]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2471 0.0722 0.5353 0.5195], Lowest was [0.2369 0.0722 0.5353 0.5035]
Median for last 10 epochs: [0.2571 0.0727 0.5353 0.5136], Epochs since improvement 0
  7%|▋         | 37/500 [32:32<6:29:51, 50.52s/it]  8%|▊         | 38/500 [33:36<6:59:17, 54.45s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 4.26E+06, Train scatter: [0.2697 0.0704 0.5438 0.5044]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2685 0.0708 0.5353 0.5008], Lowest was [0.2369 0.0708 0.5353 0.5008]
Median for last 10 epochs: [0.2571 0.0725 0.5353 0.507 ], Epochs since improvement 0
  8%|▊         | 39/500 [34:17<6:27:24, 50.42s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 4.47E+06, Train scatter: [0.4043 0.0811 0.5439 0.5111]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3979 0.0806 0.5353 0.5064], Lowest was [0.2369 0.0708 0.5353 0.5008]
Median for last 10 epochs: [0.2685 0.0725 0.5353 0.5064], Epochs since improvement 2
  8%|▊         | 40/500 [35:27<7:10:29, 56.15s/it]  8%|▊         | 41/500 [36:08<6:35:02, 51.64s/it]  8%|▊         | 42/500 [37:12<7:02:33, 55.36s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 4.32E+06, Train scatter: [0.4147 0.0759 0.5439 0.5034]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4064 0.0758 0.5353 0.5024], Lowest was [0.2369 0.0708 0.5353 0.5008]
Median for last 10 epochs: [0.2685 0.0725 0.5353 0.504 ], Epochs since improvement 4
  9%|▊         | 43/500 [37:53<6:29:31, 51.14s/it]  9%|▉         | 44/500 [38:56<6:56:29, 54.80s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.27E+06, Train scatter: [0.4444 0.0738 0.5438 0.5069]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4393 0.0744 0.5352 0.5025], Lowest was [0.2369 0.0708 0.5352 0.5008]
Median for last 10 epochs: [0.3979 0.0744 0.5353 0.5025], Epochs since improvement 0
  9%|▉         | 45/500 [39:38<6:24:55, 50.76s/it]  9%|▉         | 46/500 [40:42<6:55:19, 54.89s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.31E+06, Train scatter: [0.3685 0.0804 0.5437 0.5194]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3637 0.0797 0.5351 0.5201], Lowest was [0.2369 0.0708 0.5351 0.5008]
Median for last 10 epochs: [0.3979 0.0758 0.5353 0.5025], Epochs since improvement 0
  9%|▉         | 47/500 [41:24<6:24:09, 50.88s/it] 10%|▉         | 48/500 [42:28<6:52:58, 54.82s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 4.21E+06, Train scatter: [0.3738 0.076  0.5435 0.5007]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3678 0.0758 0.5349 0.4945], Lowest was [0.2369 0.0708 0.5349 0.4945]
Median for last 10 epochs: [0.3979 0.0758 0.5352 0.5025], Epochs since improvement 0
 10%|▉         | 49/500 [43:09<6:20:48, 50.66s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 4.16E+06, Train scatter: [0.2625 0.0823 0.5434 0.5201]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.268  0.0811 0.5348 0.5145], Lowest was [0.2369 0.0708 0.5348 0.4945]
Median for last 10 epochs: [0.3678 0.0758 0.5351 0.5025], Epochs since improvement 0
 10%|█         | 50/500 [44:19<7:04:07, 56.55s/it] 10%|█         | 51/500 [45:00<6:28:45, 51.95s/it] 10%|█         | 52/500 [46:04<6:54:45, 55.55s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 4.12E+06, Train scatter: [0.2492 0.0769 0.5433 0.538 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2495 0.0764 0.5348 0.5412], Lowest was [0.2369 0.0708 0.5348 0.4945]
Median for last 10 epochs: [0.3637 0.0764 0.5349 0.5145], Epochs since improvement 0
 11%|█         | 53/500 [46:45<6:22:11, 51.30s/it] 11%|█         | 54/500 [47:50<6:50:46, 55.26s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 4.08E+06, Train scatter: [0.2388 0.0753 0.5431 0.5231]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2467 0.0751 0.5346 0.5142], Lowest was [0.2369 0.0708 0.5346 0.4945]
Median for last 10 epochs: [0.268  0.0764 0.5348 0.5145], Epochs since improvement 0
 11%|█         | 55/500 [48:31<6:18:13, 51.00s/it] 11%|█         | 56/500 [49:34<6:44:32, 54.67s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.05E+06, Train scatter: [0.2624 0.0762 0.5432 0.579 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2659 0.0754 0.5347 0.5901], Lowest was [0.2369 0.0708 0.5346 0.4945]
Median for last 10 epochs: [0.2659 0.0758 0.5348 0.5145], Epochs since improvement 2
 11%|█▏        | 57/500 [50:15<6:13:19, 50.56s/it] 12%|█▏        | 58/500 [51:20<6:43:34, 54.78s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.93E+06, Train scatter: [0.3552 0.0758 0.543  0.5749]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3604 0.0754 0.5345 0.5913], Lowest was [0.2369 0.0708 0.5345 0.4945]
Median for last 10 epochs: [0.2659 0.0754 0.5347 0.5412], Epochs since improvement 0
 12%|█▏        | 59/500 [52:01<6:12:32, 50.69s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.88E+06, Train scatter: [0.3355 0.0753 0.543  0.5745]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3255 0.0738 0.5345 0.5704], Lowest was [0.2369 0.0708 0.5345 0.4945]
Median for last 10 epochs: [0.2659 0.0754 0.5346 0.5704], Epochs since improvement 0
 12%|█▏        | 60/500 [53:11<6:54:50, 56.57s/it] 12%|█▏        | 61/500 [53:52<6:19:42, 51.90s/it] 12%|█▏        | 62/500 [54:57<6:46:58, 55.75s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.66E+06, Train scatter: [0.2364 0.0757 0.543  0.5058]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.237  0.0746 0.5344 0.5007], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.2659 0.0751 0.5345 0.5704], Epochs since improvement 0
 13%|█▎        | 63/500 [55:38<6:13:54, 51.34s/it] 13%|█▎        | 64/500 [56:41<6:38:24, 54.83s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.65E+06, Train scatter: [0.2497 0.0788 0.543  0.5098]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2422 0.0773 0.5345 0.5066], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.2659 0.0754 0.5345 0.5704], Epochs since improvement 2
 13%|█▎        | 65/500 [57:22<6:07:57, 50.75s/it] 13%|█▎        | 66/500 [58:26<6:34:31, 54.54s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.15E+08, Train scatter: [0.9299 0.173  0.5441 0.9941]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9144 0.1691 0.5355 0.9837], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.3255 0.0754 0.5345 0.5704], Epochs since improvement 4
 13%|█▎        | 67/500 [59:06<6:03:40, 50.39s/it] 14%|█▎        | 68/500 [1:00:09<6:30:03, 54.18s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.42E+07, Train scatter: [0.9319 0.1702 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9164 0.1664 0.5355 0.9849], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.3255 0.0773 0.5345 0.5704], Epochs since improvement 6
 14%|█▍        | 69/500 [1:00:50<6:00:59, 50.25s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.27E+07, Train scatter: [0.9311 0.1652 0.5441 0.9957]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9157 0.1616 0.5355 0.9854], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.9144 0.1616 0.5355 0.9837], Epochs since improvement 8
 14%|█▍        | 70/500 [1:02:02<6:46:30, 56.72s/it] 14%|█▍        | 71/500 [1:02:43<6:11:03, 51.90s/it] 14%|█▍        | 72/500 [1:03:46<6:35:00, 55.38s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.18E+07, Train scatter: [0.9281 0.1574 0.5441 0.9948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9128 0.1542 0.5355 0.9845], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.9144 0.1616 0.5355 0.9845], Epochs since improvement 10
 15%|█▍        | 73/500 [1:04:27<6:02:43, 50.97s/it] 15%|█▍        | 74/500 [1:05:31<6:29:43, 54.89s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 1.02E+07, Train scatter: [0.917  0.1461 0.5441 0.9936]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9023 0.1437 0.5355 0.9833], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.9144 0.1616 0.5355 0.9845], Epochs since improvement 12
 15%|█▌        | 75/500 [1:06:12<5:59:14, 50.72s/it] 15%|█▌        | 76/500 [1:07:15<6:24:39, 54.43s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 9.41E+06, Train scatter: [0.933  0.1358 0.5441 0.9932]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9174 0.1342 0.5355 0.983 ], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.9157 0.1542 0.5355 0.9845], Epochs since improvement 14
 15%|█▌        | 77/500 [1:07:56<5:54:39, 50.31s/it] 16%|█▌        | 78/500 [1:09:01<6:24:03, 54.60s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 9.00E+06, Train scatter: [0.9318 0.1367 0.5441 0.9948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9163 0.1352 0.5355 0.9845], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.9157 0.1437 0.5355 0.9845], Epochs since improvement 16
 16%|█▌        | 79/500 [1:09:42<5:54:30, 50.52s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 8.71E+06, Train scatter: [0.9307 0.1366 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9153 0.1351 0.5355 0.9852], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.9153 0.1352 0.5355 0.9845], Epochs since improvement 18
 16%|█▌        | 80/500 [1:10:54<6:39:21, 57.05s/it] 16%|█▌        | 81/500 [1:11:35<6:04:49, 52.24s/it] 16%|█▋        | 82/500 [1:12:39<6:29:13, 55.87s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 8.13E+06, Train scatter: [0.9245 0.1368 0.5441 0.9957]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9092 0.1352 0.5355 0.9853], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.9153 0.1352 0.5355 0.9845], Epochs since improvement 20
 17%|█▋        | 83/500 [1:13:20<5:57:18, 51.41s/it] 17%|█▋        | 83/500 [1:14:24<6:13:48, 53.78s/it]
Epoch: 84 done with learning rate 9.99E-03, Train loss: 7.39E+06, Train scatter: [0.9352 0.1385 0.5441 0.996 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1365 0.5355 0.9856], Lowest was [0.2369 0.0708 0.5344 0.4945]
Median for last 10 epochs: [0.9163 0.1352 0.5355 0.9852], Epochs since improvement 22
Exited after 84 epochs due to early stopping
4464.16 seconds spent training, 8.928 seconds per epoch. Processed 7799 trees per second
[0.91952413 0.13652286 0.53547615 0.9855983 ]
{'epoch_exit': 83, 'scatter_m_star': 0.91952413, 'lowest_m_star': 0.23686941, 'last20_m_star': 0.91546077, 'last10_m_star': 0.9162872, 'scatter_v_disk': 0.13652286, 'lowest_v_disk': 0.07077071, 'last20_v_disk': 0.1400953, 'last10_v_disk': 0.1351954, 'scatter_m_cold': 0.53547615, 'lowest_m_cold': 0.5344279, 'last20_m_cold': 0.5354889, 'last10_m_cold': 0.53548706, 'scatter_sfr_100': 0.9855983, 'lowest_sfr_100': 0.4944843, 'last20_sfr_100': 0.9846808, 'last10_sfr_100': 0.9851514}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_cnnsil
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:02<8:39:37, 62.48s/it]  0%|          | 2/500 [02:32<10:53:12, 78.70s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.38E+07, Train scatter: [0.9351 0.1297 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1249 0.5355 0.9851], Lowest was [0.9195 0.1249 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1249 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:35<9:50:36, 71.30s/it]   1%|          | 4/500 [05:07<10:57:18, 79.51s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.29E+07, Train scatter: [0.9293 0.1023 0.5429 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9135 0.1023 0.5342 0.9851], Lowest was [0.9135 0.1023 0.5342 0.9851]
Median for last 10 epochs: [0.9135 0.1023 0.5342 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:09<10:05:05, 73.34s/it]  1%|          | 6/500 [07:41<10:56:27, 79.73s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.05E+07, Train scatter: [0.8252 0.095  0.5313 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8163 0.0958 0.5232 0.9851], Lowest was [0.8163 0.0958 0.5232 0.9851]
Median for last 10 epochs: [0.8163 0.0958 0.5232 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [08:44<10:09:02, 74.12s/it]  2%|▏         | 8/500 [10:16<10:55:45, 79.97s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.76E+07, Train scatter: [0.6888 0.096  0.4273 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6767 0.0957 0.418  0.985 ], Lowest was [0.6767 0.0957 0.418  0.985 ]
Median for last 10 epochs: [0.7465 0.0958 0.4706 0.985 ], Epochs since improvement 0
  2%|▏         | 9/500 [11:19<10:09:22, 74.46s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.56E+07, Train scatter: [0.6021 0.0917 0.3567 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6053 0.0937 0.358  0.985 ], Lowest was [0.6053 0.0937 0.358  0.985 ]
Median for last 10 epochs: [0.6767 0.0957 0.418  0.985 ], Epochs since improvement 0
  2%|▏         | 10/500 [12:57<11:08:41, 81.88s/it]  2%|▏         | 11/500 [13:59<10:18:11, 75.85s/it]  2%|▏         | 12/500 [15:30<10:54:43, 80.50s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.47E+07, Train scatter: [0.5879 0.0848 0.3386 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5972 0.0862 0.3403 0.9851], Lowest was [0.5972 0.0862 0.3403 0.985 ]
Median for last 10 epochs: [0.6767 0.0957 0.418  0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [16:33<10:08:15, 74.94s/it]  3%|▎         | 14/500 [18:04<10:48:25, 80.05s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.33E+07, Train scatter: [0.5505 0.0861 0.3274 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5561 0.0876 0.3332 0.985 ], Lowest was [0.5561 0.0862 0.3332 0.985 ]
Median for last 10 epochs: [0.6053 0.0937 0.358  0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [19:07<10:03:21, 74.64s/it]  3%|▎         | 16/500 [20:38<10:43:46, 79.81s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.39E+07, Train scatter: [0.5012 0.0848 0.3426 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5034 0.0867 0.3462 0.9851], Lowest was [0.5034 0.0862 0.3332 0.985 ]
Median for last 10 epochs: [0.5972 0.0876 0.3462 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [21:41<10:00:18, 74.57s/it]  4%|▎         | 18/500 [23:13<10:40:51, 79.78s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.97E+07, Train scatter: [0.6049 0.0945 0.3696 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.597  0.0941 0.3798 0.985 ], Lowest was [0.5034 0.0862 0.3332 0.985 ]
Median for last 10 epochs: [0.597  0.0876 0.3462 0.985 ], Epochs since improvement 2
  4%|▍         | 19/500 [24:15<9:56:49, 74.45s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 1.18E+07, Train scatter: [0.513  0.0833 0.3298 0.9741]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5103 0.0826 0.3321 0.9659], Lowest was [0.5034 0.0826 0.3321 0.9659]
Median for last 10 epochs: [0.5561 0.0867 0.3403 0.985 ], Epochs since improvement 0
  4%|▍         | 20/500 [25:53<10:52:58, 81.62s/it]  4%|▍         | 21/500 [26:55<10:05:03, 75.79s/it]  4%|▍         | 22/500 [28:26<10:39:56, 80.33s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.51E+06, Train scatter: [0.4937 0.0831 0.3714 0.6095]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.488  0.0834 0.3733 0.6096], Lowest was [0.488  0.0826 0.3321 0.6096]
Median for last 10 epochs: [0.5103 0.0867 0.3462 0.985 ], Epochs since improvement 0
  5%|▍         | 23/500 [29:28<9:55:17, 74.88s/it]   5%|▍         | 24/500 [30:59<10:32:23, 79.71s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.83E+06, Train scatter: [0.4678 0.0755 0.3221 0.5107]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4634 0.0764 0.33   0.5108], Lowest was [0.4634 0.0764 0.33   0.5108]
Median for last 10 epochs: [0.5034 0.0834 0.3462 0.9659], Epochs since improvement 0
  5%|▌         | 25/500 [32:02<9:49:38, 74.48s/it]   5%|▌         | 26/500 [33:34<10:30:07, 79.76s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.32E+06, Train scatter: [0.4328 0.0738 0.3154 0.4944]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4228 0.0728 0.317  0.492 ], Lowest was [0.4228 0.0728 0.317  0.492 ]
Median for last 10 epochs: [0.488  0.0826 0.3321 0.6096], Epochs since improvement 0
  5%|▌         | 27/500 [34:36<9:47:40, 74.55s/it]   6%|▌         | 28/500 [36:07<10:25:59, 79.57s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.16E+06, Train scatter: [0.4905 0.0721 0.3031 0.4821]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4795 0.0716 0.3069 0.4824], Lowest was [0.4228 0.0716 0.3069 0.4824]
Median for last 10 epochs: [0.4795 0.0764 0.33   0.5108], Epochs since improvement 0
  6%|▌         | 29/500 [37:10<9:44:28, 74.46s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.91E+06, Train scatter: [0.4189 0.0699 0.2987 0.475 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4162 0.0695 0.3023 0.4733], Lowest was [0.4162 0.0695 0.3023 0.4733]
Median for last 10 epochs: [0.4634 0.0728 0.317  0.492 ], Epochs since improvement 0
  6%|▌         | 30/500 [38:48<10:40:08, 81.72s/it]  6%|▌         | 31/500 [39:51<9:52:59, 75.86s/it]   6%|▋         | 32/500 [41:22<10:28:41, 80.60s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.01E+06, Train scatter: [0.4119 0.0713 0.2958 0.4705]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4059 0.072  0.3022 0.4744], Lowest was [0.4059 0.0695 0.3022 0.4733]
Median for last 10 epochs: [0.4228 0.072  0.3069 0.4824], Epochs since improvement 0
  7%|▋         | 33/500 [42:25<9:44:27, 75.09s/it]   7%|▋         | 34/500 [43:57<10:23:06, 80.23s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.78E+06, Train scatter: [0.4029 0.0678 0.3038 0.4891]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4039 0.0679 0.3106 0.4915], Lowest was [0.4039 0.0679 0.3022 0.4733]
Median for last 10 epochs: [0.4162 0.0716 0.3069 0.4824], Epochs since improvement 0
  7%|▋         | 35/500 [44:59<9:39:34, 74.78s/it]   7%|▋         | 36/500 [46:31<10:18:11, 79.94s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.71E+06, Train scatter: [0.3879 0.0693 0.318  0.4868]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3802 0.0694 0.3208 0.4846], Lowest was [0.3802 0.0679 0.3022 0.4733]
Median for last 10 epochs: [0.4059 0.0695 0.3069 0.4824], Epochs since improvement 0
  7%|▋         | 37/500 [47:33<9:35:26, 74.57s/it]   8%|▊         | 38/500 [49:05<10:14:05, 79.75s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.63E+06, Train scatter: [0.3979 0.0665 0.2896 0.4614]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3861 0.0661 0.2946 0.4581], Lowest was [0.3802 0.0661 0.2946 0.4581]
Median for last 10 epochs: [0.4039 0.0694 0.3023 0.4744], Epochs since improvement 0
  8%|▊         | 39/500 [50:07<9:31:53, 74.43s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.57E+06, Train scatter: [0.3623 0.0674 0.2947 0.4764]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3564 0.0681 0.3015 0.4817], Lowest was [0.3564 0.0661 0.2946 0.4581]
Median for last 10 epochs: [0.3861 0.0681 0.3022 0.4817], Epochs since improvement 0
  8%|▊         | 40/500 [51:46<10:27:41, 81.87s/it]  8%|▊         | 41/500 [52:48<9:40:35, 75.89s/it]   8%|▊         | 42/500 [54:19<10:15:10, 80.59s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.48E+06, Train scatter: [0.374  0.0667 0.298  0.4554]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3673 0.0669 0.3068 0.4593], Lowest was [0.3564 0.0661 0.2946 0.4581]
Median for last 10 epochs: [0.3802 0.0679 0.3068 0.4817], Epochs since improvement 2
  9%|▊         | 43/500 [55:22<9:31:32, 75.04s/it]   9%|▉         | 44/500 [56:53<10:07:34, 79.94s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.48E+06, Train scatter: [0.3225 0.0644 0.287  0.4524]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3235 0.0642 0.292  0.4532], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.3673 0.0669 0.3015 0.4593], Epochs since improvement 0
  9%|▉         | 45/500 [57:55<9:25:52, 74.62s/it]   9%|▉         | 46/500 [59:27<10:04:19, 79.87s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 5.64E+08, Train scatter: [0.9366 0.1755 0.5441 0.9958]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9209 0.1715 0.5355 0.9854], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.3673 0.0669 0.3015 0.4593], Epochs since improvement 2
  9%|▉         | 47/500 [1:00:29<9:22:33, 74.51s/it] 10%|▉         | 48/500 [1:02:00<9:58:24, 79.44s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.16E+07, Train scatter: [0.9343 0.1421 0.5441 0.9839]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9187 0.1415 0.5355 0.9742], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.3673 0.0681 0.3068 0.4817], Epochs since improvement 4
 10%|▉         | 49/500 [1:03:02<9:18:01, 74.24s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 9.29E+06, Train scatter: [0.9042 0.1221 0.5425 0.8497]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8897 0.118  0.534  0.8432], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.8897 0.118  0.534  0.8432], Epochs since improvement 6
 10%|█         | 50/500 [1:04:43<10:17:27, 82.33s/it] 10%|█         | 51/500 [1:05:46<9:30:58, 76.30s/it]  10%|█         | 52/500 [1:07:18<10:05:10, 81.05s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.92E+06, Train scatter: [0.8497 0.1072 0.5419 0.6016]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8382 0.1028 0.5334 0.5925], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.8897 0.118  0.534  0.8432], Epochs since improvement 8
 11%|█         | 53/500 [1:08:20<9:21:50, 75.42s/it]  11%|█         | 54/500 [1:09:51<9:55:49, 80.16s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.45E+06, Train scatter: [0.7274 0.1058 0.5398 0.5979]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7243 0.1009 0.5315 0.5855], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.8897 0.118  0.534  0.8432], Epochs since improvement 10
 11%|█         | 55/500 [1:10:53<9:13:57, 74.69s/it] 11%|█         | 56/500 [1:12:25<9:50:57, 79.86s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.12E+06, Train scatter: [0.6269 0.1021 0.5331 0.5811]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6295 0.0989 0.525  0.5697], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.8382 0.1028 0.5334 0.5925], Epochs since improvement 12
 11%|█▏        | 57/500 [1:13:27<9:10:10, 74.52s/it] 12%|█▏        | 58/500 [1:14:59<9:47:18, 79.73s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.91E+06, Train scatter: [0.5643 0.0987 0.4844 0.5809]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5636 0.0961 0.4781 0.57  ], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.7243 0.1009 0.5315 0.5855], Epochs since improvement 14
 12%|█▏        | 59/500 [1:16:01<9:07:03, 74.43s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.74E+06, Train scatter: [0.469  0.0984 0.4691 0.588 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4617 0.0961 0.4638 0.5802], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.6295 0.0989 0.525  0.5802], Epochs since improvement 16
 12%|█▏        | 60/500 [1:17:40<10:00:24, 81.87s/it] 12%|█▏        | 61/500 [1:18:42<9:15:26, 75.92s/it]  12%|█▏        | 62/500 [1:20:15<9:49:33, 80.76s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.59E+06, Train scatter: [0.4541 0.0974 0.4435 0.5711]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4447 0.0948 0.4374 0.5626], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.5636 0.0961 0.4781 0.57  ], Epochs since improvement 18
 13%|█▎        | 63/500 [1:21:16<9:06:59, 75.10s/it] 13%|█▎        | 64/500 [1:22:49<9:44:01, 80.37s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.51E+06, Train scatter: [0.6037 0.1001 0.4592 0.5641]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5976 0.0977 0.4522 0.5578], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.5636 0.0961 0.4638 0.5697], Epochs since improvement 20
 13%|█▎        | 65/500 [1:23:51<9:02:30, 74.83s/it] 13%|█▎        | 65/500 [1:25:23<9:31:28, 78.83s/it]
Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.31E+06, Train scatter: [0.4512 0.0988 0.43   0.554 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4422 0.0967 0.4234 0.5467], Lowest was [0.3235 0.0642 0.292  0.4532]
Median for last 10 epochs: [0.4617 0.0961 0.4522 0.5626], Epochs since improvement 22
Exited after 66 epochs due to early stopping
5123.65 seconds spent training, 10.247 seconds per epoch. Processed 6796 trees per second
[0.44220558 0.09667654 0.4234144  0.546673  ]
{'epoch_exit': 65, 'scatter_m_star': 0.44220558, 'lowest_m_star': 0.32353058, 'last20_m_star': 0.6135675, 'last10_m_star': 0.46168151, 'scatter_v_disk': 0.09667654, 'lowest_v_disk': 0.064207636, 'last20_v_disk': 0.09828196, 'last10_v_disk': 0.096134976, 'scatter_m_cold': 0.4234144, 'lowest_m_cold': 0.29204017, 'last20_m_cold': 0.5015916, 'last10_m_cold': 0.45224723, 'scatter_sfr_100': 0.546673, 'lowest_sfr_100': 0.4532237, 'last20_sfr_100': 0.57511365, 'last10_sfr_100': 0.56264204}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_ygbzur
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:54<7:31:03, 54.24s/it]  0%|          | 2/500 [02:15<9:42:54, 70.23s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.1704 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1652 0.5355 0.985 ], Lowest was [0.9196 0.1652 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1652 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:09<8:39:53, 62.76s/it]  1%|          | 4/500 [04:31<9:42:56, 70.52s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 9.09E+07, Train scatter: [0.9352 0.1511 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1464 0.5355 0.985 ], Lowest was [0.9196 0.1464 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1464 0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:25<8:52:12, 64.51s/it]  1%|          | 6/500 [06:48<9:40:40, 70.53s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.78E+07, Train scatter: [0.9351 0.1322 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1297 0.5355 0.985 ], Lowest was [0.9195 0.1297 0.5355 0.985 ]
Median for last 10 epochs: [0.9195 0.1297 0.5355 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [07:41<8:54:51, 65.09s/it]  2%|▏         | 8/500 [09:03<9:38:06, 70.50s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.39E+07, Train scatter: [0.9337 0.1096 0.5438 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.918  0.1092 0.5352 0.9851], Lowest was [0.918  0.1092 0.5352 0.985 ]
Median for last 10 epochs: [0.9187 0.1195 0.5354 0.985 ], Epochs since improvement 0
  2%|▏         | 9/500 [09:57<8:54:29, 65.31s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.22E+07, Train scatter: [0.8007 0.0992 0.5421 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7854 0.0999 0.5336 0.9851], Lowest was [0.7854 0.0999 0.5336 0.985 ]
Median for last 10 epochs: [0.918  0.1092 0.5352 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:26<9:51:57, 72.49s/it]  2%|▏         | 11/500 [12:20<9:04:37, 66.83s/it]  2%|▏         | 12/500 [13:43<9:42:41, 71.64s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.09E+07, Train scatter: [0.7012 0.092  0.5356 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6942 0.0924 0.5273 0.985 ], Lowest was [0.6942 0.0924 0.5273 0.985 ]
Median for last 10 epochs: [0.918  0.1092 0.5352 0.985 ], Epochs since improvement 0
  3%|▎         | 13/500 [14:36<8:57:36, 66.24s/it]  3%|▎         | 14/500 [15:57<9:32:38, 70.70s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.96E+07, Train scatter: [0.544  0.0873 0.531  0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5448 0.0884 0.5232 0.9849], Lowest was [0.5448 0.0884 0.5232 0.9849]
Median for last 10 epochs: [0.7854 0.0999 0.5336 0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [16:51<8:50:37, 65.65s/it]  3%|▎         | 16/500 [18:13<9:28:14, 70.44s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.88E+07, Train scatter: [0.4766 0.0875 0.4495 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.481  0.0867 0.4544 0.9849], Lowest was [0.481  0.0867 0.4544 0.9849]
Median for last 10 epochs: [0.6942 0.0924 0.5273 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [19:07<8:47:16, 65.50s/it]  4%|▎         | 18/500 [20:28<9:23:39, 70.17s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.87E+07, Train scatter: [0.4742 0.0846 0.5414 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4665 0.0845 0.5329 0.9849], Lowest was [0.4665 0.0845 0.4544 0.9849]
Median for last 10 epochs: [0.5448 0.0884 0.5273 0.9849], Epochs since improvement 0
  4%|▍         | 19/500 [21:22<8:43:26, 65.29s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.78E+07, Train scatter: [0.4514 0.0811 0.5274 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4556 0.0816 0.5194 0.9849], Lowest was [0.4556 0.0816 0.4544 0.9849]
Median for last 10 epochs: [0.481  0.0867 0.5232 0.9849], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:51<9:39:03, 72.38s/it]  4%|▍         | 21/500 [23:45<8:53:30, 66.83s/it]  4%|▍         | 22/500 [25:07<9:30:17, 71.58s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.66E+07, Train scatter: [0.5322 0.0878 0.3884 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5462 0.0889 0.386  0.985 ], Lowest was [0.4556 0.0816 0.386  0.9849]
Median for last 10 epochs: [0.481  0.0867 0.5194 0.9849], Epochs since improvement 0
  5%|▍         | 23/500 [26:01<8:46:44, 66.26s/it]  5%|▍         | 24/500 [27:22<9:21:25, 70.77s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.52E+07, Train scatter: [0.5412 0.0921 0.3598 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5577 0.0943 0.3699 0.985 ], Lowest was [0.4556 0.0816 0.3699 0.9849]
Median for last 10 epochs: [0.481  0.0867 0.4544 0.9849], Epochs since improvement 0
  5%|▌         | 25/500 [28:16<8:39:47, 65.66s/it]  5%|▌         | 26/500 [29:39<9:20:25, 70.94s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.29E+07, Train scatter: [0.4887 0.0842 0.3316 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5016 0.0857 0.3371 0.985 ], Lowest was [0.4556 0.0816 0.3371 0.9849]
Median for last 10 epochs: [0.5016 0.0857 0.386  0.985 ], Epochs since improvement 0
  5%|▌         | 27/500 [30:33<8:38:52, 65.82s/it]  6%|▌         | 28/500 [31:55<9:14:47, 70.52s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.23E+07, Train scatter: [0.5554 0.086  0.3703 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5652 0.0863 0.3772 0.985 ], Lowest was [0.4556 0.0816 0.3371 0.9849]
Median for last 10 epochs: [0.5462 0.0863 0.3772 0.985 ], Epochs since improvement 2
  6%|▌         | 29/500 [32:49<8:34:43, 65.57s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.19E+07, Train scatter: [0.3908 0.079  0.3129 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4061 0.0792 0.3134 0.985 ], Lowest was [0.4061 0.0792 0.3134 0.9849]
Median for last 10 epochs: [0.5462 0.0863 0.3699 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [34:18<9:28:42, 72.60s/it]  6%|▌         | 31/500 [35:12<8:43:12, 66.94s/it]  6%|▋         | 32/500 [36:34<9:19:06, 71.68s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.12E+07, Train scatter: [0.4602 0.0767 0.327  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4779 0.0768 0.3238 0.985 ], Lowest was [0.4061 0.0768 0.3134 0.9849]
Median for last 10 epochs: [0.5016 0.0857 0.3371 0.985 ], Epochs since improvement 0
  7%|▋         | 33/500 [37:28<8:36:07, 66.31s/it]  7%|▋         | 34/500 [38:49<9:09:54, 70.80s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.05E+07, Train scatter: [0.432  0.0823 0.3844 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4471 0.0832 0.3828 0.9851], Lowest was [0.4061 0.0768 0.3134 0.9849]
Median for last 10 epochs: [0.4779 0.0832 0.3371 0.985 ], Epochs since improvement 2
  7%|▋         | 35/500 [39:43<8:29:17, 65.71s/it]  7%|▋         | 36/500 [41:05<9:05:44, 70.57s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.02E+07, Train scatter: [0.3887 0.0768 0.3046 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3797 0.0773 0.3077 0.985 ], Lowest was [0.3797 0.0768 0.3077 0.9849]
Median for last 10 epochs: [0.4471 0.0792 0.3238 0.985 ], Epochs since improvement 0
  7%|▋         | 37/500 [41:59<8:25:34, 65.52s/it]  8%|▊         | 38/500 [43:21<9:02:22, 70.44s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.48E+07, Train scatter: [0.3666 0.0741 0.2979 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3599 0.0744 0.2997 0.985 ], Lowest was [0.3599 0.0744 0.2997 0.9849]
Median for last 10 epochs: [0.4061 0.0773 0.3134 0.985 ], Epochs since improvement 0
  8%|▊         | 39/500 [44:15<8:22:46, 65.44s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.94E+07, Train scatter: [0.3131 0.0727 0.295  0.993 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3236 0.0727 0.3006 0.983 ], Lowest was [0.3236 0.0727 0.2997 0.983 ]
Median for last 10 epochs: [0.3797 0.0768 0.3077 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:45<9:19:24, 72.97s/it]  8%|▊         | 41/500 [46:39<8:33:56, 67.18s/it]  8%|▊         | 42/500 [48:01<9:07:01, 71.66s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 5.54E+06, Train scatter: [0.4639 0.0786 0.3359 0.5745]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4617 0.0788 0.3474 0.5775], Lowest was [0.3236 0.0727 0.2997 0.5775]
Median for last 10 epochs: [0.3797 0.0773 0.3077 0.985 ], Epochs since improvement 0
  9%|▊         | 43/500 [48:55<8:25:16, 66.34s/it]  9%|▉         | 44/500 [50:16<8:58:39, 70.88s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.02E+06, Train scatter: [0.5557 0.0774 0.3196 0.5623]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5399 0.0778 0.3231 0.5573], Lowest was [0.3236 0.0727 0.2997 0.5573]
Median for last 10 epochs: [0.3797 0.0773 0.3077 0.983 ], Epochs since improvement 0
  9%|▉         | 45/500 [51:10<8:18:34, 65.75s/it]  9%|▉         | 46/500 [52:32<8:55:10, 70.73s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.37E+06, Train scatter: [0.3834 0.0773 0.3125 0.5126]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3793 0.0769 0.3169 0.5111], Lowest was [0.3236 0.0727 0.2997 0.5111]
Median for last 10 epochs: [0.3793 0.0769 0.3169 0.5775], Epochs since improvement 0
  9%|▉         | 47/500 [53:26<8:15:45, 65.66s/it] 10%|▉         | 48/500 [54:49<8:53:17, 70.79s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.48E+06, Train scatter: [0.4229 0.0748 0.2997 0.5193]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4241 0.0749 0.3026 0.5202], Lowest was [0.3236 0.0727 0.2997 0.5111]
Median for last 10 epochs: [0.4241 0.0769 0.3169 0.5573], Epochs since improvement 2
 10%|▉         | 49/500 [55:43<8:13:48, 65.70s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.39E+06, Train scatter: [0.4189 0.0783 0.3163 0.5124]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4125 0.0779 0.3176 0.5098], Lowest was [0.3236 0.0727 0.2997 0.5098]
Median for last 10 epochs: [0.4241 0.0778 0.3176 0.5202], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [57:12<9:04:57, 72.66s/it] 10%|█         | 51/500 [58:06<8:22:03, 67.09s/it] 10%|█         | 52/500 [59:28<8:54:42, 71.61s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.61E+06, Train scatter: [0.4077 0.0726 0.3123 0.4861]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4001 0.0732 0.3155 0.4864], Lowest was [0.3236 0.0727 0.2997 0.4864]
Median for last 10 epochs: [0.4125 0.0769 0.3169 0.5111], Epochs since improvement 0
 11%|█         | 53/500 [1:00:22<8:13:58, 66.31s/it] 11%|█         | 54/500 [1:01:43<8:46:53, 70.88s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.05E+06, Train scatter: [0.5211 0.07   0.2893 0.503 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5111 0.069  0.2926 0.498 ], Lowest was [0.3236 0.069  0.2926 0.4864]
Median for last 10 epochs: [0.4125 0.0749 0.3155 0.5098], Epochs since improvement 0
 11%|█         | 55/500 [1:02:38<8:08:21, 65.85s/it] 11%|█         | 56/500 [1:04:00<8:44:11, 70.84s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.87E+06, Train scatter: [0.2688 0.0654 0.2804 0.4731]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2756 0.0656 0.2853 0.4708], Lowest was [0.2756 0.0656 0.2853 0.4708]
Median for last 10 epochs: [0.4125 0.0732 0.3026 0.498 ], Epochs since improvement 0
 11%|█▏        | 57/500 [1:04:54<8:05:56, 65.82s/it] 12%|█▏        | 58/500 [1:06:15<8:38:44, 70.42s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.08E+06, Train scatter: [0.4011 0.0678 0.278  0.4727]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3913 0.0684 0.2829 0.4705], Lowest was [0.2756 0.0656 0.2829 0.4705]
Median for last 10 epochs: [0.4001 0.069  0.2926 0.4864], Epochs since improvement 0
 12%|█▏        | 59/500 [1:07:09<8:01:13, 65.47s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.75E+06, Train scatter: [0.301  0.0664 0.3054 0.475 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3038 0.0669 0.3084 0.4746], Lowest was [0.2756 0.0656 0.2829 0.4705]
Median for last 10 epochs: [0.3913 0.0684 0.2926 0.4746], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:08:39<8:52:40, 72.64s/it] 12%|█▏        | 61/500 [1:09:33<8:10:33, 67.05s/it] 12%|█▏        | 62/500 [1:10:55<8:42:08, 71.53s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.89E+06, Train scatter: [0.3595 0.066  0.2954 0.4833]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3561 0.0669 0.2981 0.485 ], Lowest was [0.2756 0.0656 0.2829 0.4705]
Median for last 10 epochs: [0.3561 0.0669 0.2926 0.4746], Epochs since improvement 4
 13%|█▎        | 63/500 [1:11:49<8:02:49, 66.29s/it] 13%|█▎        | 64/500 [1:13:11<8:37:13, 71.18s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.63E+06, Train scatter: [0.5632 0.0631 0.2829 0.4719]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5359 0.064  0.2869 0.473 ], Lowest was [0.2756 0.064  0.2829 0.4705]
Median for last 10 epochs: [0.3561 0.0669 0.2869 0.473 ], Epochs since improvement 0
 13%|█▎        | 65/500 [1:14:05<7:58:49, 66.04s/it] 13%|█▎        | 66/500 [1:15:28<8:33:42, 71.02s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.68E+06, Train scatter: [0.4209 0.0633 0.283  0.4778]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4098 0.0636 0.2842 0.479 ], Lowest was [0.2756 0.0636 0.2829 0.4705]
Median for last 10 epochs: [0.3913 0.0669 0.2869 0.4746], Epochs since improvement 0
 13%|█▎        | 67/500 [1:16:22<7:55:53, 65.94s/it] 14%|█▎        | 68/500 [1:17:44<8:28:56, 70.69s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.47E+06, Train scatter: [0.4077 0.0762 0.2794 0.4666]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3973 0.0766 0.2835 0.4674], Lowest was [0.2756 0.0636 0.2829 0.4674]
Median for last 10 epochs: [0.3973 0.0669 0.2869 0.4746], Epochs since improvement 0
 14%|█▍        | 69/500 [1:18:38<7:51:38, 65.66s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.48E+06, Train scatter: [0.3051 0.0638 0.289  0.4808]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3055 0.0645 0.2889 0.4785], Lowest was [0.2756 0.0636 0.2829 0.4674]
Median for last 10 epochs: [0.3973 0.0645 0.2869 0.4785], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:20:07<8:41:35, 72.78s/it] 14%|█▍        | 71/500 [1:21:01<8:00:07, 67.15s/it] 14%|█▍        | 72/500 [1:22:23<8:30:20, 71.54s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 2.52E+06, Train scatter: [0.4719 0.0634 0.2786 0.4698]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4648 0.0645 0.2841 0.4709], Lowest was [0.2756 0.0636 0.2829 0.4674]
Median for last 10 epochs: [0.4098 0.0645 0.2842 0.473 ], Epochs since improvement 4
 15%|█▍        | 73/500 [1:23:17<7:51:42, 66.28s/it] 15%|█▍        | 74/500 [1:24:39<8:24:16, 71.02s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.40E+06, Train scatter: [0.3749 0.067  0.2827 0.4878]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3655 0.0666 0.2846 0.4908], Lowest was [0.2756 0.0636 0.2829 0.4674]
Median for last 10 epochs: [0.3973 0.0645 0.2842 0.4785], Epochs since improvement 6
 15%|█▌        | 75/500 [1:25:33<7:46:58, 65.93s/it] 15%|█▌        | 76/500 [1:26:55<8:19:33, 70.69s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.35E+06, Train scatter: [0.3492 0.0611 0.2695 0.4825]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.345  0.0616 0.2738 0.4835], Lowest was [0.2756 0.0616 0.2738 0.4674]
Median for last 10 epochs: [0.3655 0.0645 0.2841 0.4785], Epochs since improvement 0
 15%|█▌        | 77/500 [1:27:49<7:43:09, 65.70s/it] 16%|█▌        | 78/500 [1:29:11<8:16:30, 70.59s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.42E+06, Train scatter: [0.4376 0.0626 0.2681 0.4612]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4255 0.0645 0.2736 0.4654], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.3655 0.0645 0.2841 0.4785], Epochs since improvement 0
 16%|█▌        | 79/500 [1:30:05<7:40:18, 65.60s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.25E+06, Train scatter: [0.3846 0.0734 0.2833 0.4891]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3765 0.0736 0.2888 0.4924], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.3765 0.0645 0.2841 0.4835], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:31:35<8:30:01, 72.86s/it] 16%|█▌        | 81/500 [1:32:29<7:49:21, 67.21s/it] 16%|█▋        | 82/500 [1:33:50<8:18:28, 71.55s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.20E+06, Train scatter: [0.4585 0.0821 0.2806 0.4823]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4496 0.082  0.2839 0.4833], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.3765 0.0666 0.2839 0.4835], Epochs since improvement 4
 17%|█▋        | 83/500 [1:34:44<7:40:32, 66.27s/it] 17%|█▋        | 84/500 [1:36:07<8:13:09, 71.13s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 5.92E+08, Train scatter: [0.9357 0.1728 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9201 0.169  0.5355 0.9848], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.4255 0.0736 0.2839 0.4835], Epochs since improvement 6
 17%|█▋        | 85/500 [1:37:01<7:36:43, 66.03s/it] 17%|█▋        | 86/500 [1:38:23<8:07:55, 70.71s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 6.59E+06, Train scatter: [0.9356 0.1728 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.92   0.169  0.5355 0.9849], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.4496 0.082  0.2888 0.4924], Epochs since improvement 8
 17%|█▋        | 87/500 [1:39:17<7:32:14, 65.70s/it] 18%|█▊        | 88/500 [1:40:38<8:04:00, 70.49s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 4.81E+06, Train scatter: [0.9357 0.1728 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.92   0.169  0.5355 0.9849], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.92   0.169  0.5355 0.9848], Epochs since improvement 10
 18%|█▊        | 89/500 [1:41:32<7:29:08, 65.57s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 3.44E+06, Train scatter: [0.9358 0.1732 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9201 0.1694 0.5355 0.9849], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.92   0.169  0.5355 0.9849], Epochs since improvement 12
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:43:02<8:17:23, 72.79s/it] 18%|█▊        | 91/500 [1:43:56<7:37:38, 67.14s/it] 18%|█▊        | 92/500 [1:45:17<8:05:20, 71.37s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.67E+06, Train scatter: [0.9359 0.1734 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9202 0.1695 0.5355 0.9848], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.9201 0.169  0.5355 0.9849], Epochs since improvement 14
 19%|█▊        | 93/500 [1:46:11<7:28:29, 66.12s/it] 19%|█▉        | 94/500 [1:47:33<7:59:54, 70.92s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.13E+06, Train scatter: [0.9359 0.1734 0.5441 0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9202 0.1696 0.5355 0.9847], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.9201 0.1694 0.5355 0.9849], Epochs since improvement 16
 19%|█▉        | 95/500 [1:48:27<7:25:00, 65.93s/it] 19%|█▉        | 96/500 [1:49:49<7:56:23, 70.75s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 1.65E+06, Train scatter: [0.936  0.1735 0.5441 0.9949]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9204 0.1697 0.5355 0.9845], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.9202 0.1695 0.5355 0.9848], Epochs since improvement 18
 19%|█▉        | 97/500 [1:50:43<7:21:38, 65.75s/it] 20%|█▉        | 98/500 [1:52:05<7:52:25, 70.51s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 1.29E+06, Train scatter: [0.936  0.1733 0.5441 0.9949]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9204 0.1695 0.5355 0.9846], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.9202 0.1695 0.5355 0.9847], Epochs since improvement 20
 20%|█▉        | 99/500 [1:52:59<7:17:56, 65.53s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 1.06E+06, Train scatter: [0.936  0.1733 0.5441 0.9947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9204 0.1695 0.5355 0.9843], Lowest was [0.2756 0.0616 0.2736 0.4654]
Median for last 10 epochs: [0.9204 0.1695 0.5355 0.9846], Epochs since improvement 22
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|█▉        | 99/500 [1:54:29<7:43:46, 69.39s/it]
Exited after 100 epochs due to early stopping
6869.83 seconds spent training, 13.740 seconds per epoch. Processed 5068 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.9203288  0.16948153 0.535467   0.9843159 ]
{'epoch_exit': 99, 'scatter_m_star': 0.9203288, 'lowest_m_star': 0.2755637, 'last20_m_star': 0.92018366, 'last10_m_star': 0.92035675, 'scatter_v_disk': 0.16948153, 'lowest_v_disk': 0.061575938, 'last20_v_disk': 0.16944297, 'last10_v_disk': 0.16954677, 'scatter_m_cold': 0.535467, 'lowest_m_cold': 0.27363348, 'last20_m_cold': 0.5354891, 'last10_m_cold': 0.53548443, 'scatter_sfr_100': 0.9843159, 'lowest_sfr_100': 0.4654194, 'last20_sfr_100': 0.98472553, 'last10_sfr_100': 0.9845517}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
