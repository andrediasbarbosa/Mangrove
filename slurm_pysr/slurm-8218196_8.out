Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_ibnorh
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:34<4:47:54, 34.62s/it]  0%|          | 2/500 [01:22<5:51:56, 42.40s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.21E+07, Train scatter: [0.9353 0.1748 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1819 0.5356 0.9851], Lowest was [0.9198 0.1819 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1819 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:53<5:08:34, 37.25s/it]  1%|          | 4/500 [02:41<5:42:44, 41.46s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 7.47E+06, Train scatter: [0.9352 0.1755 0.544  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1873 0.5354 0.985 ], Lowest was [0.9197 0.1819 0.5354 0.985 ]
Median for last 10 epochs: [0.9197 0.1846 0.5354 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:12<5:11:15, 37.73s/it]  1%|          | 6/500 [04:00<5:39:05, 41.19s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.63E+06, Train scatter: [0.9347 0.1421 0.5428 0.7262]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9191 0.145  0.5343 0.7221], Lowest was [0.9191 0.145  0.5343 0.7221]
Median for last 10 epochs: [0.9191 0.145  0.5343 0.7221], Epochs since improvement 0
  1%|▏         | 7/500 [04:31<5:11:37, 37.93s/it]  2%|▏         | 8/500 [05:19<5:36:47, 41.07s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.82E+06, Train scatter: [0.9246 0.1251 0.5365 0.6673]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9091 0.1259 0.5282 0.664 ], Lowest was [0.9091 0.1259 0.5282 0.664 ]
Median for last 10 epochs: [0.9141 0.1355 0.5312 0.6931], Epochs since improvement 0
  2%|▏         | 9/500 [05:50<5:10:40, 37.96s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.14E+06, Train scatter: [0.7702 0.1116 0.5216 0.6154]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7534 0.1132 0.5137 0.6138], Lowest was [0.7534 0.1132 0.5137 0.6138]
Median for last 10 epochs: [0.9091 0.1259 0.5282 0.664 ], Epochs since improvement 0
  2%|▏         | 10/500 [06:44<5:49:48, 42.83s/it]  2%|▏         | 11/500 [07:15<5:20:01, 39.27s/it]  2%|▏         | 12/500 [08:03<5:40:10, 41.82s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.54E+06, Train scatter: [0.5809 0.1103 0.4296 0.6009]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5842 0.1138 0.4269 0.6024], Lowest was [0.5842 0.1132 0.4269 0.6024]
Median for last 10 epochs: [0.9091 0.1259 0.5282 0.664 ], Epochs since improvement 0
  3%|▎         | 13/500 [08:34<5:13:22, 38.61s/it]  3%|▎         | 14/500 [09:21<5:34:13, 41.26s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.85E+06, Train scatter: [0.5395 0.1019 0.3856 0.5959]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5323 0.1047 0.3863 0.6029], Lowest was [0.5323 0.1047 0.3863 0.6024]
Median for last 10 epochs: [0.7534 0.1138 0.5137 0.6138], Epochs since improvement 0
  3%|▎         | 15/500 [09:53<5:09:18, 38.27s/it]  3%|▎         | 16/500 [10:40<5:31:25, 41.09s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.29E+06, Train scatter: [0.5555 0.099  0.3719 0.6075]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5655 0.1039 0.3798 0.6201], Lowest was [0.5323 0.1039 0.3798 0.6024]
Median for last 10 epochs: [0.5842 0.1132 0.4269 0.6138], Epochs since improvement 0
  3%|▎         | 17/500 [11:12<5:07:22, 38.18s/it]  4%|▎         | 18/500 [11:59<5:29:39, 41.04s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.09E+06, Train scatter: [0.5841 0.0934 0.3601 0.5932]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5722 0.0943 0.3597 0.5923], Lowest was [0.5323 0.0943 0.3597 0.5923]
Median for last 10 epochs: [0.5722 0.1047 0.3863 0.6029], Epochs since improvement 0
  4%|▍         | 19/500 [12:31<5:05:39, 38.13s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.96E+05, Train scatter: [0.5475 0.0905 0.3344 0.5958]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5347 0.0918 0.3409 0.6014], Lowest was [0.5323 0.0918 0.3409 0.5923]
Median for last 10 epochs: [0.5655 0.1039 0.3798 0.6024], Epochs since improvement 0
  4%|▍         | 20/500 [13:23<5:39:38, 42.45s/it]  4%|▍         | 21/500 [13:55<5:12:14, 39.11s/it]  4%|▍         | 22/500 [14:42<5:31:59, 41.67s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 8.19E+05, Train scatter: [0.4703 0.087  0.3313 0.5565]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4681 0.0881 0.3391 0.5544], Lowest was [0.4681 0.0881 0.3391 0.5544]
Median for last 10 epochs: [0.5347 0.0943 0.3597 0.6014], Epochs since improvement 0
  5%|▍         | 23/500 [15:14<5:06:26, 38.55s/it]  5%|▍         | 24/500 [16:02<5:28:35, 41.42s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.46E+05, Train scatter: [0.4611 0.0851 0.3223 0.5403]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4544 0.0863 0.326  0.5379], Lowest was [0.4544 0.0863 0.326  0.5379]
Median for last 10 epochs: [0.5347 0.0918 0.3409 0.5923], Epochs since improvement 0
  5%|▌         | 25/500 [16:33<5:03:49, 38.38s/it]  5%|▌         | 26/500 [17:20<5:24:49, 41.12s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 8.22E+05, Train scatter: [0.4893 0.0844 0.3154 0.5427]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4826 0.0856 0.3163 0.5391], Lowest was [0.4544 0.0856 0.3163 0.5379]
Median for last 10 epochs: [0.4826 0.0881 0.3391 0.5544], Epochs since improvement 0
  5%|▌         | 27/500 [17:52<5:00:31, 38.12s/it]  6%|▌         | 28/500 [18:39<5:22:36, 41.01s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 5.88E+05, Train scatter: [0.7187 0.0823 0.3072 0.533 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7259 0.084  0.3174 0.5379], Lowest was [0.4544 0.084  0.3163 0.5379]
Median for last 10 epochs: [0.4826 0.0863 0.326  0.5391], Epochs since improvement 0
  6%|▌         | 29/500 [19:10<4:58:28, 38.02s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 5.42E+05, Train scatter: [0.4888 0.0802 0.2971 0.5185]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4797 0.0817 0.3029 0.5199], Lowest was [0.4544 0.0817 0.3029 0.5199]
Median for last 10 epochs: [0.4797 0.0856 0.3174 0.5379], Epochs since improvement 0
  6%|▌         | 30/500 [20:03<5:32:44, 42.48s/it]  6%|▌         | 31/500 [20:34<5:05:33, 39.09s/it]  6%|▋         | 32/500 [21:23<5:25:58, 41.79s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.72E+05, Train scatter: [0.5064 0.0795 0.3137 0.5129]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4923 0.081  0.3182 0.5098], Lowest was [0.4544 0.081  0.3029 0.5098]
Median for last 10 epochs: [0.4826 0.084  0.3174 0.5379], Epochs since improvement 0
  7%|▋         | 33/500 [21:54<5:00:19, 38.59s/it]  7%|▋         | 34/500 [22:42<5:21:52, 41.44s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 5.03E+05, Train scatter: [0.4557 0.0773 0.3158 0.5284]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4486 0.0782 0.3168 0.5252], Lowest was [0.4486 0.0782 0.3029 0.5098]
Median for last 10 epochs: [0.4826 0.0817 0.3168 0.5252], Epochs since improvement 0
  7%|▋         | 35/500 [23:13<4:57:02, 38.33s/it]  7%|▋         | 36/500 [24:01<5:19:08, 41.27s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.10E+05, Train scatter: [0.4285 0.0753 0.2913 0.5024]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4263 0.0768 0.2974 0.5011], Lowest was [0.4263 0.0768 0.2974 0.5011]
Median for last 10 epochs: [0.4797 0.081  0.3168 0.5199], Epochs since improvement 0
  7%|▋         | 37/500 [24:32<4:54:38, 38.18s/it]  8%|▊         | 38/500 [25:20<5:17:42, 41.26s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.52E+05, Train scatter: [0.2874 0.0731 0.2832 0.5052]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2902 0.0743 0.2923 0.5098], Lowest was [0.2902 0.0743 0.2923 0.5011]
Median for last 10 epochs: [0.4486 0.0782 0.3029 0.5098], Epochs since improvement 0
  8%|▊         | 39/500 [25:51<4:53:21, 38.18s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: -2.02E+04, Train scatter: [0.3817 0.0703 0.2765 0.486 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3817 0.0722 0.2877 0.4898], Lowest was [0.2902 0.0722 0.2877 0.4898]
Median for last 10 epochs: [0.4263 0.0768 0.2974 0.5098], Epochs since improvement 0
  8%|▊         | 40/500 [26:45<5:28:47, 42.89s/it]  8%|▊         | 41/500 [27:16<5:00:48, 39.32s/it]  8%|▊         | 42/500 [28:05<5:21:14, 42.08s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.54E+05, Train scatter: [0.2889 0.0675 0.2743 0.4788]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2821 0.0694 0.2828 0.4812], Lowest was [0.2821 0.0694 0.2828 0.4812]
Median for last 10 epochs: [0.3817 0.0743 0.2923 0.5011], Epochs since improvement 0
  9%|▊         | 43/500 [28:36<4:55:24, 38.78s/it]  9%|▉         | 44/500 [29:24<5:16:03, 41.59s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.71E+05, Train scatter: [0.3015 0.0659 0.277  0.4741]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3031 0.0682 0.2854 0.4782], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.3031 0.0722 0.2877 0.4898], Epochs since improvement 0
  9%|▉         | 45/500 [29:55<4:51:29, 38.44s/it]  9%|▉         | 46/500 [30:43<5:13:06, 41.38s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 8.41E+11, Train scatter: [0.9357 0.1729 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.92   0.169  0.5355 0.9851], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.3031 0.0722 0.2877 0.4898], Epochs since improvement 2
  9%|▉         | 47/500 [31:14<4:49:08, 38.30s/it] 10%|▉         | 48/500 [32:03<5:11:08, 41.30s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.37E+06, Train scatter: [0.9357 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9201 0.169  0.5355 0.985 ], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.3817 0.0722 0.2877 0.4898], Epochs since improvement 4
 10%|▉         | 49/500 [32:34<4:47:29, 38.25s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.13E+06, Train scatter: [0.9356 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.92   0.169  0.5355 0.985 ], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.92   0.169  0.5355 0.985 ], Epochs since improvement 6
 10%|█         | 50/500 [33:27<5:20:39, 42.75s/it] 10%|█         | 51/500 [33:58<4:53:48, 39.26s/it] 10%|█         | 52/500 [34:47<5:14:39, 42.14s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 2.01E+06, Train scatter: [0.9356 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.92   0.169  0.5355 0.985 ], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.92   0.169  0.5355 0.985 ], Epochs since improvement 8
 11%|█         | 53/500 [35:18<4:49:10, 38.82s/it] 11%|█         | 54/500 [36:07<5:10:19, 41.75s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.94E+06, Train scatter: [0.9355 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.169  0.5355 0.9849], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.92   0.169  0.5355 0.985 ], Epochs since improvement 10
 11%|█         | 55/500 [36:38<4:45:54, 38.55s/it] 11%|█         | 56/500 [37:27<5:08:06, 41.64s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.88E+06, Train scatter: [0.9354 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.169  0.5355 0.9849], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.92   0.169  0.5355 0.985 ], Epochs since improvement 12
 11%|█▏        | 57/500 [37:58<4:44:09, 38.49s/it] 12%|█▏        | 58/500 [38:46<5:05:26, 41.46s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.83E+06, Train scatter: [0.9354 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.169  0.5355 0.9849], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.9199 0.169  0.5355 0.9849], Epochs since improvement 14
 12%|█▏        | 59/500 [39:17<4:41:55, 38.36s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.79E+06, Train scatter: [0.9353 0.1728 0.5441 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.169  0.5355 0.985 ], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.9198 0.169  0.5355 0.9849], Epochs since improvement 16
 12%|█▏        | 60/500 [40:11<5:14:35, 42.90s/it] 12%|█▏        | 61/500 [40:42<4:47:45, 39.33s/it] 12%|█▏        | 62/500 [41:30<5:07:13, 42.09s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.75E+06, Train scatter: [0.9337 0.1728 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9182 0.1689 0.5355 0.9852], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.9198 0.169  0.5355 0.9849], Epochs since improvement 18
 13%|█▎        | 63/500 [42:01<4:42:30, 38.79s/it] 13%|█▎        | 64/500 [42:50<5:02:26, 41.62s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.71E+06, Train scatter: [0.9297 0.1721 0.5441 0.9905]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9141 0.1682 0.5355 0.9802], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.9197 0.169  0.5355 0.9849], Epochs since improvement 20
 13%|█▎        | 65/500 [43:21<4:38:56, 38.48s/it] 13%|█▎        | 65/500 [44:09<4:55:32, 40.76s/it]
Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.64E+06, Train scatter: [0.9271 0.1683 0.5441 0.744 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9116 0.1645 0.5355 0.7296], Lowest was [0.2821 0.0682 0.2828 0.4782]
Median for last 10 epochs: [0.9182 0.1689 0.5355 0.9849], Epochs since improvement 22
Exited after 66 epochs due to early stopping
2650.16 seconds spent training, 5.300 seconds per epoch. Processed 13138 trees per second
[0.91158646 0.1645084  0.5354929  0.729529  ]
{'epoch_exit': 65, 'scatter_m_star': 0.91158646, 'lowest_m_star': 0.28207362, 'last20_m_star': 0.9197873, 'last10_m_star': 0.9181517, 'scatter_v_disk': 0.1645084, 'lowest_v_disk': 0.06821239, 'last20_v_disk': 0.16898644, 'last10_v_disk': 0.16894113, 'scatter_m_cold': 0.5354929, 'lowest_m_cold': 0.2828125, 'last20_m_cold': 0.5354912, 'last10_m_cold': 0.5355018, 'scatter_sfr_100': 0.729529, 'lowest_sfr_100': 0.47816396, 'last20_sfr_100': 0.9849455, 'last10_sfr_100': 0.98490703}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_nnxsxe
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:55:41, 28.34s/it]  0%|          | 2/500 [01:12<5:10:29, 37.41s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.45E+07, Train scatter: [0.9354 0.1789 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1875 0.5357 0.9851], Lowest was [0.9198 0.1875 0.5357 0.9851]
Median for last 10 epochs: [0.9198 0.1875 0.5357 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:39<4:31:10, 32.74s/it]  1%|          | 4/500 [02:24<5:11:36, 37.69s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.47E+07, Train scatter: [0.9353 0.1747 0.5442 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1779 0.5356 0.9851], Lowest was [0.9198 0.1779 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1779 0.5356 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:51<4:39:33, 33.89s/it]  1%|          | 6/500 [03:37<5:11:04, 37.78s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.07E+07, Train scatter: [0.9354 0.1653 0.5442 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.1677 0.5356 0.9851], Lowest was [0.9198 0.1677 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1677 0.5356 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:04<4:42:13, 34.35s/it]  2%|▏         | 8/500 [04:49<5:09:04, 37.69s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 9.69E+06, Train scatter: [0.9353 0.1463 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1444 0.5355 0.9847], Lowest was [0.9197 0.1444 0.5355 0.9847]
Median for last 10 epochs: [0.9198 0.156  0.5356 0.9849], Epochs since improvement 0
  2%|▏         | 9/500 [05:16<4:41:54, 34.45s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.01E+06, Train scatter: [0.9352 0.1372 0.544  0.7285]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1359 0.5355 0.7239], Lowest was [0.9196 0.1359 0.5355 0.7239]
Median for last 10 epochs: [0.9197 0.1444 0.5355 0.9847], Epochs since improvement 0
  2%|▏         | 10/500 [06:07<5:23:22, 39.60s/it]  2%|▏         | 11/500 [06:34<4:52:09, 35.85s/it]  2%|▏         | 12/500 [07:19<5:14:17, 38.64s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.84E+06, Train scatter: [0.9346 0.1243 0.544  0.6754]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9191 0.122  0.5355 0.6658], Lowest was [0.9191 0.122  0.5355 0.6658]
Median for last 10 epochs: [0.9197 0.1444 0.5355 0.9847], Epochs since improvement 0
  3%|▎         | 13/500 [07:47<4:46:02, 35.24s/it]  3%|▎         | 14/500 [08:32<5:08:31, 38.09s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.66E+06, Train scatter: [0.9163 0.1193 0.5439 0.6468]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9027 0.1174 0.5354 0.6399], Lowest was [0.9027 0.1174 0.5354 0.6399]
Median for last 10 epochs: [0.9196 0.1359 0.5355 0.7239], Epochs since improvement 0
  3%|▎         | 15/500 [08:59<4:41:42, 34.85s/it]  3%|▎         | 16/500 [09:44<5:05:01, 37.81s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.49E+06, Train scatter: [0.7922 0.1124 0.5426 0.6078]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7878 0.1104 0.5342 0.5982], Lowest was [0.7878 0.1104 0.5342 0.5982]
Median for last 10 epochs: [0.9191 0.122  0.5355 0.6658], Epochs since improvement 0
  3%|▎         | 17/500 [10:11<4:39:13, 34.69s/it]  4%|▎         | 18/500 [10:57<5:04:46, 37.94s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 6.25E+06, Train scatter: [0.5447 0.1047 0.5392 0.5846]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5444 0.1041 0.531  0.5804], Lowest was [0.5444 0.1041 0.531  0.5804]
Median for last 10 epochs: [0.9027 0.1174 0.5354 0.6399], Epochs since improvement 0
  4%|▍         | 19/500 [11:24<4:38:26, 34.73s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 6.03E+06, Train scatter: [0.4875 0.1014 0.536  0.5966]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4952 0.1011 0.5279 0.5928], Lowest was [0.4952 0.1011 0.5279 0.5804]
Median for last 10 epochs: [0.7878 0.1104 0.5342 0.5982], Epochs since improvement 0
  4%|▍         | 20/500 [12:14<5:13:57, 39.24s/it]  4%|▍         | 21/500 [12:41<4:44:50, 35.68s/it]  4%|▍         | 22/500 [13:26<5:07:09, 38.56s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.69E+06, Train scatter: [0.4808 0.0964 0.5325 0.6045]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4963 0.0977 0.5253 0.6073], Lowest was [0.4952 0.0977 0.5253 0.5804]
Median for last 10 epochs: [0.5444 0.1041 0.531  0.5982], Epochs since improvement 0
  5%|▍         | 23/500 [13:53<4:39:30, 35.16s/it]  5%|▍         | 24/500 [14:39<5:03:53, 38.31s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 5.40E+06, Train scatter: [0.4565 0.0954 0.5204 0.5677]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4676 0.0971 0.5124 0.5681], Lowest was [0.4676 0.0971 0.5124 0.5681]
Median for last 10 epochs: [0.4963 0.1011 0.5279 0.5928], Epochs since improvement 0
  5%|▌         | 25/500 [15:06<4:37:01, 34.99s/it]  5%|▌         | 26/500 [15:51<4:59:37, 37.93s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 5.14E+06, Train scatter: [0.5666 0.1172 0.49   0.7313]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5747 0.1173 0.4842 0.7191], Lowest was [0.4676 0.0971 0.4842 0.5681]
Median for last 10 epochs: [0.4963 0.1011 0.5253 0.5928], Epochs since improvement 0
  5%|▌         | 27/500 [16:18<4:33:38, 34.71s/it]  6%|▌         | 28/500 [17:04<4:59:40, 38.09s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.21E+06, Train scatter: [0.4986 0.1025 0.4309 0.64  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5002 0.1048 0.425  0.6265], Lowest was [0.4676 0.0971 0.425  0.5681]
Median for last 10 epochs: [0.4963 0.1011 0.5124 0.6073], Epochs since improvement 0
  6%|▌         | 29/500 [17:31<4:33:19, 34.82s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.86E+06, Train scatter: [0.4874 0.1006 0.3816 0.6266]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4927 0.1025 0.3834 0.6217], Lowest was [0.4676 0.0971 0.3834 0.5681]
Median for last 10 epochs: [0.4963 0.1025 0.4842 0.6217], Epochs since improvement 0
  6%|▌         | 30/500 [18:23<5:11:08, 39.72s/it]  6%|▌         | 31/500 [18:50<4:41:38, 36.03s/it]  6%|▋         | 32/500 [19:35<5:03:00, 38.85s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.48E+06, Train scatter: [0.5151 0.0962 0.3517 0.5925]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5211 0.0974 0.3519 0.5868], Lowest was [0.4676 0.0971 0.3519 0.5681]
Median for last 10 epochs: [0.5002 0.1025 0.425  0.6217], Epochs since improvement 0
  7%|▋         | 33/500 [20:03<4:35:16, 35.37s/it]  7%|▋         | 34/500 [20:48<4:58:36, 38.45s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.18E+06, Train scatter: [0.4065 0.097  0.3364 0.5671]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4196 0.0981 0.3374 0.5611], Lowest was [0.4196 0.0971 0.3374 0.5611]
Median for last 10 epochs: [0.5002 0.1025 0.3834 0.6217], Epochs since improvement 0
  7%|▋         | 35/500 [21:16<4:31:59, 35.10s/it]  7%|▋         | 36/500 [22:01<4:55:53, 38.26s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 1.93E+06, Train scatter: [0.3946 0.0907 0.3279 0.5469]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.394  0.0918 0.3322 0.5472], Lowest was [0.394  0.0918 0.3322 0.5472]
Median for last 10 epochs: [0.4927 0.0981 0.3519 0.5868], Epochs since improvement 0
  7%|▋         | 37/500 [22:29<4:29:47, 34.96s/it]  8%|▊         | 38/500 [23:15<4:54:54, 38.30s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.70E+06, Train scatter: [0.398  0.0892 0.3204 0.5414]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4131 0.0911 0.3296 0.546 ], Lowest was [0.394  0.0911 0.3296 0.546 ]
Median for last 10 epochs: [0.4196 0.0974 0.3374 0.5611], Epochs since improvement 0
  8%|▊         | 39/500 [23:42<4:28:52, 35.00s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.56E+06, Train scatter: [0.343  0.088  0.3121 0.5572]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.354  0.0897 0.3139 0.5567], Lowest was [0.354  0.0897 0.3139 0.546 ]
Median for last 10 epochs: [0.4131 0.0918 0.3322 0.5567], Epochs since improvement 0
  8%|▊         | 40/500 [24:33<5:05:45, 39.88s/it]  8%|▊         | 41/500 [25:01<4:36:14, 36.11s/it]  8%|▊         | 42/500 [25:47<4:59:39, 39.26s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.52E+06, Train scatter: [0.311  0.0883 0.3482 0.5341]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3211 0.0901 0.354  0.5309], Lowest was [0.3211 0.0897 0.3139 0.5309]
Median for last 10 epochs: [0.394  0.0911 0.3322 0.5472], Epochs since improvement 0
  9%|▊         | 43/500 [26:14<4:31:20, 35.62s/it]  9%|▉         | 44/500 [27:00<4:54:50, 38.80s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.51E+06, Train scatter: [0.3371 0.085  0.3291 0.5267]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3537 0.0881 0.3372 0.5333], Lowest was [0.3211 0.0881 0.3139 0.5309]
Median for last 10 epochs: [0.354  0.0901 0.3322 0.546 ], Epochs since improvement 0
  9%|▉         | 45/500 [27:28<4:27:35, 35.29s/it]  9%|▉         | 46/500 [28:14<4:52:42, 38.68s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.52E+06, Train scatter: [0.306  0.0851 0.3224 0.551 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3146 0.0873 0.3232 0.5523], Lowest was [0.3146 0.0873 0.3139 0.5309]
Median for last 10 epochs: [0.3537 0.0897 0.3296 0.546 ], Epochs since improvement 0
  9%|▉         | 47/500 [28:41<4:26:00, 35.23s/it] 10%|▉         | 48/500 [29:27<4:49:05, 38.37s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.47E+06, Train scatter: [0.3389 0.0851 0.3286 0.5355]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3418 0.0881 0.3346 0.5403], Lowest was [0.3146 0.0873 0.3139 0.5309]
Median for last 10 epochs: [0.3418 0.0881 0.3346 0.5403], Epochs since improvement 2
 10%|▉         | 49/500 [29:54<4:23:23, 35.04s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.39E+06, Train scatter: [0.477  0.0886 0.3251 0.5482]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4752 0.0936 0.3416 0.5496], Lowest was [0.3146 0.0873 0.3139 0.5309]
Median for last 10 epochs: [0.3418 0.0881 0.3372 0.5403], Epochs since improvement 4
 10%|█         | 50/500 [30:45<4:58:42, 39.83s/it] 10%|█         | 51/500 [31:13<4:29:48, 36.05s/it] 10%|█         | 52/500 [31:59<4:51:37, 39.06s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.38E+06, Train scatter: [0.2953 0.0806 0.2917 0.5097]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2981 0.083  0.297  0.5102], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.3418 0.0881 0.3346 0.5403], Epochs since improvement 0
 11%|█         | 53/500 [32:26<4:24:26, 35.50s/it] 11%|█         | 54/500 [33:11<4:46:32, 38.55s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 4.94E+06, Train scatter: [0.5465 0.1573 0.5437 0.8599]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5526 0.1543 0.5351 0.8584], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.3418 0.0881 0.3346 0.5496], Epochs since improvement 2
 11%|█         | 55/500 [33:39<4:20:38, 35.14s/it] 11%|█         | 56/500 [34:25<4:44:07, 38.40s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 5.78E+06, Train scatter: [0.9098 0.1719 0.5098 0.9866]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8953 0.1701 0.5055 0.9756], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.4752 0.0936 0.3416 0.5496], Epochs since improvement 4
 11%|█▏        | 57/500 [34:52<4:19:04, 35.09s/it] 12%|█▏        | 58/500 [35:40<4:46:08, 38.84s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 4.11E+06, Train scatter: [0.8791 0.1597 0.5115 0.9639]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8656 0.1581 0.5039 0.9545], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.5526 0.1543 0.5039 0.8584], Epochs since improvement 6
 12%|█▏        | 59/500 [36:07<4:19:38, 35.33s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.56E+06, Train scatter: [0.7545 0.1509 0.4942 0.8084]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7747 0.1486 0.4857 0.8039], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.7747 0.1543 0.5039 0.8584], Epochs since improvement 8
 12%|█▏        | 60/500 [36:58<4:53:47, 40.06s/it] 12%|█▏        | 61/500 [37:25<4:25:00, 36.22s/it] 12%|█▏        | 62/500 [38:11<4:45:26, 39.10s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.29E+06, Train scatter: [0.7002 0.1446 0.494  0.7648]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8102 0.1425 0.4877 0.759 ], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.8102 0.1543 0.5039 0.8584], Epochs since improvement 10
 13%|█▎        | 63/500 [38:38<4:18:50, 35.54s/it] 13%|█▎        | 64/500 [39:24<4:40:43, 38.63s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.17E+06, Train scatter: [0.6957 0.1383 0.4929 0.7531]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7676 0.137  0.4858 0.7431], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.8102 0.1486 0.4877 0.8039], Epochs since improvement 12
 13%|█▎        | 65/500 [39:51<4:15:33, 35.25s/it] 13%|█▎        | 66/500 [40:37<4:38:25, 38.49s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.92E+06, Train scatter: [0.6863 0.1396 0.5404 0.9172]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7737 0.138  0.5319 0.9079], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.7747 0.1425 0.4877 0.8039], Epochs since improvement 14
 13%|█▎        | 67/500 [41:05<4:13:21, 35.11s/it] 14%|█▎        | 68/500 [41:51<4:37:15, 38.51s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.25E+06, Train scatter: [0.6786 0.1195 0.5391 0.764 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7262 0.1177 0.5306 0.7504], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.7737 0.138  0.4877 0.759 ], Epochs since improvement 16
 14%|█▍        | 69/500 [42:18<4:12:16, 35.12s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.42E+06, Train scatter: [0.5985 0.1067 0.4474 0.681 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5859 0.1061 0.4397 0.6686], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.7676 0.137  0.4877 0.7504], Epochs since improvement 18
 14%|█▍        | 70/500 [43:10<4:46:30, 39.98s/it] 14%|█▍        | 71/500 [43:37<4:18:22, 36.14s/it] 14%|█▍        | 72/500 [44:23<4:39:42, 39.21s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.72E+06, Train scatter: [0.5868 0.0998 0.4161 0.6427]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5699 0.1004 0.4131 0.6318], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.7262 0.1177 0.4858 0.7431], Epochs since improvement 20
 15%|█▍        | 73/500 [44:50<4:13:25, 35.61s/it] 15%|█▍        | 73/500 [45:36<4:26:47, 37.49s/it]
Epoch: 74 done with learning rate 1.00E-02, Train loss: 1.44E+06, Train scatter: [0.5793 0.0954 0.3972 0.6244]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5618 0.0969 0.3987 0.6208], Lowest was [0.2981 0.083  0.297  0.5102]
Median for last 10 epochs: [0.5859 0.1061 0.4397 0.6686], Epochs since improvement 22
Exited after 74 epochs due to early stopping
2736.57 seconds spent training, 5.473 seconds per epoch. Processed 12723 trees per second
[0.5617675  0.09685006 0.39864358 0.6207674 ]
{'epoch_exit': 73, 'scatter_m_star': 0.5617675, 'lowest_m_star': 0.2980535, 'last20_m_star': 0.77064407, 'last10_m_star': 0.5859278, 'scatter_v_disk': 0.09685006, 'lowest_v_disk': 0.08299806, 'last20_v_disk': 0.13752353, 'last10_v_disk': 0.106106944, 'scatter_m_cold': 0.39864358, 'lowest_m_cold': 0.2969623, 'last20_m_cold': 0.48674428, 'last10_m_cold': 0.43965384, 'scatter_sfr_100': 0.6207674, 'lowest_sfr_100': 0.51015717, 'last20_sfr_100': 0.7547023, 'last10_sfr_100': 0.66860974}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_szeanm
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:47<6:33:55, 47.36s/it]  0%|          | 2/500 [01:57<8:26:04, 60.97s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.47E+07, Train scatter: [0.9352 0.1518 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1479 0.5356 0.9851], Lowest was [0.9196 0.1479 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1479 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:44<7:31:12, 54.47s/it]  1%|          | 4/500 [03:56<8:25:55, 61.20s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.65E+07, Train scatter: [0.9342 0.1059 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9186 0.1037 0.5355 0.9847], Lowest was [0.9186 0.1037 0.5355 0.9847]
Median for last 10 epochs: [0.9186 0.1037 0.5355 0.9847], Epochs since improvement 0
  1%|          | 5/500 [04:42<7:41:43, 55.97s/it]  1%|          | 6/500 [05:53<8:23:09, 61.11s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.10E+07, Train scatter: [0.7754 0.0944 0.5441 0.6262]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7643 0.0943 0.5355 0.6186], Lowest was [0.7643 0.0943 0.5355 0.6186]
Median for last 10 epochs: [0.7643 0.0943 0.5355 0.6186], Epochs since improvement 0
  1%|▏         | 7/500 [06:40<7:44:19, 56.51s/it]  2%|▏         | 8/500 [07:52<8:22:11, 61.24s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.25E+06, Train scatter: [0.6492 0.089  0.5441 0.5779]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6411 0.0895 0.5355 0.5706], Lowest was [0.6411 0.0895 0.5355 0.5706]
Median for last 10 epochs: [0.7027 0.0919 0.5355 0.5946], Epochs since improvement 0
  2%|▏         | 9/500 [08:38<7:43:34, 56.65s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 5.69E+06, Train scatter: [0.3908 0.0844 0.544  0.5568]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3911 0.0844 0.5354 0.5506], Lowest was [0.3911 0.0844 0.5354 0.5506]
Median for last 10 epochs: [0.6411 0.0895 0.5355 0.5706], Epochs since improvement 0
  2%|▏         | 10/500 [09:56<8:34:51, 63.04s/it]  2%|▏         | 11/500 [10:43<7:53:50, 58.14s/it]  2%|▏         | 12/500 [11:54<8:24:25, 62.02s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 4.52E+06, Train scatter: [0.2848 0.0736 0.5441 0.5441]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2906 0.0735 0.5355 0.5409], Lowest was [0.2906 0.0735 0.5354 0.5409]
Median for last 10 epochs: [0.6411 0.0895 0.5355 0.5706], Epochs since improvement 0
  3%|▎         | 13/500 [12:41<7:46:54, 57.52s/it]  3%|▎         | 14/500 [13:53<8:20:43, 61.82s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 4.31E+06, Train scatter: [0.3009 0.0742 0.544  0.5313]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3037 0.0736 0.5355 0.5251], Lowest was [0.2906 0.0735 0.5354 0.5251]
Median for last 10 epochs: [0.3911 0.0844 0.5355 0.5506], Epochs since improvement 0
  3%|▎         | 15/500 [14:40<7:43:35, 57.35s/it]  3%|▎         | 16/500 [15:51<8:16:49, 61.59s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.08E+06, Train scatter: [0.2449 0.0718 0.5439 0.5143]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.247  0.072  0.5354 0.509 ], Lowest was [0.247  0.072  0.5354 0.509 ]
Median for last 10 epochs: [0.3037 0.0736 0.5355 0.5409], Epochs since improvement 0
  3%|▎         | 17/500 [16:38<7:40:21, 57.19s/it]  4%|▎         | 18/500 [17:50<8:14:58, 61.62s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.88E+06, Train scatter: [0.2335 0.0699 0.5439 0.5223]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2367 0.0695 0.5353 0.5119], Lowest was [0.2367 0.0695 0.5353 0.509 ]
Median for last 10 epochs: [0.2906 0.0735 0.5354 0.5251], Epochs since improvement 0
  4%|▍         | 19/500 [18:37<7:38:12, 57.16s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.82E+06, Train scatter: [0.296  0.0697 0.5438 0.5674]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3024 0.0698 0.5353 0.5707], Lowest was [0.2367 0.0695 0.5353 0.509 ]
Median for last 10 epochs: [0.2906 0.072  0.5354 0.5251], Epochs since improvement 0
  4%|▍         | 20/500 [19:55<8:27:39, 63.46s/it]  4%|▍         | 21/500 [20:41<7:46:01, 58.37s/it]  4%|▍         | 22/500 [21:53<8:17:29, 62.45s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.75E+06, Train scatter: [0.217  0.0692 0.5438 0.5228]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2221 0.0694 0.5352 0.5201], Lowest was [0.2221 0.0694 0.5352 0.509 ]
Median for last 10 epochs: [0.247  0.0698 0.5353 0.5201], Epochs since improvement 0
  5%|▍         | 23/500 [22:40<7:38:14, 57.64s/it]  5%|▍         | 24/500 [23:51<8:10:55, 61.88s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.71E+06, Train scatter: [0.2052 0.068  0.5438 0.5049]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2086 0.0683 0.5352 0.501 ], Lowest was [0.2086 0.0683 0.5352 0.501 ]
Median for last 10 epochs: [0.2367 0.0695 0.5353 0.5119], Epochs since improvement 0
  5%|▌         | 25/500 [24:38<7:33:49, 57.33s/it]  5%|▌         | 26/500 [25:49<8:04:12, 61.29s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.68E+06, Train scatter: [0.2146 0.0655 0.5437 0.502 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2194 0.0656 0.5352 0.498 ], Lowest was [0.2086 0.0656 0.5352 0.498 ]
Median for last 10 epochs: [0.2221 0.0694 0.5352 0.5119], Epochs since improvement 0
  5%|▌         | 27/500 [26:35<7:28:44, 56.92s/it]  6%|▌         | 28/500 [27:46<8:01:06, 61.16s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.65E+06, Train scatter: [0.2187 0.0687 0.5436 0.5098]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2233 0.0679 0.5351 0.5014], Lowest was [0.2086 0.0656 0.5351 0.498 ]
Median for last 10 epochs: [0.2221 0.0683 0.5352 0.5014], Epochs since improvement 0
  6%|▌         | 29/500 [28:33<7:26:10, 56.84s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.65E+06, Train scatter: [0.2157 0.0656 0.5436 0.4974]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2229 0.0655 0.535  0.4937], Lowest was [0.2086 0.0655 0.535  0.4937]
Median for last 10 epochs: [0.2221 0.0679 0.5352 0.501 ], Epochs since improvement 0
  6%|▌         | 30/500 [29:51<8:14:45, 63.16s/it]  6%|▌         | 31/500 [30:38<7:34:52, 58.19s/it]  6%|▋         | 32/500 [31:50<8:06:25, 62.36s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.65E+06, Train scatter: [0.2685 0.0769 0.5436 0.5268]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.27   0.0764 0.535  0.5193], Lowest was [0.2086 0.0655 0.535  0.4937]
Median for last 10 epochs: [0.2229 0.0679 0.5351 0.501 ], Epochs since improvement 2
  7%|▋         | 33/500 [32:37<7:28:55, 57.68s/it]  7%|▋         | 34/500 [33:47<7:58:31, 61.61s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.64E+06, Train scatter: [0.2136 0.0655 0.5435 0.5058]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2142 0.0659 0.5349 0.5001], Lowest was [0.2086 0.0655 0.5349 0.4937]
Median for last 10 epochs: [0.2229 0.0659 0.535  0.5001], Epochs since improvement 0
  7%|▋         | 35/500 [34:34<7:22:25, 57.09s/it]  7%|▋         | 36/500 [35:45<7:54:01, 61.30s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.64E+06, Train scatter: [0.218  0.0716 0.5435 0.5023]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.221  0.0716 0.5349 0.4924], Lowest was [0.2086 0.0655 0.5349 0.4924]
Median for last 10 epochs: [0.2229 0.0679 0.535  0.5001], Epochs since improvement 0
  7%|▋         | 37/500 [36:32<7:20:17, 57.06s/it]  8%|▊         | 38/500 [37:44<7:53:20, 61.47s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.27E+07, Train scatter: [0.5408 0.1046 0.5438 0.6655]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5256 0.1037 0.5352 0.6642], Lowest was [0.2086 0.0655 0.5349 0.4924]
Median for last 10 epochs: [0.2229 0.0716 0.535  0.5001], Epochs since improvement 2
  8%|▊         | 39/500 [38:30<7:17:46, 56.98s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 9.78E+06, Train scatter: [0.5236 0.0928 0.5435 0.6295]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5504 0.0925 0.5349 0.6275], Lowest was [0.2086 0.0655 0.5349 0.4924]
Median for last 10 epochs: [0.27   0.0764 0.5349 0.5193], Epochs since improvement 4
  8%|▊         | 40/500 [39:48<8:03:44, 63.10s/it]  8%|▊         | 41/500 [40:34<7:25:00, 58.17s/it]  8%|▊         | 42/500 [41:45<7:53:21, 62.01s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 9.36E+06, Train scatter: [0.492  0.0923 0.5435 0.6247]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4808 0.0921 0.5349 0.6239], Lowest was [0.2086 0.0655 0.5349 0.4924]
Median for last 10 epochs: [0.4808 0.0921 0.5349 0.6239], Epochs since improvement 6
  9%|▊         | 43/500 [42:32<7:17:19, 57.42s/it]  9%|▉         | 44/500 [43:43<7:47:40, 61.54s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 8.99E+06, Train scatter: [0.4537 0.0874 0.5435 0.6073]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4977 0.0869 0.5349 0.6038], Lowest was [0.2086 0.0655 0.5349 0.4924]
Median for last 10 epochs: [0.4977 0.0921 0.5349 0.6239], Epochs since improvement 8
  9%|▉         | 45/500 [44:30<7:12:40, 57.06s/it]  9%|▉         | 46/500 [45:41<7:44:41, 61.41s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 8.66E+06, Train scatter: [0.4721 0.089  0.5434 0.6092]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4632 0.0886 0.5349 0.606 ], Lowest was [0.2086 0.0655 0.5349 0.4924]
Median for last 10 epochs: [0.4977 0.0921 0.5349 0.6239], Epochs since improvement 0
  9%|▉         | 47/500 [46:28<7:10:13, 56.98s/it] 10%|▉         | 48/500 [47:39<7:40:41, 61.15s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 7.87E+06, Train scatter: [0.4612 0.0866 0.5427 0.587 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4531 0.0862 0.5343 0.5828], Lowest was [0.2086 0.0655 0.5343 0.4924]
Median for last 10 epochs: [0.4808 0.0886 0.5349 0.606 ], Epochs since improvement 0
 10%|▉         | 49/500 [48:26<7:06:58, 56.80s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 7.61E+06, Train scatter: [0.5758 0.0897 0.5418 0.5775]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.563  0.0898 0.5335 0.5765], Lowest was [0.2086 0.0655 0.5335 0.4924]
Median for last 10 epochs: [0.4808 0.0886 0.5349 0.6038], Epochs since improvement 0
 10%|█         | 50/500 [49:43<7:51:42, 62.89s/it] 10%|█         | 51/500 [50:29<7:14:17, 58.04s/it] 10%|█         | 52/500 [51:41<7:43:43, 62.11s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 7.48E+06, Train scatter: [0.4522 0.0816 0.5412 0.5824]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4429 0.0813 0.5329 0.5807], Lowest was [0.2086 0.0655 0.5329 0.4924]
Median for last 10 epochs: [0.4632 0.0869 0.5343 0.5828], Epochs since improvement 0
 11%|█         | 53/500 [52:28<7:08:10, 57.47s/it] 11%|█         | 54/500 [53:38<7:36:44, 61.44s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 7.36E+06, Train scatter: [0.4471 0.0754 0.5401 0.5676]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4402 0.0749 0.5319 0.566 ], Lowest was [0.2086 0.0655 0.5319 0.4924]
Median for last 10 epochs: [0.4531 0.0862 0.5335 0.5807], Epochs since improvement 0
 11%|█         | 55/500 [54:25<7:02:51, 57.01s/it] 11%|█         | 56/500 [55:36<7:32:01, 61.08s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 7.26E+06, Train scatter: [0.4559 0.0746 0.539  0.5702]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4413 0.0745 0.5309 0.568 ], Lowest was [0.2086 0.0655 0.5309 0.4924]
Median for last 10 epochs: [0.4429 0.0813 0.5329 0.5765], Epochs since improvement 0
 11%|█▏        | 57/500 [56:23<6:59:43, 56.85s/it] 12%|█▏        | 58/500 [57:33<7:29:16, 60.99s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 7.14E+06, Train scatter: [0.4397 0.0759 0.5382 0.5797]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4258 0.0753 0.5303 0.5781], Lowest was [0.2086 0.0655 0.5303 0.4924]
Median for last 10 epochs: [0.4413 0.0753 0.5319 0.5765], Epochs since improvement 0
 12%|█▏        | 59/500 [58:20<6:56:50, 56.71s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 7.02E+06, Train scatter: [0.4222 0.0754 0.5355 0.5627]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4175 0.0761 0.5274 0.5623], Lowest was [0.2086 0.0655 0.5274 0.4924]
Median for last 10 epochs: [0.4402 0.0753 0.5309 0.568 ], Epochs since improvement 0
 12%|█▏        | 60/500 [59:38<7:42:20, 63.05s/it] 12%|█▏        | 61/500 [1:00:25<7:05:38, 58.18s/it] 12%|█▏        | 62/500 [1:01:36<7:32:35, 62.00s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 6.85E+06, Train scatter: [0.3922 0.0798 0.5338 0.5599]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3851 0.0803 0.5258 0.5567], Lowest was [0.2086 0.0655 0.5258 0.4924]
Median for last 10 epochs: [0.4258 0.0753 0.5303 0.566 ], Epochs since improvement 0
 13%|█▎        | 63/500 [1:02:23<6:59:26, 57.59s/it] 13%|█▎        | 64/500 [1:03:33<7:25:05, 61.25s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 6.79E+06, Train scatter: [0.4382 0.0738 0.5332 0.5592]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4229 0.0728 0.5254 0.5547], Lowest was [0.2086 0.0655 0.5254 0.4924]
Median for last 10 epochs: [0.4229 0.0753 0.5274 0.5623], Epochs since improvement 0
 13%|█▎        | 65/500 [1:04:20<6:53:01, 56.97s/it] 13%|█▎        | 66/500 [1:05:31<7:22:35, 61.19s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 6.66E+06, Train scatter: [0.3033 0.075  0.4592 0.5591]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3148 0.0743 0.4576 0.5549], Lowest was [0.2086 0.0655 0.4576 0.4924]
Median for last 10 epochs: [0.4175 0.0753 0.5258 0.5567], Epochs since improvement 0
 13%|█▎        | 67/500 [1:06:18<6:50:50, 56.93s/it] 14%|█▎        | 68/500 [1:07:28<7:18:25, 60.89s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 5.87E+06, Train scatter: [0.2715 0.0731 0.4627 0.5666]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2775 0.0728 0.4584 0.563 ], Lowest was [0.2086 0.0655 0.4576 0.4924]
Median for last 10 epochs: [0.3851 0.0743 0.5254 0.5567], Epochs since improvement 2
 14%|█▍        | 69/500 [1:08:15<6:47:05, 56.67s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 5.64E+06, Train scatter: [0.2781 0.079  0.4455 0.5582]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2881 0.0784 0.4384 0.5551], Lowest was [0.2086 0.0655 0.4384 0.4924]
Median for last 10 epochs: [0.3148 0.0743 0.4584 0.5551], Epochs since improvement 0
 14%|█▍        | 70/500 [1:09:32<7:29:36, 62.74s/it] 14%|█▍        | 71/500 [1:10:19<6:54:51, 58.02s/it] 14%|█▍        | 72/500 [1:11:29<7:20:06, 61.70s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 5.47E+06, Train scatter: [0.2801 0.071  0.463  0.5488]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2806 0.0708 0.4552 0.5447], Lowest was [0.2086 0.0655 0.4384 0.4924]
Median for last 10 epochs: [0.2881 0.0728 0.4576 0.5549], Epochs since improvement 2
 15%|█▍        | 73/500 [1:12:16<6:47:24, 57.25s/it] 15%|█▍        | 74/500 [1:13:27<7:16:21, 61.46s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 1.67E+07, Train scatter: [0.7466 0.1288 0.5431 0.9065]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7515 0.1292 0.5346 0.9002], Lowest was [0.2086 0.0655 0.4384 0.4924]
Median for last 10 epochs: [0.2881 0.0743 0.4576 0.5551], Epochs since improvement 4
 15%|█▌        | 75/500 [1:14:14<6:44:16, 57.07s/it] 15%|█▌        | 76/500 [1:15:25<7:13:24, 61.33s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 1.11E+07, Train scatter: [0.574  0.1155 0.5153 0.7558]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5698 0.1157 0.5067 0.7487], Lowest was [0.2086 0.0655 0.4384 0.4924]
Median for last 10 epochs: [0.2881 0.0784 0.4584 0.563 ], Epochs since improvement 6
 15%|█▌        | 77/500 [1:16:12<6:41:27, 56.94s/it] 16%|█▌        | 78/500 [1:17:22<7:07:49, 60.83s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 9.68E+06, Train scatter: [0.5321 0.111  0.484  0.7376]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5319 0.1113 0.4819 0.7312], Lowest was [0.2086 0.0655 0.4384 0.4924]
Median for last 10 epochs: [0.5319 0.1113 0.4819 0.7312], Epochs since improvement 8
 16%|█▌        | 79/500 [1:18:09<6:37:20, 56.63s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 9.00E+06, Train scatter: [0.498  0.1201 0.4634 0.7168]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4933 0.118  0.4601 0.7094], Lowest was [0.2086 0.0655 0.4384 0.4924]
Median for last 10 epochs: [0.5319 0.1157 0.4819 0.7312], Epochs since improvement 10
 16%|█▌        | 80/500 [1:19:26<7:19:12, 62.75s/it] 16%|█▌        | 81/500 [1:20:12<6:44:49, 57.97s/it] 16%|█▋        | 82/500 [1:21:23<7:10:19, 61.77s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 8.45E+06, Train scatter: [0.5004 0.11   0.4556 0.7047]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4944 0.1111 0.4508 0.6964], Lowest was [0.2086 0.0655 0.4384 0.4924]
Median for last 10 epochs: [0.5319 0.1157 0.4819 0.7312], Epochs since improvement 12
 17%|█▋        | 83/500 [1:22:10<6:37:31, 57.20s/it] 17%|█▋        | 84/500 [1:23:20<7:03:23, 61.07s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 8.02E+06, Train scatter: [0.4576 0.096  0.442  0.6851]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4564 0.0969 0.4404 0.6794], Lowest was [0.2086 0.0655 0.4384 0.4924]
Median for last 10 epochs: [0.4944 0.1113 0.4601 0.7094], Epochs since improvement 14
 17%|█▋        | 85/500 [1:24:06<6:32:37, 56.77s/it] 17%|█▋        | 86/500 [1:25:16<6:59:14, 60.76s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 7.53E+06, Train scatter: [0.4561 0.0928 0.4297 0.6726]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.457  0.0918 0.4289 0.6658], Lowest was [0.2086 0.0655 0.4289 0.4924]
Median for last 10 epochs: [0.4933 0.1111 0.4508 0.6964], Epochs since improvement 0
 17%|█▋        | 87/500 [1:26:03<6:28:54, 56.50s/it] 18%|█▊        | 88/500 [1:27:14<6:57:35, 60.81s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 6.91E+06, Train scatter: [0.4236 0.0865 0.4129 0.6455]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4266 0.0869 0.4122 0.6391], Lowest was [0.2086 0.0655 0.4122 0.4924]
Median for last 10 epochs: [0.457  0.0969 0.4404 0.6794], Epochs since improvement 0
 18%|█▊        | 89/500 [1:28:01<6:27:25, 56.56s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 6.57E+06, Train scatter: [0.3268 0.0816 0.4015 0.625 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3218 0.0826 0.4031 0.6181], Lowest was [0.2086 0.0655 0.4031 0.4924]
Median for last 10 epochs: [0.4564 0.0918 0.4289 0.6658], Epochs since improvement 0
 18%|█▊        | 90/500 [1:29:19<7:10:53, 63.06s/it] 18%|█▊        | 91/500 [1:30:05<6:36:20, 58.14s/it] 18%|█▊        | 92/500 [1:31:16<7:00:34, 61.85s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 6.22E+06, Train scatter: [0.4028 0.0797 0.3949 0.6154]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4082 0.0802 0.3991 0.6111], Lowest was [0.2086 0.0655 0.3991 0.4924]
Median for last 10 epochs: [0.4266 0.0869 0.4122 0.6391], Epochs since improvement 0
 19%|█▊        | 93/500 [1:32:03<6:29:12, 57.38s/it] 19%|█▉        | 94/500 [1:33:15<6:58:11, 61.80s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 5.86E+06, Train scatter: [0.3628 0.0795 0.3999 0.6237]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3496 0.0787 0.3948 0.6116], Lowest was [0.2086 0.0655 0.3948 0.4924]
Median for last 10 epochs: [0.4082 0.0826 0.4031 0.6181], Epochs since improvement 0
 19%|█▉        | 95/500 [1:34:01<6:25:53, 57.17s/it] 19%|█▉        | 96/500 [1:35:13<6:53:32, 61.42s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 5.45E+06, Train scatter: [0.3299 0.0744 0.378  0.6026]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3403 0.076  0.3853 0.6045], Lowest was [0.2086 0.0655 0.3853 0.4924]
Median for last 10 epochs: [0.3496 0.0802 0.3991 0.6116], Epochs since improvement 0
 19%|█▉        | 97/500 [1:35:59<6:22:25, 56.94s/it] 20%|█▉        | 98/500 [1:37:11<6:51:11, 61.37s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 5.06E+06, Train scatter: [0.3725 0.0779 0.3801 0.593 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3732 0.0784 0.388  0.5932], Lowest was [0.2086 0.0655 0.3853 0.4924]
Median for last 10 epochs: [0.3496 0.0787 0.3948 0.6111], Epochs since improvement 2
 20%|█▉        | 99/500 [1:37:57<6:20:09, 56.88s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 4.85E+06, Train scatter: [0.2657 0.0741 0.3742 0.589 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2686 0.075  0.3801 0.589 ], Lowest was [0.2086 0.0655 0.3801 0.4924]
Median for last 10 epochs: [0.3496 0.0784 0.388  0.6045], Epochs since improvement 0
 20%|██        | 100/500 [1:39:15<7:00:11, 63.03s/it] 20%|██        | 101/500 [1:40:01<6:26:32, 58.13s/it] 20%|██        | 102/500 [1:41:12<6:51:21, 62.01s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 4.52E+06, Train scatter: [0.273  0.0702 0.3726 0.5826]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2742 0.0702 0.3755 0.5802], Lowest was [0.2086 0.0655 0.3755 0.4924]
Median for last 10 epochs: [0.3403 0.076  0.3853 0.5932], Epochs since improvement 0
 21%|██        | 103/500 [1:41:59<6:19:47, 57.40s/it] 21%|██        | 104/500 [1:43:10<6:44:48, 61.33s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 4.49E+06, Train scatter: [0.4007 0.0696 0.3638 0.5759]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3929 0.0699 0.3675 0.5719], Lowest was [0.2086 0.0655 0.3675 0.4924]
Median for last 10 epochs: [0.3403 0.075  0.3801 0.589 ], Epochs since improvement 0
 21%|██        | 105/500 [1:43:56<6:14:41, 56.92s/it] 21%|██        | 106/500 [1:45:07<6:41:56, 61.21s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 4.15E+06, Train scatter: [0.3231 0.083  0.3948 0.6212]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3155 0.0833 0.4024 0.6328], Lowest was [0.2086 0.0655 0.3675 0.4924]
Median for last 10 epochs: [0.3155 0.075  0.3801 0.589 ], Epochs since improvement 2
 21%|██▏       | 107/500 [1:45:54<6:12:24, 56.86s/it] 22%|██▏       | 108/500 [1:47:05<6:38:58, 61.07s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 4.10E+06, Train scatter: [0.4452 0.068  0.356  0.5691]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4256 0.0684 0.3608 0.5653], Lowest was [0.2086 0.0655 0.3608 0.4924]
Median for last 10 epochs: [0.3155 0.0702 0.3755 0.5802], Epochs since improvement 0
 22%|██▏       | 109/500 [1:47:52<6:09:33, 56.71s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 4.09E+06, Train scatter: [0.3518 0.0909 0.4357 0.6129]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3628 0.0911 0.4332 0.6113], Lowest was [0.2086 0.0655 0.3608 0.4924]
Median for last 10 epochs: [0.3628 0.0702 0.3755 0.5802], Epochs since improvement 2
 22%|██▏       | 110/500 [1:49:09<6:49:25, 62.99s/it] 22%|██▏       | 111/500 [1:49:56<6:16:36, 58.09s/it] 22%|██▏       | 112/500 [1:51:06<6:39:43, 61.81s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 3.92E+06, Train scatter: [0.2628 0.0693 0.3557 0.558 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2615 0.0698 0.3581 0.5525], Lowest was [0.2086 0.0655 0.3581 0.4924]
Median for last 10 epochs: [0.3628 0.0699 0.3675 0.5719], Epochs since improvement 0
 23%|██▎       | 113/500 [1:51:53<6:08:58, 57.20s/it] 23%|██▎       | 114/500 [1:53:04<6:35:03, 61.41s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 3.80E+06, Train scatter: [0.2541 0.068  0.3513 0.552 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2535 0.0691 0.3551 0.5479], Lowest was [0.2086 0.0655 0.3551 0.4924]
Median for last 10 epochs: [0.3155 0.0698 0.3608 0.5653], Epochs since improvement 0
 23%|██▎       | 115/500 [1:53:51<6:05:28, 56.96s/it] 23%|██▎       | 116/500 [1:55:02<6:31:33, 61.18s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 3.62E+06, Train scatter: [0.2462 0.0651 0.3512 0.5433]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2439 0.0661 0.3571 0.5396], Lowest was [0.2086 0.0655 0.3551 0.4924]
Median for last 10 epochs: [0.2615 0.0691 0.3581 0.5525], Epochs since improvement 2
 23%|██▎       | 117/500 [1:55:48<6:02:25, 56.78s/it] 24%|██▎       | 118/500 [1:56:59<6:27:57, 60.93s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 3.47E+06, Train scatter: [0.2725 0.0699 0.3596 0.5467]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2783 0.0722 0.3679 0.5449], Lowest was [0.2086 0.0655 0.3551 0.4924]
Median for last 10 epochs: [0.2615 0.0698 0.3581 0.5479], Epochs since improvement 4
 24%|██▍       | 119/500 [1:57:45<5:59:37, 56.63s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 3.40E+06, Train scatter: [0.2798 0.072  0.3593 0.5601]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2911 0.0757 0.3656 0.5616], Lowest was [0.2086 0.0655 0.3551 0.4924]
Median for last 10 epochs: [0.2615 0.0698 0.3581 0.5479], Epochs since improvement 6
 24%|██▍       | 120/500 [1:59:02<6:37:11, 62.71s/it] 24%|██▍       | 121/500 [1:59:49<6:05:19, 57.83s/it] 24%|██▍       | 122/500 [2:01:00<6:29:06, 61.76s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 3.06E+06, Train scatter: [0.2769 0.0666 0.3492 0.529 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2664 0.0671 0.3551 0.5283], Lowest was [0.2086 0.0655 0.3551 0.4924]
Median for last 10 epochs: [0.2664 0.0691 0.3571 0.5449], Epochs since improvement 0
 25%|██▍       | 123/500 [2:01:46<5:59:23, 57.20s/it] 25%|██▍       | 124/500 [2:02:57<6:23:52, 61.26s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 2.87E+06, Train scatter: [0.2692 0.0799 0.3746 0.5571]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2717 0.082  0.3825 0.5598], Lowest was [0.2086 0.0655 0.3551 0.4924]
Median for last 10 epochs: [0.2717 0.0722 0.3656 0.5449], Epochs since improvement 2
 25%|██▌       | 125/500 [2:03:43<5:55:19, 56.85s/it] 25%|██▌       | 126/500 [2:04:54<6:19:36, 60.90s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 2.61E+06, Train scatter: [0.2337 0.0645 0.3457 0.5194]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2287 0.0647 0.3501 0.5138], Lowest was [0.2086 0.0647 0.3501 0.4924]
Median for last 10 epochs: [0.2717 0.0722 0.3656 0.5449], Epochs since improvement 0
 25%|██▌       | 127/500 [2:05:40<5:51:44, 56.58s/it] 26%|██▌       | 128/500 [2:06:51<6:17:11, 60.84s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 2.43E+06, Train scatter: [0.2206 0.0629 0.3415 0.5145]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2182 0.0632 0.3438 0.5097], Lowest was [0.2086 0.0632 0.3438 0.4924]
Median for last 10 epochs: [0.2664 0.0671 0.3551 0.5283], Epochs since improvement 0
 26%|██▌       | 129/500 [2:07:38<5:50:03, 56.61s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 2.34E+06, Train scatter: [0.2882 0.0741 0.3592 0.5697]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2996 0.0759 0.3642 0.5685], Lowest was [0.2086 0.0632 0.3438 0.4924]
Median for last 10 epochs: [0.2664 0.0671 0.3551 0.5283], Epochs since improvement 2
 26%|██▌       | 130/500 [2:08:55<6:26:56, 62.75s/it] 26%|██▌       | 131/500 [2:09:41<5:56:01, 57.89s/it] 26%|██▋       | 132/500 [2:10:53<6:20:27, 62.03s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 2.31E+06, Train scatter: [0.2179 0.0661 0.3518 0.5204]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2101 0.064  0.3508 0.5109], Lowest was [0.2086 0.0632 0.3438 0.4924]
Median for last 10 epochs: [0.2287 0.0647 0.3508 0.5138], Epochs since improvement 4
 27%|██▋       | 133/500 [2:11:40<5:51:29, 57.46s/it] 27%|██▋       | 134/500 [2:12:50<6:13:59, 61.31s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 2.27E+06, Train scatter: [0.2347 0.0669 0.3477 0.5094]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2295 0.0663 0.3506 0.5058], Lowest was [0.2086 0.0632 0.3438 0.4924]
Median for last 10 epochs: [0.2287 0.0647 0.3506 0.5109], Epochs since improvement 6
 27%|██▋       | 135/500 [2:13:37<5:46:32, 56.97s/it] 27%|██▋       | 136/500 [2:14:48<6:10:21, 61.05s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 2.20E+06, Train scatter: [0.2691 0.0668 0.3577 0.5269]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2786 0.0675 0.359  0.5222], Lowest was [0.2086 0.0632 0.3438 0.4924]
Median for last 10 epochs: [0.2295 0.0663 0.3508 0.5109], Epochs since improvement 8
 27%|██▋       | 137/500 [2:15:35<5:43:43, 56.81s/it] 28%|██▊       | 138/500 [2:16:45<6:07:42, 60.94s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: 2.17E+06, Train scatter: [0.2405 0.0741 0.3615 0.5695]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2431 0.0751 0.3633 0.566 ], Lowest was [0.2086 0.0632 0.3438 0.4924]
Median for last 10 epochs: [0.2431 0.0675 0.359  0.5222], Epochs since improvement 10
 28%|██▊       | 139/500 [2:17:32<5:41:25, 56.75s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: 2.11E+06, Train scatter: [0.2532 0.0675 0.3463 0.5055]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2501 0.0663 0.3454 0.4975], Lowest was [0.2086 0.0632 0.3438 0.4924]
Median for last 10 epochs: [0.2431 0.0663 0.3508 0.5109], Epochs since improvement 12
 28%|██▊       | 140/500 [2:18:49<6:16:30, 62.75s/it] 28%|██▊       | 141/500 [2:19:36<5:46:57, 57.99s/it] 28%|██▊       | 142/500 [2:20:46<6:08:35, 61.78s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: 2.08E+06, Train scatter: [0.2147 0.0675 0.3544 0.5076]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2116 0.0659 0.3517 0.4997], Lowest was [0.2086 0.0632 0.3438 0.4924]
Median for last 10 epochs: [0.2431 0.0663 0.3517 0.5058], Epochs since improvement 14
 29%|██▊       | 143/500 [2:21:33<5:41:09, 57.34s/it] 29%|██▉       | 144/500 [2:22:45<6:04:52, 61.49s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 2.08E+06, Train scatter: [0.2483 0.0623 0.3443 0.4977]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2481 0.0619 0.3461 0.4931], Lowest was [0.2086 0.0619 0.3438 0.4924]
Median for last 10 epochs: [0.2481 0.0663 0.3517 0.4997], Epochs since improvement 0
 29%|██▉       | 145/500 [2:23:31<5:37:50, 57.10s/it] 29%|██▉       | 146/500 [2:24:42<6:00:10, 61.05s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 2.03E+06, Train scatter: [0.2722 0.0615 0.3374 0.4949]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2636 0.0609 0.3376 0.4892], Lowest was [0.2086 0.0609 0.3376 0.4892]
Median for last 10 epochs: [0.2481 0.0659 0.3461 0.4975], Epochs since improvement 0
 29%|██▉       | 147/500 [2:25:29<5:34:20, 56.83s/it] 30%|██▉       | 148/500 [2:26:38<5:56:15, 60.73s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 2.46E+06, Train scatter: [0.2468 0.0601 0.3464 0.4954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2409 0.0599 0.3469 0.4905], Lowest was [0.2086 0.0599 0.3376 0.4892]
Median for last 10 epochs: [0.2481 0.0619 0.3461 0.4931], Epochs since improvement 0
 30%|██▉       | 149/500 [2:27:26<5:31:22, 56.65s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 1.96E+06, Train scatter: [0.34   0.0621 0.3566 0.4966]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.336  0.0625 0.357  0.494 ], Lowest was [0.2086 0.0599 0.3376 0.4892]
Median for last 10 epochs: [0.2481 0.0619 0.3469 0.4931], Epochs since improvement 2
 30%|███       | 150/500 [2:28:42<6:05:37, 62.68s/it] 30%|███       | 151/500 [2:29:29<5:37:13, 57.98s/it] 30%|███       | 152/500 [2:30:40<5:58:56, 61.89s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 1.93E+06, Train scatter: [0.2138 0.061  0.343  0.4833]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2134 0.0609 0.3431 0.4806], Lowest was [0.2086 0.0599 0.3376 0.4806]
Median for last 10 epochs: [0.2481 0.0609 0.3461 0.4905], Epochs since improvement 0
 31%|███       | 153/500 [2:31:27<5:32:15, 57.45s/it] 31%|███       | 154/500 [2:32:38<5:53:59, 61.39s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 1.89E+06, Train scatter: [0.2266 0.0591 0.3313 0.4781]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2229 0.0594 0.3326 0.4745], Lowest was [0.2086 0.0594 0.3326 0.4745]
Median for last 10 epochs: [0.2409 0.0609 0.3431 0.4892], Epochs since improvement 0
 31%|███       | 155/500 [2:33:25<5:28:07, 57.07s/it] 31%|███       | 156/500 [2:34:36<5:50:20, 61.11s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 1.83E+06, Train scatter: [0.2177 0.059  0.3303 0.4833]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2197 0.06   0.3327 0.4839], Lowest was [0.2086 0.0594 0.3326 0.4745]
Median for last 10 epochs: [0.2229 0.06   0.3431 0.4839], Epochs since improvement 2
 31%|███▏      | 157/500 [2:35:23<5:25:09, 56.88s/it] 32%|███▏      | 158/500 [2:36:33<5:47:04, 60.89s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 1.82E+06, Train scatter: [0.2076 0.0615 0.3407 0.4788]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.208  0.0625 0.3448 0.4776], Lowest was [0.208  0.0594 0.3326 0.4745]
Median for last 10 epochs: [0.2197 0.0609 0.3431 0.4806], Epochs since improvement 0
 32%|███▏      | 159/500 [2:37:20<5:21:57, 56.65s/it]Epoch: 160 done with learning rate 9.05E-03, Train loss: 1.76E+06, Train scatter: [0.21   0.059  0.3325 0.4742]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2051 0.0598 0.3359 0.4702], Lowest was [0.2051 0.0594 0.3326 0.4702]
Median for last 10 epochs: [0.2134 0.06   0.3359 0.4776], Epochs since improvement 0
 32%|███▏      | 160/500 [2:38:38<5:57:42, 63.13s/it] 32%|███▏      | 161/500 [2:39:25<5:29:13, 58.27s/it] 32%|███▏      | 162/500 [2:40:35<5:49:05, 61.97s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: 1.73E+06, Train scatter: [0.2138 0.0586 0.3336 0.4723]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2147 0.0589 0.3347 0.4673], Lowest was [0.2051 0.0589 0.3326 0.4673]
Median for last 10 epochs: [0.2147 0.0598 0.3347 0.4745], Epochs since improvement 0
 33%|███▎      | 163/500 [2:41:22<5:22:56, 57.50s/it] 33%|███▎      | 164/500 [2:42:34<5:45:06, 61.63s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: 1.72E+06, Train scatter: [0.2585 0.0645 0.3247 0.4683]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2376 0.0646 0.326  0.4647], Lowest was [0.2051 0.0589 0.326  0.4647]
Median for last 10 epochs: [0.2147 0.06   0.3347 0.4702], Epochs since improvement 0
 33%|███▎      | 165/500 [2:43:20<5:19:13, 57.17s/it] 33%|███▎      | 166/500 [2:44:32<5:42:16, 61.49s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: 1.74E+06, Train scatter: [0.2205 0.0617 0.339  0.4876]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2183 0.0607 0.3391 0.4831], Lowest was [0.2051 0.0589 0.326  0.4647]
Median for last 10 epochs: [0.2147 0.0607 0.3359 0.4702], Epochs since improvement 2
 33%|███▎      | 167/500 [2:45:19<5:16:39, 57.06s/it] 34%|███▎      | 168/500 [2:46:31<5:40:31, 61.54s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: 1.72E+06, Train scatter: [0.2563 0.0563 0.3149 0.4662]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2488 0.0566 0.3213 0.465 ], Lowest was [0.2051 0.0566 0.3213 0.4647]
Median for last 10 epochs: [0.2183 0.0598 0.3347 0.4673], Epochs since improvement 0
 34%|███▍      | 169/500 [2:47:18<5:15:02, 57.11s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: 1.66E+06, Train scatter: [0.2394 0.0585 0.3193 0.4624]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2349 0.0594 0.3253 0.4623], Lowest was [0.2051 0.0566 0.3213 0.4623]
Median for last 10 epochs: [0.2349 0.0594 0.326  0.465 ], Epochs since improvement 0
 34%|███▍      | 170/500 [2:48:36<5:49:26, 63.53s/it] 34%|███▍      | 171/500 [2:49:23<5:20:48, 58.51s/it] 34%|███▍      | 172/500 [2:50:34<5:40:36, 62.31s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: 1.61E+06, Train scatter: [0.229  0.0674 0.3287 0.4829]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.225  0.0675 0.3364 0.4803], Lowest was [0.2051 0.0566 0.3213 0.4623]
Median for last 10 epochs: [0.2349 0.0607 0.326  0.465 ], Epochs since improvement 2
 35%|███▍      | 173/500 [2:51:21<5:13:47, 57.58s/it] 35%|███▍      | 174/500 [2:52:32<5:36:11, 61.88s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: 1.55E+06, Train scatter: [0.2215 0.0569 0.3112 0.4528]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2178 0.0575 0.3171 0.4483], Lowest was [0.2051 0.0566 0.3171 0.4483]
Median for last 10 epochs: [0.225  0.0594 0.3253 0.465 ], Epochs since improvement 0
 35%|███▌      | 175/500 [2:53:19<5:10:14, 57.28s/it] 35%|███▌      | 176/500 [2:54:29<5:30:31, 61.21s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: 1.50E+06, Train scatter: [0.1997 0.0571 0.3211 0.4438]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2049 0.058  0.3254 0.4403], Lowest was [0.2049 0.0566 0.3171 0.4403]
Median for last 10 epochs: [0.225  0.058  0.3253 0.4623], Epochs since improvement 0
 35%|███▌      | 177/500 [2:55:16<5:05:46, 56.80s/it] 36%|███▌      | 178/500 [2:56:28<5:29:54, 61.47s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: 1.46E+06, Train scatter: [0.2031 0.0567 0.3033 0.4469]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2055 0.0572 0.3131 0.446 ], Lowest was [0.2049 0.0566 0.3131 0.4403]
Median for last 10 epochs: [0.2178 0.058  0.3253 0.4483], Epochs since improvement 0
 36%|███▌      | 179/500 [2:57:15<5:05:02, 57.02s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: 1.44E+06, Train scatter: [0.204  0.0535 0.2889 0.4365]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2013 0.0539 0.2965 0.4378], Lowest was [0.2013 0.0539 0.2965 0.4378]
Median for last 10 epochs: [0.2055 0.0575 0.3171 0.446 ], Epochs since improvement 0
 36%|███▌      | 180/500 [2:58:33<5:37:08, 63.21s/it] 36%|███▌      | 181/500 [2:59:19<5:09:37, 58.24s/it] 36%|███▋      | 182/500 [3:00:30<5:29:05, 62.09s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: 1.40E+06, Train scatter: [0.2086 0.0557 0.2861 0.4449]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2051 0.0553 0.2881 0.4448], Lowest was [0.2013 0.0539 0.2881 0.4378]
Median for last 10 epochs: [0.2051 0.0572 0.3131 0.4448], Epochs since improvement 0
 37%|███▋      | 183/500 [3:01:17<5:03:20, 57.41s/it] 37%|███▋      | 184/500 [3:02:28<5:24:27, 61.61s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: 1.62E+06, Train scatter: [0.3029 0.083  0.3238 0.4966]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3097 0.0833 0.3285 0.5033], Lowest was [0.2013 0.0539 0.2881 0.4378]
Median for last 10 epochs: [0.2051 0.0572 0.3131 0.4448], Epochs since improvement 2
 37%|███▋      | 185/500 [3:03:15<4:59:39, 57.08s/it] 37%|███▋      | 186/500 [3:04:25<5:20:04, 61.16s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: 1.39E+06, Train scatter: [0.2235 0.0558 0.2898 0.4363]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2171 0.0556 0.2909 0.4335], Lowest was [0.2013 0.0539 0.2881 0.4335]
Median for last 10 epochs: [0.2055 0.0556 0.2965 0.4448], Epochs since improvement 0
 37%|███▋      | 187/500 [3:05:12<4:56:13, 56.79s/it] 38%|███▊      | 188/500 [3:06:22<5:16:37, 60.89s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: 1.40E+06, Train scatter: [0.2095 0.0544 0.3052 0.4401]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2124 0.0539 0.3094 0.4356], Lowest was [0.2013 0.0539 0.2881 0.4335]
Median for last 10 epochs: [0.2124 0.0553 0.2965 0.4378], Epochs since improvement 0
 38%|███▊      | 189/500 [3:07:09<4:53:23, 56.60s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: 1.36E+06, Train scatter: [0.2    0.0536 0.3095 0.438 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2039 0.0529 0.3137 0.4376], Lowest was [0.2013 0.0529 0.2881 0.4335]
Median for last 10 epochs: [0.2124 0.0553 0.3094 0.4376], Epochs since improvement 0
 38%|███▊      | 190/500 [3:08:27<5:25:46, 63.05s/it] 38%|███▊      | 191/500 [3:09:14<4:59:08, 58.08s/it] 38%|███▊      | 192/500 [3:10:25<5:18:31, 62.05s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: 1.32E+06, Train scatter: [0.2007 0.0542 0.2725 0.4354]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.207  0.0542 0.2763 0.4395], Lowest was [0.2013 0.0529 0.2763 0.4335]
Median for last 10 epochs: [0.2124 0.0542 0.3094 0.4376], Epochs since improvement 0
 39%|███▊      | 193/500 [3:11:11<4:53:47, 57.42s/it] 39%|███▉      | 194/500 [3:12:22<5:13:02, 61.38s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: 1.33E+06, Train scatter: [0.2441 0.0651 0.3192 0.4537]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2525 0.0633 0.3135 0.4473], Lowest was [0.2013 0.0529 0.2763 0.4335]
Median for last 10 epochs: [0.2124 0.0542 0.3094 0.4376], Epochs since improvement 2
 39%|███▉      | 195/500 [3:13:09<4:49:32, 56.96s/it] 39%|███▉      | 196/500 [3:14:19<5:09:23, 61.06s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: 1.35E+06, Train scatter: [0.2248 0.0536 0.3223 0.4433]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2354 0.0534 0.3238 0.4468], Lowest was [0.2013 0.0529 0.2763 0.4335]
Median for last 10 epochs: [0.2124 0.0539 0.3135 0.4395], Epochs since improvement 4
 39%|███▉      | 197/500 [3:15:06<4:46:30, 56.73s/it] 40%|███▉      | 198/500 [3:16:17<5:07:27, 61.08s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: 1.29E+06, Train scatter: [0.222  0.0521 0.2737 0.4251]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2252 0.052  0.2762 0.4292], Lowest was [0.2013 0.052  0.2762 0.4292]
Median for last 10 epochs: [0.2252 0.0534 0.3135 0.4395], Epochs since improvement 0
 40%|███▉      | 199/500 [3:17:04<4:44:54, 56.79s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: 1.29E+06, Train scatter: [0.1872 0.0521 0.2642 0.4241]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1907 0.051  0.2683 0.4235], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.2252 0.0534 0.2763 0.4395], Epochs since improvement 0
 40%|████      | 200/500 [3:18:22<5:15:11, 63.04s/it] 40%|████      | 201/500 [3:19:08<4:49:51, 58.17s/it] 40%|████      | 202/500 [3:20:19<5:06:59, 61.81s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: 1.30E+06, Train scatter: [0.2133 0.0522 0.2739 0.4267]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.207  0.0516 0.2784 0.4274], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.2252 0.052  0.2784 0.4292], Epochs since improvement 2
 41%|████      | 203/500 [3:21:06<4:43:41, 57.31s/it] 41%|████      | 204/500 [3:22:16<5:02:51, 61.39s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: 5.37E+06, Train scatter: [0.9393 0.1106 0.5346 0.6564]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9236 0.1092 0.5265 0.6767], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.2252 0.052  0.2784 0.4292], Epochs since improvement 4
 41%|████      | 205/500 [3:23:03<4:40:23, 57.03s/it] 41%|████      | 206/500 [3:24:14<4:59:01, 61.03s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: 2.53E+06, Train scatter: [0.6212 0.0907 0.3995 0.5332]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6029 0.0898 0.3992 0.5307], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.2252 0.052  0.2784 0.4292], Epochs since improvement 6
 41%|████▏     | 207/500 [3:25:00<4:37:05, 56.74s/it] 42%|████▏     | 208/500 [3:26:10<4:55:18, 60.68s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: 2.21E+06, Train scatter: [0.5673 0.0792 0.3845 0.5079]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5845 0.0792 0.3861 0.5075], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.5845 0.0792 0.3861 0.5075], Epochs since improvement 8
 42%|████▏     | 209/500 [3:26:57<4:33:37, 56.42s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: 2.10E+06, Train scatter: [0.5107 0.0866 0.4    0.5054]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4956 0.0861 0.4003 0.5057], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.5845 0.0861 0.3992 0.5075], Epochs since improvement 10
 42%|████▏     | 210/500 [3:28:14<5:02:56, 62.68s/it] 42%|████▏     | 211/500 [3:29:01<4:38:43, 57.87s/it] 42%|████▏     | 212/500 [3:30:11<4:56:04, 61.68s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: 2.00E+06, Train scatter: [0.5419 0.0728 0.3625 0.4971]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5292 0.0726 0.3653 0.491 ], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.5845 0.0861 0.3992 0.5075], Epochs since improvement 12
 43%|████▎     | 213/500 [3:30:58<4:33:25, 57.16s/it] 43%|████▎     | 214/500 [3:32:09<4:52:02, 61.27s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: 1.92E+06, Train scatter: [0.455  0.0692 0.3618 0.4917]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4388 0.0692 0.3671 0.4934], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.5292 0.0792 0.3861 0.5057], Epochs since improvement 14
 43%|████▎     | 215/500 [3:32:56<4:30:25, 56.93s/it] 43%|████▎     | 216/500 [3:34:07<4:49:38, 61.19s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: 1.93E+06, Train scatter: [0.4759 0.0672 0.3578 0.4817]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4555 0.0679 0.3625 0.4849], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.4956 0.0726 0.3671 0.4934], Epochs since improvement 16
 43%|████▎     | 217/500 [3:34:54<4:28:23, 56.90s/it] 44%|████▎     | 218/500 [3:36:05<4:47:38, 61.20s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: 1.86E+06, Train scatter: [0.497  0.0692 0.3548 0.4772]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4862 0.0705 0.3591 0.4802], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.4862 0.0705 0.3653 0.491 ], Epochs since improvement 18
 44%|████▍     | 219/500 [3:36:52<4:26:36, 56.93s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: 1.74E+06, Train scatter: [0.4193 0.063  0.3505 0.4966]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4022 0.0642 0.3522 0.4993], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.4555 0.0692 0.3625 0.491 ], Epochs since improvement 20
 44%|████▍     | 220/500 [3:38:09<4:54:10, 63.04s/it] 44%|████▍     | 221/500 [3:38:56<4:30:32, 58.18s/it] 44%|████▍     | 221/500 [3:40:07<4:37:53, 59.76s/it]
Epoch: 222 done with learning rate 7.33E-03, Train loss: 1.71E+06, Train scatter: [0.4156 0.0591 0.3449 0.4826]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3967 0.0598 0.3481 0.4835], Lowest was [0.1907 0.051  0.2683 0.4235]
Median for last 10 epochs: [0.4388 0.0679 0.3591 0.4849], Epochs since improvement 22
Exited after 222 epochs due to early stopping
13207.10 seconds spent training, 26.414 seconds per epoch. Processed 2636 trees per second
[0.39668104 0.05980593 0.34813696 0.48349187]
{'epoch_exit': 221, 'scatter_m_star': 0.39668104, 'lowest_m_star': 0.19073771, 'last20_m_star': 0.49087894, 'last10_m_star': 0.438783, 'scatter_v_disk': 0.059805933, 'lowest_v_disk': 0.051028717, 'last20_v_disk': 0.071544945, 'last10_v_disk': 0.06792146, 'scatter_m_cold': 0.34813696, 'lowest_m_cold': 0.268264, 'last20_m_cold': 0.36621135, 'last10_m_cold': 0.35912356, 'scatter_sfr_100': 0.48349187, 'lowest_sfr_100': 0.423497, 'last20_sfr_100': 0.49633032, 'last10_sfr_100': 0.48493135}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_hhdekp
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:40<5:38:40, 40.72s/it]  0%|          | 2/500 [01:43<7:24:14, 53.52s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.08E+07, Train scatter: [0.9352 0.1715 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1684 0.5355 0.9851], Lowest was [0.9196 0.1684 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1684 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:23<6:33:19, 47.48s/it]  1%|          | 4/500 [03:25<7:21:13, 53.37s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.32E+07, Train scatter: [0.9352 0.1613 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1579 0.5355 0.9851], Lowest was [0.9196 0.1579 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1579 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:06<6:41:07, 48.62s/it]  1%|          | 6/500 [05:08<7:20:07, 53.46s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.86E+07, Train scatter: [0.9351 0.1342 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1313 0.5356 0.9851], Lowest was [0.9196 0.1313 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1313 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [05:49<6:43:52, 49.15s/it]  2%|▏         | 8/500 [06:52<7:18:50, 53.52s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.47E+07, Train scatter: [0.9332 0.1153 0.5441 0.981 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9176 0.1141 0.5355 0.9707], Lowest was [0.9176 0.1141 0.5355 0.9707]
Median for last 10 epochs: [0.9186 0.1227 0.5355 0.9779], Epochs since improvement 0
  2%|▏         | 9/500 [07:32<6:44:05, 49.38s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 1.14E+07, Train scatter: [0.7542 0.103  0.5441 0.6474]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7444 0.1042 0.5355 0.6442], Lowest was [0.7444 0.1042 0.5355 0.6442]
Median for last 10 epochs: [0.9176 0.1141 0.5355 0.9707], Epochs since improvement 0
  2%|▏         | 10/500 [08:41<7:31:54, 55.34s/it]  2%|▏         | 11/500 [09:21<6:53:35, 50.75s/it]  2%|▏         | 12/500 [10:24<7:22:33, 54.41s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.05E+06, Train scatter: [0.6098 0.0954 0.5441 0.6311]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6109 0.0955 0.5355 0.6265], Lowest was [0.6109 0.0955 0.5355 0.6265]
Median for last 10 epochs: [0.9176 0.1141 0.5355 0.9707], Epochs since improvement 0
  3%|▎         | 13/500 [11:04<6:46:53, 50.13s/it]  3%|▎         | 14/500 [12:07<7:18:44, 54.16s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.58E+06, Train scatter: [0.4183 0.0871 0.544  0.5819]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4273 0.0877 0.5355 0.5788], Lowest was [0.4273 0.0877 0.5355 0.5788]
Median for last 10 epochs: [0.7444 0.1042 0.5355 0.6442], Epochs since improvement 0
  3%|▎         | 15/500 [12:48<6:43:45, 49.95s/it]  3%|▎         | 16/500 [13:51<7:15:48, 54.03s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 5.71E+06, Train scatter: [0.3638 0.0828 0.544  0.5527]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3694 0.0837 0.5354 0.55  ], Lowest was [0.3694 0.0837 0.5354 0.55  ]
Median for last 10 epochs: [0.6109 0.0955 0.5355 0.6265], Epochs since improvement 0
  3%|▎         | 17/500 [14:31<6:41:37, 49.89s/it]  4%|▎         | 18/500 [15:35<7:14:30, 54.09s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 5.01E+06, Train scatter: [0.2758 0.0835 0.5439 0.5497]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2837 0.0837 0.5353 0.5483], Lowest was [0.2837 0.0837 0.5353 0.5483]
Median for last 10 epochs: [0.4273 0.0877 0.5355 0.5788], Epochs since improvement 0
  4%|▍         | 19/500 [16:15<6:39:51, 49.88s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 4.67E+06, Train scatter: [0.303  0.0807 0.5439 0.5436]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3084 0.0814 0.5353 0.5447], Lowest was [0.2837 0.0814 0.5353 0.5447]
Median for last 10 epochs: [0.3694 0.0837 0.5354 0.55  ], Epochs since improvement 0
  4%|▍         | 20/500 [17:25<7:26:20, 55.79s/it]  4%|▍         | 21/500 [18:05<6:48:02, 51.11s/it]  4%|▍         | 22/500 [19:08<7:14:53, 54.59s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.26E+06, Train scatter: [0.3643 0.0783 0.5439 0.5428]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3632 0.0788 0.5354 0.5443], Lowest was [0.2837 0.0788 0.5353 0.5443]
Median for last 10 epochs: [0.3632 0.0837 0.5354 0.5483], Epochs since improvement 0
  5%|▍         | 23/500 [19:48<6:39:28, 50.25s/it]  5%|▍         | 24/500 [20:52<7:11:04, 54.34s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.14E+06, Train scatter: [0.2718 0.0768 0.544  0.5159]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2763 0.0776 0.5354 0.5146], Lowest was [0.2763 0.0776 0.5353 0.5146]
Median for last 10 epochs: [0.3084 0.0814 0.5354 0.5447], Epochs since improvement 0
  5%|▌         | 25/500 [21:32<6:36:39, 50.10s/it]  5%|▌         | 26/500 [22:35<7:05:48, 53.90s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.07E+06, Train scatter: [0.2608 0.0778 0.5439 0.5168]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2638 0.0784 0.5354 0.5144], Lowest was [0.2638 0.0776 0.5353 0.5144]
Median for last 10 epochs: [0.2837 0.0788 0.5354 0.5443], Epochs since improvement 0
  5%|▌         | 27/500 [23:15<6:32:22, 49.77s/it]  6%|▌         | 28/500 [24:18<7:03:55, 53.89s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.07E+06, Train scatter: [0.2431 0.0763 0.5439 0.515 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2499 0.077  0.5353 0.5095], Lowest was [0.2499 0.077  0.5353 0.5095]
Median for last 10 epochs: [0.2763 0.0784 0.5354 0.5146], Epochs since improvement 0
  6%|▌         | 29/500 [24:59<6:30:36, 49.76s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.02E+06, Train scatter: [0.3329 0.0756 0.5438 0.5627]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3323 0.0764 0.5353 0.5649], Lowest was [0.2499 0.0764 0.5353 0.5095]
Median for last 10 epochs: [0.2763 0.0776 0.5354 0.5146], Epochs since improvement 0
  6%|▌         | 30/500 [26:07<7:14:45, 55.50s/it]  6%|▌         | 31/500 [26:48<6:37:50, 50.90s/it]  6%|▋         | 32/500 [27:51<7:05:15, 54.52s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.99E+06, Train scatter: [0.2425 0.0739 0.5438 0.5108]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2499 0.0746 0.5352 0.5105], Lowest was [0.2499 0.0746 0.5352 0.5095]
Median for last 10 epochs: [0.2638 0.077  0.5353 0.5144], Epochs since improvement 0
  7%|▋         | 33/500 [28:31<6:30:51, 50.22s/it]  7%|▋         | 34/500 [29:34<6:59:46, 54.05s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.94E+06, Train scatter: [0.2157 0.072  0.5438 0.4993]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2251 0.0731 0.5352 0.4978], Lowest was [0.2251 0.0731 0.5352 0.4978]
Median for last 10 epochs: [0.2499 0.0764 0.5353 0.5105], Epochs since improvement 0
  7%|▋         | 35/500 [30:14<6:26:18, 49.85s/it]  7%|▋         | 36/500 [31:17<6:55:50, 53.77s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 4.04E+06, Train scatter: [0.3689 0.0783 0.5438 0.5942]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3679 0.0784 0.5352 0.5925], Lowest was [0.2251 0.0731 0.5352 0.4978]
Median for last 10 epochs: [0.2499 0.0764 0.5352 0.5105], Epochs since improvement 2
  7%|▋         | 37/500 [31:57<6:24:02, 49.77s/it]  8%|▊         | 38/500 [33:01<6:55:31, 53.96s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.90E+06, Train scatter: [0.2246 0.071  0.5438 0.5182]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2326 0.0715 0.5352 0.5182], Lowest was [0.2251 0.0715 0.5352 0.4978]
Median for last 10 epochs: [0.2499 0.0746 0.5352 0.5182], Epochs since improvement 0
  8%|▊         | 39/500 [33:41<6:22:24, 49.77s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.99E+06, Train scatter: [0.2077 0.0735 0.5437 0.9799]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2173 0.0742 0.5351 0.9696], Lowest was [0.2173 0.0715 0.5351 0.4978]
Median for last 10 epochs: [0.2326 0.0742 0.5352 0.5182], Epochs since improvement 0
  8%|▊         | 40/500 [34:51<7:07:12, 55.72s/it]  8%|▊         | 41/500 [35:31<6:30:54, 51.10s/it]  8%|▊         | 42/500 [36:35<6:59:29, 54.96s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.79E+06, Train scatter: [0.2207 0.0704 0.5436 0.7905]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2615 0.0704 0.535  0.7963], Lowest was [0.2173 0.0704 0.535  0.4978]
Median for last 10 epochs: [0.2326 0.0731 0.5352 0.5925], Epochs since improvement 0
  9%|▊         | 43/500 [37:15<6:24:41, 50.51s/it]  9%|▉         | 44/500 [38:18<6:52:02, 54.22s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.72E+06, Train scatter: [0.2424 0.0715 0.5435 0.5149]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2991 0.0716 0.5349 0.5191], Lowest was [0.2173 0.0704 0.5349 0.4978]
Median for last 10 epochs: [0.2615 0.0716 0.5351 0.5925], Epochs since improvement 0
  9%|▉         | 45/500 [38:58<6:19:10, 50.00s/it]  9%|▉         | 46/500 [40:01<6:49:01, 54.06s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.70E+06, Train scatter: [0.2197 0.0667 0.5434 0.5069]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2279 0.0673 0.5348 0.5111], Lowest was [0.2173 0.0673 0.5348 0.4978]
Median for last 10 epochs: [0.2326 0.0715 0.535  0.5191], Epochs since improvement 0
  9%|▉         | 47/500 [40:42<6:16:43, 49.90s/it] 10%|▉         | 48/500 [41:46<6:47:34, 54.10s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.61E+06, Train scatter: [0.4287 0.0729 0.5435 0.5191]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4175 0.073  0.5349 0.5163], Lowest was [0.2173 0.0673 0.5348 0.4978]
Median for last 10 epochs: [0.2615 0.0716 0.5349 0.5191], Epochs since improvement 2
 10%|▉         | 49/500 [42:26<6:15:15, 49.92s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.15E+06, Train scatter: [0.2354 0.0715 0.5437 0.5118]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2476 0.0712 0.5351 0.5092], Lowest was [0.2173 0.0673 0.5348 0.4978]
Median for last 10 epochs: [0.2615 0.0712 0.5349 0.5163], Epochs since improvement 4
 10%|█         | 50/500 [43:34<6:56:39, 55.55s/it] 10%|█         | 51/500 [44:15<6:21:09, 50.93s/it] 10%|█         | 52/500 [45:18<6:48:09, 54.66s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.09E+06, Train scatter: [0.3327 0.0742 0.5435 0.5353]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3358 0.0729 0.535  0.5363], Lowest was [0.2173 0.0673 0.5348 0.4978]
Median for last 10 epochs: [0.2991 0.0716 0.5349 0.5163], Epochs since improvement 6
 11%|█         | 53/500 [45:58<6:14:43, 50.30s/it] 11%|█         | 54/500 [47:02<6:43:31, 54.29s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.07E+06, Train scatter: [0.2134 0.0688 0.5434 0.5036]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2264 0.0709 0.5349 0.5003], Lowest was [0.2173 0.0673 0.5348 0.4978]
Median for last 10 epochs: [0.2476 0.0712 0.5349 0.5111], Epochs since improvement 8
 11%|█         | 55/500 [47:42<6:11:14, 50.06s/it] 11%|█         | 56/500 [48:45<6:38:25, 53.84s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.06E+06, Train scatter: [0.366  0.0715 0.5435 0.5045]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3636 0.072  0.5349 0.5   ], Lowest was [0.2173 0.0673 0.5348 0.4978]
Median for last 10 epochs: [0.3358 0.072  0.5349 0.5092], Epochs since improvement 10
 11%|█▏        | 57/500 [49:25<6:06:58, 49.70s/it] 12%|█▏        | 58/500 [50:28<6:36:00, 53.76s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.01E+06, Train scatter: [0.3811 0.0655 0.5433 0.5005]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3764 0.0658 0.5347 0.4923], Lowest was [0.2173 0.0658 0.5347 0.4923]
Median for last 10 epochs: [0.3358 0.0712 0.5349 0.5003], Epochs since improvement 0
 12%|█▏        | 59/500 [51:08<6:05:12, 49.69s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.02E+06, Train scatter: [0.3616 0.0971 0.5433 0.53  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3577 0.096  0.5347 0.5263], Lowest was [0.2173 0.0658 0.5347 0.4923]
Median for last 10 epochs: [0.3577 0.072  0.5349 0.5003], Epochs since improvement 2
 12%|█▏        | 60/500 [52:17<6:47:15, 55.53s/it] 12%|█▏        | 61/500 [52:58<6:13:05, 50.99s/it] 12%|█▏        | 62/500 [54:01<6:39:23, 54.71s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.98E+06, Train scatter: [0.3782 0.0719 0.5432 0.5139]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3713 0.0715 0.5346 0.5084], Lowest was [0.2173 0.0658 0.5346 0.4923]
Median for last 10 epochs: [0.3636 0.0715 0.5347 0.5003], Epochs since improvement 0
 13%|█▎        | 63/500 [54:41<6:07:02, 50.39s/it] 13%|█▎        | 64/500 [55:44<6:33:29, 54.15s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.94E+06, Train scatter: [0.4379 0.0941 0.5433 0.5836]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.434  0.093  0.5348 0.5873], Lowest was [0.2173 0.0658 0.5346 0.4923]
Median for last 10 epochs: [0.3713 0.072  0.5347 0.5084], Epochs since improvement 2
 13%|█▎        | 65/500 [56:25<6:02:36, 50.02s/it] 13%|█▎        | 66/500 [57:26<6:27:30, 53.57s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.92E+06, Train scatter: [0.378  0.0717 0.5428 0.506 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3788 0.0699 0.5343 0.5017], Lowest was [0.2173 0.0658 0.5343 0.4923]
Median for last 10 epochs: [0.3764 0.0715 0.5347 0.5084], Epochs since improvement 0
 13%|█▎        | 67/500 [58:07<5:57:57, 49.60s/it] 14%|█▎        | 68/500 [59:09<6:25:21, 53.52s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.89E+06, Train scatter: [0.3851 0.0674 0.5428 0.5048]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3759 0.0666 0.5342 0.5008], Lowest was [0.2173 0.0658 0.5342 0.4923]
Median for last 10 epochs: [0.3759 0.0715 0.5346 0.5084], Epochs since improvement 0
 14%|█▍        | 69/500 [59:50<5:56:13, 49.59s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.91E+06, Train scatter: [0.363  0.0649 0.5426 0.5036]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3571 0.0649 0.5341 0.4996], Lowest was [0.2173 0.0649 0.5341 0.4923]
Median for last 10 epochs: [0.3759 0.0699 0.5343 0.5017], Epochs since improvement 0
 14%|█▍        | 70/500 [1:01:01<6:41:27, 56.02s/it] 14%|█▍        | 71/500 [1:01:41<6:06:55, 51.32s/it] 14%|█▍        | 72/500 [1:02:44<6:29:42, 54.63s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.01E+06, Train scatter: [0.8491 0.1022 0.5437 0.6937]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8359 0.0987 0.5351 0.6774], Lowest was [0.2173 0.0649 0.5341 0.4923]
Median for last 10 epochs: [0.3788 0.0699 0.5343 0.5017], Epochs since improvement 2
 15%|█▍        | 73/500 [1:03:24<5:58:30, 50.38s/it] 15%|█▍        | 74/500 [1:04:27<6:24:22, 54.14s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.92E+06, Train scatter: [0.5    0.0714 0.5431 0.5166]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5066 0.0704 0.5345 0.5098], Lowest was [0.2173 0.0649 0.5341 0.4923]
Median for last 10 epochs: [0.3788 0.0699 0.5343 0.5017], Epochs since improvement 4
 15%|█▌        | 75/500 [1:05:07<5:54:41, 50.07s/it] 15%|█▌        | 76/500 [1:06:10<6:20:23, 53.83s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.94E+06, Train scatter: [0.4321 0.0866 0.5434 0.5764]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4316 0.0854 0.5349 0.5684], Lowest was [0.2173 0.0649 0.5341 0.4923]
Median for last 10 epochs: [0.4316 0.0704 0.5345 0.5098], Epochs since improvement 6
 15%|█▌        | 77/500 [1:06:51<5:51:23, 49.84s/it] 16%|█▌        | 78/500 [1:07:53<6:17:17, 53.64s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.90E+06, Train scatter: [0.5295 0.0796 0.5431 0.5391]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.517  0.0779 0.5346 0.5308], Lowest was [0.2173 0.0649 0.5341 0.4923]
Median for last 10 epochs: [0.5066 0.0779 0.5346 0.5308], Epochs since improvement 8
 16%|█▌        | 79/500 [1:08:34<5:48:50, 49.72s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.88E+06, Train scatter: [0.5289 0.076  0.5429 0.5441]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5167 0.0751 0.5344 0.5372], Lowest was [0.2173 0.0649 0.5341 0.4923]
Median for last 10 epochs: [0.5167 0.0779 0.5346 0.5372], Epochs since improvement 10
 16%|█▌        | 80/500 [1:09:43<6:28:08, 55.45s/it] 16%|█▌        | 81/500 [1:10:23<5:55:56, 50.97s/it] 16%|█▋        | 82/500 [1:11:25<6:18:35, 54.34s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.87E+06, Train scatter: [0.4467 0.0745 0.5426 0.5244]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4403 0.0748 0.5341 0.5181], Lowest was [0.2173 0.0649 0.5341 0.4923]
Median for last 10 epochs: [0.5066 0.0751 0.5345 0.5308], Epochs since improvement 0
 17%|█▋        | 83/500 [1:12:06<5:48:52, 50.20s/it] 17%|█▋        | 84/500 [1:13:09<6:15:22, 54.14s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.84E+06, Train scatter: [0.4011 0.0659 0.5424 0.5087]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3938 0.0662 0.5339 0.5046], Lowest was [0.2173 0.0649 0.5339 0.4923]
Median for last 10 epochs: [0.4403 0.0751 0.5344 0.5308], Epochs since improvement 0
 17%|█▋        | 85/500 [1:13:50<5:46:18, 50.07s/it] 17%|█▋        | 86/500 [1:14:52<6:11:28, 53.84s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.86E+06, Train scatter: [0.3989 0.0669 0.5423 0.5068]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.39   0.0673 0.5338 0.5038], Lowest was [0.2173 0.0649 0.5338 0.4923]
Median for last 10 epochs: [0.4403 0.0748 0.5341 0.5181], Epochs since improvement 0
 17%|█▋        | 87/500 [1:15:33<5:43:05, 49.84s/it] 18%|█▊        | 88/500 [1:16:36<6:10:34, 53.97s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.87E+06, Train scatter: [0.5131 0.0792 0.5415 0.5245]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5065 0.079  0.533  0.5208], Lowest was [0.2173 0.0649 0.533  0.4923]
Median for last 10 epochs: [0.4403 0.0748 0.5339 0.5181], Epochs since improvement 0
 18%|█▊        | 89/500 [1:17:17<5:41:58, 49.92s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.81E+06, Train scatter: [0.4492 0.0622 0.5412 0.5049]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4362 0.0624 0.5328 0.4985], Lowest was [0.2173 0.0624 0.5328 0.4923]
Median for last 10 epochs: [0.4362 0.0673 0.5338 0.5046], Epochs since improvement 0
 18%|█▊        | 90/500 [1:18:28<6:24:11, 56.22s/it] 18%|█▊        | 91/500 [1:19:08<5:50:55, 51.48s/it] 18%|█▊        | 92/500 [1:20:11<6:12:19, 54.75s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.82E+06, Train scatter: [0.2695 0.0666 0.5413 0.512 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2733 0.0669 0.5328 0.5069], Lowest was [0.2173 0.0624 0.5328 0.4923]
Median for last 10 epochs: [0.3938 0.0669 0.533  0.5046], Epochs since improvement 2
 19%|█▊        | 93/500 [1:20:51<5:42:02, 50.42s/it] 19%|█▉        | 94/500 [1:21:55<6:08:03, 54.39s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.78E+06, Train scatter: [0.413  0.0615 0.5394 0.4949]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4032 0.0618 0.5309 0.4898], Lowest was [0.2173 0.0618 0.5309 0.4898]
Median for last 10 epochs: [0.4032 0.0669 0.5328 0.5038], Epochs since improvement 0
 19%|█▉        | 95/500 [1:22:35<5:38:55, 50.21s/it] 19%|█▉        | 96/500 [1:23:38<6:03:55, 54.05s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.75E+06, Train scatter: [0.4842 0.0775 0.4193 0.5491]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4882 0.0777 0.4126 0.5533], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.4362 0.0669 0.5328 0.5069], Epochs since improvement 0
 19%|█▉        | 97/500 [1:24:18<5:35:22, 49.93s/it] 20%|█▉        | 98/500 [1:25:22<6:01:26, 53.95s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 9.78E+06, Train scatter: [0.7271 0.1416 0.5439 0.9771]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7254 0.1392 0.5353 0.9674], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.4362 0.0669 0.5328 0.5069], Epochs since improvement 2
 20%|█▉        | 99/500 [1:26:02<5:33:18, 49.87s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 7.48E+06, Train scatter: [0.6116 0.1264 0.544  0.9789]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6055 0.1254 0.5354 0.9691], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.4882 0.0777 0.5328 0.5533], Epochs since improvement 4
 20%|██        | 100/500 [1:27:11<6:09:59, 55.50s/it] 20%|██        | 101/500 [1:27:51<5:39:05, 50.99s/it] 20%|██        | 102/500 [1:28:55<6:02:51, 54.70s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 6.61E+06, Train scatter: [0.8915 0.1273 0.544  0.9798]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9409 0.1248 0.5354 0.9701], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.6055 0.1248 0.5353 0.9674], Epochs since improvement 6
 21%|██        | 103/500 [1:29:35<5:33:18, 50.37s/it] 21%|██        | 104/500 [1:30:38<5:58:44, 54.36s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 6.11E+06, Train scatter: [0.5671 0.1155 0.544  0.9779]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.585  0.1154 0.5354 0.9682], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.6055 0.1248 0.5354 0.9682], Epochs since improvement 8
 21%|██        | 105/500 [1:31:19<5:30:01, 50.13s/it] 21%|██        | 106/500 [1:32:23<5:56:13, 54.25s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 5.75E+06, Train scatter: [0.5405 0.1146 0.544  0.976 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5372 0.1133 0.5354 0.9664], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.6055 0.1248 0.5354 0.9682], Epochs since improvement 10
 21%|██▏       | 107/500 [1:33:03<5:27:54, 50.06s/it] 22%|██▏       | 108/500 [1:34:06<5:53:25, 54.10s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 5.46E+06, Train scatter: [0.5319 0.114  0.544  0.9726]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5303 0.113  0.5354 0.9631], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.585  0.1154 0.5354 0.9682], Epochs since improvement 12
 22%|██▏       | 109/500 [1:34:47<5:25:21, 49.93s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 5.18E+06, Train scatter: [0.5232 0.1125 0.544  0.9655]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5222 0.1116 0.5354 0.9562], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.5372 0.1133 0.5354 0.9664], Epochs since improvement 14
 22%|██▏       | 110/500 [1:35:56<6:02:26, 55.76s/it] 22%|██▏       | 111/500 [1:36:36<5:31:42, 51.16s/it] 22%|██▏       | 112/500 [1:37:39<5:53:41, 54.69s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 4.93E+06, Train scatter: [0.5498 0.1169 0.5438 0.9553]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5536 0.1167 0.5353 0.9463], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.5372 0.1133 0.5354 0.9631], Epochs since improvement 16
 23%|██▎       | 113/500 [1:38:20<5:25:04, 50.40s/it] 23%|██▎       | 114/500 [1:39:22<5:48:04, 54.11s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 4.76E+06, Train scatter: [0.4796 0.1267 0.5432 0.935 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.476  0.1235 0.5347 0.9264], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.5303 0.1133 0.5354 0.9562], Epochs since improvement 18
 23%|██▎       | 115/500 [1:40:03<5:20:51, 50.00s/it] 23%|██▎       | 116/500 [1:41:05<5:43:22, 53.65s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 4.59E+06, Train scatter: [0.4666 0.1113 0.5423 0.8906]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4678 0.1115 0.5338 0.8829], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.5222 0.113  0.5353 0.9463], Epochs since improvement 20
 23%|██▎       | 117/500 [1:41:45<5:16:59, 49.66s/it] 23%|██▎       | 117/500 [1:42:49<5:36:35, 52.73s/it]
Epoch: 118 done with learning rate 9.75E-03, Train loss: 4.41E+06, Train scatter: [0.4934 0.1092 0.5407 0.8056]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4913 0.1061 0.5323 0.7985], Lowest was [0.2173 0.0618 0.4126 0.4898]
Median for last 10 epochs: [0.4913 0.1116 0.5347 0.9264], Epochs since improvement 22
Exited after 118 epochs due to early stopping
6169.42 seconds spent training, 12.339 seconds per epoch. Processed 5644 trees per second
[0.49129117 0.10614153 0.5322848  0.79847354]
{'epoch_exit': 117, 'scatter_m_star': 0.49129117, 'lowest_m_star': 0.21731628, 'last20_m_star': 0.5337577, 'last10_m_star': 0.49130586, 'scatter_v_disk': 0.10614153, 'lowest_v_disk': 0.0618211, 'last20_v_disk': 0.11433919, 'last10_v_disk': 0.11163617, 'scatter_m_cold': 0.5322848, 'lowest_m_cold': 0.41258463, 'last20_m_cold': 0.5353719, 'last10_m_cold': 0.53469616, 'scatter_sfr_100': 0.79847354, 'lowest_sfr_100': 0.48976544, 'last20_sfr_100': 0.9596654, 'last10_sfr_100': 0.9264364}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_ciiahw
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:01<8:28:32, 61.15s/it]  0%|          | 2/500 [02:29<10:41:41, 77.31s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.34E+07, Train scatter: [0.9351 0.1289 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1247 0.5355 0.9851], Lowest was [0.9195 0.1247 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1247 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:31<9:39:38, 69.98s/it]   1%|          | 4/500 [05:01<10:47:00, 78.27s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.35E+07, Train scatter: [0.9313 0.104  0.543  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9153 0.1043 0.5343 0.9851], Lowest was [0.9153 0.1043 0.5343 0.9851]
Median for last 10 epochs: [0.9153 0.1043 0.5343 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:02<9:54:11, 72.02s/it]   1%|          | 6/500 [07:33<10:44:21, 78.26s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.07E+07, Train scatter: [0.9188 0.0964 0.5325 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9026 0.0963 0.5243 0.985 ], Lowest was [0.9026 0.0963 0.5243 0.985 ]
Median for last 10 epochs: [0.9026 0.0963 0.5243 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [08:34<9:56:40, 72.62s/it]   2%|▏         | 8/500 [10:03<10:39:50, 78.03s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.76E+07, Train scatter: [0.7056 0.1    0.3947 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7    0.1023 0.3925 0.985 ], Lowest was [0.7    0.0963 0.3925 0.985 ]
Median for last 10 epochs: [0.8013 0.0993 0.4584 0.985 ], Epochs since improvement 0
  2%|▏         | 9/500 [11:05<9:55:11, 72.73s/it] Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.60E+07, Train scatter: [0.5993 0.0909 0.3875 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.608  0.0932 0.3915 0.985 ], Lowest was [0.608  0.0932 0.3915 0.985 ]
Median for last 10 epochs: [0.7    0.0963 0.3925 0.985 ], Epochs since improvement 0
  2%|▏         | 10/500 [12:42<10:57:30, 80.51s/it]  2%|▏         | 11/500 [13:44<10:08:08, 74.62s/it]  2%|▏         | 12/500 [15:14<10:45:34, 79.37s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.53E+07, Train scatter: [0.5496 0.0843 0.3404 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5494 0.0855 0.3417 0.985 ], Lowest was [0.5494 0.0855 0.3417 0.985 ]
Median for last 10 epochs: [0.7    0.0963 0.3925 0.985 ], Epochs since improvement 0
  3%|▎         | 13/500 [16:15<9:59:56, 73.92s/it]   3%|▎         | 14/500 [17:46<10:38:45, 78.86s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.65E+07, Train scatter: [0.5687 0.0846 0.3232 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5693 0.0862 0.3284 0.985 ], Lowest was [0.5494 0.0855 0.3284 0.985 ]
Median for last 10 epochs: [0.608  0.0932 0.3915 0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [18:47<9:54:08, 73.50s/it]   3%|▎         | 16/500 [20:17<10:34:10, 78.62s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.64E+07, Train scatter: [0.5177 0.0814 0.3233 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5137 0.0814 0.3268 0.985 ], Lowest was [0.5137 0.0814 0.3268 0.985 ]
Median for last 10 epochs: [0.5693 0.0862 0.3417 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [21:19<9:51:07, 73.43s/it]   4%|▎         | 18/500 [22:50<10:33:09, 78.82s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.72E+07, Train scatter: [0.5132 0.0764 0.3029 0.9948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5046 0.0767 0.3065 0.9846], Lowest was [0.5046 0.0767 0.3065 0.9846]
Median for last 10 epochs: [0.5494 0.0855 0.3284 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [23:51<9:49:07, 73.49s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.01E+06, Train scatter: [0.4318 0.076  0.3126 0.6757]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.423  0.0757 0.3154 0.6736], Lowest was [0.423  0.0757 0.3065 0.6736]
Median for last 10 epochs: [0.5137 0.0814 0.3268 0.985 ], Epochs since improvement 0
  4%|▍         | 20/500 [25:29<10:46:02, 80.76s/it]  4%|▍         | 21/500 [26:30<9:57:59, 74.91s/it]   4%|▍         | 22/500 [28:00<10:33:08, 79.47s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.89E+06, Train scatter: [0.4356 0.0728 0.3092 0.56  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4248 0.072  0.3136 0.5633], Lowest was [0.423  0.072  0.3065 0.5633]
Median for last 10 epochs: [0.5046 0.0767 0.3154 0.9846], Epochs since improvement 0
  5%|▍         | 23/500 [29:01<9:48:40, 74.05s/it]   5%|▍         | 24/500 [30:31<10:24:31, 78.72s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.47E+06, Train scatter: [0.4331 0.0753 0.3077 0.5071]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4206 0.0735 0.3079 0.504 ], Lowest was [0.4206 0.072  0.3065 0.504 ]
Median for last 10 epochs: [0.4248 0.0757 0.3136 0.6736], Epochs since improvement 0
  5%|▌         | 25/500 [31:33<9:42:20, 73.56s/it]   5%|▌         | 26/500 [33:03<10:21:21, 78.65s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.24E+06, Train scatter: [0.9273 0.0793 0.3166 0.5398]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9138 0.0811 0.3218 0.5444], Lowest was [0.4206 0.072  0.3065 0.504 ]
Median for last 10 epochs: [0.4248 0.0757 0.3136 0.5633], Epochs since improvement 2
  5%|▌         | 27/500 [34:05<9:39:28, 73.51s/it]   6%|▌         | 28/500 [35:35<10:17:39, 78.52s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.08E+06, Train scatter: [0.4221 0.074  0.3023 0.4887]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4119 0.0724 0.3061 0.4881], Lowest was [0.4119 0.072  0.3061 0.4881]
Median for last 10 epochs: [0.423  0.0735 0.3136 0.5444], Epochs since improvement 0
  6%|▌         | 29/500 [36:36<9:35:44, 73.34s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.84E+06, Train scatter: [0.3944 0.0686 0.2913 0.4679]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3861 0.0679 0.2964 0.4687], Lowest was [0.3861 0.0679 0.2964 0.4687]
Median for last 10 epochs: [0.4206 0.0724 0.3079 0.504 ], Epochs since improvement 0
  6%|▌         | 30/500 [38:14<10:31:36, 80.63s/it]  6%|▌         | 31/500 [39:15<9:44:48, 74.82s/it]   6%|▋         | 32/500 [40:46<10:22:03, 79.75s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.75E+06, Train scatter: [0.4224 0.0709 0.2895 0.4701]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4126 0.072  0.2924 0.4734], Lowest was [0.3861 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.4126 0.0724 0.3061 0.4881], Epochs since improvement 0
  7%|▋         | 33/500 [41:47<9:37:05, 74.14s/it]   7%|▋         | 34/500 [43:18<10:14:36, 79.13s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 4.73E+07, Train scatter: [0.9355 0.1733 0.5437 0.9874]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.92   0.1695 0.5351 0.9776], Lowest was [0.3861 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.4126 0.0724 0.3061 0.4881], Epochs since improvement 2
  7%|▋         | 35/500 [44:19<9:31:59, 73.81s/it]   7%|▋         | 36/500 [45:51<10:10:51, 78.99s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 8.33E+06, Train scatter: [0.9073 0.1475 0.5412 0.6932]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8927 0.1449 0.5327 0.697 ], Lowest was [0.3861 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.4126 0.0724 0.3061 0.4881], Epochs since improvement 4
  7%|▋         | 37/500 [46:52<9:28:13, 73.64s/it]   8%|▊         | 38/500 [48:22<10:06:04, 78.71s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.30E+06, Train scatter: [0.8883 0.1109 0.535  0.6579]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8737 0.1114 0.5267 0.6531], Lowest was [0.3861 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.8737 0.1114 0.5267 0.6531], Epochs since improvement 6
  8%|▊         | 39/500 [49:24<9:24:51, 73.52s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 5.35E+06, Train scatter: [0.8182 0.0996 0.5127 0.6452]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8035 0.1002 0.5047 0.6388], Lowest was [0.3861 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.8737 0.1114 0.5267 0.6531], Epochs since improvement 8
  8%|▊         | 40/500 [51:03<10:22:03, 81.14s/it]  8%|▊         | 41/500 [52:04<9:34:59, 75.16s/it]   8%|▊         | 42/500 [53:34<10:07:48, 79.63s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 4.57E+06, Train scatter: [0.5243 0.0921 0.4973 0.6104]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5246 0.0927 0.4906 0.6017], Lowest was [0.3861 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.8737 0.1114 0.5267 0.6531], Epochs since improvement 10
  9%|▊         | 43/500 [54:35<9:24:19, 74.09s/it]   9%|▉         | 44/500 [56:06<10:00:32, 79.02s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.18E+06, Train scatter: [0.4249 0.0909 0.4727 0.5905]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4461 0.0915 0.467  0.5845], Lowest was [0.3861 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.8035 0.1002 0.5047 0.6388], Epochs since improvement 12
  9%|▉         | 45/500 [57:06<9:18:00, 73.58s/it]   9%|▉         | 46/500 [58:37<9:54:55, 78.62s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.92E+06, Train scatter: [0.4507 0.0881 0.4509 0.593 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4496 0.0881 0.4461 0.5828], Lowest was [0.3861 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.5246 0.0927 0.4906 0.6017], Epochs since improvement 14
  9%|▉         | 47/500 [59:38<9:13:47, 73.35s/it] 10%|▉         | 48/500 [1:01:08<9:49:51, 78.30s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.75E+06, Train scatter: [0.3569 0.0858 0.4381 0.5664]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3794 0.0856 0.4327 0.5596], Lowest was [0.3794 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.4496 0.0915 0.467  0.5845], Epochs since improvement 0
 10%|▉         | 49/500 [1:02:09<9:09:30, 73.11s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.47E+06, Train scatter: [0.363  0.0831 0.4712 0.5512]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.346  0.0828 0.4659 0.5446], Lowest was [0.346  0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.4461 0.0881 0.4659 0.5828], Epochs since improvement 0
 10%|█         | 50/500 [1:03:47<10:04:07, 80.55s/it] 10%|█         | 51/500 [1:04:48<9:18:54, 74.69s/it]  10%|█         | 52/500 [1:06:18<9:53:48, 79.53s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.40E+06, Train scatter: [0.3529 0.0818 0.4177 0.5487]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3651 0.0812 0.4153 0.541 ], Lowest was [0.346  0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.3794 0.0856 0.4461 0.5596], Epochs since improvement 2
 11%|█         | 53/500 [1:07:19<9:10:54, 73.95s/it] 11%|█         | 54/500 [1:08:49<9:44:57, 78.69s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.99E+06, Train scatter: [0.3547 0.082  0.411  0.5322]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.332  0.0819 0.4095 0.5297], Lowest was [0.332  0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.3651 0.0828 0.4327 0.5446], Epochs since improvement 0
 11%|█         | 55/500 [1:09:50<9:04:15, 73.38s/it] 11%|█         | 56/500 [1:11:20<9:39:25, 78.30s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.75E+06, Train scatter: [0.3033 0.0781 0.3934 0.5219]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3173 0.0779 0.3915 0.5186], Lowest was [0.3173 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.346  0.0819 0.4153 0.541 ], Epochs since improvement 0
 11%|█▏        | 57/500 [1:12:21<9:00:16, 73.18s/it] 12%|█▏        | 58/500 [1:13:51<9:35:56, 78.18s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.44E+06, Train scatter: [0.2868 0.0754 0.3811 0.5163]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2913 0.0752 0.3784 0.5133], Lowest was [0.2913 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.332  0.0812 0.4095 0.5297], Epochs since improvement 0
 12%|█▏        | 59/500 [1:14:52<8:56:51, 73.04s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.17E+06, Train scatter: [0.2897 0.0741 0.3715 0.5099]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2946 0.0737 0.3674 0.5062], Lowest was [0.2913 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.3173 0.0779 0.3915 0.5186], Epochs since improvement 2
 12%|█▏        | 60/500 [1:16:30<9:49:38, 80.41s/it] 12%|█▏        | 61/500 [1:17:31<9:06:12, 74.65s/it] 12%|█▏        | 62/500 [1:19:00<9:37:45, 79.14s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.00E+06, Train scatter: [0.284  0.0715 0.3694 0.499 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2853 0.0716 0.3682 0.4985], Lowest was [0.2853 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.2946 0.0752 0.3784 0.5133], Epochs since improvement 0
 13%|█▎        | 63/500 [1:20:02<8:57:03, 73.74s/it] 13%|█▎        | 64/500 [1:21:32<9:33:01, 78.86s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.79E+06, Train scatter: [0.3093 0.0701 0.3563 0.5012]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3136 0.07   0.3551 0.5018], Lowest was [0.2853 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.2946 0.0737 0.3682 0.5062], Epochs since improvement 2
 13%|█▎        | 65/500 [1:22:34<8:53:32, 73.59s/it] 13%|█▎        | 66/500 [1:24:03<9:26:45, 78.35s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.77E+06, Train scatter: [0.4026 0.0716 0.355  0.506 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3935 0.0725 0.3566 0.5015], Lowest was [0.2853 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.2946 0.0725 0.3674 0.5018], Epochs since improvement 4
 13%|█▎        | 67/500 [1:25:05<8:48:56, 73.30s/it] 14%|█▎        | 68/500 [1:26:34<9:22:24, 78.11s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.63E+06, Train scatter: [0.2605 0.0765 0.3606 0.5084]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2675 0.077  0.3597 0.5049], Lowest was [0.2675 0.0679 0.2924 0.4687]
Median for last 10 epochs: [0.2946 0.0725 0.3597 0.5018], Epochs since improvement 0
 14%|█▍        | 69/500 [1:27:35<8:44:48, 73.06s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.53E+06, Train scatter: [0.2507 0.064  0.3494 0.5079]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.253  0.0637 0.3494 0.497 ], Lowest was [0.253  0.0637 0.2924 0.4687]
Median for last 10 epochs: [0.2853 0.0716 0.3566 0.5015], Epochs since improvement 0
 14%|█▍        | 70/500 [1:29:12<9:34:30, 80.16s/it] 14%|█▍        | 71/500 [1:30:13<8:52:49, 74.52s/it] 14%|█▍        | 72/500 [1:31:44<9:25:53, 79.33s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.42E+06, Train scatter: [0.2756 0.0636 0.3407 0.4906]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.274  0.0631 0.3408 0.49  ], Lowest was [0.253  0.0631 0.2924 0.4687]
Median for last 10 epochs: [0.274  0.07   0.3551 0.5015], Epochs since improvement 0
 15%|█▍        | 73/500 [1:32:45<8:46:21, 73.96s/it] 15%|█▍        | 74/500 [1:34:15<9:17:55, 78.58s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 1.36E+06, Train scatter: [0.2376 0.0639 0.3304 0.4678]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2296 0.0645 0.3348 0.4675], Lowest was [0.2296 0.0631 0.2924 0.4675]
Median for last 10 epochs: [0.2675 0.0645 0.3494 0.497 ], Epochs since improvement 0
 15%|█▌        | 75/500 [1:35:16<8:40:17, 73.45s/it] 15%|█▌        | 76/500 [1:36:45<9:12:35, 78.20s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 1.20E+06, Train scatter: [0.2247 0.064  0.323  0.4667]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2238 0.0657 0.3304 0.4653], Lowest was [0.2238 0.0631 0.2924 0.4653]
Median for last 10 epochs: [0.253  0.0645 0.3408 0.49  ], Epochs since improvement 0
 15%|█▌        | 77/500 [1:37:47<8:35:45, 73.16s/it] 16%|█▌        | 78/500 [1:39:17<9:10:02, 78.21s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 1.13E+06, Train scatter: [0.2035 0.056  0.3238 0.4609]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.203  0.0566 0.3275 0.4596], Lowest was [0.203  0.0566 0.2924 0.4596]
Median for last 10 epochs: [0.2296 0.0637 0.3348 0.4675], Epochs since improvement 0
 16%|█▌        | 79/500 [1:40:18<8:32:51, 73.09s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 9.88E+05, Train scatter: [0.2242 0.057  0.3122 0.4591]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2163 0.057  0.3149 0.4538], Lowest was [0.203  0.0566 0.2924 0.4538]
Median for last 10 epochs: [0.2238 0.0631 0.3304 0.4653], Epochs since improvement 0
 16%|█▌        | 80/500 [1:41:58<9:27:46, 81.11s/it] 16%|█▌        | 81/500 [1:42:59<8:45:08, 75.20s/it] 16%|█▋        | 82/500 [1:44:30<9:15:54, 79.80s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 8.00E+05, Train scatter: [0.2777 0.0624 0.318  0.4562]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2586 0.0632 0.3202 0.4559], Lowest was [0.203  0.0566 0.2924 0.4538]
Median for last 10 epochs: [0.2238 0.0632 0.3275 0.4596], Epochs since improvement 2
 17%|█▋        | 83/500 [1:45:31<8:35:58, 74.24s/it] 17%|█▋        | 84/500 [1:47:02<9:09:45, 79.29s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 6.52E+05, Train scatter: [0.2077 0.0566 0.3077 0.4466]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1985 0.0566 0.3104 0.4427], Lowest was [0.1985 0.0566 0.2924 0.4427]
Median for last 10 epochs: [0.2163 0.057  0.3202 0.4559], Epochs since improvement 0
 17%|█▋        | 85/500 [1:48:03<8:30:40, 73.83s/it] 17%|█▋        | 86/500 [1:49:33<9:03:12, 78.73s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 4.36E+05, Train scatter: [0.1746 0.0544 0.2971 0.4335]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1754 0.0547 0.3019 0.4323], Lowest was [0.1754 0.0547 0.2924 0.4323]
Median for last 10 epochs: [0.203  0.0566 0.3149 0.4538], Epochs since improvement 0
 17%|█▋        | 87/500 [1:50:34<8:25:19, 73.41s/it] 18%|█▊        | 88/500 [1:52:04<8:57:37, 78.30s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.36E+05, Train scatter: [0.1718 0.0534 0.3067 0.4302]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1737 0.0533 0.3053 0.4287], Lowest was [0.1737 0.0533 0.2924 0.4287]
Median for last 10 epochs: [0.1985 0.0566 0.3104 0.4427], Epochs since improvement 0
 18%|█▊        | 89/500 [1:53:05<8:20:34, 73.08s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 5.06E+04, Train scatter: [0.4627 0.0543 0.3325 0.4476]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.446  0.0533 0.3458 0.4404], Lowest was [0.1737 0.0533 0.2924 0.4287]
Median for last 10 epochs: [0.1985 0.0547 0.3104 0.4404], Epochs since improvement 0
 18%|█▊        | 90/500 [1:54:42<9:09:08, 80.36s/it] 18%|█▊        | 91/500 [1:55:43<8:27:51, 74.50s/it] 18%|█▊        | 92/500 [1:57:13<8:58:28, 79.19s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: -8.51E+04, Train scatter: [0.3105 0.051  0.2857 0.4205]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2958 0.0512 0.287  0.4165], Lowest was [0.1737 0.0512 0.287  0.4165]
Median for last 10 epochs: [0.1985 0.0533 0.3053 0.4323], Epochs since improvement 0
 19%|█▊        | 93/500 [1:58:14<8:20:07, 73.73s/it] 19%|█▉        | 94/500 [1:59:44<8:51:59, 78.62s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: -1.86E+05, Train scatter: [0.3655 0.0481 0.2663 0.4259]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3566 0.0481 0.2688 0.4197], Lowest was [0.1737 0.0481 0.2688 0.4165]
Median for last 10 epochs: [0.2958 0.0533 0.3019 0.4287], Epochs since improvement 0
 19%|█▉        | 95/500 [2:00:45<8:14:46, 73.30s/it] 19%|█▉        | 96/500 [2:02:16<8:48:34, 78.50s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: -2.48E+05, Train scatter: [0.378  0.0465 0.2723 0.4113]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3669 0.0466 0.2739 0.4079], Lowest was [0.1737 0.0466 0.2688 0.4079]
Median for last 10 epochs: [0.3566 0.0512 0.287  0.4197], Epochs since improvement 0
 19%|█▉        | 97/500 [2:03:17<8:11:53, 73.23s/it] 20%|█▉        | 98/500 [2:04:47<8:45:05, 78.37s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: -2.89E+05, Train scatter: [0.3334 0.0453 0.3074 0.4109]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.325  0.0452 0.3082 0.4064], Lowest was [0.1737 0.0452 0.2688 0.4064]
Median for last 10 epochs: [0.3566 0.0481 0.287  0.4165], Epochs since improvement 0
 20%|█▉        | 99/500 [2:05:48<8:08:27, 73.09s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: -3.06E+05, Train scatter: [0.2215 0.0512 0.2845 0.4304]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2214 0.0501 0.2835 0.4191], Lowest was [0.1737 0.0452 0.2688 0.4064]
Median for last 10 epochs: [0.325  0.0481 0.2835 0.4165], Epochs since improvement 2
 20%|██        | 100/500 [2:07:26<8:57:20, 80.60s/it] 20%|██        | 101/500 [2:08:27<8:16:56, 74.73s/it] 20%|██        | 102/500 [2:09:58<8:47:52, 79.58s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: -3.34E+05, Train scatter: [0.1386 0.0476 0.2477 0.4097]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1358 0.0477 0.25   0.4042], Lowest was [0.1358 0.0452 0.25   0.4042]
Median for last 10 epochs: [0.325  0.0477 0.2739 0.4079], Epochs since improvement 0
 21%|██        | 103/500 [2:10:59<8:09:14, 73.94s/it] 21%|██        | 104/500 [2:12:29<8:39:56, 78.78s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: -3.06E+05, Train scatter: [0.3414 0.054  0.2611 0.432 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3337 0.054  0.2643 0.4256], Lowest was [0.1358 0.0452 0.25   0.4042]
Median for last 10 epochs: [0.325  0.0477 0.2739 0.4079], Epochs since improvement 2
 21%|██        | 105/500 [2:13:30<8:03:19, 73.42s/it] 21%|██        | 106/500 [2:15:00<8:35:09, 78.45s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: -3.36E+05, Train scatter: [0.251  0.0546 0.266  0.4445]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2411 0.0537 0.2668 0.4344], Lowest was [0.1358 0.0452 0.25   0.4042]
Median for last 10 epochs: [0.2411 0.0501 0.2668 0.4191], Epochs since improvement 4
 21%|██▏       | 107/500 [2:16:01<7:59:42, 73.24s/it] 22%|██▏       | 108/500 [2:17:31<8:32:11, 78.40s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: -3.55E+05, Train scatter: [0.3709 0.0466 0.2464 0.4222]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3599 0.0462 0.2473 0.417 ], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.2411 0.0501 0.2643 0.4191], Epochs since improvement 0
 22%|██▏       | 109/500 [2:18:32<7:56:34, 73.13s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 3.43E+07, Train scatter: [0.8277 0.1727 0.5355 0.8697]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8145 0.1689 0.5273 0.8635], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.3337 0.0537 0.2643 0.4256], Epochs since improvement 2
 22%|██▏       | 110/500 [2:20:10<8:44:03, 80.62s/it] 22%|██▏       | 111/500 [2:21:11<8:04:15, 74.69s/it] 22%|██▏       | 112/500 [2:22:42<8:33:19, 79.38s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 2.58E+05, Train scatter: [0.5961 0.1732 0.5207 0.755 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5882 0.1693 0.5137 0.7459], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.3599 0.054  0.2668 0.4344], Epochs since improvement 4
 23%|██▎       | 113/500 [2:23:42<7:56:12, 73.83s/it] 23%|██▎       | 114/500 [2:25:13<8:26:56, 78.80s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 5.32E+04, Train scatter: [0.5158 0.1144 0.5061 0.6699]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5082 0.1119 0.4985 0.6604], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.5082 0.1119 0.4985 0.6604], Epochs since improvement 6
 23%|██▎       | 115/500 [2:26:14<7:51:00, 73.40s/it] 23%|██▎       | 116/500 [2:27:44<8:22:47, 78.56s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.28E+04, Train scatter: [0.556  0.1064 0.5062 0.6445]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5457 0.1043 0.4979 0.6365], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.5457 0.1119 0.4985 0.6604], Epochs since improvement 8
 23%|██▎       | 117/500 [2:28:45<7:47:37, 73.26s/it] 24%|██▎       | 118/500 [2:30:15<8:18:26, 78.29s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: -2.00E+04, Train scatter: [0.4901 0.1092 0.4731 0.6462]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4814 0.1071 0.4664 0.638 ], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.5457 0.1119 0.4985 0.6604], Epochs since improvement 10
 24%|██▍       | 119/500 [2:31:16<7:44:20, 73.12s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: -5.76E+04, Train scatter: [0.4929 0.1064 0.4486 0.6333]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4872 0.1047 0.4443 0.6246], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.5082 0.1071 0.4979 0.638 ], Epochs since improvement 12
 24%|██▍       | 120/500 [2:32:53<8:29:00, 80.37s/it] 24%|██▍       | 121/500 [2:33:54<7:50:51, 74.54s/it] 24%|██▍       | 122/500 [2:35:25<8:20:19, 79.42s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: -7.82E+04, Train scatter: [0.5217 0.0988 0.4853 0.6125]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5288 0.0989 0.4908 0.6064], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.5082 0.1047 0.4908 0.6365], Epochs since improvement 14
 25%|██▍       | 123/500 [2:36:26<7:44:10, 73.87s/it] 25%|██▍       | 124/500 [2:37:56<8:13:06, 78.69s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: -1.11E+05, Train scatter: [0.5208 0.0957 0.4046 0.5909]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5246 0.0968 0.4038 0.5907], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.5246 0.1043 0.4664 0.6246], Epochs since improvement 16
 25%|██▌       | 125/500 [2:38:57<7:38:51, 73.42s/it] 25%|██▌       | 126/500 [2:40:27<8:08:23, 78.35s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: -1.47E+05, Train scatter: [0.447  0.0864 0.4015 0.5586]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4394 0.0859 0.399  0.5525], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.4872 0.0989 0.4443 0.6064], Epochs since improvement 18
 25%|██▌       | 127/500 [2:41:28<7:34:41, 73.14s/it] 26%|██▌       | 128/500 [2:42:59<8:05:51, 78.36s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -1.91E+05, Train scatter: [0.4397 0.076  0.3539 0.5273]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4319 0.0761 0.3507 0.5257], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.4872 0.0968 0.4038 0.5907], Epochs since improvement 20
 26%|██▌       | 129/500 [2:44:00<7:32:51, 73.24s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -2.30E+05, Train scatter: [0.3943 0.0748 0.3695 0.5379]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3835 0.0749 0.3704 0.5329], Lowest was [0.1358 0.0452 0.2473 0.4042]
Median for last 10 epochs: [0.4394 0.0859 0.399  0.5525], Epochs since improvement 22
 26%|██▌       | 129/500 [2:45:37<7:56:18, 77.03s/it]
Exited after 130 epochs due to early stopping
9937.17 seconds spent training, 19.874 seconds per epoch. Processed 3504 trees per second
[0.38352415 0.07489698 0.37041804 0.5329086 ]
{'epoch_exit': 129, 'scatter_m_star': 0.38352415, 'lowest_m_star': 0.13580714, 'last20_m_star': 0.4977153, 'last10_m_star': 0.43936583, 'scatter_v_disk': 0.074896984, 'lowest_v_disk': 0.04518589, 'last20_v_disk': 0.10162388, 'last10_v_disk': 0.08591855, 'scatter_m_cold': 0.37041804, 'lowest_m_cold': 0.24730575, 'last20_m_cold': 0.455346, 'last10_m_cold': 0.39898837, 'scatter_sfr_100': 0.5329086, 'lowest_sfr_100': 0.40418962, 'last20_sfr_100': 0.6155114, 'last10_sfr_100': 0.5524919}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_euyzzj
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:21:05, 53.04s/it]  0%|          | 2/500 [02:13<9:32:36, 68.99s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.1705 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1653 0.5355 0.985 ], Lowest was [0.9196 0.1653 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1653 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:06<8:31:51, 61.79s/it]  1%|          | 4/500 [04:27<9:33:54, 69.42s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 9.09E+07, Train scatter: [0.9352 0.1516 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1467 0.5355 0.985 ], Lowest was [0.9196 0.1467 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1467 0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:20<8:44:15, 63.55s/it]  1%|          | 6/500 [06:41<9:31:40, 69.43s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.79E+07, Train scatter: [0.9351 0.1309 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1291 0.5355 0.985 ], Lowest was [0.9195 0.1291 0.5355 0.985 ]
Median for last 10 epochs: [0.9195 0.1291 0.5355 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [07:34<8:46:30, 64.08s/it]  2%|▏         | 8/500 [08:54<9:26:21, 69.07s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.41E+07, Train scatter: [0.9351 0.1114 0.5439 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1098 0.5353 0.9851], Lowest was [0.9195 0.1098 0.5353 0.985 ]
Median for last 10 epochs: [0.9195 0.1195 0.5354 0.985 ], Epochs since improvement 0
  2%|▏         | 9/500 [09:47<8:45:00, 64.16s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.20E+07, Train scatter: [0.9308 0.0969 0.5422 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9152 0.098  0.5337 0.9851], Lowest was [0.9152 0.098  0.5337 0.985 ]
Median for last 10 epochs: [0.9195 0.1098 0.5353 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:15<9:42:37, 71.34s/it]  2%|▏         | 11/500 [12:08<8:56:31, 65.83s/it]  2%|▏         | 12/500 [13:28<9:31:02, 70.21s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.03E+07, Train scatter: [0.6794 0.0903 0.5343 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6698 0.0914 0.5263 0.985 ], Lowest was [0.6698 0.0914 0.5263 0.985 ]
Median for last 10 epochs: [0.9195 0.1098 0.5353 0.985 ], Epochs since improvement 0
  3%|▎         | 13/500 [14:22<8:48:46, 65.15s/it]  3%|▎         | 14/500 [15:42<9:24:11, 69.65s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.92E+07, Train scatter: [0.513  0.0861 0.53   0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5123 0.0875 0.5223 0.985 ], Lowest was [0.5123 0.0875 0.5223 0.985 ]
Median for last 10 epochs: [0.9152 0.098  0.5337 0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [16:35<8:43:24, 64.75s/it]  3%|▎         | 16/500 [17:57<9:23:22, 69.84s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.85E+07, Train scatter: [0.4829 0.0888 0.5291 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4825 0.0898 0.5205 0.985 ], Lowest was [0.4825 0.0875 0.5205 0.985 ]
Median for last 10 epochs: [0.6698 0.0914 0.5263 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [18:50<8:41:38, 64.80s/it]  4%|▎         | 18/500 [20:11<9:18:53, 69.57s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.76E+07, Train scatter: [0.4798 0.0823 0.5215 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4872 0.0841 0.5137 0.9849], Lowest was [0.4825 0.0841 0.5137 0.9849]
Median for last 10 epochs: [0.5123 0.0898 0.5223 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [21:04<8:38:17, 64.65s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.57E+07, Train scatter: [0.51   0.0863 0.3872 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5252 0.0885 0.3862 0.985 ], Lowest was [0.4825 0.0841 0.3862 0.9849]
Median for last 10 epochs: [0.5123 0.0885 0.5205 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:32<9:34:29, 71.81s/it]  4%|▍         | 21/500 [23:25<8:48:41, 66.22s/it]  4%|▍         | 22/500 [24:46<9:21:53, 70.53s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.50E+07, Train scatter: [0.5401 0.0861 0.3409 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5504 0.0889 0.3486 0.985 ], Lowest was [0.4825 0.0841 0.3486 0.9849]
Median for last 10 epochs: [0.5123 0.0885 0.5137 0.985 ], Epochs since improvement 0
  5%|▍         | 23/500 [25:39<8:39:37, 65.36s/it]  5%|▍         | 24/500 [26:59<9:12:59, 69.71s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.42E+07, Train scatter: [0.4855 0.0808 0.3332 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5041 0.0825 0.339  0.985 ], Lowest was [0.4825 0.0825 0.339  0.9849]
Median for last 10 epochs: [0.5041 0.0885 0.3862 0.985 ], Epochs since improvement 0
  5%|▌         | 25/500 [27:52<8:32:54, 64.79s/it]  5%|▌         | 26/500 [29:13<9:08:34, 69.44s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.41E+07, Train scatter: [0.5701 0.0839 0.3415 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5728 0.086  0.3447 0.9849], Lowest was [0.4825 0.0825 0.339  0.9849]
Median for last 10 epochs: [0.5252 0.086  0.3486 0.985 ], Epochs since improvement 2
  5%|▌         | 27/500 [30:06<8:29:20, 64.61s/it]  6%|▌         | 28/500 [31:26<9:05:27, 69.34s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.36E+07, Train scatter: [0.4972 0.0779 0.3364 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.505  0.079  0.3448 0.9851], Lowest was [0.4825 0.079  0.339  0.9849]
Median for last 10 epochs: [0.5252 0.086  0.3448 0.985 ], Epochs since improvement 0
  6%|▌         | 29/500 [32:20<8:26:31, 64.53s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.32E+07, Train scatter: [0.483  0.0755 0.3005 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4968 0.0764 0.3071 0.985 ], Lowest was [0.4825 0.0764 0.3071 0.9849]
Median for last 10 epochs: [0.505  0.0825 0.3447 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [33:47<9:18:41, 71.32s/it]  6%|▌         | 31/500 [34:40<8:35:10, 65.91s/it]  6%|▋         | 32/500 [36:00<9:07:20, 70.17s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.28E+07, Train scatter: [0.4497 0.0748 0.3139 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4604 0.0752 0.3178 0.985 ], Lowest was [0.4604 0.0752 0.3071 0.9849]
Median for last 10 epochs: [0.5041 0.079  0.339  0.985 ], Epochs since improvement 0
  7%|▋         | 33/500 [36:54<8:26:46, 65.11s/it]  7%|▋         | 34/500 [38:15<9:03:26, 69.97s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.24E+07, Train scatter: [0.3477 0.075  0.329  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3585 0.076  0.3337 0.985 ], Lowest was [0.3585 0.0752 0.3071 0.9849]
Median for last 10 epochs: [0.4968 0.0764 0.3337 0.985 ], Epochs since improvement 0
  7%|▋         | 35/500 [39:08<8:24:02, 65.04s/it]  7%|▋         | 36/500 [40:30<9:00:22, 69.88s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.18E+07, Train scatter: [0.3778 0.0719 0.3069 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3834 0.0722 0.3113 0.9851], Lowest was [0.3585 0.0722 0.3071 0.9849]
Median for last 10 epochs: [0.4604 0.076  0.3178 0.985 ], Epochs since improvement 0
  7%|▋         | 37/500 [41:23<8:21:04, 64.93s/it]  8%|▊         | 38/500 [42:44<8:56:45, 69.71s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.70E+07, Train scatter: [0.4669 0.078  0.3293 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4659 0.0787 0.338  0.9849], Lowest was [0.3585 0.0722 0.3071 0.9849]
Median for last 10 epochs: [0.4604 0.076  0.3178 0.985 ], Epochs since improvement 0
  8%|▊         | 39/500 [43:37<8:18:14, 64.85s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.01E+07, Train scatter: [0.5011 0.075  0.3163 0.9947]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5095 0.077  0.324  0.9844], Lowest was [0.3585 0.0722 0.3071 0.9844]
Median for last 10 epochs: [0.4604 0.076  0.324  0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:04<9:08:11, 71.50s/it]  8%|▊         | 41/500 [45:58<8:26:15, 66.18s/it]  8%|▊         | 42/500 [47:19<8:59:22, 70.66s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 5.26E+06, Train scatter: [0.4878 0.0738 0.3108 0.5692]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4933 0.0761 0.3177 0.571 ], Lowest was [0.3585 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.4659 0.0761 0.324  0.9849], Epochs since improvement 0
  9%|▊         | 43/500 [48:13<8:19:01, 65.52s/it]  9%|▉         | 44/500 [49:34<8:54:18, 70.30s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.90E+07, Train scatter: [0.6442 0.1626 0.5373 0.8112]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6426 0.1592 0.5289 0.807 ], Lowest was [0.3585 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.4933 0.077  0.324  0.9844], Epochs since improvement 2
  9%|▉         | 45/500 [50:28<8:14:22, 65.19s/it]  9%|▉         | 46/500 [51:49<8:49:56, 70.04s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 9.30E+06, Train scatter: [0.5435 0.1206 0.4953 0.6496]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5404 0.118  0.4907 0.6451], Lowest was [0.3585 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.5095 0.0787 0.338  0.807 ], Epochs since improvement 4
  9%|▉         | 47/500 [52:42<8:11:24, 65.09s/it] 10%|▉         | 48/500 [54:02<8:44:00, 69.56s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 8.16E+06, Train scatter: [0.8859 0.1022 0.5182 0.6356]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8715 0.1002 0.5095 0.6189], Lowest was [0.3585 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.5404 0.1002 0.4907 0.6451], Epochs since improvement 6
 10%|▉         | 49/500 [54:56<8:06:45, 64.76s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.67E+07, Train scatter: [0.8184 0.1175 0.5437 0.9433]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8104 0.1159 0.5351 0.9349], Lowest was [0.3585 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.6426 0.1159 0.5095 0.6451], Epochs since improvement 8
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [56:23<8:56:14, 71.50s/it] 10%|█         | 51/500 [57:17<8:14:48, 66.12s/it] 10%|█         | 52/500 [58:37<8:45:25, 70.37s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 9.43E+06, Train scatter: [0.591  0.113  0.5435 0.7178]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5905 0.1115 0.5349 0.7073], Lowest was [0.3585 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.6426 0.1159 0.5289 0.7073], Epochs since improvement 10
 11%|█         | 53/500 [59:31<8:06:35, 65.31s/it] 11%|█         | 54/500 [1:00:51<8:38:57, 69.82s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 8.28E+06, Train scatter: [0.5134 0.1085 0.5433 0.6831]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5027 0.1071 0.5347 0.6701], Lowest was [0.3585 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.5905 0.1115 0.5347 0.6701], Epochs since improvement 12
 11%|█         | 55/500 [1:01:45<8:01:43, 64.95s/it] 11%|█         | 56/500 [1:03:05<8:35:07, 69.61s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 7.65E+06, Train scatter: [0.484  0.1059 0.543  0.6586]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4825 0.1048 0.5345 0.6495], Lowest was [0.3585 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.5905 0.1071 0.5347 0.6701], Epochs since improvement 14
 11%|█▏        | 57/500 [1:03:59<7:58:17, 64.78s/it] 12%|█▏        | 58/500 [1:05:19<8:31:48, 69.48s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 7.24E+06, Train scatter: [0.4689 0.1026 0.5425 0.6228]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4618 0.1019 0.534  0.6163], Lowest was [0.3585 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.5027 0.1071 0.5347 0.6701], Epochs since improvement 16
 12%|█▏        | 59/500 [1:06:13<7:55:36, 64.71s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 6.67E+06, Train scatter: [0.4176 0.099  0.5418 0.5998]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4245 0.0988 0.5334 0.5958], Lowest was [0.3585 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.4825 0.1048 0.5345 0.6495], Epochs since improvement 18
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:07:40<8:43:59, 71.45s/it] 12%|█▏        | 61/500 [1:08:33<8:03:33, 66.09s/it] 12%|█▏        | 62/500 [1:09:54<8:35:01, 70.55s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 6.09E+06, Train scatter: [0.4131 0.0956 0.5407 0.6078]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4091 0.0956 0.5323 0.6039], Lowest was [0.3585 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.4618 0.1019 0.534  0.6163], Epochs since improvement 20
 13%|█▎        | 63/500 [1:10:48<7:56:46, 65.46s/it] 13%|█▎        | 64/500 [1:12:08<8:27:55, 69.90s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 5.63E+06, Train scatter: [0.3457 0.0923 0.5378 0.5872]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3493 0.0924 0.5295 0.5841], Lowest was [0.3493 0.0722 0.3071 0.571 ]
Median for last 10 epochs: [0.4245 0.0988 0.5334 0.6039], Epochs since improvement 0
 13%|█▎        | 65/500 [1:13:02<7:51:02, 64.97s/it] 13%|█▎        | 66/500 [1:14:22<8:24:01, 69.68s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 5.34E+06, Train scatter: [0.3953 0.0882 0.507  0.5558]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3909 0.0885 0.501  0.5548], Lowest was [0.3493 0.0722 0.3071 0.5548]
Median for last 10 epochs: [0.4091 0.0956 0.5323 0.5958], Epochs since improvement 0
 13%|█▎        | 67/500 [1:15:16<7:47:46, 64.82s/it] 14%|█▎        | 68/500 [1:16:36<8:20:30, 69.52s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 4.53E+06, Train scatter: [0.4337 0.0894 0.4137 0.5796]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.429  0.0895 0.4188 0.575 ], Lowest was [0.3493 0.0722 0.3071 0.5548]
Median for last 10 epochs: [0.4091 0.0924 0.5295 0.5841], Epochs since improvement 2
 14%|█▍        | 69/500 [1:17:30<7:44:26, 64.66s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 4.11E+06, Train scatter: [0.3981 0.0857 0.4002 0.5472]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4069 0.0858 0.4033 0.5439], Lowest was [0.3493 0.0722 0.3071 0.5439]
Median for last 10 epochs: [0.4069 0.0895 0.501  0.575 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:18:57<8:33:13, 71.61s/it] 14%|█▍        | 71/500 [1:19:51<7:52:57, 66.15s/it] 14%|█▍        | 72/500 [1:21:13<8:25:21, 70.84s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 4.63E+06, Train scatter: [0.3302 0.0826 0.3739 0.5407]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3324 0.0835 0.379  0.5389], Lowest was [0.3324 0.0722 0.3071 0.5389]
Median for last 10 epochs: [0.3909 0.0885 0.4188 0.5548], Epochs since improvement 0
 15%|█▍        | 73/500 [1:22:06<7:47:05, 65.63s/it] 15%|█▍        | 74/500 [1:23:27<8:18:48, 70.26s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.79E+06, Train scatter: [0.341  0.0834 0.3644 0.5409]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3401 0.0838 0.3728 0.5358], Lowest was [0.3324 0.0722 0.3071 0.5358]
Median for last 10 epochs: [0.3909 0.0858 0.4033 0.5439], Epochs since improvement 0
 15%|█▌        | 75/500 [1:24:20<7:41:46, 65.19s/it] 15%|█▌        | 76/500 [1:25:41<8:13:41, 69.86s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 4.33E+06, Train scatter: [0.3408 0.0815 0.3674 0.5388]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3426 0.0824 0.3728 0.5388], Lowest was [0.3324 0.0722 0.3071 0.5358]
Median for last 10 epochs: [0.3426 0.0838 0.379  0.5389], Epochs since improvement 2
 15%|█▌        | 77/500 [1:26:35<7:37:56, 64.96s/it] 16%|█▌        | 78/500 [1:27:56<8:11:42, 69.91s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.64E+06, Train scatter: [0.3935 0.0801 0.3611 0.5349]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3911 0.0806 0.365  0.5358], Lowest was [0.3324 0.0722 0.3071 0.5358]
Median for last 10 epochs: [0.3426 0.0835 0.3728 0.5388], Epochs since improvement 4
 16%|█▌        | 79/500 [1:28:50<7:35:37, 64.93s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 3.41E+06, Train scatter: [0.2885 0.0767 0.3543 0.5077]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2914 0.0776 0.3617 0.5052], Lowest was [0.2914 0.0722 0.3071 0.5052]
Median for last 10 epochs: [0.3401 0.0824 0.3728 0.5358], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:30:18<8:24:03, 72.01s/it] 16%|█▌        | 81/500 [1:31:11<7:43:53, 66.43s/it] 16%|█▋        | 82/500 [1:32:33<8:13:37, 70.85s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 3.17E+06, Train scatter: [0.296  0.0776 0.3327 0.5008]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3023 0.0786 0.3404 0.5015], Lowest was [0.2914 0.0722 0.3071 0.5015]
Median for last 10 epochs: [0.3401 0.0806 0.365  0.5358], Epochs since improvement 0
 17%|█▋        | 83/500 [1:33:26<7:36:03, 65.62s/it] 17%|█▋        | 84/500 [1:34:47<8:06:52, 70.22s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 3.14E+06, Train scatter: [0.2981 0.076  0.3339 0.5168]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3021 0.0766 0.3404 0.5207], Lowest was [0.2914 0.0722 0.3071 0.5015]
Median for last 10 epochs: [0.3023 0.0786 0.3617 0.5207], Epochs since improvement 2
 17%|█▋        | 85/500 [1:35:40<7:30:34, 65.14s/it] 17%|█▋        | 86/500 [1:37:02<8:03:18, 70.05s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.97E+06, Train scatter: [0.2861 0.0732 0.3179 0.4952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2937 0.0739 0.3227 0.4985], Lowest was [0.2914 0.0722 0.3071 0.4985]
Median for last 10 epochs: [0.3021 0.0776 0.3404 0.5052], Epochs since improvement 0
 17%|█▋        | 87/500 [1:37:55<7:27:24, 65.00s/it] 18%|█▊        | 88/500 [1:39:16<7:59:49, 69.88s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.72E+06, Train scatter: [0.2943 0.0696 0.3167 0.491 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2917 0.0699 0.3218 0.4939], Lowest was [0.2914 0.0699 0.3071 0.4939]
Median for last 10 epochs: [0.2937 0.0766 0.3404 0.5015], Epochs since improvement 0
 18%|█▊        | 89/500 [1:40:10<7:24:35, 64.90s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.58E+06, Train scatter: [0.2619 0.068  0.3088 0.4848]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2622 0.0686 0.3131 0.4814], Lowest was [0.2622 0.0686 0.3071 0.4814]
Median for last 10 epochs: [0.2937 0.0739 0.3227 0.4985], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:41:38<8:11:20, 71.90s/it] 18%|█▊        | 91/500 [1:42:31<7:32:11, 66.34s/it] 18%|█▊        | 92/500 [1:43:51<7:59:21, 70.49s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.51E+06, Train scatter: [0.339  0.0665 0.3248 0.4888]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3376 0.0667 0.3254 0.483 ], Lowest was [0.2622 0.0667 0.3071 0.4814]
Median for last 10 epochs: [0.2937 0.0699 0.3227 0.4939], Epochs since improvement 0
 19%|█▊        | 93/500 [1:44:45<7:23:34, 65.39s/it] 19%|█▉        | 94/500 [1:46:05<7:52:56, 69.89s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.46E+06, Train scatter: [0.242  0.0654 0.3078 0.4758]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2463 0.0661 0.3133 0.475 ], Lowest was [0.2463 0.0661 0.3071 0.475 ]
Median for last 10 epochs: [0.2917 0.0686 0.3218 0.483 ], Epochs since improvement 0
 19%|█▉        | 95/500 [1:46:58<7:18:02, 64.89s/it] 19%|█▉        | 96/500 [1:48:19<7:48:37, 69.60s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.39E+06, Train scatter: [0.268  0.0668 0.2981 0.4691]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.272  0.0673 0.3045 0.4702], Lowest was [0.2463 0.0661 0.3045 0.4702]
Median for last 10 epochs: [0.272  0.0673 0.3133 0.4814], Epochs since improvement 0
 19%|█▉        | 97/500 [1:49:12<7:14:30, 64.69s/it] 20%|█▉        | 98/500 [1:50:33<7:45:56, 69.54s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 6.36E+06, Train scatter: [0.8803 0.16   0.4784 0.5698]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8651 0.1576 0.4893 0.5605], Lowest was [0.2463 0.0661 0.3045 0.4702]
Median for last 10 epochs: [0.272  0.0673 0.3133 0.4814], Epochs since improvement 2
 20%|█▉        | 99/500 [1:51:26<7:12:02, 64.64s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 2.97E+06, Train scatter: [0.8694 0.1527 0.411  0.5323]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8524 0.149  0.411  0.5392], Lowest was [0.2463 0.0661 0.3045 0.4702]
Median for last 10 epochs: [0.3376 0.0673 0.3254 0.483 ], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:52:55<7:58:19, 71.75s/it] 20%|██        | 101/500 [1:53:48<7:20:30, 66.24s/it] 20%|██        | 102/500 [1:55:09<7:48:38, 70.65s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 2.66E+06, Train scatter: [0.8328 0.1133 0.4305 0.4875]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8199 0.1111 0.4368 0.4865], Lowest was [0.2463 0.0661 0.3045 0.4702]
Median for last 10 epochs: [0.8199 0.1111 0.411  0.4865], Epochs since improvement 6
 21%|██        | 103/500 [1:56:02<7:13:18, 65.49s/it] 21%|██        | 104/500 [1:57:23<7:41:49, 69.97s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 2.19E+06, Train scatter: [0.5911 0.0813 0.3353 0.4858]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5786 0.083  0.3422 0.4867], Lowest was [0.2463 0.0661 0.3045 0.4702]
Median for last 10 epochs: [0.8199 0.1111 0.411  0.4867], Epochs since improvement 8
 21%|██        | 105/500 [1:58:16<7:07:32, 64.94s/it] 21%|██        | 106/500 [1:59:37<7:37:49, 69.72s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 2.06E+06, Train scatter: [0.4682 0.0745 0.3208 0.473 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4612 0.0747 0.3254 0.4749], Lowest was [0.2463 0.0661 0.3045 0.4702]
Median for last 10 epochs: [0.8199 0.1111 0.411  0.4867], Epochs since improvement 10
 21%|██▏       | 107/500 [2:00:30<7:04:09, 64.76s/it] 22%|██▏       | 108/500 [2:01:51<7:35:10, 69.67s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 2.00E+06, Train scatter: [0.388  0.074  0.3535 0.4754]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3815 0.074  0.3479 0.4758], Lowest was [0.2463 0.0661 0.3045 0.4702]
Median for last 10 epochs: [0.5786 0.083  0.3479 0.4865], Epochs since improvement 12
 22%|██▏       | 109/500 [2:02:45<7:02:03, 64.77s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 1.88E+06, Train scatter: [0.5669 0.0918 0.333  0.4978]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.539  0.0953 0.338  0.5027], Lowest was [0.2463 0.0661 0.3045 0.4702]
Median for last 10 epochs: [0.539  0.083  0.3422 0.4865], Epochs since improvement 14
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:04:15<7:50:33, 72.39s/it] 22%|██▏       | 111/500 [2:05:08<7:12:18, 66.68s/it] 22%|██▏       | 112/500 [2:06:29<7:39:45, 71.10s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.84E+06, Train scatter: [0.3658 0.0711 0.31   0.4604]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4434 0.0711 0.3141 0.4581], Lowest was [0.2463 0.0661 0.3045 0.4581]
Median for last 10 epochs: [0.4612 0.0747 0.338  0.4758], Epochs since improvement 0
 23%|██▎       | 113/500 [2:07:23<7:04:06, 65.75s/it] 23%|██▎       | 114/500 [2:08:44<7:33:12, 70.45s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.78E+06, Train scatter: [0.4224 0.0691 0.3108 0.4549]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4044 0.0692 0.3145 0.4552], Lowest was [0.2463 0.0661 0.3045 0.4552]
Median for last 10 epochs: [0.4434 0.074  0.3254 0.4749], Epochs since improvement 0
 23%|██▎       | 115/500 [2:09:37<6:59:02, 65.30s/it] 23%|██▎       | 116/500 [2:10:59<7:28:08, 70.02s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.76E+06, Train scatter: [0.4601 0.0656 0.3067 0.4565]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4403 0.0657 0.3106 0.4547], Lowest was [0.2463 0.0657 0.3045 0.4547]
Median for last 10 epochs: [0.4403 0.0711 0.3145 0.4581], Epochs since improvement 0
 23%|██▎       | 117/500 [2:11:52<6:55:10, 65.04s/it] 24%|██▎       | 118/500 [2:13:13<7:25:03, 69.90s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.57E+06, Train scatter: [0.4043 0.0608 0.3032 0.4495]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3935 0.0614 0.3058 0.4526], Lowest was [0.2463 0.0614 0.3045 0.4526]
Median for last 10 epochs: [0.4403 0.0692 0.3141 0.4552], Epochs since improvement 0
 24%|██▍       | 119/500 [2:14:07<6:52:28, 64.96s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.60E+06, Train scatter: [0.4827 0.0633 0.3182 0.4569]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.465  0.0641 0.32   0.4561], Lowest was [0.2463 0.0614 0.3045 0.4526]
Median for last 10 epochs: [0.4403 0.0657 0.3141 0.4552], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 24%|██▍       | 120/500 [2:15:34<7:34:29, 71.76s/it] 24%|██▍       | 121/500 [2:16:28<6:59:07, 66.35s/it] 24%|██▍       | 122/500 [2:17:49<7:25:00, 70.64s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 1.55E+06, Train scatter: [0.489  0.0708 0.3156 0.4505]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.469  0.0711 0.3178 0.4518], Lowest was [0.2463 0.0614 0.3045 0.4518]
Median for last 10 epochs: [0.4403 0.0657 0.3145 0.4547], Epochs since improvement 0
 25%|██▍       | 123/500 [2:18:42<6:51:14, 65.45s/it] 25%|██▍       | 124/500 [2:20:03<7:18:32, 69.98s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.48E+06, Train scatter: [0.3209 0.0708 0.3059 0.448 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3259 0.0715 0.309  0.4478], Lowest was [0.2463 0.0614 0.3045 0.4478]
Median for last 10 epochs: [0.4403 0.0657 0.3106 0.4526], Epochs since improvement 0
 25%|██▌       | 125/500 [2:20:56<6:46:05, 64.98s/it] 25%|██▌       | 126/500 [2:22:16<7:14:17, 69.67s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.37E+06, Train scatter: [0.393  0.0647 0.3032 0.4417]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3827 0.0653 0.3069 0.4444], Lowest was [0.2463 0.0614 0.3045 0.4444]
Median for last 10 epochs: [0.3935 0.0653 0.309  0.4518], Epochs since improvement 0
 25%|██▌       | 127/500 [2:23:10<6:42:36, 64.76s/it] 26%|██▌       | 128/500 [2:24:31<7:12:23, 69.74s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 1.20E+06, Train scatter: [0.3945 0.0598 0.2963 0.4349]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3829 0.0595 0.2969 0.4335], Lowest was [0.2463 0.0595 0.2969 0.4335]
Median for last 10 epochs: [0.3829 0.0653 0.309  0.4478], Epochs since improvement 0
 26%|██▌       | 129/500 [2:25:25<6:40:59, 64.85s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 1.22E+06, Train scatter: [0.4391 0.0585 0.3057 0.444 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.417  0.0575 0.3037 0.4423], Lowest was [0.2463 0.0575 0.2969 0.4335]
Median for last 10 epochs: [0.3829 0.0653 0.3069 0.4444], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 26%|██▌       | 130/500 [2:26:53<7:23:26, 71.91s/it] 26%|██▌       | 131/500 [2:27:46<6:48:04, 66.35s/it] 26%|██▋       | 132/500 [2:29:08<7:15:22, 70.98s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 1.18E+06, Train scatter: [0.5654 0.0568 0.2979 0.4338]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5413 0.0563 0.2973 0.4324], Lowest was [0.2463 0.0563 0.2969 0.4324]
Median for last 10 epochs: [0.3829 0.0595 0.3037 0.4423], Epochs since improvement 0
 27%|██▋       | 133/500 [2:30:01<6:41:30, 65.64s/it] 27%|██▋       | 134/500 [2:31:23<7:09:50, 70.47s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 1.17E+06, Train scatter: [0.483  0.0552 0.2953 0.4374]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4646 0.0548 0.2963 0.4342], Lowest was [0.2463 0.0548 0.2963 0.4324]
Median for last 10 epochs: [0.417  0.0575 0.2973 0.4342], Epochs since improvement 0
 27%|██▋       | 135/500 [2:32:16<6:37:31, 65.35s/it] 27%|██▋       | 136/500 [2:33:37<7:04:54, 70.04s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 1.11E+06, Train scatter: [0.4003 0.0537 0.2894 0.4308]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3901 0.0532 0.2888 0.4334], Lowest was [0.2463 0.0532 0.2888 0.4324]
Median for last 10 epochs: [0.417  0.0563 0.2969 0.4335], Epochs since improvement 0
 27%|██▋       | 137/500 [2:34:31<6:33:13, 65.00s/it] 28%|██▊       | 138/500 [2:35:52<7:01:48, 69.91s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: 1.00E+06, Train scatter: [0.3861 0.0536 0.2879 0.435 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3742 0.0531 0.2873 0.4304], Lowest was [0.2463 0.0531 0.2873 0.4304]
Median for last 10 epochs: [0.417  0.0548 0.2963 0.4334], Epochs since improvement 0
 28%|██▊       | 139/500 [2:36:45<6:30:31, 64.91s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: 9.70E+05, Train scatter: [0.3161 0.053  0.3029 0.4291]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3118 0.0531 0.3029 0.4279], Lowest was [0.2463 0.0531 0.2873 0.4279]
Median for last 10 epochs: [0.3901 0.0532 0.2963 0.4324], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 28%|██▊       | 140/500 [2:38:13<7:10:06, 71.68s/it] 28%|██▊       | 141/500 [2:39:06<6:35:55, 66.17s/it] 28%|██▊       | 142/500 [2:40:27<7:00:50, 70.53s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: 9.81E+05, Train scatter: [0.3693 0.0531 0.2912 0.4344]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3529 0.0527 0.2909 0.426 ], Lowest was [0.2463 0.0527 0.2873 0.426 ]
Median for last 10 epochs: [0.3742 0.0531 0.2909 0.4304], Epochs since improvement 0
 29%|██▊       | 143/500 [2:41:20<6:29:02, 65.38s/it] 29%|██▉       | 144/500 [2:42:42<6:57:18, 70.33s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 8.81E+05, Train scatter: [0.3858 0.0526 0.2979 0.4307]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3763 0.0522 0.2966 0.4294], Lowest was [0.2463 0.0522 0.2873 0.426 ]
Median for last 10 epochs: [0.3742 0.0531 0.2909 0.4294], Epochs since improvement 0
 29%|██▉       | 145/500 [2:43:35<6:26:04, 65.25s/it] 29%|██▉       | 146/500 [2:44:57<6:53:26, 70.07s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 8.54E+05, Train scatter: [0.2726 0.0531 0.2932 0.4274]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2742 0.0521 0.2927 0.4176], Lowest was [0.2463 0.0521 0.2873 0.4176]
Median for last 10 epochs: [0.3529 0.0527 0.2927 0.4279], Epochs since improvement 0
 29%|██▉       | 147/500 [2:45:50<6:22:43, 65.05s/it] 30%|██▉       | 148/500 [2:47:11<6:49:12, 69.75s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 7.94E+05, Train scatter: [0.351  0.0518 0.3237 0.4221]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3412 0.0517 0.3254 0.422 ], Lowest was [0.2463 0.0517 0.2873 0.4176]
Median for last 10 epochs: [0.3412 0.0522 0.2966 0.426 ], Epochs since improvement 0
 30%|██▉       | 149/500 [2:48:04<6:19:05, 64.80s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 8.42E+05, Train scatter: [0.465  0.0564 0.296  0.4278]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.449  0.0555 0.2947 0.4226], Lowest was [0.2463 0.0517 0.2873 0.4176]
Median for last 10 epochs: [0.3529 0.0522 0.2947 0.4226], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 30%|███       | 150/500 [2:49:31<6:57:37, 71.59s/it] 30%|███       | 151/500 [2:50:25<6:24:49, 66.16s/it] 30%|███       | 152/500 [2:51:46<6:50:17, 70.74s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 6.81E+05, Train scatter: [0.3834 0.0544 0.2854 0.4374]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3721 0.0543 0.2847 0.4381], Lowest was [0.2463 0.0517 0.2847 0.4176]
Median for last 10 epochs: [0.3721 0.0522 0.2947 0.4226], Epochs since improvement 0
 31%|███       | 153/500 [2:52:40<6:18:43, 65.49s/it] 31%|███       | 154/500 [2:54:02<6:46:54, 70.56s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 6.18E+05, Train scatter: [0.342  0.0513 0.2832 0.4163]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.334  0.0509 0.2834 0.4133], Lowest was [0.2463 0.0509 0.2834 0.4133]
Median for last 10 epochs: [0.3412 0.0521 0.2927 0.422 ], Epochs since improvement 0
 31%|███       | 155/500 [2:54:55<6:15:52, 65.37s/it] 31%|███       | 156/500 [2:56:17<6:42:25, 70.19s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 5.73E+05, Train scatter: [0.4879 0.0493 0.2799 0.416 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4689 0.049  0.2791 0.4098], Lowest was [0.2463 0.049  0.2791 0.4098]
Median for last 10 epochs: [0.3721 0.0517 0.2847 0.422 ], Epochs since improvement 0
 31%|███▏      | 157/500 [2:57:10<6:12:23, 65.14s/it] 32%|███▏      | 158/500 [2:58:31<6:37:46, 69.78s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 5.31E+05, Train scatter: [0.4295 0.0524 0.3034 0.4225]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4141 0.0515 0.3019 0.4191], Lowest was [0.2463 0.049  0.2791 0.4098]
Median for last 10 epochs: [0.4141 0.0515 0.2847 0.4191], Epochs since improvement 2
 32%|███▏      | 159/500 [2:59:24<6:08:45, 64.88s/it]Epoch: 160 done with learning rate 9.04E-03, Train loss: 4.40E+05, Train scatter: [0.3637 0.0507 0.2966 0.4317]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3536 0.0503 0.2962 0.4231], Lowest was [0.2463 0.049  0.2791 0.4098]
Median for last 10 epochs: [0.3721 0.0509 0.2847 0.4191], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 32%|███▏      | 160/500 [3:00:52<6:47:18, 71.88s/it] 32%|███▏      | 161/500 [3:01:46<6:14:50, 66.34s/it] 32%|███▏      | 162/500 [3:03:07<6:39:35, 70.93s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: 3.44E+05, Train scatter: [0.2638 0.0475 0.283  0.4094]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2637 0.0473 0.2827 0.4075], Lowest was [0.2463 0.0473 0.2791 0.4075]
Median for last 10 epochs: [0.3536 0.0503 0.2834 0.4133], Epochs since improvement 0
 33%|███▎      | 163/500 [3:04:01<6:08:48, 65.66s/it] 33%|███▎      | 164/500 [3:05:22<6:33:22, 70.24s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: 2.78E+05, Train scatter: [0.3978 0.047  0.2797 0.4142]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3835 0.0467 0.2796 0.4136], Lowest was [0.2463 0.0467 0.2791 0.4075]
Median for last 10 epochs: [0.3835 0.049  0.2827 0.4136], Epochs since improvement 0
 33%|███▎      | 165/500 [3:06:15<6:03:25, 65.09s/it] 33%|███▎      | 166/500 [3:07:35<6:28:09, 69.73s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: 1.90E+05, Train scatter: [0.3498 0.0471 0.2766 0.4087]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3392 0.0465 0.2785 0.4025], Lowest was [0.2463 0.0465 0.2785 0.4025]
Median for last 10 epochs: [0.3536 0.0473 0.2827 0.4136], Epochs since improvement 0
 33%|███▎      | 167/500 [3:08:28<5:58:42, 64.63s/it] 34%|███▎      | 168/500 [3:09:48<6:23:42, 69.34s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: 8.60E+04, Train scatter: [0.3795 0.0467 0.2685 0.4065]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3668 0.046  0.2693 0.4005], Lowest was [0.2463 0.046  0.2693 0.4005]
Median for last 10 epochs: [0.3536 0.0467 0.2796 0.4075], Epochs since improvement 0
 34%|███▍      | 169/500 [3:10:41<5:55:05, 64.37s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -3.37E+02, Train scatter: [0.3408 0.0478 0.2684 0.413 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3326 0.0479 0.2685 0.4121], Lowest was [0.2463 0.046  0.2685 0.4005]
Median for last 10 epochs: [0.3392 0.0467 0.2785 0.4075], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 34%|███▍      | 170/500 [3:12:07<6:29:26, 70.81s/it] 34%|███▍      | 171/500 [3:13:00<5:58:43, 65.42s/it] 34%|███▍      | 172/500 [3:14:20<6:21:08, 69.72s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -5.32E+04, Train scatter: [0.3459 0.0451 0.261  0.4076]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3355 0.0447 0.2632 0.3996], Lowest was [0.2463 0.0447 0.2632 0.3996]
Median for last 10 epochs: [0.3392 0.0465 0.2693 0.4025], Epochs since improvement 0
 35%|███▍      | 173/500 [3:15:12<5:52:17, 64.64s/it] 35%|███▍      | 174/500 [3:16:32<6:16:18, 69.26s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -1.21E+05, Train scatter: [0.442  0.0453 0.2753 0.4032]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4269 0.0446 0.2756 0.3973], Lowest was [0.2463 0.0446 0.2632 0.3973]
Median for last 10 epochs: [0.3392 0.046  0.2693 0.4005], Epochs since improvement 0
 35%|███▌      | 175/500 [3:17:25<5:48:41, 64.37s/it] 35%|███▌      | 176/500 [3:18:45<6:12:53, 69.06s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -1.66E+05, Train scatter: [0.4044 0.0443 0.2659 0.4019]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3911 0.0439 0.2712 0.398 ], Lowest was [0.2463 0.0439 0.2632 0.3973]
Median for last 10 epochs: [0.3668 0.0447 0.2693 0.3996], Epochs since improvement 0
 35%|███▌      | 177/500 [3:19:38<5:45:27, 64.17s/it] 36%|███▌      | 178/500 [3:20:58<6:10:03, 68.96s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -2.12E+05, Train scatter: [0.391  0.0461 0.2642 0.4044]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3791 0.0459 0.2666 0.3975], Lowest was [0.2463 0.0439 0.2632 0.3973]
Median for last 10 epochs: [0.3791 0.0447 0.2685 0.398 ], Epochs since improvement 2
 36%|███▌      | 179/500 [3:21:51<5:43:02, 64.12s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -2.46E+05, Train scatter: [0.3727 0.0456 0.2583 0.4072]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3608 0.0456 0.2597 0.4008], Lowest was [0.2463 0.0439 0.2597 0.3973]
Median for last 10 epochs: [0.3791 0.0447 0.2666 0.398 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 36%|███▌      | 180/500 [3:23:19<6:20:17, 71.30s/it] 36%|███▌      | 181/500 [3:24:12<5:49:34, 65.75s/it] 36%|███▋      | 182/500 [3:25:32<6:11:23, 70.07s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -2.66E+05, Train scatter: [0.3751 0.048  0.2922 0.4166]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3641 0.0473 0.2959 0.4064], Lowest was [0.2463 0.0439 0.2597 0.3973]
Median for last 10 epochs: [0.3791 0.0456 0.2712 0.398 ], Epochs since improvement 2
 37%|███▋      | 183/500 [3:26:25<5:42:48, 64.88s/it] 37%|███▋      | 184/500 [3:27:44<6:04:38, 69.23s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -2.94E+05, Train scatter: [0.3997 0.0446 0.2499 0.4058]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3873 0.0444 0.2524 0.4017], Lowest was [0.2463 0.0439 0.2524 0.3973]
Median for last 10 epochs: [0.3791 0.0456 0.2666 0.4008], Epochs since improvement 0
 37%|███▋      | 185/500 [3:28:37<5:37:28, 64.28s/it] 37%|███▋      | 186/500 [3:29:56<6:00:11, 68.83s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -3.02E+05, Train scatter: [0.1752 0.0433 0.2439 0.4022]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1808 0.0427 0.2453 0.3958], Lowest was [0.1808 0.0427 0.2453 0.3958]
Median for last 10 epochs: [0.3641 0.0456 0.2597 0.4008], Epochs since improvement 0
 37%|███▋      | 187/500 [3:30:49<5:34:07, 64.05s/it] 38%|███▊      | 188/500 [3:32:10<5:59:21, 69.11s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -3.20E+05, Train scatter: [0.5286 0.0473 0.2649 0.4112]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5193 0.0462 0.2657 0.4049], Lowest was [0.1808 0.0427 0.2453 0.3958]
Median for last 10 epochs: [0.3641 0.0456 0.2597 0.4017], Epochs since improvement 2
 38%|███▊      | 189/500 [3:33:03<5:32:47, 64.20s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -3.35E+05, Train scatter: [0.3743 0.0441 0.245  0.4029]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3641 0.0434 0.2461 0.4002], Lowest was [0.1808 0.0427 0.2453 0.3958]
Median for last 10 epochs: [0.3641 0.0444 0.2524 0.4017], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 38%|███▊      | 190/500 [3:34:32<6:09:28, 71.51s/it] 38%|███▊      | 191/500 [3:35:24<5:39:30, 65.92s/it] 38%|███▊      | 192/500 [3:36:45<6:00:48, 70.29s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -3.28E+05, Train scatter: [0.4373 0.0677 0.311  0.4636]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4272 0.068  0.3104 0.4591], Lowest was [0.1808 0.0427 0.2453 0.3958]
Median for last 10 epochs: [0.3873 0.0444 0.2524 0.4017], Epochs since improvement 6
 39%|███▊      | 193/500 [3:37:38<5:32:50, 65.05s/it] 39%|███▉      | 194/500 [3:38:58<5:54:45, 69.56s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -3.58E+05, Train scatter: [0.3191 0.0424 0.2313 0.4037]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3105 0.0421 0.2339 0.3996], Lowest was [0.1808 0.0421 0.2339 0.3958]
Median for last 10 epochs: [0.3641 0.0434 0.2461 0.4002], Epochs since improvement 0
 39%|███▉      | 195/500 [3:39:51<5:27:56, 64.51s/it] 39%|███▉      | 196/500 [3:41:10<5:49:47, 69.04s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -3.61E+05, Train scatter: [0.3853 0.0496 0.2459 0.4234]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3731 0.0496 0.2493 0.4225], Lowest was [0.1808 0.0421 0.2339 0.3958]
Median for last 10 epochs: [0.3731 0.0462 0.2493 0.4049], Epochs since improvement 2
 39%|███▉      | 197/500 [3:42:03<5:24:23, 64.24s/it] 40%|███▉      | 198/500 [3:43:23<5:47:28, 69.03s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -3.57E+05, Train scatter: [0.3903 0.0419 0.2301 0.4011]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3783 0.0415 0.2321 0.3958], Lowest was [0.1808 0.0415 0.2321 0.3958]
Median for last 10 epochs: [0.3731 0.0434 0.2461 0.4002], Epochs since improvement 0
 40%|███▉      | 199/500 [3:44:16<5:21:54, 64.17s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -3.66E+05, Train scatter: [0.4138 0.0422 0.2357 0.4152]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4034 0.0421 0.2368 0.412 ], Lowest was [0.1808 0.0415 0.2321 0.3958]
Median for last 10 epochs: [0.3783 0.0421 0.2368 0.412 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 40%|████      | 200/500 [3:45:44<5:55:38, 71.13s/it] 40%|████      | 201/500 [3:46:36<5:27:10, 65.65s/it] 40%|████      | 202/500 [3:47:57<5:47:49, 70.03s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -3.78E+05, Train scatter: [0.1832 0.0419 0.2322 0.4041]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1826 0.0416 0.2355 0.4002], Lowest was [0.1808 0.0415 0.2321 0.3958]
Median for last 10 epochs: [0.3731 0.0421 0.2355 0.4002], Epochs since improvement 4
 41%|████      | 203/500 [3:48:50<5:21:08, 64.88s/it] 41%|████      | 204/500 [3:50:10<5:43:22, 69.60s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -3.91E+05, Train scatter: [0.371  0.042  0.2278 0.4031]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3614 0.0417 0.2302 0.3979], Lowest was [0.1808 0.0415 0.2302 0.3958]
Median for last 10 epochs: [0.3731 0.0417 0.2355 0.4002], Epochs since improvement 0
 41%|████      | 205/500 [3:51:03<5:17:28, 64.57s/it] 41%|████      | 206/500 [3:52:23<5:38:46, 69.14s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -3.84E+05, Train scatter: [0.4151 0.0413 0.2305 0.4118]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4011 0.0409 0.2328 0.4052], Lowest was [0.1808 0.0409 0.2302 0.3958]
Median for last 10 epochs: [0.3783 0.0416 0.2328 0.4002], Epochs since improvement 0
 41%|████▏     | 207/500 [3:53:16<5:13:45, 64.25s/it] 42%|████▏     | 208/500 [3:54:36<5:35:29, 68.94s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -3.79E+05, Train scatter: [0.3354 0.0415 0.2254 0.4063]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3275 0.0408 0.2283 0.3989], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.3614 0.0416 0.2328 0.4002], Epochs since improvement 0
 42%|████▏     | 209/500 [3:55:28<5:11:04, 64.14s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -2.55E+05, Train scatter: [0.936  0.1755 0.5441 0.9907]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9203 0.1716 0.5355 0.9804], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.3614 0.0416 0.2328 0.4002], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 42%|████▏     | 210/500 [3:56:55<5:42:08, 70.79s/it] 42%|████▏     | 211/500 [3:57:48<5:14:58, 65.39s/it] 42%|████▏     | 212/500 [3:59:08<5:35:17, 69.85s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -8.94E+04, Train scatter: [0.6228 0.1079 0.528  0.6848]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6164 0.1057 0.5197 0.6736], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.4011 0.0417 0.2328 0.4052], Epochs since improvement 4
 43%|████▎     | 213/500 [4:00:01<5:09:34, 64.72s/it] 43%|████▎     | 214/500 [4:01:21<5:30:51, 69.41s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: -1.75E+05, Train scatter: [0.3793 0.0987 0.4512 0.6068]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3803 0.0976 0.4475 0.5977], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.4011 0.0976 0.4475 0.5977], Epochs since improvement 6
 43%|████▎     | 215/500 [4:02:14<5:06:18, 64.49s/it] 43%|████▎     | 216/500 [4:03:33<5:26:15, 68.93s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -1.80E+05, Train scatter: [0.4272 0.0769 0.4047 0.5668]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4168 0.0763 0.4001 0.5569], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.4168 0.0976 0.4475 0.5977], Epochs since improvement 8
 43%|████▎     | 217/500 [4:04:26<5:02:26, 64.12s/it] 44%|████▎     | 218/500 [4:05:46<5:23:04, 68.74s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -2.38E+05, Train scatter: [0.3594 0.0669 0.3653 0.5286]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3404 0.0662 0.3622 0.5172], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.4168 0.0976 0.4475 0.5977], Epochs since improvement 10
 44%|████▍     | 219/500 [4:06:38<4:59:31, 63.96s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -8.89E+04, Train scatter: [0.4285 0.0942 0.4671 0.5848]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4274 0.0925 0.4611 0.5829], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.4168 0.0925 0.4475 0.5829], Epochs since improvement 12
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 44%|████▍     | 220/500 [4:08:06<5:31:02, 70.94s/it] 44%|████▍     | 221/500 [4:08:59<5:04:33, 65.50s/it] 44%|████▍     | 222/500 [4:10:18<5:23:07, 69.74s/it]Epoch: 222 done with learning rate 7.33E-03, Train loss: -2.20E+05, Train scatter: [0.4628 0.081  0.4602 0.5415]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4541 0.0784 0.4493 0.5323], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.4168 0.0784 0.4475 0.5569], Epochs since improvement 14
 45%|████▍     | 223/500 [4:11:11<4:58:42, 64.70s/it] 45%|████▍     | 224/500 [4:12:32<5:19:47, 69.52s/it]Epoch: 224 done with learning rate 7.26E-03, Train loss: -2.37E+05, Train scatter: [0.2814 0.0671 0.3445 0.5129]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2768 0.0663 0.3404 0.5057], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.4168 0.0763 0.4001 0.5323], Epochs since improvement 16
 45%|████▌     | 225/500 [4:13:25<4:55:37, 64.50s/it] 45%|████▌     | 226/500 [4:14:44<5:15:27, 69.08s/it]Epoch: 226 done with learning rate 7.20E-03, Train loss: -2.72E+05, Train scatter: [0.2115 0.0659 0.4214 0.5034]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2157 0.0643 0.4138 0.4935], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.3404 0.0663 0.4138 0.5172], Epochs since improvement 18
 45%|████▌     | 227/500 [4:15:37<4:52:14, 64.23s/it] 46%|████▌     | 228/500 [4:16:57<5:12:01, 68.83s/it]Epoch: 228 done with learning rate 7.13E-03, Train loss: -2.94E+05, Train scatter: [0.2863 0.0656 0.4567 0.5029]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2808 0.0638 0.4492 0.4945], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.2808 0.0663 0.4492 0.5057], Epochs since improvement 20
 46%|████▌     | 229/500 [4:17:50<4:49:19, 64.06s/it]Epoch: 230 done with learning rate 7.06E-03, Train loss: -2.91E+05, Train scatter: [0.2597 0.0575 0.4111 0.4824]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2564 0.0571 0.4031 0.4775], Lowest was [0.1808 0.0408 0.2283 0.3958]
Median for last 10 epochs: [0.2768 0.0643 0.4138 0.4945], Epochs since improvement 22
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 46%|████▌     | 229/500 [4:19:16<5:06:49, 67.93s/it]
Exited after 230 epochs due to early stopping
15556.69 seconds spent training, 31.113 seconds per epoch. Processed 2238 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.25635222 0.05707038 0.40306485 0.47751725]
{'epoch_exit': 229, 'scatter_m_star': 0.25635222, 'lowest_m_star': 0.18075392, 'last20_m_star': 0.36034465, 'last10_m_star': 0.27678397, 'scatter_v_disk': 0.057070382, 'lowest_v_disk': 0.0408141, 'last20_v_disk': 0.071303084, 'last10_v_disk': 0.06431435, 'scatter_m_cold': 0.40306485, 'lowest_m_cold': 0.22831121, 'last20_m_cold': 0.43062943, 'last10_m_cold': 0.41380447, 'scatter_sfr_100': 0.47751725, 'lowest_sfr_100': 0.39577565, 'last20_sfr_100': 0.524717, 'last10_sfr_100': 0.4944699}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
