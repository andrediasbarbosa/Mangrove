Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
Folder already exists
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 3e-05, 'l2_lambda': 3e-05, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_jsbgon
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:30<4:17:26, 30.96s/it]  0%|          | 2/500 [01:18<5:36:47, 40.58s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.27E+07, Train scatter: [0.9352 0.1649 0.5441 0.9954]
L1 regularization loss: 4.56E-01, L2 regularization loss: 9.93E-02
Test scatter: [0.9196 0.1649 0.5355 0.9851], Lowest was [0.9196 0.1649 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1649 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:49<4:59:12, 36.12s/it]  1%|          | 4/500 [02:37<5:39:07, 41.02s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 6.61E+06, Train scatter: [0.9352 0.1473 0.544  0.9954]
L1 regularization loss: 4.62E-01, L2 regularization loss: 1.06E-01
Test scatter: [0.9196 0.1438 0.5354 0.985 ], Lowest was [0.9196 0.1438 0.5354 0.985 ]
Median for last 10 epochs: [0.9196 0.1438 0.5354 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:08<5:08:18, 37.37s/it]  1%|          | 6/500 [03:57<5:38:56, 41.17s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.15E+06, Train scatter: [0.9343 0.1229 0.5418 0.7044]
L1 regularization loss: 4.73E-01, L2 regularization loss: 1.17E-01
Test scatter: [0.9186 0.1223 0.533  0.6891], Lowest was [0.9186 0.1223 0.533  0.6891]
Median for last 10 epochs: [0.9186 0.1223 0.533  0.6891], Epochs since improvement 0
  1%|▏         | 7/500 [04:28<5:10:55, 37.84s/it]  2%|▏         | 8/500 [05:16<5:38:05, 41.23s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.23E+06, Train scatter: [0.9109 0.1034 0.5329 0.6208]
L1 regularization loss: 4.79E-01, L2 regularization loss: 1.21E-01
Test scatter: [0.8955 0.1043 0.5238 0.6097], Lowest was [0.8955 0.1043 0.5238 0.6097]
Median for last 10 epochs: [0.907  0.1133 0.5284 0.6494], Epochs since improvement 0
  2%|▏         | 9/500 [05:47<5:10:55, 38.00s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 3.26E+06, Train scatter: [0.7635 0.0967 0.43   0.6862]
L1 regularization loss: 4.85E-01, L2 regularization loss: 1.24E-01
Test scatter: [0.7504 0.1013 0.4233 0.675 ], Lowest was [0.7504 0.1013 0.4233 0.6097]
Median for last 10 epochs: [0.8955 0.1043 0.5238 0.675 ], Epochs since improvement 0
  2%|▏         | 10/500 [06:41<5:49:51, 42.84s/it]  2%|▏         | 11/500 [07:12<5:19:38, 39.22s/it]  2%|▏         | 12/500 [08:00<5:42:10, 42.07s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.60E+06, Train scatter: [0.5697 0.0946 0.443  0.6053]
L1 regularization loss: 4.90E-01, L2 regularization loss: 1.28E-01
Test scatter: [0.5707 0.0993 0.4402 0.6087], Lowest was [0.5707 0.0993 0.4233 0.6087]
Median for last 10 epochs: [0.8955 0.1043 0.5238 0.675 ], Epochs since improvement 0
  3%|▎         | 13/500 [08:31<5:14:15, 38.72s/it]  3%|▎         | 14/500 [09:20<5:37:15, 41.64s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.58E+06, Train scatter: [0.6142 0.0914 0.3583 0.6068]
L1 regularization loss: 4.95E-01, L2 regularization loss: 1.31E-01
Test scatter: [0.594  0.0959 0.364  0.6191], Lowest was [0.5707 0.0959 0.364  0.6087]
Median for last 10 epochs: [0.7504 0.1013 0.4402 0.6191], Epochs since improvement 0
  3%|▎         | 15/500 [09:51<5:10:46, 38.45s/it]  3%|▎         | 16/500 [10:39<5:33:01, 41.28s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.17E+06, Train scatter: [0.5899 0.0878 0.342  0.5932]
L1 regularization loss: 5.04E-01, L2 regularization loss: 1.34E-01
Test scatter: [0.5772 0.0914 0.35   0.6   ], Lowest was [0.5707 0.0914 0.35   0.6   ]
Median for last 10 epochs: [0.594  0.0993 0.4233 0.6097], Epochs since improvement 0
  3%|▎         | 17/500 [11:10<5:07:34, 38.21s/it]  4%|▎         | 18/500 [11:58<5:31:33, 41.27s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 9.68E+05, Train scatter: [0.5309 0.0847 0.3197 0.5793]
L1 regularization loss: 5.10E-01, L2 regularization loss: 1.36E-01
Test scatter: [0.5328 0.0876 0.3307 0.5809], Lowest was [0.5328 0.0876 0.3307 0.5809]
Median for last 10 epochs: [0.5772 0.0959 0.364  0.6087], Epochs since improvement 0
  4%|▍         | 19/500 [12:29<5:05:51, 38.15s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.10E+05, Train scatter: [0.5749 0.0836 0.3101 0.5738]
L1 regularization loss: 5.16E-01, L2 regularization loss: 1.39E-01
Test scatter: [0.5757 0.0881 0.3203 0.5796], Lowest was [0.5328 0.0876 0.3203 0.5796]
Median for last 10 epochs: [0.5757 0.0914 0.35   0.6   ], Epochs since improvement 0
  4%|▍         | 20/500 [13:23<5:42:46, 42.85s/it]  4%|▍         | 21/500 [13:54<5:13:20, 39.25s/it]  4%|▍         | 22/500 [14:42<5:34:34, 42.00s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 6.72E+05, Train scatter: [0.5118 0.0795 0.3146 0.5556]
L1 regularization loss: 5.24E-01, L2 regularization loss: 1.42E-01
Test scatter: [0.516  0.0818 0.3247 0.5578], Lowest was [0.516  0.0818 0.3203 0.5578]
Median for last 10 epochs: [0.5757 0.0881 0.3307 0.5809], Epochs since improvement 0
  5%|▍         | 23/500 [15:13<5:07:34, 38.69s/it]  5%|▍         | 24/500 [16:01<5:29:52, 41.58s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.25E+05, Train scatter: [0.6002 0.0868 0.3392 0.616 ]
L1 regularization loss: 5.34E-01, L2 regularization loss: 1.46E-01
Test scatter: [0.5881 0.0906 0.342  0.6106], Lowest was [0.516  0.0818 0.3203 0.5578]
Median for last 10 epochs: [0.5757 0.0881 0.3307 0.5809], Epochs since improvement 2
  5%|▌         | 25/500 [16:32<5:04:17, 38.44s/it]  5%|▌         | 26/500 [17:20<5:26:26, 41.32s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.81E+05, Train scatter: [0.508  0.0866 0.3155 0.5592]
L1 regularization loss: 5.70E-01, L2 regularization loss: 1.68E-01
Test scatter: [0.5176 0.0893 0.3196 0.5599], Lowest was [0.516  0.0818 0.3196 0.5578]
Median for last 10 epochs: [0.5328 0.0881 0.3247 0.5796], Epochs since improvement 0
  5%|▌         | 27/500 [17:51<5:01:32, 38.25s/it]  6%|▌         | 28/500 [18:40<5:24:24, 41.24s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 5.80E+05, Train scatter: [0.59   0.081  0.3027 0.5675]
L1 regularization loss: 5.80E-01, L2 regularization loss: 1.74E-01
Test scatter: [0.5909 0.0821 0.3075 0.5695], Lowest was [0.516  0.0818 0.3075 0.5578]
Median for last 10 epochs: [0.5757 0.0881 0.3203 0.5695], Epochs since improvement 0
  6%|▌         | 29/500 [19:11<4:59:54, 38.21s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 5.41E+05, Train scatter: [0.5118 0.0764 0.288  0.5413]
L1 regularization loss: 5.90E-01, L2 regularization loss: 1.81E-01
Test scatter: [0.5275 0.0784 0.2971 0.5464], Lowest was [0.516  0.0784 0.2971 0.5464]
Median for last 10 epochs: [0.5275 0.0821 0.3196 0.5599], Epochs since improvement 0
  6%|▌         | 30/500 [20:04<5:35:21, 42.81s/it]  6%|▌         | 31/500 [20:35<5:07:07, 39.29s/it]  6%|▋         | 32/500 [21:24<5:27:37, 42.00s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.72E+05, Train scatter: [0.457  0.075  0.2762 0.5225]
L1 regularization loss: 6.05E-01, L2 regularization loss: 1.91E-01
Test scatter: [0.4642 0.0773 0.2877 0.5236], Lowest was [0.4642 0.0773 0.2877 0.5236]
Median for last 10 epochs: [0.5275 0.0821 0.3075 0.5599], Epochs since improvement 0
  7%|▋         | 33/500 [21:55<5:01:22, 38.72s/it]  7%|▋         | 34/500 [22:43<5:22:23, 41.51s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.57E+05, Train scatter: [1.606  0.0754 0.3128 0.5285]
L1 regularization loss: 6.18E-01, L2 regularization loss: 2.00E-01
Test scatter: [1.6348 0.0774 0.32   0.5273], Lowest was [0.4642 0.0773 0.2877 0.5236]
Median for last 10 epochs: [0.5275 0.0784 0.3075 0.5464], Epochs since improvement 2
  7%|▋         | 35/500 [23:14<4:57:27, 38.38s/it]  7%|▋         | 36/500 [24:02<5:20:04, 41.39s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.47E+05, Train scatter: [0.4653 0.0721 0.2744 0.5051]
L1 regularization loss: 6.43E-01, L2 regularization loss: 2.15E-01
Test scatter: [0.4636 0.074  0.2823 0.5051], Lowest was [0.4636 0.074  0.2823 0.5051]
Median for last 10 epochs: [0.5275 0.0774 0.2971 0.5273], Epochs since improvement 0
  7%|▋         | 37/500 [24:33<4:55:36, 38.31s/it]  8%|▊         | 38/500 [25:22<5:18:28, 41.36s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.49E+05, Train scatter: [0.4071 0.0727 0.2791 0.5096]
L1 regularization loss: 6.57E-01, L2 regularization loss: 2.26E-01
Test scatter: [0.4069 0.0731 0.2852 0.5109], Lowest was [0.4069 0.0731 0.2823 0.5051]
Median for last 10 epochs: [0.4642 0.0773 0.2877 0.5236], Epochs since improvement 0
  8%|▊         | 39/500 [25:53<4:54:09, 38.29s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: -8.54E+04, Train scatter: [0.4005 0.068  0.2655 0.4876]
L1 regularization loss: 6.74E-01, L2 regularization loss: 2.37E-01
Test scatter: [0.3989 0.0699 0.2734 0.4887], Lowest was [0.3989 0.0699 0.2734 0.4887]
Median for last 10 epochs: [0.4636 0.074  0.2852 0.5109], Epochs since improvement 0
  8%|▊         | 40/500 [26:47<5:29:09, 42.93s/it]  8%|▊         | 41/500 [27:18<5:01:13, 39.38s/it]  8%|▊         | 42/500 [28:06<5:21:06, 42.07s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.62E+05, Train scatter: [0.4288 0.0644 0.2653 0.4724]
L1 regularization loss: 6.86E-01, L2 regularization loss: 2.47E-01
Test scatter: [0.4198 0.0653 0.2727 0.4732], Lowest was [0.3989 0.0653 0.2727 0.4732]
Median for last 10 epochs: [0.4198 0.0731 0.2823 0.5051], Epochs since improvement 0
  9%|▊         | 43/500 [28:38<4:55:43, 38.83s/it]  9%|▉         | 44/500 [29:26<5:16:16, 41.62s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.75E+05, Train scatter: [0.461  0.0632 0.2669 0.4829]
L1 regularization loss: 7.03E-01, L2 regularization loss: 2.59E-01
Test scatter: [0.4591 0.0643 0.2766 0.4872], Lowest was [0.3989 0.0643 0.2727 0.4732]
Median for last 10 epochs: [0.4198 0.0699 0.2766 0.4887], Epochs since improvement 0
  9%|▉         | 45/500 [29:57<4:51:47, 38.48s/it]  9%|▉         | 46/500 [30:45<5:13:59, 41.50s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: -2.81E+05, Train scatter: [0.4163 0.0616 0.26   0.4625]
L1 regularization loss: 7.16E-01, L2 regularization loss: 2.70E-01
Test scatter: [0.4103 0.0628 0.2691 0.4652], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.4103 0.0653 0.2734 0.4872], Epochs since improvement 0
  9%|▉         | 47/500 [31:16<4:49:52, 38.39s/it] 10%|▉         | 48/500 [32:05<5:11:54, 41.40s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.01E+09, Train scatter: [0.9354 0.1728 0.5441 0.9954]
L1 regularization loss: 1.66E+00, L2 regularization loss: 6.02E-01
Test scatter: [0.9198 0.169  0.5355 0.9851], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.4198 0.0653 0.2734 0.4872], Epochs since improvement 2
 10%|▉         | 49/500 [32:36<4:48:01, 38.32s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 6.93E+06, Train scatter: [0.9351 0.1728 0.5441 0.9954]
L1 regularization loss: 1.67E+00, L2 regularization loss: 6.45E-01
Test scatter: [0.9195 0.169  0.5355 0.985 ], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.4591 0.0653 0.2766 0.4872], Epochs since improvement 4
 10%|█         | 50/500 [33:30<5:21:55, 42.92s/it] 10%|█         | 51/500 [34:01<4:55:08, 39.44s/it] 10%|█         | 52/500 [34:50<5:15:59, 42.32s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 5.91E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 1.67E+00, L2 regularization loss: 6.55E-01
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 6
 11%|█         | 53/500 [35:21<4:50:01, 38.93s/it] 11%|█         | 54/500 [36:10<5:10:55, 41.83s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 5.32E+06, Train scatter: [0.9352 0.1728 0.5441 0.9952]
L1 regularization loss: 1.68E+00, L2 regularization loss: 6.81E-01
Test scatter: [0.9195 0.169  0.5355 0.9849], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 8
 11%|█         | 55/500 [36:41<4:46:07, 38.58s/it] 11%|█         | 56/500 [37:29<5:08:08, 41.64s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.87E+06, Train scatter: [0.9346 0.1727 0.544  0.9949]
L1 regularization loss: 1.68E+00, L2 regularization loss: 7.27E-01
Test scatter: [0.919  0.1689 0.5354 0.9846], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 10
 11%|█▏        | 57/500 [38:01<4:44:08, 38.48s/it] 12%|█▏        | 58/500 [38:49<5:05:34, 41.48s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 4.55E+06, Train scatter: [0.9307 0.17   0.5438 0.9914]
L1 regularization loss: 1.69E+00, L2 regularization loss: 8.29E-01
Test scatter: [0.9151 0.1661 0.5352 0.981 ], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.9849], Epochs since improvement 12
 12%|█▏        | 59/500 [39:20<4:41:38, 38.32s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.89E+06, Train scatter: [0.9254 0.1333 0.543  0.9773]
L1 regularization loss: 1.70E+00, L2 regularization loss: 9.39E-01
Test scatter: [0.9099 0.1302 0.5345 0.967 ], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.919  0.1689 0.5354 0.9846], Epochs since improvement 14
 12%|█▏        | 60/500 [40:14<5:14:52, 42.94s/it] 12%|█▏        | 61/500 [40:45<4:48:35, 39.44s/it] 12%|█▏        | 62/500 [41:33<5:07:46, 42.16s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.33E+06, Train scatter: [0.9269 0.1175 0.5424 0.9615]
L1 regularization loss: 1.70E+00, L2 regularization loss: 9.56E-01
Test scatter: [0.9115 0.1154 0.5339 0.9515], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.9151 0.1661 0.5352 0.981 ], Epochs since improvement 16
 13%|█▎        | 63/500 [42:05<4:43:02, 38.86s/it] 13%|█▎        | 64/500 [42:54<5:04:23, 41.89s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.11E+06, Train scatter: [0.9261 0.1132 0.5397 0.9275]
L1 regularization loss: 1.71E+00, L2 regularization loss: 9.85E-01
Test scatter: [0.9106 0.1116 0.5313 0.9182], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.9115 0.1302 0.5345 0.967 ], Epochs since improvement 18
 13%|█▎        | 65/500 [43:25<4:41:03, 38.77s/it] 13%|█▎        | 66/500 [44:14<5:01:42, 41.71s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.89E+06, Train scatter: [0.924  0.1094 0.5195 0.8128]
L1 regularization loss: 1.71E+00, L2 regularization loss: 1.02E+00
Test scatter: [0.9086 0.1079 0.5119 0.8058], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.9106 0.1154 0.5339 0.9515], Epochs since improvement 20
 13%|█▎        | 67/500 [44:45<4:38:29, 38.59s/it] 13%|█▎        | 67/500 [45:34<4:54:29, 40.81s/it]
Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.66E+06, Train scatter: [0.9185 0.1088 0.5134 0.6968]
L1 regularization loss: 1.72E+00, L2 regularization loss: 1.04E+00
Test scatter: [0.9032 0.1073 0.5065 0.6893], Lowest was [0.3989 0.0628 0.2691 0.4652]
Median for last 10 epochs: [0.9099 0.1116 0.5313 0.9182], Epochs since improvement 22
Exited after 68 epochs due to early stopping
2734.35 seconds spent training, 5.469 seconds per epoch. Processed 12734 trees per second
[0.903178   0.10724862 0.5064409  0.68925416]
{'epoch_exit': 67, 'scatter_m_star': 0.903178, 'lowest_m_star': 0.39889854, 'last20_m_star': 0.91328347, 'last10_m_star': 0.9099072, 'scatter_v_disk': 0.10724862, 'lowest_v_disk': 0.062813215, 'last20_v_disk': 0.14815703, 'last10_v_disk': 0.11158014, 'scatter_m_cold': 0.5064409, 'lowest_m_cold': 0.26909116, 'last20_m_cold': 0.534822, 'last10_m_cold': 0.5312752, 'scatter_sfr_100': 0.68925416, 'lowest_sfr_100': 0.46519676, 'last20_sfr_100': 0.9740191, 'last10_sfr_100': 0.91817975}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 3e-05, 'l2_lambda': 3e-05, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_gufxkm
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:56:22, 28.42s/it]  0%|          | 2/500 [01:12<5:12:10, 37.61s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.37E+07, Train scatter: [0.9353 0.1635 0.5442 0.9954]
L1 regularization loss: 4.54E-01, L2 regularization loss: 9.77E-02
Test scatter: [0.9197 0.1657 0.5356 0.9851], Lowest was [0.9197 0.1657 0.5356 0.9851]
Median for last 10 epochs: [0.9197 0.1657 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:39<4:32:59, 32.96s/it]  1%|          | 4/500 [02:25<5:13:35, 37.93s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.22E+07, Train scatter: [0.9353 0.1758 0.5441 0.9954]
L1 regularization loss: 4.58E-01, L2 regularization loss: 9.95E-02
Test scatter: [0.9197 0.1769 0.5355 0.9851], Lowest was [0.9197 0.1657 0.5355 0.9851]
Median for last 10 epochs: [0.9197 0.1713 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:52<4:41:37, 34.14s/it]  1%|          | 6/500 [03:38<5:12:47, 37.99s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.87E+06, Train scatter: [0.9352 0.1661 0.5442 0.9954]
L1 regularization loss: 4.61E-01, L2 regularization loss: 1.03E-01
Test scatter: [0.9197 0.1612 0.5356 0.9851], Lowest was [0.9197 0.1612 0.5355 0.9851]
Median for last 10 epochs: [0.9197 0.1612 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:05<4:43:57, 34.56s/it]  2%|▏         | 8/500 [04:50<5:10:45, 37.90s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.51E+06, Train scatter: [0.9352 0.1433 0.5442 0.9948]
L1 regularization loss: 4.66E-01, L2 regularization loss: 1.10E-01
Test scatter: [0.9196 0.14   0.5356 0.9845], Lowest was [0.9196 0.14   0.5355 0.9845]
Median for last 10 epochs: [0.9196 0.1506 0.5355 0.9848], Epochs since improvement 0
  2%|▏         | 9/500 [05:18<4:43:19, 34.62s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.01E+06, Train scatter: [0.9349 0.1328 0.5441 0.7031]
L1 regularization loss: 4.75E-01, L2 regularization loss: 1.18E-01
Test scatter: [0.9193 0.1302 0.5355 0.7092], Lowest was [0.9193 0.1302 0.5355 0.7092]
Median for last 10 epochs: [0.9196 0.14   0.5355 0.9845], Epochs since improvement 0
  2%|▏         | 10/500 [06:08<5:22:43, 39.52s/it]  2%|▏         | 11/500 [06:36<4:52:07, 35.84s/it]  2%|▏         | 12/500 [07:20<5:13:06, 38.50s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.55E+06, Train scatter: [0.9317 0.1215 0.5441 0.6591]
L1 regularization loss: 4.79E-01, L2 regularization loss: 1.21E-01
Test scatter: [0.916  0.1183 0.5355 0.6532], Lowest was [0.916  0.1183 0.5355 0.6532]
Median for last 10 epochs: [0.9196 0.14   0.5355 0.9845], Epochs since improvement 0
  3%|▎         | 13/500 [07:48<4:44:57, 35.11s/it]  3%|▎         | 14/500 [08:33<5:09:44, 38.24s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.01E+06, Train scatter: [0.9006 0.1119 0.5436 0.603 ]
L1 regularization loss: 4.83E-01, L2 regularization loss: 1.23E-01
Test scatter: [0.8878 0.1087 0.535  0.5964], Lowest was [0.8878 0.1087 0.535  0.5964]
Median for last 10 epochs: [0.9193 0.1302 0.5355 0.7092], Epochs since improvement 0
  3%|▎         | 15/500 [09:00<4:42:12, 34.91s/it]  3%|▎         | 16/500 [09:45<5:05:23, 37.86s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.19E+06, Train scatter: [0.6978 0.1043 0.5406 0.5866]
L1 regularization loss: 4.87E-01, L2 regularization loss: 1.26E-01
Test scatter: [0.6874 0.1035 0.5321 0.5774], Lowest was [0.6874 0.1035 0.5321 0.5774]
Median for last 10 epochs: [0.916  0.1183 0.5355 0.6532], Epochs since improvement 0
  3%|▎         | 17/500 [10:12<4:39:07, 34.67s/it]  4%|▎         | 18/500 [10:57<5:03:37, 37.80s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 5.59E+06, Train scatter: [0.5312 0.0973 0.5369 0.5668]
L1 regularization loss: 4.93E-01, L2 regularization loss: 1.29E-01
Test scatter: [0.5255 0.0968 0.5288 0.5628], Lowest was [0.5255 0.0968 0.5288 0.5628]
Median for last 10 epochs: [0.8878 0.1087 0.535  0.5964], Epochs since improvement 0
  4%|▍         | 19/500 [11:25<4:37:43, 34.64s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.07E+06, Train scatter: [0.4552 0.0922 0.534  0.5716]
L1 regularization loss: 4.97E-01, L2 regularization loss: 1.32E-01
Test scatter: [0.461  0.0926 0.5256 0.5739], Lowest was [0.461  0.0926 0.5256 0.5628]
Median for last 10 epochs: [0.6874 0.1035 0.5321 0.5774], Epochs since improvement 0
  4%|▍         | 20/500 [12:14<5:13:06, 39.14s/it]  4%|▍         | 21/500 [12:42<4:44:33, 35.64s/it]  4%|▍         | 22/500 [13:28<5:08:12, 38.69s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.66E+06, Train scatter: [0.4791 0.0903 0.5309 0.6063]
L1 regularization loss: 5.00E-01, L2 regularization loss: 1.35E-01
Test scatter: [0.4939 0.091  0.5222 0.6131], Lowest was [0.461  0.091  0.5222 0.5628]
Median for last 10 epochs: [0.5255 0.0968 0.5288 0.5774], Epochs since improvement 0
  5%|▍         | 23/500 [13:55<4:40:21, 35.26s/it]  5%|▍         | 24/500 [14:41<5:05:21, 38.49s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.15E+06, Train scatter: [0.5332 0.0908 0.5078 0.5642]
L1 regularization loss: 5.04E-01, L2 regularization loss: 1.38E-01
Test scatter: [0.5339 0.0915 0.503  0.5663], Lowest was [0.461  0.091  0.503  0.5628]
Median for last 10 epochs: [0.5255 0.0926 0.5256 0.5739], Epochs since improvement 0
  5%|▌         | 25/500 [15:08<4:38:36, 35.19s/it]  5%|▌         | 26/500 [15:53<5:00:52, 38.09s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.22E+06, Train scatter: [0.6175 0.1036 0.4528 0.632 ]
L1 regularization loss: 5.10E-01, L2 regularization loss: 1.42E-01
Test scatter: [0.6243 0.1047 0.4507 0.637 ], Lowest was [0.461  0.091  0.4507 0.5628]
Median for last 10 epochs: [0.5255 0.0926 0.5222 0.5739], Epochs since improvement 0
  5%|▌         | 27/500 [16:21<4:34:48, 34.86s/it]  6%|▌         | 28/500 [17:06<4:59:48, 38.11s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.59E+06, Train scatter: [0.4637 0.0879 0.3681 0.6065]
L1 regularization loss: 5.17E-01, L2 regularization loss: 1.46E-01
Test scatter: [0.4647 0.0873 0.3676 0.5998], Lowest was [0.461  0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.4939 0.0915 0.503  0.5998], Epochs since improvement 0
  6%|▌         | 29/500 [17:34<4:33:55, 34.89s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.75E+07, Train scatter: [0.8961 0.2139 0.5419 0.9822]
L1 regularization loss: 6.04E-01, L2 regularization loss: 1.70E-01
Test scatter: [0.8819 0.2047 0.5334 0.9722], Lowest was [0.461  0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.5339 0.0915 0.503  0.6131], Epochs since improvement 2
  6%|▌         | 30/500 [18:25<5:12:02, 39.83s/it]  6%|▌         | 31/500 [18:52<4:42:17, 36.11s/it]  6%|▋         | 32/500 [19:38<5:04:26, 39.03s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 1.06E+07, Train scatter: [0.6592 0.1434 0.5204 0.8313]
L1 regularization loss: 6.17E-01, L2 regularization loss: 1.82E-01
Test scatter: [0.6576 0.1412 0.514  0.828 ], Lowest was [0.461  0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.6243 0.1047 0.503  0.637 ], Epochs since improvement 4
  7%|▋         | 33/500 [20:06<4:36:27, 35.52s/it]  7%|▋         | 34/500 [20:52<5:01:18, 38.80s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.76E+06, Train scatter: [0.6433 0.1326 0.503  0.7586]
L1 regularization loss: 6.20E-01, L2 regularization loss: 1.89E-01
Test scatter: [0.6414 0.1305 0.498  0.747 ], Lowest was [0.461  0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.6414 0.1305 0.498  0.747 ], Epochs since improvement 6
  7%|▋         | 35/500 [21:19<4:33:49, 35.33s/it]  7%|▋         | 36/500 [22:05<4:57:10, 38.43s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 6.23E+06, Train scatter: [0.4929 0.1269 0.4945 0.7156]
L1 regularization loss: 6.25E-01, L2 regularization loss: 1.96E-01
Test scatter: [0.4906 0.1251 0.4879 0.7095], Lowest was [0.461  0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.6414 0.1305 0.498  0.747 ], Epochs since improvement 8
  7%|▋         | 37/500 [22:32<4:30:51, 35.10s/it]  8%|▊         | 38/500 [23:18<4:54:56, 38.30s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 5.11E+06, Train scatter: [0.4559 0.1237 0.5047 0.7141]
L1 regularization loss: 6.27E-01, L2 regularization loss: 2.01E-01
Test scatter: [0.4551 0.1218 0.4997 0.7072], Lowest was [0.4551 0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.6414 0.1305 0.4997 0.747 ], Epochs since improvement 0
  8%|▊         | 39/500 [23:45<4:28:55, 35.00s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 4.19E+06, Train scatter: [0.4213 0.1173 0.481  0.6779]
L1 regularization loss: 6.30E-01, L2 regularization loss: 2.07E-01
Test scatter: [0.4159 0.1158 0.4728 0.6664], Lowest was [0.4159 0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.4906 0.1251 0.498  0.7095], Epochs since improvement 0
  8%|▊         | 40/500 [24:37<5:06:24, 39.97s/it]  8%|▊         | 41/500 [25:04<4:37:08, 36.23s/it]  8%|▊         | 42/500 [25:50<4:58:38, 39.12s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.78E+06, Train scatter: [0.4113 0.1139 0.4969 0.6684]
L1 regularization loss: 6.33E-01, L2 regularization loss: 2.14E-01
Test scatter: [0.4067 0.1125 0.4917 0.6584], Lowest was [0.4067 0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.4551 0.1218 0.4917 0.7072], Epochs since improvement 0
  9%|▊         | 43/500 [26:18<4:30:54, 35.57s/it]  9%|▉         | 44/500 [27:03<4:53:56, 38.68s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.08E+06, Train scatter: [0.3802 0.1097 0.4493 0.656 ]
L1 regularization loss: 6.37E-01, L2 regularization loss: 2.22E-01
Test scatter: [0.3795 0.1084 0.4432 0.646 ], Lowest was [0.3795 0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.4159 0.1158 0.4879 0.6664], Epochs since improvement 0
  9%|▉         | 45/500 [27:31<4:27:16, 35.25s/it]  9%|▉         | 46/500 [28:17<4:51:06, 38.47s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.16E+06, Train scatter: [0.3934 0.1067 0.4512 0.6624]
L1 regularization loss: 6.42E-01, L2 regularization loss: 2.29E-01
Test scatter: [0.4026 0.1058 0.4494 0.6611], Lowest was [0.3795 0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.4067 0.1125 0.4728 0.6611], Epochs since improvement 2
  9%|▉         | 47/500 [28:44<4:24:58, 35.10s/it] 10%|▉         | 48/500 [29:30<4:50:03, 38.50s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.77E+06, Train scatter: [0.7602 0.1125 0.4704 0.7338]
L1 regularization loss: 6.49E-01, L2 regularization loss: 2.37E-01
Test scatter: [0.7485 0.1105 0.4738 0.7239], Lowest was [0.3795 0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.4067 0.1105 0.4728 0.6611], Epochs since improvement 4
 10%|▉         | 49/500 [29:58<4:24:06, 35.14s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.19E+06, Train scatter: [0.4118 0.0999 0.4082 0.6299]
L1 regularization loss: 6.52E-01, L2 regularization loss: 2.41E-01
Test scatter: [0.3994 0.0968 0.3978 0.613 ], Lowest was [0.3795 0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.4026 0.1084 0.4494 0.6584], Epochs since improvement 6
 10%|█         | 50/500 [30:50<5:01:28, 40.20s/it] 10%|█         | 51/500 [31:17<4:31:56, 36.34s/it] 10%|█         | 52/500 [32:03<4:53:28, 39.31s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.97E+06, Train scatter: [0.3741 0.0963 0.4056 0.6162]
L1 regularization loss: 6.55E-01, L2 regularization loss: 2.44E-01
Test scatter: [0.3822 0.0944 0.4027 0.6051], Lowest was [0.3795 0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.3994 0.1058 0.4432 0.646 ], Epochs since improvement 8
 11%|█         | 53/500 [32:30<4:25:49, 35.68s/it] 11%|█         | 54/500 [33:17<4:48:28, 38.81s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.85E+06, Train scatter: [0.4085 0.0953 0.4058 0.63  ]
L1 regularization loss: 6.59E-01, L2 regularization loss: 2.48E-01
Test scatter: [0.4328 0.0987 0.4032 0.6342], Lowest was [0.3795 0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.4026 0.0987 0.4032 0.6342], Epochs since improvement 10
 11%|█         | 55/500 [33:44<4:22:15, 35.36s/it] 11%|█         | 56/500 [34:30<4:45:34, 38.59s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.54E+06, Train scatter: [0.4169 0.0944 0.4024 0.6539]
L1 regularization loss: 6.63E-01, L2 regularization loss: 2.51E-01
Test scatter: [0.4486 0.1002 0.3984 0.6636], Lowest was [0.3795 0.0873 0.3676 0.5628]
Median for last 10 epochs: [0.4328 0.0987 0.4027 0.6342], Epochs since improvement 12
 11%|█▏        | 57/500 [34:57<4:20:01, 35.22s/it] 12%|█▏        | 58/500 [35:45<4:45:53, 38.81s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.34E+06, Train scatter: [0.3607 0.09   0.3495 0.613 ]
L1 regularization loss: 6.69E-01, L2 regularization loss: 2.57E-01
Test scatter: [0.4178 0.0921 0.3558 0.6098], Lowest was [0.3795 0.0873 0.3558 0.5628]
Median for last 10 epochs: [0.4178 0.0968 0.3984 0.613 ], Epochs since improvement 0
 12%|█▏        | 59/500 [36:12<4:19:43, 35.34s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.51E+06, Train scatter: [0.346  0.0887 0.3731 0.6284]
L1 regularization loss: 6.78E-01, L2 regularization loss: 2.68E-01
Test scatter: [0.3725 0.0921 0.3697 0.6268], Lowest was [0.3725 0.0873 0.3558 0.5628]
Median for last 10 epochs: [0.4178 0.0944 0.3984 0.6268], Epochs since improvement 0
 12%|█▏        | 60/500 [37:03<4:54:53, 40.21s/it] 12%|█▏        | 61/500 [37:31<4:25:50, 36.33s/it] 12%|█▏        | 62/500 [38:17<4:46:25, 39.24s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.78E+06, Train scatter: [0.3264 0.0859 0.355  0.6054]
L1 regularization loss: 6.83E-01, L2 regularization loss: 2.74E-01
Test scatter: [0.3511 0.0883 0.3618 0.6076], Lowest was [0.3511 0.0873 0.3558 0.5628]
Median for last 10 epochs: [0.4178 0.0921 0.3697 0.6268], Epochs since improvement 0
 13%|█▎        | 63/500 [38:44<4:19:40, 35.65s/it] 13%|█▎        | 64/500 [39:30<4:41:32, 38.74s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 9.84E+05, Train scatter: [0.3723 0.0834 0.326  0.6071]
L1 regularization loss: 6.88E-01, L2 regularization loss: 2.79E-01
Test scatter: [0.3815 0.0823 0.3306 0.5943], Lowest was [0.3511 0.0823 0.3306 0.5628]
Median for last 10 epochs: [0.3815 0.0921 0.3618 0.6098], Epochs since improvement 0
 13%|█▎        | 65/500 [39:57<4:15:52, 35.29s/it] 13%|█▎        | 66/500 [40:43<4:38:33, 38.51s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 9.13E+05, Train scatter: [0.327  0.0832 0.326  0.5875]
L1 regularization loss: 6.93E-01, L2 regularization loss: 2.85E-01
Test scatter: [0.3674 0.082  0.3294 0.58  ], Lowest was [0.3511 0.082  0.3294 0.5628]
Median for last 10 epochs: [0.3725 0.0883 0.3558 0.6076], Epochs since improvement 0
 13%|█▎        | 67/500 [41:10<4:13:27, 35.12s/it] 14%|█▎        | 68/500 [41:57<4:37:39, 38.56s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 8.07E+05, Train scatter: [0.3087 0.08   0.3193 0.5821]
L1 regularization loss: 6.98E-01, L2 regularization loss: 2.91E-01
Test scatter: [0.316  0.0795 0.3203 0.5748], Lowest was [0.316  0.0795 0.3203 0.5628]
Median for last 10 epochs: [0.3674 0.0823 0.3306 0.5943], Epochs since improvement 0
 14%|█▍        | 69/500 [42:24<4:12:32, 35.16s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 7.85E+05, Train scatter: [0.3037 0.0803 0.3418 0.5739]
L1 regularization loss: 7.03E-01, L2 regularization loss: 2.97E-01
Test scatter: [0.3679 0.0835 0.3411 0.5752], Lowest was [0.316  0.0795 0.3203 0.5628]
Median for last 10 epochs: [0.3674 0.0823 0.3306 0.58  ], Epochs since improvement 2
 14%|█▍        | 70/500 [43:16<4:48:12, 40.21s/it] 14%|█▍        | 71/500 [43:43<4:19:46, 36.33s/it] 14%|█▍        | 72/500 [44:30<4:40:36, 39.34s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 7.23E+05, Train scatter: [0.4109 0.0907 0.343  0.6095]
L1 regularization loss: 7.07E-01, L2 regularization loss: 3.03E-01
Test scatter: [0.4407 0.0987 0.3935 0.6162], Lowest was [0.316  0.0795 0.3203 0.5628]
Median for last 10 epochs: [0.3679 0.0823 0.3306 0.58  ], Epochs since improvement 4
 15%|█▍        | 73/500 [44:57<4:14:12, 35.72s/it] 15%|█▍        | 74/500 [45:44<4:36:34, 38.95s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 6.38E+05, Train scatter: [0.2865 0.0757 0.3049 0.5747]
L1 regularization loss: 7.12E-01, L2 regularization loss: 3.09E-01
Test scatter: [0.2989 0.077  0.3102 0.5687], Lowest was [0.2989 0.077  0.3102 0.5628]
Median for last 10 epochs: [0.3674 0.082  0.3294 0.5752], Epochs since improvement 0
 15%|█▌        | 75/500 [46:11<4:11:10, 35.46s/it] 15%|█▌        | 76/500 [46:57<4:33:00, 38.63s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 5.66E+05, Train scatter: [0.3    0.0783 0.2995 0.5554]
L1 regularization loss: 7.19E-01, L2 regularization loss: 3.15E-01
Test scatter: [0.3174 0.0825 0.3135 0.5582], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.3174 0.0825 0.3203 0.5748], Epochs since improvement 0
 15%|█▌        | 77/500 [47:24<4:08:17, 35.22s/it] 16%|█▌        | 78/500 [48:11<4:31:48, 38.64s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 6.28E+05, Train scatter: [0.4947 0.1033 0.4876 0.7191]
L1 regularization loss: 7.26E-01, L2 regularization loss: 3.22E-01
Test scatter: [0.4876 0.1013 0.4797 0.7144], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.3679 0.0835 0.3411 0.5752], Epochs since improvement 2
 16%|█▌        | 79/500 [48:38<4:07:15, 35.24s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 1.05E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 1.56E+00, L2 regularization loss: 6.90E-01
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.4407 0.0987 0.3935 0.6162], Epochs since improvement 4
 16%|█▌        | 80/500 [49:31<4:43:38, 40.52s/it] 16%|█▌        | 81/500 [49:58<4:15:05, 36.53s/it] 16%|█▋        | 82/500 [50:45<4:35:51, 39.60s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 8.92E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 1.56E+00, L2 regularization loss: 7.08E-01
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.4876 0.1013 0.4797 0.7144], Epochs since improvement 6
 17%|█▋        | 83/500 [51:12<4:09:29, 35.90s/it] 17%|█▋        | 84/500 [51:58<4:30:03, 38.95s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 7.97E+06, Train scatter: [0.9351 0.1728 0.5441 0.9954]
L1 regularization loss: 1.56E+00, L2 regularization loss: 7.40E-01
Test scatter: [0.9195 0.169  0.5355 0.985 ], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 8
 17%|█▋        | 85/500 [52:26<4:05:06, 35.44s/it] 17%|█▋        | 86/500 [53:11<4:26:06, 38.57s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 7.28E+06, Train scatter: [0.9351 0.1728 0.5441 0.9954]
L1 regularization loss: 1.56E+00, L2 regularization loss: 7.60E-01
Test scatter: [0.9195 0.1689 0.5355 0.985 ], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 10
 17%|█▋        | 87/500 [53:39<4:02:16, 35.20s/it] 18%|█▊        | 88/500 [54:25<4:23:50, 38.42s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 6.75E+06, Train scatter: [0.9351 0.1728 0.5441 0.9954]
L1 regularization loss: 1.56E+00, L2 regularization loss: 7.81E-01
Test scatter: [0.9195 0.1689 0.5355 0.985 ], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 12
 18%|█▊        | 89/500 [54:52<4:00:30, 35.11s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 6.30E+06, Train scatter: [0.9351 0.1728 0.5441 0.9954]
L1 regularization loss: 1.57E+00, L2 regularization loss: 7.98E-01
Test scatter: [0.9195 0.1689 0.5355 0.985 ], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.9195 0.1689 0.5355 0.985 ], Epochs since improvement 14
 18%|█▊        | 90/500 [55:44<4:33:51, 40.08s/it] 18%|█▊        | 91/500 [56:11<4:07:07, 36.25s/it] 18%|█▊        | 92/500 [56:58<4:27:56, 39.40s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 5.38E+06, Train scatter: [0.9351 0.1727 0.5441 0.9954]
L1 regularization loss: 1.57E+00, L2 regularization loss: 8.26E-01
Test scatter: [0.9195 0.1689 0.5355 0.9851], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.9195 0.1689 0.5355 0.985 ], Epochs since improvement 16
 19%|█▊        | 93/500 [57:25<4:02:40, 35.77s/it] 19%|█▉        | 94/500 [58:12<4:23:53, 39.00s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 5.00E+06, Train scatter: [0.9351 0.1726 0.5441 0.9955]
L1 regularization loss: 1.58E+00, L2 regularization loss: 8.52E-01
Test scatter: [0.9195 0.1688 0.5355 0.9852], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.9195 0.1689 0.5355 0.985 ], Epochs since improvement 18
 19%|█▉        | 95/500 [58:39<3:59:37, 35.50s/it] 19%|█▉        | 96/500 [59:26<4:21:48, 38.88s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 4.73E+06, Train scatter: [0.9351 0.1726 0.5441 0.9955]
L1 regularization loss: 1.58E+00, L2 regularization loss: 8.69E-01
Test scatter: [0.9195 0.1688 0.5355 0.9852], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.9195 0.1689 0.5355 0.9851], Epochs since improvement 20
 19%|█▉        | 97/500 [59:53<3:57:34, 35.37s/it] 19%|█▉        | 97/500 [1:00:39<4:12:00, 37.52s/it]
Epoch: 98 done with learning rate 9.93E-03, Train loss: 4.49E+06, Train scatter: [0.9352 0.1726 0.5441 0.9955]
L1 regularization loss: 1.58E+00, L2 regularization loss: 8.84E-01
Test scatter: [0.9195 0.1688 0.5355 0.9852], Lowest was [0.2989 0.077  0.3102 0.5582]
Median for last 10 epochs: [0.9195 0.1688 0.5355 0.9852], Epochs since improvement 22
Exited after 98 epochs due to early stopping
3639.33 seconds spent training, 7.279 seconds per epoch. Processed 9567 trees per second
[0.91951007 0.16875745 0.53547615 0.98519963]
{'epoch_exit': 97, 'scatter_m_star': 0.91951007, 'lowest_m_star': 0.2988562, 'last20_m_star': 0.91952527, 'last10_m_star': 0.9195203, 'scatter_v_disk': 0.16875745, 'lowest_v_disk': 0.07695554, 'last20_v_disk': 0.16894306, 'last10_v_disk': 0.16883975, 'scatter_m_cold': 0.53547615, 'lowest_m_cold': 0.3101905, 'last20_m_cold': 0.535488, 'last10_m_cold': 0.535491, 'scatter_sfr_100': 0.98519963, 'lowest_sfr_100': 0.5582366, 'last20_sfr_100': 0.9850466, 'last10_sfr_100': 0.98515457}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 3e-05, 'l2_lambda': 3e-05, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_bgwcgb
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:47<6:31:58, 47.13s/it]  0%|          | 2/500 [01:57<8:24:11, 60.75s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.29E+07, Train scatter: [0.9351 0.1398 0.544  0.9954]
L1 regularization loss: 5.97E-01, L2 regularization loss: 1.15E-01
Test scatter: [0.9195 0.1372 0.5355 0.9851], Lowest was [0.9195 0.1372 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1372 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:44<7:29:45, 54.30s/it]  1%|          | 4/500 [03:53<8:19:23, 60.41s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.49E+07, Train scatter: [0.9312 0.0924 0.5439 0.9946]
L1 regularization loss: 6.05E-01, L2 regularization loss: 1.24E-01
Test scatter: [0.9155 0.0915 0.5353 0.9843], Lowest was [0.9155 0.0915 0.5353 0.9843]
Median for last 10 epochs: [0.9155 0.0915 0.5353 0.9843], Epochs since improvement 0
  1%|          | 5/500 [04:40<7:36:59, 55.39s/it]  1%|          | 6/500 [05:49<8:16:01, 60.25s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.14E+06, Train scatter: [0.6268 0.0843 0.5438 0.607 ]
L1 regularization loss: 6.18E-01, L2 regularization loss: 1.36E-01
Test scatter: [0.6119 0.0843 0.5353 0.6056], Lowest was [0.6119 0.0843 0.5353 0.6056]
Median for last 10 epochs: [0.6119 0.0843 0.5353 0.6056], Epochs since improvement 0
  1%|▏         | 7/500 [06:36<7:38:24, 55.79s/it]  2%|▏         | 8/500 [07:46<8:15:36, 60.44s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 5.62E+06, Train scatter: [0.467  0.078  0.5438 0.5559]
L1 regularization loss: 6.21E-01, L2 regularization loss: 1.40E-01
Test scatter: [0.4659 0.0789 0.5353 0.5506], Lowest was [0.4659 0.0789 0.5353 0.5506]
Median for last 10 epochs: [0.5389 0.0816 0.5353 0.5781], Epochs since improvement 0
  2%|▏         | 9/500 [08:33<7:39:45, 56.18s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.22E+06, Train scatter: [0.381  0.0746 0.5437 0.5337]
L1 regularization loss: 6.24E-01, L2 regularization loss: 1.43E-01
Test scatter: [0.386  0.0743 0.5352 0.5302], Lowest was [0.386  0.0743 0.5352 0.5302]
Median for last 10 epochs: [0.4659 0.0789 0.5353 0.5506], Epochs since improvement 0
  2%|▏         | 10/500 [09:50<8:29:18, 62.36s/it]  2%|▏         | 11/500 [10:36<7:49:16, 57.58s/it]  2%|▏         | 12/500 [11:46<8:17:57, 61.22s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 3.76E+06, Train scatter: [0.2497 0.0727 0.5437 0.5368]
L1 regularization loss: 6.27E-01, L2 regularization loss: 1.45E-01
Test scatter: [0.2567 0.0716 0.5352 0.5273], Lowest was [0.2567 0.0716 0.5352 0.5273]
Median for last 10 epochs: [0.4659 0.0789 0.5353 0.5506], Epochs since improvement 0
  3%|▎         | 13/500 [12:33<7:41:15, 56.83s/it]  3%|▎         | 14/500 [13:44<8:15:36, 61.19s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 3.59E+06, Train scatter: [0.2639 0.0698 0.5437 0.5136]
L1 regularization loss: 6.29E-01, L2 regularization loss: 1.46E-01
Test scatter: [0.2744 0.0703 0.5352 0.5104], Lowest was [0.2567 0.0703 0.5352 0.5104]
Median for last 10 epochs: [0.386  0.0743 0.5352 0.5302], Epochs since improvement 0
  3%|▎         | 15/500 [14:31<7:39:35, 56.86s/it]  3%|▎         | 16/500 [15:41<8:12:25, 61.04s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.52E+06, Train scatter: [0.2309 0.0701 0.5437 0.5139]
L1 regularization loss: 6.32E-01, L2 regularization loss: 1.48E-01
Test scatter: [0.2367 0.0705 0.5352 0.5098], Lowest was [0.2367 0.0703 0.5352 0.5098]
Median for last 10 epochs: [0.2744 0.0716 0.5352 0.5273], Epochs since improvement 0
  3%|▎         | 17/500 [16:28<7:36:49, 56.75s/it]  4%|▎         | 18/500 [17:39<8:08:56, 60.86s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.44E+06, Train scatter: [0.2205 0.068  0.5437 0.5105]
L1 regularization loss: 6.35E-01, L2 regularization loss: 1.49E-01
Test scatter: [0.2269 0.0677 0.5352 0.5023], Lowest was [0.2269 0.0677 0.5352 0.5023]
Median for last 10 epochs: [0.2567 0.0705 0.5352 0.5104], Epochs since improvement 0
  4%|▍         | 19/500 [18:26<7:34:50, 56.74s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.39E+06, Train scatter: [0.2181 0.0654 0.5437 0.5095]
L1 regularization loss: 6.38E-01, L2 regularization loss: 1.50E-01
Test scatter: [0.2249 0.0657 0.5352 0.5089], Lowest was [0.2249 0.0657 0.5352 0.5023]
Median for last 10 epochs: [0.2367 0.0703 0.5352 0.5098], Epochs since improvement 0
  4%|▍         | 20/500 [19:44<8:25:45, 63.22s/it]  4%|▍         | 21/500 [20:31<7:45:12, 58.27s/it]  4%|▍         | 22/500 [21:41<8:13:24, 61.93s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.33E+06, Train scatter: [0.2032 0.0651 0.5437 0.4988]
L1 regularization loss: 6.43E-01, L2 regularization loss: 1.52E-01
Test scatter: [0.2095 0.065  0.5352 0.493 ], Lowest was [0.2095 0.065  0.5352 0.493 ]
Median for last 10 epochs: [0.2269 0.0677 0.5352 0.5089], Epochs since improvement 0
  5%|▍         | 23/500 [22:28<7:36:07, 57.37s/it]  5%|▍         | 24/500 [23:39<8:06:45, 61.36s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.25E+06, Train scatter: [0.2247 0.0673 0.5436 0.5242]
L1 regularization loss: 6.48E-01, L2 regularization loss: 1.53E-01
Test scatter: [0.2259 0.0677 0.5351 0.5214], Lowest was [0.2095 0.065  0.5351 0.493 ]
Median for last 10 epochs: [0.2259 0.0677 0.5352 0.5089], Epochs since improvement 0
  5%|▌         | 25/500 [24:25<7:30:56, 56.96s/it]  5%|▌         | 26/500 [25:35<8:00:45, 60.86s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.20E+06, Train scatter: [0.2025 0.0673 0.5436 0.4984]
L1 regularization loss: 6.53E-01, L2 regularization loss: 1.55E-01
Test scatter: [0.2068 0.0669 0.5351 0.4912], Lowest was [0.2068 0.065  0.5351 0.4912]
Median for last 10 epochs: [0.2249 0.0669 0.5352 0.5023], Epochs since improvement 0
  5%|▌         | 27/500 [26:22<7:26:39, 56.66s/it]  6%|▌         | 28/500 [27:32<7:56:49, 60.61s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.16E+06, Train scatter: [0.2138 0.0664 0.5436 0.4961]
L1 regularization loss: 6.58E-01, L2 regularization loss: 1.58E-01
Test scatter: [0.2225 0.0654 0.535  0.4887], Lowest was [0.2068 0.065  0.535  0.4887]
Median for last 10 epochs: [0.2225 0.0657 0.5351 0.493 ], Epochs since improvement 0
  6%|▌         | 29/500 [28:19<7:24:36, 56.64s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.09E+06, Train scatter: [0.1924 0.0638 0.5437 0.4917]
L1 regularization loss: 6.65E-01, L2 regularization loss: 1.60E-01
Test scatter: [0.2011 0.0637 0.5351 0.4861], Lowest was [0.2011 0.0637 0.535  0.4861]
Median for last 10 epochs: [0.2095 0.0654 0.5351 0.4912], Epochs since improvement 0
  6%|▌         | 30/500 [29:36<8:11:44, 62.78s/it]  6%|▌         | 31/500 [30:23<7:33:14, 57.98s/it]  6%|▋         | 32/500 [31:34<8:01:06, 61.68s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.07E+06, Train scatter: [0.2635 0.0684 0.5436 0.5207]
L1 regularization loss: 6.72E-01, L2 regularization loss: 1.63E-01
Test scatter: [0.2754 0.0675 0.535  0.5138], Lowest was [0.2011 0.0637 0.535  0.4861]
Median for last 10 epochs: [0.2225 0.0669 0.5351 0.4912], Epochs since improvement 0
  7%|▋         | 33/500 [32:21<7:25:52, 57.29s/it]  7%|▋         | 34/500 [33:30<7:54:06, 61.04s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.08E+06, Train scatter: [0.2424 0.0685 0.5436 0.5186]
L1 regularization loss: 6.81E-01, L2 regularization loss: 1.67E-01
Test scatter: [0.2465 0.068  0.535  0.5121], Lowest was [0.2011 0.0637 0.535  0.4861]
Median for last 10 epochs: [0.2225 0.0669 0.535  0.4912], Epochs since improvement 2
  7%|▋         | 35/500 [34:17<7:20:21, 56.82s/it]  7%|▋         | 36/500 [35:27<7:48:40, 60.61s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.07E+06, Train scatter: [0.2018 0.0619 0.5437 0.4848]
L1 regularization loss: 6.90E-01, L2 regularization loss: 1.71E-01
Test scatter: [0.2123 0.0631 0.5352 0.4781], Lowest was [0.2011 0.0631 0.535  0.4781]
Median for last 10 epochs: [0.2225 0.0654 0.535  0.4887], Epochs since improvement 0
  7%|▋         | 37/500 [36:14<7:16:02, 56.51s/it]  8%|▊         | 38/500 [37:24<7:46:29, 60.58s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.08E+06, Train scatter: [0.241  0.0721 0.5437 0.5153]
L1 regularization loss: 7.01E-01, L2 regularization loss: 1.76E-01
Test scatter: [0.2495 0.0733 0.5351 0.5083], Lowest was [0.2011 0.0631 0.535  0.4781]
Median for last 10 epochs: [0.2465 0.0675 0.5351 0.5083], Epochs since improvement 2
  8%|▊         | 39/500 [38:11<7:14:12, 56.51s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.10E+06, Train scatter: [0.4074 0.073  0.5437 0.5066]
L1 regularization loss: 7.21E-01, L2 regularization loss: 1.85E-01
Test scatter: [0.4052 0.0725 0.5351 0.5035], Lowest was [0.2011 0.0631 0.535  0.4781]
Median for last 10 epochs: [0.2495 0.068  0.5351 0.5083], Epochs since improvement 4
  8%|▊         | 40/500 [39:28<7:59:45, 62.58s/it]  8%|▊         | 41/500 [40:15<7:22:55, 57.90s/it]  8%|▊         | 42/500 [41:25<7:50:29, 61.64s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.05E+06, Train scatter: [0.2951 0.072  0.5436 0.5157]
L1 regularization loss: 7.26E-01, L2 regularization loss: 1.89E-01
Test scatter: [0.2922 0.072  0.5351 0.5116], Lowest was [0.2011 0.0631 0.535  0.4781]
Median for last 10 epochs: [0.2495 0.072  0.5351 0.5083], Epochs since improvement 6
  9%|▊         | 43/500 [42:12<7:15:54, 57.23s/it]  9%|▉         | 44/500 [43:23<7:45:37, 61.27s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.03E+06, Train scatter: [0.2015 0.0698 0.5435 0.486 ]
L1 regularization loss: 7.36E-01, L2 regularization loss: 1.95E-01
Test scatter: [0.2089 0.0686 0.5349 0.4767], Lowest was [0.2011 0.0631 0.5349 0.4767]
Median for last 10 epochs: [0.2495 0.072  0.5351 0.5035], Epochs since improvement 0
  9%|▉         | 45/500 [44:09<7:11:51, 56.95s/it]  9%|▉         | 46/500 [45:19<7:39:03, 60.67s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.04E+06, Train scatter: [0.2727 0.0651 0.5434 0.476 ]
L1 regularization loss: 7.48E-01, L2 regularization loss: 2.01E-01
Test scatter: [0.274  0.0666 0.5349 0.4725], Lowest was [0.2011 0.0631 0.5349 0.4725]
Median for last 10 epochs: [0.274  0.072  0.5351 0.5035], Epochs since improvement 0
  9%|▉         | 47/500 [46:06<7:06:49, 56.53s/it] 10%|▉         | 48/500 [47:16<7:37:04, 60.67s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.01E+06, Train scatter: [0.2374 0.0643 0.5432 0.4964]
L1 regularization loss: 7.56E-01, L2 regularization loss: 2.07E-01
Test scatter: [0.2372 0.0646 0.5346 0.4912], Lowest was [0.2011 0.0631 0.5346 0.4725]
Median for last 10 epochs: [0.274  0.0686 0.5349 0.4912], Epochs since improvement 0
 10%|▉         | 49/500 [48:03<7:05:08, 56.56s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.03E+06, Train scatter: [0.4049 0.0605 0.5399 0.4674]
L1 regularization loss: 7.69E-01, L2 regularization loss: 2.17E-01
Test scatter: [0.3958 0.0618 0.5315 0.4671], Lowest was [0.2011 0.0618 0.5315 0.4671]
Median for last 10 epochs: [0.274  0.0666 0.5349 0.4767], Epochs since improvement 0
 10%|█         | 50/500 [49:19<7:48:32, 62.47s/it] 10%|█         | 51/500 [50:06<7:12:47, 57.83s/it] 10%|█         | 52/500 [51:16<7:38:54, 61.46s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 4.68E+07, Train scatter: [0.9343 0.1728 0.5441 0.9953]
L1 regularization loss: 1.04E+00, L2 regularization loss: 3.51E-01
Test scatter: [0.9187 0.1689 0.5355 0.985 ], Lowest was [0.2011 0.0618 0.5315 0.4671]
Median for last 10 epochs: [0.274  0.0666 0.5349 0.4767], Epochs since improvement 2
 11%|█         | 53/500 [52:03<7:05:16, 57.08s/it] 11%|█         | 54/500 [53:13<7:32:15, 60.84s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 5.74E+06, Train scatter: [0.9231 0.1508 0.544  0.9931]
L1 regularization loss: 1.06E+00, L2 regularization loss: 3.75E-01
Test scatter: [0.9081 0.148  0.5354 0.9828], Lowest was [0.2011 0.0618 0.5315 0.4671]
Median for last 10 epochs: [0.3958 0.0666 0.5349 0.4912], Epochs since improvement 4
 11%|█         | 55/500 [54:00<7:00:15, 56.66s/it] 11%|█         | 56/500 [55:10<7:30:15, 60.84s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.74E+06, Train scatter: [0.9096 0.1507 0.5441 0.9894]
L1 regularization loss: 1.07E+00, L2 regularization loss: 3.83E-01
Test scatter: [0.8951 0.148  0.5355 0.9793], Lowest was [0.2011 0.0618 0.5315 0.4671]
Median for last 10 epochs: [0.8951 0.148  0.5354 0.9793], Epochs since improvement 6
 11%|█▏        | 57/500 [55:57<6:58:25, 56.67s/it] 12%|█▏        | 58/500 [57:07<7:27:21, 60.73s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 4.27E+06, Train scatter: [0.7    0.1518 0.5439 0.9632]
L1 regularization loss: 1.08E+00, L2 regularization loss: 4.15E-01
Test scatter: [0.6921 0.1483 0.5354 0.9535], Lowest was [0.2011 0.0618 0.5315 0.4671]
Median for last 10 epochs: [0.8951 0.148  0.5354 0.9793], Epochs since improvement 8
 12%|█▏        | 59/500 [57:54<6:56:00, 56.60s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.88E+06, Train scatter: [0.613  0.1286 0.5405 0.6819]
L1 regularization loss: 1.10E+00, L2 regularization loss: 4.89E-01
Test scatter: [0.6051 0.126  0.532  0.6748], Lowest was [0.2011 0.0618 0.5315 0.4671]
Median for last 10 epochs: [0.8951 0.148  0.5354 0.9793], Epochs since improvement 10
 12%|█▏        | 60/500 [59:11<7:39:28, 62.66s/it] 12%|█▏        | 61/500 [59:58<7:03:38, 57.90s/it] 12%|█▏        | 62/500 [1:01:09<7:31:49, 61.89s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.54E+06, Train scatter: [0.5013 0.1078 0.5366 0.6149]
L1 regularization loss: 1.11E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.4953 0.1054 0.5282 0.6077], Lowest was [0.2011 0.0618 0.5282 0.4671]
Median for last 10 epochs: [0.6921 0.148  0.5354 0.9535], Epochs since improvement 0
 13%|█▎        | 63/500 [1:01:56<6:57:26, 57.31s/it] 13%|█▎        | 64/500 [1:03:05<7:23:13, 60.99s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.22E+06, Train scatter: [0.4605 0.1007 0.5326 0.5865]
L1 regularization loss: 1.12E+00, L2 regularization loss: 5.23E-01
Test scatter: [0.4504 0.0981 0.5246 0.5815], Lowest was [0.2011 0.0618 0.5246 0.4671]
Median for last 10 epochs: [0.6051 0.126  0.532  0.6748], Epochs since improvement 0
 13%|█▎        | 65/500 [1:03:52<6:50:37, 56.64s/it] 13%|█▎        | 66/500 [1:05:02<7:19:16, 60.73s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.98E+06, Train scatter: [0.466  0.1025 0.4477 0.6045]
L1 regularization loss: 1.13E+00, L2 regularization loss: 5.41E-01
Test scatter: [0.4646 0.1002 0.444  0.5984], Lowest was [0.2011 0.0618 0.444  0.4671]
Median for last 10 epochs: [0.4953 0.1054 0.5282 0.6077], Epochs since improvement 0
 13%|█▎        | 67/500 [1:05:49<6:47:30, 56.47s/it] 14%|█▎        | 68/500 [1:06:59<7:16:50, 60.67s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.58E+06, Train scatter: [0.4337 0.0913 0.4583 0.5893]
L1 regularization loss: 1.14E+00, L2 regularization loss: 5.58E-01
Test scatter: [0.4364 0.09   0.4566 0.5881], Lowest was [0.2011 0.0618 0.444  0.4671]
Median for last 10 epochs: [0.4646 0.1002 0.5246 0.5984], Epochs since improvement 2
 14%|█▍        | 69/500 [1:07:46<6:45:52, 56.50s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.43E+06, Train scatter: [0.4437 0.0834 0.438  0.5591]
L1 regularization loss: 1.15E+00, L2 regularization loss: 5.81E-01
Test scatter: [0.4352 0.082  0.4378 0.5551], Lowest was [0.2011 0.0618 0.4378 0.4671]
Median for last 10 epochs: [0.4504 0.0981 0.4566 0.5881], Epochs since improvement 0
 14%|█▍        | 70/500 [1:09:02<7:27:43, 62.47s/it] 14%|█▍        | 71/500 [1:09:49<6:53:20, 57.81s/it] 14%|█▍        | 72/500 [1:10:59<7:17:56, 61.39s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 2.35E+06, Train scatter: [0.4857 0.0861 0.4968 0.5759]
L1 regularization loss: 1.16E+00, L2 regularization loss: 6.06E-01
Test scatter: [0.4788 0.0855 0.4933 0.5712], Lowest was [0.2011 0.0618 0.4378 0.4671]
Median for last 10 epochs: [0.4504 0.09   0.4566 0.5815], Epochs since improvement 2
 15%|█▍        | 73/500 [1:11:46<6:45:43, 57.01s/it] 15%|█▍        | 74/500 [1:12:56<7:12:39, 60.94s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.20E+06, Train scatter: [0.5291 0.0771 0.4096 0.5571]
L1 regularization loss: 1.17E+00, L2 regularization loss: 6.30E-01
Test scatter: [0.511  0.076  0.4102 0.5479], Lowest was [0.2011 0.0618 0.4102 0.4671]
Median for last 10 epochs: [0.4646 0.0855 0.444  0.5712], Epochs since improvement 0
 15%|█▌        | 75/500 [1:13:43<6:41:41, 56.71s/it] 15%|█▌        | 76/500 [1:14:53<7:10:33, 60.93s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 1.75E+06, Train scatter: [0.3757 0.0736 0.3718 0.5444]
L1 regularization loss: 1.19E+00, L2 regularization loss: 6.62E-01
Test scatter: [0.3696 0.0725 0.374  0.5349], Lowest was [0.2011 0.0618 0.374  0.4671]
Median for last 10 epochs: [0.4364 0.082  0.4378 0.5551], Epochs since improvement 0
 15%|█▌        | 77/500 [1:15:40<6:39:12, 56.63s/it] 16%|█▌        | 78/500 [1:16:50<7:06:37, 60.66s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 1.23E+06, Train scatter: [0.4528 0.071  0.3619 0.555 ]
L1 regularization loss: 1.20E+00, L2 regularization loss: 6.91E-01
Test scatter: [0.4383 0.0707 0.3663 0.543 ], Lowest was [0.2011 0.0618 0.3663 0.4671]
Median for last 10 epochs: [0.4383 0.076  0.4102 0.5479], Epochs since improvement 0
 16%|█▌        | 79/500 [1:17:36<6:35:41, 56.39s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 9.90E+05, Train scatter: [0.4457 0.0737 0.3517 0.5873]
L1 regularization loss: 1.21E+00, L2 regularization loss: 7.20E-01
Test scatter: [0.4268 0.0711 0.3482 0.5693], Lowest was [0.2011 0.0618 0.3482 0.4671]
Median for last 10 epochs: [0.4383 0.0725 0.374  0.5479], Epochs since improvement 0
 16%|█▌        | 80/500 [1:18:53<7:17:01, 62.43s/it] 16%|█▌        | 81/500 [1:19:39<6:42:37, 57.65s/it] 16%|█▋        | 82/500 [1:20:50<7:08:40, 61.53s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 8.85E+05, Train scatter: [0.3758 0.0655 0.3136 0.5441]
L1 regularization loss: 1.22E+00, L2 regularization loss: 7.55E-01
Test scatter: [0.3727 0.0666 0.3246 0.5371], Lowest was [0.2011 0.0618 0.3246 0.4671]
Median for last 10 epochs: [0.4268 0.0711 0.3663 0.543 ], Epochs since improvement 0
 17%|█▋        | 83/500 [1:21:36<6:35:55, 56.97s/it] 17%|█▋        | 84/500 [1:22:46<7:02:11, 60.89s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 7.09E+05, Train scatter: [0.3874 0.066  0.3019 0.5558]
L1 regularization loss: 1.23E+00, L2 regularization loss: 7.94E-01
Test scatter: [0.376  0.0665 0.3041 0.5454], Lowest was [0.2011 0.0618 0.3041 0.4671]
Median for last 10 epochs: [0.376  0.0707 0.3482 0.543 ], Epochs since improvement 0
 17%|█▋        | 85/500 [1:23:33<6:31:33, 56.61s/it] 17%|█▋        | 86/500 [1:24:43<6:58:36, 60.67s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 6.77E+05, Train scatter: [0.2867 0.0649 0.3102 0.5519]
L1 regularization loss: 1.25E+00, L2 regularization loss: 8.33E-01
Test scatter: [0.2884 0.0656 0.3155 0.5447], Lowest was [0.2011 0.0618 0.3041 0.4671]
Median for last 10 epochs: [0.376  0.0666 0.3246 0.5447], Epochs since improvement 2
 17%|█▋        | 87/500 [1:25:30<6:28:42, 56.47s/it] 18%|█▊        | 88/500 [1:26:40<6:55:28, 60.51s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 5.75E+05, Train scatter: [0.2434 0.0617 0.2863 0.5378]
L1 regularization loss: 1.26E+00, L2 regularization loss: 8.71E-01
Test scatter: [0.2427 0.0595 0.2815 0.5221], Lowest was [0.2011 0.0595 0.2815 0.4671]
Median for last 10 epochs: [0.3727 0.0665 0.3155 0.5447], Epochs since improvement 0
 18%|█▊        | 89/500 [1:27:27<6:26:41, 56.45s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 5.86E+05, Train scatter: [0.2521 0.0592 0.2687 0.5274]
L1 regularization loss: 1.28E+00, L2 regularization loss: 9.06E-01
Test scatter: [0.2537 0.0604 0.2773 0.5199], Lowest was [0.2011 0.0595 0.2773 0.4671]
Median for last 10 epochs: [0.2884 0.0656 0.3041 0.5371], Epochs since improvement 0
 18%|█▊        | 90/500 [1:28:45<7:09:55, 62.92s/it] 18%|█▊        | 91/500 [1:29:32<6:36:08, 58.11s/it] 18%|█▊        | 92/500 [1:30:41<6:58:09, 61.49s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 5.89E+05, Train scatter: [0.2807 0.0609 0.266  0.5218]
L1 regularization loss: 1.29E+00, L2 regularization loss: 9.37E-01
Test scatter: [0.2821 0.0623 0.2716 0.5115], Lowest was [0.2011 0.0595 0.2716 0.4671]
Median for last 10 epochs: [0.2821 0.0623 0.2815 0.5221], Epochs since improvement 0
 19%|█▊        | 93/500 [1:31:28<6:26:57, 57.05s/it] 19%|█▉        | 94/500 [1:32:38<6:52:36, 60.98s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 4.49E+05, Train scatter: [0.316  0.0616 0.2888 0.5661]
L1 regularization loss: 1.31E+00, L2 regularization loss: 9.68E-01
Test scatter: [0.3144 0.0628 0.2954 0.5698], Lowest was [0.2011 0.0595 0.2716 0.4671]
Median for last 10 epochs: [0.2821 0.0623 0.2815 0.5221], Epochs since improvement 2
 19%|█▉        | 95/500 [1:33:24<6:22:19, 56.64s/it] 19%|█▉        | 96/500 [1:34:35<6:49:03, 60.75s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 4.42E+05, Train scatter: [0.2681 0.0631 0.3047 0.5576]
L1 regularization loss: 1.31E+00, L2 regularization loss: 9.95E-01
Test scatter: [0.2734 0.0652 0.3123 0.5605], Lowest was [0.2011 0.0595 0.2716 0.4671]
Median for last 10 epochs: [0.2734 0.0623 0.2815 0.5221], Epochs since improvement 4
 19%|█▉        | 97/500 [1:35:21<6:19:22, 56.48s/it] 20%|█▉        | 98/500 [1:36:33<6:48:30, 60.97s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 4.87E+05, Train scatter: [0.2682 0.0566 0.2603 0.5138]
L1 regularization loss: 1.33E+00, L2 regularization loss: 1.04E+00
Test scatter: [0.2614 0.056  0.2594 0.5012], Lowest was [0.2011 0.056  0.2594 0.4671]
Median for last 10 epochs: [0.2734 0.0623 0.2773 0.5199], Epochs since improvement 0
 20%|█▉        | 99/500 [1:37:19<6:18:15, 56.60s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 5.78E+05, Train scatter: [0.2684 0.0613 0.2659 0.5203]
L1 regularization loss: 1.36E+00, L2 regularization loss: 1.09E+00
Test scatter: [0.2649 0.0594 0.2646 0.5103], Lowest was [0.2011 0.056  0.2594 0.4671]
Median for last 10 epochs: [0.2734 0.0623 0.2716 0.5115], Epochs since improvement 2
 20%|██        | 100/500 [1:38:36<6:58:16, 62.74s/it] 20%|██        | 101/500 [1:39:23<6:24:46, 57.86s/it] 20%|██        | 102/500 [1:40:34<6:50:33, 61.89s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 3.81E+05, Train scatter: [0.2457 0.0551 0.2572 0.504 ]
L1 regularization loss: 1.35E+00, L2 regularization loss: 1.12E+00
Test scatter: [0.2429 0.0562 0.2652 0.4964], Lowest was [0.2011 0.056  0.2594 0.4671]
Median for last 10 epochs: [0.2649 0.0594 0.2652 0.5103], Epochs since improvement 4
 21%|██        | 103/500 [1:41:21<6:19:18, 57.32s/it] 21%|██        | 104/500 [1:42:30<6:42:29, 60.98s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 4.24E+05, Train scatter: [0.5162 0.087  0.3677 0.7063]
L1 regularization loss: 1.36E+00, L2 regularization loss: 1.15E+00
Test scatter: [0.5273 0.0886 0.3661 0.7164], Lowest was [0.2011 0.056  0.2594 0.4671]
Median for last 10 epochs: [0.2649 0.0594 0.2652 0.5103], Epochs since improvement 6
 21%|██        | 105/500 [1:43:17<6:13:28, 56.73s/it] 21%|██        | 106/500 [1:44:27<6:38:59, 60.76s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 4.08E+05, Train scatter: [0.2524 0.0623 0.2593 0.5227]
L1 regularization loss: 1.37E+00, L2 regularization loss: 1.19E+00
Test scatter: [0.2472 0.0591 0.2629 0.5128], Lowest was [0.2011 0.056  0.2594 0.4671]
Median for last 10 epochs: [0.2614 0.0591 0.2646 0.5103], Epochs since improvement 8
 21%|██▏       | 107/500 [1:45:14<6:10:42, 56.60s/it] 22%|██▏       | 108/500 [1:46:25<6:37:19, 60.81s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 3.66E+05, Train scatter: [0.2276 0.0549 0.2468 0.4963]
L1 regularization loss: 1.39E+00, L2 regularization loss: 1.24E+00
Test scatter: [0.2258 0.056  0.2541 0.4902], Lowest was [0.2011 0.056  0.2541 0.4671]
Median for last 10 epochs: [0.2472 0.0591 0.2646 0.5103], Epochs since improvement 0
 22%|██▏       | 109/500 [1:47:12<6:09:08, 56.65s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 3.83E+05, Train scatter: [0.3685 0.0544 0.2493 0.4962]
L1 regularization loss: 1.47E+00, L2 regularization loss: 1.32E+00
Test scatter: [0.3565 0.0548 0.2515 0.4916], Lowest was [0.2011 0.0548 0.2515 0.4671]
Median for last 10 epochs: [0.2472 0.0562 0.2629 0.4964], Epochs since improvement 0
 22%|██▏       | 110/500 [1:48:29<6:49:14, 62.96s/it] 22%|██▏       | 111/500 [1:49:16<6:16:25, 58.06s/it] 22%|██▏       | 112/500 [1:50:26<6:39:10, 61.73s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 2.95E+05, Train scatter: [0.2304 0.0549 0.2481 0.4908]
L1 regularization loss: 1.45E+00, L2 regularization loss: 1.35E+00
Test scatter: [0.2337 0.0559 0.2588 0.4876], Lowest was [0.2011 0.0548 0.2515 0.4671]
Median for last 10 epochs: [0.2472 0.056  0.2588 0.4916], Epochs since improvement 2
 23%|██▎       | 113/500 [1:51:13<6:08:39, 57.16s/it] 23%|██▎       | 114/500 [1:52:23<6:33:45, 61.21s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 2.62E+05, Train scatter: [0.2532 0.0611 0.2839 0.5047]
L1 regularization loss: 1.45E+00, L2 regularization loss: 1.38E+00
Test scatter: [0.2537 0.0622 0.2935 0.5037], Lowest was [0.2011 0.0548 0.2515 0.4671]
Median for last 10 epochs: [0.2472 0.056  0.2588 0.4916], Epochs since improvement 4
 23%|██▎       | 115/500 [1:53:10<6:04:25, 56.79s/it] 23%|██▎       | 116/500 [1:54:21<6:30:51, 61.07s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 3.08E+05, Train scatter: [0.283  0.0627 0.2583 0.5138]
L1 regularization loss: 1.47E+00, L2 regularization loss: 1.43E+00
Test scatter: [0.2758 0.0603 0.2591 0.5033], Lowest was [0.2011 0.0548 0.2515 0.4671]
Median for last 10 epochs: [0.2537 0.056  0.2588 0.4916], Epochs since improvement 6
 23%|██▎       | 117/500 [1:55:07<6:01:25, 56.62s/it] 24%|██▎       | 118/500 [1:56:18<6:28:01, 60.95s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 2.16E+05, Train scatter: [0.2276 0.0576 0.2535 0.4877]
L1 regularization loss: 1.47E+00, L2 regularization loss: 1.47E+00
Test scatter: [0.2235 0.0556 0.2524 0.4794], Lowest was [0.2011 0.0548 0.2515 0.4671]
Median for last 10 epochs: [0.2537 0.0559 0.2588 0.4916], Epochs since improvement 8
 24%|██▍       | 119/500 [1:57:05<5:59:17, 56.58s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.71E+05, Train scatter: [0.2448 0.0578 0.2644 0.4896]
L1 regularization loss: 1.50E+00, L2 regularization loss: 1.51E+00
Test scatter: [0.2454 0.0563 0.2692 0.4825], Lowest was [0.2011 0.0548 0.2515 0.4671]
Median for last 10 epochs: [0.2454 0.0563 0.2591 0.4876], Epochs since improvement 10
 24%|██▍       | 120/500 [1:58:22<6:37:43, 62.80s/it] 24%|██▍       | 121/500 [1:59:09<6:06:26, 58.01s/it] 24%|██▍       | 122/500 [2:00:19<6:28:34, 61.68s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 1.31E+05, Train scatter: [0.2948 0.0596 0.2742 0.4957]
L1 regularization loss: 1.52E+00, L2 regularization loss: 1.57E+00
Test scatter: [0.2772 0.0584 0.2736 0.4869], Lowest was [0.2011 0.0548 0.2515 0.4671]
Median for last 10 epochs: [0.2537 0.0584 0.2692 0.4869], Epochs since improvement 12
 25%|██▍       | 123/500 [2:01:06<5:59:49, 57.27s/it] 25%|██▍       | 124/500 [2:02:17<6:24:11, 61.31s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 7.63E+04, Train scatter: [0.2272 0.0605 0.2448 0.4927]
L1 regularization loss: 1.53E+00, L2 regularization loss: 1.61E+00
Test scatter: [0.224  0.0596 0.2467 0.4868], Lowest was [0.2011 0.0548 0.2467 0.4671]
Median for last 10 epochs: [0.2454 0.0584 0.2591 0.4868], Epochs since improvement 0
 25%|██▌       | 125/500 [2:03:04<5:56:16, 57.00s/it] 25%|██▌       | 126/500 [2:04:14<6:20:35, 61.06s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.98E+04, Train scatter: [0.2217 0.0513 0.2372 0.4625]
L1 regularization loss: 1.54E+00, L2 regularization loss: 1.65E+00
Test scatter: [0.2206 0.0513 0.2465 0.4581], Lowest was [0.2011 0.0513 0.2465 0.4581]
Median for last 10 epochs: [0.224  0.0563 0.2524 0.4825], Epochs since improvement 0
 25%|██▌       | 127/500 [2:05:01<5:52:28, 56.70s/it] 26%|██▌       | 128/500 [2:06:11<6:17:19, 60.86s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 7.03E+04, Train scatter: [0.2556 0.0554 0.2481 0.48  ]
L1 regularization loss: 1.63E+00, L2 regularization loss: 1.73E+00
Test scatter: [0.2544 0.0562 0.2519 0.478 ], Lowest was [0.2011 0.0513 0.2465 0.4581]
Median for last 10 epochs: [0.2454 0.0563 0.2519 0.4825], Epochs since improvement 2
 26%|██▌       | 129/500 [2:06:58<5:50:07, 56.62s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -1.82E+05, Train scatter: [0.1993 0.0519 0.244  0.4602]
L1 regularization loss: 1.59E+00, L2 regularization loss: 1.75E+00
Test scatter: [0.2019 0.0528 0.2518 0.459 ], Lowest was [0.2011 0.0513 0.2465 0.4581]
Median for last 10 epochs: [0.224  0.0562 0.2518 0.478 ], Epochs since improvement 4
 26%|██▌       | 130/500 [2:08:14<6:25:27, 62.51s/it] 26%|██▌       | 131/500 [2:09:01<5:55:40, 57.83s/it] 26%|██▋       | 132/500 [2:10:12<6:18:06, 61.65s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -2.91E+05, Train scatter: [0.1801 0.0481 0.2329 0.4443]
L1 regularization loss: 1.59E+00, L2 regularization loss: 1.78E+00
Test scatter: [0.179  0.048  0.2356 0.4393], Lowest was [0.179  0.048  0.2356 0.4393]
Median for last 10 epochs: [0.2206 0.0528 0.2467 0.459 ], Epochs since improvement 0
 27%|██▋       | 133/500 [2:10:58<5:48:42, 57.01s/it] 27%|██▋       | 134/500 [2:12:08<6:11:14, 60.86s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: -3.28E+05, Train scatter: [0.1794 0.0505 0.2319 0.4434]
L1 regularization loss: 1.59E+00, L2 regularization loss: 1.82E+00
Test scatter: [0.1776 0.0496 0.2322 0.4352], Lowest was [0.1776 0.048  0.2322 0.4352]
Median for last 10 epochs: [0.2019 0.0513 0.2465 0.4581], Epochs since improvement 0
 27%|██▋       | 135/500 [2:12:54<5:44:04, 56.56s/it] 27%|██▋       | 136/500 [2:14:04<6:07:43, 60.61s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: -3.40E+05, Train scatter: [0.1625 0.0471 0.2299 0.4362]
L1 regularization loss: 1.60E+00, L2 regularization loss: 1.85E+00
Test scatter: [0.161  0.0467 0.2359 0.429 ], Lowest was [0.161  0.0467 0.2322 0.429 ]
Median for last 10 epochs: [0.179  0.0496 0.2359 0.4393], Epochs since improvement 0
 27%|██▋       | 137/500 [2:14:51<5:41:06, 56.38s/it] 28%|██▊       | 138/500 [2:16:01<6:05:10, 60.53s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -3.58E+05, Train scatter: [0.1659 0.0458 0.2263 0.4453]
L1 regularization loss: 1.60E+00, L2 regularization loss: 1.89E+00
Test scatter: [0.1683 0.0456 0.23   0.4426], Lowest was [0.161  0.0456 0.23   0.429 ]
Median for last 10 epochs: [0.1776 0.048  0.2356 0.4393], Epochs since improvement 0
 28%|██▊       | 139/500 [2:16:48<5:39:34, 56.44s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -3.64E+05, Train scatter: [0.1566 0.0497 0.2314 0.442 ]
L1 regularization loss: 1.60E+00, L2 regularization loss: 1.92E+00
Test scatter: [0.1576 0.0488 0.2368 0.4366], Lowest was [0.1576 0.0456 0.23   0.429 ]
Median for last 10 epochs: [0.1683 0.048  0.2356 0.4366], Epochs since improvement 0
 28%|██▊       | 140/500 [2:18:05<6:15:01, 62.51s/it] 28%|██▊       | 141/500 [2:18:51<5:45:30, 57.75s/it] 28%|██▊       | 142/500 [2:20:01<6:06:29, 61.42s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -3.68E+05, Train scatter: [0.1694 0.0486 0.2269 0.4358]
L1 regularization loss: 1.66E+00, L2 regularization loss: 1.97E+00
Test scatter: [0.1722 0.0488 0.2321 0.4316], Lowest was [0.1576 0.0456 0.23   0.429 ]
Median for last 10 epochs: [0.1683 0.0488 0.2322 0.4352], Epochs since improvement 2
 29%|██▊       | 143/500 [2:20:48<5:38:52, 56.95s/it] 29%|██▉       | 144/500 [2:21:58<6:01:55, 61.00s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: -3.81E+05, Train scatter: [0.1747 0.0512 0.2361 0.4421]
L1 regularization loss: 1.62E+00, L2 regularization loss: 2.00E+00
Test scatter: [0.1744 0.0498 0.2361 0.4345], Lowest was [0.1576 0.0456 0.23   0.429 ]
Median for last 10 epochs: [0.1683 0.0488 0.2359 0.4345], Epochs since improvement 4
 29%|██▉       | 145/500 [2:22:45<5:35:02, 56.63s/it] 29%|██▉       | 146/500 [2:23:54<5:57:13, 60.55s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: -3.73E+05, Train scatter: [0.2032 0.0514 0.2604 0.4567]
L1 regularization loss: 1.67E+00, L2 regularization loss: 2.04E+00
Test scatter: [0.2011 0.0507 0.2646 0.4506], Lowest was [0.1576 0.0456 0.23   0.429 ]
Median for last 10 epochs: [0.1722 0.0488 0.2361 0.4366], Epochs since improvement 6
 29%|██▉       | 147/500 [2:24:41<5:32:00, 56.43s/it] 30%|██▉       | 148/500 [2:25:50<5:53:48, 60.31s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: -3.82E+05, Train scatter: [0.219  0.0556 0.2499 0.4301]
L1 regularization loss: 1.69E+00, L2 regularization loss: 2.09E+00
Test scatter: [0.2124 0.0544 0.2529 0.4239], Lowest was [0.1576 0.0456 0.23   0.4239]
Median for last 10 epochs: [0.1744 0.0498 0.2368 0.4345], Epochs since improvement 0
 30%|██▉       | 149/500 [2:26:37<5:28:38, 56.18s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: -3.91E+05, Train scatter: [0.1526 0.0451 0.2254 0.4173]
L1 regularization loss: 1.69E+00, L2 regularization loss: 2.13E+00
Test scatter: [0.1537 0.0442 0.2274 0.4119], Lowest was [0.1537 0.0442 0.2274 0.4119]
Median for last 10 epochs: [0.1744 0.0498 0.2361 0.4316], Epochs since improvement 0
 30%|███       | 150/500 [2:27:53<6:02:43, 62.18s/it] 30%|███       | 151/500 [2:28:40<5:34:44, 57.55s/it] 30%|███       | 152/500 [2:29:50<5:56:03, 61.39s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: -3.87E+05, Train scatter: [0.1374 0.0449 0.2266 0.4241]
L1 regularization loss: 1.73E+00, L2 regularization loss: 2.19E+00
Test scatter: [0.1386 0.0445 0.2283 0.4198], Lowest was [0.1386 0.0442 0.2274 0.4119]
Median for last 10 epochs: [0.1744 0.0498 0.2361 0.4239], Epochs since improvement 0
 31%|███       | 153/500 [2:30:37<5:29:03, 56.90s/it] 31%|███       | 154/500 [2:31:46<5:50:23, 60.76s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: -3.87E+05, Train scatter: [0.1365 0.045  0.2319 0.4221]
L1 regularization loss: 1.77E+00, L2 regularization loss: 2.24E+00
Test scatter: [0.1379 0.0446 0.2359 0.4145], Lowest was [0.1379 0.0442 0.2274 0.4119]
Median for last 10 epochs: [0.1537 0.0446 0.2359 0.4198], Epochs since improvement 0
 31%|███       | 155/500 [2:32:33<5:24:56, 56.51s/it] 31%|███       | 156/500 [2:33:43<5:47:22, 60.59s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: -3.95E+05, Train scatter: [0.1386 0.0457 0.2315 0.4284]
L1 regularization loss: 1.77E+00, L2 regularization loss: 2.29E+00
Test scatter: [0.138  0.0452 0.2339 0.4213], Lowest was [0.1379 0.0442 0.2274 0.4119]
Median for last 10 epochs: [0.1386 0.0446 0.2339 0.4198], Epochs since improvement 2
 31%|███▏      | 157/500 [2:34:30<5:22:27, 56.41s/it] 32%|███▏      | 158/500 [2:35:40<5:44:45, 60.49s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: -3.95E+05, Train scatter: [0.1308 0.0437 0.2313 0.4134]
L1 regularization loss: 1.79E+00, L2 regularization loss: 2.33E+00
Test scatter: [0.1301 0.0434 0.236  0.4088], Lowest was [0.1301 0.0434 0.2274 0.4088]
Median for last 10 epochs: [0.138  0.0445 0.2339 0.4145], Epochs since improvement 0
 32%|███▏      | 159/500 [2:36:26<5:19:50, 56.28s/it]Epoch: 160 done with learning rate 9.05E-03, Train loss: -4.00E+05, Train scatter: [0.2712 0.0808 0.4314 0.4986]
L1 regularization loss: 1.86E+00, L2 regularization loss: 2.43E+00
Test scatter: [0.2685 0.079  0.4265 0.4962], Lowest was [0.1301 0.0434 0.2274 0.4088]
Median for last 10 epochs: [0.138  0.0446 0.2359 0.4198], Epochs since improvement 2
 32%|███▏      | 160/500 [2:37:44<5:55:18, 62.70s/it] 32%|███▏      | 161/500 [2:38:30<5:26:49, 57.85s/it] 32%|███▏      | 162/500 [2:39:41<5:46:26, 61.50s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: -3.98E+05, Train scatter: [0.1608 0.047  0.2475 0.4317]
L1 regularization loss: 1.88E+00, L2 regularization loss: 2.48E+00
Test scatter: [0.1581 0.046  0.2469 0.4235], Lowest was [0.1301 0.0434 0.2274 0.4088]
Median for last 10 epochs: [0.138  0.0452 0.236  0.4213], Epochs since improvement 4
 33%|███▎      | 163/500 [2:40:27<5:20:18, 57.03s/it] 33%|███▎      | 164/500 [2:41:37<5:41:18, 60.95s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: -4.10E+05, Train scatter: [0.1292 0.0428 0.2194 0.4099]
L1 regularization loss: 1.87E+00, L2 regularization loss: 2.51E+00
Test scatter: [0.129  0.0423 0.2208 0.4038], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.138  0.0452 0.236  0.4213], Epochs since improvement 0
 33%|███▎      | 165/500 [2:42:24<5:17:01, 56.78s/it] 33%|███▎      | 166/500 [2:43:34<5:37:50, 60.69s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: -4.05E+05, Train scatter: [0.1536 0.0509 0.2686 0.4445]
L1 regularization loss: 1.92E+00, L2 regularization loss: 2.57E+00
Test scatter: [0.1498 0.0494 0.2699 0.435 ], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.1498 0.046  0.2469 0.4235], Epochs since improvement 2
 33%|███▎      | 167/500 [2:44:20<5:12:54, 56.38s/it] 34%|███▎      | 168/500 [2:45:31<5:35:35, 60.65s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: -4.06E+05, Train scatter: [0.1355 0.0463 0.2336 0.4138]
L1 regularization loss: 1.93E+00, L2 regularization loss: 2.62E+00
Test scatter: [0.1341 0.0459 0.2365 0.4089], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.1498 0.046  0.2469 0.4235], Epochs since improvement 4
 34%|███▍      | 169/500 [2:46:17<5:11:05, 56.39s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -2.07E+04, Train scatter: [0.5592 0.1311 0.542  0.8256]
L1 regularization loss: 2.12E+00, L2 regularization loss: 2.85E+00
Test scatter: [0.5496 0.1285 0.5334 0.8147], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.1498 0.046  0.2469 0.4235], Epochs since improvement 6
 34%|███▍      | 170/500 [2:47:35<5:44:40, 62.67s/it] 34%|███▍      | 171/500 [2:48:21<5:16:55, 57.80s/it] 34%|███▍      | 172/500 [2:49:31<5:35:18, 61.34s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -1.44E+05, Train scatter: [0.9023 0.1675 0.5362 0.7935]
L1 regularization loss: 2.30E+00, L2 regularization loss: 3.38E+00
Test scatter: [0.8876 0.1639 0.528  0.7916], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.1498 0.0494 0.2699 0.435 ], Epochs since improvement 8
 35%|███▍      | 173/500 [2:50:18<5:10:54, 57.05s/it] 35%|███▍      | 174/500 [2:51:28<5:30:58, 60.92s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -2.27E+05, Train scatter: [0.4668 0.0704 0.4662 0.5344]
L1 regularization loss: 2.30E+00, L2 regularization loss: 3.51E+00
Test scatter: [0.4546 0.0699 0.4575 0.5252], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.4546 0.0699 0.4575 0.5252], Epochs since improvement 10
 35%|███▌      | 175/500 [2:52:14<5:06:40, 56.62s/it] 35%|███▌      | 176/500 [2:53:25<5:28:50, 60.90s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -2.60E+05, Train scatter: [0.3921 0.0663 0.3772 0.5448]
L1 regularization loss: 2.36E+00, L2 regularization loss: 3.58E+00
Test scatter: [0.3769 0.0661 0.3757 0.5383], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.4546 0.0699 0.4575 0.5383], Epochs since improvement 12
 35%|███▌      | 177/500 [2:54:12<5:04:22, 56.54s/it] 36%|███▌      | 178/500 [2:55:22<5:26:28, 60.83s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -3.23E+05, Train scatter: [0.2157 0.0537 0.3781 0.4638]
L1 regularization loss: 2.33E+00, L2 regularization loss: 3.59E+00
Test scatter: [0.2126 0.053  0.3689 0.4557], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.4546 0.0699 0.4575 0.5383], Epochs since improvement 14
 36%|███▌      | 179/500 [2:56:09<5:02:22, 56.52s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -2.79E+05, Train scatter: [0.2279 0.0551 0.3948 0.4754]
L1 regularization loss: 2.37E+00, L2 regularization loss: 3.64E+00
Test scatter: [0.2268 0.0548 0.3855 0.4673], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.3769 0.0661 0.3855 0.5252], Epochs since improvement 16
 36%|███▌      | 180/500 [2:57:27<5:35:12, 62.85s/it] 36%|███▌      | 181/500 [2:58:13<5:08:16, 57.98s/it] 36%|███▋      | 182/500 [2:59:23<5:26:14, 61.56s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -3.53E+05, Train scatter: [0.1918 0.0503 0.2824 0.4467]
L1 regularization loss: 2.36E+00, L2 regularization loss: 3.64E+00
Test scatter: [0.1857 0.0496 0.2837 0.4418], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.2268 0.0548 0.3757 0.4673], Epochs since improvement 18
 37%|███▋      | 183/500 [3:00:10<5:01:42, 57.10s/it] 37%|███▋      | 184/500 [3:01:21<5:22:28, 61.23s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -3.77E+05, Train scatter: [0.1632 0.0463 0.2643 0.4307]
L1 regularization loss: 2.39E+00, L2 regularization loss: 3.67E+00
Test scatter: [0.1566 0.0455 0.2624 0.4233], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.2126 0.053  0.3689 0.4557], Epochs since improvement 20
 37%|███▋      | 185/500 [3:02:07<4:57:51, 56.73s/it] 37%|███▋      | 185/500 [3:03:17<5:12:05, 59.45s/it]
Epoch: 186 done with learning rate 8.41E-03, Train loss: -3.77E+05, Train scatter: [0.1524 0.0458 0.2985 0.4318]
L1 regularization loss: 2.44E+00, L2 regularization loss: 3.73E+00
Test scatter: [0.1455 0.045  0.2976 0.423 ], Lowest was [0.129  0.0423 0.2208 0.4038]
Median for last 10 epochs: [0.1857 0.0496 0.2976 0.4418], Epochs since improvement 22
Exited after 186 epochs due to early stopping
10997.47 seconds spent training, 21.995 seconds per epoch. Processed 3166 trees per second
[0.14545834 0.04497814 0.29754394 0.4230128 ]
{'epoch_exit': 185, 'scatter_m_star': 0.14545834, 'lowest_m_star': 0.12904616, 'last20_m_star': 0.21967831, 'last10_m_star': 0.1857315, 'scatter_v_disk': 0.044978138, 'lowest_v_disk': 0.042326257, 'last20_v_disk': 0.05393594, 'last10_v_disk': 0.04959674, 'scatter_m_cold': 0.29754394, 'lowest_m_cold': 0.22083987, 'last20_m_cold': 0.37233067, 'last10_m_cold': 0.2975527, 'scatter_sfr_100': 0.4230128, 'lowest_sfr_100': 0.40381932, 'last20_sfr_100': 0.46152505, 'last10_sfr_100': 0.44181928}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 3e-05, 'l2_lambda': 3e-05, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_tdxsmb
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:41<5:41:35, 41.07s/it]  0%|          | 2/500 [01:42<7:22:06, 53.27s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.02E+07, Train scatter: [0.9352 0.1709 0.5441 0.9954]
L1 regularization loss: 5.94E-01, L2 regularization loss: 1.13E-01
Test scatter: [0.9196 0.1674 0.5356 0.9851], Lowest was [0.9196 0.1674 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1674 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:22<6:31:21, 47.25s/it]  1%|          | 4/500 [03:25<7:20:43, 53.31s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.24E+07, Train scatter: [0.9352 0.1597 0.5441 0.9954]
L1 regularization loss: 5.97E-01, L2 regularization loss: 1.15E-01
Test scatter: [0.9196 0.1554 0.5356 0.9851], Lowest was [0.9196 0.1554 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1554 0.5356 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:05<6:40:46, 48.58s/it]  1%|          | 6/500 [05:08<7:19:25, 53.37s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.79E+07, Train scatter: [0.935  0.1209 0.5441 0.9954]
L1 regularization loss: 6.03E-01, L2 regularization loss: 1.20E-01
Test scatter: [0.9194 0.1197 0.5355 0.9851], Lowest was [0.9194 0.1197 0.5355 0.9851]
Median for last 10 epochs: [0.9194 0.1197 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [05:48<6:43:07, 49.06s/it]  2%|▏         | 8/500 [06:52<7:19:42, 53.62s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.37E+07, Train scatter: [0.9266 0.0962 0.544  0.8754]
L1 regularization loss: 6.11E-01, L2 regularization loss: 1.28E-01
Test scatter: [0.9118 0.0966 0.5354 0.874 ], Lowest was [0.9118 0.0966 0.5354 0.874 ]
Median for last 10 epochs: [0.9156 0.1082 0.5355 0.9296], Epochs since improvement 0
  2%|▏         | 9/500 [07:32<6:44:13, 49.40s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 1.01E+07, Train scatter: [0.8818 0.1066 0.544  0.7899]
L1 regularization loss: 6.20E-01, L2 regularization loss: 1.37E-01
Test scatter: [0.8702 0.1063 0.5354 0.7869], Lowest was [0.8702 0.0966 0.5354 0.7869]
Median for last 10 epochs: [0.9118 0.1063 0.5354 0.874 ], Epochs since improvement 0
  2%|▏         | 10/500 [08:41<7:34:14, 55.62s/it]  2%|▏         | 11/500 [09:21<6:55:02, 50.93s/it]  2%|▏         | 12/500 [10:24<7:22:37, 54.42s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.05E+06, Train scatter: [0.4866 0.0853 0.544  0.5729]
L1 regularization loss: 6.27E-01, L2 regularization loss: 1.43E-01
Test scatter: [0.4859 0.0863 0.5354 0.5692], Lowest was [0.4859 0.0863 0.5354 0.5692]
Median for last 10 epochs: [0.9118 0.1063 0.5354 0.874 ], Epochs since improvement 0
  3%|▎         | 13/500 [11:04<6:47:27, 50.20s/it]  3%|▎         | 14/500 [12:08<7:19:34, 54.27s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 5.19E+06, Train scatter: [0.366  0.0822 0.544  0.5442]
L1 regularization loss: 6.29E-01, L2 regularization loss: 1.45E-01
Test scatter: [0.3792 0.0832 0.5354 0.5423], Lowest was [0.3792 0.0832 0.5354 0.5423]
Median for last 10 epochs: [0.8702 0.0966 0.5354 0.7869], Epochs since improvement 0
  3%|▎         | 15/500 [12:48<6:44:29, 50.04s/it]  3%|▎         | 16/500 [13:52<7:16:36, 54.13s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.51E+06, Train scatter: [0.3643 0.0804 0.5439 0.5402]
L1 regularization loss: 6.31E-01, L2 regularization loss: 1.47E-01
Test scatter: [0.3668 0.0811 0.5354 0.5367], Lowest was [0.3668 0.0811 0.5354 0.5367]
Median for last 10 epochs: [0.4859 0.0863 0.5354 0.5692], Epochs since improvement 0
  3%|▎         | 17/500 [14:32<6:42:10, 49.96s/it]  4%|▎         | 18/500 [15:35<7:13:15, 53.93s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.26E+06, Train scatter: [0.2524 0.0789 0.5439 0.5336]
L1 regularization loss: 6.34E-01, L2 regularization loss: 1.49E-01
Test scatter: [0.2594 0.0796 0.5354 0.5291], Lowest was [0.2594 0.0796 0.5354 0.5291]
Median for last 10 epochs: [0.3792 0.0832 0.5354 0.5423], Epochs since improvement 0
  4%|▍         | 19/500 [16:16<6:40:27, 49.95s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 4.06E+06, Train scatter: [0.2815 0.077  0.5439 0.5216]
L1 regularization loss: 6.37E-01, L2 regularization loss: 1.50E-01
Test scatter: [0.2865 0.0775 0.5354 0.5212], Lowest was [0.2594 0.0775 0.5354 0.5212]
Median for last 10 epochs: [0.3668 0.0811 0.5354 0.5367], Epochs since improvement 0
  4%|▍         | 20/500 [17:26<7:27:57, 55.99s/it]  4%|▍         | 21/500 [18:06<6:49:32, 51.30s/it]  4%|▍         | 22/500 [19:10<7:18:53, 55.09s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.01E+06, Train scatter: [0.2491 0.0745 0.5439 0.5159]
L1 regularization loss: 6.39E-01, L2 regularization loss: 1.51E-01
Test scatter: [0.2529 0.0748 0.5353 0.5119], Lowest was [0.2529 0.0748 0.5353 0.5119]
Median for last 10 epochs: [0.2865 0.0796 0.5354 0.5291], Epochs since improvement 0
  5%|▍         | 23/500 [19:51<6:42:30, 50.63s/it]  5%|▍         | 24/500 [20:54<7:11:52, 54.44s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.98E+06, Train scatter: [0.4002 0.0769 0.5439 0.5612]
L1 regularization loss: 6.42E-01, L2 regularization loss: 1.53E-01
Test scatter: [0.4052 0.079  0.5353 0.5679], Lowest was [0.2529 0.0748 0.5353 0.5119]
Median for last 10 epochs: [0.2865 0.079  0.5354 0.5291], Epochs since improvement 0
  5%|▌         | 25/500 [21:34<6:37:47, 50.25s/it]  5%|▌         | 26/500 [22:37<7:07:09, 54.07s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.04E+06, Train scatter: [0.246  0.0747 0.5439 0.527 ]
L1 regularization loss: 6.45E-01, L2 regularization loss: 1.54E-01
Test scatter: [0.2542 0.0754 0.5353 0.5205], Lowest was [0.2529 0.0748 0.5353 0.5119]
Median for last 10 epochs: [0.2594 0.0775 0.5353 0.5212], Epochs since improvement 2
  5%|▌         | 27/500 [23:18<6:33:36, 49.93s/it]  6%|▌         | 28/500 [24:21<7:04:44, 53.99s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.90E+06, Train scatter: [0.2662 0.0776 0.5438 0.5516]
L1 regularization loss: 6.49E-01, L2 regularization loss: 1.55E-01
Test scatter: [0.274  0.078  0.5353 0.5452], Lowest was [0.2529 0.0748 0.5353 0.5119]
Median for last 10 epochs: [0.274  0.0775 0.5353 0.5212], Epochs since improvement 0
  6%|▌         | 29/500 [25:01<6:31:37, 49.89s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.81E+06, Train scatter: [0.2607 0.0721 0.5438 0.5143]
L1 regularization loss: 6.53E-01, L2 regularization loss: 1.57E-01
Test scatter: [0.2648 0.0725 0.5353 0.5107], Lowest was [0.2529 0.0725 0.5353 0.5107]
Median for last 10 epochs: [0.2648 0.0754 0.5353 0.5205], Epochs since improvement 0
  6%|▌         | 30/500 [26:11<7:17:55, 55.91s/it]  6%|▌         | 31/500 [26:52<6:40:36, 51.25s/it]  6%|▋         | 32/500 [27:55<7:08:11, 54.90s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.79E+06, Train scatter: [0.2099 0.0717 0.5438 0.5191]
L1 regularization loss: 6.58E-01, L2 regularization loss: 1.59E-01
Test scatter: [0.2191 0.0718 0.5352 0.5149], Lowest was [0.2191 0.0718 0.5352 0.5107]
Median for last 10 epochs: [0.2648 0.0754 0.5353 0.5205], Epochs since improvement 0
  7%|▋         | 33/500 [28:36<6:33:24, 50.54s/it]  7%|▋         | 34/500 [29:39<7:02:09, 54.36s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.77E+06, Train scatter: [0.2069 0.0703 0.5438 0.5083]
L1 regularization loss: 6.63E-01, L2 regularization loss: 1.61E-01
Test scatter: [0.2134 0.0708 0.5352 0.5046], Lowest was [0.2134 0.0708 0.5352 0.5046]
Median for last 10 epochs: [0.2542 0.0725 0.5353 0.5149], Epochs since improvement 0
  7%|▋         | 35/500 [30:19<6:28:57, 50.19s/it]  7%|▋         | 36/500 [31:23<7:00:13, 54.34s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.72E+06, Train scatter: [0.1926 0.0695 0.5437 0.502 ]
L1 regularization loss: 6.68E-01, L2 regularization loss: 1.63E-01
Test scatter: [0.1999 0.0697 0.5351 0.497 ], Lowest was [0.1999 0.0697 0.5351 0.497 ]
Median for last 10 epochs: [0.2191 0.0718 0.5352 0.5107], Epochs since improvement 0
  7%|▋         | 37/500 [32:04<6:27:09, 50.17s/it]  8%|▊         | 38/500 [33:06<6:55:06, 53.91s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.74E+06, Train scatter: [0.2238 0.0699 0.5436 0.5052]
L1 regularization loss: 6.75E-01, L2 regularization loss: 1.66E-01
Test scatter: [0.2366 0.0701 0.5351 0.4992], Lowest was [0.1999 0.0697 0.5351 0.497 ]
Median for last 10 epochs: [0.2191 0.0708 0.5352 0.5046], Epochs since improvement 0
  8%|▊         | 39/500 [33:47<6:23:11, 49.87s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.73E+06, Train scatter: [0.2506 0.0736 0.5436 0.5488]
L1 regularization loss: 6.80E-01, L2 regularization loss: 1.69E-01
Test scatter: [0.2611 0.0749 0.535  0.5516], Lowest was [0.1999 0.0697 0.535  0.497 ]
Median for last 10 epochs: [0.2191 0.0708 0.5351 0.5046], Epochs since improvement 0
  8%|▊         | 40/500 [34:57<7:08:04, 55.84s/it]  8%|▊         | 41/500 [35:37<6:31:22, 51.16s/it]  8%|▊         | 42/500 [36:40<6:58:34, 54.84s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.67E+06, Train scatter: [0.2258 0.0686 0.5435 0.5131]
L1 regularization loss: 6.87E-01, L2 regularization loss: 1.72E-01
Test scatter: [0.2363 0.0696 0.535  0.5134], Lowest was [0.1999 0.0696 0.535  0.497 ]
Median for last 10 epochs: [0.2363 0.0701 0.5351 0.5046], Epochs since improvement 0
  9%|▊         | 43/500 [37:21<6:24:35, 50.49s/it]  9%|▉         | 44/500 [38:24<6:52:43, 54.31s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.64E+06, Train scatter: [0.1929 0.0652 0.5435 0.5006]
L1 regularization loss: 6.91E-01, L2 regularization loss: 1.75E-01
Test scatter: [0.1995 0.0658 0.535  0.4957], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.2363 0.0697 0.535  0.4992], Epochs since improvement 0
  9%|▉         | 45/500 [39:04<6:19:52, 50.09s/it]  9%|▉         | 46/500 [40:08<6:51:13, 54.35s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.60E+06, Train scatter: [0.2098 0.0754 0.5437 0.5309]
L1 regularization loss: 7.12E-01, L2 regularization loss: 1.85E-01
Test scatter: [0.2119 0.0752 0.5351 0.5287], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.2363 0.0701 0.535  0.5134], Epochs since improvement 2
  9%|▉         | 47/500 [40:49<6:18:23, 50.12s/it] 10%|▉         | 48/500 [41:52<6:48:35, 54.24s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 5.99E+06, Train scatter: [0.9136 0.1725 0.5441 0.9869]
L1 regularization loss: 8.92E-01, L2 regularization loss: 2.60E-01
Test scatter: [0.8972 0.1678 0.5355 0.9762], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.2363 0.0749 0.535  0.5287], Epochs since improvement 4
 10%|▉         | 49/500 [42:33<6:16:14, 50.05s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 5.16E+06, Train scatter: [0.8945 0.1655 0.544  0.981 ]
L1 regularization loss: 9.00E-01, L2 regularization loss: 2.73E-01
Test scatter: [0.877  0.162  0.5355 0.9705], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.2363 0.0752 0.5351 0.5287], Epochs since improvement 6
 10%|█         | 50/500 [43:43<6:59:51, 55.98s/it] 10%|█         | 51/500 [44:23<6:24:25, 51.37s/it] 10%|█         | 52/500 [45:27<6:52:06, 55.19s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 5.00E+06, Train scatter: [0.6625 0.1557 0.544  0.9623]
L1 regularization loss: 9.06E-01, L2 regularization loss: 2.82E-01
Test scatter: [0.6486 0.1519 0.5354 0.9523], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.6486 0.1519 0.5354 0.9523], Epochs since improvement 8
 11%|█         | 53/500 [46:08<6:18:01, 50.74s/it] 11%|█         | 54/500 [47:13<6:49:00, 55.02s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 4.78E+06, Train scatter: [0.6678 0.1286 0.5439 0.7374]
L1 regularization loss: 9.21E-01, L2 regularization loss: 3.02E-01
Test scatter: [0.6647 0.1261 0.5354 0.732 ], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.6647 0.1519 0.5354 0.9523], Epochs since improvement 10
 11%|█         | 55/500 [47:53<6:15:07, 50.58s/it] 11%|█         | 56/500 [48:56<6:42:56, 54.45s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.41E+06, Train scatter: [0.5451 0.1076 0.5438 0.6566]
L1 regularization loss: 9.35E-01, L2 regularization loss: 3.23E-01
Test scatter: [0.5501 0.1065 0.5352 0.6553], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.6647 0.1519 0.5354 0.9523], Epochs since improvement 12
 11%|█▏        | 57/500 [49:37<6:11:01, 50.25s/it] 12%|█▏        | 58/500 [50:40<6:38:51, 54.14s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.85E+06, Train scatter: [0.5449 0.1005 0.5438 0.6237]
L1 regularization loss: 9.45E-01, L2 regularization loss: 3.38E-01
Test scatter: [0.5437 0.1003 0.5353 0.6206], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.6486 0.1261 0.5354 0.732 ], Epochs since improvement 14
 12%|█▏        | 59/500 [51:20<6:07:13, 49.96s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.85E+06, Train scatter: [0.9058 0.1148 0.5439 0.7251]
L1 regularization loss: 9.56E-01, L2 regularization loss: 3.50E-01
Test scatter: [0.8896 0.1142 0.5353 0.7251], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.6486 0.1142 0.5353 0.7251], Epochs since improvement 16
 12%|█▏        | 60/500 [52:30<6:50:37, 56.00s/it] 12%|█▏        | 61/500 [53:11<6:15:36, 51.34s/it] 12%|█▏        | 62/500 [54:14<6:41:09, 54.95s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.79E+06, Train scatter: [0.8558 0.1199 0.5439 0.7585]
L1 regularization loss: 9.61E-01, L2 regularization loss: 3.58E-01
Test scatter: [0.8406 0.1188 0.5353 0.7592], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.6647 0.1142 0.5353 0.7251], Epochs since improvement 18
 13%|█▎        | 63/500 [54:55<6:08:40, 50.62s/it] 13%|█▎        | 64/500 [55:58<6:35:42, 54.45s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.53E+06, Train scatter: [0.6148 0.1047 0.5439 0.6858]
L1 regularization loss: 9.63E-01, L2 regularization loss: 3.64E-01
Test scatter: [0.5954 0.1028 0.5353 0.6767], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.5954 0.1065 0.5353 0.6767], Epochs since improvement 20
 13%|█▎        | 65/500 [56:38<6:03:40, 50.16s/it] 13%|█▎        | 65/500 [57:42<6:26:10, 53.27s/it]
Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.47E+06, Train scatter: [0.5276 0.1029 0.5439 0.6887]
L1 regularization loss: 9.67E-01, L2 regularization loss: 3.71E-01
Test scatter: [0.5198 0.1014 0.5353 0.6763], Lowest was [0.1995 0.0658 0.535  0.4957]
Median for last 10 epochs: [0.5954 0.1028 0.5353 0.6767], Epochs since improvement 22
Exited after 66 epochs due to early stopping
3462.33 seconds spent training, 6.925 seconds per epoch. Processed 10056 trees per second
[0.5197942  0.10141938 0.53527063 0.67627424]
{'epoch_exit': 65, 'scatter_m_star': 0.5197942, 'lowest_m_star': 0.19951305, 'last20_m_star': 0.65665865, 'last10_m_star': 0.59540015, 'scatter_v_disk': 0.10141938, 'lowest_v_disk': 0.0658096, 'last20_v_disk': 0.11650428, 'last10_v_disk': 0.10281146, 'scatter_m_cold': 0.53527063, 'lowest_m_cold': 0.53496546, 'last20_m_cold': 0.5353327, 'last10_m_cold': 0.53530604, 'scatter_sfr_100': 0.67627424, 'lowest_sfr_100': 0.49566537, 'last20_sfr_100': 0.72857666, 'last10_sfr_100': 0.67673606}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 3e-05, 'l2_lambda': 3e-05, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_khtocy
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:01<8:29:23, 61.25s/it]  0%|          | 2/500 [02:29<10:41:26, 77.28s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.19E+07, Train scatter: [0.9352 0.1433 0.5441 0.9954]
L1 regularization loss: 7.36E-01, L2 regularization loss: 1.27E-01
Test scatter: [0.9196 0.1395 0.5355 0.9851], Lowest was [0.9196 0.1395 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1395 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:30<9:39:03, 69.91s/it]   1%|          | 4/500 [05:00<10:42:59, 77.78s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.09E+07, Train scatter: [0.9336 0.1034 0.544  0.9954]
L1 regularization loss: 7.40E-01, L2 regularization loss: 1.29E-01
Test scatter: [0.918  0.1026 0.5354 0.9851], Lowest was [0.918  0.1026 0.5354 0.9851]
Median for last 10 epochs: [0.918  0.1026 0.5354 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:01<9:52:11, 71.78s/it]   1%|          | 6/500 [07:31<10:42:12, 78.00s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 7.85E+07, Train scatter: [0.8271 0.0874 0.5396 0.9954]
L1 regularization loss: 7.47E-01, L2 regularization loss: 1.32E-01
Test scatter: [0.816  0.0881 0.5312 0.9851], Lowest was [0.816  0.0881 0.5312 0.9851]
Median for last 10 epochs: [0.816  0.0881 0.5312 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [08:33<9:55:54, 72.52s/it]   2%|▏         | 8/500 [10:02<10:39:17, 77.96s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.25E+07, Train scatter: [0.8113 0.0922 0.4424 0.9954]
L1 regularization loss: 7.53E-01, L2 regularization loss: 1.35E-01
Test scatter: [0.8071 0.0925 0.4361 0.9851], Lowest was [0.8071 0.0881 0.4361 0.9851]
Median for last 10 epochs: [0.8115 0.0903 0.4836 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [11:03<9:54:27, 72.64s/it] Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.07E+07, Train scatter: [0.5759 0.0877 0.3691 0.9954]
L1 regularization loss: 7.57E-01, L2 regularization loss: 1.39E-01
Test scatter: [0.5741 0.0879 0.3644 0.9851], Lowest was [0.5741 0.0879 0.3644 0.9851]
Median for last 10 epochs: [0.8071 0.0881 0.4361 0.9851], Epochs since improvement 0
  2%|▏         | 10/500 [12:40<10:54:54, 80.19s/it]  2%|▏         | 11/500 [13:41<10:05:58, 74.35s/it]  2%|▏         | 12/500 [15:11<10:41:27, 78.87s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.00E+07, Train scatter: [0.5746 0.0849 0.3671 0.9954]
L1 regularization loss: 7.61E-01, L2 regularization loss: 1.42E-01
Test scatter: [0.5873 0.0862 0.3665 0.9851], Lowest was [0.5741 0.0862 0.3644 0.9851]
Median for last 10 epochs: [0.8071 0.0881 0.4361 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [16:12<9:56:36, 73.50s/it]   3%|▎         | 14/500 [17:41<10:33:37, 78.22s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.91E+07, Train scatter: [0.5708 0.0815 0.3253 0.9954]
L1 regularization loss: 7.66E-01, L2 regularization loss: 1.44E-01
Test scatter: [0.5825 0.0824 0.3268 0.9851], Lowest was [0.5741 0.0824 0.3268 0.9851]
Median for last 10 epochs: [0.5873 0.0879 0.3665 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [18:42<9:50:14, 73.02s/it]   3%|▎         | 16/500 [20:11<10:27:36, 77.80s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.73E+07, Train scatter: [0.5195 0.0885 0.4695 0.9955]
L1 regularization loss: 7.69E-01, L2 regularization loss: 1.46E-01
Test scatter: [0.5233 0.0903 0.4744 0.9852], Lowest was [0.5233 0.0824 0.3268 0.9851]
Median for last 10 epochs: [0.5825 0.0879 0.3665 0.9851], Epochs since improvement 0
  3%|▎         | 17/500 [21:12<9:45:36, 72.75s/it]   4%|▎         | 18/500 [22:42<10:26:23, 77.97s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.08E+07, Train scatter: [0.5567 0.08   0.3191 0.9634]
L1 regularization loss: 7.76E-01, L2 regularization loss: 1.50E-01
Test scatter: [0.576  0.0799 0.3199 0.9556], Lowest was [0.5233 0.0799 0.3199 0.9556]
Median for last 10 epochs: [0.576  0.0862 0.3644 0.9851], Epochs since improvement 0
  4%|▍         | 19/500 [23:43<9:44:10, 72.87s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.21E+06, Train scatter: [0.4529 0.0759 0.3471 0.6393]
L1 regularization loss: 7.86E-01, L2 regularization loss: 1.55E-01
Test scatter: [0.4513 0.0755 0.3508 0.6411], Lowest was [0.4513 0.0755 0.3199 0.6411]
Median for last 10 epochs: [0.576  0.0824 0.3508 0.9851], Epochs since improvement 0
  4%|▍         | 20/500 [25:20<10:40:28, 80.06s/it]  4%|▍         | 21/500 [26:21<9:53:41, 74.37s/it]   4%|▍         | 22/500 [27:51<10:29:39, 79.04s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.64E+06, Train scatter: [0.4264 0.0727 0.3205 0.5352]
L1 regularization loss: 7.98E-01, L2 regularization loss: 1.59E-01
Test scatter: [0.4192 0.0734 0.3241 0.5409], Lowest was [0.4192 0.0734 0.3199 0.5409]
Median for last 10 epochs: [0.5233 0.0799 0.3268 0.9556], Epochs since improvement 0
  5%|▍         | 23/500 [28:52<9:45:56, 73.70s/it]   5%|▍         | 24/500 [30:21<10:21:32, 78.35s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.28E+06, Train scatter: [0.4222 0.0683 0.2994 0.4992]
L1 regularization loss: 8.14E-01, L2 regularization loss: 1.66E-01
Test scatter: [0.4201 0.0687 0.3015 0.5011], Lowest was [0.4192 0.0687 0.3015 0.5011]
Median for last 10 epochs: [0.4513 0.0755 0.3241 0.6411], Epochs since improvement 0
  5%|▌         | 25/500 [31:22<9:39:20, 73.18s/it]   5%|▌         | 26/500 [32:52<10:17:16, 78.14s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 2.95E+06, Train scatter: [0.4175 0.0663 0.2933 0.5045]
L1 regularization loss: 8.32E-01, L2 regularization loss: 1.76E-01
Test scatter: [0.4145 0.0658 0.293  0.5027], Lowest was [0.4145 0.0658 0.293  0.5011]
Median for last 10 epochs: [0.4201 0.0734 0.3199 0.5409], Epochs since improvement 0
  5%|▌         | 27/500 [33:53<9:35:44, 73.03s/it]   6%|▌         | 28/500 [35:23<10:15:04, 78.19s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.89E+06, Train scatter: [0.3716 0.0672 0.3024 0.4828]
L1 regularization loss: 8.53E-01, L2 regularization loss: 1.89E-01
Test scatter: [0.3697 0.067  0.3033 0.4842], Lowest was [0.3697 0.0658 0.293  0.4842]
Median for last 10 epochs: [0.4192 0.0687 0.3033 0.5027], Epochs since improvement 0
  6%|▌         | 29/500 [36:24<9:33:11, 73.02s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.73E+06, Train scatter: [0.3693 0.0638 0.3004 0.4988]
L1 regularization loss: 8.75E-01, L2 regularization loss: 2.07E-01
Test scatter: [0.3734 0.0642 0.3028 0.501 ], Lowest was [0.3697 0.0642 0.293  0.4842]
Median for last 10 epochs: [0.4145 0.067  0.3028 0.5011], Epochs since improvement 0
  6%|▌         | 30/500 [38:01<10:28:25, 80.23s/it]  6%|▌         | 31/500 [39:03<9:42:24, 74.51s/it]   6%|▋         | 32/500 [40:32<10:15:19, 78.89s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.70E+06, Train scatter: [0.3921 0.0687 0.3429 0.5094]
L1 regularization loss: 9.02E-01, L2 regularization loss: 2.26E-01
Test scatter: [0.3866 0.0699 0.3541 0.5128], Lowest was [0.3697 0.0642 0.293  0.4842]
Median for last 10 epochs: [0.3866 0.067  0.3028 0.5011], Epochs since improvement 2
  7%|▋         | 33/500 [41:33<9:32:17, 73.53s/it]   7%|▋         | 34/500 [43:03<10:09:05, 78.42s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.60E+06, Train scatter: [0.3984 0.0622 0.2865 0.484 ]
L1 regularization loss: 9.23E-01, L2 regularization loss: 2.42E-01
Test scatter: [0.3901 0.0625 0.2917 0.4884], Lowest was [0.3697 0.0625 0.2917 0.4842]
Median for last 10 epochs: [0.3866 0.0658 0.3028 0.501 ], Epochs since improvement 0
  7%|▋         | 35/500 [44:04<9:27:28, 73.22s/it]   7%|▋         | 36/500 [45:34<10:06:18, 78.40s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.55E+06, Train scatter: [0.3546 0.0608 0.3064 0.4834]
L1 regularization loss: 9.51E-01, L2 regularization loss: 2.58E-01
Test scatter: [0.3528 0.0608 0.308  0.4841], Lowest was [0.3528 0.0608 0.2917 0.4841]
Median for last 10 epochs: [0.3734 0.0642 0.3033 0.4884], Epochs since improvement 0
  7%|▋         | 37/500 [46:35<9:24:43, 73.18s/it]   8%|▊         | 38/500 [48:06<10:04:05, 78.45s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.49E+06, Train scatter: [0.3924 0.0662 0.3114 0.5112]
L1 regularization loss: 9.77E-01, L2 regularization loss: 2.75E-01
Test scatter: [0.3906 0.0691 0.3166 0.522 ], Lowest was [0.3528 0.0608 0.2917 0.4841]
Median for last 10 epochs: [0.3866 0.0642 0.308  0.501 ], Epochs since improvement 2
  8%|▊         | 39/500 [49:07<9:22:28, 73.21s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.54E+06, Train scatter: [0.3953 0.0617 0.2913 0.4898]
L1 regularization loss: 9.99E-01, L2 regularization loss: 2.92E-01
Test scatter: [0.3887 0.0624 0.2948 0.4968], Lowest was [0.3528 0.0608 0.2917 0.4841]
Median for last 10 epochs: [0.3887 0.0625 0.308  0.4968], Epochs since improvement 4
  8%|▊         | 40/500 [50:43<10:14:43, 80.18s/it]  8%|▊         | 41/500 [51:44<9:29:05, 74.39s/it]   8%|▊         | 42/500 [53:14<10:02:22, 78.91s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.31E+06, Train scatter: [0.4072 0.06   0.2736 0.4587]
L1 regularization loss: 1.02E+00, L2 regularization loss: 3.12E-01
Test scatter: [0.3976 0.0593 0.2776 0.463 ], Lowest was [0.3528 0.0593 0.2776 0.463 ]
Median for last 10 epochs: [0.3901 0.0624 0.2948 0.4884], Epochs since improvement 0
  9%|▊         | 43/500 [54:15<9:20:00, 73.52s/it]   9%|▉         | 44/500 [55:44<9:55:06, 78.30s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.28E+06, Train scatter: [0.4126 0.0575 0.3015 0.458 ]
L1 regularization loss: 1.05E+00, L2 regularization loss: 3.34E-01
Test scatter: [0.4041 0.0577 0.3084 0.4597], Lowest was [0.3528 0.0577 0.2776 0.4597]
Median for last 10 epochs: [0.3906 0.0608 0.308  0.4841], Epochs since improvement 0
  9%|▉         | 45/500 [56:45<9:15:09, 73.21s/it]  9%|▉         | 46/500 [58:15<9:51:21, 78.15s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.16E+06, Train scatter: [0.4092 0.0583 0.2797 0.4476]
L1 regularization loss: 1.08E+00, L2 regularization loss: 3.57E-01
Test scatter: [0.4034 0.0593 0.2817 0.4508], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.3976 0.0593 0.2948 0.463 ], Epochs since improvement 0
  9%|▉         | 47/500 [59:16<9:11:55, 73.10s/it] 10%|▉         | 48/500 [1:00:45<9:46:57, 77.91s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.93E+06, Train scatter: [0.3561 0.0616 0.2851 0.4719]
L1 regularization loss: 1.10E+00, L2 regularization loss: 3.79E-01
Test scatter: [0.3538 0.0607 0.2832 0.4721], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.3976 0.0593 0.2832 0.463 ], Epochs since improvement 2
 10%|▉         | 49/500 [1:01:47<9:07:51, 72.89s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.58E+07, Train scatter: [0.9345 0.1728 0.5441 0.9954]
L1 regularization loss: 2.60E+00, L2 regularization loss: 8.88E-01
Test scatter: [0.9189 0.169  0.5355 0.9851], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.4034 0.0593 0.2832 0.463 ], Epochs since improvement 4
 10%|█         | 50/500 [1:03:25<10:03:51, 80.51s/it] 10%|█         | 51/500 [1:04:26<9:18:58, 74.70s/it]  10%|█         | 52/500 [1:05:57<9:53:24, 79.47s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.32E+07, Train scatter: [0.9423 0.1728 0.544  0.9953]
L1 regularization loss: 2.61E+00, L2 regularization loss: 9.73E-01
Test scatter: [0.9265 0.169  0.5355 0.9849], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.4041 0.0607 0.3084 0.4721], Epochs since improvement 6
 11%|█         | 53/500 [1:06:58<9:11:03, 73.97s/it] 11%|█         | 54/500 [1:08:27<9:44:24, 78.62s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.21E+06, Train scatter: [0.9376 0.1817 0.544  0.9527]
L1 regularization loss: 2.63E+00, L2 regularization loss: 1.11E+00
Test scatter: [0.9219 0.1776 0.5355 0.9434], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.9189 0.169  0.5355 0.9434], Epochs since improvement 8
 11%|█         | 55/500 [1:09:28<9:03:42, 73.31s/it] 11%|█         | 56/500 [1:10:58<9:39:35, 78.32s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.55E+06, Train scatter: [0.9411 0.1846 0.544  0.7969]
L1 regularization loss: 2.64E+00, L2 regularization loss: 1.13E+00
Test scatter: [0.9254 0.1804 0.5354 0.7913], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.9219 0.169  0.5355 0.9434], Epochs since improvement 10
 11%|█▏        | 57/500 [1:11:59<9:00:03, 73.15s/it] 12%|█▏        | 58/500 [1:13:30<9:37:01, 78.33s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.17E+06, Train scatter: [0.9399 0.1639 0.5439 0.7662]
L1 regularization loss: 2.64E+00, L2 regularization loss: 1.13E+00
Test scatter: [0.9242 0.1604 0.5353 0.7614], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.9242 0.169  0.5355 0.9434], Epochs since improvement 12
 12%|█▏        | 59/500 [1:14:31<8:57:32, 73.13s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.06E+06, Train scatter: [0.9397 0.135  0.5438 0.7494]
L1 regularization loss: 2.64E+00, L2 regularization loss: 1.14E+00
Test scatter: [0.924  0.1328 0.5352 0.7452], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.9242 0.169  0.5354 0.7913], Epochs since improvement 14
 12%|█▏        | 60/500 [1:16:08<9:49:09, 80.34s/it] 12%|█▏        | 61/500 [1:17:09<9:05:34, 74.57s/it] 12%|█▏        | 62/500 [1:18:38<9:36:18, 78.95s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 9.72E+05, Train scatter: [0.939  0.1137 0.5435 0.7451]
L1 regularization loss: 2.64E+00, L2 regularization loss: 1.15E+00
Test scatter: [0.9233 0.1126 0.535  0.7426], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.924  0.1604 0.5353 0.7614], Epochs since improvement 16
 13%|█▎        | 63/500 [1:19:40<8:56:36, 73.68s/it] 13%|█▎        | 64/500 [1:21:10<9:31:40, 78.67s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 9.34E+05, Train scatter: [0.9383 0.1127 0.5431 0.723 ]
L1 regularization loss: 2.64E+00, L2 regularization loss: 1.16E+00
Test scatter: [0.9226 0.1116 0.5346 0.7188], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.924  0.1328 0.5352 0.7452], Epochs since improvement 18
 13%|█▎        | 65/500 [1:22:11<8:52:18, 73.42s/it] 13%|█▎        | 66/500 [1:23:40<9:25:38, 78.20s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 8.82E+05, Train scatter: [0.938  0.111  0.5419 0.7399]
L1 regularization loss: 2.64E+00, L2 regularization loss: 1.17E+00
Test scatter: [0.9223 0.1099 0.5334 0.7322], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.9233 0.1126 0.535  0.7426], Epochs since improvement 20
 13%|█▎        | 67/500 [1:24:41<8:47:10, 73.05s/it] 13%|█▎        | 67/500 [1:26:11<9:17:02, 77.19s/it]
Epoch: 68 done with learning rate 9.80E-03, Train loss: 8.53E+05, Train scatter: [0.9377 0.1109 0.5378 0.7228]
L1 regularization loss: 2.64E+00, L2 regularization loss: 1.17E+00
Test scatter: [0.922  0.1099 0.5295 0.7168], Lowest was [0.3528 0.0577 0.2776 0.4508]
Median for last 10 epochs: [0.9226 0.1116 0.5346 0.7322], Epochs since improvement 22
Exited after 68 epochs due to early stopping
5171.64 seconds spent training, 10.343 seconds per epoch. Processed 6732 trees per second
[0.92196417 0.10986236 0.5294637  0.71682143]
{'epoch_exit': 67, 'scatter_m_star': 0.92196417, 'lowest_m_star': 0.3528473, 'last20_m_star': 0.9229395, 'last10_m_star': 0.9225896, 'scatter_v_disk': 0.109862365, 'lowest_v_disk': 0.057704356, 'last20_v_disk': 0.14659487, 'last10_v_disk': 0.11160773, 'scatter_m_cold': 0.5294637, 'lowest_m_cold': 0.27763128, 'last20_m_cold': 0.5352423, 'last10_m_cold': 0.5345843, 'scatter_sfr_100': 0.71682143, 'lowest_sfr_100': 0.45077488, 'last20_sfr_100': 0.7532824, 'last10_sfr_100': 0.7321634}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 3e-05, 'l2_lambda': 3e-05, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_bffirl
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:27:37, 53.82s/it]  0%|          | 2/500 [02:14<9:39:02, 69.76s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.1733 0.5441 0.9953]
L1 regularization loss: 7.33E-01, L2 regularization loss: 1.27E-01
Test scatter: [0.9196 0.1685 0.5355 0.985 ], Lowest was [0.9196 0.1685 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1685 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:08<8:35:57, 62.29s/it]  1%|          | 4/500 [04:29<9:36:55, 69.79s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.99E+07, Train scatter: [0.9352 0.1321 0.5441 0.9954]
L1 regularization loss: 7.37E-01, L2 regularization loss: 1.28E-01
Test scatter: [0.9196 0.1283 0.5355 0.9851], Lowest was [0.9196 0.1283 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1283 0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:22<8:46:43, 63.85s/it]  1%|          | 6/500 [06:43<9:34:23, 69.77s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.56E+07, Train scatter: [0.9348 0.112  0.5441 0.9954]
L1 regularization loss: 7.39E-01, L2 regularization loss: 1.28E-01
Test scatter: [0.9192 0.1104 0.5356 0.9851], Lowest was [0.9192 0.1104 0.5355 0.985 ]
Median for last 10 epochs: [0.9192 0.1104 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:37<8:49:28, 64.44s/it]  2%|▏         | 8/500 [08:58<9:31:22, 69.68s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.41E+07, Train scatter: [0.9334 0.1008 0.5438 0.9954]
L1 regularization loss: 7.42E-01, L2 regularization loss: 1.30E-01
Test scatter: [0.9178 0.1002 0.5352 0.9851], Lowest was [0.9178 0.1002 0.5352 0.985 ]
Median for last 10 epochs: [0.9185 0.1053 0.5354 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [09:51<8:48:17, 64.56s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.28E+07, Train scatter: [0.7886 0.0907 0.5412 0.9954]
L1 regularization loss: 7.48E-01, L2 regularization loss: 1.32E-01
Test scatter: [0.7805 0.0914 0.5328 0.9851], Lowest was [0.7805 0.0914 0.5328 0.985 ]
Median for last 10 epochs: [0.9178 0.1002 0.5352 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:18<9:44:04, 71.52s/it]  2%|▏         | 11/500 [12:12<8:58:14, 66.04s/it]  2%|▏         | 12/500 [13:33<9:33:59, 70.57s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.16E+07, Train scatter: [0.6158 0.0875 0.5325 0.9954]
L1 regularization loss: 7.53E-01, L2 regularization loss: 1.36E-01
Test scatter: [0.6162 0.089  0.5248 0.9851], Lowest was [0.6162 0.089  0.5248 0.985 ]
Median for last 10 epochs: [0.9178 0.1002 0.5352 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:26<8:51:16, 65.45s/it]  3%|▎         | 14/500 [15:46<9:25:45, 69.85s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 8.06E+07, Train scatter: [0.5329 0.0854 0.5298 0.9954]
L1 regularization loss: 7.57E-01, L2 regularization loss: 1.40E-01
Test scatter: [0.5295 0.0858 0.5222 0.9851], Lowest was [0.5295 0.0858 0.5222 0.985 ]
Median for last 10 epochs: [0.7805 0.0914 0.5328 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [16:40<8:44:42, 64.91s/it]  3%|▎         | 16/500 [18:00<9:21:09, 69.57s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.85E+07, Train scatter: [0.7574 0.1194 0.5429 0.9953]
L1 regularization loss: 7.61E-01, L2 regularization loss: 1.42E-01
Test scatter: [0.7526 0.1182 0.5344 0.985 ], Lowest was [0.5295 0.0858 0.5222 0.985 ]
Median for last 10 epochs: [0.7526 0.0914 0.5328 0.9851], Epochs since improvement 0
  3%|▎         | 17/500 [18:54<8:41:27, 64.78s/it]  4%|▎         | 18/500 [20:15<9:19:24, 69.64s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.54E+07, Train scatter: [0.4988 0.0815 0.5258 0.9952]
L1 regularization loss: 7.64E-01, L2 regularization loss: 1.44E-01
Test scatter: [0.4877 0.0817 0.5187 0.9848], Lowest was [0.4877 0.0817 0.5187 0.9848]
Median for last 10 epochs: [0.6162 0.089  0.5248 0.9851], Epochs since improvement 0
  4%|▍         | 19/500 [21:08<8:39:17, 64.78s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.41E+07, Train scatter: [0.6083 0.0906 0.4553 0.9952]
L1 regularization loss: 7.69E-01, L2 regularization loss: 1.46E-01
Test scatter: [0.6026 0.0895 0.4481 0.9849], Lowest was [0.4877 0.0817 0.4481 0.9848]
Median for last 10 epochs: [0.6026 0.089  0.5222 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:36<9:32:50, 71.60s/it]  4%|▍         | 21/500 [23:30<8:48:33, 66.21s/it]  4%|▍         | 22/500 [24:50<9:21:42, 70.51s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.27E+07, Train scatter: [0.5397 0.088  0.3917 0.9952]
L1 regularization loss: 7.73E-01, L2 regularization loss: 1.48E-01
Test scatter: [0.5384 0.0905 0.3972 0.9849], Lowest was [0.4877 0.0817 0.3972 0.9848]
Median for last 10 epochs: [0.5384 0.0895 0.5187 0.9849], Epochs since improvement 0
  5%|▍         | 23/500 [25:44<8:39:49, 65.39s/it]  5%|▍         | 24/500 [27:04<9:14:18, 69.87s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.20E+07, Train scatter: [0.534  0.0846 0.3398 0.9952]
L1 regularization loss: 7.80E-01, L2 regularization loss: 1.51E-01
Test scatter: [0.5421 0.0846 0.3424 0.9849], Lowest was [0.4877 0.0817 0.3424 0.9848]
Median for last 10 epochs: [0.5421 0.0895 0.4481 0.9849], Epochs since improvement 0
  5%|▌         | 25/500 [27:57<8:34:16, 64.96s/it]  5%|▌         | 26/500 [29:19<9:11:46, 69.85s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.15E+07, Train scatter: [0.5224 0.0807 0.3672 0.9953]
L1 regularization loss: 7.88E-01, L2 regularization loss: 1.53E-01
Test scatter: [0.5224 0.0815 0.3745 0.985 ], Lowest was [0.4877 0.0815 0.3424 0.9848]
Median for last 10 epochs: [0.5384 0.0846 0.3972 0.9849], Epochs since improvement 0
  5%|▌         | 27/500 [30:12<8:32:00, 64.95s/it]  6%|▌         | 28/500 [31:33<9:07:26, 69.59s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.10E+07, Train scatter: [0.4995 0.0775 0.3353 0.9952]
L1 regularization loss: 7.93E-01, L2 regularization loss: 1.55E-01
Test scatter: [0.5029 0.0789 0.3421 0.9849], Lowest was [0.4877 0.0789 0.3421 0.9848]
Median for last 10 epochs: [0.5384 0.0846 0.3745 0.9849], Epochs since improvement 0
  6%|▌         | 29/500 [32:26<8:28:31, 64.78s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.04E+07, Train scatter: [0.5528 0.076  0.3361 0.9953]
L1 regularization loss: 7.97E-01, L2 regularization loss: 1.57E-01
Test scatter: [0.5645 0.0769 0.3405 0.985 ], Lowest was [0.4877 0.0769 0.3405 0.9848]
Median for last 10 epochs: [0.5384 0.0815 0.3424 0.9849], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [33:53<9:20:17, 71.53s/it]  6%|▌         | 31/500 [34:47<8:36:39, 66.10s/it]  6%|▋         | 32/500 [36:09<9:12:07, 70.78s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.05E+07, Train scatter: [0.5188 0.0814 0.3285 0.9952]
L1 regularization loss: 8.02E-01, L2 regularization loss: 1.59E-01
Test scatter: [0.5142 0.0812 0.3302 0.9849], Lowest was [0.4877 0.0769 0.3302 0.9848]
Median for last 10 epochs: [0.5224 0.0812 0.3421 0.9849], Epochs since improvement 0
  7%|▋         | 33/500 [37:02<8:30:30, 65.59s/it]  7%|▋         | 34/500 [38:23<9:04:51, 70.15s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 6.97E+07, Train scatter: [0.472  0.0771 0.3067 0.9953]
L1 regularization loss: 8.11E-01, L2 regularization loss: 1.63E-01
Test scatter: [0.4741 0.0776 0.3075 0.985 ], Lowest was [0.4741 0.0769 0.3075 0.9848]
Median for last 10 epochs: [0.5142 0.0789 0.3405 0.985 ], Epochs since improvement 0
  7%|▋         | 35/500 [39:16<8:24:43, 65.12s/it]  7%|▋         | 36/500 [40:37<8:59:06, 69.71s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 6.92E+07, Train scatter: [0.4168 0.0724 0.2871 0.9953]
L1 regularization loss: 8.17E-01, L2 regularization loss: 1.66E-01
Test scatter: [0.4248 0.074  0.294  0.985 ], Lowest was [0.4248 0.074  0.294  0.9848]
Median for last 10 epochs: [0.5029 0.0776 0.3302 0.985 ], Epochs since improvement 0
  7%|▋         | 37/500 [41:30<8:20:03, 64.80s/it]  8%|▊         | 38/500 [42:52<8:57:44, 69.84s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.83E+07, Train scatter: [0.4454 0.0745 0.3055 0.9953]
L1 regularization loss: 8.25E-01, L2 regularization loss: 1.71E-01
Test scatter: [0.4464 0.0749 0.3111 0.985 ], Lowest was [0.4248 0.074  0.294  0.9848]
Median for last 10 epochs: [0.4741 0.0769 0.3111 0.985 ], Epochs since improvement 2
  8%|▊         | 39/500 [43:45<8:19:19, 64.99s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 5.46E+07, Train scatter: [0.485  0.0714 0.2974 0.9952]
L1 regularization loss: 8.31E-01, L2 regularization loss: 1.76E-01
Test scatter: [0.4744 0.0713 0.302  0.9849], Lowest was [0.4248 0.0713 0.294  0.9848]
Median for last 10 epochs: [0.4741 0.0749 0.3075 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:14<9:12:28, 72.06s/it]  8%|▊         | 41/500 [46:07<8:28:34, 66.48s/it]  8%|▊         | 42/500 [47:29<9:02:15, 71.04s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.29E+07, Train scatter: [0.389  0.0756 0.3081 0.9389]
L1 regularization loss: 8.41E-01, L2 regularization loss: 1.82E-01
Test scatter: [0.399  0.0755 0.3116 0.9317], Lowest was [0.399  0.0713 0.294  0.9317]
Median for last 10 epochs: [0.4464 0.0749 0.3075 0.985 ], Epochs since improvement 0
  9%|▊         | 43/500 [48:22<8:21:10, 65.80s/it]  9%|▉         | 44/500 [49:44<8:55:34, 70.47s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.46E+06, Train scatter: [0.4238 0.0747 0.3142 0.5864]
L1 regularization loss: 8.52E-01, L2 regularization loss: 1.92E-01
Test scatter: [0.419  0.0744 0.3164 0.5847], Lowest was [0.399  0.0713 0.294  0.5847]
Median for last 10 epochs: [0.4248 0.0744 0.3111 0.9849], Epochs since improvement 0
  9%|▉         | 45/500 [50:37<8:15:34, 65.35s/it]  9%|▉         | 46/500 [51:59<8:51:24, 70.23s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.71E+06, Train scatter: [0.428  0.0688 0.3155 0.6187]
L1 regularization loss: 8.62E-01, L2 regularization loss: 1.99E-01
Test scatter: [0.4227 0.0679 0.318  0.6247], Lowest was [0.399  0.0679 0.294  0.5847]
Median for last 10 epochs: [0.4227 0.0744 0.3116 0.9317], Epochs since improvement 0
  9%|▉         | 47/500 [52:52<8:12:32, 65.24s/it] 10%|▉         | 48/500 [54:13<8:47:02, 69.96s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.35E+06, Train scatter: [0.3736 0.0669 0.2885 0.5052]
L1 regularization loss: 8.69E-01, L2 regularization loss: 2.04E-01
Test scatter: [0.3662 0.066  0.293  0.5031], Lowest was [0.3662 0.066  0.293  0.5031]
Median for last 10 epochs: [0.419  0.0713 0.3116 0.6247], Epochs since improvement 0
 10%|▉         | 49/500 [55:07<8:08:53, 65.04s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.34E+06, Train scatter: [0.3906 0.0743 0.3351 0.5429]
L1 regularization loss: 8.79E-01, L2 regularization loss: 2.11E-01
Test scatter: [0.3849 0.0741 0.3405 0.5442], Lowest was [0.3662 0.066  0.293  0.5031]
Median for last 10 epochs: [0.399  0.0741 0.3164 0.5847], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [56:35<8:59:58, 72.00s/it] 10%|█         | 51/500 [57:29<8:17:33, 66.49s/it] 10%|█         | 52/500 [58:50<8:48:46, 70.82s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.10E+06, Train scatter: [0.3499 0.0657 0.2955 0.4918]
L1 regularization loss: 8.88E-01, L2 regularization loss: 2.15E-01
Test scatter: [0.3477 0.0654 0.2988 0.4903], Lowest was [0.3477 0.0654 0.293  0.4903]
Median for last 10 epochs: [0.3849 0.0679 0.3164 0.5442], Epochs since improvement 0
 11%|█         | 53/500 [59:43<8:08:43, 65.60s/it] 11%|█         | 54/500 [1:01:03<8:40:20, 70.00s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.95E+06, Train scatter: [0.3109 0.0666 0.3194 0.5168]
L1 regularization loss: 8.94E-01, L2 regularization loss: 2.20E-01
Test scatter: [0.3118 0.0662 0.3231 0.517 ], Lowest was [0.3118 0.0654 0.293  0.4903]
Median for last 10 epochs: [0.3662 0.0662 0.318  0.517 ], Epochs since improvement 0
 11%|█         | 55/500 [1:01:57<8:02:22, 65.04s/it] 11%|█         | 56/500 [1:03:18<8:36:17, 69.77s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.15E+06, Train scatter: [0.2844 0.0677 0.3078 0.5181]
L1 regularization loss: 9.11E-01, L2 regularization loss: 2.29E-01
Test scatter: [0.2934 0.0684 0.3122 0.5265], Lowest was [0.2934 0.0654 0.293  0.4903]
Median for last 10 epochs: [0.3477 0.0662 0.3122 0.517 ], Epochs since improvement 0
 11%|█▏        | 57/500 [1:04:11<7:59:07, 64.89s/it] 12%|█▏        | 58/500 [1:05:32<8:32:38, 69.59s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.73E+06, Train scatter: [0.3421 0.0625 0.3202 0.4741]
L1 regularization loss: 9.18E-01, L2 regularization loss: 2.34E-01
Test scatter: [0.3443 0.0635 0.3245 0.4745], Lowest was [0.2934 0.0635 0.293  0.4745]
Median for last 10 epochs: [0.3443 0.0662 0.3231 0.517 ], Epochs since improvement 0
 12%|█▏        | 59/500 [1:06:25<7:55:38, 64.71s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.29E+06, Train scatter: [0.3609 0.062  0.2842 0.4693]
L1 regularization loss: 9.34E-01, L2 regularization loss: 2.45E-01
Test scatter: [0.3568 0.0623 0.2864 0.4691], Lowest was [0.2934 0.0623 0.2864 0.4691]
Median for last 10 epochs: [0.3443 0.0654 0.3122 0.4903], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:07:53<8:46:07, 71.74s/it] 12%|█▏        | 61/500 [1:08:47<8:04:53, 66.27s/it] 12%|█▏        | 62/500 [1:10:08<8:35:31, 70.62s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.76E+06, Train scatter: [0.4394 0.0624 0.2908 0.4713]
L1 regularization loss: 9.49E-01, L2 regularization loss: 2.56E-01
Test scatter: [0.4352 0.0635 0.2944 0.4719], Lowest was [0.2934 0.0623 0.2864 0.4691]
Median for last 10 epochs: [0.3443 0.0635 0.3122 0.4745], Epochs since improvement 2
 13%|█▎        | 63/500 [1:11:01<7:57:01, 65.50s/it] 13%|█▎        | 64/500 [1:12:22<8:29:36, 70.13s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.58E+06, Train scatter: [0.5118 0.0635 0.3037 0.4995]
L1 regularization loss: 9.60E-01, L2 regularization loss: 2.65E-01
Test scatter: [0.5041 0.0638 0.3063 0.5057], Lowest was [0.2934 0.0623 0.2864 0.4691]
Median for last 10 epochs: [0.3568 0.0635 0.3063 0.4745], Epochs since improvement 4
 13%|█▎        | 65/500 [1:13:16<7:52:14, 65.14s/it] 13%|█▎        | 66/500 [1:14:37<8:26:18, 70.00s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.64E+06, Train scatter: [0.5316 0.0619 0.2763 0.5014]
L1 regularization loss: 9.82E-01, L2 regularization loss: 2.79E-01
Test scatter: [0.5205 0.0628 0.2804 0.5076], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.4352 0.0635 0.2944 0.4745], Epochs since improvement 0
 13%|█▎        | 67/500 [1:15:30<7:48:58, 64.99s/it] 14%|█▎        | 68/500 [1:16:51<8:22:00, 69.72s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 6.37E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 3.46E+00, L2 regularization loss: 1.20E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.5041 0.0635 0.2944 0.5057], Epochs since improvement 2
 14%|█▍        | 69/500 [1:17:44<7:45:35, 64.82s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 5.67E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 3.46E+00, L2 regularization loss: 1.21E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.5205 0.0638 0.3063 0.5076], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:19:12<8:34:28, 71.79s/it] 14%|█▍        | 71/500 [1:20:06<7:53:42, 66.25s/it] 14%|█▍        | 72/500 [1:21:26<8:22:56, 70.51s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 5.21E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 3.47E+00, L2 regularization loss: 1.24E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 6
 15%|█▍        | 73/500 [1:22:20<7:45:18, 65.38s/it] 15%|█▍        | 74/500 [1:23:40<8:17:16, 70.04s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 4.85E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 3.47E+00, L2 regularization loss: 1.27E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 8
 15%|█▌        | 75/500 [1:24:34<7:40:36, 65.03s/it] 15%|█▌        | 76/500 [1:25:55<8:13:20, 69.81s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 4.54E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 3.48E+00, L2 regularization loss: 1.32E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 10
 15%|█▌        | 77/500 [1:26:48<7:37:13, 64.85s/it] 16%|█▌        | 78/500 [1:28:09<8:10:04, 69.68s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 4.27E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 3.48E+00, L2 regularization loss: 1.35E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 12
 16%|█▌        | 79/500 [1:29:03<7:35:21, 64.90s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 4.02E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 3.48E+00, L2 regularization loss: 1.39E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 14
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:30:31<8:22:34, 71.80s/it] 16%|█▌        | 81/500 [1:31:24<7:42:53, 66.29s/it] 16%|█▋        | 82/500 [1:32:44<8:11:05, 70.49s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 3.80E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 3.48E+00, L2 regularization loss: 1.40E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 16
 17%|█▋        | 83/500 [1:33:38<7:34:21, 65.37s/it] 17%|█▋        | 84/500 [1:34:58<8:04:54, 69.94s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 3.56E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 3.48E+00, L2 regularization loss: 1.41E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 18
 17%|█▋        | 85/500 [1:35:52<7:29:47, 65.03s/it] 17%|█▋        | 86/500 [1:37:12<8:00:50, 69.69s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 3.33E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 3.49E+00, L2 regularization loss: 1.42E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 20
 17%|█▋        | 87/500 [1:38:06<7:25:59, 64.79s/it] 17%|█▋        | 87/500 [1:39:26<7:52:05, 68.58s/it]
Epoch: 88 done with learning rate 9.98E-03, Train loss: 3.12E+07, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 3.49E+00, L2 regularization loss: 1.42E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2934 0.0623 0.2804 0.4691]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 22
Exited after 88 epochs due to early stopping
5966.90 seconds spent training, 11.934 seconds per epoch. Processed 5835 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.9195844  0.16897835 0.53547174 0.9850121 ]
{'epoch_exit': 87, 'scatter_m_star': 0.9195844, 'lowest_m_star': 0.29343432, 'last20_m_star': 0.9195847, 'last10_m_star': 0.9196094, 'scatter_v_disk': 0.16897835, 'lowest_v_disk': 0.062257923, 'last20_v_disk': 0.16898665, 'last10_v_disk': 0.16898336, 'scatter_m_cold': 0.53547174, 'lowest_m_cold': 0.28035226, 'last20_m_cold': 0.5354903, 'last10_m_cold': 0.5354868, 'scatter_sfr_100': 0.9850121, 'lowest_sfr_100': 0.4691266, 'last20_sfr_100': 0.98504055, 'last10_sfr_100': 0.9850406}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
