Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_xgdosi
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:32<4:33:56, 32.94s/it]  0%|          | 2/500 [01:21<5:50:12, 42.19s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.27E+07, Train scatter: [0.9352 0.1636 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.31E-01
Test scatter: [0.9196 0.162  0.5355 0.9851], Lowest was [0.9196 0.162  0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.162  0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:52<5:07:24, 37.11s/it]  1%|          | 4/500 [02:41<5:45:40, 41.82s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 6.37E+06, Train scatter: [0.9352 0.1418 0.5439 0.9953]
L1 regularization loss: 1.53E+00, L2 regularization loss: 3.54E-01
Test scatter: [0.9196 0.141  0.5353 0.9849], Lowest was [0.9196 0.141  0.5353 0.9849]
Median for last 10 epochs: [0.9196 0.141  0.5353 0.9849], Epochs since improvement 0
  1%|          | 5/500 [03:12<5:12:58, 37.94s/it]  1%|          | 6/500 [04:01<5:43:52, 41.77s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 4.87E+06, Train scatter: [0.9327 0.1137 0.5407 0.6601]
L1 regularization loss: 1.57E+00, L2 regularization loss: 3.90E-01
Test scatter: [0.9171 0.1125 0.5321 0.6506], Lowest was [0.9171 0.1125 0.5321 0.6506]
Median for last 10 epochs: [0.9171 0.1125 0.5321 0.6506], Epochs since improvement 0
  1%|▏         | 7/500 [04:33<5:14:56, 38.33s/it]  2%|▏         | 8/500 [05:21<5:41:20, 41.63s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 3.96E+06, Train scatter: [0.9128 0.0997 0.5327 0.5997]
L1 regularization loss: 1.59E+00, L2 regularization loss: 4.02E-01
Test scatter: [0.8997 0.0983 0.5246 0.5984], Lowest was [0.8997 0.0983 0.5246 0.5984]
Median for last 10 epochs: [0.9084 0.1054 0.5283 0.6245], Epochs since improvement 0
  2%|▏         | 9/500 [05:53<5:13:59, 38.37s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 3.39E+06, Train scatter: [0.7575 0.0931 0.5207 0.5683]
L1 regularization loss: 1.60E+00, L2 regularization loss: 4.11E-01
Test scatter: [0.7508 0.0924 0.5127 0.5682], Lowest was [0.7508 0.0924 0.5127 0.5682]
Median for last 10 epochs: [0.8997 0.0983 0.5246 0.5984], Epochs since improvement 0
  2%|▏         | 10/500 [06:47<5:54:40, 43.43s/it]  2%|▏         | 11/500 [07:19<5:23:33, 39.70s/it]  2%|▏         | 12/500 [08:07<5:44:49, 42.40s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.03E+06, Train scatter: [0.6019 0.0921 0.3837 0.5824]
L1 regularization loss: 1.62E+00, L2 regularization loss: 4.20E-01
Test scatter: [0.598  0.0929 0.3851 0.5881], Lowest was [0.598  0.0924 0.3851 0.5682]
Median for last 10 epochs: [0.8997 0.0983 0.5246 0.5984], Epochs since improvement 0
  3%|▎         | 13/500 [08:38<5:16:37, 39.01s/it]  3%|▎         | 14/500 [09:27<5:40:00, 41.98s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.45E+06, Train scatter: [0.5438 0.0887 0.3633 0.587 ]
L1 regularization loss: 1.63E+00, L2 regularization loss: 4.28E-01
Test scatter: [0.5337 0.0895 0.3634 0.5962], Lowest was [0.5337 0.0895 0.3634 0.5682]
Median for last 10 epochs: [0.7508 0.0929 0.5127 0.5962], Epochs since improvement 0
  3%|▎         | 15/500 [09:59<5:14:03, 38.85s/it]  3%|▎         | 16/500 [10:48<5:38:01, 41.90s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.05E+06, Train scatter: [0.5352 0.0886 0.3316 0.5773]
L1 regularization loss: 1.65E+00, L2 regularization loss: 4.37E-01
Test scatter: [0.5246 0.0908 0.337  0.5873], Lowest was [0.5246 0.0895 0.337  0.5682]
Median for last 10 epochs: [0.598  0.0924 0.3851 0.5881], Epochs since improvement 0
  3%|▎         | 17/500 [11:19<5:11:38, 38.71s/it]  4%|▎         | 18/500 [12:08<5:36:38, 41.91s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 8.99E+05, Train scatter: [0.5159 0.0852 0.3353 0.5399]
L1 regularization loss: 1.67E+00, L2 regularization loss: 4.48E-01
Test scatter: [0.4929 0.0861 0.3374 0.5439], Lowest was [0.4929 0.0861 0.337  0.5439]
Median for last 10 epochs: [0.5337 0.0908 0.3634 0.5873], Epochs since improvement 0
  4%|▍         | 19/500 [12:40<5:10:34, 38.74s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.22E+05, Train scatter: [0.5131 0.0834 0.3186 0.5472]
L1 regularization loss: 1.70E+00, L2 regularization loss: 4.58E-01
Test scatter: [0.495  0.0837 0.3239 0.5496], Lowest was [0.4929 0.0837 0.3239 0.5439]
Median for last 10 epochs: [0.5246 0.0895 0.3374 0.5873], Epochs since improvement 0
  4%|▍         | 20/500 [13:34<5:46:19, 43.29s/it]  4%|▍         | 21/500 [14:05<5:17:03, 39.72s/it]  4%|▍         | 22/500 [14:53<5:36:52, 42.29s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.19E+05, Train scatter: [0.4574 0.0803 0.3001 0.5291]
L1 regularization loss: 1.73E+00, L2 regularization loss: 4.71E-01
Test scatter: [0.4423 0.0813 0.3085 0.5337], Lowest was [0.4423 0.0813 0.3085 0.5337]
Median for last 10 epochs: [0.495  0.0861 0.337  0.5496], Epochs since improvement 0
  5%|▍         | 23/500 [15:25<5:10:03, 39.00s/it]  5%|▍         | 24/500 [16:13<5:32:38, 41.93s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 6.89E+05, Train scatter: [0.5238 0.0813 0.317  0.5393]
L1 regularization loss: 1.77E+00, L2 regularization loss: 4.85E-01
Test scatter: [0.5001 0.0821 0.3214 0.5404], Lowest was [0.4423 0.0813 0.3085 0.5337]
Median for last 10 epochs: [0.495  0.0837 0.3239 0.5439], Epochs since improvement 2
  5%|▌         | 25/500 [16:45<5:07:15, 38.81s/it]  5%|▌         | 26/500 [17:34<5:29:37, 41.72s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 6.24E+05, Train scatter: [0.4562 0.0775 0.3293 0.5309]
L1 regularization loss: 1.80E+00, L2 regularization loss: 5.03E-01
Test scatter: [0.4476 0.0781 0.3319 0.5299], Lowest was [0.4423 0.0781 0.3085 0.5299]
Median for last 10 epochs: [0.4929 0.0821 0.3239 0.5404], Epochs since improvement 0
  5%|▌         | 27/500 [18:05<5:04:21, 38.61s/it]  6%|▌         | 28/500 [18:53<5:27:15, 41.60s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 5.56E+05, Train scatter: [0.4276 0.0776 0.3322 0.5269]
L1 regularization loss: 1.84E+00, L2 regularization loss: 5.24E-01
Test scatter: [0.4165 0.0778 0.3378 0.527 ], Lowest was [0.4165 0.0778 0.3085 0.527 ]
Median for last 10 epochs: [0.4476 0.0813 0.3239 0.5337], Epochs since improvement 0
  6%|▌         | 29/500 [19:25<5:02:33, 38.54s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 5.07E+05, Train scatter: [0.5429 0.0855 0.3043 0.5139]
L1 regularization loss: 1.88E+00, L2 regularization loss: 5.47E-01
Test scatter: [0.5622 0.0899 0.3149 0.5159], Lowest was [0.4165 0.0778 0.3085 0.5159]
Median for last 10 epochs: [0.4476 0.0813 0.3214 0.5299], Epochs since improvement 0
  6%|▌         | 30/500 [20:19<5:38:16, 43.18s/it]  6%|▌         | 31/500 [20:50<5:09:51, 39.64s/it]  6%|▋         | 32/500 [21:40<5:31:44, 42.53s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.32E+05, Train scatter: [0.486  0.0776 0.3146 0.5532]
L1 regularization loss: 1.92E+00, L2 regularization loss: 5.73E-01
Test scatter: [0.4673 0.0778 0.3237 0.5534], Lowest was [0.4165 0.0778 0.3085 0.5159]
Median for last 10 epochs: [0.4673 0.0781 0.3237 0.5299], Epochs since improvement 2
  7%|▋         | 33/500 [22:11<5:04:42, 39.15s/it]  7%|▋         | 34/500 [23:00<5:27:25, 42.16s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.79E+05, Train scatter: [0.4739 0.0744 0.3387 0.5055]
L1 regularization loss: 1.96E+00, L2 regularization loss: 6.00E-01
Test scatter: [0.4658 0.0745 0.3612 0.5033], Lowest was [0.4165 0.0745 0.3085 0.5033]
Median for last 10 epochs: [0.4658 0.0778 0.3319 0.527 ], Epochs since improvement 0
  7%|▋         | 35/500 [23:31<5:01:25, 38.89s/it]  7%|▋         | 36/500 [24:20<5:24:41, 41.99s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.78E+05, Train scatter: [0.4336 0.0719 0.2934 0.4989]
L1 regularization loss: 1.99E+00, L2 regularization loss: 6.31E-01
Test scatter: [0.424  0.0726 0.3024 0.4974], Lowest was [0.4165 0.0726 0.3024 0.4974]
Median for last 10 epochs: [0.4658 0.0778 0.3237 0.5159], Epochs since improvement 0
  7%|▋         | 37/500 [24:52<4:58:53, 38.73s/it]  8%|▊         | 38/500 [25:41<5:22:23, 41.87s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.36E+05, Train scatter: [0.3843 0.0704 0.2869 0.5079]
L1 regularization loss: 2.03E+00, L2 regularization loss: 6.58E-01
Test scatter: [0.3853 0.0708 0.2954 0.5093], Lowest was [0.3853 0.0708 0.2954 0.4974]
Median for last 10 epochs: [0.4658 0.0745 0.3149 0.5093], Epochs since improvement 0
  8%|▊         | 39/500 [26:12<4:57:24, 38.71s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 6.92E+04, Train scatter: [0.2934 0.0665 0.2645 0.4762]
L1 regularization loss: 2.06E+00, L2 regularization loss: 6.86E-01
Test scatter: [0.3496 0.0678 0.2752 0.4769], Lowest was [0.3496 0.0678 0.2752 0.4769]
Median for last 10 epochs: [0.424  0.0726 0.3024 0.5033], Epochs since improvement 0
  8%|▊         | 40/500 [27:06<5:32:40, 43.39s/it]  8%|▊         | 41/500 [27:38<5:04:18, 39.78s/it]  8%|▊         | 42/500 [28:27<5:24:43, 42.54s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.72E+05, Train scatter: [0.4423 0.0623 0.2667 0.4694]
L1 regularization loss: 2.09E+00, L2 regularization loss: 7.07E-01
Test scatter: [0.4304 0.0633 0.2739 0.4719], Lowest was [0.3496 0.0633 0.2739 0.4719]
Median for last 10 epochs: [0.424  0.0708 0.2954 0.4974], Epochs since improvement 0
  9%|▊         | 43/500 [28:58<4:57:56, 39.12s/it]  9%|▉         | 44/500 [29:47<5:19:00, 41.97s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.48E+05, Train scatter: [0.6366 0.0609 0.2813 0.489 ]
L1 regularization loss: 2.20E+00, L2 regularization loss: 7.64E-01
Test scatter: [0.6249 0.0625 0.2917 0.4899], Lowest was [0.3496 0.0625 0.2739 0.4719]
Median for last 10 epochs: [0.424  0.0678 0.2917 0.4899], Epochs since improvement 0
  9%|▉         | 45/500 [30:18<4:53:38, 38.72s/it]  9%|▉         | 46/500 [31:07<5:16:19, 41.81s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: -2.79E+05, Train scatter: [0.4489 0.0628 0.2833 0.5022]
L1 regularization loss: 2.25E+00, L2 regularization loss: 8.11E-01
Test scatter: [0.4449 0.0648 0.295  0.5051], Lowest was [0.3496 0.0625 0.2739 0.4719]
Median for last 10 epochs: [0.4304 0.0648 0.2917 0.4899], Epochs since improvement 2
  9%|▉         | 47/500 [31:38<4:51:16, 38.58s/it] 10%|▉         | 48/500 [32:26<5:13:13, 41.58s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: -2.84E+05, Train scatter: [0.3803 0.0584 0.2683 0.4612]
L1 regularization loss: 2.27E+00, L2 regularization loss: 8.38E-01
Test scatter: [0.3722 0.06   0.2773 0.4644], Lowest was [0.3496 0.06   0.2739 0.4644]
Median for last 10 epochs: [0.4304 0.0633 0.2773 0.4769], Epochs since improvement 0
 10%|▉         | 49/500 [32:58<4:49:12, 38.48s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: -2.91E+05, Train scatter: [0.379  0.061  0.2798 0.4786]
L1 regularization loss: 2.28E+00, L2 regularization loss: 8.64E-01
Test scatter: [0.3745 0.0616 0.2863 0.4756], Lowest was [0.3496 0.06   0.2739 0.4644]
Median for last 10 epochs: [0.4304 0.0625 0.2863 0.4756], Epochs since improvement 2
 10%|█         | 50/500 [33:52<5:24:34, 43.28s/it] 10%|█         | 51/500 [34:23<4:56:41, 39.65s/it] 10%|█         | 52/500 [35:13<5:17:49, 42.57s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: -2.95E+05, Train scatter: [0.2885 0.058  0.2736 0.4558]
L1 regularization loss: 2.30E+00, L2 regularization loss: 8.93E-01
Test scatter: [0.2762 0.0593 0.2799 0.4588], Lowest was [0.2762 0.0593 0.2739 0.4588]
Median for last 10 epochs: [0.3745 0.0616 0.2863 0.4756], Epochs since improvement 0
 11%|█         | 53/500 [35:44<4:51:35, 39.14s/it] 11%|█         | 54/500 [36:33<5:13:10, 42.13s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: -2.97E+05, Train scatter: [0.4141 0.0587 0.2741 0.461 ]
L1 regularization loss: 2.34E+00, L2 regularization loss: 9.38E-01
Test scatter: [0.4111 0.0603 0.2834 0.4684], Lowest was [0.2762 0.0593 0.2739 0.4588]
Median for last 10 epochs: [0.3745 0.0603 0.2834 0.4684], Epochs since improvement 2
 11%|█         | 55/500 [37:04<4:48:08, 38.85s/it] 11%|█         | 56/500 [37:53<5:10:35, 41.97s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: -2.95E+05, Train scatter: [0.2455 0.0567 0.2989 0.4737]
L1 regularization loss: 2.39E+00, L2 regularization loss: 9.87E-01
Test scatter: [0.3323 0.0584 0.3054 0.4798], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.3722 0.06   0.2834 0.4684], Epochs since improvement 0
 11%|█▏        | 57/500 [38:24<4:45:48, 38.71s/it] 12%|█▏        | 58/500 [39:14<5:08:41, 41.90s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: -3.00E+05, Train scatter: [0.2077 0.0583 0.2811 0.4627]
L1 regularization loss: 2.43E+00, L2 regularization loss: 1.04E+00
Test scatter: [0.4712 0.061  0.2929 0.4755], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.3745 0.0603 0.2863 0.4755], Epochs since improvement 2
 12%|█▏        | 59/500 [39:45<4:44:15, 38.67s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.66E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.60E+00, L2 regularization loss: 2.49E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.4111 0.0603 0.2929 0.4755], Epochs since improvement 4
 12%|█▏        | 60/500 [40:39<5:17:33, 43.30s/it] 12%|█▏        | 61/500 [41:10<4:50:10, 39.66s/it] 12%|█▏        | 62/500 [41:59<5:10:30, 42.54s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.57E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.54E+00, L2 regularization loss: 2.52E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.4712 0.061  0.3054 0.4798], Epochs since improvement 6
 13%|█▎        | 63/500 [42:30<4:44:44, 39.10s/it] 13%|█▎        | 64/500 [43:19<5:05:24, 42.03s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.49E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.48E+00, L2 regularization loss: 2.53E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 8
 13%|█▎        | 65/500 [43:51<4:41:28, 38.82s/it] 13%|█▎        | 66/500 [44:40<5:03:33, 41.97s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.42E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.42E+00, L2 regularization loss: 2.53E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 10
 13%|█▎        | 67/500 [45:11<4:39:25, 38.72s/it] 14%|█▎        | 68/500 [46:00<5:01:46, 41.91s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.37E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.36E+00, L2 regularization loss: 2.51E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 12
 14%|█▍        | 69/500 [46:32<4:38:15, 38.74s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.33E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.31E+00, L2 regularization loss: 2.50E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 14
 14%|█▍        | 70/500 [47:27<5:12:30, 43.61s/it] 14%|█▍        | 71/500 [47:58<4:45:16, 39.90s/it] 14%|█▍        | 72/500 [48:47<5:03:58, 42.61s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.30E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.27E+00, L2 regularization loss: 2.48E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 16
 15%|█▍        | 73/500 [49:18<4:38:53, 39.19s/it] 15%|█▍        | 74/500 [50:07<4:59:30, 42.18s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 1.23E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.23E+00, L2 regularization loss: 2.47E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 18
 15%|█▌        | 75/500 [50:39<4:35:43, 38.93s/it] 15%|█▌        | 76/500 [51:28<4:56:41, 41.98s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 1.19E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.18E+00, L2 regularization loss: 2.45E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 20
 15%|█▌        | 77/500 [51:59<4:33:41, 38.82s/it] 15%|█▌        | 77/500 [52:48<4:50:07, 41.15s/it]
Epoch: 78 done with learning rate 1.00E-02, Train loss: 1.15E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.17E+00, L2 regularization loss: 2.44E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2762 0.0584 0.2739 0.4588]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 22
Exited after 78 epochs due to early stopping
3169.62 seconds spent training, 6.339 seconds per epoch. Processed 10985 trees per second
[0.9195534  0.16899113 0.5354733  0.9850203 ]
{'epoch_exit': 77, 'scatter_m_star': 0.9195534, 'lowest_m_star': 0.27620804, 'last20_m_star': 0.91957986, 'last10_m_star': 0.91957974, 'scatter_v_disk': 0.16899113, 'lowest_v_disk': 0.05844235, 'last20_v_disk': 0.1689961, 'last10_v_disk': 0.16899571, 'scatter_m_cold': 0.5354733, 'lowest_m_cold': 0.2739119, 'last20_m_cold': 0.5354882, 'last10_m_cold': 0.5354882, 'scatter_sfr_100': 0.9850203, 'lowest_sfr_100': 0.458815, 'last20_sfr_100': 0.98504996, 'last10_sfr_100': 0.9850497}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_eeacqn
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:59:06, 28.75s/it]  0%|          | 2/500 [01:12<5:12:30, 37.65s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.37E+07, Train scatter: [0.9353 0.1632 0.5442 0.9954]
L1 regularization loss: 1.51E+00, L2 regularization loss: 3.26E-01
Test scatter: [0.9197 0.1656 0.5356 0.9851], Lowest was [0.9197 0.1656 0.5356 0.9851]
Median for last 10 epochs: [0.9197 0.1656 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:39<4:32:17, 32.87s/it]  1%|          | 4/500 [02:25<5:14:19, 38.02s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.23E+07, Train scatter: [0.9352 0.1748 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.32E-01
Test scatter: [0.9197 0.1733 0.5355 0.9851], Lowest was [0.9197 0.1656 0.5355 0.9851]
Median for last 10 epochs: [0.9197 0.1694 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:52<4:40:49, 34.04s/it]  1%|          | 6/500 [03:37<5:11:27, 37.83s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.94E+06, Train scatter: [0.9353 0.1636 0.5441 0.9954]
L1 regularization loss: 1.53E+00, L2 regularization loss: 3.44E-01
Test scatter: [0.9198 0.1623 0.5356 0.9851], Lowest was [0.9197 0.1623 0.5355 0.9851]
Median for last 10 epochs: [0.9197 0.1623 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:05<4:42:07, 34.34s/it]  2%|▏         | 8/500 [04:50<5:10:22, 37.85s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.97E+06, Train scatter: [0.9352 0.1444 0.5441 0.9947]
L1 regularization loss: 1.55E+00, L2 regularization loss: 3.65E-01
Test scatter: [0.9196 0.1403 0.5355 0.9843], Lowest was [0.9196 0.1403 0.5355 0.9843]
Median for last 10 epochs: [0.9196 0.1513 0.5355 0.9847], Epochs since improvement 0
  2%|▏         | 9/500 [05:17<4:42:45, 34.55s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.35E+06, Train scatter: [0.9349 0.1311 0.544  0.6918]
L1 regularization loss: 1.58E+00, L2 regularization loss: 3.93E-01
Test scatter: [0.9194 0.1286 0.5355 0.6941], Lowest was [0.9194 0.1286 0.5355 0.6941]
Median for last 10 epochs: [0.9196 0.1403 0.5355 0.9843], Epochs since improvement 0
  2%|▏         | 10/500 [06:08<5:23:48, 39.65s/it]  2%|▏         | 11/500 [06:36<4:52:23, 35.88s/it]  2%|▏         | 12/500 [07:21<5:15:46, 38.82s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.86E+06, Train scatter: [0.9324 0.12   0.544  0.6596]
L1 regularization loss: 1.60E+00, L2 regularization loss: 4.03E-01
Test scatter: [0.9169 0.1189 0.5354 0.65  ], Lowest was [0.9169 0.1189 0.5354 0.65  ]
Median for last 10 epochs: [0.9196 0.1403 0.5355 0.9843], Epochs since improvement 0
  3%|▎         | 13/500 [07:48<4:46:51, 35.34s/it]  3%|▎         | 14/500 [08:34<5:11:04, 38.41s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.48E+06, Train scatter: [0.9083 0.1118 0.5428 0.6044]
L1 regularization loss: 1.61E+00, L2 regularization loss: 4.11E-01
Test scatter: [0.8922 0.1116 0.5342 0.5935], Lowest was [0.8922 0.1116 0.5342 0.5935]
Median for last 10 epochs: [0.9194 0.1286 0.5355 0.6941], Epochs since improvement 0
  3%|▎         | 15/500 [09:01<4:43:24, 35.06s/it]  3%|▎         | 16/500 [09:47<5:08:53, 38.29s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.11E+06, Train scatter: [0.7179 0.1042 0.5404 0.5903]
L1 regularization loss: 1.62E+00, L2 regularization loss: 4.22E-01
Test scatter: [0.707  0.1046 0.5318 0.5818], Lowest was [0.707  0.1046 0.5318 0.5818]
Median for last 10 epochs: [0.9169 0.1189 0.5354 0.65  ], Epochs since improvement 0
  3%|▎         | 17/500 [10:14<4:41:13, 34.93s/it]  4%|▎         | 18/500 [10:59<5:03:57, 37.84s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 5.74E+06, Train scatter: [0.624  0.1003 0.5369 0.5878]
L1 regularization loss: 1.64E+00, L2 regularization loss: 4.34E-01
Test scatter: [0.6201 0.1014 0.5286 0.5887], Lowest was [0.6201 0.1014 0.5286 0.5818]
Median for last 10 epochs: [0.8922 0.1116 0.5342 0.5935], Epochs since improvement 0
  4%|▍         | 19/500 [11:26<4:38:02, 34.68s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.26E+06, Train scatter: [0.5024 0.0951 0.5337 0.5611]
L1 regularization loss: 1.66E+00, L2 regularization loss: 4.44E-01
Test scatter: [0.502  0.0957 0.5253 0.5558], Lowest was [0.502  0.0957 0.5253 0.5558]
Median for last 10 epochs: [0.707  0.1046 0.5318 0.5887], Epochs since improvement 0
  4%|▍         | 20/500 [12:16<5:13:49, 39.23s/it]  4%|▍         | 21/500 [12:43<4:44:16, 35.61s/it]  4%|▍         | 22/500 [13:29<5:08:13, 38.69s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.86E+06, Train scatter: [0.4897 0.0886 0.5307 0.5916]
L1 regularization loss: 1.67E+00, L2 regularization loss: 4.53E-01
Test scatter: [0.503  0.0891 0.5225 0.5889], Lowest was [0.502  0.0891 0.5225 0.5558]
Median for last 10 epochs: [0.6201 0.1014 0.5286 0.5887], Epochs since improvement 0
  5%|▍         | 23/500 [13:56<4:40:11, 35.24s/it]  5%|▍         | 24/500 [14:43<5:06:23, 38.62s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.32E+06, Train scatter: [0.6319 0.0996 0.5045 0.5958]
L1 regularization loss: 1.68E+00, L2 regularization loss: 4.64E-01
Test scatter: [0.6126 0.1053 0.4979 0.6132], Lowest was [0.502  0.0891 0.4979 0.5558]
Median for last 10 epochs: [0.6126 0.1014 0.5253 0.5887], Epochs since improvement 0
  5%|▌         | 25/500 [15:10<4:38:22, 35.16s/it]  5%|▌         | 26/500 [15:55<5:02:40, 38.31s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.35E+06, Train scatter: [0.5325 0.0942 0.4194 0.5865]
L1 regularization loss: 1.70E+00, L2 regularization loss: 4.76E-01
Test scatter: [0.5488 0.098  0.419  0.5917], Lowest was [0.502  0.0891 0.419  0.5558]
Median for last 10 epochs: [0.5488 0.098  0.5225 0.5889], Epochs since improvement 0
  5%|▌         | 27/500 [16:23<4:35:43, 34.98s/it]  6%|▌         | 28/500 [17:09<5:01:21, 38.31s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.09E+06, Train scatter: [0.4978 0.0898 0.3551 0.5815]
L1 regularization loss: 1.72E+00, L2 regularization loss: 4.87E-01
Test scatter: [0.4987 0.0921 0.359  0.5762], Lowest was [0.4987 0.0891 0.359  0.5558]
Median for last 10 epochs: [0.503  0.0957 0.4979 0.5889], Epochs since improvement 0
  6%|▌         | 29/500 [17:36<4:34:39, 34.99s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 1.94E+06, Train scatter: [0.6564 0.0933 0.3602 0.5851]
L1 regularization loss: 1.74E+00, L2 regularization loss: 4.97E-01
Test scatter: [0.6182 0.0972 0.365  0.5845], Lowest was [0.4987 0.0891 0.359  0.5558]
Median for last 10 epochs: [0.5488 0.0972 0.419  0.5889], Epochs since improvement 2
  6%|▌         | 30/500 [18:27<5:11:14, 39.73s/it]  6%|▌         | 31/500 [18:54<4:41:13, 35.98s/it]  6%|▋         | 32/500 [19:40<5:03:33, 38.92s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 1.65E+06, Train scatter: [0.566  0.0856 0.3335 0.5581]
L1 regularization loss: 1.77E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.5519 0.0878 0.3432 0.5611], Lowest was [0.4987 0.0878 0.3432 0.5558]
Median for last 10 epochs: [0.5519 0.0972 0.365  0.5845], Epochs since improvement 0
  7%|▋         | 33/500 [20:07<4:35:39, 35.42s/it]  7%|▋         | 34/500 [20:53<4:59:33, 38.57s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 1.57E+06, Train scatter: [0.4617 0.0835 0.3327 0.5399]
L1 regularization loss: 1.79E+00, L2 regularization loss: 5.23E-01
Test scatter: [0.4697 0.0854 0.3331 0.5388], Lowest was [0.4697 0.0854 0.3331 0.5388]
Median for last 10 epochs: [0.5488 0.0921 0.359  0.5762], Epochs since improvement 0
  7%|▋         | 35/500 [21:20<4:32:57, 35.22s/it]  7%|▋         | 36/500 [22:06<4:57:28, 38.47s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 1.53E+06, Train scatter: [0.5092 0.0849 0.3383 0.5753]
L1 regularization loss: 1.82E+00, L2 regularization loss: 5.36E-01
Test scatter: [0.5114 0.0877 0.3383 0.5685], Lowest was [0.4697 0.0854 0.3331 0.5388]
Median for last 10 epochs: [0.5114 0.0878 0.3432 0.5685], Epochs since improvement 2
  7%|▋         | 37/500 [22:34<4:30:49, 35.10s/it]  8%|▊         | 38/500 [23:20<4:55:45, 38.41s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.39E+06, Train scatter: [0.4904 0.0831 0.3147 0.5337]
L1 regularization loss: 1.85E+00, L2 regularization loss: 5.51E-01
Test scatter: [0.4952 0.0875 0.3257 0.5356], Lowest was [0.4697 0.0854 0.3257 0.5356]
Median for last 10 epochs: [0.5114 0.0877 0.3383 0.5611], Epochs since improvement 0
  8%|▊         | 39/500 [23:47<4:29:20, 35.06s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.36E+06, Train scatter: [0.3943 0.0826 0.3136 0.5464]
L1 regularization loss: 1.88E+00, L2 regularization loss: 5.68E-01
Test scatter: [0.4063 0.084  0.3171 0.5458], Lowest was [0.4063 0.084  0.3171 0.5356]
Median for last 10 epochs: [0.4952 0.0875 0.3331 0.5458], Epochs since improvement 0
  8%|▊         | 40/500 [24:39<5:07:51, 40.16s/it]  8%|▊         | 41/500 [25:06<4:37:57, 36.33s/it]  8%|▊         | 42/500 [25:53<5:01:01, 39.43s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.27E+06, Train scatter: [0.4433 0.0848 0.418  0.5548]
L1 regularization loss: 1.92E+00, L2 regularization loss: 5.87E-01
Test scatter: [0.4453 0.0875 0.4149 0.5549], Lowest was [0.4063 0.084  0.3171 0.5356]
Median for last 10 epochs: [0.4697 0.0875 0.3331 0.5458], Epochs since improvement 2
  9%|▊         | 43/500 [26:21<4:32:47, 35.82s/it]  9%|▉         | 44/500 [27:07<4:55:29, 38.88s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.18E+06, Train scatter: [0.397  0.0809 0.3998 0.5201]
L1 regularization loss: 1.94E+00, L2 regularization loss: 6.03E-01
Test scatter: [0.3998 0.0827 0.3979 0.5193], Lowest was [0.3998 0.0827 0.3171 0.5193]
Median for last 10 epochs: [0.4453 0.0875 0.3383 0.5458], Epochs since improvement 0
  9%|▉         | 45/500 [27:34<4:28:31, 35.41s/it]  9%|▉         | 46/500 [28:20<4:52:15, 38.62s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.14E+06, Train scatter: [0.3889 0.0857 0.3526 0.5415]
L1 regularization loss: 1.97E+00, L2 regularization loss: 6.22E-01
Test scatter: [0.3932 0.0879 0.3629 0.5442], Lowest was [0.3932 0.0827 0.3171 0.5193]
Median for last 10 epochs: [0.4063 0.0875 0.3629 0.5442], Epochs since improvement 0
  9%|▉         | 47/500 [28:47<4:25:58, 35.23s/it] 10%|▉         | 48/500 [29:34<4:51:03, 38.64s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.03E+06, Train scatter: [0.331  0.0789 0.3202 0.5176]
L1 regularization loss: 2.00E+00, L2 regularization loss: 6.43E-01
Test scatter: [0.3395 0.0812 0.3229 0.5193], Lowest was [0.3395 0.0812 0.3171 0.5193]
Median for last 10 epochs: [0.3998 0.084  0.3629 0.5442], Epochs since improvement 0
 10%|▉         | 49/500 [30:01<4:25:01, 35.26s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.03E+06, Train scatter: [0.3183 0.0824 0.3032 0.5771]
L1 regularization loss: 2.03E+00, L2 regularization loss: 6.65E-01
Test scatter: [0.357  0.083  0.3091 0.5729], Lowest was [0.3395 0.0812 0.3091 0.5193]
Median for last 10 epochs: [0.3932 0.083  0.3629 0.5442], Epochs since improvement 0
 10%|█         | 50/500 [30:54<5:04:17, 40.57s/it] 10%|█         | 51/500 [31:22<4:34:16, 36.65s/it] 10%|█         | 52/500 [32:08<4:54:54, 39.50s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 9.63E+05, Train scatter: [0.3901 0.077  0.2964 0.5129]
L1 regularization loss: 2.05E+00, L2 regularization loss: 6.85E-01
Test scatter: [0.398  0.0776 0.3006 0.5137], Lowest was [0.3395 0.0776 0.3006 0.5137]
Median for last 10 epochs: [0.3932 0.0827 0.3229 0.5193], Epochs since improvement 0
 11%|█         | 53/500 [32:35<4:26:52, 35.82s/it] 11%|█         | 54/500 [33:22<4:50:34, 39.09s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 9.11E+05, Train scatter: [0.4066 0.0771 0.2898 0.4986]
L1 regularization loss: 2.08E+00, L2 regularization loss: 7.07E-01
Test scatter: [0.4108 0.0768 0.2959 0.5004], Lowest was [0.3395 0.0768 0.2959 0.5004]
Median for last 10 epochs: [0.3932 0.0812 0.3091 0.5193], Epochs since improvement 0
 11%|█         | 55/500 [33:49<4:23:31, 35.53s/it] 11%|█         | 56/500 [34:35<4:47:06, 38.80s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 8.02E+05, Train scatter: [0.2784 0.0754 0.3069 0.5041]
L1 regularization loss: 2.10E+00, L2 regularization loss: 7.27E-01
Test scatter: [0.2833 0.0767 0.3203 0.5037], Lowest was [0.2833 0.0767 0.2959 0.5004]
Median for last 10 epochs: [0.357  0.0776 0.3091 0.5137], Epochs since improvement 0
 11%|█▏        | 57/500 [35:03<4:21:15, 35.39s/it] 12%|█▏        | 58/500 [35:49<4:44:34, 38.63s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 7.31E+05, Train scatter: [0.287  0.0743 0.2872 0.5083]
L1 regularization loss: 2.12E+00, L2 regularization loss: 7.49E-01
Test scatter: [0.3276 0.0752 0.2948 0.5064], Lowest was [0.2833 0.0752 0.2948 0.5004]
Median for last 10 epochs: [0.357  0.0768 0.3006 0.5064], Epochs since improvement 0
 12%|█▏        | 59/500 [36:16<4:19:06, 35.25s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.03E+06, Train scatter: [0.2668 0.0738 0.2746 0.5003]
L1 regularization loss: 2.15E+00, L2 regularization loss: 7.72E-01
Test scatter: [0.2801 0.0742 0.2858 0.5022], Lowest was [0.2801 0.0742 0.2858 0.5004]
Median for last 10 epochs: [0.3276 0.0767 0.2959 0.5037], Epochs since improvement 0
 12%|█▏        | 60/500 [37:08<4:55:00, 40.23s/it] 12%|█▏        | 61/500 [37:36<4:26:13, 36.39s/it] 12%|█▏        | 62/500 [38:23<4:49:26, 39.65s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 8.93E+05, Train scatter: [0.329  0.0733 0.2789 0.495 ]
L1 regularization loss: 2.18E+00, L2 regularization loss: 8.03E-01
Test scatter: [0.34   0.0745 0.289  0.4955], Lowest was [0.2801 0.0742 0.2858 0.4955]
Median for last 10 epochs: [0.3276 0.0752 0.2948 0.5022], Epochs since improvement 0
 13%|█▎        | 63/500 [38:50<4:22:03, 35.98s/it] 13%|█▎        | 64/500 [39:37<4:45:04, 39.23s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 6.51E+05, Train scatter: [0.3627 0.0827 0.3063 0.5162]
L1 regularization loss: 2.20E+00, L2 regularization loss: 8.28E-01
Test scatter: [0.3727 0.0855 0.3124 0.5203], Lowest was [0.2801 0.0742 0.2858 0.4955]
Median for last 10 epochs: [0.3276 0.0752 0.2948 0.5037], Epochs since improvement 2
 13%|█▎        | 65/500 [40:05<4:18:53, 35.71s/it] 13%|█▎        | 66/500 [40:51<4:41:25, 38.91s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.87E+06, Train scatter: [0.2508 0.0721 0.3904 0.4897]
L1 regularization loss: 2.25E+00, L2 regularization loss: 8.63E-01
Test scatter: [0.2629 0.0739 0.3832 0.4922], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.3276 0.0745 0.2948 0.5022], Epochs since improvement 0
 13%|█▎        | 67/500 [41:18<4:15:47, 35.44s/it] 14%|█▎        | 68/500 [42:05<4:38:26, 38.67s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.11E+06, Train scatter: [0.3827 0.0864 0.44   0.5777]
L1 regularization loss: 2.34E+00, L2 regularization loss: 9.38E-01
Test scatter: [0.3934 0.0873 0.4492 0.5804], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.34   0.0745 0.3124 0.5022], Epochs since improvement 2
 14%|█▍        | 69/500 [42:32<4:13:33, 35.30s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 4.55E+06, Train scatter: [0.931  0.135  0.5197 0.775 ]
L1 regularization loss: 3.22E+00, L2 regularization loss: 1.42E+00
Test scatter: [0.9151 0.1345 0.512  0.7754], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.3727 0.0855 0.3832 0.5203], Epochs since improvement 4
 14%|█▍        | 70/500 [43:24<4:48:00, 40.19s/it] 14%|█▍        | 71/500 [43:51<4:19:38, 36.31s/it] 14%|█▍        | 72/500 [44:37<4:40:05, 39.27s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.28E+06, Train scatter: [0.9224 0.124  0.512  0.7336]
L1 regularization loss: 3.23E+00, L2 regularization loss: 1.45E+00
Test scatter: [0.907  0.1234 0.507  0.7251], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.3934 0.0873 0.4492 0.5804], Epochs since improvement 6
 15%|█▍        | 73/500 [45:04<4:13:39, 35.64s/it] 15%|█▍        | 74/500 [45:50<4:35:19, 38.78s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.73E+06, Train scatter: [0.8985 0.1173 0.5046 0.7076]
L1 regularization loss: 3.24E+00, L2 regularization loss: 1.49E+00
Test scatter: [0.8846 0.1172 0.499  0.6975], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.8846 0.1172 0.499  0.6975], Epochs since improvement 8
 15%|█▌        | 75/500 [46:18<4:10:23, 35.35s/it] 15%|█▌        | 76/500 [47:05<4:34:18, 38.82s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.79E+06, Train scatter: [0.8413 0.1136 0.534  0.6929]
L1 regularization loss: 3.30E+00, L2 regularization loss: 1.59E+00
Test scatter: [0.8327 0.1133 0.5266 0.6845], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.8846 0.1172 0.507  0.6975], Epochs since improvement 10
 15%|█▌        | 77/500 [47:32<4:09:18, 35.36s/it] 16%|█▌        | 78/500 [48:18<4:31:09, 38.55s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.39E+06, Train scatter: [0.6959 0.1108 0.5118 0.6804]
L1 regularization loss: 3.32E+00, L2 regularization loss: 1.73E+00
Test scatter: [0.7027 0.1106 0.5066 0.6704], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.8846 0.1172 0.507  0.6975], Epochs since improvement 12
 16%|█▌        | 79/500 [48:45<4:07:00, 35.20s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.22E+06, Train scatter: [0.6405 0.1088 0.5196 0.6738]
L1 regularization loss: 3.32E+00, L2 regularization loss: 1.79E+00
Test scatter: [0.6685 0.1089 0.5131 0.6652], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.8327 0.1133 0.507  0.6845], Epochs since improvement 14
 16%|█▌        | 80/500 [49:37<4:40:34, 40.08s/it] 16%|█▌        | 81/500 [50:04<4:13:22, 36.28s/it] 16%|█▋        | 82/500 [50:50<4:32:43, 39.15s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.06E+06, Train scatter: [0.6474 0.1072 0.5042 0.6685]
L1 regularization loss: 3.33E+00, L2 regularization loss: 1.83E+00
Test scatter: [0.6672 0.1071 0.4982 0.661 ], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.7027 0.1106 0.5066 0.6704], Epochs since improvement 16
 17%|█▋        | 83/500 [51:18<4:07:49, 35.66s/it] 17%|█▋        | 84/500 [52:04<4:28:58, 38.80s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.08E+06, Train scatter: [0.6171 0.1058 0.5064 0.6543]
L1 regularization loss: 3.34E+00, L2 regularization loss: 1.88E+00
Test scatter: [0.638  0.1061 0.4999 0.6475], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.6685 0.1089 0.5066 0.6652], Epochs since improvement 18
 17%|█▋        | 85/500 [52:31<4:04:42, 35.38s/it] 17%|█▋        | 86/500 [53:17<4:26:15, 38.59s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 1.71E+06, Train scatter: [0.6061 0.1039 0.4927 0.6822]
L1 regularization loss: 3.35E+00, L2 regularization loss: 1.93E+00
Test scatter: [0.6169 0.1039 0.487  0.6703], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.6672 0.1071 0.4999 0.6652], Epochs since improvement 20
 17%|█▋        | 87/500 [53:45<4:02:42, 35.26s/it] 17%|█▋        | 87/500 [54:31<4:18:49, 37.60s/it]
Epoch: 88 done with learning rate 9.98E-03, Train loss: 1.33E+06, Train scatter: [0.6042 0.1022 0.4419 0.6277]
L1 regularization loss: 3.36E+00, L2 regularization loss: 1.98E+00
Test scatter: [0.6107 0.1029 0.4388 0.6223], Lowest was [0.2629 0.0739 0.2858 0.4922]
Median for last 10 epochs: [0.638  0.1061 0.4982 0.661 ], Epochs since improvement 22
Exited after 88 epochs due to early stopping
3271.39 seconds spent training, 6.543 seconds per epoch. Processed 10643 trees per second
[0.6106457  0.10285594 0.43877834 0.6223226 ]
{'epoch_exit': 87, 'scatter_m_star': 0.6106457, 'lowest_m_star': 0.262868, 'last20_m_star': 0.6855866, 'last10_m_star': 0.6379969, 'scatter_v_disk': 0.10285594, 'lowest_v_disk': 0.07387694, 'last20_v_disk': 0.10975815, 'last10_v_disk': 0.106131926, 'scatter_m_cold': 0.43877834, 'lowest_m_cold': 0.28582948, 'last20_m_cold': 0.5032407, 'last10_m_cold': 0.4982485, 'scatter_sfr_100': 0.6223226, 'lowest_sfr_100': 0.49215168, 'last20_sfr_100': 0.67032695, 'last10_sfr_100': 0.66102266}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_tjhecu
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:47<6:37:24, 47.78s/it]  0%|          | 2/500 [01:58<8:30:17, 61.48s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.30E+07, Train scatter: [0.9351 0.1369 0.544  0.9954]
L1 regularization loss: 1.98E+00, L2 regularization loss: 3.83E-01
Test scatter: [0.9195 0.1344 0.5354 0.9851], Lowest was [0.9195 0.1344 0.5354 0.9851]
Median for last 10 epochs: [0.9195 0.1344 0.5354 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:45<7:34:07, 54.82s/it]  1%|          | 4/500 [03:56<8:25:07, 61.10s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.47E+07, Train scatter: [0.9233 0.0915 0.5439 0.992 ]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.11E-01
Test scatter: [0.9074 0.0912 0.5353 0.9815], Lowest was [0.9074 0.0912 0.5353 0.9815]
Median for last 10 epochs: [0.9074 0.0912 0.5353 0.9815], Epochs since improvement 0
  1%|          | 5/500 [04:43<7:41:58, 56.00s/it]  1%|          | 6/500 [05:54<8:23:36, 61.17s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.17E+06, Train scatter: [0.7514 0.0866 0.5438 0.6062]
L1 regularization loss: 2.05E+00, L2 regularization loss: 4.53E-01
Test scatter: [0.7382 0.0869 0.5353 0.6045], Lowest was [0.7382 0.0869 0.5353 0.6045]
Median for last 10 epochs: [0.7382 0.0869 0.5353 0.6045], Epochs since improvement 0
  1%|▏         | 7/500 [06:41<7:44:18, 56.51s/it]  2%|▏         | 8/500 [07:54<8:26:14, 61.74s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 5.43E+06, Train scatter: [0.4772 0.0769 0.5438 0.5477]
L1 regularization loss: 2.06E+00, L2 regularization loss: 4.66E-01
Test scatter: [0.4747 0.0774 0.5353 0.5432], Lowest was [0.4747 0.0774 0.5353 0.5432]
Median for last 10 epochs: [0.6065 0.0822 0.5353 0.5738], Epochs since improvement 0
  2%|▏         | 9/500 [08:41<7:46:18, 56.98s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.14E+06, Train scatter: [0.3193 0.0733 0.5438 0.5334]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.75E-01
Test scatter: [0.3269 0.0741 0.5352 0.5284], Lowest was [0.3269 0.0741 0.5352 0.5284]
Median for last 10 epochs: [0.4747 0.0774 0.5353 0.5432], Epochs since improvement 0
  2%|▏         | 10/500 [09:59<8:40:18, 63.71s/it]  2%|▏         | 11/500 [10:46<7:56:49, 58.51s/it]  2%|▏         | 12/500 [11:57<8:26:19, 62.25s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 3.68E+06, Train scatter: [0.2668 0.0729 0.5438 0.5182]
L1 regularization loss: 2.08E+00, L2 regularization loss: 4.81E-01
Test scatter: [0.2715 0.0735 0.5352 0.5131], Lowest was [0.2715 0.0735 0.5352 0.5131]
Median for last 10 epochs: [0.4747 0.0774 0.5353 0.5432], Epochs since improvement 0
  3%|▎         | 13/500 [12:43<7:46:47, 57.51s/it]  3%|▎         | 14/500 [13:54<8:18:02, 61.49s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 3.49E+06, Train scatter: [0.2245 0.0716 0.5437 0.5144]
L1 regularization loss: 2.08E+00, L2 regularization loss: 4.86E-01
Test scatter: [0.2316 0.0726 0.5352 0.511 ], Lowest was [0.2316 0.0726 0.5352 0.511 ]
Median for last 10 epochs: [0.3269 0.0741 0.5352 0.5284], Epochs since improvement 0
  3%|▎         | 15/500 [14:41<7:40:44, 57.00s/it]  3%|▎         | 16/500 [15:52<8:15:41, 61.45s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.32E+06, Train scatter: [0.2592 0.0698 0.5437 0.5105]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.90E-01
Test scatter: [0.263  0.0705 0.5351 0.5085], Lowest was [0.2316 0.0705 0.5351 0.5085]
Median for last 10 epochs: [0.2715 0.0735 0.5352 0.5131], Epochs since improvement 0
  3%|▎         | 17/500 [16:39<7:38:44, 56.99s/it]  4%|▎         | 18/500 [17:51<8:13:02, 61.37s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.29E+06, Train scatter: [0.2553 0.0701 0.5435 0.5112]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.93E-01
Test scatter: [0.2651 0.071  0.535  0.5066], Lowest was [0.2316 0.0705 0.535  0.5066]
Median for last 10 epochs: [0.2651 0.0726 0.5352 0.511 ], Epochs since improvement 0
  4%|▍         | 19/500 [18:37<7:36:19, 56.92s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.31E+06, Train scatter: [0.2266 0.069  0.5436 0.5112]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.97E-01
Test scatter: [0.2298 0.0699 0.535  0.5103], Lowest was [0.2298 0.0699 0.535  0.5066]
Median for last 10 epochs: [0.263  0.071  0.5351 0.5103], Epochs since improvement 0
  4%|▍         | 20/500 [19:55<8:25:46, 63.22s/it]  4%|▍         | 21/500 [20:42<7:45:12, 58.27s/it]  4%|▍         | 22/500 [21:54<8:16:19, 62.30s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.18E+06, Train scatter: [0.2161 0.066  0.5435 0.5059]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.01E-01
Test scatter: [0.2188 0.0666 0.535  0.5032], Lowest was [0.2188 0.0666 0.535  0.5032]
Median for last 10 epochs: [0.2316 0.0705 0.535  0.5085], Epochs since improvement 0
  5%|▍         | 23/500 [22:40<7:37:39, 57.57s/it]  5%|▍         | 24/500 [23:52<8:09:59, 61.76s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.16E+06, Train scatter: [0.2264 0.0642 0.5435 0.5082]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.07E-01
Test scatter: [0.2321 0.0639 0.535  0.5068], Lowest was [0.2188 0.0639 0.535  0.5032]
Median for last 10 epochs: [0.2321 0.0699 0.535  0.5068], Epochs since improvement 0
  5%|▌         | 25/500 [24:38<7:32:35, 57.17s/it]  5%|▌         | 26/500 [25:49<8:04:23, 61.32s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.13E+06, Train scatter: [0.1945 0.0619 0.5435 0.4927]
L1 regularization loss: 2.16E+00, L2 regularization loss: 5.13E-01
Test scatter: [0.2015 0.062  0.535  0.4875], Lowest was [0.2015 0.062  0.535  0.4875]
Median for last 10 epochs: [0.2298 0.0666 0.535  0.5066], Epochs since improvement 0
  5%|▌         | 27/500 [26:36<7:28:27, 56.89s/it]  6%|▌         | 28/500 [27:47<8:01:49, 61.25s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.08E+06, Train scatter: [0.3084 0.0652 0.5434 0.5231]
L1 regularization loss: 2.18E+00, L2 regularization loss: 5.21E-01
Test scatter: [0.3109 0.0651 0.5349 0.5205], Lowest was [0.2015 0.062  0.5349 0.4875]
Median for last 10 epochs: [0.2298 0.0651 0.535  0.5068], Epochs since improvement 0
  6%|▌         | 29/500 [28:34<7:26:42, 56.90s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.07E+06, Train scatter: [0.2037 0.0583 0.5436 0.4855]
L1 regularization loss: 2.20E+00, L2 regularization loss: 5.28E-01
Test scatter: [0.2099 0.0585 0.535  0.4786], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.2188 0.0639 0.535  0.5032], Epochs since improvement 0
  6%|▌         | 30/500 [29:52<8:16:15, 63.35s/it]  6%|▌         | 31/500 [30:39<7:36:22, 58.38s/it]  6%|▋         | 32/500 [31:51<8:07:43, 62.53s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.06E+06, Train scatter: [0.2247 0.0607 0.5436 0.4956]
L1 regularization loss: 2.22E+00, L2 regularization loss: 5.37E-01
Test scatter: [0.2293 0.0603 0.535  0.4898], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.2293 0.062  0.535  0.4898], Epochs since improvement 2
  7%|▋         | 33/500 [32:38<7:29:20, 57.73s/it]  7%|▋         | 34/500 [33:49<7:59:53, 61.79s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.01E+06, Train scatter: [0.3317 0.0811 0.5437 0.6037]
L1 regularization loss: 2.24E+00, L2 regularization loss: 5.46E-01
Test scatter: [0.3302 0.0813 0.5351 0.6032], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.2293 0.062  0.535  0.4898], Epochs since improvement 4
  7%|▋         | 35/500 [34:36<7:23:37, 57.24s/it]  7%|▋         | 36/500 [35:48<7:56:41, 61.64s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.08E+06, Train scatter: [0.4105 0.0763 0.5437 0.5156]
L1 regularization loss: 2.30E+00, L2 regularization loss: 5.67E-01
Test scatter: [0.4043 0.0755 0.5352 0.5083], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.3109 0.0651 0.535  0.5083], Epochs since improvement 6
  7%|▋         | 37/500 [36:34<7:20:58, 57.15s/it]  8%|▊         | 38/500 [37:46<7:54:37, 61.64s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.13E+06, Train scatter: [0.4917 0.1103 0.5438 0.594 ]
L1 regularization loss: 2.33E+00, L2 regularization loss: 5.85E-01
Test scatter: [0.4853 0.1083 0.5353 0.5826], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.3302 0.0755 0.5351 0.5083], Epochs since improvement 8
  8%|▊         | 39/500 [38:33<7:18:45, 57.11s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 4.96E+06, Train scatter: [0.9334 0.1714 0.5441 0.9954]
L1 regularization loss: 2.86E+00, L2 regularization loss: 7.56E-01
Test scatter: [0.9179 0.1675 0.5355 0.985 ], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.4043 0.0813 0.5352 0.5826], Epochs since improvement 10
  8%|▊         | 40/500 [39:51<8:07:18, 63.56s/it]  8%|▊         | 41/500 [40:38<7:27:42, 58.52s/it]  8%|▊         | 42/500 [41:50<7:57:03, 62.50s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 4.14E+06, Train scatter: [0.9274 0.1539 0.5441 0.9954]
L1 regularization loss: 2.88E+00, L2 regularization loss: 7.91E-01
Test scatter: [0.9122 0.1506 0.5355 0.985 ], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.4853 0.1083 0.5353 0.6032], Epochs since improvement 12
  9%|▊         | 43/500 [42:37<7:19:40, 57.73s/it]  9%|▉         | 44/500 [43:49<7:51:36, 62.05s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.70E+06, Train scatter: [0.8975 0.1177 0.5441 0.9954]
L1 regularization loss: 2.90E+00, L2 regularization loss: 8.39E-01
Test scatter: [0.8828 0.1166 0.5355 0.9851], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.8828 0.1166 0.5355 0.985 ], Epochs since improvement 14
  9%|▉         | 45/500 [44:35<7:15:10, 57.38s/it]  9%|▉         | 46/500 [45:47<7:46:14, 61.62s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.50E+06, Train scatter: [0.6203 0.1079 0.544  0.9948]
L1 regularization loss: 2.94E+00, L2 regularization loss: 9.11E-01
Test scatter: [0.6146 0.1067 0.5355 0.9845], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.8828 0.1166 0.5355 0.985 ], Epochs since improvement 16
  9%|▉         | 47/500 [46:33<7:11:01, 57.09s/it] 10%|▉         | 48/500 [47:44<7:40:46, 61.16s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.47E+06, Train scatter: [0.5613 0.1087 0.544  0.9935]
L1 regularization loss: 2.96E+00, L2 regularization loss: 9.35E-01
Test scatter: [0.5545 0.1067 0.5354 0.9831], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.8828 0.1166 0.5355 0.985 ], Epochs since improvement 18
 10%|▉         | 49/500 [48:31<7:07:02, 56.81s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.44E+06, Train scatter: [0.6128 0.1003 0.544  0.9868]
L1 regularization loss: 2.99E+00, L2 regularization loss: 9.63E-01
Test scatter: [0.6147 0.098  0.5354 0.9766], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.6147 0.1067 0.5355 0.9845], Epochs since improvement 20
 10%|█         | 50/500 [49:48<7:52:46, 63.04s/it] 10%|█         | 51/500 [50:35<7:14:39, 58.08s/it] 10%|█         | 51/500 [51:47<7:35:55, 60.92s/it]
Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.40E+06, Train scatter: [0.5213 0.0999 0.544  0.6839]
L1 regularization loss: 3.03E+00, L2 regularization loss: 1.01E+00
Test scatter: [0.5117 0.0989 0.5354 0.6791], Lowest was [0.2015 0.0585 0.5349 0.4786]
Median for last 10 epochs: [0.6146 0.1067 0.5354 0.9831], Epochs since improvement 22
Exited after 52 epochs due to early stopping
3107.17 seconds spent training, 6.214 seconds per epoch. Processed 11206 trees per second
[0.51167417 0.09889577 0.5354124  0.6790454 ]
{'epoch_exit': 51, 'scatter_m_star': 0.51167417, 'lowest_m_star': 0.20154332, 'last20_m_star': 0.584537, 'last10_m_star': 0.61457235, 'scatter_v_disk': 0.09889577, 'lowest_v_disk': 0.058487397, 'last20_v_disk': 0.106695466, 'last10_v_disk': 0.10667839, 'scatter_m_cold': 0.5354124, 'lowest_m_cold': 0.53486747, 'last20_m_cold': 0.53543913, 'last10_m_cold': 0.5354461, 'scatter_sfr_100': 0.6790454, 'lowest_sfr_100': 0.4786243, 'last20_sfr_100': 0.97987103, 'last10_sfr_100': 0.98310935}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_ebrobz
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:41<5:42:56, 41.24s/it]  0%|          | 2/500 [01:44<7:29:27, 54.15s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.01E+07, Train scatter: [0.9352 0.1713 0.5441 0.9954]
L1 regularization loss: 1.98E+00, L2 regularization loss: 3.76E-01
Test scatter: [0.9196 0.1674 0.5356 0.9851], Lowest was [0.9196 0.1674 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1674 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:24<6:35:41, 47.77s/it]  1%|          | 4/500 [03:27<7:23:27, 53.64s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.21E+07, Train scatter: [0.9352 0.1563 0.5441 0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.85E-01
Test scatter: [0.9196 0.1527 0.5355 0.9851], Lowest was [0.9196 0.1527 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1527 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:07<6:42:37, 48.80s/it]  1%|          | 6/500 [05:09<7:20:02, 53.45s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.69E+07, Train scatter: [0.9349 0.1095 0.544  0.9954]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.01E-01
Test scatter: [0.9193 0.1089 0.5355 0.9851], Lowest was [0.9193 0.1089 0.5355 0.9851]
Median for last 10 epochs: [0.9193 0.1089 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [05:50<6:43:51, 49.15s/it]  2%|▏         | 8/500 [06:53<7:19:34, 53.61s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.31E+07, Train scatter: [0.9054 0.0913 0.5439 0.8175]
L1 regularization loss: 2.04E+00, L2 regularization loss: 4.28E-01
Test scatter: [0.8918 0.0922 0.5353 0.8242], Lowest was [0.8918 0.0922 0.5353 0.8242]
Median for last 10 epochs: [0.9056 0.1006 0.5354 0.9047], Epochs since improvement 0
  2%|▏         | 9/500 [07:33<6:44:36, 49.44s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 9.75E+06, Train scatter: [0.8178 0.0986 0.5438 0.649 ]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.59E-01
Test scatter: [0.803  0.0983 0.5353 0.6428], Lowest was [0.803  0.0922 0.5353 0.6428]
Median for last 10 epochs: [0.8918 0.0983 0.5353 0.8242], Epochs since improvement 0
  2%|▏         | 10/500 [08:43<7:34:35, 55.66s/it]  2%|▏         | 11/500 [09:23<6:56:08, 51.06s/it]  2%|▏         | 12/500 [10:26<7:23:59, 54.59s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.71E+06, Train scatter: [0.6734 0.0839 0.5439 0.5758]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.75E-01
Test scatter: [0.6693 0.0843 0.5354 0.58  ], Lowest was [0.6693 0.0843 0.5353 0.58  ]
Median for last 10 epochs: [0.8918 0.0983 0.5354 0.8242], Epochs since improvement 0
  3%|▎         | 13/500 [11:07<6:48:40, 50.35s/it]  3%|▎         | 14/500 [12:10<7:20:49, 54.42s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 4.90E+06, Train scatter: [0.3812 0.0807 0.5439 0.5706]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.84E-01
Test scatter: [0.3906 0.0822 0.5353 0.5662], Lowest was [0.3906 0.0822 0.5353 0.5662]
Median for last 10 epochs: [0.803  0.0922 0.5353 0.6428], Epochs since improvement 0
  3%|▎         | 15/500 [12:51<6:46:16, 50.26s/it]  3%|▎         | 16/500 [13:54<7:17:12, 54.20s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.28E+06, Train scatter: [0.3107 0.0793 0.5438 0.5395]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.91E-01
Test scatter: [0.3151 0.0799 0.5353 0.5326], Lowest was [0.3151 0.0799 0.5353 0.5326]
Median for last 10 epochs: [0.6693 0.0843 0.5353 0.58  ], Epochs since improvement 0
  3%|▎         | 17/500 [14:35<6:42:59, 50.06s/it]  4%|▎         | 18/500 [15:39<7:15:20, 54.19s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.96E+06, Train scatter: [0.2811 0.0757 0.5438 0.5202]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.96E-01
Test scatter: [0.2886 0.0763 0.5352 0.5148], Lowest was [0.2886 0.0763 0.5352 0.5148]
Median for last 10 epochs: [0.3906 0.0822 0.5353 0.5662], Epochs since improvement 0
  4%|▍         | 19/500 [16:19<6:41:19, 50.06s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.81E+06, Train scatter: [0.2258 0.0748 0.5437 0.5297]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.00E-01
Test scatter: [0.2329 0.0749 0.5352 0.5203], Lowest was [0.2329 0.0749 0.5352 0.5148]
Median for last 10 epochs: [0.3151 0.0799 0.5353 0.5326], Epochs since improvement 0
  4%|▍         | 20/500 [17:29<7:27:04, 55.89s/it]  4%|▍         | 21/500 [18:09<6:48:56, 51.22s/it]  4%|▍         | 22/500 [19:13<7:18:19, 55.02s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.74E+06, Train scatter: [0.2736 0.0718 0.5437 0.5108]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.04E-01
Test scatter: [0.2795 0.0729 0.5352 0.5061], Lowest was [0.2329 0.0729 0.5352 0.5061]
Median for last 10 epochs: [0.2886 0.0763 0.5352 0.5203], Epochs since improvement 0
  5%|▍         | 23/500 [19:53<6:42:46, 50.66s/it]  5%|▍         | 24/500 [20:57<7:13:45, 54.67s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.89E+06, Train scatter: [0.2691 0.0727 0.5437 0.5162]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.08E-01
Test scatter: [0.2733 0.0733 0.5352 0.5152], Lowest was [0.2329 0.0729 0.5352 0.5061]
Median for last 10 epochs: [0.2795 0.0749 0.5352 0.5152], Epochs since improvement 0
  5%|▌         | 25/500 [21:38<6:38:59, 50.40s/it]  5%|▌         | 26/500 [22:40<7:07:03, 54.06s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.56E+06, Train scatter: [0.2659 0.07   0.5437 0.5197]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.2677 0.0706 0.5351 0.5146], Lowest was [0.2329 0.0706 0.5351 0.5061]
Median for last 10 epochs: [0.2733 0.0733 0.5352 0.5148], Epochs since improvement 0
  5%|▌         | 27/500 [23:21<6:34:22, 50.03s/it]  6%|▌         | 28/500 [24:24<7:04:11, 53.92s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.53E+06, Train scatter: [0.2176 0.0719 0.5436 0.5064]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.16E-01
Test scatter: [0.2273 0.0728 0.5351 0.503 ], Lowest was [0.2273 0.0706 0.5351 0.503 ]
Median for last 10 epochs: [0.2677 0.0729 0.5352 0.5146], Epochs since improvement 0
  6%|▌         | 29/500 [25:04<6:31:32, 49.88s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.52E+06, Train scatter: [0.204  0.0691 0.5435 0.5048]
L1 regularization loss: 2.16E+00, L2 regularization loss: 5.20E-01
Test scatter: [0.2123 0.0698 0.535  0.4994], Lowest was [0.2123 0.0698 0.535  0.4994]
Median for last 10 epochs: [0.2677 0.0728 0.5351 0.5061], Epochs since improvement 0
  6%|▌         | 30/500 [26:15<7:18:28, 55.98s/it]  6%|▌         | 31/500 [26:55<6:41:04, 51.31s/it]  6%|▋         | 32/500 [27:59<7:08:59, 55.00s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.46E+06, Train scatter: [0.2156 0.0706 0.5434 0.5118]
L1 regularization loss: 2.17E+00, L2 regularization loss: 5.25E-01
Test scatter: [0.2186 0.0708 0.5349 0.5064], Lowest was [0.2123 0.0698 0.5349 0.4994]
Median for last 10 epochs: [0.2273 0.0708 0.5351 0.5064], Epochs since improvement 0
  7%|▋         | 33/500 [28:39<6:33:47, 50.59s/it]  7%|▋         | 34/500 [29:42<7:02:19, 54.38s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.42E+06, Train scatter: [0.1997 0.0675 0.5434 0.5067]
L1 regularization loss: 2.19E+00, L2 regularization loss: 5.33E-01
Test scatter: [0.2075 0.0683 0.5349 0.5015], Lowest was [0.2075 0.0683 0.5349 0.4994]
Median for last 10 epochs: [0.2186 0.0706 0.535  0.503 ], Epochs since improvement 0
  7%|▋         | 35/500 [30:23<6:28:56, 50.19s/it]  7%|▋         | 36/500 [31:27<7:00:27, 54.37s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.36E+06, Train scatter: [0.2588 0.0678 0.5434 0.5059]
L1 regularization loss: 2.20E+00, L2 regularization loss: 5.40E-01
Test scatter: [0.2524 0.0679 0.5349 0.499 ], Lowest was [0.2075 0.0679 0.5349 0.499 ]
Median for last 10 epochs: [0.2186 0.0698 0.5349 0.5015], Epochs since improvement 0
  7%|▋         | 37/500 [32:07<6:26:57, 50.15s/it]  8%|▊         | 38/500 [33:10<6:55:51, 54.01s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.60E+06, Train scatter: [0.2921 0.0901 0.5437 0.5596]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.70E-01
Test scatter: [0.295  0.089  0.5351 0.5533], Lowest was [0.2075 0.0679 0.5349 0.499 ]
Median for last 10 epochs: [0.2186 0.0698 0.5349 0.5015], Epochs since improvement 2
  8%|▊         | 39/500 [33:51<6:24:02, 49.98s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.33E+06, Train scatter: [0.228  0.0756 0.5436 0.5159]
L1 regularization loss: 2.28E+00, L2 regularization loss: 5.80E-01
Test scatter: [0.2324 0.0749 0.535  0.5092], Lowest was [0.2075 0.0679 0.5349 0.499 ]
Median for last 10 epochs: [0.2324 0.0708 0.5349 0.5064], Epochs since improvement 4
  8%|▊         | 40/500 [35:00<7:06:46, 55.67s/it]  8%|▊         | 41/500 [35:40<6:31:12, 51.14s/it]  8%|▊         | 42/500 [36:44<6:59:41, 54.98s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.32E+06, Train scatter: [0.3055 0.076  0.5436 0.5696]
L1 regularization loss: 2.30E+00, L2 regularization loss: 5.86E-01
Test scatter: [0.3125 0.0766 0.535  0.5726], Lowest was [0.2075 0.0679 0.5349 0.499 ]
Median for last 10 epochs: [0.2524 0.0749 0.535  0.5092], Epochs since improvement 6
  9%|▊         | 43/500 [37:25<6:26:12, 50.71s/it]  9%|▉         | 44/500 [38:28<6:54:05, 54.49s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.28E+06, Train scatter: [0.2416 0.0717 0.5435 0.5108]
L1 regularization loss: 2.30E+00, L2 regularization loss: 5.91E-01
Test scatter: [0.2464 0.072  0.535  0.5073], Lowest was [0.2075 0.0679 0.5349 0.499 ]
Median for last 10 epochs: [0.2524 0.0749 0.535  0.5092], Epochs since improvement 8
  9%|▉         | 45/500 [39:09<6:21:10, 50.27s/it]  9%|▉         | 46/500 [40:12<6:51:14, 54.35s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.28E+06, Train scatter: [0.304  0.0736 0.5435 0.5484]
L1 regularization loss: 2.32E+00, L2 regularization loss: 6.01E-01
Test scatter: [0.3058 0.0734 0.535  0.5453], Lowest was [0.2075 0.0679 0.5349 0.499 ]
Median for last 10 epochs: [0.295  0.0749 0.535  0.5453], Epochs since improvement 10
  9%|▉         | 47/500 [40:53<6:18:50, 50.18s/it] 10%|▉         | 48/500 [41:57<6:49:20, 54.34s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.29E+06, Train scatter: [0.3015 0.0711 0.5435 0.5074]
L1 regularization loss: 2.33E+00, L2 regularization loss: 6.07E-01
Test scatter: [0.2966 0.0705 0.5349 0.4995], Lowest was [0.2075 0.0679 0.5349 0.499 ]
Median for last 10 epochs: [0.2966 0.0734 0.535  0.5092], Epochs since improvement 12
 10%|▉         | 49/500 [42:37<6:17:02, 50.16s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.26E+06, Train scatter: [0.2164 0.0727 0.5434 0.5053]
L1 regularization loss: 2.34E+00, L2 regularization loss: 6.15E-01
Test scatter: [0.2202 0.072  0.5349 0.4989], Lowest was [0.2075 0.0679 0.5349 0.4989]
Median for last 10 epochs: [0.2966 0.072  0.535  0.5073], Epochs since improvement 0
 10%|█         | 50/500 [43:47<7:00:19, 56.04s/it] 10%|█         | 51/500 [44:28<6:24:38, 51.40s/it] 10%|█         | 52/500 [45:31<6:50:20, 54.96s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.23E+06, Train scatter: [0.2081 0.0685 0.5434 0.5009]
L1 regularization loss: 2.35E+00, L2 regularization loss: 6.21E-01
Test scatter: [0.2137 0.068  0.5349 0.4957], Lowest was [0.2075 0.0679 0.5349 0.4957]
Median for last 10 epochs: [0.2464 0.072  0.5349 0.4995], Epochs since improvement 0
 11%|█         | 53/500 [46:11<6:16:44, 50.57s/it] 11%|█         | 54/500 [47:15<6:44:42, 54.44s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.24E+06, Train scatter: [0.2169 0.0666 0.5434 0.5037]
L1 regularization loss: 2.42E+00, L2 regularization loss: 6.44E-01
Test scatter: [0.2252 0.0663 0.5349 0.5   ], Lowest was [0.2075 0.0663 0.5349 0.4957]
Median for last 10 epochs: [0.2252 0.0705 0.5349 0.4995], Epochs since improvement 0
 11%|█         | 55/500 [47:55<6:12:48, 50.27s/it] 11%|█         | 56/500 [48:59<6:41:44, 54.29s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.30E+06, Train scatter: [0.2195 0.075  0.5434 0.5037]
L1 regularization loss: 2.45E+00, L2 regularization loss: 6.62E-01
Test scatter: [0.2248 0.0747 0.5349 0.4979], Lowest was [0.2075 0.0663 0.5349 0.4957]
Median for last 10 epochs: [0.2248 0.0705 0.5349 0.4989], Epochs since improvement 2
 11%|█▏        | 57/500 [49:39<6:10:25, 50.17s/it] 12%|█▏        | 58/500 [50:43<6:39:26, 54.22s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.23E+06, Train scatter: [0.4434 0.0771 0.5433 0.5168]
L1 regularization loss: 2.50E+00, L2 regularization loss: 6.81E-01
Test scatter: [0.4373 0.0765 0.5348 0.5094], Lowest was [0.2075 0.0663 0.5348 0.4957]
Median for last 10 epochs: [0.2248 0.072  0.5349 0.4989], Epochs since improvement 0
 12%|█▏        | 59/500 [51:24<6:07:56, 50.06s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.22E+06, Train scatter: [0.4838 0.0697 0.5433 0.5325]
L1 regularization loss: 2.51E+00, L2 regularization loss: 6.88E-01
Test scatter: [0.4752 0.0701 0.5348 0.5268], Lowest was [0.2075 0.0663 0.5348 0.4957]
Median for last 10 epochs: [0.2252 0.0701 0.5349 0.5   ], Epochs since improvement 2
 12%|█▏        | 60/500 [52:33<6:50:50, 56.02s/it] 12%|█▏        | 61/500 [53:14<6:15:31, 51.32s/it] 12%|█▏        | 62/500 [54:18<6:42:31, 55.14s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.21E+06, Train scatter: [0.2102 0.0637 0.5433 0.4952]
L1 regularization loss: 2.52E+00, L2 regularization loss: 7.00E-01
Test scatter: [0.2167 0.0639 0.5348 0.491 ], Lowest was [0.2075 0.0639 0.5348 0.491 ]
Median for last 10 epochs: [0.2252 0.0701 0.5348 0.5   ], Epochs since improvement 0
 13%|█▎        | 63/500 [54:58<6:09:28, 50.73s/it] 13%|█▎        | 64/500 [56:02<6:37:28, 54.70s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.19E+06, Train scatter: [0.2306 0.066  0.5433 0.5   ]
L1 regularization loss: 2.54E+00, L2 regularization loss: 7.08E-01
Test scatter: [0.2352 0.0657 0.5347 0.4944], Lowest was [0.2075 0.0639 0.5347 0.491 ]
Median for last 10 epochs: [0.2352 0.0701 0.5348 0.4979], Epochs since improvement 0
 13%|█▎        | 65/500 [56:43<6:05:28, 50.41s/it] 13%|█▎        | 66/500 [57:47<6:33:53, 54.45s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.19E+06, Train scatter: [0.2792 0.0647 0.5432 0.5023]
L1 regularization loss: 2.53E+00, L2 regularization loss: 7.16E-01
Test scatter: [0.2766 0.0642 0.5347 0.4948], Lowest was [0.2075 0.0639 0.5347 0.491 ]
Median for last 10 epochs: [0.2766 0.0657 0.5348 0.4948], Epochs since improvement 0
 13%|█▎        | 67/500 [58:27<6:02:39, 50.25s/it] 14%|█▎        | 68/500 [59:29<6:28:17, 53.93s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.25E+06, Train scatter: [0.4379 0.0626 0.5432 0.4956]
L1 regularization loss: 2.55E+00, L2 regularization loss: 7.31E-01
Test scatter: [0.4295 0.0627 0.5347 0.4915], Lowest was [0.2075 0.0627 0.5347 0.491 ]
Median for last 10 epochs: [0.2766 0.0642 0.5347 0.4944], Epochs since improvement 0
 14%|█▍        | 69/500 [1:00:10<5:58:38, 49.93s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.22E+06, Train scatter: [0.3631 0.0654 0.5433 0.5084]
L1 regularization loss: 2.57E+00, L2 regularization loss: 7.46E-01
Test scatter: [0.358  0.0657 0.5348 0.5071], Lowest was [0.2075 0.0627 0.5347 0.491 ]
Median for last 10 epochs: [0.2766 0.0642 0.5347 0.4944], Epochs since improvement 2
 14%|█▍        | 70/500 [1:01:20<6:40:41, 55.91s/it] 14%|█▍        | 71/500 [1:02:01<6:07:10, 51.35s/it] 14%|█▍        | 72/500 [1:03:03<6:29:24, 54.59s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.21E+06, Train scatter: [0.3667 0.0619 0.5432 0.4926]
L1 regularization loss: 2.58E+00, L2 regularization loss: 7.54E-01
Test scatter: [0.3574 0.0622 0.5347 0.4909], Lowest was [0.2075 0.0622 0.5347 0.4909]
Median for last 10 epochs: [0.3574 0.0642 0.5347 0.4944], Epochs since improvement 0
 15%|█▍        | 73/500 [1:03:43<5:58:27, 50.37s/it] 15%|█▍        | 74/500 [1:04:46<6:24:39, 54.18s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.19E+06, Train scatter: [0.2997 0.0689 0.5433 0.5343]
L1 regularization loss: 2.58E+00, L2 regularization loss: 7.65E-01
Test scatter: [0.3168 0.0701 0.5348 0.5425], Lowest was [0.2075 0.0622 0.5347 0.4909]
Median for last 10 epochs: [0.3574 0.0642 0.5347 0.4948], Epochs since improvement 2
 15%|█▌        | 75/500 [1:05:27<5:54:26, 50.04s/it] 15%|█▌        | 76/500 [1:06:30<6:21:54, 54.04s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.96E+06, Train scatter: [0.3274 0.0779 0.5435 0.5186]
L1 regularization loss: 2.63E+00, L2 regularization loss: 7.92E-01
Test scatter: [0.3239 0.0771 0.5349 0.51  ], Lowest was [0.2075 0.0622 0.5347 0.4909]
Median for last 10 epochs: [0.3574 0.0657 0.5348 0.5071], Epochs since improvement 4
 15%|█▌        | 77/500 [1:07:10<5:51:50, 49.91s/it] 16%|█▌        | 78/500 [1:08:14<6:19:33, 53.97s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.94E+06, Train scatter: [0.2261 0.0656 0.5435 0.5097]
L1 regularization loss: 2.64E+00, L2 regularization loss: 8.05E-01
Test scatter: [0.2307 0.0652 0.535  0.5062], Lowest was [0.2075 0.0622 0.5347 0.4909]
Median for last 10 epochs: [0.3239 0.0657 0.5348 0.5071], Epochs since improvement 6
 16%|█▌        | 79/500 [1:08:54<5:49:56, 49.87s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.94E+06, Train scatter: [0.2421 0.0645 0.5434 0.5078]
L1 regularization loss: 2.66E+00, L2 regularization loss: 8.23E-01
Test scatter: [0.2407 0.064  0.5349 0.5084], Lowest was [0.2075 0.0622 0.5347 0.4909]
Median for last 10 epochs: [0.3168 0.0652 0.5349 0.5084], Epochs since improvement 8
 16%|█▌        | 80/500 [1:10:06<6:35:09, 56.45s/it] 16%|█▌        | 81/500 [1:10:46<6:00:37, 51.64s/it] 16%|█▋        | 82/500 [1:11:51<6:26:17, 55.45s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.94E+06, Train scatter: [0.2293 0.0671 0.5435 0.5132]
L1 regularization loss: 2.67E+00, L2 regularization loss: 8.36E-01
Test scatter: [0.2332 0.0671 0.5349 0.5093], Lowest was [0.2075 0.0622 0.5347 0.4909]
Median for last 10 epochs: [0.2407 0.0671 0.5349 0.5093], Epochs since improvement 10
 17%|█▋        | 83/500 [1:12:31<5:54:13, 50.97s/it] 17%|█▋        | 84/500 [1:13:35<6:19:06, 54.68s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.90E+06, Train scatter: [0.3766 0.0648 0.5434 0.4958]
L1 regularization loss: 2.66E+00, L2 regularization loss: 8.46E-01
Test scatter: [0.3676 0.0645 0.5349 0.4911], Lowest was [0.2075 0.0622 0.5347 0.4909]
Median for last 10 epochs: [0.2407 0.0652 0.5349 0.5084], Epochs since improvement 12
 17%|█▋        | 85/500 [1:14:15<5:49:01, 50.46s/it] 17%|█▋        | 86/500 [1:15:18<6:13:52, 54.18s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.88E+06, Train scatter: [0.2498 0.0653 0.5435 0.4924]
L1 regularization loss: 2.66E+00, L2 regularization loss: 8.55E-01
Test scatter: [0.2541 0.0649 0.5349 0.4918], Lowest was [0.2075 0.0622 0.5347 0.4909]
Median for last 10 epochs: [0.2407 0.0649 0.5349 0.5062], Epochs since improvement 14
 17%|█▋        | 87/500 [1:15:58<5:44:29, 50.05s/it] 18%|█▊        | 88/500 [1:17:02<6:10:56, 54.02s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.89E+06, Train scatter: [0.1933 0.0599 0.5434 0.4821]
L1 regularization loss: 2.67E+00, L2 regularization loss: 8.68E-01
Test scatter: [0.2012 0.0597 0.5348 0.4806], Lowest was [0.2012 0.0597 0.5347 0.4806]
Median for last 10 epochs: [0.2407 0.0645 0.5349 0.4918], Epochs since improvement 0
 18%|█▊        | 89/500 [1:17:42<5:41:41, 49.88s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.88E+06, Train scatter: [0.2185 0.0624 0.5433 0.489 ]
L1 regularization loss: 2.70E+00, L2 regularization loss: 8.92E-01
Test scatter: [0.2256 0.0615 0.5348 0.4853], Lowest was [0.2012 0.0597 0.5347 0.4806]
Median for last 10 epochs: [0.2332 0.0645 0.5349 0.4911], Epochs since improvement 2
 18%|█▊        | 90/500 [1:18:53<6:24:00, 56.20s/it] 18%|█▊        | 91/500 [1:19:33<5:50:54, 51.48s/it] 18%|█▊        | 92/500 [1:20:37<6:13:52, 54.98s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.87E+06, Train scatter: [0.2064 0.0599 0.5432 0.4806]
L1 regularization loss: 2.71E+00, L2 regularization loss: 9.08E-01
Test scatter: [0.2279 0.0594 0.5347 0.4786], Lowest was [0.2012 0.0594 0.5347 0.4786]
Median for last 10 epochs: [0.2279 0.0615 0.5348 0.4853], Epochs since improvement 0
 19%|█▊        | 93/500 [1:21:17<5:43:17, 50.61s/it] 19%|█▉        | 94/500 [1:22:21<6:08:57, 54.53s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.88E+06, Train scatter: [0.2189 0.0704 0.5431 0.4884]
L1 regularization loss: 2.73E+00, L2 regularization loss: 9.27E-01
Test scatter: [0.2201 0.0708 0.5345 0.4858], Lowest was [0.2012 0.0594 0.5345 0.4786]
Median for last 10 epochs: [0.2256 0.0615 0.5348 0.4853], Epochs since improvement 0
 19%|█▉        | 95/500 [1:23:01<5:39:12, 50.25s/it] 19%|█▉        | 96/500 [1:24:05<6:06:11, 54.38s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.86E+06, Train scatter: [0.2607 0.0647 0.543  0.5022]
L1 regularization loss: 2.73E+00, L2 regularization loss: 9.42E-01
Test scatter: [0.268  0.0649 0.5344 0.5068], Lowest was [0.2012 0.0594 0.5344 0.4786]
Median for last 10 epochs: [0.2256 0.0615 0.5347 0.4853], Epochs since improvement 0
 19%|█▉        | 97/500 [1:24:46<5:37:28, 50.24s/it] 20%|█▉        | 98/500 [1:25:49<6:02:43, 54.14s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.85E+06, Train scatter: [0.2207 0.0601 0.5423 0.4908]
L1 regularization loss: 2.75E+00, L2 regularization loss: 9.64E-01
Test scatter: [0.224  0.061  0.5337 0.4896], Lowest was [0.2012 0.0594 0.5337 0.4786]
Median for last 10 epochs: [0.2256 0.0615 0.5345 0.4858], Epochs since improvement 0
 20%|█▉        | 99/500 [1:26:29<5:34:43, 50.08s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 2.89E+06, Train scatter: [0.2304 0.0588 0.5411 0.4742]
L1 regularization loss: 2.77E+00, L2 regularization loss: 9.87E-01
Test scatter: [0.2336 0.059  0.5325 0.4723], Lowest was [0.2012 0.059  0.5325 0.4723]
Median for last 10 epochs: [0.2279 0.061  0.5344 0.4858], Epochs since improvement 0
 20%|██        | 100/500 [1:27:38<6:11:48, 55.77s/it] 20%|██        | 101/500 [1:28:19<5:40:34, 51.21s/it] 20%|██        | 102/500 [1:29:22<6:03:48, 54.85s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 2.82E+06, Train scatter: [0.1968 0.0638 0.5389 0.489 ]
L1 regularization loss: 2.78E+00, L2 regularization loss: 1.01E+00
Test scatter: [0.2106 0.0652 0.5303 0.4886], Lowest was [0.2012 0.059  0.5303 0.4723]
Median for last 10 epochs: [0.224  0.0649 0.5337 0.4886], Epochs since improvement 0
 21%|██        | 103/500 [1:30:03<5:33:56, 50.47s/it] 21%|██        | 104/500 [1:31:06<5:59:12, 54.43s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 2.80E+06, Train scatter: [0.203  0.0607 0.5372 0.4916]
L1 regularization loss: 2.79E+00, L2 regularization loss: 1.03E+00
Test scatter: [0.2064 0.061  0.5287 0.4916], Lowest was [0.2012 0.059  0.5287 0.4723]
Median for last 10 epochs: [0.224  0.061  0.5325 0.4896], Epochs since improvement 0
 21%|██        | 105/500 [1:31:47<5:30:31, 50.21s/it] 21%|██        | 106/500 [1:32:51<5:58:09, 54.54s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 2.77E+06, Train scatter: [0.2593 0.0654 0.5354 0.4707]
L1 regularization loss: 2.81E+00, L2 regularization loss: 1.05E+00
Test scatter: [0.2596 0.0663 0.5269 0.4706], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.224  0.061  0.5303 0.4886], Epochs since improvement 0
 21%|██▏       | 107/500 [1:33:32<5:29:32, 50.31s/it] 22%|██▏       | 108/500 [1:34:35<5:53:31, 54.11s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 8.00E+06, Train scatter: [0.9333 0.1702 0.5441 0.9944]
L1 regularization loss: 4.46E+00, L2 regularization loss: 1.84E+00
Test scatter: [0.9179 0.1664 0.5355 0.9841], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.2336 0.0652 0.5303 0.4886], Epochs since improvement 2
 22%|██▏       | 109/500 [1:35:15<5:25:45, 49.99s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 7.25E+06, Train scatter: [0.9329 0.1645 0.5441 0.994 ]
L1 regularization loss: 4.46E+00, L2 regularization loss: 1.87E+00
Test scatter: [0.9174 0.1609 0.5355 0.9836], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.2596 0.0663 0.5303 0.4916], Epochs since improvement 4
 22%|██▏       | 110/500 [1:36:24<6:01:09, 55.56s/it] 22%|██▏       | 111/500 [1:37:04<5:30:48, 51.02s/it] 22%|██▏       | 112/500 [1:38:07<5:54:06, 54.76s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 6.75E+06, Train scatter: [0.9324 0.1612 0.5441 0.9939]
L1 regularization loss: 4.47E+00, L2 regularization loss: 1.89E+00
Test scatter: [0.9169 0.1583 0.5355 0.9836], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.9169 0.1583 0.5355 0.9836], Epochs since improvement 6
 23%|██▎       | 113/500 [1:38:48<5:25:50, 50.52s/it] 23%|██▎       | 114/500 [1:39:51<5:48:42, 54.20s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 6.30E+06, Train scatter: [0.9322 0.1618 0.5441 0.994 ]
L1 regularization loss: 4.47E+00, L2 regularization loss: 1.91E+00
Test scatter: [0.9167 0.159  0.5355 0.9836], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.9169 0.159  0.5355 0.9836], Epochs since improvement 8
 23%|██▎       | 115/500 [1:40:31<5:21:20, 50.08s/it] 23%|██▎       | 116/500 [1:41:35<5:47:27, 54.29s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 5.72E+06, Train scatter: [0.934  0.1601 0.5441 0.9938]
L1 regularization loss: 4.49E+00, L2 regularization loss: 1.96E+00
Test scatter: [0.9184 0.1577 0.5355 0.9834], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.9174 0.159  0.5355 0.9836], Epochs since improvement 10
 23%|██▎       | 117/500 [1:42:16<5:19:36, 50.07s/it] 24%|██▎       | 118/500 [1:43:19<5:43:38, 53.98s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 5.15E+06, Train scatter: [0.9318 0.1473 0.5441 0.9933]
L1 regularization loss: 4.50E+00, L2 regularization loss: 1.98E+00
Test scatter: [0.9162 0.1457 0.5355 0.9829], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.9169 0.1583 0.5355 0.9836], Epochs since improvement 12
 24%|██▍       | 119/500 [1:43:59<5:16:44, 49.88s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 4.71E+06, Train scatter: [0.9292 0.1311 0.5441 0.9936]
L1 regularization loss: 4.51E+00, L2 regularization loss: 2.01E+00
Test scatter: [0.9138 0.13   0.5355 0.9832], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.9167 0.1577 0.5355 0.9834], Epochs since improvement 14
 24%|██▍       | 120/500 [1:45:09<5:54:10, 55.92s/it] 24%|██▍       | 121/500 [1:45:50<5:23:51, 51.27s/it] 24%|██▍       | 122/500 [1:46:54<5:48:36, 55.34s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 4.50E+06, Train scatter: [0.9213 0.1243 0.5441 0.9929]
L1 regularization loss: 4.53E+00, L2 regularization loss: 2.07E+00
Test scatter: [0.906  0.1233 0.5355 0.9825], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.9162 0.1457 0.5355 0.9832], Epochs since improvement 16
 25%|██▍       | 123/500 [1:47:35<5:19:07, 50.79s/it] 25%|██▍       | 124/500 [1:48:39<5:43:06, 54.75s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 4.37E+06, Train scatter: [0.8967 0.1183 0.5441 0.9925]
L1 regularization loss: 4.56E+00, L2 regularization loss: 2.18E+00
Test scatter: [0.882  0.1172 0.5355 0.9822], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.9138 0.13   0.5355 0.9829], Epochs since improvement 18
 25%|██▌       | 125/500 [1:49:19<5:15:37, 50.50s/it] 25%|██▌       | 126/500 [1:50:22<5:38:31, 54.31s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 4.25E+06, Train scatter: [0.6948 0.1137 0.5441 0.9923]
L1 regularization loss: 4.61E+00, L2 regularization loss: 2.31E+00
Test scatter: [0.6832 0.1128 0.5355 0.982 ], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.906  0.1233 0.5355 0.9825], Epochs since improvement 20
 25%|██▌       | 127/500 [1:51:03<5:12:08, 50.21s/it] 25%|██▌       | 127/500 [1:52:07<5:29:17, 52.97s/it]
Epoch: 128 done with learning rate 9.62E-03, Train loss: 4.19E+06, Train scatter: [0.8696 0.1115 0.5439 0.9919]
L1 regularization loss: 4.64E+00, L2 regularization loss: 2.39E+00
Test scatter: [0.8562 0.1106 0.5354 0.9816], Lowest was [0.2012 0.059  0.5269 0.4706]
Median for last 10 epochs: [0.882  0.1172 0.5355 0.9822], Epochs since improvement 22
Exited after 128 epochs due to early stopping
6727.19 seconds spent training, 13.454 seconds per epoch. Processed 5176 trees per second
[0.8562196  0.11058971 0.5353532  0.9815491 ]
{'epoch_exit': 127, 'scatter_m_star': 0.8562196, 'lowest_m_star': 0.20121494, 'last20_m_star': 0.9150003, 'last10_m_star': 0.8820491, 'scatter_v_disk': 0.110589705, 'lowest_v_disk': 0.05900944, 'last20_v_disk': 0.13784057, 'last10_v_disk': 0.11716948, 'scatter_m_cold': 0.5353532, 'lowest_m_cold': 0.52692634, 'last20_m_cold': 0.5354835, 'last10_m_cold': 0.5354764, 'scatter_sfr_100': 0.9815491, 'lowest_sfr_100': 0.47061542, 'last20_sfr_100': 0.983063, 'last10_sfr_100': 0.98219985}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_bhqcto
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:00<8:23:25, 60.53s/it]  0%|          | 2/500 [02:29<10:41:32, 77.29s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.10E+07, Train scatter: [0.9351 0.1365 0.5441 0.9955]
L1 regularization loss: 2.45E+00, L2 regularization loss: 4.24E-01
Test scatter: [0.9195 0.1321 0.5355 0.9852], Lowest was [0.9195 0.1321 0.5355 0.9852]
Median for last 10 epochs: [0.9195 0.1321 0.5355 0.9852], Epochs since improvement 2
  1%|          | 3/500 [03:30<9:38:37, 69.85s/it]   1%|          | 4/500 [05:00<10:42:25, 77.71s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.03E+07, Train scatter: [0.9331 0.1045 0.5439 0.9955]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.29E-01
Test scatter: [0.9174 0.1028 0.5353 0.9852], Lowest was [0.9174 0.1028 0.5353 0.9852]
Median for last 10 epochs: [0.9174 0.1028 0.5353 0.9852], Epochs since improvement 0
  1%|          | 5/500 [06:01<9:53:05, 71.89s/it]   1%|          | 6/500 [07:31<10:41:42, 77.94s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.03E+08, Train scatter: [0.9351 0.1652 0.544  0.9954]
L1 regularization loss: 2.50E+00, L2 regularization loss: 4.43E-01
Test scatter: [0.9196 0.1588 0.5354 0.9851], Lowest was [0.9174 0.1028 0.5353 0.9851]
Median for last 10 epochs: [0.9174 0.1028 0.5353 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [08:32<9:55:34, 72.48s/it]   2%|▏         | 8/500 [10:04<10:43:27, 78.47s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.19E+07, Train scatter: [0.9225 0.136  0.5416 0.9954]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.61E-01
Test scatter: [0.9078 0.1334 0.5332 0.985 ], Lowest was [0.9078 0.1028 0.5332 0.985 ]
Median for last 10 epochs: [0.9126 0.1181 0.5343 0.985 ], Epochs since improvement 0
  2%|▏         | 9/500 [11:05<9:57:56, 73.07s/it] Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.65E+07, Train scatter: [0.5741 0.108  0.4672 0.9954]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.84E-01
Test scatter: [0.5601 0.1076 0.4599 0.9851], Lowest was [0.5601 0.1028 0.4599 0.985 ]
Median for last 10 epochs: [0.9078 0.1076 0.5332 0.9851], Epochs since improvement 0
  2%|▏         | 10/500 [12:43<10:59:16, 80.73s/it]  2%|▏         | 11/500 [13:44<10:09:55, 74.84s/it]  2%|▏         | 12/500 [15:14<10:45:52, 79.41s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.38E+07, Train scatter: [0.4467 0.0979 0.4346 0.9954]
L1 regularization loss: 2.56E+00, L2 regularization loss: 4.93E-01
Test scatter: [0.4454 0.0987 0.43   0.9851], Lowest was [0.4454 0.0987 0.43   0.985 ]
Median for last 10 epochs: [0.9078 0.1076 0.5332 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [16:16<10:00:35, 74.00s/it]  3%|▎         | 14/500 [17:44<10:35:47, 78.49s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.04E+07, Train scatter: [0.3687 0.0889 0.3955 0.9953]
L1 regularization loss: 2.57E+00, L2 regularization loss: 5.00E-01
Test scatter: [0.3811 0.0904 0.3941 0.9849], Lowest was [0.3811 0.0904 0.3941 0.9849]
Median for last 10 epochs: [0.5601 0.1076 0.4599 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [18:46<9:52:19, 73.28s/it]   3%|▎         | 16/500 [20:16<10:33:06, 78.48s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.31E+07, Train scatter: [0.3998 0.0846 0.3883 0.9954]
L1 regularization loss: 2.58E+00, L2 regularization loss: 5.07E-01
Test scatter: [0.4079 0.085  0.3857 0.985 ], Lowest was [0.3811 0.085  0.3857 0.9849]
Median for last 10 epochs: [0.4454 0.0987 0.43   0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [21:17<9:50:03, 73.30s/it]   4%|▎         | 18/500 [22:48<10:30:01, 78.43s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.62E+07, Train scatter: [0.3392 0.0806 0.3638 0.9908]
L1 regularization loss: 2.59E+00, L2 regularization loss: 5.13E-01
Test scatter: [0.3516 0.0812 0.3641 0.9807], Lowest was [0.3516 0.0812 0.3641 0.9807]
Median for last 10 epochs: [0.4079 0.0904 0.3941 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [23:49<9:47:20, 73.26s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 6.79E+06, Train scatter: [0.4783 0.0797 0.3667 0.762 ]
L1 regularization loss: 2.60E+00, L2 regularization loss: 5.24E-01
Test scatter: [0.4845 0.0792 0.3706 0.7653], Lowest was [0.3516 0.0792 0.3641 0.7653]
Median for last 10 epochs: [0.4079 0.085  0.3857 0.9849], Epochs since improvement 0
  4%|▍         | 20/500 [25:26<10:42:38, 80.33s/it]  4%|▍         | 21/500 [26:28<9:56:50, 74.76s/it]   4%|▍         | 22/500 [27:58<10:32:32, 79.40s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.44E+06, Train scatter: [0.2712 0.0759 0.343  0.5713]
L1 regularization loss: 2.62E+00, L2 regularization loss: 5.33E-01
Test scatter: [0.2818 0.0763 0.3443 0.5677], Lowest was [0.2818 0.0763 0.3443 0.5677]
Median for last 10 epochs: [0.3811 0.0812 0.3706 0.9807], Epochs since improvement 0
  5%|▍         | 23/500 [28:59<9:48:10, 73.98s/it]   5%|▍         | 24/500 [30:29<10:24:31, 78.72s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.71E+06, Train scatter: [0.2767 0.0716 0.3293 0.5153]
L1 regularization loss: 2.63E+00, L2 regularization loss: 5.44E-01
Test scatter: [0.2839 0.0724 0.3321 0.516 ], Lowest was [0.2818 0.0724 0.3321 0.516 ]
Median for last 10 epochs: [0.3516 0.0792 0.3641 0.7653], Epochs since improvement 0
  5%|▌         | 25/500 [31:30<9:41:32, 73.46s/it]   5%|▌         | 26/500 [33:00<10:19:41, 78.44s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.27E+06, Train scatter: [0.3443 0.071  0.3259 0.5638]
L1 regularization loss: 2.66E+00, L2 regularization loss: 5.56E-01
Test scatter: [0.3517 0.0714 0.3298 0.5576], Lowest was [0.2818 0.0714 0.3298 0.516 ]
Median for last 10 epochs: [0.3516 0.0763 0.3443 0.5677], Epochs since improvement 0
  5%|▌         | 27/500 [34:02<9:38:08, 73.34s/it]   6%|▌         | 28/500 [35:32<10:17:54, 78.55s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.03E+06, Train scatter: [0.2557 0.0691 0.3176 0.4887]
L1 regularization loss: 2.68E+00, L2 regularization loss: 5.68E-01
Test scatter: [0.2662 0.0699 0.3242 0.4859], Lowest was [0.2662 0.0699 0.3242 0.4859]
Median for last 10 epochs: [0.2839 0.0724 0.3321 0.5576], Epochs since improvement 0
  6%|▌         | 29/500 [36:34<9:36:55, 73.49s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.15E+06, Train scatter: [0.2397 0.0695 0.3115 0.4881]
L1 regularization loss: 2.70E+00, L2 regularization loss: 5.81E-01
Test scatter: [0.2512 0.0705 0.3216 0.4884], Lowest was [0.2512 0.0699 0.3216 0.4859]
Median for last 10 epochs: [0.2818 0.0714 0.3298 0.516 ], Epochs since improvement 0
  6%|▌         | 30/500 [38:12<10:32:10, 80.70s/it]  6%|▌         | 31/500 [39:13<9:45:21, 74.89s/it]   6%|▋         | 32/500 [40:43<10:19:47, 79.46s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.81E+06, Train scatter: [0.2504 0.0704 0.3256 0.501 ]
L1 regularization loss: 2.72E+00, L2 regularization loss: 5.93E-01
Test scatter: [0.2609 0.0698 0.325  0.4987], Lowest was [0.2512 0.0698 0.3216 0.4859]
Median for last 10 epochs: [0.2662 0.0705 0.325  0.4987], Epochs since improvement 0
  7%|▋         | 33/500 [41:44<9:35:41, 73.96s/it]   7%|▋         | 34/500 [43:14<10:11:57, 78.79s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.79E+06, Train scatter: [0.4035 0.0702 0.3437 0.5924]
L1 regularization loss: 2.75E+00, L2 regularization loss: 6.08E-01
Test scatter: [0.4038 0.071  0.3441 0.591 ], Lowest was [0.2512 0.0698 0.3216 0.4859]
Median for last 10 epochs: [0.2662 0.0705 0.325  0.4987], Epochs since improvement 2
  7%|▋         | 35/500 [44:16<9:30:01, 73.55s/it]   7%|▋         | 36/500 [45:45<10:06:31, 78.43s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.05E+06, Train scatter: [0.3158 0.0715 0.3387 0.5026]
L1 regularization loss: 2.78E+00, L2 regularization loss: 6.28E-01
Test scatter: [0.3236 0.0719 0.3402 0.5042], Lowest was [0.2512 0.0698 0.3216 0.4859]
Median for last 10 epochs: [0.2662 0.0705 0.325  0.4987], Epochs since improvement 4
  7%|▋         | 37/500 [46:47<9:26:08, 73.37s/it]   8%|▊         | 38/500 [48:17<10:03:51, 78.42s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.54E+06, Train scatter: [0.2837 0.0651 0.2864 0.478 ]
L1 regularization loss: 2.80E+00, L2 regularization loss: 6.43E-01
Test scatter: [0.2897 0.0657 0.2939 0.4785], Lowest was [0.2512 0.0657 0.2939 0.4785]
Median for last 10 epochs: [0.2897 0.0705 0.325  0.4987], Epochs since improvement 0
  8%|▊         | 39/500 [49:19<9:23:37, 73.36s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.44E+06, Train scatter: [0.2528 0.0618 0.3065 0.4932]
L1 regularization loss: 2.84E+00, L2 regularization loss: 6.65E-01
Test scatter: [0.2641 0.0631 0.3151 0.4973], Lowest was [0.2512 0.0631 0.2939 0.4785]
Median for last 10 epochs: [0.2897 0.0698 0.325  0.4987], Epochs since improvement 0
  8%|▊         | 40/500 [50:56<10:18:06, 80.62s/it]  8%|▊         | 41/500 [51:57<9:32:15, 74.80s/it]   8%|▊         | 42/500 [53:27<10:05:12, 79.29s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.46E+06, Train scatter: [0.2679 0.0594 0.2978 0.461 ]
L1 regularization loss: 2.88E+00, L2 regularization loss: 6.89E-01
Test scatter: [0.2778 0.0611 0.3065 0.4624], Lowest was [0.2512 0.0611 0.2939 0.4624]
Median for last 10 epochs: [0.2897 0.0657 0.3151 0.4973], Epochs since improvement 0
  9%|▊         | 43/500 [54:28<9:22:38, 73.87s/it]   9%|▉         | 44/500 [55:58<9:56:28, 78.48s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.27E+06, Train scatter: [0.3056 0.0698 0.3136 0.4971]
L1 regularization loss: 2.92E+00, L2 regularization loss: 7.16E-01
Test scatter: [0.3076 0.0708 0.3221 0.5052], Lowest was [0.2512 0.0611 0.2939 0.4624]
Median for last 10 epochs: [0.2897 0.0657 0.3151 0.4973], Epochs since improvement 2
  9%|▉         | 45/500 [56:59<9:16:35, 73.40s/it]  9%|▉         | 46/500 [58:29<9:53:27, 78.43s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.38E+06, Train scatter: [0.3296 0.0674 0.2867 0.4729]
L1 regularization loss: 2.96E+00, L2 regularization loss: 7.51E-01
Test scatter: [0.3335 0.0675 0.289  0.468 ], Lowest was [0.2512 0.0611 0.289  0.4624]
Median for last 10 epochs: [0.2897 0.0657 0.3065 0.4785], Epochs since improvement 0
  9%|▉         | 47/500 [59:31<9:13:18, 73.29s/it] 10%|▉         | 48/500 [1:01:00<9:49:26, 78.24s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.05E+06, Train scatter: [0.2383 0.063  0.2757 0.4683]
L1 regularization loss: 3.01E+00, L2 regularization loss: 7.84E-01
Test scatter: [0.2609 0.0626 0.2802 0.4657], Lowest was [0.2512 0.0611 0.2802 0.4624]
Median for last 10 epochs: [0.2778 0.0631 0.3065 0.468 ], Epochs since improvement 0
 10%|▉         | 49/500 [1:02:02<9:09:31, 73.11s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.99E+06, Train scatter: [0.226  0.06   0.2841 0.4639]
L1 regularization loss: 3.08E+00, L2 regularization loss: 8.27E-01
Test scatter: [0.2404 0.0598 0.2856 0.4589], Lowest was [0.2404 0.0598 0.2802 0.4589]
Median for last 10 epochs: [0.2778 0.0626 0.289  0.4657], Epochs since improvement 0
 10%|█         | 50/500 [1:03:40<10:05:19, 80.71s/it] 10%|█         | 51/500 [1:04:42<9:20:52, 74.95s/it]  10%|█         | 52/500 [1:06:12<9:53:12, 79.45s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.72E+06, Train scatter: [0.2134 0.0559 0.2705 0.4535]
L1 regularization loss: 3.11E+00, L2 regularization loss: 8.61E-01
Test scatter: [0.2585 0.0569 0.2756 0.448 ], Lowest was [0.2404 0.0569 0.2756 0.448 ]
Median for last 10 epochs: [0.2609 0.0626 0.2856 0.4657], Epochs since improvement 0
 11%|█         | 53/500 [1:07:13<9:11:54, 74.08s/it] 11%|█         | 54/500 [1:08:43<9:45:07, 78.72s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.67E+06, Train scatter: [0.2055 0.0595 0.2913 0.4675]
L1 regularization loss: 3.15E+00, L2 regularization loss: 8.94E-01
Test scatter: [0.2148 0.0595 0.293  0.4658], Lowest was [0.2148 0.0569 0.2756 0.448 ]
Median for last 10 epochs: [0.2585 0.0598 0.2856 0.4657], Epochs since improvement 0
 11%|█         | 55/500 [1:09:44<9:05:16, 73.52s/it] 11%|█         | 56/500 [1:11:15<9:42:49, 78.76s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.56E+06, Train scatter: [0.209  0.0578 0.2812 0.4483]
L1 regularization loss: 3.19E+00, L2 regularization loss: 9.28E-01
Test scatter: [0.2216 0.0584 0.2865 0.4505], Lowest was [0.2148 0.0569 0.2756 0.448 ]
Median for last 10 epochs: [0.2404 0.0595 0.2856 0.4589], Epochs since improvement 2
 11%|█▏        | 57/500 [1:12:16<9:02:34, 73.49s/it] 12%|█▏        | 58/500 [1:13:46<9:37:14, 78.36s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.51E+06, Train scatter: [0.1961 0.0578 0.2723 0.4416]
L1 regularization loss: 3.23E+00, L2 regularization loss: 9.66E-01
Test scatter: [0.2077 0.0584 0.2769 0.4423], Lowest was [0.2077 0.0569 0.2756 0.4423]
Median for last 10 epochs: [0.2216 0.0584 0.2856 0.4505], Epochs since improvement 0
 12%|█▏        | 59/500 [1:14:47<8:58:23, 73.25s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.45E+06, Train scatter: [0.2458 0.0611 0.2944 0.4743]
L1 regularization loss: 3.28E+00, L2 regularization loss: 1.01E+00
Test scatter: [0.2643 0.0623 0.3012 0.4794], Lowest was [0.2077 0.0569 0.2756 0.4423]
Median for last 10 epochs: [0.2216 0.0584 0.2865 0.4505], Epochs since improvement 2
 12%|█▏        | 60/500 [1:16:25<9:50:20, 80.50s/it] 12%|█▏        | 61/500 [1:17:26<9:07:32, 74.84s/it] 12%|█▏        | 62/500 [1:18:56<9:39:14, 79.35s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.37E+06, Train scatter: [0.4139 0.0722 0.366  0.5094]
L1 regularization loss: 3.65E+00, L2 regularization loss: 1.23E+00
Test scatter: [0.4204 0.0734 0.3718 0.5163], Lowest was [0.2077 0.0569 0.2756 0.4423]
Median for last 10 epochs: [0.2216 0.0595 0.293  0.4658], Epochs since improvement 4
 13%|█▎        | 63/500 [1:19:58<8:58:41, 73.96s/it] 13%|█▎        | 64/500 [1:21:29<9:34:38, 79.08s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.66E+06, Train scatter: [0.289  0.0742 0.3243 0.493 ]
L1 regularization loss: 3.71E+00, L2 regularization loss: 1.34E+00
Test scatter: [0.3028 0.0749 0.3283 0.4941], Lowest was [0.2077 0.0569 0.2756 0.4423]
Median for last 10 epochs: [0.2643 0.0623 0.3012 0.4794], Epochs since improvement 6
 13%|█▎        | 65/500 [1:22:30<8:54:09, 73.68s/it] 13%|█▎        | 66/500 [1:24:00<9:29:44, 78.77s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.46E+06, Train scatter: [0.221  0.0572 0.3037 0.4445]
L1 regularization loss: 3.74E+00, L2 regularization loss: 1.39E+00
Test scatter: [0.2423 0.0581 0.3126 0.4428], Lowest was [0.2077 0.0569 0.2756 0.4423]
Median for last 10 epochs: [0.2643 0.0623 0.3126 0.4794], Epochs since improvement 8
 13%|█▎        | 67/500 [1:25:01<8:50:24, 73.50s/it] 14%|█▎        | 68/500 [1:26:31<9:23:19, 78.24s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.24E+06, Train scatter: [0.2505 0.0548 0.2977 0.4468]
L1 regularization loss: 3.78E+00, L2 regularization loss: 1.45E+00
Test scatter: [0.2479 0.0551 0.3013 0.4452], Lowest was [0.2077 0.0551 0.2756 0.4423]
Median for last 10 epochs: [0.2643 0.0623 0.3126 0.4794], Epochs since improvement 0
 14%|█▍        | 69/500 [1:27:32<8:46:07, 73.24s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.12E+06, Train scatter: [0.3297 0.0606 0.3023 0.4418]
L1 regularization loss: 3.83E+00, L2 regularization loss: 1.52E+00
Test scatter: [0.3567 0.0606 0.3031 0.4366], Lowest was [0.2077 0.0551 0.2756 0.4366]
Median for last 10 epochs: [0.3028 0.0606 0.3126 0.4452], Epochs since improvement 0
 14%|█▍        | 70/500 [1:29:11<9:38:26, 80.71s/it] 14%|█▍        | 71/500 [1:30:12<8:55:37, 74.91s/it] 14%|█▍        | 72/500 [1:31:42<9:27:19, 79.53s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.05E+06, Train scatter: [0.2223 0.0569 0.2882 0.4304]
L1 regularization loss: 3.87E+00, L2 regularization loss: 1.59E+00
Test scatter: [0.2217 0.0572 0.2945 0.4316], Lowest was [0.2077 0.0551 0.2756 0.4316]
Median for last 10 epochs: [0.2479 0.0581 0.3031 0.4428], Epochs since improvement 0
 15%|█▍        | 73/500 [1:32:43<8:46:44, 74.01s/it] 15%|█▍        | 74/500 [1:34:14<9:20:35, 78.96s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 9.59E+05, Train scatter: [0.215  0.0649 0.292  0.4424]
L1 regularization loss: 3.93E+00, L2 regularization loss: 1.66E+00
Test scatter: [0.2898 0.0645 0.2988 0.4355], Lowest was [0.2077 0.0551 0.2756 0.4316]
Median for last 10 epochs: [0.2479 0.0581 0.3013 0.4366], Epochs since improvement 2
 15%|█▌        | 75/500 [1:35:15<8:41:44, 73.66s/it] 15%|█▌        | 76/500 [1:36:45<9:14:52, 78.52s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 8.83E+05, Train scatter: [0.2432 0.0515 0.2681 0.4204]
L1 regularization loss: 3.98E+00, L2 regularization loss: 1.75E+00
Test scatter: [0.3467 0.0514 0.2745 0.4198], Lowest was [0.2077 0.0514 0.2745 0.4198]
Median for last 10 epochs: [0.2898 0.0572 0.2988 0.4355], Epochs since improvement 0
 15%|█▌        | 77/500 [1:37:47<8:37:37, 73.42s/it] 16%|█▌        | 78/500 [1:39:17<9:12:47, 78.60s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 8.58E+05, Train scatter: [0.1759 0.0532 0.2752 0.4217]
L1 regularization loss: 4.03E+00, L2 regularization loss: 1.82E+00
Test scatter: [0.2832 0.0537 0.2795 0.4206], Lowest was [0.2077 0.0514 0.2745 0.4198]
Median for last 10 epochs: [0.2898 0.0572 0.2945 0.4316], Epochs since improvement 2
 16%|█▌        | 79/500 [1:40:19<8:35:27, 73.46s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 7.13E+05, Train scatter: [0.1778 0.0489 0.2655 0.4172]
L1 regularization loss: 4.06E+00, L2 regularization loss: 1.89E+00
Test scatter: [0.3069 0.0493 0.2709 0.4169], Lowest was [0.2077 0.0493 0.2709 0.4169]
Median for last 10 epochs: [0.2898 0.0537 0.2795 0.4206], Epochs since improvement 0
 16%|█▌        | 80/500 [1:41:57<9:26:16, 80.90s/it] 16%|█▌        | 81/500 [1:42:58<8:43:41, 74.99s/it] 16%|█▋        | 82/500 [1:44:28<9:14:35, 79.61s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 6.10E+05, Train scatter: [0.167  0.0469 0.2755 0.4179]
L1 regularization loss: 4.11E+00, L2 regularization loss: 1.98E+00
Test scatter: [0.2306 0.0471 0.28   0.4157], Lowest was [0.2077 0.0471 0.2709 0.4157]
Median for last 10 epochs: [0.2898 0.0514 0.2795 0.4198], Epochs since improvement 0
 17%|█▋        | 83/500 [1:45:30<8:35:03, 74.11s/it] 17%|█▋        | 84/500 [1:47:00<9:08:03, 79.05s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 5.11E+05, Train scatter: [0.2112 0.0573 0.2626 0.4148]
L1 regularization loss: 4.21E+00, L2 regularization loss: 2.08E+00
Test scatter: [0.2916 0.057  0.2647 0.4121], Lowest was [0.2077 0.0471 0.2647 0.4121]
Median for last 10 epochs: [0.2916 0.0514 0.2745 0.4169], Epochs since improvement 0
 17%|█▋        | 85/500 [1:48:02<8:30:30, 73.81s/it] 17%|█▋        | 86/500 [1:49:32<9:02:33, 78.63s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 3.64E+05, Train scatter: [0.1716 0.0519 0.2495 0.4067]
L1 regularization loss: 4.25E+00, L2 regularization loss: 2.17E+00
Test scatter: [0.1935 0.0514 0.2518 0.4013], Lowest was [0.1935 0.0471 0.2518 0.4013]
Median for last 10 epochs: [0.2832 0.0514 0.2709 0.4157], Epochs since improvement 0
 17%|█▋        | 87/500 [1:50:33<8:25:32, 73.44s/it] 18%|█▊        | 88/500 [1:52:03<8:57:17, 78.25s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.28E+05, Train scatter: [0.2207 0.0483 0.2426 0.4129]
L1 regularization loss: 4.33E+00, L2 regularization loss: 2.27E+00
Test scatter: [0.2282 0.0482 0.2472 0.4124], Lowest was [0.1935 0.0471 0.2472 0.4013]
Median for last 10 epochs: [0.2306 0.0493 0.2647 0.4124], Epochs since improvement 0
 18%|█▊        | 89/500 [1:53:04<8:21:07, 73.16s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 8.00E+04, Train scatter: [0.2342 0.0475 0.2507 0.4089]
L1 regularization loss: 4.36E+00, L2 regularization loss: 2.33E+00
Test scatter: [0.235  0.0474 0.2502 0.4018], Lowest was [0.1935 0.0471 0.2472 0.4013]
Median for last 10 epochs: [0.2306 0.0482 0.2518 0.4121], Epochs since improvement 2
 18%|█▊        | 90/500 [1:54:41<9:09:37, 80.43s/it] 18%|█▊        | 91/500 [1:55:43<8:29:05, 74.68s/it] 18%|█▊        | 92/500 [1:57:13<8:59:24, 79.32s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: -6.33E+04, Train scatter: [0.165  0.046  0.2459 0.4032]
L1 regularization loss: 4.42E+00, L2 regularization loss: 2.40E+00
Test scatter: [0.171  0.0456 0.2495 0.4014], Lowest was [0.171  0.0456 0.2472 0.4013]
Median for last 10 epochs: [0.2282 0.0482 0.2502 0.4018], Epochs since improvement 0
 19%|█▊        | 93/500 [1:58:14<8:21:49, 73.98s/it] 19%|█▉        | 94/500 [1:59:44<8:52:18, 78.67s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: -1.71E+05, Train scatter: [0.3326 0.0434 0.2284 0.3912]
L1 regularization loss: 4.45E+00, L2 regularization loss: 2.47E+00
Test scatter: [0.3294 0.0436 0.2324 0.3878], Lowest was [0.171  0.0436 0.2324 0.3878]
Median for last 10 epochs: [0.2282 0.0474 0.2495 0.4014], Epochs since improvement 0
 19%|█▉        | 95/500 [2:00:45<8:15:45, 73.45s/it] 19%|█▉        | 96/500 [2:02:15<8:48:27, 78.48s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: -2.61E+05, Train scatter: [0.3543 0.048  0.2513 0.4023]
L1 regularization loss: 4.46E+00, L2 regularization loss: 2.52E+00
Test scatter: [0.3509 0.0477 0.2544 0.4029], Lowest was [0.171  0.0436 0.2324 0.3878]
Median for last 10 epochs: [0.235  0.0474 0.2495 0.4018], Epochs since improvement 2
 19%|█▉        | 97/500 [2:03:17<8:12:20, 73.30s/it] 20%|█▉        | 98/500 [2:04:46<8:44:14, 78.25s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: -3.15E+05, Train scatter: [0.1634 0.0452 0.2462 0.3985]
L1 regularization loss: 4.62E+00, L2 regularization loss: 2.63E+00
Test scatter: [0.1721 0.0452 0.2498 0.3951], Lowest was [0.171  0.0436 0.2324 0.3878]
Median for last 10 epochs: [0.235  0.0456 0.2498 0.4014], Epochs since improvement 4
 20%|█▉        | 99/500 [2:05:48<8:09:09, 73.19s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: -3.36E+05, Train scatter: [0.1317 0.0421 0.2182 0.3849]
L1 regularization loss: 4.66E+00, L2 regularization loss: 2.73E+00
Test scatter: [0.1361 0.042  0.2215 0.3813], Lowest was [0.1361 0.042  0.2215 0.3813]
Median for last 10 epochs: [0.1721 0.0452 0.2495 0.3951], Epochs since improvement 0
 20%|██        | 100/500 [2:07:25<8:56:09, 80.42s/it] 20%|██        | 101/500 [2:08:27<8:17:41, 74.84s/it] 20%|██        | 102/500 [2:09:57<8:46:05, 79.31s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: -3.56E+05, Train scatter: [0.1463 0.0423 0.2156 0.3862]
L1 regularization loss: 4.72E+00, L2 regularization loss: 2.82E+00
Test scatter: [0.1479 0.042  0.2192 0.3824], Lowest was [0.1361 0.042  0.2192 0.3813]
Median for last 10 epochs: [0.1721 0.0436 0.2324 0.3878], Epochs since improvement 0
 21%|██        | 103/500 [2:10:58<8:09:24, 73.97s/it] 21%|██        | 104/500 [2:12:29<8:41:04, 78.95s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: -3.78E+05, Train scatter: [0.1908 0.0513 0.2334 0.4035]
L1 regularization loss: 4.73E+00, L2 regularization loss: 2.88E+00
Test scatter: [0.1923 0.0509 0.2375 0.4008], Lowest was [0.1361 0.042  0.2192 0.3813]
Median for last 10 epochs: [0.1721 0.0452 0.2375 0.3951], Epochs since improvement 2
 21%|██        | 105/500 [2:13:30<8:05:06, 73.69s/it] 21%|██        | 106/500 [2:15:00<8:35:51, 78.56s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: -3.94E+05, Train scatter: [0.1317 0.0427 0.2281 0.3948]
L1 regularization loss: 4.74E+00, L2 regularization loss: 2.95E+00
Test scatter: [0.1345 0.0423 0.2312 0.3888], Lowest was [0.1345 0.042  0.2192 0.3813]
Median for last 10 epochs: [0.1479 0.0423 0.2312 0.3888], Epochs since improvement 0
 21%|██▏       | 107/500 [2:16:01<8:00:52, 73.42s/it] 22%|██▏       | 108/500 [2:17:31<8:31:37, 78.31s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: -3.93E+05, Train scatter: [0.16   0.0443 0.2126 0.3981]
L1 regularization loss: 4.73E+00, L2 regularization loss: 3.01E+00
Test scatter: [0.1592 0.0443 0.2169 0.395 ], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.1479 0.0423 0.2215 0.3888], Epochs since improvement 0
 22%|██▏       | 109/500 [2:18:32<7:57:08, 73.22s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 3.63E+04, Train scatter: [0.8964 0.1413 0.5434 0.9764]
L1 regularization loss: 5.88E+00, L2 regularization loss: 3.61E+00
Test scatter: [0.8817 0.1386 0.5348 0.9664], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.1592 0.0443 0.2312 0.395 ], Epochs since improvement 2
 22%|██▏       | 110/500 [2:20:10<8:42:52, 80.44s/it] 22%|██▏       | 111/500 [2:21:11<8:04:23, 74.71s/it] 22%|██▏       | 112/500 [2:22:42<8:33:48, 79.46s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: -1.21E+05, Train scatter: [0.5916 0.1136 0.5292 0.7438]
L1 regularization loss: 5.99E+00, L2 regularization loss: 3.95E+00
Test scatter: [0.5837 0.1122 0.5201 0.7355], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.1923 0.0509 0.2375 0.4008], Epochs since improvement 4
 23%|██▎       | 113/500 [2:23:43<7:57:16, 74.00s/it] 23%|██▎       | 114/500 [2:25:13<8:27:48, 78.93s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: -1.62E+05, Train scatter: [0.609  0.1002 0.5118 0.6192]
L1 regularization loss: 5.96E+00, L2 regularization loss: 4.07E+00
Test scatter: [0.5943 0.0976 0.5037 0.6098], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.5837 0.0976 0.5037 0.6098], Epochs since improvement 6
 23%|██▎       | 115/500 [2:26:15<7:52:44, 73.67s/it] 23%|██▎       | 116/500 [2:27:45<8:22:37, 78.54s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: -1.77E+05, Train scatter: [0.4278 0.0938 0.4904 0.5929]
L1 regularization loss: 5.88E+00, L2 regularization loss: 4.22E+00
Test scatter: [0.4228 0.0925 0.483  0.5861], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.5837 0.0976 0.5037 0.6098], Epochs since improvement 8
 23%|██▎       | 117/500 [2:28:46<7:48:05, 73.33s/it] 24%|██▎       | 118/500 [2:30:16<8:19:32, 78.46s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: -1.60E+05, Train scatter: [0.4742 0.0905 0.4896 0.5781]
L1 regularization loss: 5.91E+00, L2 regularization loss: 4.43E+00
Test scatter: [0.4615 0.0882 0.4811 0.5662], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.5837 0.0976 0.5037 0.6098], Epochs since improvement 10
 24%|██▍       | 119/500 [2:31:18<7:45:57, 73.38s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: -1.68E+05, Train scatter: [0.4244 0.0895 0.4788 0.592 ]
L1 regularization loss: 6.20E+00, L2 regularization loss: 4.65E+00
Test scatter: [0.417  0.088  0.4714 0.5821], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.4615 0.0925 0.483  0.5861], Epochs since improvement 12
 24%|██▍       | 120/500 [2:32:57<8:33:12, 81.03s/it] 24%|██▍       | 121/500 [2:33:58<7:54:40, 75.15s/it] 24%|██▍       | 122/500 [2:35:29<8:23:15, 79.88s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: -2.01E+05, Train scatter: [0.3716 0.0804 0.4543 0.5514]
L1 regularization loss: 6.06E+00, L2 regularization loss: 4.68E+00
Test scatter: [0.363  0.0791 0.4462 0.5427], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.4228 0.0882 0.4811 0.5821], Epochs since improvement 14
 25%|██▍       | 123/500 [2:36:31<7:47:21, 74.38s/it] 25%|██▍       | 124/500 [2:38:00<8:15:18, 79.04s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: -2.04E+05, Train scatter: [0.4061 0.0782 0.4671 0.5418]
L1 regularization loss: 5.98E+00, L2 regularization loss: 4.75E+00
Test scatter: [0.3981 0.0764 0.4587 0.5332], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.417  0.088  0.4714 0.5662], Epochs since improvement 16
 25%|██▌       | 125/500 [2:39:02<7:41:11, 73.79s/it] 25%|██▌       | 126/500 [2:40:32<8:10:16, 78.65s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: -2.23E+05, Train scatter: [0.4263 0.0812 0.4503 0.5498]
L1 regularization loss: 6.09E+00, L2 regularization loss: 4.97E+00
Test scatter: [0.4176 0.0793 0.4422 0.5413], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.417  0.0793 0.4587 0.5427], Epochs since improvement 18
 25%|██▌       | 127/500 [2:41:34<7:37:10, 73.54s/it] 26%|██▌       | 128/500 [2:43:04<8:07:13, 78.59s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -1.89E+05, Train scatter: [0.5805 0.0849 0.484  0.6036]
L1 regularization loss: 6.23E+00, L2 regularization loss: 5.32E+00
Test scatter: [0.5662 0.0825 0.4771 0.5911], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.417  0.0793 0.4587 0.5427], Epochs since improvement 20
 26%|██▌       | 129/500 [2:44:05<7:34:10, 73.45s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -2.28E+05, Train scatter: [0.3632 0.0718 0.4283 0.542 ]
L1 regularization loss: 6.40E+00, L2 regularization loss: 5.58E+00
Test scatter: [0.359  0.0707 0.421  0.5352], Lowest was [0.1345 0.042  0.2169 0.3813]
Median for last 10 epochs: [0.3981 0.0791 0.4462 0.5413], Epochs since improvement 22
 26%|██▌       | 129/500 [2:45:44<7:56:39, 77.09s/it]
Exited after 130 epochs due to early stopping
9944.20 seconds spent training, 19.888 seconds per epoch. Processed 3501 trees per second
[0.35895404 0.07068434 0.4209844  0.53521687]
{'epoch_exit': 129, 'scatter_m_star': 0.35895404, 'lowest_m_star': 0.13452427, 'last20_m_star': 0.42021456, 'last10_m_star': 0.39807007, 'scatter_v_disk': 0.07068434, 'lowest_v_disk': 0.04195584, 'last20_v_disk': 0.08528441, 'last10_v_disk': 0.07906306, 'scatter_m_cold': 0.4209844, 'lowest_m_cold': 0.21691841, 'last20_m_cold': 0.47420695, 'last10_m_cold': 0.44624496, 'scatter_sfr_100': 0.53521687, 'lowest_sfr_100': 0.3812617, 'last20_sfr_100': 0.57416666, 'last10_sfr_100': 0.5412733}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_yadqxw
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:24:47, 53.48s/it]  0%|          | 2/500 [02:13<9:35:23, 69.32s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.1725 0.5441 0.9953]
L1 regularization loss: 2.44E+00, L2 regularization loss: 4.23E-01
Test scatter: [0.9196 0.1681 0.5355 0.985 ], Lowest was [0.9196 0.1681 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1681 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:07<8:33:28, 61.99s/it]  1%|          | 4/500 [04:28<9:36:43, 69.77s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.75E+07, Train scatter: [0.9351 0.1371 0.5441 0.9955]
L1 regularization loss: 2.46E+00, L2 regularization loss: 4.25E-01
Test scatter: [0.9195 0.1333 0.5355 0.9851], Lowest was [0.9195 0.1333 0.5355 0.985 ]
Median for last 10 epochs: [0.9195 0.1333 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [05:22<8:46:56, 63.87s/it]  1%|          | 6/500 [06:42<9:31:14, 69.38s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.30E+07, Train scatter: [0.9349 0.1108 0.5441 0.9955]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.29E-01
Test scatter: [0.9192 0.1096 0.5355 0.9852], Lowest was [0.9192 0.1096 0.5355 0.985 ]
Median for last 10 epochs: [0.9192 0.1096 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:35<8:47:48, 64.24s/it]  2%|▏         | 8/500 [08:56<9:30:22, 69.56s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.10E+07, Train scatter: [0.9322 0.1003 0.544  0.9955]
L1 regularization loss: 2.48E+00, L2 regularization loss: 4.33E-01
Test scatter: [0.9167 0.0996 0.5354 0.9851], Lowest was [0.9167 0.0996 0.5354 0.985 ]
Median for last 10 epochs: [0.918  0.1046 0.5354 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [09:50<8:48:16, 64.55s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.88E+07, Train scatter: [0.79   0.0934 0.5439 0.9954]
L1 regularization loss: 2.49E+00, L2 regularization loss: 4.41E-01
Test scatter: [0.7818 0.0925 0.5353 0.9851], Lowest was [0.7818 0.0925 0.5353 0.985 ]
Median for last 10 epochs: [0.9167 0.0996 0.5354 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:18<9:45:54, 71.74s/it]  2%|▏         | 11/500 [12:11<8:59:10, 66.16s/it]  2%|▏         | 12/500 [13:33<9:36:14, 70.85s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.75E+07, Train scatter: [0.6737 0.0883 0.5437 0.9954]
L1 regularization loss: 2.51E+00, L2 regularization loss: 4.49E-01
Test scatter: [0.6686 0.0876 0.5352 0.9851], Lowest was [0.6686 0.0876 0.5352 0.985 ]
Median for last 10 epochs: [0.9167 0.0996 0.5354 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:26<8:52:25, 65.60s/it]  3%|▎         | 14/500 [15:47<9:27:01, 70.00s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.58E+07, Train scatter: [0.5959 0.0851 0.5428 0.9953]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.58E-01
Test scatter: [0.5934 0.084  0.5344 0.985 ], Lowest was [0.5934 0.084  0.5344 0.985 ]
Median for last 10 epochs: [0.7818 0.0925 0.5353 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [16:40<8:45:34, 65.02s/it]  3%|▎         | 16/500 [18:01<9:23:11, 69.82s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.51E+07, Train scatter: [0.4639 0.0828 0.5342 0.9953]
L1 regularization loss: 2.53E+00, L2 regularization loss: 4.65E-01
Test scatter: [0.4628 0.0818 0.5267 0.985 ], Lowest was [0.4628 0.0818 0.5267 0.985 ]
Median for last 10 epochs: [0.6686 0.0876 0.5352 0.9851], Epochs since improvement 0
  3%|▎         | 17/500 [18:54<8:42:21, 64.89s/it]  4%|▎         | 18/500 [20:15<9:20:06, 69.72s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.45E+07, Train scatter: [0.5616 0.0809 0.5291 0.9953]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.73E-01
Test scatter: [0.5495 0.0803 0.5216 0.985 ], Lowest was [0.4628 0.0803 0.5216 0.985 ]
Median for last 10 epochs: [0.5934 0.084  0.5344 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [21:09<8:39:28, 64.80s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.41E+07, Train scatter: [0.6733 0.1044 0.5192 0.9954]
L1 regularization loss: 2.56E+00, L2 regularization loss: 4.79E-01
Test scatter: [0.6807 0.102  0.5101 0.9851], Lowest was [0.4628 0.0803 0.5101 0.985 ]
Median for last 10 epochs: [0.5934 0.084  0.5267 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:37<9:34:58, 71.87s/it]  4%|▍         | 21/500 [23:31<8:49:31, 66.33s/it]  4%|▍         | 22/500 [24:51<9:23:20, 70.71s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.26E+07, Train scatter: [0.5287 0.0864 0.4182 0.9953]
L1 regularization loss: 2.57E+00, L2 regularization loss: 4.84E-01
Test scatter: [0.5341 0.0861 0.4213 0.985 ], Lowest was [0.4628 0.0803 0.4213 0.985 ]
Median for last 10 epochs: [0.5495 0.084  0.5216 0.985 ], Epochs since improvement 0
  5%|▍         | 23/500 [25:45<8:41:25, 65.59s/it]  5%|▍         | 24/500 [27:05<9:15:32, 70.03s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.19E+07, Train scatter: [0.542  0.0874 0.3811 0.9953]
L1 regularization loss: 2.59E+00, L2 regularization loss: 4.92E-01
Test scatter: [0.5389 0.0876 0.3819 0.985 ], Lowest was [0.4628 0.0803 0.3819 0.985 ]
Median for last 10 epochs: [0.5389 0.0861 0.5101 0.985 ], Epochs since improvement 0
  5%|▌         | 25/500 [27:59<8:34:52, 65.04s/it]  5%|▌         | 26/500 [29:19<9:09:24, 69.55s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 9.22E+07, Train scatter: [0.9167 0.167  0.542  0.9954]
L1 regularization loss: 2.81E+00, L2 regularization loss: 5.58E-01
Test scatter: [0.8999 0.1628 0.5335 0.985 ], Lowest was [0.4628 0.0803 0.3819 0.985 ]
Median for last 10 epochs: [0.5495 0.0876 0.5101 0.985 ], Epochs since improvement 2
  5%|▌         | 27/500 [30:12<8:29:40, 64.65s/it]  6%|▌         | 28/500 [31:32<9:05:05, 69.29s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.91E+07, Train scatter: [0.5288 0.1351 0.476  0.9954]
L1 regularization loss: 2.86E+00, L2 regularization loss: 6.21E-01
Test scatter: [0.5397 0.1325 0.4837 0.9851], Lowest was [0.4628 0.0803 0.3819 0.985 ]
Median for last 10 epochs: [0.5397 0.102  0.4837 0.985 ], Epochs since improvement 4
  6%|▌         | 29/500 [32:26<8:26:16, 64.49s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.71E+07, Train scatter: [0.5226 0.1118 0.5302 0.9954]
L1 regularization loss: 2.88E+00, L2 regularization loss: 6.36E-01
Test scatter: [0.5196 0.1117 0.5214 0.9851], Lowest was [0.4628 0.0803 0.3819 0.985 ]
Median for last 10 epochs: [0.5389 0.1117 0.4837 0.985 ], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [33:53<9:18:22, 71.28s/it]  6%|▌         | 31/500 [34:46<8:35:49, 65.99s/it]  6%|▋         | 32/500 [36:07<9:09:42, 70.47s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.61E+07, Train scatter: [0.5077 0.103  0.5046 0.9955]
L1 regularization loss: 2.90E+00, L2 regularization loss: 6.49E-01
Test scatter: [0.496  0.1062 0.4971 0.9851], Lowest was [0.4628 0.0803 0.3819 0.985 ]
Median for last 10 epochs: [0.5389 0.1117 0.4971 0.9851], Epochs since improvement 8
  7%|▋         | 33/500 [37:01<8:28:32, 65.34s/it]  7%|▋         | 34/500 [38:21<9:01:28, 69.72s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.50E+07, Train scatter: [0.4631 0.0923 0.4102 0.9954]
L1 regularization loss: 2.91E+00, L2 regularization loss: 6.61E-01
Test scatter: [0.4619 0.0924 0.4099 0.9851], Lowest was [0.4619 0.0803 0.3819 0.985 ]
Median for last 10 epochs: [0.5196 0.1117 0.4971 0.9851], Epochs since improvement 0
  7%|▋         | 35/500 [39:14<8:22:55, 64.89s/it]  7%|▋         | 36/500 [40:34<8:57:04, 69.45s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.54E+07, Train scatter: [0.495  0.1048 0.539  0.9954]
L1 regularization loss: 2.92E+00, L2 regularization loss: 6.76E-01
Test scatter: [0.4979 0.1038 0.5306 0.985 ], Lowest was [0.4619 0.0803 0.3819 0.985 ]
Median for last 10 epochs: [0.4979 0.1062 0.4971 0.9851], Epochs since improvement 2
  7%|▋         | 37/500 [41:28<8:19:39, 64.75s/it]  8%|▊         | 38/500 [42:48<8:54:17, 69.39s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 7.44E+07, Train scatter: [0.6139 0.1429 0.5431 0.9954]
L1 regularization loss: 2.95E+00, L2 regularization loss: 6.98E-01
Test scatter: [0.5991 0.1391 0.5345 0.9851], Lowest was [0.4619 0.0803 0.3819 0.985 ]
Median for last 10 epochs: [0.4979 0.1062 0.5214 0.9851], Epochs since improvement 4
  8%|▊         | 39/500 [43:42<8:16:37, 64.64s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 6.83E+07, Train scatter: [0.4343 0.1036 0.5383 0.9952]
L1 regularization loss: 2.96E+00, L2 regularization loss: 7.13E-01
Test scatter: [0.4393 0.103  0.5299 0.9849], Lowest was [0.4393 0.0803 0.3819 0.9849]
Median for last 10 epochs: [0.496  0.1038 0.5299 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:10<9:08:43, 71.57s/it]  8%|▊         | 41/500 [46:03<8:26:14, 66.18s/it]  8%|▊         | 42/500 [47:23<8:56:43, 70.31s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.77E+07, Train scatter: [0.5471 0.1079 0.4531 0.9707]
L1 regularization loss: 2.98E+00, L2 regularization loss: 7.41E-01
Test scatter: [0.5544 0.108  0.4547 0.9597], Lowest was [0.4393 0.0803 0.3819 0.9597]
Median for last 10 epochs: [0.4979 0.1038 0.5299 0.985 ], Epochs since improvement 0
  9%|▊         | 43/500 [48:17<8:17:24, 65.31s/it]  9%|▉         | 44/500 [49:37<8:51:11, 69.89s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 6.00E+06, Train scatter: [0.3958 0.091  0.4041 0.641 ]
L1 regularization loss: 3.01E+00, L2 regularization loss: 7.72E-01
Test scatter: [0.391  0.0912 0.4049 0.6352], Lowest was [0.391  0.0803 0.3819 0.6352]
Median for last 10 epochs: [0.4979 0.1038 0.5299 0.9849], Epochs since improvement 0
  9%|▉         | 45/500 [50:31<8:12:36, 64.96s/it]  9%|▉         | 46/500 [51:52<8:47:26, 69.71s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 5.55E+06, Train scatter: [0.3551 0.087  0.3803 0.5734]
L1 regularization loss: 3.02E+00, L2 regularization loss: 7.86E-01
Test scatter: [0.3496 0.0861 0.385  0.5707], Lowest was [0.3496 0.0803 0.3819 0.5707]
Median for last 10 epochs: [0.4393 0.103  0.4547 0.9597], Epochs since improvement 0
  9%|▉         | 47/500 [52:45<8:10:09, 64.92s/it] 10%|▉         | 48/500 [54:07<8:46:19, 69.87s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 4.67E+06, Train scatter: [0.3743 0.0838 0.3932 0.6123]
L1 regularization loss: 3.03E+00, L2 regularization loss: 7.98E-01
Test scatter: [0.3731 0.0827 0.3944 0.6066], Lowest was [0.3496 0.0803 0.3819 0.5707]
Median for last 10 epochs: [0.391  0.0912 0.4049 0.6352], Epochs since improvement 2
 10%|▉         | 49/500 [55:00<8:08:31, 64.99s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 4.31E+06, Train scatter: [0.3628 0.0812 0.3912 0.614 ]
L1 regularization loss: 3.05E+00, L2 regularization loss: 8.13E-01
Test scatter: [0.3624 0.0804 0.3923 0.6082], Lowest was [0.3496 0.0803 0.3819 0.5707]
Median for last 10 epochs: [0.3731 0.0861 0.3944 0.6082], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [56:29<8:59:55, 71.99s/it] 10%|█         | 51/500 [57:22<8:17:17, 66.45s/it] 10%|█         | 52/500 [58:43<8:49:06, 70.86s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 4.36E+06, Train scatter: [0.3259 0.0825 0.3794 0.5501]
L1 regularization loss: 3.07E+00, L2 regularization loss: 8.32E-01
Test scatter: [0.3269 0.082  0.3799 0.5473], Lowest was [0.3269 0.0803 0.3799 0.5473]
Median for last 10 epochs: [0.3624 0.0827 0.3923 0.6066], Epochs since improvement 0
 11%|█         | 53/500 [59:37<8:09:09, 65.66s/it] 11%|█         | 54/500 [1:00:57<8:40:04, 69.97s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 4.00E+06, Train scatter: [0.3014 0.0745 0.355  0.5496]
L1 regularization loss: 3.08E+00, L2 regularization loss: 8.47E-01
Test scatter: [0.3083 0.0751 0.3581 0.5428], Lowest was [0.3083 0.0751 0.3581 0.5428]
Median for last 10 epochs: [0.3496 0.082  0.385  0.5707], Epochs since improvement 0
 11%|█         | 55/500 [1:01:50<8:02:08, 65.01s/it] 11%|█         | 56/500 [1:03:11<8:36:40, 69.82s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.63E+06, Train scatter: [0.394  0.075  0.3599 0.5435]
L1 regularization loss: 3.09E+00, L2 regularization loss: 8.58E-01
Test scatter: [0.3928 0.076  0.3596 0.5374], Lowest was [0.3083 0.0751 0.3581 0.5374]
Median for last 10 epochs: [0.3624 0.0804 0.3799 0.5473], Epochs since improvement 0
 11%|█▏        | 57/500 [1:04:05<7:58:56, 64.87s/it] 12%|█▏        | 58/500 [1:05:25<8:31:44, 69.47s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.66E+06, Train scatter: [0.4271 0.0813 0.4125 0.6228]
L1 regularization loss: 3.11E+00, L2 regularization loss: 8.76E-01
Test scatter: [0.423  0.0804 0.4104 0.6171], Lowest was [0.3083 0.0751 0.3581 0.5374]
Median for last 10 epochs: [0.3624 0.0804 0.3799 0.5473], Epochs since improvement 2
 12%|█▏        | 59/500 [1:06:18<7:55:06, 64.64s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.63E+06, Train scatter: [0.2972 0.0724 0.3401 0.5198]
L1 regularization loss: 3.12E+00, L2 regularization loss: 8.93E-01
Test scatter: [0.3024 0.0727 0.3456 0.5161], Lowest was [0.3024 0.0727 0.3456 0.5161]
Median for last 10 epochs: [0.3269 0.076  0.3596 0.5428], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:07:47<8:46:43, 71.83s/it] 12%|█▏        | 61/500 [1:08:40<8:05:23, 66.34s/it] 12%|█▏        | 62/500 [1:10:01<8:35:31, 70.62s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.53E+06, Train scatter: [0.2762 0.0728 0.331  0.5015]
L1 regularization loss: 3.14E+00, L2 regularization loss: 9.15E-01
Test scatter: [0.2817 0.073  0.335  0.4973], Lowest was [0.2817 0.0727 0.335  0.4973]
Median for last 10 epochs: [0.3083 0.0751 0.3581 0.5374], Epochs since improvement 0
 13%|█▎        | 63/500 [1:10:54<7:56:37, 65.44s/it] 13%|█▎        | 64/500 [1:12:15<8:29:30, 70.12s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.25E+06, Train scatter: [0.5146 0.0718 0.3522 0.5319]
L1 regularization loss: 3.17E+00, L2 regularization loss: 9.42E-01
Test scatter: [0.5066 0.0723 0.3564 0.5271], Lowest was [0.2817 0.0723 0.335  0.4973]
Median for last 10 epochs: [0.3928 0.073  0.3564 0.5271], Epochs since improvement 0
 13%|█▎        | 65/500 [1:13:09<7:52:17, 65.14s/it] 13%|█▎        | 66/500 [1:14:30<8:25:00, 69.82s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.20E+06, Train scatter: [0.266  0.0701 0.3188 0.4945]
L1 regularization loss: 3.19E+00, L2 regularization loss: 9.68E-01
Test scatter: [0.2733 0.0709 0.3256 0.4927], Lowest was [0.2733 0.0709 0.3256 0.4927]
Median for last 10 epochs: [0.3024 0.0727 0.3456 0.5161], Epochs since improvement 0
 13%|█▎        | 67/500 [1:15:23<7:48:46, 64.96s/it] 14%|█▎        | 68/500 [1:16:43<8:19:59, 69.44s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.69E+06, Train scatter: [0.4631 0.0716 0.3144 0.5068]
L1 regularization loss: 3.23E+00, L2 regularization loss: 1.01E+00
Test scatter: [0.4508 0.0725 0.3234 0.5026], Lowest was [0.2733 0.0709 0.3234 0.4927]
Median for last 10 epochs: [0.3024 0.0725 0.335  0.5026], Epochs since improvement 0
 14%|█▍        | 69/500 [1:17:37<7:44:24, 64.65s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.00E+06, Train scatter: [0.2528 0.069  0.3292 0.5072]
L1 regularization loss: 3.24E+00, L2 regularization loss: 1.02E+00
Test scatter: [0.254  0.0699 0.3348 0.4999], Lowest was [0.254  0.0699 0.3234 0.4927]
Median for last 10 epochs: [0.2817 0.0723 0.3348 0.4999], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:19:05<8:33:48, 71.69s/it] 14%|█▍        | 71/500 [1:19:58<7:53:11, 66.18s/it] 14%|█▍        | 72/500 [1:21:19<8:22:54, 70.50s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 2.92E+06, Train scatter: [0.254  0.0701 0.3058 0.493 ]
L1 regularization loss: 3.26E+00, L2 regularization loss: 1.05E+00
Test scatter: [0.2577 0.0711 0.3114 0.4904], Lowest was [0.254  0.0699 0.3114 0.4904]
Median for last 10 epochs: [0.2733 0.0711 0.3256 0.4999], Epochs since improvement 0
 15%|█▍        | 73/500 [1:22:12<7:45:17, 65.38s/it] 15%|█▍        | 74/500 [1:23:32<8:15:59, 69.86s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.86E+06, Train scatter: [0.2658 0.0722 0.3009 0.4976]
L1 regularization loss: 3.29E+00, L2 regularization loss: 1.08E+00
Test scatter: [0.2714 0.0728 0.3087 0.4977], Lowest was [0.254  0.0699 0.3087 0.4904]
Median for last 10 epochs: [0.2714 0.0711 0.3234 0.4977], Epochs since improvement 0
 15%|█▌        | 75/500 [1:24:26<7:40:14, 64.98s/it] 15%|█▌        | 76/500 [1:25:47<8:12:33, 69.70s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.86E+06, Train scatter: [0.2424 0.0691 0.2931 0.4798]
L1 regularization loss: 3.33E+00, L2 regularization loss: 1.12E+00
Test scatter: [0.2506 0.0692 0.3006 0.4753], Lowest was [0.2506 0.0692 0.3006 0.4753]
Median for last 10 epochs: [0.2577 0.0711 0.3114 0.4977], Epochs since improvement 0
 15%|█▌        | 77/500 [1:26:40<7:36:57, 64.82s/it] 16%|█▌        | 78/500 [1:28:01<8:10:07, 69.69s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.72E+06, Train scatter: [0.2535 0.0685 0.299  0.4787]
L1 regularization loss: 3.35E+00, L2 regularization loss: 1.14E+00
Test scatter: [0.2595 0.0696 0.3078 0.4765], Lowest was [0.2506 0.0692 0.3006 0.4753]
Median for last 10 epochs: [0.2577 0.0699 0.3087 0.4904], Epochs since improvement 2
 16%|█▌        | 79/500 [1:28:55<7:35:09, 64.87s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.60E+06, Train scatter: [0.2465 0.0695 0.2871 0.4722]
L1 regularization loss: 3.38E+00, L2 regularization loss: 1.17E+00
Test scatter: [0.2489 0.0703 0.2944 0.4703], Lowest was [0.2489 0.0692 0.2944 0.4703]
Median for last 10 epochs: [0.2577 0.0703 0.3078 0.4765], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:30:23<8:23:37, 71.95s/it] 16%|█▌        | 81/500 [1:31:17<7:44:36, 66.53s/it] 16%|█▋        | 82/500 [1:32:37<8:12:03, 70.63s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.57E+06, Train scatter: [0.246  0.0673 0.2785 0.4661]
L1 regularization loss: 3.41E+00, L2 regularization loss: 1.20E+00
Test scatter: [0.2528 0.0681 0.2872 0.4628], Lowest was [0.2489 0.0681 0.2872 0.4628]
Median for last 10 epochs: [0.2528 0.0696 0.3006 0.4753], Epochs since improvement 0
 17%|█▋        | 83/500 [1:33:31<7:35:08, 65.49s/it] 17%|█▋        | 84/500 [1:34:52<8:06:17, 70.14s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.60E+06, Train scatter: [0.2614 0.067  0.29   0.4933]
L1 regularization loss: 3.43E+00, L2 regularization loss: 1.23E+00
Test scatter: [0.2635 0.067  0.2942 0.4914], Lowest was [0.2489 0.067  0.2872 0.4628]
Median for last 10 epochs: [0.2528 0.0692 0.2944 0.4753], Epochs since improvement 0
 17%|█▋        | 85/500 [1:35:45<7:30:09, 65.08s/it] 17%|█▋        | 86/500 [1:37:06<8:01:56, 69.85s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.57E+06, Train scatter: [0.2373 0.0694 0.2843 0.4731]
L1 regularization loss: 3.46E+00, L2 regularization loss: 1.26E+00
Test scatter: [0.244  0.0699 0.2918 0.4736], Lowest was [0.244  0.067  0.2872 0.4628]
Median for last 10 epochs: [0.2528 0.0696 0.2942 0.4736], Epochs since improvement 0
 17%|█▋        | 87/500 [1:37:59<7:26:32, 64.87s/it] 18%|█▊        | 88/500 [1:39:19<7:56:24, 69.38s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.39E+06, Train scatter: [0.2621 0.0665 0.2781 0.4633]
L1 regularization loss: 3.47E+00, L2 regularization loss: 1.29E+00
Test scatter: [0.2662 0.0671 0.2843 0.4602], Lowest was [0.244  0.067  0.2843 0.4602]
Median for last 10 epochs: [0.2528 0.0681 0.2918 0.4703], Epochs since improvement 0
 18%|█▊        | 89/500 [1:40:13<7:22:23, 64.58s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.28E+06, Train scatter: [0.2224 0.0635 0.2718 0.4636]
L1 regularization loss: 3.50E+00, L2 regularization loss: 1.32E+00
Test scatter: [0.2273 0.0634 0.274  0.4577], Lowest was [0.2273 0.0634 0.274  0.4577]
Median for last 10 epochs: [0.2528 0.0671 0.2872 0.4628], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:41:42<8:11:28, 71.92s/it] 18%|█▊        | 91/500 [1:42:35<7:32:11, 66.34s/it] 18%|█▊        | 92/500 [1:43:56<8:01:06, 70.75s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.17E+06, Train scatter: [0.2934 0.0632 0.272  0.4759]
L1 regularization loss: 3.52E+00, L2 regularization loss: 1.35E+00
Test scatter: [0.2971 0.0636 0.279  0.4703], Lowest was [0.2273 0.0634 0.274  0.4577]
Median for last 10 epochs: [0.2635 0.067  0.2843 0.4703], Epochs since improvement 2
 19%|█▊        | 93/500 [1:44:49<7:24:30, 65.53s/it] 19%|█▉        | 94/500 [1:46:10<7:52:57, 69.90s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.17E+06, Train scatter: [0.2388 0.062  0.276  0.4657]
L1 regularization loss: 3.54E+00, L2 regularization loss: 1.38E+00
Test scatter: [0.2425 0.0623 0.2807 0.4629], Lowest was [0.2273 0.0623 0.274  0.4577]
Median for last 10 epochs: [0.244  0.0636 0.2807 0.4629], Epochs since improvement 0
 19%|█▉        | 95/500 [1:47:03<7:18:56, 65.03s/it] 19%|█▉        | 96/500 [1:48:24<7:49:06, 69.67s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.08E+06, Train scatter: [0.2522 0.0608 0.2987 0.4708]
L1 regularization loss: 3.57E+00, L2 regularization loss: 1.42E+00
Test scatter: [0.2572 0.0609 0.3018 0.4725], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.2572 0.0634 0.2807 0.4629], Epochs since improvement 0
 19%|█▉        | 97/500 [1:49:17<7:15:25, 64.83s/it] 20%|█▉        | 98/500 [1:50:37<7:44:44, 69.37s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 1.99E+06, Train scatter: [0.2298 0.0622 0.2738 0.4771]
L1 regularization loss: 3.59E+00, L2 regularization loss: 1.45E+00
Test scatter: [0.2358 0.063  0.2803 0.4751], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.2425 0.063  0.2803 0.4703], Epochs since improvement 2
 20%|█▉        | 99/500 [1:51:31<7:11:48, 64.61s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 8.27E+06, Train scatter: [0.8016 0.1544 0.5426 0.7103]
L1 regularization loss: 3.88E+00, L2 regularization loss: 1.66E+00
Test scatter: [0.7901 0.1512 0.534  0.6994], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.2572 0.063  0.2807 0.4725], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:53:01<8:01:40, 72.25s/it] 20%|██        | 101/500 [1:53:54<7:22:52, 66.60s/it] 20%|██        | 102/500 [1:55:15<7:50:30, 70.93s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 3.94E+06, Train scatter: [0.6389 0.0939 0.5157 0.5782]
L1 regularization loss: 3.92E+00, L2 regularization loss: 1.72E+00
Test scatter: [0.6344 0.0924 0.5073 0.5734], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.2572 0.063  0.3018 0.4751], Epochs since improvement 6
 21%|██        | 103/500 [1:56:09<7:15:09, 65.77s/it] 21%|██        | 104/500 [1:57:29<7:43:13, 70.19s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 3.00E+06, Train scatter: [0.5954 0.0823 0.5141 0.5402]
L1 regularization loss: 3.94E+00, L2 regularization loss: 1.78E+00
Test scatter: [0.5744 0.0829 0.506  0.5327], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.5744 0.0829 0.506  0.5327], Epochs since improvement 8
 21%|██        | 105/500 [1:58:23<7:09:06, 65.18s/it] 21%|██        | 106/500 [1:59:44<7:38:55, 69.89s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 2.36E+06, Train scatter: [0.4786 0.0733 0.477  0.5029]
L1 regularization loss: 3.96E+00, L2 regularization loss: 1.84E+00
Test scatter: [0.4713 0.0728 0.4692 0.4985], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.5744 0.0829 0.506  0.5327], Epochs since improvement 10
 21%|██▏       | 107/500 [2:00:37<7:05:12, 64.92s/it] 22%|██▏       | 108/500 [2:01:58<7:35:58, 69.79s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 2.05E+06, Train scatter: [0.2939 0.0704 0.4474 0.484 ]
L1 regularization loss: 3.97E+00, L2 regularization loss: 1.89E+00
Test scatter: [0.2997 0.07   0.443  0.4806], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.5744 0.0829 0.506  0.5327], Epochs since improvement 12
 22%|██▏       | 109/500 [2:02:52<7:03:13, 64.94s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 1.95E+06, Train scatter: [0.2705 0.0781 0.427  0.5106]
L1 regularization loss: 4.00E+00, L2 regularization loss: 1.94E+00
Test scatter: [0.2858 0.0777 0.4225 0.5064], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.4713 0.0777 0.4692 0.5064], Epochs since improvement 14
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:04:21<7:48:31, 72.08s/it] 22%|██▏       | 111/500 [2:05:14<7:11:02, 66.48s/it] 22%|██▏       | 112/500 [2:06:35<7:37:16, 70.71s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.79E+06, Train scatter: [0.2697 0.0694 0.3554 0.4768]
L1 regularization loss: 4.02E+00, L2 regularization loss: 2.00E+00
Test scatter: [0.2737 0.0688 0.358  0.4749], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.2997 0.0728 0.443  0.4985], Epochs since improvement 16
 23%|██▎       | 113/500 [2:07:28<7:02:40, 65.53s/it] 23%|██▎       | 114/500 [2:08:48<7:30:06, 69.97s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.63E+06, Train scatter: [0.3346 0.0701 0.3432 0.4719]
L1 regularization loss: 4.04E+00, L2 regularization loss: 2.04E+00
Test scatter: [0.3294 0.0699 0.3471 0.4691], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.2997 0.07   0.4225 0.4806], Epochs since improvement 18
 23%|██▎       | 115/500 [2:09:42<6:57:10, 65.02s/it] 23%|██▎       | 116/500 [2:11:02<7:25:48, 69.66s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.68E+06, Train scatter: [0.2325 0.0677 0.3494 0.466 ]
L1 regularization loss: 4.06E+00, L2 regularization loss: 2.10E+00
Test scatter: [0.2449 0.0679 0.3544 0.4635], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.2858 0.0699 0.358  0.4749], Epochs since improvement 20
 23%|██▎       | 117/500 [2:11:56<6:53:35, 64.79s/it] 23%|██▎       | 117/500 [2:13:16<7:16:17, 68.35s/it]
Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.47E+06, Train scatter: [0.2347 0.0677 0.3318 0.4642]
L1 regularization loss: 4.08E+00, L2 regularization loss: 2.14E+00
Test scatter: [0.2418 0.0663 0.336  0.4631], Lowest was [0.2273 0.0609 0.274  0.4577]
Median for last 10 epochs: [0.2737 0.0688 0.3544 0.4691], Epochs since improvement 22
Exited after 118 epochs due to early stopping
7996.74 seconds spent training, 15.993 seconds per epoch. Processed 4354 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.24182524 0.06626622 0.33601978 0.4630435 ]
{'epoch_exit': 117, 'scatter_m_star': 0.24182524, 'lowest_m_star': 0.22725864, 'last20_m_star': 0.31454384, 'last10_m_star': 0.27370834, 'scatter_v_disk': 0.06626622, 'lowest_v_disk': 0.06085277, 'last20_v_disk': 0.07142177, 'last10_v_disk': 0.068780184, 'scatter_m_cold': 0.33601978, 'lowest_m_cold': 0.2739514, 'last20_m_cold': 0.43275788, 'last10_m_cold': 0.35437182, 'scatter_sfr_100': 0.4630435, 'lowest_sfr_100': 0.45770028, 'last20_sfr_100': 0.48954034, 'last10_sfr_100': 0.46911472}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
