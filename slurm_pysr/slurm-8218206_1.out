Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_dsslnr
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:31<4:24:28, 31.80s/it]  0%|          | 2/500 [01:20<5:45:04, 41.57s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.27E+07, Train scatter: [0.9352 0.1672 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.31E-01
Test scatter: [0.9196 0.1666 0.5355 0.9851], Lowest was [0.9196 0.1666 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1666 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:51<5:04:44, 36.79s/it]  1%|          | 4/500 [02:39<5:42:46, 41.46s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 6.85E+06, Train scatter: [0.9351 0.1468 0.5439 0.9954]
L1 regularization loss: 1.53E+00, L2 regularization loss: 3.54E-01
Test scatter: [0.9195 0.1452 0.5353 0.985 ], Lowest was [0.9195 0.1452 0.5353 0.985 ]
Median for last 10 epochs: [0.9195 0.1452 0.5353 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:11<5:11:15, 37.73s/it]  1%|          | 6/500 [03:59<5:41:51, 41.52s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.24E+06, Train scatter: [0.9346 0.127  0.5421 0.7274]
L1 regularization loss: 1.57E+00, L2 regularization loss: 3.91E-01
Test scatter: [0.919  0.1266 0.5334 0.7171], Lowest was [0.919  0.1266 0.5334 0.7171]
Median for last 10 epochs: [0.919  0.1266 0.5334 0.7171], Epochs since improvement 0
  1%|▏         | 7/500 [04:31<5:13:16, 38.13s/it]  2%|▏         | 8/500 [05:19<5:40:13, 41.49s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.53E+06, Train scatter: [0.9176 0.1093 0.5332 0.6211]
L1 regularization loss: 1.59E+00, L2 regularization loss: 4.04E-01
Test scatter: [0.9015 0.1105 0.5246 0.611 ], Lowest was [0.9015 0.1105 0.5246 0.611 ]
Median for last 10 epochs: [0.9102 0.1185 0.529  0.6641], Epochs since improvement 0
  2%|▏         | 9/500 [05:51<5:13:27, 38.30s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 3.82E+06, Train scatter: [0.8184 0.1036 0.4798 0.6784]
L1 regularization loss: 1.61E+00, L2 regularization loss: 4.15E-01
Test scatter: [0.8068 0.1053 0.466  0.6717], Lowest was [0.8068 0.1053 0.466  0.611 ]
Median for last 10 epochs: [0.9015 0.1105 0.5246 0.6717], Epochs since improvement 0
  2%|▏         | 10/500 [06:45<5:52:30, 43.16s/it]  2%|▏         | 11/500 [07:16<5:21:48, 39.48s/it]  2%|▏         | 12/500 [08:04<5:43:13, 42.20s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.48E+06, Train scatter: [0.5922 0.0948 0.4329 0.6089]
L1 regularization loss: 1.62E+00, L2 regularization loss: 4.27E-01
Test scatter: [0.5948 0.0964 0.4314 0.6094], Lowest was [0.5948 0.0964 0.4314 0.6094]
Median for last 10 epochs: [0.9015 0.1105 0.5246 0.6717], Epochs since improvement 0
  3%|▎         | 13/500 [08:35<5:15:40, 38.89s/it]  3%|▎         | 14/500 [09:24<5:38:41, 41.81s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.52E+06, Train scatter: [0.5396 0.0923 0.3759 0.593 ]
L1 regularization loss: 1.64E+00, L2 regularization loss: 4.35E-01
Test scatter: [0.5308 0.0938 0.3733 0.5918], Lowest was [0.5308 0.0938 0.3733 0.5918]
Median for last 10 epochs: [0.8068 0.1053 0.466  0.611 ], Epochs since improvement 0
  3%|▎         | 15/500 [09:55<5:12:19, 38.64s/it]  3%|▎         | 16/500 [10:44<5:35:58, 41.65s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.20E+06, Train scatter: [0.5789 0.0901 0.3497 0.5895]
L1 regularization loss: 1.66E+00, L2 regularization loss: 4.43E-01
Test scatter: [0.5718 0.0923 0.3568 0.5954], Lowest was [0.5308 0.0923 0.3568 0.5918]
Median for last 10 epochs: [0.5948 0.0964 0.4314 0.6094], Epochs since improvement 0
  3%|▎         | 17/500 [11:15<5:10:11, 38.53s/it]  4%|▎         | 18/500 [12:04<5:33:08, 41.47s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.03E+06, Train scatter: [0.5132 0.0865 0.3367 0.5744]
L1 regularization loss: 1.68E+00, L2 regularization loss: 4.54E-01
Test scatter: [0.506  0.0884 0.3389 0.5796], Lowest was [0.506  0.0884 0.3389 0.5796]
Median for last 10 epochs: [0.5718 0.0938 0.3733 0.5954], Epochs since improvement 0
  4%|▍         | 19/500 [12:35<5:08:05, 38.43s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.38E+05, Train scatter: [0.5336 0.0831 0.3135 0.5932]
L1 regularization loss: 1.70E+00, L2 regularization loss: 4.64E-01
Test scatter: [0.5249 0.0852 0.3205 0.6103], Lowest was [0.506  0.0852 0.3205 0.5796]
Median for last 10 epochs: [0.5308 0.0923 0.3568 0.5954], Epochs since improvement 0
  4%|▍         | 20/500 [13:29<5:45:08, 43.14s/it]  4%|▍         | 21/500 [14:00<5:16:12, 39.61s/it]  4%|▍         | 22/500 [14:49<5:37:32, 42.37s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 6.85E+05, Train scatter: [0.4913 0.0808 0.3288 0.5812]
L1 regularization loss: 1.72E+00, L2 regularization loss: 4.73E-01
Test scatter: [0.4973 0.0826 0.3419 0.5911], Lowest was [0.4973 0.0826 0.3205 0.5796]
Median for last 10 epochs: [0.5249 0.0884 0.3419 0.5918], Epochs since improvement 0
  5%|▍         | 23/500 [15:20<5:10:19, 39.03s/it]  5%|▍         | 24/500 [16:09<5:32:10, 41.87s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 6.38E+05, Train scatter: [0.4577 0.0791 0.3233 0.5421]
L1 regularization loss: 1.75E+00, L2 regularization loss: 4.84E-01
Test scatter: [0.4587 0.0813 0.3291 0.5447], Lowest was [0.4587 0.0813 0.3205 0.5447]
Median for last 10 epochs: [0.506  0.0852 0.3389 0.5911], Epochs since improvement 0
  5%|▌         | 25/500 [16:40<5:06:12, 38.68s/it]  5%|▌         | 26/500 [17:29<5:28:30, 41.58s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.55E+05, Train scatter: [0.5698 0.0964 0.4753 0.8243]
L1 regularization loss: 1.79E+00, L2 regularization loss: 5.00E-01
Test scatter: [0.5601 0.1053 0.4736 0.8156], Lowest was [0.4587 0.0813 0.3205 0.5447]
Median for last 10 epochs: [0.506  0.0852 0.3389 0.5911], Epochs since improvement 2
  5%|▌         | 27/500 [18:00<5:03:54, 38.55s/it]  6%|▌         | 28/500 [18:48<5:26:41, 41.53s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.42E+05, Train scatter: [0.5679 0.0772 0.3136 0.5402]
L1 regularization loss: 1.82E+00, L2 regularization loss: 5.16E-01
Test scatter: [0.5662 0.0798 0.3245 0.5422], Lowest was [0.4587 0.0798 0.3205 0.5422]
Median for last 10 epochs: [0.5249 0.0826 0.3291 0.5911], Epochs since improvement 0
  6%|▌         | 29/500 [19:20<5:02:11, 38.50s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.56E+05, Train scatter: [0.4926 0.0771 0.3264 0.5505]
L1 regularization loss: 1.85E+00, L2 regularization loss: 5.33E-01
Test scatter: [0.493  0.0784 0.3321 0.5489], Lowest was [0.4587 0.0784 0.3205 0.5422]
Median for last 10 epochs: [0.4973 0.0813 0.3321 0.5489], Epochs since improvement 0
  6%|▌         | 30/500 [20:13<5:36:58, 43.02s/it]  6%|▌         | 31/500 [20:45<5:08:49, 39.51s/it]  6%|▋         | 32/500 [21:33<5:29:14, 42.21s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.21E+05, Train scatter: [0.401  0.0734 0.2896 0.5485]
L1 regularization loss: 1.88E+00, L2 regularization loss: 5.52E-01
Test scatter: [0.4074 0.0751 0.299  0.5526], Lowest was [0.4074 0.0751 0.299  0.5422]
Median for last 10 epochs: [0.493  0.0798 0.3291 0.5489], Epochs since improvement 0
  7%|▋         | 33/500 [22:05<5:03:34, 39.00s/it]  7%|▋         | 34/500 [22:53<5:25:09, 41.86s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 4.92E+05, Train scatter: [0.4226 0.0725 0.2933 0.5096]
L1 regularization loss: 1.92E+00, L2 regularization loss: 5.75E-01
Test scatter: [0.4225 0.0748 0.3039 0.5122], Lowest was [0.4074 0.0748 0.299  0.5122]
Median for last 10 epochs: [0.493  0.0784 0.3245 0.5489], Epochs since improvement 0
  7%|▋         | 35/500 [23:25<5:00:19, 38.75s/it]  7%|▋         | 36/500 [24:14<5:22:41, 41.73s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.33E+05, Train scatter: [0.3462 0.0703 0.2839 0.4947]
L1 regularization loss: 1.95E+00, L2 regularization loss: 5.96E-01
Test scatter: [0.3429 0.0717 0.2919 0.4941], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.4225 0.0751 0.3039 0.5422], Epochs since improvement 0
  7%|▋         | 37/500 [24:45<4:58:21, 38.67s/it]  8%|▊         | 38/500 [25:34<5:20:58, 41.69s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.62E+06, Train scatter: [0.8783 0.1228 0.5224 0.9731]
L1 regularization loss: 2.36E+00, L2 regularization loss: 7.51E-01
Test scatter: [0.8617 0.1222 0.5143 0.9644], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.4225 0.0751 0.3039 0.5489], Epochs since improvement 2
  8%|▊         | 39/500 [26:05<4:56:44, 38.62s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 7.43E+04, Train scatter: [0.5696 0.1097 0.4801 0.9048]
L1 regularization loss: 2.40E+00, L2 regularization loss: 8.00E-01
Test scatter: [0.5667 0.1096 0.4751 0.8986], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.4225 0.0751 0.3039 0.5526], Epochs since improvement 4
  8%|▊         | 40/500 [26:59<5:31:27, 43.23s/it]  8%|▊         | 41/500 [27:31<5:04:01, 39.74s/it]  8%|▊         | 42/500 [28:20<5:24:26, 42.50s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -1.90E+04, Train scatter: [0.4589 0.1032 0.4601 0.7925]
L1 regularization loss: 2.43E+00, L2 regularization loss: 8.65E-01
Test scatter: [0.4659 0.1036 0.4552 0.7888], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.4659 0.1036 0.4552 0.7888], Epochs since improvement 6
  9%|▊         | 43/500 [28:51<4:58:37, 39.21s/it]  9%|▉         | 44/500 [29:39<5:18:24, 41.89s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 9.03E+05, Train scatter: [0.8178 0.136  0.5413 0.9817]
L1 regularization loss: 2.61E+00, L2 regularization loss: 1.01E+00
Test scatter: [0.8086 0.1341 0.5329 0.9731], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.5667 0.1096 0.4751 0.8986], Epochs since improvement 8
  9%|▉         | 45/500 [30:11<4:53:58, 38.77s/it]  9%|▉         | 46/500 [30:59<5:15:00, 41.63s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.29E+06, Train scatter: [0.9323 0.1723 0.541  0.9829]
L1 regularization loss: 3.09E+00, L2 regularization loss: 1.30E+00
Test scatter: [0.9167 0.1685 0.5326 0.9731], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.8086 0.1222 0.5143 0.9644], Epochs since improvement 10
  9%|▉         | 47/500 [31:31<4:51:06, 38.56s/it] 10%|▉         | 48/500 [32:20<5:13:57, 41.68s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 8.47E+05, Train scatter: [0.9217 0.1388 0.4933 0.7815]
L1 regularization loss: 3.12E+00, L2 regularization loss: 1.36E+00
Test scatter: [0.906  0.1362 0.4878 0.7763], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.8086 0.1341 0.4878 0.8986], Epochs since improvement 12
 10%|▉         | 49/500 [32:51<4:50:23, 38.63s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 5.05E+05, Train scatter: [0.9272 0.1189 0.5421 0.7421]
L1 regularization loss: 3.14E+00, L2 regularization loss: 1.38E+00
Test scatter: [0.9118 0.1171 0.5336 0.7365], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.906  0.1341 0.5326 0.7888], Epochs since improvement 14
 10%|█         | 50/500 [33:45<5:23:24, 43.12s/it] 10%|█         | 51/500 [34:16<4:56:34, 39.63s/it] 10%|█         | 52/500 [35:04<5:14:26, 42.11s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 4.37E+05, Train scatter: [0.923  0.116  0.5419 0.7323]
L1 regularization loss: 3.14E+00, L2 regularization loss: 1.40E+00
Test scatter: [0.9075 0.1143 0.5334 0.7276], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.9075 0.1341 0.5329 0.7763], Epochs since improvement 16
 11%|█         | 53/500 [35:35<4:49:31, 38.86s/it] 11%|█         | 54/500 [36:24<5:11:47, 41.94s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 4.00E+05, Train scatter: [0.9207 0.1153 0.5414 0.7279]
L1 regularization loss: 3.15E+00, L2 regularization loss: 1.46E+00
Test scatter: [0.9052 0.1138 0.5329 0.723 ], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.9075 0.1171 0.5329 0.7365], Epochs since improvement 18
 11%|█         | 55/500 [36:56<4:47:34, 38.77s/it] 11%|█         | 56/500 [37:45<5:09:30, 41.83s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.52E+05, Train scatter: [0.921  0.1158 0.5403 0.7352]
L1 regularization loss: 3.16E+00, L2 regularization loss: 1.55E+00
Test scatter: [0.9055 0.1155 0.5319 0.7315], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.906  0.1155 0.5329 0.7315], Epochs since improvement 20
 11%|█▏        | 57/500 [38:16<4:45:40, 38.69s/it] 11%|█▏        | 57/500 [39:05<5:03:47, 41.14s/it]
Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.20E+05, Train scatter: [0.9192 0.1167 0.5368 0.7483]
L1 regularization loss: 3.16E+00, L2 regularization loss: 1.66E+00
Test scatter: [0.9037 0.1144 0.5287 0.7458], Lowest was [0.3429 0.0717 0.2919 0.4941]
Median for last 10 epochs: [0.9055 0.1144 0.5329 0.7315], Epochs since improvement 22
Exited after 58 epochs due to early stopping
2346.56 seconds spent training, 4.693 seconds per epoch. Processed 14838 trees per second
[0.9037102  0.11440678 0.5286646  0.7457496 ]
{'epoch_exit': 57, 'scatter_m_star': 0.9037102, 'lowest_m_star': 0.34289694, 'last20_m_star': 0.90535355, 'last10_m_star': 0.9055354, 'scatter_v_disk': 0.11440678, 'lowest_v_disk': 0.07168121, 'last20_v_disk': 0.11495755, 'last10_v_disk': 0.114410244, 'scatter_m_cold': 0.5286646, 'lowest_m_cold': 0.29185987, 'last20_m_cold': 0.5322726, 'last10_m_cold': 0.53294945, 'scatter_sfr_100': 0.7457496, 'lowest_sfr_100': 0.49408212, 'last20_sfr_100': 0.76105446, 'last10_sfr_100': 0.73152566}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_xxgucf
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:54:18, 28.17s/it]  0%|          | 2/500 [01:13<5:16:18, 38.11s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.37E+07, Train scatter: [0.9353 0.1634 0.5442 0.9954]
L1 regularization loss: 1.51E+00, L2 regularization loss: 3.26E-01
Test scatter: [0.9197 0.1656 0.5356 0.9851], Lowest was [0.9197 0.1656 0.5356 0.9851]
Median for last 10 epochs: [0.9197 0.1656 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:40<4:34:47, 33.17s/it]  1%|          | 4/500 [02:26<5:16:31, 38.29s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.23E+07, Train scatter: [0.9353 0.1737 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.31E-01
Test scatter: [0.9197 0.1743 0.5355 0.9851], Lowest was [0.9197 0.1656 0.5355 0.9851]
Median for last 10 epochs: [0.9197 0.17   0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:53<4:43:04, 34.31s/it]  1%|          | 6/500 [03:40<5:16:02, 38.39s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.85E+06, Train scatter: [0.9352 0.1731 0.5441 0.9954]
L1 regularization loss: 1.53E+00, L2 regularization loss: 3.43E-01
Test scatter: [0.9196 0.1694 0.5356 0.9851], Lowest was [0.9196 0.1656 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1694 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:07<4:45:18, 34.72s/it]  2%|▏         | 8/500 [04:53<5:13:45, 38.26s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.66E+06, Train scatter: [0.9352 0.1508 0.5441 0.9952]
L1 regularization loss: 1.55E+00, L2 regularization loss: 3.64E-01
Test scatter: [0.9196 0.1458 0.5355 0.9848], Lowest was [0.9196 0.1458 0.5355 0.9848]
Median for last 10 epochs: [0.9196 0.1576 0.5355 0.9849], Epochs since improvement 0
  2%|▏         | 9/500 [05:20<4:45:08, 34.84s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.07E+06, Train scatter: [0.9351 0.1393 0.5441 0.7179]
L1 regularization loss: 1.58E+00, L2 regularization loss: 3.92E-01
Test scatter: [0.9195 0.1359 0.5355 0.7314], Lowest was [0.9195 0.1359 0.5355 0.7314]
Median for last 10 epochs: [0.9196 0.1458 0.5355 0.9848], Epochs since improvement 0
  2%|▏         | 10/500 [06:11<5:24:43, 39.76s/it]  2%|▏         | 11/500 [06:38<4:53:19, 35.99s/it]  2%|▏         | 12/500 [07:24<5:15:56, 38.85s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.65E+06, Train scatter: [0.9334 0.1311 0.5441 0.6651]
L1 regularization loss: 1.59E+00, L2 regularization loss: 4.03E-01
Test scatter: [0.9177 0.126  0.5355 0.6557], Lowest was [0.9177 0.126  0.5355 0.6557]
Median for last 10 epochs: [0.9196 0.1458 0.5355 0.9848], Epochs since improvement 0
  3%|▎         | 13/500 [07:51<4:47:31, 35.42s/it]  3%|▎         | 14/500 [08:37<5:12:05, 38.53s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.23E+06, Train scatter: [0.9115 0.1194 0.5437 0.6343]
L1 regularization loss: 1.60E+00, L2 regularization loss: 4.09E-01
Test scatter: [0.8953 0.1143 0.5351 0.621 ], Lowest was [0.8953 0.1143 0.5351 0.621 ]
Median for last 10 epochs: [0.9195 0.1359 0.5355 0.7314], Epochs since improvement 0
  3%|▎         | 15/500 [09:04<4:44:23, 35.18s/it]  3%|▎         | 16/500 [09:49<5:05:52, 37.92s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.37E+06, Train scatter: [0.7337 0.1125 0.5413 0.5935]
L1 regularization loss: 1.62E+00, L2 regularization loss: 4.18E-01
Test scatter: [0.7208 0.1104 0.5326 0.5922], Lowest was [0.7208 0.1104 0.5326 0.5922]
Median for last 10 epochs: [0.9177 0.126  0.5355 0.6557], Epochs since improvement 0
  3%|▎         | 17/500 [10:16<4:39:12, 34.68s/it]  4%|▎         | 18/500 [11:01<5:04:03, 37.85s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 5.79E+06, Train scatter: [0.5602 0.1043 0.5374 0.5815]
L1 regularization loss: 1.63E+00, L2 regularization loss: 4.27E-01
Test scatter: [0.5995 0.1049 0.5291 0.5834], Lowest was [0.5995 0.1049 0.5291 0.5834]
Median for last 10 epochs: [0.8953 0.1143 0.5351 0.621 ], Epochs since improvement 0
  4%|▍         | 19/500 [11:28<4:38:03, 34.69s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.39E+06, Train scatter: [0.4629 0.0994 0.5342 0.5754]
L1 regularization loss: 1.65E+00, L2 regularization loss: 4.35E-01
Test scatter: [0.4645 0.0977 0.5253 0.574 ], Lowest was [0.4645 0.0977 0.5253 0.574 ]
Median for last 10 epochs: [0.7208 0.1104 0.5326 0.5922], Epochs since improvement 0
  4%|▍         | 20/500 [12:20<5:17:57, 39.75s/it]  4%|▍         | 21/500 [12:47<4:47:55, 36.07s/it]  4%|▍         | 22/500 [13:34<5:11:50, 39.14s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.05E+06, Train scatter: [0.5382 0.0984 0.5324 0.6589]
L1 regularization loss: 1.66E+00, L2 regularization loss: 4.44E-01
Test scatter: [0.5583 0.0965 0.5228 0.6628], Lowest was [0.4645 0.0965 0.5228 0.574 ]
Median for last 10 epochs: [0.5995 0.1049 0.5291 0.5922], Epochs since improvement 0
  5%|▍         | 23/500 [14:01<4:42:58, 35.59s/it]  5%|▍         | 24/500 [14:47<5:06:36, 38.65s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.50E+06, Train scatter: [0.7315 0.1042 0.5395 0.7648]
L1 regularization loss: 1.68E+00, L2 regularization loss: 4.55E-01
Test scatter: [0.7521 0.1028 0.5289 0.7742], Lowest was [0.4645 0.0965 0.5228 0.574 ]
Median for last 10 epochs: [0.5995 0.1028 0.5289 0.5922], Epochs since improvement 2
  5%|▌         | 25/500 [15:14<4:39:20, 35.29s/it]  5%|▌         | 26/500 [16:00<5:03:20, 38.40s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.48E+06, Train scatter: [0.5355 0.1026 0.4088 0.632 ]
L1 regularization loss: 1.70E+00, L2 regularization loss: 4.68E-01
Test scatter: [0.5501 0.1014 0.4105 0.6338], Lowest was [0.4645 0.0965 0.4105 0.574 ]
Median for last 10 epochs: [0.5583 0.1014 0.5253 0.6338], Epochs since improvement 0
  5%|▌         | 27/500 [16:28<4:37:29, 35.20s/it]  6%|▌         | 28/500 [17:14<5:03:23, 38.57s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.31E+06, Train scatter: [0.5696 0.0903 0.3628 0.5835]
L1 regularization loss: 1.72E+00, L2 regularization loss: 4.76E-01
Test scatter: [0.5649 0.0909 0.3632 0.5886], Lowest was [0.4645 0.0909 0.3632 0.574 ]
Median for last 10 epochs: [0.5583 0.0977 0.5228 0.6338], Epochs since improvement 0
  6%|▌         | 29/500 [17:41<4:36:11, 35.18s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.07E+06, Train scatter: [0.5103 0.0886 0.3599 0.5712]
L1 regularization loss: 1.74E+00, L2 regularization loss: 4.86E-01
Test scatter: [0.526  0.0887 0.3588 0.5732], Lowest was [0.4645 0.0887 0.3588 0.5732]
Median for last 10 epochs: [0.5583 0.0965 0.4105 0.6338], Epochs since improvement 0
  6%|▌         | 30/500 [18:34<5:16:00, 40.34s/it]  6%|▌         | 31/500 [19:01<4:44:33, 36.40s/it]  6%|▋         | 32/500 [19:47<5:06:51, 39.34s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 1.93E+06, Train scatter: [0.4725 0.0866 0.3522 0.5637]
L1 regularization loss: 1.85E+00, L2 regularization loss: 5.36E-01
Test scatter: [0.4739 0.0867 0.348  0.5614], Lowest was [0.4645 0.0867 0.348  0.5614]
Median for last 10 epochs: [0.5501 0.0909 0.3632 0.5886], Epochs since improvement 0
  7%|▋         | 33/500 [20:14<4:38:16, 35.75s/it]  7%|▋         | 34/500 [21:00<5:01:13, 38.78s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 1.83E+06, Train scatter: [0.5114 0.0867 0.3595 0.554 ]
L1 regularization loss: 1.88E+00, L2 regularization loss: 5.54E-01
Test scatter: [0.5121 0.0868 0.3571 0.552 ], Lowest was [0.4645 0.0867 0.348  0.552 ]
Median for last 10 epochs: [0.526  0.0887 0.3588 0.5732], Epochs since improvement 0
  7%|▋         | 35/500 [21:28<4:34:32, 35.42s/it]  7%|▋         | 36/500 [22:15<5:00:05, 38.80s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 1.54E+06, Train scatter: [0.4962 0.0825 0.3507 0.5948]
L1 regularization loss: 1.90E+00, L2 regularization loss: 5.71E-01
Test scatter: [0.4894 0.082  0.3506 0.5955], Lowest was [0.4645 0.082  0.348  0.552 ]
Median for last 10 epochs: [0.5121 0.0868 0.3571 0.5732], Epochs since improvement 0
  7%|▋         | 37/500 [22:42<4:33:10, 35.40s/it]  8%|▊         | 38/500 [23:29<4:59:35, 38.91s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.48E+06, Train scatter: [0.4618 0.0825 0.3273 0.54  ]
L1 regularization loss: 1.92E+00, L2 regularization loss: 5.87E-01
Test scatter: [0.4542 0.083  0.3256 0.5424], Lowest was [0.4542 0.082  0.3256 0.5424]
Median for last 10 epochs: [0.4894 0.0867 0.3506 0.5614], Epochs since improvement 0
  8%|▊         | 39/500 [23:56<4:32:10, 35.42s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.54E+06, Train scatter: [0.5481 0.0824 0.3439 0.5678]
L1 regularization loss: 1.94E+00, L2 regularization loss: 6.03E-01
Test scatter: [0.5363 0.0831 0.3423 0.5644], Lowest was [0.4542 0.082  0.3256 0.5424]
Median for last 10 epochs: [0.4894 0.0831 0.348  0.5614], Epochs since improvement 2
  8%|▊         | 40/500 [24:48<5:09:11, 40.33s/it]  8%|▊         | 41/500 [25:16<4:38:33, 36.41s/it]  8%|▊         | 42/500 [26:02<4:59:58, 39.30s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.36E+06, Train scatter: [0.5149 0.0834 0.3172 0.5528]
L1 regularization loss: 1.96E+00, L2 regularization loss: 6.21E-01
Test scatter: [0.515  0.0842 0.3214 0.5558], Lowest was [0.4542 0.082  0.3214 0.5424]
Median for last 10 epochs: [0.5121 0.0831 0.3423 0.5558], Epochs since improvement 0
  9%|▊         | 43/500 [26:29<4:31:59, 35.71s/it]  9%|▉         | 44/500 [27:15<4:56:07, 38.96s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.25E+06, Train scatter: [0.5057 0.0795 0.3122 0.5406]
L1 regularization loss: 1.99E+00, L2 regularization loss: 6.40E-01
Test scatter: [0.5029 0.0796 0.3115 0.546 ], Lowest was [0.4542 0.0796 0.3115 0.5424]
Median for last 10 epochs: [0.5029 0.083  0.3256 0.5558], Epochs since improvement 0
  9%|▉         | 45/500 [27:43<4:29:13, 35.50s/it]  9%|▉         | 46/500 [28:29<4:53:44, 38.82s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.31E+06, Train scatter: [0.4439 0.0757 0.319  0.5219]
L1 regularization loss: 2.03E+00, L2 regularization loss: 6.68E-01
Test scatter: [0.4439 0.0767 0.3207 0.5214], Lowest was [0.4439 0.0767 0.3115 0.5214]
Median for last 10 epochs: [0.5029 0.083  0.3214 0.546 ], Epochs since improvement 0
  9%|▉         | 47/500 [28:57<4:27:14, 35.40s/it] 10%|▉         | 48/500 [29:43<4:51:26, 38.69s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.10E+06, Train scatter: [0.5205 0.0741 0.305  0.5286]
L1 regularization loss: 2.05E+00, L2 regularization loss: 6.91E-01
Test scatter: [0.5067 0.0756 0.3074 0.5244], Lowest was [0.4439 0.0756 0.3074 0.5214]
Median for last 10 epochs: [0.5067 0.0796 0.3207 0.546 ], Epochs since improvement 0
 10%|▉         | 49/500 [30:11<4:25:41, 35.35s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.31E+06, Train scatter: [0.3986 0.0772 0.3048 0.5227]
L1 regularization loss: 2.08E+00, L2 regularization loss: 7.16E-01
Test scatter: [0.4001 0.0778 0.3069 0.5224], Lowest was [0.4001 0.0756 0.3069 0.5214]
Median for last 10 epochs: [0.5029 0.0778 0.3115 0.5244], Epochs since improvement 0
 10%|█         | 50/500 [31:03<5:02:24, 40.32s/it] 10%|█         | 51/500 [31:30<4:33:08, 36.50s/it] 10%|█         | 52/500 [32:17<4:55:22, 39.56s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.05E+06, Train scatter: [0.3487 0.0735 0.2996 0.5045]
L1 regularization loss: 2.10E+00, L2 regularization loss: 7.37E-01
Test scatter: [0.3608 0.0751 0.3012 0.502 ], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.4439 0.0767 0.3074 0.5224], Epochs since improvement 0
 11%|█         | 53/500 [32:44<4:27:08, 35.86s/it] 11%|█         | 54/500 [33:31<4:49:57, 39.01s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 9.99E+06, Train scatter: [0.9274 0.1665 0.5438 0.8288]
L1 regularization loss: 2.87E+00, L2 regularization loss: 1.08E+00
Test scatter: [0.9124 0.1642 0.5353 0.8239], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.4439 0.0767 0.3074 0.5224], Epochs since improvement 2
 11%|█         | 55/500 [33:58<4:23:33, 35.54s/it] 11%|█         | 56/500 [34:45<4:48:38, 39.01s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 6.17E+06, Train scatter: [0.9064 0.1554 0.5436 0.7954]
L1 regularization loss: 2.88E+00, L2 regularization loss: 1.12E+00
Test scatter: [0.8927 0.1538 0.5351 0.7926], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.5067 0.0778 0.3074 0.5244], Epochs since improvement 4
 11%|█▏        | 57/500 [35:12<4:22:19, 35.53s/it] 12%|█▏        | 58/500 [36:00<4:47:23, 39.01s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 4.58E+06, Train scatter: [0.828  0.1452 0.5431 0.7728]
L1 regularization loss: 2.90E+00, L2 regularization loss: 1.18E+00
Test scatter: [0.8192 0.1441 0.5346 0.7687], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.8192 0.1441 0.5346 0.7687], Epochs since improvement 6
 12%|█▏        | 59/500 [36:27<4:21:14, 35.54s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.90E+06, Train scatter: [0.6748 0.1382 0.5314 0.7608]
L1 regularization loss: 2.93E+00, L2 regularization loss: 1.28E+00
Test scatter: [0.6683 0.1365 0.5236 0.764 ], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.8192 0.1441 0.5346 0.7687], Epochs since improvement 8
 12%|█▏        | 60/500 [37:19<4:57:17, 40.54s/it] 12%|█▏        | 61/500 [37:47<4:28:03, 36.64s/it] 12%|█▏        | 62/500 [38:35<4:51:47, 39.97s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.39E+06, Train scatter: [0.6213 0.1338 0.5132 0.7396]
L1 regularization loss: 2.94E+00, L2 regularization loss: 1.32E+00
Test scatter: [0.6183 0.1322 0.5078 0.7391], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.8192 0.1441 0.5346 0.7687], Epochs since improvement 10
 13%|█▎        | 63/500 [39:02<4:23:53, 36.23s/it] 13%|█▎        | 64/500 [39:48<4:45:25, 39.28s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.07E+06, Train scatter: [0.548  0.1283 0.5017 0.7213]
L1 regularization loss: 2.95E+00, L2 regularization loss: 1.36E+00
Test scatter: [0.5567 0.1268 0.52   0.7189], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.6683 0.1365 0.5236 0.764 ], Epochs since improvement 12
 13%|█▎        | 65/500 [40:16<4:19:05, 35.74s/it] 13%|█▎        | 66/500 [41:02<4:41:35, 38.93s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.86E+06, Train scatter: [0.5235 0.1245 0.4989 0.7138]
L1 regularization loss: 2.96E+00, L2 regularization loss: 1.40E+00
Test scatter: [0.5326 0.1235 0.4997 0.7127], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.6183 0.1322 0.52   0.7391], Epochs since improvement 14
 13%|█▎        | 67/500 [41:30<4:15:48, 35.45s/it] 14%|█▎        | 68/500 [42:17<4:41:05, 39.04s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.74E+06, Train scatter: [0.5032 0.1215 0.4972 0.6924]
L1 regularization loss: 2.97E+00, L2 regularization loss: 1.45E+00
Test scatter: [0.513  0.121  0.4984 0.6869], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.5567 0.1268 0.5078 0.7189], Epochs since improvement 16
 14%|█▍        | 69/500 [42:45<4:15:34, 35.58s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.49E+06, Train scatter: [0.4814 0.1179 0.4636 0.6747]
L1 regularization loss: 2.98E+00, L2 regularization loss: 1.48E+00
Test scatter: [0.4907 0.1179 0.4659 0.6767], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.5326 0.1235 0.4997 0.7127], Epochs since improvement 18
 14%|█▍        | 70/500 [43:37<4:50:11, 40.49s/it] 14%|█▍        | 71/500 [44:04<4:21:26, 36.57s/it] 14%|█▍        | 72/500 [44:51<4:42:42, 39.63s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 2.30E+06, Train scatter: [0.4859 0.1155 0.4505 0.6716]
L1 regularization loss: 2.99E+00, L2 regularization loss: 1.53E+00
Test scatter: [0.4955 0.1159 0.4542 0.6696], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.513  0.121  0.4984 0.6869], Epochs since improvement 20
 15%|█▍        | 73/500 [45:18<4:15:52, 35.96s/it] 15%|█▍        | 73/500 [46:05<4:29:33, 37.88s/it]
Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.09E+06, Train scatter: [0.4733 0.1122 0.4792 0.6574]
L1 regularization loss: 3.00E+00, L2 regularization loss: 1.56E+00
Test scatter: [0.4801 0.1127 0.4852 0.6615], Lowest was [0.3608 0.0751 0.3012 0.502 ]
Median for last 10 epochs: [0.4955 0.1179 0.4852 0.6767], Epochs since improvement 22
Exited after 74 epochs due to early stopping
2765.10 seconds spent training, 5.530 seconds per epoch. Processed 12592 trees per second
[0.48006135 0.11265638 0.48517367 0.6615229 ]
{'epoch_exit': 73, 'scatter_m_star': 0.48006135, 'lowest_m_star': 0.360754, 'last20_m_star': 0.5446402, 'last10_m_star': 0.4955142, 'scatter_v_disk': 0.112656385, 'lowest_v_disk': 0.07514416, 'last20_v_disk': 0.12514296, 'last10_v_disk': 0.11792267, 'scatter_m_cold': 0.48517367, 'lowest_m_cold': 0.30120423, 'last20_m_cold': 0.5037419, 'last10_m_cold': 0.4851883, 'scatter_sfr_100': 0.6615229, 'lowest_sfr_100': 0.5019814, 'last20_sfr_100': 0.715767, 'last10_sfr_100': 0.6766841}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_kafmsx
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:47<6:35:23, 47.54s/it]  0%|          | 2/500 [01:58<8:28:43, 61.29s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.30E+07, Train scatter: [0.9351 0.1374 0.544  0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.83E-01
Test scatter: [0.9195 0.135  0.5354 0.9851], Lowest was [0.9195 0.135  0.5354 0.9851]
Median for last 10 epochs: [0.9195 0.135  0.5354 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:45<7:33:39, 54.77s/it]  1%|          | 4/500 [03:56<8:25:50, 61.19s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.49E+07, Train scatter: [0.9311 0.0983 0.544  0.995 ]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.11E-01
Test scatter: [0.9154 0.0971 0.5354 0.9847], Lowest was [0.9154 0.0971 0.5354 0.9847]
Median for last 10 epochs: [0.9154 0.0971 0.5354 0.9847], Epochs since improvement 0
  1%|          | 5/500 [04:43<7:42:04, 56.01s/it]  1%|          | 6/500 [05:54<8:23:22, 61.14s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.66E+06, Train scatter: [0.8361 0.0941 0.5439 0.641 ]
L1 regularization loss: 2.06E+00, L2 regularization loss: 4.54E-01
Test scatter: [0.8231 0.0948 0.5353 0.636 ], Lowest was [0.8231 0.0948 0.5353 0.636 ]
Median for last 10 epochs: [0.8231 0.0948 0.5353 0.636 ], Epochs since improvement 0
  1%|▏         | 7/500 [06:41<7:44:02, 56.47s/it]  2%|▏         | 8/500 [07:52<8:21:04, 61.11s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 5.66E+06, Train scatter: [0.5418 0.0784 0.5439 0.5727]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.73E-01
Test scatter: [0.537  0.0782 0.5353 0.5691], Lowest was [0.537  0.0782 0.5353 0.5691]
Median for last 10 epochs: [0.6801 0.0865 0.5353 0.6025], Epochs since improvement 0
  2%|▏         | 9/500 [08:39<7:44:01, 56.70s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.04E+06, Train scatter: [0.369  0.0714 0.5439 0.5256]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.84E-01
Test scatter: [0.3744 0.0708 0.5353 0.5221], Lowest was [0.3744 0.0708 0.5353 0.5221]
Median for last 10 epochs: [0.537  0.0782 0.5353 0.5691], Epochs since improvement 0
  2%|▏         | 10/500 [09:57<8:36:29, 63.24s/it]  2%|▏         | 11/500 [10:44<7:54:54, 58.27s/it]  2%|▏         | 12/500 [11:55<8:26:37, 62.29s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 3.55E+06, Train scatter: [0.2651 0.0717 0.5438 0.5249]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.91E-01
Test scatter: [0.2677 0.0714 0.5353 0.5209], Lowest was [0.2677 0.0708 0.5353 0.5209]
Median for last 10 epochs: [0.537  0.0782 0.5353 0.5691], Epochs since improvement 0
  3%|▎         | 13/500 [12:42<7:48:02, 57.66s/it]  3%|▎         | 14/500 [13:54<8:22:34, 62.05s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 3.37E+06, Train scatter: [0.2606 0.072  0.5437 0.5174]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.96E-01
Test scatter: [0.267  0.0732 0.5352 0.5153], Lowest was [0.267  0.0708 0.5352 0.5153]
Median for last 10 epochs: [0.3744 0.0732 0.5353 0.5221], Epochs since improvement 0
  3%|▎         | 15/500 [14:41<7:44:38, 57.48s/it]  3%|▎         | 16/500 [15:53<8:18:54, 61.85s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.30E+06, Train scatter: [0.2346 0.0695 0.5436 0.5129]
L1 regularization loss: 2.11E+00, L2 regularization loss: 5.00E-01
Test scatter: [0.2389 0.0701 0.5351 0.5098], Lowest was [0.2389 0.0701 0.5351 0.5098]
Median for last 10 epochs: [0.2677 0.0714 0.5353 0.5209], Epochs since improvement 0
  3%|▎         | 17/500 [16:40<7:41:54, 57.38s/it]  4%|▎         | 18/500 [17:52<8:16:00, 61.74s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.24E+06, Train scatter: [0.2564 0.0727 0.5436 0.5161]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.03E-01
Test scatter: [0.2619 0.074  0.535  0.5128], Lowest was [0.2389 0.0701 0.535  0.5098]
Median for last 10 epochs: [0.267  0.0714 0.5352 0.5153], Epochs since improvement 0
  4%|▍         | 19/500 [18:39<7:39:33, 57.33s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.20E+06, Train scatter: [0.2591 0.0667 0.5435 0.5043]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.07E-01
Test scatter: [0.2589 0.0663 0.5349 0.5007], Lowest was [0.2389 0.0663 0.5349 0.5007]
Median for last 10 epochs: [0.2619 0.0714 0.5351 0.5128], Epochs since improvement 0
  4%|▍         | 20/500 [19:58<8:30:30, 63.81s/it]  4%|▍         | 21/500 [20:45<7:48:47, 58.72s/it]  4%|▍         | 22/500 [21:57<8:20:09, 62.78s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.05E+06, Train scatter: [0.2174 0.0663 0.5434 0.5252]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.12E-01
Test scatter: [0.223  0.067  0.5349 0.5214], Lowest was [0.223  0.0663 0.5349 0.5007]
Median for last 10 epochs: [0.2589 0.0701 0.535  0.5128], Epochs since improvement 0
  5%|▍         | 23/500 [22:44<7:41:35, 58.06s/it]  5%|▍         | 24/500 [23:56<8:13:22, 62.19s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.01E+06, Train scatter: [0.1918 0.0636 0.5433 0.5006]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.16E-01
Test scatter: [0.1979 0.0632 0.5348 0.4922], Lowest was [0.1979 0.0632 0.5348 0.4922]
Median for last 10 epochs: [0.2389 0.067  0.5349 0.5098], Epochs since improvement 0
  5%|▌         | 25/500 [24:43<7:35:41, 57.56s/it]  5%|▌         | 26/500 [25:54<8:07:40, 61.73s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 2.95E+06, Train scatter: [0.2477 0.0703 0.5433 0.5189]
L1 regularization loss: 2.17E+00, L2 regularization loss: 5.23E-01
Test scatter: [0.2534 0.0705 0.5348 0.5174], Lowest was [0.1979 0.0632 0.5348 0.4922]
Median for last 10 epochs: [0.2534 0.067  0.5349 0.5128], Epochs since improvement 0
  5%|▌         | 27/500 [26:41<7:31:27, 57.27s/it]  6%|▌         | 28/500 [27:53<8:04:34, 61.60s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.90E+06, Train scatter: [0.333  0.074  0.5432 0.5918]
L1 regularization loss: 2.18E+00, L2 regularization loss: 5.28E-01
Test scatter: [0.3293 0.0746 0.5347 0.5965], Lowest was [0.1979 0.0632 0.5347 0.4922]
Median for last 10 epochs: [0.2534 0.067  0.5348 0.5174], Epochs since improvement 0
  6%|▌         | 29/500 [28:40<7:28:55, 57.19s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.87E+06, Train scatter: [0.2644 0.064  0.543  0.4938]
L1 regularization loss: 2.20E+00, L2 regularization loss: 5.35E-01
Test scatter: [0.2586 0.064  0.5345 0.4889], Lowest was [0.1979 0.0632 0.5345 0.4889]
Median for last 10 epochs: [0.2534 0.067  0.5348 0.5174], Epochs since improvement 0
  6%|▌         | 30/500 [29:59<8:20:32, 63.90s/it]  6%|▌         | 31/500 [30:46<7:38:59, 58.72s/it]  6%|▋         | 32/500 [31:57<8:07:42, 62.53s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.84E+06, Train scatter: [0.321  0.078  0.5431 0.5704]
L1 regularization loss: 2.21E+00, L2 regularization loss: 5.43E-01
Test scatter: [0.3248 0.0804 0.5346 0.575 ], Lowest was [0.1979 0.0632 0.5345 0.4889]
Median for last 10 epochs: [0.2586 0.0705 0.5347 0.5174], Epochs since improvement 2
  7%|▋         | 33/500 [32:44<7:30:09, 57.84s/it]  7%|▋         | 34/500 [33:55<8:00:03, 61.81s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.82E+06, Train scatter: [0.2512 0.063  0.5428 0.5147]
L1 regularization loss: 2.25E+00, L2 regularization loss: 5.54E-01
Test scatter: [0.2559 0.0632 0.5343 0.5119], Lowest was [0.1979 0.0632 0.5343 0.4889]
Median for last 10 epochs: [0.2586 0.0705 0.5346 0.5174], Epochs since improvement 0
  7%|▋         | 35/500 [34:42<7:24:04, 57.30s/it]  7%|▋         | 36/500 [35:54<7:55:45, 61.52s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.81E+06, Train scatter: [0.285  0.059  0.5427 0.4917]
L1 regularization loss: 2.26E+00, L2 regularization loss: 5.62E-01
Test scatter: [0.2831 0.0592 0.5342 0.4878], Lowest was [0.1979 0.0592 0.5342 0.4878]
Median for last 10 epochs: [0.2831 0.064  0.5345 0.5119], Epochs since improvement 0
  7%|▋         | 37/500 [36:40<7:20:53, 57.13s/it]  8%|▊         | 38/500 [37:52<7:52:28, 61.36s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.80E+06, Train scatter: [0.2088 0.0604 0.5424 0.4861]
L1 regularization loss: 2.28E+00, L2 regularization loss: 5.73E-01
Test scatter: [0.2154 0.0607 0.5339 0.4808], Lowest was [0.1979 0.0592 0.5339 0.4808]
Median for last 10 epochs: [0.2586 0.0632 0.5343 0.4889], Epochs since improvement 0
  8%|▊         | 39/500 [38:38<7:17:50, 56.99s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.87E+06, Train scatter: [0.3974 0.0845 0.543  0.5201]
L1 regularization loss: 2.44E+00, L2 regularization loss: 6.30E-01
Test scatter: [0.3991 0.0841 0.5345 0.5144], Lowest was [0.1979 0.0592 0.5339 0.4808]
Median for last 10 epochs: [0.2831 0.0632 0.5343 0.5119], Epochs since improvement 2
  8%|▊         | 40/500 [39:57<8:06:43, 63.48s/it]  8%|▊         | 41/500 [40:44<7:27:29, 58.49s/it]  8%|▊         | 42/500 [41:55<7:55:34, 62.30s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.79E+06, Train scatter: [0.2041 0.0668 0.5419 0.4903]
L1 regularization loss: 2.48E+00, L2 regularization loss: 6.65E-01
Test scatter: [0.2094 0.0665 0.5335 0.488 ], Lowest was [0.1979 0.0592 0.5335 0.4808]
Median for last 10 epochs: [0.2559 0.0632 0.5342 0.488 ], Epochs since improvement 0
  9%|▊         | 43/500 [42:42<7:19:13, 57.67s/it]  9%|▉         | 44/500 [43:54<7:50:45, 61.94s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.76E+06, Train scatter: [0.27   0.0664 0.541  0.529 ]
L1 regularization loss: 2.52E+00, L2 regularization loss: 6.94E-01
Test scatter: [0.2757 0.0676 0.5326 0.5344], Lowest was [0.1979 0.0592 0.5326 0.4808]
Median for last 10 epochs: [0.2757 0.0665 0.5339 0.488 ], Epochs since improvement 0
  9%|▉         | 45/500 [44:41<7:15:15, 57.40s/it]  9%|▉         | 46/500 [45:52<7:45:45, 61.55s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.27E+06, Train scatter: [0.6424 0.1179 0.5439 0.735 ]
L1 regularization loss: 2.71E+00, L2 regularization loss: 7.84E-01
Test scatter: [0.6477 0.1187 0.5353 0.7353], Lowest was [0.1979 0.0592 0.5326 0.4808]
Median for last 10 epochs: [0.2757 0.0676 0.5339 0.5144], Epochs since improvement 2
  9%|▉         | 47/500 [46:39<7:11:24, 57.14s/it] 10%|▉         | 48/500 [47:51<7:43:59, 61.59s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.93E+06, Train scatter: [0.4489 0.085  0.5432 0.5443]
L1 regularization loss: 2.72E+00, L2 regularization loss: 8.10E-01
Test scatter: [0.4413 0.0837 0.5347 0.5371], Lowest was [0.1979 0.0592 0.5326 0.4808]
Median for last 10 epochs: [0.3991 0.0837 0.5345 0.5344], Epochs since improvement 4
 10%|▉         | 49/500 [48:38<7:10:04, 57.22s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.76E+06, Train scatter: [0.3844 0.0751 0.5427 0.5253]
L1 regularization loss: 2.74E+00, L2 regularization loss: 8.37E-01
Test scatter: [0.3741 0.0737 0.5343 0.5225], Lowest was [0.1979 0.0592 0.5326 0.4808]
Median for last 10 epochs: [0.3741 0.0737 0.5343 0.5344], Epochs since improvement 6
 10%|█         | 50/500 [49:56<7:55:28, 63.40s/it] 10%|█         | 51/500 [50:42<7:17:16, 58.43s/it] 10%|█         | 52/500 [51:54<7:45:37, 62.36s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 2.73E+06, Train scatter: [0.4561 0.069  0.5415 0.507 ]
L1 regularization loss: 2.75E+00, L2 regularization loss: 8.60E-01
Test scatter: [0.44   0.0689 0.5331 0.5048], Lowest was [0.1979 0.0592 0.5326 0.4808]
Median for last 10 epochs: [0.44   0.0737 0.5343 0.5344], Epochs since improvement 8
 11%|█         | 53/500 [52:41<7:09:59, 57.72s/it] 11%|█         | 54/500 [53:51<7:37:46, 61.58s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.69E+06, Train scatter: [0.2596 0.0687 0.539  0.505 ]
L1 regularization loss: 2.76E+00, L2 regularization loss: 8.84E-01
Test scatter: [0.2663 0.0685 0.5306 0.503 ], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.44   0.0737 0.5343 0.5225], Epochs since improvement 0
 11%|█         | 55/500 [54:38<7:04:24, 57.22s/it] 11%|█         | 56/500 [55:49<7:32:26, 61.14s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.91E+06, Train scatter: [0.4093 0.0979 0.5428 0.5813]
L1 regularization loss: 2.85E+00, L2 regularization loss: 9.61E-01
Test scatter: [0.4035 0.0947 0.5343 0.5738], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.4035 0.0737 0.5343 0.5225], Epochs since improvement 2
 11%|█▏        | 57/500 [56:36<6:59:41, 56.84s/it] 12%|█▏        | 58/500 [57:46<7:29:42, 61.05s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.38E+05, Train scatter: [0.9352 0.1728 0.5441 0.9955]
L1 regularization loss: 8.24E+00, L2 regularization loss: 2.95E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.4035 0.0737 0.5343 0.5225], Epochs since improvement 4
 12%|█▏        | 59/500 [58:33<6:57:47, 56.84s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.46E+05, Train scatter: [0.9352 0.1729 0.5441 0.9958]
L1 regularization loss: 8.24E+00, L2 regularization loss: 3.11E+00
Test scatter: [0.9196 0.169  0.5355 0.9854], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.44   0.0947 0.5343 0.5738], Epochs since improvement 6
 12%|█▏        | 60/500 [59:52<7:44:13, 63.30s/it] 12%|█▏        | 61/500 [1:00:39<7:07:37, 58.45s/it] 12%|█▏        | 62/500 [1:01:50<7:34:37, 62.28s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.11E+05, Train scatter: [0.9351 0.1728 0.5441 0.9953]
L1 regularization loss: 8.24E+00, L2 regularization loss: 3.17E+00
Test scatter: [0.9195 0.1689 0.5355 0.985 ], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.9195 0.1689 0.5355 0.985 ], Epochs since improvement 8
 13%|█▎        | 63/500 [1:02:37<7:00:01, 57.67s/it] 13%|█▎        | 64/500 [1:03:49<7:29:17, 61.83s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 9.48E+04, Train scatter: [0.9351 0.1728 0.5441 0.9952]
L1 regularization loss: 8.23E+00, L2 regularization loss: 3.18E+00
Test scatter: [0.9195 0.1689 0.5355 0.9849], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.9195 0.1689 0.5355 0.985 ], Epochs since improvement 10
 13%|█▎        | 65/500 [1:04:36<6:55:49, 57.35s/it] 13%|█▎        | 66/500 [1:05:46<7:23:01, 61.25s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 6.98E+04, Train scatter: [0.935  0.1727 0.5441 0.995 ]
L1 regularization loss: 8.21E+00, L2 regularization loss: 3.19E+00
Test scatter: [0.9194 0.1689 0.5355 0.9847], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.9195 0.1689 0.5355 0.985 ], Epochs since improvement 12
 13%|█▎        | 67/500 [1:06:33<6:51:14, 56.99s/it] 14%|█▎        | 68/500 [1:07:44<7:20:44, 61.21s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 5.95E+04, Train scatter: [0.9349 0.1727 0.5441 0.9947]
L1 regularization loss: 8.20E+00, L2 regularization loss: 3.21E+00
Test scatter: [0.9193 0.1688 0.5355 0.9844], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.9195 0.1689 0.5355 0.9849], Epochs since improvement 14
 14%|█▍        | 69/500 [1:08:31<6:48:55, 56.93s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 5.28E+04, Train scatter: [0.9346 0.1726 0.5441 0.9921]
L1 regularization loss: 8.19E+00, L2 regularization loss: 3.25E+00
Test scatter: [0.919  0.1687 0.5355 0.9818], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.9194 0.1689 0.5355 0.9847], Epochs since improvement 16
 14%|█▍        | 70/500 [1:09:49<7:33:39, 63.30s/it] 14%|█▍        | 71/500 [1:10:36<6:58:03, 58.47s/it] 14%|█▍        | 72/500 [1:11:47<7:24:03, 62.25s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: -3.26E+03, Train scatter: [0.9083 0.1249 0.5423 0.8822]
L1 regularization loss: 8.25E+00, L2 regularization loss: 3.48E+00
Test scatter: [0.8944 0.122  0.5341 0.8768], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.9193 0.1688 0.5355 0.9844], Epochs since improvement 18
 15%|█▍        | 73/500 [1:12:34<6:50:31, 57.68s/it] 15%|█▍        | 74/500 [1:13:46<7:19:38, 61.92s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 9.63E+06, Train scatter: [0.9298 0.1438 0.544  1.0128]
L1 regularization loss: 1.06E+01, L2 regularization loss: 6.08E+00
Test scatter: [0.9144 0.1409 0.5354 1.0027], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.919  0.1687 0.5355 0.9844], Epochs since improvement 20
 15%|█▌        | 75/500 [1:14:33<6:46:58, 57.46s/it] 15%|█▌        | 75/500 [1:15:44<7:09:12, 60.59s/it]
Epoch: 76 done with learning rate 1.00E-02, Train loss: 8.30E+06, Train scatter: [0.9299 0.1432 0.5435 1.0167]
L1 regularization loss: 1.06E+01, L2 regularization loss: 6.09E+00
Test scatter: [0.9143 0.1401 0.5349 1.0065], Lowest was [0.1979 0.0592 0.5306 0.4808]
Median for last 10 epochs: [0.9144 0.1409 0.5354 0.9844], Epochs since improvement 22
Exited after 76 epochs due to early stopping
4544.52 seconds spent training, 9.089 seconds per epoch. Processed 7662 trees per second
[0.9143223  0.14007328 0.53487945 1.0064546 ]
{'epoch_exit': 75, 'scatter_m_star': 0.9143223, 'lowest_m_star': 0.1979488, 'last20_m_star': 0.9193717, 'last10_m_star': 0.9144048, 'scatter_v_disk': 0.14007328, 'lowest_v_disk': 0.059205983, 'last20_v_disk': 0.16884878, 'last10_v_disk': 0.14088362, 'scatter_m_cold': 0.53487945, 'lowest_m_cold': 0.5306204, 'last20_m_cold': 0.53548485, 'last10_m_cold': 0.53543013, 'scatter_sfr_100': 1.0064546, 'lowest_sfr_100': 0.48080984, 'last20_sfr_100': 0.98493975, 'last10_sfr_100': 0.98436487}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_jtblbn
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:41<5:41:21, 41.05s/it]  0%|          | 2/500 [01:43<7:25:45, 53.71s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.01E+07, Train scatter: [0.9352 0.1709 0.5441 0.9954]
L1 regularization loss: 1.98E+00, L2 regularization loss: 3.76E-01
Test scatter: [0.9196 0.167  0.5356 0.9851], Lowest was [0.9196 0.167  0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.167  0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:24<6:34:33, 47.63s/it]  1%|          | 4/500 [03:26<7:22:40, 53.55s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.21E+07, Train scatter: [0.9352 0.1532 0.5441 0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.85E-01
Test scatter: [0.9196 0.1495 0.5355 0.9851], Lowest was [0.9196 0.1495 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1495 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:07<6:42:53, 48.83s/it]  1%|          | 6/500 [05:09<7:20:42, 53.53s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.71E+07, Train scatter: [0.9347 0.1054 0.544  0.9953]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.01E-01
Test scatter: [0.9191 0.1043 0.5355 0.985 ], Lowest was [0.9191 0.1043 0.5355 0.985 ]
Median for last 10 epochs: [0.9191 0.1043 0.5355 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [05:50<6:44:55, 49.28s/it]  2%|▏         | 8/500 [06:53<7:21:28, 53.84s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.33E+07, Train scatter: [0.8979 0.0915 0.544  0.7954]
L1 regularization loss: 2.04E+00, L2 regularization loss: 4.28E-01
Test scatter: [0.8843 0.0914 0.5354 0.7921], Lowest was [0.8843 0.0914 0.5354 0.7921]
Median for last 10 epochs: [0.9017 0.0979 0.5354 0.8885], Epochs since improvement 0
  2%|▏         | 9/500 [07:34<6:46:27, 49.67s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 9.43E+06, Train scatter: [0.5346 0.0901 0.5439 0.6305]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.60E-01
Test scatter: [0.5376 0.0903 0.5354 0.6269], Lowest was [0.5376 0.0903 0.5354 0.6269]
Median for last 10 epochs: [0.8843 0.0914 0.5354 0.7921], Epochs since improvement 0
  2%|▏         | 10/500 [08:44<7:37:46, 56.05s/it]  2%|▏         | 11/500 [09:25<6:58:33, 51.36s/it]  2%|▏         | 12/500 [10:28<7:25:52, 54.82s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.44E+06, Train scatter: [0.5591 0.0831 0.5439 0.582 ]
L1 regularization loss: 2.08E+00, L2 regularization loss: 4.72E-01
Test scatter: [0.5637 0.0835 0.5354 0.5798], Lowest was [0.5376 0.0835 0.5354 0.5798]
Median for last 10 epochs: [0.8843 0.0914 0.5354 0.7921], Epochs since improvement 0
  3%|▎         | 13/500 [11:08<6:49:32, 50.46s/it]  3%|▎         | 14/500 [12:13<7:23:09, 54.71s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 5.04E+06, Train scatter: [0.429  0.0793 0.5439 0.5566]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.81E-01
Test scatter: [0.4369 0.0795 0.5354 0.554 ], Lowest was [0.4369 0.0795 0.5354 0.554 ]
Median for last 10 epochs: [0.5637 0.0903 0.5354 0.6269], Epochs since improvement 0
  3%|▎         | 15/500 [12:53<6:48:11, 50.50s/it]  3%|▎         | 16/500 [13:57<7:18:21, 54.34s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.41E+06, Train scatter: [0.5023 0.0883 0.544  0.5638]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.88E-01
Test scatter: [0.4935 0.0875 0.5354 0.5599], Lowest was [0.4369 0.0795 0.5354 0.554 ]
Median for last 10 epochs: [0.5376 0.0875 0.5354 0.5798], Epochs since improvement 2
  3%|▎         | 17/500 [14:37<6:43:39, 50.14s/it]  4%|▎         | 18/500 [15:41<7:16:35, 54.35s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.09E+06, Train scatter: [0.2886 0.0759 0.5439 0.5337]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.96E-01
Test scatter: [0.2984 0.076  0.5353 0.5318], Lowest was [0.2984 0.076  0.5353 0.5318]
Median for last 10 epochs: [0.4935 0.0835 0.5354 0.5599], Epochs since improvement 0
  4%|▍         | 19/500 [16:22<6:42:22, 50.19s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.90E+06, Train scatter: [0.2558 0.077  0.5439 0.5411]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.01E-01
Test scatter: [0.2603 0.0771 0.5353 0.5334], Lowest was [0.2603 0.076  0.5353 0.5318]
Median for last 10 epochs: [0.4369 0.0795 0.5354 0.554 ], Epochs since improvement 0
  4%|▍         | 20/500 [17:32<7:29:54, 56.24s/it]  4%|▍         | 21/500 [18:13<6:51:20, 51.52s/it]  4%|▍         | 22/500 [19:16<7:19:15, 55.14s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.80E+06, Train scatter: [0.2931 0.0727 0.5439 0.5262]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.06E-01
Test scatter: [0.2893 0.0731 0.5353 0.5223], Lowest was [0.2603 0.0731 0.5353 0.5223]
Median for last 10 epochs: [0.2984 0.0771 0.5353 0.5334], Epochs since improvement 0
  5%|▍         | 23/500 [19:57<6:43:16, 50.73s/it]  5%|▍         | 24/500 [21:02<7:16:26, 55.01s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.62E+06, Train scatter: [0.3461 0.0755 0.5438 0.5397]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.344  0.0751 0.5353 0.535 ], Lowest was [0.2603 0.0731 0.5353 0.5223]
Median for last 10 epochs: [0.2984 0.076  0.5353 0.5334], Epochs since improvement 0
  5%|▌         | 25/500 [21:42<6:40:45, 50.62s/it]  5%|▌         | 26/500 [22:45<7:10:02, 54.43s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.51E+06, Train scatter: [0.4446 0.0821 0.5438 0.6483]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.15E-01
Test scatter: [0.4378 0.0811 0.5352 0.643 ], Lowest was [0.2603 0.0731 0.5352 0.5223]
Median for last 10 epochs: [0.2984 0.076  0.5353 0.5334], Epochs since improvement 0
  5%|▌         | 27/500 [23:26<6:36:08, 50.25s/it]  6%|▌         | 28/500 [24:29<7:06:09, 54.17s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.47E+06, Train scatter: [0.3054 0.0761 0.5438 0.5619]
L1 regularization loss: 2.16E+00, L2 regularization loss: 5.21E-01
Test scatter: [0.2962 0.0753 0.5352 0.5582], Lowest was [0.2603 0.0731 0.5352 0.5223]
Median for last 10 epochs: [0.2962 0.0753 0.5353 0.535 ], Epochs since improvement 0
  6%|▌         | 29/500 [25:09<6:32:28, 50.00s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.44E+06, Train scatter: [0.2194 0.0717 0.5437 0.5048]
L1 regularization loss: 2.18E+00, L2 regularization loss: 5.26E-01
Test scatter: [0.2229 0.0717 0.5352 0.5001], Lowest was [0.2229 0.0717 0.5352 0.5001]
Median for last 10 epochs: [0.2962 0.0751 0.5352 0.535 ], Epochs since improvement 0
  6%|▌         | 30/500 [26:20<7:20:25, 56.23s/it]  6%|▌         | 31/500 [27:00<6:42:18, 51.47s/it]  6%|▋         | 32/500 [28:04<7:09:30, 55.07s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.42E+06, Train scatter: [0.2036 0.0704 0.5436 0.5093]
L1 regularization loss: 2.19E+00, L2 regularization loss: 5.31E-01
Test scatter: [0.2097 0.07   0.5351 0.5024], Lowest was [0.2097 0.07   0.5351 0.5001]
Median for last 10 epochs: [0.2962 0.0751 0.5352 0.535 ], Epochs since improvement 0
  7%|▋         | 33/500 [28:44<6:34:07, 50.64s/it]  7%|▋         | 34/500 [29:48<7:04:43, 54.69s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.34E+06, Train scatter: [0.2671 0.0708 0.5436 0.5251]
L1 regularization loss: 2.20E+00, L2 regularization loss: 5.39E-01
Test scatter: [0.2606 0.0708 0.5351 0.5175], Lowest was [0.2097 0.07   0.5351 0.5001]
Median for last 10 epochs: [0.2606 0.0717 0.5352 0.5175], Epochs since improvement 0
  7%|▋         | 35/500 [30:29<6:30:20, 50.37s/it]  7%|▋         | 36/500 [31:32<7:00:42, 54.40s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.30E+06, Train scatter: [0.3144 0.0811 0.5436 0.5813]
L1 regularization loss: 2.21E+00, L2 regularization loss: 5.45E-01
Test scatter: [0.3086 0.0807 0.5351 0.5742], Lowest was [0.2097 0.07   0.5351 0.5001]
Median for last 10 epochs: [0.2606 0.0717 0.5351 0.5175], Epochs since improvement 0
  7%|▋         | 37/500 [32:13<6:27:00, 50.15s/it]  8%|▊         | 38/500 [33:16<6:55:46, 54.00s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.28E+06, Train scatter: [0.2019 0.0682 0.5436 0.4993]
L1 regularization loss: 2.23E+00, L2 regularization loss: 5.55E-01
Test scatter: [0.2056 0.068  0.535  0.4938], Lowest was [0.2056 0.068  0.535  0.4938]
Median for last 10 epochs: [0.2229 0.0708 0.5351 0.5024], Epochs since improvement 0
  8%|▊         | 39/500 [33:56<6:23:10, 49.87s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.25E+06, Train scatter: [0.201  0.0714 0.5436 0.5159]
L1 regularization loss: 2.25E+00, L2 regularization loss: 5.63E-01
Test scatter: [0.2045 0.0706 0.535  0.5113], Lowest was [0.2045 0.068  0.535  0.4938]
Median for last 10 epochs: [0.2097 0.0706 0.5351 0.5113], Epochs since improvement 0
  8%|▊         | 40/500 [35:05<7:06:40, 55.65s/it]  8%|▊         | 41/500 [35:45<6:30:35, 51.06s/it]  8%|▊         | 42/500 [36:49<6:59:11, 54.92s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.16E+06, Train scatter: [0.1953 0.0687 0.5435 0.4938]
L1 regularization loss: 2.26E+00, L2 regularization loss: 5.70E-01
Test scatter: [0.2005 0.0684 0.5349 0.4889], Lowest was [0.2005 0.068  0.5349 0.4889]
Median for last 10 epochs: [0.2056 0.0706 0.535  0.5113], Epochs since improvement 0
  9%|▊         | 43/500 [37:30<6:24:46, 50.52s/it]  9%|▉         | 44/500 [38:34<6:54:47, 54.58s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.14E+06, Train scatter: [0.2072 0.0715 0.5434 0.4946]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.77E-01
Test scatter: [0.214  0.0711 0.5348 0.4901], Lowest was [0.2005 0.068  0.5348 0.4889]
Median for last 10 epochs: [0.2056 0.0706 0.535  0.4938], Epochs since improvement 0
  9%|▉         | 45/500 [39:14<6:21:25, 50.30s/it]  9%|▉         | 46/500 [40:19<6:53:35, 54.66s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.14E+06, Train scatter: [0.2199 0.0755 0.5433 0.5248]
L1 regularization loss: 2.29E+00, L2 regularization loss: 5.84E-01
Test scatter: [0.22   0.0745 0.5348 0.523 ], Lowest was [0.2005 0.068  0.5348 0.4889]
Median for last 10 epochs: [0.2056 0.0706 0.5349 0.4938], Epochs since improvement 0
  9%|▉         | 47/500 [40:59<6:20:03, 50.34s/it] 10%|▉         | 48/500 [42:03<6:50:46, 54.53s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.10E+06, Train scatter: [0.2126 0.0737 0.5432 0.538 ]
L1 regularization loss: 2.30E+00, L2 regularization loss: 5.91E-01
Test scatter: [0.2195 0.0735 0.5346 0.5355], Lowest was [0.2005 0.068  0.5346 0.4889]
Median for last 10 epochs: [0.214  0.0711 0.5348 0.5113], Epochs since improvement 0
 10%|▉         | 49/500 [42:44<6:17:32, 50.23s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.09E+06, Train scatter: [0.2139 0.0718 0.5432 0.4976]
L1 regularization loss: 2.33E+00, L2 regularization loss: 6.03E-01
Test scatter: [0.2226 0.0714 0.5347 0.4954], Lowest was [0.2005 0.068  0.5346 0.4889]
Median for last 10 epochs: [0.2195 0.0714 0.5348 0.4954], Epochs since improvement 2
 10%|█         | 50/500 [43:54<7:01:37, 56.22s/it] 10%|█         | 51/500 [44:34<6:25:10, 51.47s/it] 10%|█         | 52/500 [45:39<6:53:44, 55.41s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.10E+06, Train scatter: [0.2013 0.0687 0.5432 0.4936]
L1 regularization loss: 2.34E+00, L2 regularization loss: 6.09E-01
Test scatter: [0.2052 0.0682 0.5347 0.4891], Lowest was [0.2005 0.068  0.5346 0.4889]
Median for last 10 epochs: [0.2195 0.0714 0.5347 0.4954], Epochs since improvement 4
 11%|█         | 53/500 [46:19<6:19:19, 50.92s/it] 11%|█         | 54/500 [47:24<6:49:20, 55.07s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.03E+06, Train scatter: [0.2274 0.0695 0.5431 0.5161]
L1 regularization loss: 2.34E+00, L2 regularization loss: 6.14E-01
Test scatter: [0.2394 0.0697 0.5345 0.5165], Lowest was [0.2005 0.068  0.5345 0.4889]
Median for last 10 epochs: [0.22   0.0714 0.5347 0.5165], Epochs since improvement 0
 11%|█         | 55/500 [48:04<6:15:30, 50.63s/it] 11%|█         | 56/500 [49:08<6:44:36, 54.68s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.00E+06, Train scatter: [0.3212 0.0842 0.5431 0.5742]
L1 regularization loss: 2.35E+00, L2 regularization loss: 6.21E-01
Test scatter: [0.3179 0.082  0.5345 0.5744], Lowest was [0.2005 0.068  0.5345 0.4889]
Median for last 10 epochs: [0.2226 0.0714 0.5346 0.5165], Epochs since improvement 2
 11%|█▏        | 57/500 [49:49<6:12:23, 50.44s/it] 12%|█▏        | 58/500 [50:54<6:44:03, 54.85s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.03E+06, Train scatter: [0.2174 0.0779 0.543  0.5018]
L1 regularization loss: 2.38E+00, L2 regularization loss: 6.36E-01
Test scatter: [0.2208 0.0767 0.5344 0.4974], Lowest was [0.2005 0.068  0.5344 0.4889]
Median for last 10 epochs: [0.2226 0.0714 0.5345 0.4974], Epochs since improvement 0
 12%|█▏        | 59/500 [51:34<6:11:12, 50.50s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.02E+06, Train scatter: [0.3763 0.0722 0.5428 0.5369]
L1 regularization loss: 2.39E+00, L2 regularization loss: 6.47E-01
Test scatter: [0.3696 0.0711 0.5343 0.5406], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.2394 0.0711 0.5345 0.5165], Epochs since improvement 0
 12%|█▏        | 60/500 [52:45<6:54:58, 56.59s/it] 12%|█▏        | 61/500 [53:25<6:18:11, 51.69s/it] 12%|█▏        | 62/500 [54:30<6:44:49, 55.45s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.04E+06, Train scatter: [0.214  0.0885 0.5429 0.5007]
L1 regularization loss: 2.42E+00, L2 regularization loss: 6.61E-01
Test scatter: [0.2215 0.0863 0.5344 0.4977], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.2394 0.0767 0.5344 0.5165], Epochs since improvement 2
 13%|█▎        | 63/500 [55:10<6:11:00, 50.94s/it] 13%|█▎        | 64/500 [56:13<6:36:53, 54.62s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.07E+06, Train scatter: [0.2451 0.0803 0.543  0.5206]
L1 regularization loss: 2.45E+00, L2 regularization loss: 6.83E-01
Test scatter: [0.2492 0.0795 0.5345 0.5167], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.2492 0.0795 0.5344 0.5167], Epochs since improvement 4
 13%|█▎        | 65/500 [56:54<6:05:10, 50.37s/it] 13%|█▎        | 66/500 [57:56<6:31:13, 54.09s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.36E+06, Train scatter: [0.447  0.1037 0.5435 0.7856]
L1 regularization loss: 2.55E+00, L2 regularization loss: 7.38E-01
Test scatter: [0.4303 0.0995 0.5349 0.7614], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.2492 0.0795 0.5344 0.5167], Epochs since improvement 6
 13%|█▎        | 67/500 [58:37<6:00:39, 49.98s/it] 14%|█▎        | 68/500 [59:40<6:28:01, 53.89s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.11E+06, Train scatter: [0.4569 0.0777 0.5433 0.5408]
L1 regularization loss: 2.55E+00, L2 regularization loss: 7.49E-01
Test scatter: [0.4513 0.0764 0.5348 0.5293], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.3696 0.0795 0.5345 0.5293], Epochs since improvement 8
 14%|█▍        | 69/500 [1:00:20<5:57:54, 49.83s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.14E+06, Train scatter: [0.4018 0.0831 0.5432 0.5144]
L1 regularization loss: 2.59E+00, L2 regularization loss: 7.76E-01
Test scatter: [0.397  0.0815 0.5346 0.5084], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.397  0.0815 0.5346 0.5167], Epochs since improvement 10
 14%|█▍        | 70/500 [1:01:29<6:38:38, 55.62s/it] 14%|█▍        | 71/500 [1:02:10<6:05:06, 51.06s/it] 14%|█▍        | 72/500 [1:03:13<6:30:41, 54.77s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.06E+06, Train scatter: [0.3721 0.0768 0.5432 0.5566]
L1 regularization loss: 2.61E+00, L2 regularization loss: 7.90E-01
Test scatter: [0.3676 0.0752 0.5346 0.5576], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.397  0.0795 0.5346 0.5293], Epochs since improvement 12
 15%|█▍        | 73/500 [1:03:54<5:59:10, 50.47s/it] 15%|█▍        | 74/500 [1:04:58<6:28:21, 54.70s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 4.45E+06, Train scatter: [0.933  0.1631 0.5441 0.9934]
L1 regularization loss: 3.44E+00, L2 regularization loss: 1.26E+00
Test scatter: [0.9175 0.1598 0.5355 0.9831], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.4303 0.0815 0.5348 0.5576], Epochs since improvement 14
 15%|█▌        | 75/500 [1:05:38<5:56:51, 50.38s/it] 15%|█▌        | 76/500 [1:06:42<6:24:39, 54.43s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 5.55E+06, Train scatter: [0.5825 0.1171 0.544  0.8186]
L1 regularization loss: 3.57E+00, L2 regularization loss: 1.49E+00
Test scatter: [0.608  0.1167 0.5354 0.8255], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.4513 0.0815 0.5348 0.5576], Epochs since improvement 16
 15%|█▌        | 77/500 [1:07:23<5:54:16, 50.25s/it] 16%|█▌        | 78/500 [1:08:26<6:21:32, 54.25s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 4.83E+06, Train scatter: [0.5353 0.1084 0.544  0.7272]
L1 regularization loss: 3.59E+00, L2 regularization loss: 1.54E+00
Test scatter: [0.5477 0.1081 0.5353 0.7331], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.5477 0.1081 0.5353 0.7331], Epochs since improvement 18
 16%|█▌        | 79/500 [1:09:07<5:51:43, 50.13s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 4.53E+06, Train scatter: [0.485  0.107  0.5438 0.7226]
L1 regularization loss: 3.60E+00, L2 regularization loss: 1.56E+00
Test scatter: [0.4962 0.1062 0.5352 0.7213], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.5477 0.1081 0.5353 0.7331], Epochs since improvement 20
 16%|█▌        | 80/500 [1:10:18<6:35:14, 56.46s/it] 16%|█▌        | 81/500 [1:10:59<6:00:40, 51.65s/it] 16%|█▌        | 81/500 [1:12:02<6:12:41, 53.37s/it]
Epoch: 82 done with learning rate 9.99E-03, Train loss: 4.37E+06, Train scatter: [0.5149 0.1095 0.5438 0.711 ]
L1 regularization loss: 3.60E+00, L2 regularization loss: 1.58E+00
Test scatter: [0.5235 0.1085 0.5352 0.7096], Lowest was [0.2005 0.068  0.5343 0.4889]
Median for last 10 epochs: [0.5477 0.1085 0.5353 0.7331], Epochs since improvement 22
Exited after 82 epochs due to early stopping
4322.90 seconds spent training, 8.646 seconds per epoch. Processed 8054 trees per second
[0.52350956 0.10853199 0.53520566 0.70953125]
{'epoch_exit': 81, 'scatter_m_star': 0.52350956, 'lowest_m_star': 0.20047468, 'last20_m_star': 0.47374114, 'last10_m_star': 0.5476517, 'scatter_v_disk': 0.10853199, 'lowest_v_disk': 0.06801004, 'last20_v_disk': 0.10284842, 'last10_v_disk': 0.10853511, 'scatter_m_cold': 0.53520566, 'lowest_m_cold': 0.5342533, 'last20_m_cold': 0.53507674, 'last10_m_cold': 0.53533995, 'scatter_sfr_100': 0.70953125, 'lowest_sfr_100': 0.4888637, 'last20_sfr_100': 0.71544147, 'last10_sfr_100': 0.73309034}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_qnmrga
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:01<8:30:05, 61.33s/it]  0%|          | 2/500 [02:31<10:49:49, 78.29s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.40E+07, Train scatter: [0.9352 0.1301 0.5441 0.9955]
L1 regularization loss: 2.45E+00, L2 regularization loss: 4.24E-01
Test scatter: [0.9195 0.1255 0.5355 0.9851], Lowest was [0.9195 0.1255 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1255 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:32<9:44:49, 70.60s/it]   1%|          | 4/500 [05:03<10:48:28, 78.44s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.10E+07, Train scatter: [0.9333 0.1054 0.5437 0.9955]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.29E-01
Test scatter: [0.9177 0.1034 0.5352 0.9851], Lowest was [0.9177 0.1034 0.5352 0.9851]
Median for last 10 epochs: [0.9177 0.1034 0.5352 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:04<9:56:18, 72.28s/it]   1%|          | 6/500 [07:36<10:49:13, 78.85s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 7.76E+07, Train scatter: [0.8569 0.0954 0.5383 0.9953]
L1 regularization loss: 2.49E+00, L2 regularization loss: 4.38E-01
Test scatter: [0.8437 0.0964 0.5302 0.985 ], Lowest was [0.8437 0.0964 0.5302 0.985 ]
Median for last 10 epochs: [0.8437 0.0964 0.5302 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [08:37<10:00:02, 73.03s/it]  2%|▏         | 8/500 [10:08<10:45:54, 78.77s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 7.46E+07, Train scatter: [0.7606 0.1041 0.4614 0.9954]
L1 regularization loss: 2.51E+00, L2 regularization loss: 4.53E-01
Test scatter: [0.7633 0.1041 0.4502 0.985 ], Lowest was [0.7633 0.0964 0.4502 0.985 ]
Median for last 10 epochs: [0.8035 0.0999 0.4902 0.985 ], Epochs since improvement 0
  2%|▏         | 9/500 [11:09<10:00:03, 73.33s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.30E+07, Train scatter: [0.5404 0.0901 0.374  0.9954]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.63E-01
Test scatter: [0.56   0.0935 0.3718 0.9851], Lowest was [0.56   0.0935 0.3718 0.985 ]
Median for last 10 epochs: [0.7633 0.0964 0.4502 0.985 ], Epochs since improvement 0
  2%|▏         | 10/500 [12:48<11:02:02, 81.07s/it]  2%|▏         | 11/500 [13:49<10:10:54, 74.96s/it]  2%|▏         | 12/500 [15:20<10:50:30, 79.98s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.20E+07, Train scatter: [0.5273 0.0805 0.3252 0.9954]
L1 regularization loss: 2.53E+00, L2 regularization loss: 4.70E-01
Test scatter: [0.5487 0.0821 0.3261 0.985 ], Lowest was [0.5487 0.0821 0.3261 0.985 ]
Median for last 10 epochs: [0.7633 0.0964 0.4502 0.985 ], Epochs since improvement 0
  3%|▎         | 13/500 [16:22<10:03:47, 74.39s/it]  3%|▎         | 14/500 [17:53<10:42:57, 79.38s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.20E+07, Train scatter: [0.5295 0.0877 0.4296 0.9953]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.74E-01
Test scatter: [0.5393 0.0879 0.4253 0.985 ], Lowest was [0.5393 0.0821 0.3261 0.985 ]
Median for last 10 epochs: [0.56   0.0935 0.4253 0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [18:54<9:57:17, 73.89s/it]   3%|▎         | 16/500 [20:24<10:34:43, 78.69s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.96E+07, Train scatter: [0.389  0.0783 0.3147 0.9954]
L1 regularization loss: 2.56E+00, L2 regularization loss: 4.79E-01
Test scatter: [0.4098 0.0795 0.3168 0.9851], Lowest was [0.4098 0.0795 0.3168 0.985 ]
Median for last 10 epochs: [0.5487 0.0879 0.3718 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [21:25<9:50:46, 73.39s/it]   4%|▎         | 18/500 [22:58<10:37:01, 79.30s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.43E+07, Train scatter: [0.3707 0.0826 0.3669 0.9101]
L1 regularization loss: 2.57E+00, L2 regularization loss: 4.89E-01
Test scatter: [0.391  0.0822 0.3657 0.9073], Lowest was [0.391  0.0795 0.3168 0.9073]
Median for last 10 epochs: [0.5393 0.0822 0.3657 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [23:59<9:51:57, 73.84s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.07E+06, Train scatter: [0.4045 0.0786 0.3919 0.6989]
L1 regularization loss: 2.59E+00, L2 regularization loss: 5.00E-01
Test scatter: [0.4135 0.0785 0.3998 0.7065], Lowest was [0.391  0.0785 0.3168 0.7065]
Median for last 10 epochs: [0.4135 0.0821 0.3657 0.985 ], Epochs since improvement 0
  4%|▍         | 20/500 [25:37<10:49:02, 81.13s/it]  4%|▍         | 21/500 [26:38<9:59:25, 75.08s/it]   4%|▍         | 22/500 [28:09<10:37:00, 79.96s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.76E+06, Train scatter: [0.2786 0.0735 0.303  0.5202]
L1 regularization loss: 2.62E+00, L2 regularization loss: 5.09E-01
Test scatter: [0.2803 0.0729 0.3056 0.5185], Lowest was [0.2803 0.0729 0.3056 0.5185]
Median for last 10 epochs: [0.4098 0.0795 0.3657 0.9073], Epochs since improvement 0
  5%|▍         | 23/500 [29:10<9:50:31, 74.28s/it]   5%|▍         | 24/500 [30:41<10:27:49, 79.14s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.39E+06, Train scatter: [0.2706 0.0699 0.3005 0.5071]
L1 regularization loss: 2.64E+00, L2 regularization loss: 5.18E-01
Test scatter: [0.2775 0.0699 0.3031 0.5095], Lowest was [0.2775 0.0699 0.3031 0.5095]
Median for last 10 epochs: [0.391  0.0785 0.3168 0.7065], Epochs since improvement 0
  5%|▌         | 25/500 [31:42<9:43:31, 73.71s/it]   5%|▌         | 26/500 [33:13<10:24:00, 78.99s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.02E+06, Train scatter: [0.272  0.0695 0.2956 0.499 ]
L1 regularization loss: 2.67E+00, L2 regularization loss: 5.27E-01
Test scatter: [0.2668 0.0685 0.2962 0.5017], Lowest was [0.2668 0.0685 0.2962 0.5017]
Median for last 10 epochs: [0.2803 0.0729 0.3056 0.5185], Epochs since improvement 0
  5%|▌         | 27/500 [34:14<9:40:18, 73.61s/it]   6%|▌         | 28/500 [35:45<10:19:19, 78.73s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.08E+06, Train scatter: [0.2445 0.0689 0.305  0.4858]
L1 regularization loss: 2.70E+00, L2 regularization loss: 5.40E-01
Test scatter: [0.2497 0.0694 0.3176 0.4913], Lowest was [0.2497 0.0685 0.2962 0.4913]
Median for last 10 epochs: [0.2775 0.0699 0.3056 0.5095], Epochs since improvement 0
  6%|▌         | 29/500 [36:46<9:36:27, 73.43s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.88E+06, Train scatter: [0.4124 0.0661 0.2824 0.4753]
L1 regularization loss: 2.72E+00, L2 regularization loss: 5.53E-01
Test scatter: [0.4075 0.0659 0.2851 0.4748], Lowest was [0.2497 0.0659 0.2851 0.4748]
Median for last 10 epochs: [0.2775 0.0694 0.3031 0.5017], Epochs since improvement 0
  6%|▌         | 30/500 [38:25<10:34:01, 80.94s/it]  6%|▌         | 31/500 [39:26<9:46:23, 75.02s/it]   6%|▋         | 32/500 [40:56<10:21:09, 79.64s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.81E+06, Train scatter: [0.3427 0.0659 0.282  0.5062]
L1 regularization loss: 2.76E+00, L2 regularization loss: 5.68E-01
Test scatter: [0.3324 0.0661 0.2837 0.5094], Lowest was [0.2497 0.0659 0.2837 0.4748]
Median for last 10 epochs: [0.2775 0.0685 0.2962 0.5017], Epochs since improvement 0
  7%|▋         | 33/500 [41:57<9:36:38, 74.09s/it]   7%|▋         | 34/500 [43:29<10:15:34, 79.26s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.58E+06, Train scatter: [0.2645 0.0645 0.2978 0.4776]
L1 regularization loss: 2.80E+00, L2 regularization loss: 5.86E-01
Test scatter: [0.2722 0.0644 0.2965 0.4835], Lowest was [0.2497 0.0644 0.2837 0.4748]
Median for last 10 epochs: [0.2722 0.0661 0.2962 0.4913], Epochs since improvement 0
  7%|▋         | 35/500 [44:30<9:32:26, 73.86s/it]   7%|▋         | 36/500 [46:00<10:08:47, 78.72s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.57E+06, Train scatter: [0.2829 0.0664 0.3149 0.4846]
L1 regularization loss: 2.83E+00, L2 regularization loss: 6.02E-01
Test scatter: [0.2908 0.0659 0.3197 0.4826], Lowest was [0.2497 0.0644 0.2837 0.4748]
Median for last 10 epochs: [0.2908 0.0659 0.2965 0.4835], Epochs since improvement 2
  7%|▋         | 37/500 [47:01<9:26:28, 73.41s/it]   8%|▊         | 38/500 [48:32<10:05:22, 78.62s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.70E+06, Train scatter: [0.3845 0.0647 0.2895 0.462 ]
L1 regularization loss: 2.88E+00, L2 regularization loss: 6.30E-01
Test scatter: [0.3775 0.0645 0.2918 0.4616], Lowest was [0.2497 0.0644 0.2837 0.4616]
Median for last 10 epochs: [0.3324 0.0659 0.2918 0.4826], Epochs since improvement 0
  8%|▊         | 39/500 [49:33<9:23:40, 73.36s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.47E+06, Train scatter: [0.2961 0.0647 0.2847 0.4698]
L1 regularization loss: 2.91E+00, L2 regularization loss: 6.52E-01
Test scatter: [0.3005 0.065  0.2875 0.474 ], Lowest was [0.2497 0.0644 0.2837 0.4616]
Median for last 10 epochs: [0.3005 0.065  0.2918 0.4826], Epochs since improvement 2
  8%|▊         | 40/500 [51:11<10:19:24, 80.79s/it]  8%|▊         | 41/500 [52:12<9:33:10, 74.93s/it]   8%|▊         | 42/500 [53:43<10:09:21, 79.83s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.42E+06, Train scatter: [0.2146 0.0595 0.2835 0.4467]
L1 regularization loss: 2.96E+00, L2 regularization loss: 6.80E-01
Test scatter: [0.2246 0.0596 0.2862 0.4501], Lowest was [0.2246 0.0596 0.2837 0.4501]
Median for last 10 epochs: [0.2908 0.0645 0.2918 0.474 ], Epochs since improvement 0
  9%|▊         | 43/500 [54:45<9:25:14, 74.21s/it]   9%|▉         | 44/500 [56:15<10:00:20, 78.99s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 5.50E+06, Train scatter: [0.5795 0.1093 0.5089 0.6925]
L1 regularization loss: 3.26E+00, L2 regularization loss: 8.16E-01
Test scatter: [0.5788 0.1099 0.5016 0.6909], Lowest was [0.2246 0.0596 0.2837 0.4501]
Median for last 10 epochs: [0.3005 0.065  0.2918 0.474 ], Epochs since improvement 2
  9%|▉         | 45/500 [57:16<9:18:17, 73.62s/it]   9%|▉         | 46/500 [58:47<9:56:12, 78.79s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.34E+06, Train scatter: [0.4792 0.0824 0.5038 0.6072]
L1 regularization loss: 3.37E+00, L2 regularization loss: 9.27E-01
Test scatter: [0.4686 0.0817 0.4937 0.5998], Lowest was [0.2246 0.0596 0.2837 0.4501]
Median for last 10 epochs: [0.3775 0.065  0.2918 0.474 ], Epochs since improvement 4
  9%|▉         | 47/500 [59:48<9:15:07, 73.53s/it] 10%|▉         | 48/500 [1:01:19<9:54:09, 78.87s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.05E+06, Train scatter: [0.2807 0.0745 0.4657 0.5377]
L1 regularization loss: 3.37E+00, L2 regularization loss: 9.68E-01
Test scatter: [0.2916 0.0751 0.4597 0.537 ], Lowest was [0.2246 0.0596 0.2837 0.4501]
Median for last 10 epochs: [0.3005 0.0751 0.4597 0.537 ], Epochs since improvement 6
 10%|▉         | 49/500 [1:02:20<9:12:53, 73.56s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.39E+06, Train scatter: [0.2816 0.0718 0.4779 0.5204]
L1 regularization loss: 3.39E+00, L2 regularization loss: 9.93E-01
Test scatter: [0.293  0.0726 0.4622 0.521 ], Lowest was [0.2246 0.0596 0.2837 0.4501]
Median for last 10 epochs: [0.293  0.0751 0.4622 0.537 ], Epochs since improvement 8
 10%|█         | 50/500 [1:03:58<10:06:22, 80.85s/it] 10%|█         | 51/500 [1:04:59<9:20:46, 74.94s/it]  10%|█         | 52/500 [1:06:30<9:54:49, 79.66s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 2.20E+06, Train scatter: [0.257  0.0683 0.4578 0.4959]
L1 regularization loss: 3.40E+00, L2 regularization loss: 1.03E+00
Test scatter: [0.2682 0.0686 0.4403 0.4955], Lowest was [0.2246 0.0596 0.2837 0.4501]
Median for last 10 epochs: [0.293  0.0751 0.4622 0.537 ], Epochs since improvement 10
 11%|█         | 53/500 [1:07:31<9:12:26, 74.15s/it] 11%|█         | 54/500 [1:09:02<9:47:34, 79.04s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.10E+06, Train scatter: [0.51   0.1645 0.4582 0.6063]
L1 regularization loss: 3.45E+00, L2 regularization loss: 1.07E+00
Test scatter: [0.5089 0.1612 0.4609 0.6082], Lowest was [0.2246 0.0596 0.2837 0.4501]
Median for last 10 epochs: [0.293  0.0751 0.4609 0.537 ], Epochs since improvement 12
 11%|█         | 55/500 [1:10:03<9:06:31, 73.69s/it] 11%|█         | 56/500 [1:11:33<9:41:51, 78.63s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.04E+06, Train scatter: [0.3698 0.0732 0.3651 0.4818]
L1 regularization loss: 3.53E+00, L2 regularization loss: 1.15E+00
Test scatter: [0.3631 0.0734 0.3733 0.4804], Lowest was [0.2246 0.0596 0.2837 0.4501]
Median for last 10 epochs: [0.293  0.0734 0.4597 0.521 ], Epochs since improvement 14
 11%|█▏        | 57/500 [1:12:34<9:02:05, 73.42s/it] 12%|█▏        | 58/500 [1:14:04<9:37:28, 78.39s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.77E+06, Train scatter: [0.2903 0.0635 0.3647 0.4798]
L1 regularization loss: 3.53E+00, L2 regularization loss: 1.18E+00
Test scatter: [0.2776 0.0647 0.3663 0.4753], Lowest was [0.2246 0.0596 0.2837 0.4501]
Median for last 10 epochs: [0.293  0.0726 0.4403 0.4955], Epochs since improvement 16
 12%|█▏        | 59/500 [1:15:06<8:58:27, 73.26s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.65E+06, Train scatter: [0.2441 0.0616 0.3477 0.4652]
L1 regularization loss: 3.57E+00, L2 regularization loss: 1.23E+00
Test scatter: [0.2411 0.0617 0.3483 0.4605], Lowest was [0.2246 0.0596 0.2837 0.4501]
Median for last 10 epochs: [0.2776 0.0686 0.3733 0.4804], Epochs since improvement 18
 12%|█▏        | 60/500 [1:16:44<9:51:17, 80.63s/it] 12%|█▏        | 61/500 [1:17:45<9:07:31, 74.83s/it] 12%|█▏        | 62/500 [1:19:16<9:42:17, 79.77s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.56E+06, Train scatter: [0.2288 0.0626 0.3535 0.4654]
L1 regularization loss: 3.60E+00, L2 regularization loss: 1.28E+00
Test scatter: [0.2402 0.0639 0.3583 0.475 ], Lowest was [0.2246 0.0596 0.2837 0.4501]
Median for last 10 epochs: [0.2776 0.0647 0.3663 0.4753], Epochs since improvement 20
 13%|█▎        | 63/500 [1:20:17<9:00:19, 74.19s/it] 13%|█▎        | 64/500 [1:21:47<9:33:37, 78.94s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.47E+06, Train scatter: [0.2174 0.0595 0.3274 0.4442]
L1 regularization loss: 3.66E+00, L2 regularization loss: 1.35E+00
Test scatter: [0.2229 0.0588 0.3308 0.4433], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.2411 0.0639 0.3583 0.475 ], Epochs since improvement 0
 13%|█▎        | 65/500 [1:22:49<8:54:09, 73.68s/it] 13%|█▎        | 66/500 [1:24:20<9:30:22, 78.85s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.07E+07, Train scatter: [0.932  0.1711 0.5439 0.9928]
L1 regularization loss: 1.24E+01, L2 regularization loss: 4.76E+00
Test scatter: [0.9164 0.1673 0.5353 0.9826], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.2411 0.0639 0.3583 0.475 ], Epochs since improvement 2
 13%|█▎        | 67/500 [1:25:21<8:51:25, 73.64s/it] 14%|█▎        | 68/500 [1:26:51<9:24:39, 78.43s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.22E+07, Train scatter: [0.9293 0.1693 0.5437 0.9848]
L1 regularization loss: 1.24E+01, L2 regularization loss: 4.82E+00
Test scatter: [0.9138 0.1656 0.5352 0.9747], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.2411 0.0639 0.3583 0.475 ], Epochs since improvement 4
 14%|█▍        | 69/500 [1:27:52<8:46:28, 73.29s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 8.18E+06, Train scatter: [0.9229 0.162  0.5433 0.7858]
L1 regularization loss: 1.25E+01, L2 regularization loss: 5.09E+00
Test scatter: [0.9075 0.1585 0.5348 0.7808], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.9075 0.1585 0.5348 0.7808], Epochs since improvement 6
 14%|█▍        | 70/500 [1:29:30<9:37:53, 80.63s/it] 14%|█▍        | 71/500 [1:30:31<8:55:14, 74.86s/it] 14%|█▍        | 72/500 [1:32:01<9:26:56, 79.48s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 7.90E+06, Train scatter: [0.9234 0.1587 0.5431 0.971 ]
L1 regularization loss: 1.27E+01, L2 regularization loss: 5.28E+00
Test scatter: [0.9081 0.1553 0.5346 0.9612], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.9081 0.1585 0.5348 0.9612], Epochs since improvement 8
 15%|█▍        | 73/500 [1:33:03<8:46:27, 73.98s/it] 15%|█▍        | 74/500 [1:34:33<9:21:10, 79.04s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 5.30E+06, Train scatter: [0.9046 0.1204 0.517  0.7171]
L1 regularization loss: 1.28E+01, L2 regularization loss: 5.58E+00
Test scatter: [0.8895 0.1181 0.5095 0.7091], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.9081 0.1585 0.5348 0.9612], Epochs since improvement 10
 15%|█▌        | 75/500 [1:35:35<8:42:07, 73.71s/it] 15%|█▌        | 76/500 [1:37:04<9:13:58, 78.39s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 4.35E+06, Train scatter: [0.9044 0.1137 0.5214 0.6815]
L1 regularization loss: 1.28E+01, L2 regularization loss: 5.70E+00
Test scatter: [0.8893 0.1113 0.5134 0.6728], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.9075 0.1553 0.5346 0.7808], Epochs since improvement 12
 15%|█▌        | 77/500 [1:38:06<8:37:20, 73.38s/it] 16%|█▌        | 78/500 [1:39:36<9:10:59, 78.34s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.57E+06, Train scatter: [0.9058 0.1106 0.5324 0.6497]
L1 regularization loss: 1.28E+01, L2 regularization loss: 5.81E+00
Test scatter: [0.8906 0.108  0.524  0.6398], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.8906 0.1181 0.524  0.7091], Epochs since improvement 14
 16%|█▌        | 79/500 [1:40:37<8:34:10, 73.28s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 3.04E+06, Train scatter: [0.9031 0.1034 0.5118 0.6371]
L1 regularization loss: 1.28E+01, L2 regularization loss: 5.91E+00
Test scatter: [0.888  0.1012 0.5039 0.6287], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.8895 0.1113 0.5134 0.6728], Epochs since improvement 16
 16%|█▌        | 80/500 [1:42:14<9:23:20, 80.48s/it] 16%|█▌        | 81/500 [1:43:16<8:42:39, 74.84s/it] 16%|█▋        | 82/500 [1:44:47<9:14:43, 79.63s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.51E+06, Train scatter: [0.8715 0.1013 0.5112 0.6293]
L1 regularization loss: 1.28E+01, L2 regularization loss: 6.00E+00
Test scatter: [0.8569 0.0992 0.5031 0.6183], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.8893 0.108  0.5095 0.6398], Epochs since improvement 18
 17%|█▋        | 83/500 [1:45:48<8:34:55, 74.09s/it] 17%|█▋        | 84/500 [1:47:19<9:07:49, 79.01s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.05E+06, Train scatter: [0.8725 0.1    0.536  0.6357]
L1 regularization loss: 1.28E+01, L2 regularization loss: 6.14E+00
Test scatter: [0.8579 0.098  0.5276 0.6261], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.888  0.1012 0.5134 0.6287], Epochs since improvement 20
 17%|█▋        | 85/500 [1:48:20<8:29:26, 73.65s/it] 17%|█▋        | 85/500 [1:49:50<8:56:16, 77.53s/it]
Epoch: 86 done with learning rate 9.98E-03, Train loss: 1.45E+06, Train scatter: [0.8197 0.1057 0.4941 0.6537]
L1 regularization loss: 1.28E+01, L2 regularization loss: 6.28E+00
Test scatter: [0.8058 0.1037 0.4861 0.6448], Lowest was [0.2229 0.0588 0.2837 0.4433]
Median for last 10 epochs: [0.8579 0.1012 0.5039 0.6287], Epochs since improvement 22
Exited after 86 epochs due to early stopping
6590.40 seconds spent training, 13.181 seconds per epoch. Processed 5283 trees per second
[0.80581576 0.10374679 0.48610336 0.6448261 ]
{'epoch_exit': 85, 'scatter_m_star': 0.80581576, 'lowest_m_star': 0.22294113, 'last20_m_star': 0.88938427, 'last10_m_star': 0.8579096, 'scatter_v_disk': 0.103746794, 'lowest_v_disk': 0.05884499, 'last20_v_disk': 0.1096289, 'last10_v_disk': 0.101179756, 'scatter_m_cold': 0.48610336, 'lowest_m_cold': 0.28369507, 'last20_m_cold': 0.51870364, 'last10_m_cold': 0.5038547, 'scatter_sfr_100': 0.6448261, 'lowest_sfr_100': 0.44333455, 'last20_sfr_100': 0.6588155, 'last10_sfr_100': 0.62874526}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_jcscgw
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:28:47, 53.96s/it]  0%|          | 2/500 [02:14<9:38:35, 69.71s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.1743 0.5441 0.9953]
L1 regularization loss: 2.44E+00, L2 regularization loss: 4.23E-01
Test scatter: [0.9196 0.1691 0.5355 0.985 ], Lowest was [0.9196 0.1691 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1691 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:08<8:35:41, 62.26s/it]  1%|          | 4/500 [04:29<9:37:12, 69.82s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.75E+07, Train scatter: [0.9352 0.1367 0.5441 0.9954]
L1 regularization loss: 2.46E+00, L2 regularization loss: 4.25E-01
Test scatter: [0.9196 0.1339 0.5355 0.9851], Lowest was [0.9196 0.1339 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1339 0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:23<8:48:23, 64.05s/it]  1%|          | 6/500 [06:44<9:36:36, 70.03s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.34E+07, Train scatter: [0.9349 0.1137 0.5441 0.9955]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.28E-01
Test scatter: [0.9193 0.1123 0.5355 0.9851], Lowest was [0.9193 0.1123 0.5355 0.985 ]
Median for last 10 epochs: [0.9193 0.1123 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:38<8:50:23, 64.55s/it]  2%|▏         | 8/500 [08:59<9:32:31, 69.82s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.13E+07, Train scatter: [0.9304 0.0996 0.544  0.9954]
L1 regularization loss: 2.48E+00, L2 regularization loss: 4.33E-01
Test scatter: [0.9149 0.0988 0.5354 0.9851], Lowest was [0.9149 0.0988 0.5354 0.985 ]
Median for last 10 epochs: [0.9171 0.1056 0.5355 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [09:52<8:49:03, 64.65s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.91E+07, Train scatter: [0.7639 0.0908 0.5439 0.9953]
L1 regularization loss: 2.49E+00, L2 regularization loss: 4.40E-01
Test scatter: [0.7557 0.0904 0.5353 0.985 ], Lowest was [0.7557 0.0904 0.5353 0.985 ]
Median for last 10 epochs: [0.9149 0.0988 0.5354 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:20<9:47:06, 71.89s/it]  2%|▏         | 11/500 [12:14<8:59:39, 66.21s/it]  2%|▏         | 12/500 [13:35<9:37:04, 70.95s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.78E+07, Train scatter: [0.654  0.0888 0.5436 0.9953]
L1 regularization loss: 2.51E+00, L2 regularization loss: 4.49E-01
Test scatter: [0.6488 0.0888 0.535  0.985 ], Lowest was [0.6488 0.0888 0.535  0.985 ]
Median for last 10 epochs: [0.9149 0.0988 0.5354 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:29<8:52:32, 65.61s/it]  3%|▎         | 14/500 [15:50<9:28:59, 70.25s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.65E+07, Train scatter: [0.5765 0.0855 0.5417 0.9952]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.60E-01
Test scatter: [0.568  0.085  0.5334 0.9849], Lowest was [0.568  0.085  0.5334 0.9849]
Median for last 10 epochs: [0.7557 0.0904 0.5353 0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [16:43<8:47:04, 65.21s/it]  3%|▎         | 16/500 [18:04<9:25:05, 70.05s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.56E+07, Train scatter: [0.4661 0.0821 0.5322 0.9953]
L1 regularization loss: 2.53E+00, L2 regularization loss: 4.67E-01
Test scatter: [0.4695 0.0824 0.5248 0.9849], Lowest was [0.4695 0.0824 0.5248 0.9849]
Median for last 10 epochs: [0.6488 0.0888 0.535  0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [18:58<8:43:28, 65.03s/it]  4%|▎         | 18/500 [20:20<9:24:31, 70.27s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.52E+07, Train scatter: [0.4357 0.0795 0.5274 0.9952]
L1 regularization loss: 2.54E+00, L2 regularization loss: 4.72E-01
Test scatter: [0.4406 0.0799 0.5201 0.9849], Lowest was [0.4406 0.0799 0.5201 0.9849]
Median for last 10 epochs: [0.568  0.085  0.5334 0.9849], Epochs since improvement 0
  4%|▍         | 19/500 [21:14<8:42:43, 65.21s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.38E+07, Train scatter: [0.6303 0.0872 0.4555 0.9953]
L1 regularization loss: 2.56E+00, L2 regularization loss: 4.78E-01
Test scatter: [0.642  0.085  0.4487 0.985 ], Lowest was [0.4406 0.0799 0.4487 0.9849]
Median for last 10 epochs: [0.568  0.085  0.5248 0.9849], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:43<9:39:25, 72.43s/it]  4%|▍         | 21/500 [23:36<8:52:37, 66.72s/it]  4%|▍         | 22/500 [24:58<9:28:06, 71.31s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.29E+07, Train scatter: [0.563  0.0931 0.3663 0.9952]
L1 regularization loss: 2.57E+00, L2 regularization loss: 4.84E-01
Test scatter: [0.5786 0.0958 0.3766 0.9849], Lowest was [0.4406 0.0799 0.3766 0.9849]
Median for last 10 epochs: [0.568  0.085  0.5201 0.9849], Epochs since improvement 0
  5%|▍         | 23/500 [25:52<8:43:56, 65.91s/it]  5%|▍         | 24/500 [27:14<9:21:28, 70.77s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.22E+07, Train scatter: [0.5868 0.0805 0.3404 0.9952]
L1 regularization loss: 2.58E+00, L2 regularization loss: 4.89E-01
Test scatter: [0.5934 0.0806 0.3419 0.9849], Lowest was [0.4406 0.0799 0.3419 0.9849]
Median for last 10 epochs: [0.5786 0.0824 0.4487 0.9849], Epochs since improvement 0
  5%|▌         | 25/500 [28:07<8:39:10, 65.58s/it]  5%|▌         | 26/500 [29:29<9:15:24, 70.30s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.17E+07, Train scatter: [0.4695 0.0762 0.3375 0.9953]
L1 regularization loss: 2.60E+00, L2 regularization loss: 4.95E-01
Test scatter: [0.4718 0.0757 0.3416 0.985 ], Lowest was [0.4406 0.0757 0.3416 0.9849]
Median for last 10 epochs: [0.5786 0.0806 0.3766 0.9849], Epochs since improvement 0
  5%|▌         | 27/500 [30:22<8:34:39, 65.28s/it]  6%|▌         | 28/500 [31:43<9:10:29, 69.98s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.19E+07, Train scatter: [0.5066 0.0792 0.3363 0.9953]
L1 regularization loss: 2.62E+00, L2 regularization loss: 5.03E-01
Test scatter: [0.5043 0.0778 0.3407 0.985 ], Lowest was [0.4406 0.0757 0.3407 0.9849]
Median for last 10 epochs: [0.5786 0.0806 0.3419 0.985 ], Epochs since improvement 0
  6%|▌         | 29/500 [32:37<8:30:29, 65.03s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.13E+07, Train scatter: [0.455  0.0776 0.3164 0.9953]
L1 regularization loss: 2.63E+00, L2 regularization loss: 5.09E-01
Test scatter: [0.4675 0.0779 0.3246 0.985 ], Lowest was [0.4406 0.0757 0.3246 0.9849]
Median for last 10 epochs: [0.5043 0.0779 0.3416 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [34:05<9:24:19, 72.04s/it]  6%|▌         | 31/500 [34:59<8:39:44, 66.49s/it]  6%|▋         | 32/500 [36:20<9:13:51, 71.01s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.09E+07, Train scatter: [0.4401 0.073  0.316  0.9953]
L1 regularization loss: 2.64E+00, L2 regularization loss: 5.17E-01
Test scatter: [0.4418 0.0731 0.3185 0.985 ], Lowest was [0.4406 0.0731 0.3185 0.9849]
Median for last 10 epochs: [0.4718 0.0778 0.3407 0.985 ], Epochs since improvement 0
  7%|▋         | 33/500 [37:14<8:31:42, 65.74s/it]  7%|▋         | 34/500 [38:35<9:07:13, 70.46s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.06E+07, Train scatter: [0.5585 0.0826 0.3388 0.9953]
L1 regularization loss: 2.67E+00, L2 regularization loss: 5.29E-01
Test scatter: [0.5467 0.0822 0.3393 0.985 ], Lowest was [0.4406 0.0731 0.3185 0.9849]
Median for last 10 epochs: [0.4718 0.0778 0.3393 0.985 ], Epochs since improvement 2
  7%|▋         | 35/500 [39:29<8:27:11, 65.44s/it]  7%|▋         | 36/500 [40:49<9:00:57, 69.95s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.05E+07, Train scatter: [0.4746 0.0809 0.3797 0.9953]
L1 regularization loss: 2.70E+00, L2 regularization loss: 5.40E-01
Test scatter: [0.4666 0.0809 0.3766 0.9849], Lowest was [0.4406 0.0731 0.3185 0.9849]
Median for last 10 epochs: [0.4675 0.0779 0.3393 0.985 ], Epochs since improvement 4
  7%|▋         | 37/500 [41:43<8:22:32, 65.12s/it]  8%|▊         | 38/500 [43:05<9:00:39, 70.21s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.43E+07, Train scatter: [0.4932 0.074  0.3042 0.9953]
L1 regularization loss: 2.72E+00, L2 regularization loss: 5.52E-01
Test scatter: [0.5003 0.0738 0.306  0.9849], Lowest was [0.4406 0.0731 0.306  0.9849]
Median for last 10 epochs: [0.4675 0.0779 0.3246 0.985 ], Epochs since improvement 0
  8%|▊         | 39/500 [43:59<8:21:33, 65.28s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.86E+07, Train scatter: [0.3687 0.0713 0.3217 0.9936]
L1 regularization loss: 2.73E+00, L2 regularization loss: 5.67E-01
Test scatter: [0.3704 0.0705 0.3288 0.9834], Lowest was [0.3704 0.0705 0.306  0.9834]
Median for last 10 epochs: [0.4666 0.0738 0.3288 0.9849], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:27<9:12:11, 72.03s/it]  8%|▊         | 41/500 [46:20<8:28:45, 66.50s/it]  8%|▊         | 42/500 [47:42<9:02:45, 71.10s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.28E+07, Train scatter: [0.7138 0.1281 0.5189 0.7978]
L1 regularization loss: 2.86E+00, L2 regularization loss: 6.28E-01
Test scatter: [0.7066 0.1271 0.5114 0.7857], Lowest was [0.3704 0.0705 0.306  0.7857]
Median for last 10 epochs: [0.5003 0.0809 0.3393 0.9849], Epochs since improvement 0
  9%|▊         | 43/500 [48:36<8:21:25, 65.83s/it]  9%|▉         | 44/500 [49:57<8:56:16, 70.56s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 5.22E+06, Train scatter: [0.4927 0.0876 0.3661 0.5743]
L1 regularization loss: 2.89E+00, L2 regularization loss: 6.49E-01
Test scatter: [0.4869 0.0908 0.377  0.5794], Lowest was [0.3704 0.0705 0.306  0.5794]
Median for last 10 epochs: [0.4869 0.0809 0.3766 0.9834], Epochs since improvement 0
  9%|▉         | 45/500 [50:51<8:16:16, 65.44s/it]  9%|▉         | 46/500 [52:13<8:52:22, 70.36s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.34E+06, Train scatter: [0.3738 0.08   0.3414 0.5492]
L1 regularization loss: 2.91E+00, L2 regularization loss: 6.66E-01
Test scatter: [0.4078 0.0809 0.3512 0.5488], Lowest was [0.3704 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.4869 0.0809 0.3512 0.7857], Epochs since improvement 0
  9%|▉         | 47/500 [53:06<8:13:43, 65.39s/it] 10%|▉         | 48/500 [54:28<8:49:00, 70.22s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.64E+06, Train scatter: [0.4025 0.0763 0.3782 0.6441]
L1 regularization loss: 2.92E+00, L2 regularization loss: 6.80E-01
Test scatter: [0.4022 0.0758 0.3824 0.6418], Lowest was [0.3704 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.4078 0.0809 0.377  0.6418], Epochs since improvement 2
 10%|▉         | 49/500 [55:21<8:10:19, 65.23s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 4.43E+07, Train scatter: [0.9321 0.1745 0.5436 0.947 ]
L1 regularization loss: 3.70E+00, L2 regularization loss: 9.83E-01
Test scatter: [0.9166 0.1708 0.5351 0.9389], Lowest was [0.3704 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.4869 0.0908 0.3824 0.6418], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [56:50<9:02:15, 72.30s/it] 10%|█         | 51/500 [57:44<8:19:11, 66.71s/it] 10%|█         | 52/500 [59:06<8:53:32, 71.46s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.26E+07, Train scatter: [0.8949 0.1574 0.5425 0.7558]
L1 regularization loss: 3.72E+00, L2 regularization loss: 1.01E+00
Test scatter: [0.8828 0.1545 0.534  0.7599], Lowest was [0.3704 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.4869 0.0908 0.3824 0.6418], Epochs since improvement 6
 11%|█         | 53/500 [1:00:00<8:12:23, 66.09s/it] 11%|█         | 54/500 [1:01:22<8:46:03, 70.77s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 9.14E+06, Train scatter: [0.5641 0.1201 0.5351 0.6897]
L1 regularization loss: 3.79E+00, L2 regularization loss: 1.14E+00
Test scatter: [0.5646 0.1181 0.5273 0.68  ], Lowest was [0.3704 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.5646 0.1181 0.5273 0.68  ], Epochs since improvement 8
 11%|█         | 55/500 [1:02:15<8:06:55, 65.65s/it] 11%|█         | 56/500 [1:03:37<8:40:25, 70.33s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 7.84E+06, Train scatter: [0.6262 0.1057 0.5019 0.6528]
L1 regularization loss: 3.82E+00, L2 regularization loss: 1.21E+00
Test scatter: [0.6153 0.1039 0.5029 0.649 ], Lowest was [0.3704 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.6153 0.1181 0.5273 0.68  ], Epochs since improvement 10
 11%|█▏        | 57/500 [1:04:30<8:02:10, 65.31s/it] 12%|█▏        | 58/500 [1:05:51<8:35:21, 69.96s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 6.92E+06, Train scatter: [0.5432 0.0995 0.54   0.6334]
L1 regularization loss: 3.86E+00, L2 regularization loss: 1.26E+00
Test scatter: [0.5385 0.1    0.5316 0.6289], Lowest was [0.3704 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.6153 0.1181 0.5316 0.68  ], Epochs since improvement 12
 12%|█▏        | 59/500 [1:06:45<7:58:00, 65.04s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 6.65E+06, Train scatter: [0.4948 0.0951 0.5269 0.5981]
L1 regularization loss: 3.88E+00, L2 regularization loss: 1.30E+00
Test scatter: [0.4886 0.0962 0.5193 0.5959], Lowest was [0.3704 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.5646 0.1039 0.5273 0.649 ], Epochs since improvement 14
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:08:14<8:50:38, 72.36s/it] 12%|█▏        | 61/500 [1:09:08<8:08:40, 66.79s/it] 12%|█▏        | 62/500 [1:10:29<8:39:56, 71.22s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 5.17E+06, Train scatter: [0.4815 0.0984 0.4084 0.648 ]
L1 regularization loss: 3.90E+00, L2 regularization loss: 1.35E+00
Test scatter: [0.4849 0.0996 0.405  0.648 ], Lowest was [0.3704 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.5385 0.1    0.5193 0.648 ], Epochs since improvement 16
 13%|█▎        | 63/500 [1:11:23<8:00:16, 65.94s/it] 13%|█▎        | 64/500 [1:12:44<8:31:30, 70.39s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 4.66E+06, Train scatter: [0.3934 0.0907 0.3903 0.5979]
L1 regularization loss: 3.92E+00, L2 regularization loss: 1.39E+00
Test scatter: [0.4189 0.0936 0.3911 0.6031], Lowest was [0.3704 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.4886 0.0996 0.5029 0.6289], Epochs since improvement 18
 13%|█▎        | 65/500 [1:13:38<7:54:10, 65.40s/it] 13%|█▎        | 66/500 [1:14:58<8:26:06, 69.97s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 4.53E+06, Train scatter: [0.3819 0.0844 0.3614 0.562 ]
L1 regularization loss: 3.94E+00, L2 regularization loss: 1.42E+00
Test scatter: [0.3915 0.0867 0.3684 0.5638], Lowest was [0.3704 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.4849 0.0962 0.405  0.6031], Epochs since improvement 20
 13%|█▎        | 67/500 [1:15:52<7:49:37, 65.07s/it] 14%|█▎        | 68/500 [1:17:13<8:22:31, 69.80s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 4.04E+06, Train scatter: [0.3336 0.082  0.3561 0.5534]
L1 regularization loss: 3.95E+00, L2 regularization loss: 1.45E+00
Test scatter: [0.3491 0.0835 0.3628 0.5561], Lowest was [0.3491 0.0705 0.306  0.5488]
Median for last 10 epochs: [0.4189 0.0936 0.3911 0.5959], Epochs since improvement 0
 14%|█▍        | 69/500 [1:18:06<7:46:50, 64.99s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.75E+06, Train scatter: [0.3154 0.0776 0.342  0.5331]
L1 regularization loss: 3.97E+00, L2 regularization loss: 1.47E+00
Test scatter: [0.3321 0.0796 0.3484 0.5335], Lowest was [0.3321 0.0705 0.306  0.5335]
Median for last 10 epochs: [0.3915 0.0867 0.3684 0.5638], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:19:35<8:36:26, 72.06s/it] 14%|█▍        | 71/500 [1:20:29<7:55:38, 66.52s/it] 14%|█▍        | 72/500 [1:21:50<8:25:38, 70.88s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.50E+06, Train scatter: [0.3452 0.0763 0.3482 0.5252]
L1 regularization loss: 3.98E+00, L2 regularization loss: 1.49E+00
Test scatter: [0.3708 0.0787 0.3566 0.5265], Lowest was [0.3321 0.0705 0.306  0.5265]
Median for last 10 epochs: [0.3708 0.0835 0.3628 0.5561], Epochs since improvement 0
 15%|█▍        | 73/500 [1:22:43<7:47:47, 65.73s/it] 15%|█▍        | 74/500 [1:24:05<8:20:29, 70.49s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.47E+06, Train scatter: [0.2848 0.0746 0.3392 0.5151]
L1 regularization loss: 4.00E+00, L2 regularization loss: 1.52E+00
Test scatter: [0.3031 0.0768 0.3455 0.5165], Lowest was [0.3031 0.0705 0.306  0.5165]
Median for last 10 epochs: [0.3491 0.0796 0.3566 0.5335], Epochs since improvement 0
 15%|█▌        | 75/500 [1:24:59<7:43:43, 65.47s/it] 15%|█▌        | 76/500 [1:26:21<8:17:21, 70.38s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.30E+06, Train scatter: [0.3097 0.0751 0.3373 0.5119]
L1 regularization loss: 4.01E+00, L2 regularization loss: 1.54E+00
Test scatter: [0.3315 0.0785 0.3447 0.5144], Lowest was [0.3031 0.0705 0.306  0.5144]
Median for last 10 epochs: [0.3321 0.0787 0.3484 0.5265], Epochs since improvement 0
 15%|█▌        | 77/500 [1:27:14<7:41:07, 65.41s/it] 16%|█▌        | 78/500 [1:28:36<8:13:51, 70.22s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.07E+06, Train scatter: [0.2992 0.0731 0.3351 0.5069]
L1 regularization loss: 4.03E+00, L2 regularization loss: 1.57E+00
Test scatter: [0.3229 0.074  0.3464 0.5119], Lowest was [0.3031 0.0705 0.306  0.5119]
Median for last 10 epochs: [0.3315 0.0785 0.3464 0.5165], Epochs since improvement 0
 16%|█▌        | 79/500 [1:29:29<7:37:45, 65.24s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 3.05E+06, Train scatter: [0.394  0.0705 0.3267 0.5024]
L1 regularization loss: 4.06E+00, L2 regularization loss: 1.61E+00
Test scatter: [0.4319 0.0731 0.3332 0.5019], Lowest was [0.3031 0.0705 0.306  0.5019]
Median for last 10 epochs: [0.3315 0.0768 0.3455 0.5144], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:30:59<8:26:55, 72.42s/it] 16%|█▌        | 81/500 [1:31:52<7:46:28, 66.80s/it] 16%|█▋        | 82/500 [1:33:13<8:14:11, 70.94s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.92E+06, Train scatter: [0.2763 0.0738 0.3165 0.5046]
L1 regularization loss: 4.08E+00, L2 regularization loss: 1.64E+00
Test scatter: [0.31   0.0745 0.3234 0.5066], Lowest was [0.3031 0.0705 0.306  0.5019]
Median for last 10 epochs: [0.3229 0.0745 0.3447 0.5119], Epochs since improvement 2
 17%|█▋        | 83/500 [1:34:07<7:37:19, 65.80s/it] 17%|█▋        | 84/500 [1:35:28<8:09:02, 70.53s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.79E+06, Train scatter: [0.3094 0.0732 0.3297 0.5529]
L1 regularization loss: 4.11E+00, L2 regularization loss: 1.69E+00
Test scatter: [0.3763 0.0737 0.3395 0.5619], Lowest was [0.3031 0.0705 0.306  0.5019]
Median for last 10 epochs: [0.3315 0.074  0.3395 0.5119], Epochs since improvement 4
 17%|█▋        | 85/500 [1:36:22<7:33:06, 65.51s/it] 17%|█▋        | 86/500 [1:37:43<8:04:38, 70.24s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.80E+06, Train scatter: [0.2642 0.0696 0.3257 0.4823]
L1 regularization loss: 4.13E+00, L2 regularization loss: 1.72E+00
Test scatter: [0.3379 0.0733 0.333  0.4846], Lowest was [0.3031 0.0705 0.306  0.4846]
Median for last 10 epochs: [0.3379 0.0737 0.3332 0.5066], Epochs since improvement 0
 17%|█▋        | 87/500 [1:38:37<7:29:28, 65.30s/it] 18%|█▊        | 88/500 [1:39:58<7:59:35, 69.84s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.63E+06, Train scatter: [0.2795 0.0712 0.3147 0.5026]
L1 regularization loss: 4.14E+00, L2 regularization loss: 1.75E+00
Test scatter: [0.2878 0.0713 0.3244 0.5067], Lowest was [0.2878 0.0705 0.306  0.4846]
Median for last 10 epochs: [0.3379 0.0733 0.333  0.5066], Epochs since improvement 0
 18%|█▊        | 89/500 [1:40:51<7:25:16, 65.00s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.56E+06, Train scatter: [0.2532 0.0673 0.3081 0.4755]
L1 regularization loss: 4.17E+00, L2 regularization loss: 1.78E+00
Test scatter: [0.2671 0.0702 0.3151 0.4764], Lowest was [0.2671 0.0702 0.306  0.4764]
Median for last 10 epochs: [0.31   0.0733 0.3244 0.5066], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:42:21<8:14:36, 72.38s/it] 18%|█▊        | 91/500 [1:43:14<7:34:55, 66.74s/it] 18%|█▊        | 92/500 [1:44:35<8:02:50, 71.01s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.47E+06, Train scatter: [0.2968 0.0811 0.3149 0.4925]
L1 regularization loss: 4.18E+00, L2 regularization loss: 1.80E+00
Test scatter: [0.2971 0.0797 0.3183 0.498 ], Lowest was [0.2671 0.0702 0.306  0.4764]
Median for last 10 epochs: [0.2971 0.0733 0.3244 0.498 ], Epochs since improvement 2
 19%|█▊        | 93/500 [1:45:29<7:26:26, 65.81s/it] 19%|█▉        | 94/500 [1:46:50<7:55:50, 70.32s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.44E+06, Train scatter: [0.2419 0.0655 0.2943 0.4684]
L1 regularization loss: 4.20E+00, L2 regularization loss: 1.83E+00
Test scatter: [0.2584 0.0682 0.3023 0.4721], Lowest was [0.2584 0.0682 0.3023 0.4721]
Median for last 10 epochs: [0.2878 0.0713 0.3183 0.4846], Epochs since improvement 0
 19%|█▉        | 95/500 [1:47:44<7:21:22, 65.39s/it] 19%|█▉        | 96/500 [1:49:04<7:50:21, 69.86s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.17E+06, Train scatter: [0.26   0.0657 0.2958 0.4654]
L1 regularization loss: 4.22E+00, L2 regularization loss: 1.87E+00
Test scatter: [0.2657 0.0697 0.3056 0.4716], Lowest was [0.2584 0.0682 0.3023 0.4716]
Median for last 10 epochs: [0.2671 0.0702 0.3151 0.4764], Epochs since improvement 0
 19%|█▉        | 97/500 [1:49:57<7:15:04, 64.78s/it] 20%|█▉        | 98/500 [1:51:17<7:44:47, 69.37s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.07E+06, Train scatter: [0.2478 0.0666 0.2933 0.4799]
L1 regularization loss: 4.24E+00, L2 regularization loss: 1.90E+00
Test scatter: [0.263  0.0718 0.2983 0.4783], Lowest was [0.2584 0.0682 0.2983 0.4716]
Median for last 10 epochs: [0.2657 0.0702 0.3056 0.4764], Epochs since improvement 0
 20%|█▉        | 99/500 [1:52:10<7:10:52, 64.47s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 2.05E+06, Train scatter: [0.2619 0.065  0.2895 0.465 ]
L1 regularization loss: 4.26E+00, L2 regularization loss: 1.93E+00
Test scatter: [0.2705 0.0667 0.298  0.4703], Lowest was [0.2584 0.0667 0.298  0.4703]
Median for last 10 epochs: [0.2657 0.0697 0.3023 0.4721], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:53:40<8:00:35, 72.09s/it] 20%|██        | 101/500 [1:54:33<7:21:39, 66.41s/it] 20%|██        | 102/500 [1:55:54<7:49:07, 70.72s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 2.05E+06, Train scatter: [0.2547 0.065  0.3    0.4742]
L1 regularization loss: 4.29E+00, L2 regularization loss: 1.96E+00
Test scatter: [0.2665 0.0653 0.3075 0.4723], Lowest was [0.2584 0.0653 0.298  0.4703]
Median for last 10 epochs: [0.2657 0.0682 0.3023 0.4721], Epochs since improvement 0
 21%|██        | 103/500 [1:56:47<7:12:38, 65.39s/it] 21%|██        | 104/500 [1:58:07<7:40:04, 69.71s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 1.87E+06, Train scatter: [0.3849 0.0624 0.2964 0.4587]
L1 regularization loss: 4.32E+00, L2 regularization loss: 2.00E+00
Test scatter: [0.3894 0.0649 0.301  0.4577], Lowest was [0.2584 0.0649 0.298  0.4577]
Median for last 10 epochs: [0.2665 0.0667 0.301  0.4716], Epochs since improvement 0
 21%|██        | 105/500 [1:59:00<7:05:56, 64.70s/it] 21%|██        | 106/500 [2:00:20<7:36:20, 69.49s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 1.76E+06, Train scatter: [0.2411 0.0628 0.2861 0.4576]
L1 regularization loss: 4.33E+00, L2 regularization loss: 2.03E+00
Test scatter: [0.2464 0.0645 0.2923 0.4577], Lowest was [0.2464 0.0645 0.2923 0.4577]
Median for last 10 epochs: [0.2665 0.0653 0.2983 0.4703], Epochs since improvement 0
 21%|██▏       | 107/500 [2:01:13<7:02:39, 64.53s/it] 22%|██▏       | 108/500 [2:02:34<7:33:33, 69.42s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 1.72E+06, Train scatter: [0.2344 0.0633 0.2865 0.4531]
L1 regularization loss: 4.35E+00, L2 regularization loss: 2.06E+00
Test scatter: [0.2377 0.065  0.2912 0.4536], Lowest was [0.2377 0.0645 0.2912 0.4536]
Median for last 10 epochs: [0.2665 0.065  0.298  0.4577], Epochs since improvement 0
 22%|██▏       | 109/500 [2:03:27<7:00:19, 64.50s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 1.68E+06, Train scatter: [0.2844 0.0644 0.2798 0.4486]
L1 regularization loss: 4.36E+00, L2 regularization loss: 2.09E+00
Test scatter: [0.2755 0.0685 0.2859 0.4486], Lowest was [0.2377 0.0645 0.2859 0.4486]
Median for last 10 epochs: [0.2665 0.065  0.2923 0.4577], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:04:55<7:44:57, 71.53s/it] 22%|██▏       | 111/500 [2:05:48<7:07:47, 65.98s/it] 22%|██▏       | 112/500 [2:07:09<7:34:56, 70.35s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.53E+06, Train scatter: [0.2126 0.0612 0.2826 0.4408]
L1 regularization loss: 4.37E+00, L2 regularization loss: 2.12E+00
Test scatter: [0.2209 0.0624 0.2903 0.4414], Lowest was [0.2209 0.0624 0.2859 0.4414]
Median for last 10 epochs: [0.2464 0.0649 0.2912 0.4536], Epochs since improvement 0
 23%|██▎       | 113/500 [2:08:02<7:00:01, 65.12s/it] 23%|██▎       | 114/500 [2:09:23<7:29:56, 69.94s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.48E+06, Train scatter: [0.2457 0.0585 0.2708 0.4352]
L1 regularization loss: 4.39E+00, L2 regularization loss: 2.15E+00
Test scatter: [0.248  0.0603 0.2768 0.4342], Lowest was [0.2209 0.0603 0.2768 0.4342]
Median for last 10 epochs: [0.2464 0.0645 0.2903 0.4486], Epochs since improvement 0
 23%|██▎       | 115/500 [2:10:16<6:56:14, 64.87s/it] 23%|██▎       | 116/500 [2:11:37<7:26:02, 69.69s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.68E+06, Train scatter: [0.2504 0.0608 0.2917 0.4582]
L1 regularization loss: 4.48E+00, L2 regularization loss: 2.24E+00
Test scatter: [0.256  0.0622 0.299  0.4548], Lowest was [0.2209 0.0603 0.2768 0.4342]
Median for last 10 epochs: [0.248  0.0624 0.2903 0.4486], Epochs since improvement 2
 23%|██▎       | 117/500 [2:12:30<6:53:04, 64.71s/it] 24%|██▎       | 118/500 [2:13:51<7:23:51, 69.72s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.45E+06, Train scatter: [0.2198 0.0583 0.2804 0.453 ]
L1 regularization loss: 4.50E+00, L2 regularization loss: 2.27E+00
Test scatter: [0.2218 0.0596 0.2858 0.452 ], Lowest was [0.2209 0.0596 0.2768 0.4342]
Median for last 10 epochs: [0.248  0.0622 0.2859 0.4486], Epochs since improvement 0
 24%|██▍       | 119/500 [2:14:45<6:51:24, 64.79s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.30E+06, Train scatter: [0.3094 0.059  0.2831 0.453 ]
L1 regularization loss: 4.51E+00, L2 regularization loss: 2.31E+00
Test scatter: [0.3043 0.0595 0.2847 0.4467], Lowest was [0.2209 0.0595 0.2768 0.4342]
Median for last 10 epochs: [0.248  0.0603 0.2858 0.4467], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 24%|██▍       | 120/500 [2:16:12<7:34:04, 71.70s/it] 24%|██▍       | 121/500 [2:17:06<6:57:53, 66.16s/it] 24%|██▍       | 122/500 [2:18:27<7:24:45, 70.60s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 1.24E+06, Train scatter: [0.2027 0.059  0.2787 0.4372]
L1 regularization loss: 4.52E+00, L2 regularization loss: 2.34E+00
Test scatter: [0.2074 0.061  0.2838 0.4356], Lowest was [0.2074 0.0595 0.2768 0.4342]
Median for last 10 epochs: [0.248  0.0603 0.2847 0.4467], Epochs since improvement 0
 25%|██▍       | 123/500 [2:19:20<6:50:35, 65.35s/it] 25%|██▍       | 124/500 [2:20:40<7:18:35, 69.99s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.31E+06, Train scatter: [0.2703 0.057  0.2764 0.434 ]
L1 regularization loss: 4.54E+00, L2 regularization loss: 2.38E+00
Test scatter: [0.2631 0.0584 0.2826 0.4348], Lowest was [0.2074 0.0584 0.2768 0.4342]
Median for last 10 epochs: [0.256  0.0596 0.2847 0.4467], Epochs since improvement 0
 25%|██▌       | 125/500 [2:21:34<6:45:41, 64.91s/it] 25%|██▌       | 126/500 [2:22:55<7:14:45, 69.75s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.17E+06, Train scatter: [0.1963 0.0577 0.2726 0.434 ]
L1 regularization loss: 4.56E+00, L2 regularization loss: 2.42E+00
Test scatter: [0.201  0.0575 0.2799 0.432 ], Lowest was [0.201  0.0575 0.2768 0.432 ]
Median for last 10 epochs: [0.2218 0.0595 0.2838 0.4356], Epochs since improvement 0
 25%|██▌       | 127/500 [2:23:48<6:42:36, 64.76s/it] 26%|██▌       | 128/500 [2:25:08<7:09:33, 69.28s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 1.08E+06, Train scatter: [0.185  0.0557 0.2655 0.4271]
L1 regularization loss: 4.57E+00, L2 regularization loss: 2.45E+00
Test scatter: [0.1909 0.0572 0.2701 0.4263], Lowest was [0.1909 0.0572 0.2701 0.4263]
Median for last 10 epochs: [0.2074 0.0584 0.2826 0.4348], Epochs since improvement 0
 26%|██▌       | 129/500 [2:26:01<6:38:23, 64.43s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 1.12E+06, Train scatter: [0.2063 0.0574 0.2886 0.4424]
L1 regularization loss: 4.58E+00, L2 regularization loss: 2.49E+00
Test scatter: [0.21   0.0581 0.2956 0.438 ], Lowest was [0.1909 0.0572 0.2701 0.4263]
Median for last 10 epochs: [0.2074 0.0581 0.2826 0.4348], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 26%|██▌       | 130/500 [2:27:29<7:21:14, 71.55s/it] 26%|██▌       | 131/500 [2:28:22<6:45:54, 66.00s/it] 26%|██▋       | 132/500 [2:29:42<7:11:27, 70.35s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 1.02E+06, Train scatter: [0.1834 0.054  0.2702 0.4291]
L1 regularization loss: 4.59E+00, L2 regularization loss: 2.52E+00
Test scatter: [0.1908 0.0549 0.276  0.4326], Lowest was [0.1908 0.0549 0.2701 0.4263]
Median for last 10 epochs: [0.201  0.0575 0.2799 0.4326], Epochs since improvement 0
 27%|██▋       | 133/500 [2:30:35<6:38:42, 65.18s/it] 27%|██▋       | 134/500 [2:31:57<7:07:08, 70.02s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 1.01E+06, Train scatter: [0.1964 0.054  0.2814 0.4323]
L1 regularization loss: 4.61E+00, L2 regularization loss: 2.56E+00
Test scatter: [0.1985 0.0543 0.2825 0.4291], Lowest was [0.1908 0.0543 0.2701 0.4263]
Median for last 10 epochs: [0.1985 0.0572 0.2799 0.432 ], Epochs since improvement 0
 27%|██▋       | 135/500 [2:32:50<6:34:45, 64.89s/it] 27%|██▋       | 136/500 [2:34:12<7:05:11, 70.09s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 9.54E+05, Train scatter: [0.1788 0.0514 0.2632 0.4174]
L1 regularization loss: 4.63E+00, L2 regularization loss: 2.59E+00
Test scatter: [0.1845 0.0523 0.2703 0.4198], Lowest was [0.1845 0.0523 0.2701 0.4198]
Median for last 10 epochs: [0.1909 0.0549 0.276  0.4291], Epochs since improvement 0
 27%|██▋       | 137/500 [2:35:05<6:33:27, 65.03s/it] 28%|██▊       | 138/500 [2:36:26<7:01:32, 69.87s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: 9.22E+05, Train scatter: [0.1846 0.0511 0.2665 0.4248]
L1 regularization loss: 4.64E+00, L2 regularization loss: 2.62E+00
Test scatter: [0.1878 0.0517 0.2702 0.4247], Lowest was [0.1845 0.0517 0.2701 0.4198]
Median for last 10 epochs: [0.1908 0.0543 0.276  0.4291], Epochs since improvement 0
 28%|██▊       | 139/500 [2:37:19<6:30:03, 64.83s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: 8.84E+05, Train scatter: [0.2229 0.0522 0.2707 0.4261]
L1 regularization loss: 4.64E+00, L2 regularization loss: 2.64E+00
Test scatter: [0.227  0.0522 0.271  0.421 ], Lowest was [0.1845 0.0517 0.2701 0.4198]
Median for last 10 epochs: [0.1908 0.0523 0.271  0.4247], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 28%|██▊       | 140/500 [2:38:48<7:11:03, 71.84s/it] 28%|██▊       | 141/500 [2:39:41<6:36:30, 66.27s/it] 28%|██▊       | 142/500 [2:41:02<7:01:06, 70.58s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: 8.24E+05, Train scatter: [0.1957 0.0508 0.2615 0.4235]
L1 regularization loss: 4.65E+00, L2 regularization loss: 2.67E+00
Test scatter: [0.2047 0.0517 0.268  0.4212], Lowest was [0.1845 0.0517 0.268  0.4198]
Median for last 10 epochs: [0.1985 0.0522 0.2703 0.4212], Epochs since improvement 0
 29%|██▊       | 143/500 [2:41:55<6:28:44, 65.34s/it] 29%|██▉       | 144/500 [2:43:16<6:56:31, 70.20s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 7.73E+05, Train scatter: [0.1712 0.0535 0.2676 0.4226]
L1 regularization loss: 4.66E+00, L2 regularization loss: 2.70E+00
Test scatter: [0.179  0.0535 0.2746 0.427 ], Lowest was [0.179  0.0517 0.268  0.4198]
Median for last 10 epochs: [0.1878 0.0522 0.2703 0.4212], Epochs since improvement 0
 29%|██▉       | 145/500 [2:44:09<6:25:18, 65.12s/it] 29%|██▉       | 146/500 [2:45:31<6:52:39, 69.94s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 7.83E+05, Train scatter: [0.2101 0.0495 0.269  0.4144]
L1 regularization loss: 4.66E+00, L2 regularization loss: 2.72E+00
Test scatter: [0.213  0.0503 0.2734 0.4124], Lowest was [0.179  0.0503 0.268  0.4124]
Median for last 10 epochs: [0.2047 0.0517 0.271  0.4212], Epochs since improvement 0
 29%|██▉       | 147/500 [2:46:24<6:22:15, 64.97s/it] 30%|██▉       | 148/500 [2:47:44<6:47:29, 69.46s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 7.22E+05, Train scatter: [0.1692 0.0505 0.2642 0.4206]
L1 regularization loss: 4.67E+00, L2 regularization loss: 2.74E+00
Test scatter: [0.1739 0.0509 0.2723 0.4239], Lowest was [0.1739 0.0503 0.268  0.4124]
Median for last 10 epochs: [0.2047 0.0517 0.2723 0.4212], Epochs since improvement 0
 30%|██▉       | 149/500 [2:48:37<6:17:44, 64.57s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 6.47E+05, Train scatter: [0.1701 0.0501 0.2601 0.4233]
L1 regularization loss: 4.68E+00, L2 regularization loss: 2.76E+00
Test scatter: [0.1733 0.0506 0.2627 0.4187], Lowest was [0.1733 0.0503 0.2627 0.4124]
Median for last 10 epochs: [0.179  0.0509 0.2723 0.4212], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 30%|███       | 150/500 [2:50:05<6:56:39, 71.43s/it] 30%|███       | 151/500 [2:50:58<6:23:32, 65.94s/it] 30%|███       | 152/500 [2:52:18<6:46:45, 70.13s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 6.33E+05, Train scatter: [0.2112 0.052  0.2633 0.4303]
L1 regularization loss: 4.68E+00, L2 regularization loss: 2.78E+00
Test scatter: [0.2165 0.0524 0.2732 0.4308], Lowest was [0.1733 0.0503 0.2627 0.4124]
Median for last 10 epochs: [0.179  0.0509 0.2732 0.4239], Epochs since improvement 2
 31%|███       | 153/500 [2:53:11<6:16:23, 65.08s/it] 31%|███       | 154/500 [2:54:31<6:41:44, 69.67s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 5.66E+05, Train scatter: [0.1815 0.0493 0.2518 0.409 ]
L1 regularization loss: 4.69E+00, L2 regularization loss: 2.81E+00
Test scatter: [0.1787 0.0494 0.2561 0.4055], Lowest was [0.1733 0.0494 0.2561 0.4055]
Median for last 10 epochs: [0.1787 0.0506 0.2723 0.4187], Epochs since improvement 0
 31%|███       | 155/500 [2:55:24<6:12:00, 64.70s/it] 31%|███       | 156/500 [2:56:45<6:37:35, 69.35s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 5.19E+05, Train scatter: [0.1776 0.0497 0.2525 0.4049]
L1 regularization loss: 4.68E+00, L2 regularization loss: 2.83E+00
Test scatter: [0.1752 0.05   0.2543 0.4   ], Lowest was [0.1733 0.0494 0.2543 0.4   ]
Median for last 10 epochs: [0.1752 0.0506 0.2627 0.4187], Epochs since improvement 0
 31%|███▏      | 157/500 [2:57:38<6:08:49, 64.52s/it] 32%|███▏      | 158/500 [2:58:59<6:36:20, 69.53s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 4.58E+05, Train scatter: [0.1668 0.0489 0.2598 0.4152]
L1 regularization loss: 4.69E+00, L2 regularization loss: 2.85E+00
Test scatter: [0.1736 0.0487 0.265  0.4182], Lowest was [0.1733 0.0487 0.2543 0.4   ]
Median for last 10 epochs: [0.1752 0.05   0.2627 0.4182], Epochs since improvement 0
 32%|███▏      | 159/500 [2:59:52<6:07:23, 64.64s/it]Epoch: 160 done with learning rate 9.04E-03, Train loss: 4.06E+05, Train scatter: [0.1679 0.0462 0.2531 0.3968]
L1 regularization loss: 4.70E+00, L2 regularization loss: 2.87E+00
Test scatter: [0.1688 0.0465 0.259  0.3964], Lowest was [0.1688 0.0465 0.2543 0.3964]
Median for last 10 epochs: [0.1752 0.0494 0.259  0.4055], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 32%|███▏      | 160/500 [3:01:21<6:47:01, 71.83s/it] 32%|███▏      | 161/500 [3:02:14<6:14:20, 66.26s/it] 32%|███▏      | 162/500 [3:03:35<6:38:35, 70.76s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: 3.15E+05, Train scatter: [0.2142 0.0471 0.2563 0.3986]
L1 regularization loss: 4.70E+00, L2 regularization loss: 2.90E+00
Test scatter: [0.2237 0.0477 0.2597 0.4011], Lowest was [0.1688 0.0465 0.2543 0.3964]
Median for last 10 epochs: [0.1752 0.0487 0.259  0.4011], Epochs since improvement 2
 33%|███▎      | 163/500 [3:04:28<6:07:32, 65.44s/it] 33%|███▎      | 164/500 [3:05:49<6:32:17, 70.05s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: 2.57E+05, Train scatter: [0.2045 0.0492 0.2579 0.402 ]
L1 regularization loss: 4.72E+00, L2 regularization loss: 2.93E+00
Test scatter: [0.2029 0.0491 0.2623 0.3999], Lowest was [0.1688 0.0465 0.2543 0.3964]
Median for last 10 epochs: [0.1752 0.0487 0.2597 0.4   ], Epochs since improvement 4
 33%|███▎      | 165/500 [3:06:42<6:02:48, 64.98s/it] 33%|███▎      | 166/500 [3:08:03<6:28:05, 69.72s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: 1.86E+05, Train scatter: [0.1607 0.0459 0.2424 0.4029]
L1 regularization loss: 4.73E+00, L2 regularization loss: 2.96E+00
Test scatter: [0.213  0.0459 0.2455 0.3983], Lowest was [0.1688 0.0459 0.2455 0.3964]
Median for last 10 epochs: [0.2029 0.0477 0.2597 0.3999], Epochs since improvement 0
 33%|███▎      | 167/500 [3:08:56<5:59:17, 64.74s/it] 34%|███▎      | 168/500 [3:10:17<6:24:02, 69.41s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: 9.16E+04, Train scatter: [0.1647 0.0467 0.254  0.4058]
L1 regularization loss: 4.75E+00, L2 regularization loss: 2.98E+00
Test scatter: [0.1726 0.0473 0.2622 0.408 ], Lowest was [0.1688 0.0459 0.2455 0.3964]
Median for last 10 epochs: [0.2029 0.0473 0.2597 0.3999], Epochs since improvement 2
 34%|███▍      | 169/500 [3:11:10<5:55:54, 64.52s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: 2.03E+04, Train scatter: [0.2193 0.0451 0.2445 0.3913]
L1 regularization loss: 4.75E+00, L2 regularization loss: 2.99E+00
Test scatter: [0.2287 0.0456 0.2501 0.3934], Lowest was [0.1688 0.0456 0.2455 0.3934]
Median for last 10 epochs: [0.213  0.0473 0.2597 0.3999], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 34%|███▍      | 170/500 [3:12:37<6:32:33, 71.37s/it] 34%|███▍      | 171/500 [3:13:30<6:01:11, 65.87s/it] 34%|███▍      | 172/500 [3:14:51<6:25:31, 70.52s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -4.28E+04, Train scatter: [0.1423 0.0443 0.2416 0.3906]
L1 regularization loss: 4.75E+00, L2 regularization loss: 3.01E+00
Test scatter: [0.1664 0.0446 0.2484 0.389 ], Lowest was [0.1664 0.0446 0.2455 0.389 ]
Median for last 10 epochs: [0.2029 0.0459 0.2501 0.3983], Epochs since improvement 0
 35%|███▍      | 173/500 [3:15:45<5:55:49, 65.29s/it] 35%|███▍      | 174/500 [3:17:06<6:20:22, 70.01s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -1.04E+05, Train scatter: [0.1616 0.045  0.2384 0.3869]
L1 regularization loss: 4.75E+00, L2 regularization loss: 3.04E+00
Test scatter: [0.1884 0.0455 0.2409 0.3877], Lowest was [0.1664 0.0446 0.2409 0.3877]
Median for last 10 epochs: [0.1884 0.0456 0.2484 0.3934], Epochs since improvement 0
 35%|███▌      | 175/500 [3:17:59<5:51:43, 64.93s/it] 35%|███▌      | 176/500 [3:19:19<6:16:27, 69.71s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -1.63E+05, Train scatter: [0.1503 0.0465 0.2403 0.3941]
L1 regularization loss: 4.74E+00, L2 regularization loss: 3.04E+00
Test scatter: [0.1693 0.0469 0.2406 0.3921], Lowest was [0.1664 0.0446 0.2406 0.3877]
Median for last 10 epochs: [0.1726 0.0456 0.2484 0.3921], Epochs since improvement 0
 35%|███▌      | 177/500 [3:20:13<5:48:28, 64.73s/it] 36%|███▌      | 178/500 [3:21:36<6:17:14, 70.29s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -2.10E+05, Train scatter: [0.1512 0.0436 0.232  0.3856]
L1 regularization loss: 4.74E+00, L2 regularization loss: 3.06E+00
Test scatter: [0.2243 0.0439 0.2353 0.386 ], Lowest was [0.1664 0.0439 0.2353 0.386 ]
Median for last 10 epochs: [0.1884 0.0455 0.2409 0.389 ], Epochs since improvement 0
 36%|███▌      | 179/500 [3:22:30<5:50:09, 65.45s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -2.58E+05, Train scatter: [0.1601 0.0441 0.233  0.3858]
L1 regularization loss: 4.75E+00, L2 regularization loss: 3.08E+00
Test scatter: [0.1829 0.0452 0.2364 0.3849], Lowest was [0.1664 0.0439 0.2353 0.3849]
Median for last 10 epochs: [0.1829 0.0452 0.2406 0.3877], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 36%|███▌      | 180/500 [3:24:01<6:29:49, 73.09s/it] 36%|███▌      | 181/500 [3:24:54<5:56:39, 67.08s/it] 36%|███▋      | 182/500 [3:26:16<6:19:01, 71.51s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -2.63E+05, Train scatter: [0.1349 0.0437 0.2408 0.3876]
L1 regularization loss: 4.77E+00, L2 regularization loss: 3.11E+00
Test scatter: [0.1514 0.0445 0.243  0.3893], Lowest was [0.1514 0.0439 0.2353 0.3849]
Median for last 10 epochs: [0.1829 0.0452 0.2406 0.3877], Epochs since improvement 0
 37%|███▋      | 183/500 [3:27:09<5:48:19, 65.93s/it] 37%|███▋      | 184/500 [3:28:29<6:09:56, 70.24s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -2.90E+05, Train scatter: [0.1429 0.0435 0.2458 0.3912]
L1 regularization loss: 4.80E+00, L2 regularization loss: 3.15E+00
Test scatter: [0.1563 0.0435 0.2488 0.3899], Lowest was [0.1514 0.0435 0.2353 0.3849]
Median for last 10 epochs: [0.1693 0.0445 0.2406 0.3893], Epochs since improvement 0
 37%|███▋      | 185/500 [3:29:22<5:41:35, 65.06s/it] 37%|███▋      | 186/500 [3:30:43<6:05:06, 69.76s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -2.66E+05, Train scatter: [0.1645 0.0425 0.2289 0.3905]
L1 regularization loss: 4.93E+00, L2 regularization loss: 3.25E+00
Test scatter: [0.2166 0.0428 0.2324 0.3892], Lowest was [0.1514 0.0428 0.2324 0.3849]
Median for last 10 epochs: [0.1829 0.0439 0.2364 0.3892], Epochs since improvement 0
 37%|███▋      | 187/500 [3:31:36<5:37:38, 64.72s/it] 38%|███▊      | 188/500 [3:32:57<6:02:09, 69.65s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -3.39E+05, Train scatter: [0.1363 0.0424 0.2258 0.3902]
L1 regularization loss: 4.92E+00, L2 regularization loss: 3.29E+00
Test scatter: [0.1454 0.0427 0.229  0.3916], Lowest was [0.1454 0.0427 0.229  0.3849]
Median for last 10 epochs: [0.1563 0.0435 0.2364 0.3893], Epochs since improvement 0
 38%|███▊      | 189/500 [3:33:50<5:35:21, 64.70s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -3.54E+05, Train scatter: [0.1448 0.0419 0.2217 0.3879]
L1 regularization loss: 4.91E+00, L2 regularization loss: 3.31E+00
Test scatter: [0.2204 0.0426 0.2257 0.3891], Lowest was [0.1454 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.1563 0.0428 0.2324 0.3893], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 38%|███▊      | 190/500 [3:35:18<6:10:02, 71.62s/it] 38%|███▊      | 191/500 [3:36:11<5:40:33, 66.13s/it] 38%|███▊      | 192/500 [3:37:33<6:03:24, 70.79s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -3.64E+05, Train scatter: [0.1681 0.0428 0.2496 0.3941]
L1 regularization loss: 4.90E+00, L2 regularization loss: 3.33E+00
Test scatter: [0.1898 0.0433 0.2504 0.3901], Lowest was [0.1454 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.1898 0.0428 0.2324 0.3899], Epochs since improvement 2
 39%|███▊      | 193/500 [3:38:26<5:35:00, 65.47s/it] 39%|███▉      | 194/500 [3:39:47<5:58:38, 70.32s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -3.69E+05, Train scatter: [0.1585 0.0441 0.24   0.3912]
L1 regularization loss: 4.89E+00, L2 regularization loss: 3.34E+00
Test scatter: [0.1642 0.044  0.242  0.39  ], Lowest was [0.1454 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.1898 0.0428 0.2324 0.39  ], Epochs since improvement 4
 39%|███▉      | 195/500 [3:40:41<5:31:17, 65.17s/it] 39%|███▉      | 196/500 [3:42:02<5:55:17, 70.12s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -3.71E+05, Train scatter: [0.136  0.043  0.2281 0.3926]
L1 regularization loss: 4.88E+00, L2 regularization loss: 3.36E+00
Test scatter: [0.169  0.0434 0.2311 0.3935], Lowest was [0.1454 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.169  0.0433 0.2311 0.3901], Epochs since improvement 6
 39%|███▉      | 197/500 [3:42:55<5:28:14, 65.00s/it] 40%|███▉      | 198/500 [3:44:16<5:50:44, 69.68s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -3.78E+05, Train scatter: [0.1584 0.0466 0.23   0.3955]
L1 regularization loss: 4.89E+00, L2 regularization loss: 3.38E+00
Test scatter: [0.1672 0.0469 0.2333 0.3919], Lowest was [0.1454 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.169  0.0434 0.2333 0.3901], Epochs since improvement 8
 40%|███▉      | 199/500 [3:45:09<5:24:44, 64.73s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -3.87E+05, Train scatter: [0.1503 0.0467 0.2399 0.3966]
L1 regularization loss: 4.86E+00, L2 regularization loss: 3.39E+00
Test scatter: [0.1543 0.0465 0.2423 0.3985], Lowest was [0.1454 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.1672 0.044  0.242  0.3919], Epochs since improvement 10
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 40%|████      | 200/500 [3:46:38<5:59:30, 71.90s/it] 40%|████      | 201/500 [3:47:31<5:30:24, 66.30s/it] 40%|████      | 202/500 [3:48:51<5:50:26, 70.56s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -3.97E+05, Train scatter: [0.1635 0.0485 0.2385 0.3971]
L1 regularization loss: 4.88E+00, L2 regularization loss: 3.42E+00
Test scatter: [0.1706 0.0486 0.2426 0.3973], Lowest was [0.1454 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.1672 0.0465 0.242  0.3935], Epochs since improvement 12
 41%|████      | 203/500 [3:49:45<5:23:31, 65.36s/it] 41%|████      | 204/500 [3:51:05<5:44:51, 69.90s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -4.04E+05, Train scatter: [0.1379 0.0429 0.2223 0.3933]
L1 regularization loss: 4.88E+00, L2 regularization loss: 3.44E+00
Test scatter: [0.1425 0.0436 0.2272 0.3917], Lowest was [0.1425 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.1672 0.0465 0.2333 0.3935], Epochs since improvement 0
 41%|████      | 205/500 [3:51:59<5:19:19, 64.95s/it] 41%|████      | 206/500 [3:53:19<5:40:24, 69.47s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -3.97E+05, Train scatter: [0.1254 0.0451 0.2567 0.4373]
L1 regularization loss: 4.88E+00, L2 regularization loss: 3.46E+00
Test scatter: [0.1603 0.045  0.2597 0.4302], Lowest was [0.1425 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.1603 0.0465 0.2423 0.3973], Epochs since improvement 2
 41%|████▏     | 207/500 [3:54:12<5:15:31, 64.61s/it] 42%|████▏     | 208/500 [3:55:32<5:37:43, 69.40s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -2.83E+05, Train scatter: [0.5353 0.0684 0.3971 0.5362]
L1 regularization loss: 5.23E+00, L2 regularization loss: 3.68E+00
Test scatter: [0.5395 0.0687 0.3882 0.5272], Lowest was [0.1425 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.1603 0.0465 0.2426 0.3985], Epochs since improvement 4
 42%|████▏     | 209/500 [3:56:26<5:13:07, 64.56s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -3.03E+05, Train scatter: [0.3746 0.054  0.2634 0.431 ]
L1 regularization loss: 5.41E+00, L2 regularization loss: 4.00E+00
Test scatter: [0.3627 0.0547 0.2636 0.4205], Lowest was [0.1425 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.1706 0.0486 0.2597 0.4205], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 42%|████▏     | 210/500 [3:57:53<5:45:08, 71.41s/it] 42%|████▏     | 211/500 [3:58:46<5:17:24, 65.90s/it] 42%|████▏     | 212/500 [4:00:07<5:37:30, 70.32s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -3.70E+05, Train scatter: [0.2177 0.0476 0.2487 0.4194]
L1 regularization loss: 5.39E+00, L2 regularization loss: 4.04E+00
Test scatter: [0.2144 0.0466 0.2504 0.4134], Lowest was [0.1425 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.2144 0.0466 0.2597 0.4205], Epochs since improvement 8
 43%|████▎     | 213/500 [4:01:00<5:11:34, 65.14s/it] 43%|████▎     | 214/500 [4:02:21<5:33:53, 70.05s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: -3.83E+05, Train scatter: [0.3556 0.0482 0.2506 0.4136]
L1 regularization loss: 5.36E+00, L2 regularization loss: 4.07E+00
Test scatter: [0.3473 0.0481 0.2548 0.4133], Lowest was [0.1425 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.3473 0.0481 0.2597 0.4205], Epochs since improvement 10
 43%|████▎     | 215/500 [4:03:15<5:08:44, 65.00s/it] 43%|████▎     | 216/500 [4:04:36<5:30:34, 69.84s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -3.95E+05, Train scatter: [0.1515 0.0436 0.2332 0.3983]
L1 regularization loss: 5.33E+00, L2 regularization loss: 4.09E+00
Test scatter: [0.1529 0.0434 0.2381 0.3934], Lowest was [0.1425 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.3473 0.0481 0.2548 0.4134], Epochs since improvement 12
 43%|████▎     | 217/500 [4:05:29<5:05:39, 64.81s/it] 44%|████▎     | 218/500 [4:06:49<5:26:15, 69.42s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -3.56E+05, Train scatter: [0.3869 0.0434 0.2366 0.4081]
L1 regularization loss: 5.43E+00, L2 regularization loss: 4.18E+00
Test scatter: [0.3761 0.0427 0.2443 0.4006], Lowest was [0.1425 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.3473 0.0466 0.2504 0.4133], Epochs since improvement 14
 44%|████▍     | 219/500 [4:07:42<5:02:14, 64.54s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -3.86E+05, Train scatter: [0.3797 0.0691 0.3561 0.4719]
L1 regularization loss: 5.44E+00, L2 regularization loss: 4.23E+00
Test scatter: [0.3697 0.0679 0.3511 0.4669], Lowest was [0.1425 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.3473 0.0466 0.2504 0.4133], Epochs since improvement 16
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 44%|████▍     | 220/500 [4:09:09<5:32:42, 71.29s/it] 44%|████▍     | 221/500 [4:10:02<5:05:54, 65.79s/it] 44%|████▍     | 222/500 [4:11:23<5:25:59, 70.36s/it]Epoch: 222 done with learning rate 7.33E-03, Train loss: -3.99E+05, Train scatter: [0.3242 0.0525 0.2348 0.4152]
L1 regularization loss: 5.42E+00, L2 regularization loss: 4.27E+00
Test scatter: [0.3149 0.0513 0.2358 0.4036], Lowest was [0.1425 0.0426 0.2257 0.3849]
Median for last 10 epochs: [0.3473 0.0481 0.2443 0.4036], Epochs since improvement 18
 45%|████▍     | 223/500 [4:12:16<5:00:45, 65.15s/it] 45%|████▍     | 224/500 [4:13:37<5:21:17, 69.85s/it]Epoch: 224 done with learning rate 7.26E-03, Train loss: -4.02E+05, Train scatter: [0.3518 0.0413 0.2224 0.4006]
L1 regularization loss: 5.44E+00, L2 regularization loss: 4.33E+00
Test scatter: [0.3431 0.041  0.2269 0.3975], Lowest was [0.1425 0.041  0.2257 0.3849]
Median for last 10 epochs: [0.3431 0.0434 0.2381 0.4006], Epochs since improvement 0
 45%|████▌     | 225/500 [4:14:30<4:56:51, 64.77s/it] 45%|████▌     | 226/500 [4:15:51<5:18:14, 69.69s/it]Epoch: 226 done with learning rate 7.20E-03, Train loss: -3.95E+05, Train scatter: [0.189  0.0416 0.2187 0.399 ]
L1 regularization loss: 5.44E+00, L2 regularization loss: 4.35E+00
Test scatter: [0.1827 0.0409 0.2204 0.392 ], Lowest was [0.1425 0.0409 0.2204 0.3849]
Median for last 10 epochs: [0.3431 0.0427 0.2358 0.4006], Epochs since improvement 0
 45%|████▌     | 227/500 [4:16:44<4:54:29, 64.72s/it] 46%|████▌     | 228/500 [4:18:05<5:15:20, 69.56s/it]Epoch: 228 done with learning rate 7.13E-03, Train loss: -4.12E+05, Train scatter: [0.2    0.0447 0.2355 0.4133]
L1 regularization loss: 5.47E+00, L2 regularization loss: 4.38E+00
Test scatter: [0.1973 0.0442 0.2405 0.4061], Lowest was [0.1425 0.0409 0.2204 0.3849]
Median for last 10 epochs: [0.3149 0.0442 0.2358 0.4036], Epochs since improvement 2
 46%|████▌     | 229/500 [4:18:58<4:51:44, 64.59s/it]Epoch: 230 done with learning rate 7.06E-03, Train loss: -3.72E+05, Train scatter: [0.1854 0.0447 0.238  0.4197]
L1 regularization loss: 5.61E+00, L2 regularization loss: 4.48E+00
Test scatter: [0.1811 0.044  0.2404 0.4134], Lowest was [0.1425 0.0409 0.2204 0.3849]
Median for last 10 epochs: [0.1973 0.044  0.2358 0.4036], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 46%|████▌     | 230/500 [4:20:26<5:22:02, 71.57s/it] 46%|████▌     | 231/500 [4:21:19<4:55:44, 65.97s/it] 46%|████▋     | 232/500 [4:22:40<5:14:30, 70.41s/it]Epoch: 232 done with learning rate 6.99E-03, Train loss: -3.73E+05, Train scatter: [0.1406 0.0422 0.23   0.4198]
L1 regularization loss: 5.59E+00, L2 regularization loss: 4.50E+00
Test scatter: [0.1395 0.0418 0.231  0.4067], Lowest was [0.1395 0.0409 0.2204 0.3849]
Median for last 10 epochs: [0.1827 0.0418 0.231  0.4061], Epochs since improvement 0
 47%|████▋     | 233/500 [4:23:33<4:50:04, 65.19s/it] 47%|████▋     | 234/500 [4:24:54<5:10:43, 70.09s/it]Epoch: 234 done with learning rate 6.93E-03, Train loss: -4.14E+05, Train scatter: [0.2247 0.0561 0.2367 0.4096]
L1 regularization loss: 5.55E+00, L2 regularization loss: 4.49E+00
Test scatter: [0.2205 0.0563 0.2368 0.4003], Lowest was [0.1395 0.0409 0.2204 0.3849]
Median for last 10 epochs: [0.1827 0.044  0.2368 0.4061], Epochs since improvement 2
 47%|████▋     | 235/500 [4:25:47<4:46:52, 64.95s/it] 47%|████▋     | 236/500 [4:27:07<5:05:49, 69.51s/it]Epoch: 236 done with learning rate 6.86E-03, Train loss: -4.06E+05, Train scatter: [0.1584 0.0472 0.2421 0.429 ]
L1 regularization loss: 5.54E+00, L2 regularization loss: 4.51E+00
Test scatter: [0.1568 0.0468 0.2444 0.4263], Lowest was [0.1395 0.0409 0.2204 0.3849]
Median for last 10 epochs: [0.1811 0.0442 0.2404 0.4067], Epochs since improvement 4
 47%|████▋     | 237/500 [4:28:00<4:43:10, 64.60s/it] 48%|████▊     | 238/500 [4:29:21<5:02:34, 69.29s/it]Epoch: 238 done with learning rate 6.79E-03, Train loss: -4.28E+05, Train scatter: [0.1415 0.0427 0.226  0.4107]
L1 regularization loss: 5.52E+00, L2 regularization loss: 4.50E+00
Test scatter: [0.1423 0.0427 0.2295 0.4063], Lowest was [0.1395 0.0409 0.2204 0.3849]
Median for last 10 epochs: [0.1568 0.044  0.2368 0.4067], Epochs since improvement 6
 48%|████▊     | 239/500 [4:30:13<4:40:05, 64.39s/it]Epoch: 240 done with learning rate 6.72E-03, Train loss: -4.26E+05, Train scatter: [0.1243 0.0408 0.2245 0.3977]
L1 regularization loss: 5.54E+00, L2 regularization loss: 4.53E+00
Test scatter: [0.1239 0.0402 0.2263 0.3912], Lowest was [0.1239 0.0402 0.2204 0.3849]
Median for last 10 epochs: [0.1423 0.0427 0.231  0.4063], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 48%|████▊     | 240/500 [4:31:41<5:08:34, 71.21s/it] 48%|████▊     | 241/500 [4:32:34<4:44:05, 65.81s/it] 48%|████▊     | 242/500 [4:33:54<5:02:00, 70.24s/it]Epoch: 242 done with learning rate 6.65E-03, Train loss: -4.29E+05, Train scatter: [0.127  0.0433 0.2285 0.4013]
L1 regularization loss: 5.55E+00, L2 regularization loss: 4.55E+00
Test scatter: [0.1275 0.0429 0.2309 0.3942], Lowest was [0.1239 0.0402 0.2204 0.3849]
Median for last 10 epochs: [0.1423 0.0429 0.2309 0.4003], Epochs since improvement 2
 49%|████▊     | 243/500 [4:34:47<4:38:34, 65.04s/it] 49%|████▉     | 244/500 [4:36:07<4:56:45, 69.55s/it]Epoch: 244 done with learning rate 6.58E-03, Train loss: -4.34E+05, Train scatter: [0.2191 0.0496 0.2432 0.4217]
L1 regularization loss: 5.55E+00, L2 regularization loss: 4.57E+00
Test scatter: [0.2132 0.0484 0.2426 0.4127], Lowest was [0.1239 0.0402 0.2204 0.3849]
Median for last 10 epochs: [0.1423 0.0429 0.2309 0.4063], Epochs since improvement 4
 49%|████▉     | 245/500 [4:37:01<4:34:48, 64.66s/it] 49%|████▉     | 246/500 [4:38:21<4:53:26, 69.32s/it]Epoch: 246 done with learning rate 6.51E-03, Train loss: -4.13E+05, Train scatter: [0.1625 0.0409 0.2248 0.3958]
L1 regularization loss: 5.59E+00, L2 regularization loss: 4.61E+00
Test scatter: [0.1621 0.0409 0.2284 0.3902], Lowest was [0.1239 0.0402 0.2204 0.3849]
Median for last 10 epochs: [0.1423 0.0427 0.2295 0.3942], Epochs since improvement 6
 49%|████▉     | 247/500 [4:39:14<4:31:33, 64.40s/it] 50%|████▉     | 248/500 [4:40:34<4:50:38, 69.20s/it]Epoch: 248 done with learning rate 6.44E-03, Train loss: -4.45E+05, Train scatter: [0.2531 0.0419 0.2165 0.3986]
L1 regularization loss: 5.61E+00, L2 regularization loss: 4.64E+00
Test scatter: [0.2471 0.0415 0.2181 0.3932], Lowest was [0.1239 0.0402 0.2181 0.3849]
Median for last 10 epochs: [0.1621 0.0415 0.2284 0.3932], Epochs since improvement 0
 50%|████▉     | 249/500 [4:41:27<4:29:00, 64.31s/it]Epoch: 250 done with learning rate 6.37E-03, Train loss: -4.42E+05, Train scatter: [0.137  0.0411 0.2337 0.3986]
L1 regularization loss: 5.60E+00, L2 regularization loss: 4.65E+00
Test scatter: [0.1379 0.041  0.2351 0.3896], Lowest was [0.1239 0.0402 0.2181 0.3849]
Median for last 10 epochs: [0.1621 0.0415 0.2309 0.3932], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 50%|█████     | 250/500 [4:42:56<4:58:36, 71.67s/it] 50%|█████     | 251/500 [4:43:49<4:34:03, 66.04s/it] 50%|█████     | 252/500 [4:45:09<4:50:44, 70.34s/it]Epoch: 252 done with learning rate 6.30E-03, Train loss: -4.48E+05, Train scatter: [0.1224 0.0406 0.2227 0.3918]
L1 regularization loss: 5.61E+00, L2 regularization loss: 4.67E+00
Test scatter: [0.1238 0.0404 0.2237 0.3846], Lowest was [0.1238 0.0402 0.2181 0.3846]
Median for last 10 epochs: [0.1621 0.041  0.2284 0.3902], Epochs since improvement 0
 51%|█████     | 253/500 [4:46:02<4:28:18, 65.18s/it] 51%|█████     | 254/500 [4:47:22<4:45:41, 69.68s/it]Epoch: 254 done with learning rate 6.23E-03, Train loss: -4.45E+05, Train scatter: [0.1766 0.0416 0.2274 0.4007]
L1 regularization loss: 5.62E+00, L2 regularization loss: 4.69E+00
Test scatter: [0.1741 0.0414 0.2286 0.3953], Lowest was [0.1238 0.0402 0.2181 0.3846]
Median for last 10 epochs: [0.1621 0.041  0.2284 0.3902], Epochs since improvement 2
 51%|█████     | 255/500 [4:48:15<4:24:01, 64.66s/it] 51%|█████     | 256/500 [4:49:35<4:41:34, 69.24s/it]Epoch: 256 done with learning rate 6.15E-03, Train loss: -2.78E+05, Train scatter: [0.2121 0.0558 0.3478 0.47  ]
L1 regularization loss: 5.86E+00, L2 regularization loss: 4.86E+00
Test scatter: [0.2101 0.0552 0.3402 0.4644], Lowest was [0.1238 0.0402 0.2181 0.3846]
Median for last 10 epochs: [0.1741 0.0414 0.2286 0.3932], Epochs since improvement 4
 51%|█████▏    | 257/500 [4:50:28<4:20:35, 64.34s/it] 52%|█████▏    | 258/500 [4:51:49<4:39:16, 69.24s/it]Epoch: 258 done with learning rate 6.08E-03, Train loss: -4.31E+05, Train scatter: [0.1438 0.0434 0.2316 0.4078]
L1 regularization loss: 5.85E+00, L2 regularization loss: 4.89E+00
Test scatter: [0.1524 0.0435 0.2339 0.3972], Lowest was [0.1238 0.0402 0.2181 0.3846]
Median for last 10 epochs: [0.1524 0.0414 0.2339 0.3953], Epochs since improvement 6
 52%|█████▏    | 259/500 [4:52:42<4:18:35, 64.38s/it]Epoch: 260 done with learning rate 6.01E-03, Train loss: -4.55E+05, Train scatter: [0.1256 0.0395 0.2133 0.3957]
L1 regularization loss: 5.85E+00, L2 regularization loss: 4.91E+00
Test scatter: [0.1255 0.0392 0.2148 0.3888], Lowest was [0.1238 0.0392 0.2148 0.3846]
Median for last 10 epochs: [0.1524 0.0414 0.2286 0.3953], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 52%|█████▏    | 260/500 [4:54:09<4:44:34, 71.14s/it] 52%|█████▏    | 261/500 [4:55:02<4:21:46, 65.72s/it] 52%|█████▏    | 262/500 [4:56:23<4:38:21, 70.17s/it]Epoch: 262 done with learning rate 5.94E-03, Train loss: -4.58E+05, Train scatter: [0.1307 0.0411 0.2162 0.3947]
L1 regularization loss: 5.85E+00, L2 regularization loss: 4.93E+00
Test scatter: [0.1324 0.0409 0.2195 0.3897], Lowest was [0.1238 0.0392 0.2148 0.3846]
Median for last 10 epochs: [0.1524 0.0414 0.2286 0.3953], Epochs since improvement 2
 53%|█████▎    | 263/500 [4:57:15<4:16:48, 65.02s/it] 53%|█████▎    | 264/500 [4:58:36<4:33:45, 69.60s/it]Epoch: 264 done with learning rate 5.86E-03, Train loss: -4.61E+05, Train scatter: [0.1425 0.04   0.2113 0.397 ]
L1 regularization loss: 5.88E+00, L2 regularization loss: 4.96E+00
Test scatter: [0.1446 0.04   0.2144 0.3931], Lowest was [0.1238 0.0392 0.2144 0.3846]
Median for last 10 epochs: [0.1446 0.0409 0.2195 0.3931], Epochs since improvement 0
 53%|█████▎    | 265/500 [4:59:29<4:13:08, 64.63s/it] 53%|█████▎    | 266/500 [5:00:49<4:29:52, 69.20s/it]Epoch: 266 done with learning rate 5.79E-03, Train loss: -4.50E+05, Train scatter: [0.1436 0.0395 0.2126 0.393 ]
L1 regularization loss: 5.90E+00, L2 regularization loss: 4.99E+00
Test scatter: [0.1423 0.0394 0.215  0.3867], Lowest was [0.1238 0.0392 0.2144 0.3846]
Median for last 10 epochs: [0.1423 0.04   0.215  0.3897], Epochs since improvement 2
 53%|█████▎    | 267/500 [5:01:42<4:09:54, 64.35s/it] 54%|█████▎    | 268/500 [5:03:03<4:27:56, 69.30s/it]Epoch: 268 done with learning rate 5.72E-03, Train loss: -4.65E+05, Train scatter: [0.1174 0.0399 0.2202 0.3903]
L1 regularization loss: 5.92E+00, L2 regularization loss: 5.02E+00
Test scatter: [0.1194 0.0399 0.2221 0.3861], Lowest was [0.1194 0.0392 0.2144 0.3846]
Median for last 10 epochs: [0.1324 0.0399 0.215  0.3888], Epochs since improvement 0
 54%|█████▍    | 269/500 [5:03:56<4:08:14, 64.48s/it]Epoch: 270 done with learning rate 5.64E-03, Train loss: -4.65E+05, Train scatter: [0.1744 0.0423 0.2246 0.4068]
L1 regularization loss: 5.95E+00, L2 regularization loss: 5.05E+00
Test scatter: [0.1775 0.0415 0.2258 0.4007], Lowest was [0.1194 0.0392 0.2144 0.3846]
Median for last 10 epochs: [0.1423 0.04   0.2195 0.3897], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 54%|█████▍    | 270/500 [5:05:23<4:33:24, 71.32s/it] 54%|█████▍    | 271/500 [5:06:16<4:11:13, 65.82s/it] 54%|█████▍    | 272/500 [5:07:37<4:27:13, 70.32s/it]Epoch: 272 done with learning rate 5.57E-03, Train loss: -4.75E+05, Train scatter: [0.1248 0.0408 0.2154 0.3915]
L1 regularization loss: 5.96E+00, L2 regularization loss: 5.08E+00
Test scatter: [0.1281 0.0404 0.2161 0.3855], Lowest was [0.1194 0.0392 0.2144 0.3846]
Median for last 10 epochs: [0.1423 0.04   0.2161 0.3867], Epochs since improvement 4
 55%|█████▍    | 273/500 [5:08:30<4:06:24, 65.13s/it] 55%|█████▍    | 274/500 [5:09:51<4:23:10, 69.87s/it]Epoch: 274 done with learning rate 5.50E-03, Train loss: -4.68E+05, Train scatter: [0.116  0.0421 0.2278 0.3952]
L1 regularization loss: 5.98E+00, L2 regularization loss: 5.11E+00
Test scatter: [0.1174 0.0414 0.2298 0.39  ], Lowest was [0.1174 0.0392 0.2144 0.3846]
Median for last 10 epochs: [0.1281 0.0404 0.2221 0.3867], Epochs since improvement 0
 55%|█████▌    | 275/500 [5:10:44<4:03:02, 64.81s/it] 55%|█████▌    | 276/500 [5:12:05<4:20:02, 69.65s/it]Epoch: 276 done with learning rate 5.42E-03, Train loss: -4.85E+05, Train scatter: [0.136  0.0409 0.2139 0.399 ]
L1 regularization loss: 6.01E+00, L2 regularization loss: 5.14E+00
Test scatter: [0.1386 0.0408 0.2166 0.3931], Lowest was [0.1174 0.0392 0.2144 0.3846]
Median for last 10 epochs: [0.1281 0.0408 0.2221 0.39  ], Epochs since improvement 2
 55%|█████▌    | 277/500 [5:12:58<4:00:20, 64.67s/it] 56%|█████▌    | 278/500 [5:14:18<4:16:08, 69.23s/it]Epoch: 278 done with learning rate 5.35E-03, Train loss: -4.82E+05, Train scatter: [0.1275 0.0415 0.2111 0.3938]
L1 regularization loss: 6.05E+00, L2 regularization loss: 5.17E+00
Test scatter: [0.1303 0.0412 0.2137 0.3872], Lowest was [0.1174 0.0392 0.2137 0.3846]
Median for last 10 epochs: [0.1303 0.0412 0.2166 0.39  ], Epochs since improvement 0
 56%|█████▌    | 279/500 [5:15:11<3:57:07, 64.38s/it]Epoch: 280 done with learning rate 5.28E-03, Train loss: -4.75E+05, Train scatter: [0.1278 0.0428 0.226  0.3983]
L1 regularization loss: 6.09E+00, L2 regularization loss: 5.20E+00
Test scatter: [0.1279 0.0424 0.2293 0.3917], Lowest was [0.1174 0.0392 0.2137 0.3846]
Median for last 10 epochs: [0.1281 0.0412 0.2166 0.39  ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 56%|█████▌    | 280/500 [5:16:39<4:21:54, 71.43s/it] 56%|█████▌    | 281/500 [5:17:32<4:00:31, 65.90s/it] 56%|█████▋    | 282/500 [5:18:54<4:16:56, 70.72s/it]Epoch: 282 done with learning rate 5.20E-03, Train loss: -4.92E+05, Train scatter: [0.1655 0.0381 0.2115 0.3819]
L1 regularization loss: 6.11E+00, L2 regularization loss: 5.24E+00
Test scatter: [0.1629 0.0382 0.2152 0.3772], Lowest was [0.1174 0.0382 0.2137 0.3772]
Median for last 10 epochs: [0.1303 0.0412 0.2166 0.39  ], Epochs since improvement 0
 57%|█████▋    | 283/500 [5:19:47<3:56:26, 65.38s/it] 57%|█████▋    | 284/500 [5:21:07<4:11:54, 69.97s/it]Epoch: 284 done with learning rate 5.13E-03, Train loss: -4.83E+05, Train scatter: [0.1292 0.0388 0.2055 0.3849]
L1 regularization loss: 6.15E+00, L2 regularization loss: 5.27E+00
Test scatter: [0.1333 0.0385 0.208  0.3803], Lowest was [0.1174 0.0382 0.208  0.3772]
Median for last 10 epochs: [0.1333 0.0408 0.2152 0.3872], Epochs since improvement 0
 57%|█████▋    | 285/500 [5:22:00<3:52:28, 64.88s/it] 57%|█████▋    | 286/500 [5:23:19<4:06:49, 69.20s/it]Epoch: 286 done with learning rate 5.06E-03, Train loss: -4.92E+05, Train scatter: [0.1113 0.0402 0.2008 0.3821]
L1 regularization loss: 6.20E+00, L2 regularization loss: 5.32E+00
Test scatter: [0.1175 0.0399 0.2042 0.3768], Lowest was [0.1174 0.0382 0.2042 0.3768]
Median for last 10 epochs: [0.1303 0.0399 0.2137 0.3803], Epochs since improvement 0
 57%|█████▋    | 287/500 [5:24:12<3:48:21, 64.33s/it] 58%|█████▊    | 288/500 [5:25:33<4:04:58, 69.33s/it]Epoch: 288 done with learning rate 4.98E-03, Train loss: -4.99E+05, Train scatter: [0.1374 0.0401 0.2242 0.398 ]
L1 regularization loss: 6.24E+00, L2 regularization loss: 5.36E+00
Test scatter: [0.1405 0.0397 0.2255 0.3936], Lowest was [0.1174 0.0382 0.2042 0.3768]
Median for last 10 epochs: [0.1333 0.0397 0.2152 0.3803], Epochs since improvement 2
 58%|█████▊    | 289/500 [5:26:26<3:46:36, 64.44s/it]Epoch: 290 done with learning rate 4.91E-03, Train loss: -5.00E+05, Train scatter: [0.1111 0.0392 0.207  0.3867]
L1 regularization loss: 6.32E+00, L2 regularization loss: 5.40E+00
Test scatter: [0.115  0.0391 0.2106 0.3827], Lowest was [0.115  0.0382 0.2042 0.3768]
Median for last 10 epochs: [0.1333 0.0391 0.2106 0.3803], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 58%|█████▊    | 290/500 [5:27:53<4:09:00, 71.15s/it] 58%|█████▊    | 291/500 [5:28:46<3:48:49, 65.69s/it] 58%|█████▊    | 292/500 [5:30:07<4:03:02, 70.11s/it]Epoch: 292 done with learning rate 4.83E-03, Train loss: -4.96E+05, Train scatter: [0.1091 0.0371 0.2042 0.3797]
L1 regularization loss: 6.35E+00, L2 regularization loss: 5.44E+00
Test scatter: [0.1138 0.0368 0.2073 0.375 ], Lowest was [0.1138 0.0368 0.2042 0.375 ]
Median for last 10 epochs: [0.1175 0.0391 0.208  0.3803], Epochs since improvement 0
 59%|█████▊    | 293/500 [5:31:00<3:44:02, 64.94s/it] 59%|█████▉    | 294/500 [5:32:20<3:59:05, 69.64s/it]Epoch: 294 done with learning rate 4.76E-03, Train loss: -5.03E+05, Train scatter: [0.1093 0.0365 0.202  0.3812]
L1 regularization loss: 6.39E+00, L2 regularization loss: 5.48E+00
Test scatter: [0.1142 0.0364 0.2053 0.3763], Lowest was [0.1138 0.0364 0.2042 0.375 ]
Median for last 10 epochs: [0.115  0.0391 0.2073 0.3768], Epochs since improvement 0
 59%|█████▉    | 295/500 [5:33:13<3:41:01, 64.69s/it] 59%|█████▉    | 296/500 [5:34:33<3:55:35, 69.29s/it]Epoch: 296 done with learning rate 4.69E-03, Train loss: -5.09E+05, Train scatter: [0.1052 0.0375 0.1989 0.3819]
L1 regularization loss: 6.45E+00, L2 regularization loss: 5.53E+00
Test scatter: [0.1097 0.0373 0.2032 0.377 ], Lowest was [0.1097 0.0364 0.2032 0.375 ]
Median for last 10 epochs: [0.1142 0.0373 0.2073 0.377 ], Epochs since improvement 0
 59%|█████▉    | 297/500 [5:35:26<3:37:44, 64.36s/it] 60%|█████▉    | 298/500 [5:36:47<3:53:31, 69.36s/it]Epoch: 298 done with learning rate 4.61E-03, Train loss: -5.07E+05, Train scatter: [0.185  0.0383 0.2177 0.3975]
L1 regularization loss: 6.51E+00, L2 regularization loss: 5.58E+00
Test scatter: [0.18   0.0382 0.2182 0.3899], Lowest was [0.1097 0.0364 0.2032 0.375 ]
Median for last 10 epochs: [0.1142 0.0373 0.2073 0.377 ], Epochs since improvement 2
 60%|█████▉    | 299/500 [5:37:40<3:35:56, 64.46s/it]Epoch: 300 done with learning rate 4.54E-03, Train loss: -5.04E+05, Train scatter: [0.1266 0.0386 0.2054 0.3868]
L1 regularization loss: 6.57E+00, L2 regularization loss: 5.63E+00
Test scatter: [0.1303 0.0382 0.2094 0.383 ], Lowest was [0.1097 0.0364 0.2032 0.375 ]
Median for last 10 epochs: [0.1142 0.0373 0.2073 0.377 ], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 60%|██████    | 300/500 [5:39:09<3:59:28, 71.84s/it] 60%|██████    | 301/500 [5:40:02<3:39:35, 66.21s/it] 60%|██████    | 302/500 [5:41:23<3:52:59, 70.61s/it]Epoch: 302 done with learning rate 4.47E-03, Train loss: -5.13E+05, Train scatter: [0.1596 0.0466 0.2502 0.4113]
L1 regularization loss: 6.62E+00, L2 regularization loss: 5.67E+00
Test scatter: [0.1606 0.0465 0.2541 0.406 ], Lowest was [0.1097 0.0364 0.2032 0.375 ]
Median for last 10 epochs: [0.1303 0.0382 0.2094 0.383 ], Epochs since improvement 6
 61%|██████    | 303/500 [5:42:16<3:34:29, 65.33s/it] 61%|██████    | 304/500 [5:43:38<3:49:16, 70.19s/it]Epoch: 304 done with learning rate 4.39E-03, Train loss: -5.15E+05, Train scatter: [0.1061 0.0365 0.1993 0.3773]
L1 regularization loss: 6.75E+00, L2 regularization loss: 5.74E+00
Test scatter: [0.1102 0.0364 0.2028 0.3719], Lowest was [0.1097 0.0364 0.2028 0.3719]
Median for last 10 epochs: [0.1303 0.0382 0.2094 0.383 ], Epochs since improvement 0
 61%|██████    | 305/500 [5:44:31<3:31:26, 65.06s/it] 61%|██████    | 306/500 [5:45:52<3:46:06, 69.93s/it]Epoch: 306 done with learning rate 4.32E-03, Train loss: -5.19E+05, Train scatter: [0.1097 0.0371 0.2048 0.3859]
L1 regularization loss: 6.79E+00, L2 regularization loss: 5.78E+00
Test scatter: [0.1137 0.0367 0.2069 0.3761], Lowest was [0.1097 0.0364 0.2028 0.3719]
Median for last 10 epochs: [0.1303 0.0382 0.2094 0.383 ], Epochs since improvement 2
 61%|██████▏   | 307/500 [5:46:45<3:28:38, 64.86s/it] 62%|██████▏   | 308/500 [5:48:06<3:43:10, 69.74s/it]Epoch: 308 done with learning rate 4.25E-03, Train loss: -5.17E+05, Train scatter: [0.1084 0.0356 0.1979 0.3752]
L1 regularization loss: 6.84E+00, L2 regularization loss: 5.83E+00
Test scatter: [0.112  0.0355 0.201  0.369 ], Lowest was [0.1097 0.0355 0.201  0.369 ]
Median for last 10 epochs: [0.1137 0.0367 0.2069 0.3761], Epochs since improvement 0
 62%|██████▏   | 309/500 [5:48:59<3:26:05, 64.74s/it]Epoch: 310 done with learning rate 4.17E-03, Train loss: -5.26E+05, Train scatter: [0.117  0.0368 0.1976 0.3732]
L1 regularization loss: 6.89E+00, L2 regularization loss: 5.87E+00
Test scatter: [0.1184 0.0367 0.2016 0.3692], Lowest was [0.1097 0.0355 0.201  0.369 ]
Median for last 10 epochs: [0.1137 0.0367 0.2028 0.3719], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 62%|██████▏   | 310/500 [5:50:28<3:47:34, 71.86s/it] 62%|██████▏   | 311/500 [5:51:21<3:28:35, 66.22s/it] 62%|██████▏   | 312/500 [5:52:41<3:40:17, 70.30s/it]Epoch: 312 done with learning rate 4.10E-03, Train loss: -5.23E+05, Train scatter: [0.1029 0.0366 0.2014 0.3771]
L1 regularization loss: 6.94E+00, L2 regularization loss: 5.91E+00
Test scatter: [0.1074 0.0362 0.2048 0.3701], Lowest was [0.1074 0.0355 0.201  0.369 ]
Median for last 10 epochs: [0.112  0.0364 0.2028 0.3701], Epochs since improvement 0
 63%|██████▎   | 313/500 [5:53:34<3:22:58, 65.13s/it] 63%|██████▎   | 314/500 [5:54:55<3:36:37, 69.88s/it]Epoch: 314 done with learning rate 4.03E-03, Train loss: -5.30E+05, Train scatter: [0.1147 0.0358 0.1984 0.3782]
L1 regularization loss: 7.00E+00, L2 regularization loss: 5.95E+00
Test scatter: [0.1189 0.0357 0.2023 0.3702], Lowest was [0.1074 0.0355 0.201  0.369 ]
Median for last 10 epochs: [0.1137 0.0362 0.2023 0.3701], Epochs since improvement 2
 63%|██████▎   | 315/500 [5:55:48<3:19:51, 64.82s/it] 63%|██████▎   | 316/500 [5:57:09<3:33:29, 69.62s/it]Epoch: 316 done with learning rate 3.95E-03, Train loss: -5.02E+05, Train scatter: [0.1132 0.038  0.2044 0.3781]
L1 regularization loss: 7.20E+00, L2 regularization loss: 6.05E+00
Test scatter: [0.1171 0.0374 0.2068 0.3707], Lowest was [0.1074 0.0355 0.201  0.369 ]
Median for last 10 epochs: [0.1171 0.0362 0.2023 0.3701], Epochs since improvement 4
 63%|██████▎   | 317/500 [5:58:02<3:17:04, 64.62s/it] 64%|██████▎   | 318/500 [5:59:22<3:30:31, 69.40s/it]Epoch: 318 done with learning rate 3.88E-03, Train loss: -5.23E+05, Train scatter: [0.1025 0.0385 0.2113 0.3819]
L1 regularization loss: 7.24E+00, L2 regularization loss: 6.09E+00
Test scatter: [0.1063 0.0383 0.2137 0.3754], Lowest was [0.1063 0.0355 0.201  0.369 ]
Median for last 10 epochs: [0.1171 0.0367 0.2048 0.3702], Epochs since improvement 0
 64%|██████▍   | 319/500 [6:00:15<3:14:37, 64.51s/it]Epoch: 320 done with learning rate 3.81E-03, Train loss: -5.26E+05, Train scatter: [0.0989 0.036  0.2049 0.3793]
L1 regularization loss: 7.27E+00, L2 regularization loss: 6.12E+00
Test scatter: [0.1046 0.0359 0.2087 0.3756], Lowest was [0.1046 0.0355 0.201  0.369 ]
Median for last 10 epochs: [0.1074 0.0362 0.2068 0.3707], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 64%|██████▍   | 320/500 [6:01:43<3:34:43, 71.58s/it] 64%|██████▍   | 321/500 [6:02:36<3:16:57, 66.02s/it] 64%|██████▍   | 322/500 [6:03:57<3:28:56, 70.43s/it]Epoch: 322 done with learning rate 3.74E-03, Train loss: -5.28E+05, Train scatter: [0.1024 0.0351 0.1955 0.3697]
L1 regularization loss: 7.34E+00, L2 regularization loss: 6.16E+00
Test scatter: [0.1075 0.0351 0.1991 0.366 ], Lowest was [0.1046 0.0351 0.1991 0.366 ]
Median for last 10 epochs: [0.1075 0.0359 0.2068 0.3707], Epochs since improvement 0
 65%|██████▍   | 323/500 [6:04:50<3:12:13, 65.16s/it] 65%|██████▍   | 324/500 [6:06:10<3:24:40, 69.78s/it]Epoch: 324 done with learning rate 3.67E-03, Train loss: -5.37E+05, Train scatter: [0.097  0.0354 0.1963 0.3684]
L1 regularization loss: 7.37E+00, L2 regularization loss: 6.20E+00
Test scatter: [0.1032 0.0355 0.2006 0.3642], Lowest was [0.1032 0.0351 0.1991 0.3642]
Median for last 10 epochs: [0.1063 0.0359 0.2068 0.3707], Epochs since improvement 0
 65%|██████▌   | 325/500 [6:07:03<3:08:51, 64.75s/it] 65%|██████▌   | 326/500 [6:08:23<3:20:45, 69.23s/it]Epoch: 326 done with learning rate 3.60E-03, Train loss: -5.35E+05, Train scatter: [0.1012 0.036  0.2022 0.3784]
L1 regularization loss: 7.45E+00, L2 regularization loss: 6.24E+00
Test scatter: [0.1063 0.036  0.2058 0.373 ], Lowest was [0.1032 0.0351 0.1991 0.3642]
Median for last 10 epochs: [0.1063 0.0359 0.2058 0.373 ], Epochs since improvement 2
 65%|██████▌   | 327/500 [6:09:16<3:05:36, 64.37s/it] 66%|██████▌   | 328/500 [6:10:38<3:19:17, 69.52s/it]Epoch: 328 done with learning rate 3.53E-03, Train loss: -4.75E+05, Train scatter: [0.1094 0.039  0.2203 0.397 ]
L1 regularization loss: 7.62E+00, L2 regularization loss: 6.31E+00
Test scatter: [0.1127 0.0387 0.2216 0.3898], Lowest was [0.1032 0.0351 0.1991 0.3642]
Median for last 10 epochs: [0.1063 0.0359 0.2058 0.373 ], Epochs since improvement 4
 66%|██████▌   | 329/500 [6:11:31<3:04:03, 64.58s/it]Epoch: 330 done with learning rate 3.45E-03, Train loss: -5.23E+05, Train scatter: [0.1015 0.0374 0.1997 0.3818]
L1 regularization loss: 7.65E+00, L2 regularization loss: 6.35E+00
Test scatter: [0.1053 0.0372 0.203  0.3761], Lowest was [0.1032 0.0351 0.1991 0.3642]
Median for last 10 epochs: [0.1063 0.036  0.203  0.373 ], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 66%|██████▌   | 330/500 [6:13:00<3:23:46, 71.92s/it] 66%|██████▌   | 331/500 [6:13:53<3:06:41, 66.28s/it] 66%|██████▋   | 332/500 [6:15:14<3:17:39, 70.59s/it]Epoch: 332 done with learning rate 3.38E-03, Train loss: -5.39E+05, Train scatter: [0.1006 0.0354 0.197  0.3746]
L1 regularization loss: 7.71E+00, L2 regularization loss: 6.38E+00
Test scatter: [0.1069 0.0353 0.2006 0.3697], Lowest was [0.1032 0.0351 0.1991 0.3642]
Median for last 10 epochs: [0.1063 0.036  0.203  0.373 ], Epochs since improvement 8
 67%|██████▋   | 333/500 [6:16:07<3:01:54, 65.35s/it] 67%|██████▋   | 334/500 [6:17:28<3:13:52, 70.07s/it]Epoch: 334 done with learning rate 3.32E-03, Train loss: -5.44E+05, Train scatter: [0.1007 0.0359 0.1962 0.3724]
L1 regularization loss: 7.78E+00, L2 regularization loss: 6.42E+00
Test scatter: [0.1063 0.0359 0.1997 0.3679], Lowest was [0.1032 0.0351 0.1991 0.3642]
Median for last 10 epochs: [0.1063 0.036  0.203  0.373 ], Epochs since improvement 10
 67%|██████▋   | 335/500 [6:18:21<2:58:31, 64.92s/it] 67%|██████▋   | 336/500 [6:19:41<3:10:04, 69.54s/it]Epoch: 336 done with learning rate 3.25E-03, Train loss: -5.46E+05, Train scatter: [0.1022 0.0359 0.1941 0.3692]
L1 regularization loss: 7.81E+00, L2 regularization loss: 6.45E+00
Test scatter: [0.1053 0.036  0.1978 0.3658], Lowest was [0.1032 0.0351 0.1978 0.3642]
Median for last 10 epochs: [0.1063 0.036  0.2006 0.3697], Epochs since improvement 0
 67%|██████▋   | 337/500 [6:20:34<2:55:27, 64.59s/it] 68%|██████▊   | 338/500 [6:21:54<3:06:53, 69.22s/it]Epoch: 338 done with learning rate 3.18E-03, Train loss: -5.44E+05, Train scatter: [0.1027 0.0353 0.1998 0.3709]
L1 regularization loss: 7.86E+00, L2 regularization loss: 6.48E+00
Test scatter: [0.1077 0.0352 0.2027 0.3663], Lowest was [0.1032 0.0351 0.1978 0.3642]
Median for last 10 epochs: [0.1063 0.0359 0.2006 0.3679], Epochs since improvement 2
 68%|██████▊   | 339/500 [6:22:47<2:52:40, 64.35s/it]Epoch: 340 done with learning rate 3.11E-03, Train loss: -5.55E+05, Train scatter: [0.0996 0.0346 0.2    0.3698]
L1 regularization loss: 7.91E+00, L2 regularization loss: 6.52E+00
Test scatter: [0.105  0.0348 0.2033 0.3674], Lowest was [0.1032 0.0348 0.1978 0.3642]
Median for last 10 epochs: [0.1063 0.0353 0.2006 0.3674], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 68%|██████▊   | 340/500 [6:24:15<3:10:23, 71.40s/it] 68%|██████▊   | 341/500 [6:25:08<2:54:39, 65.91s/it] 68%|██████▊   | 342/500 [6:26:28<3:04:55, 70.23s/it]Epoch: 342 done with learning rate 3.04E-03, Train loss: -5.57E+05, Train scatter: [0.095  0.0347 0.1949 0.3669]
L1 regularization loss: 7.96E+00, L2 regularization loss: 6.55E+00
Test scatter: [0.1006 0.0351 0.1994 0.3642], Lowest was [0.1006 0.0348 0.1978 0.3642]
Median for last 10 epochs: [0.1053 0.0352 0.1997 0.3663], Epochs since improvement 0
 69%|██████▊   | 343/500 [6:27:21<2:50:05, 65.00s/it] 69%|██████▉   | 344/500 [6:28:42<3:01:33, 69.83s/it]Epoch: 344 done with learning rate 2.97E-03, Train loss: -5.46E+05, Train scatter: [0.0926 0.0343 0.1924 0.365 ]
L1 regularization loss: 8.03E+00, L2 regularization loss: 6.59E+00
Test scatter: [0.0987 0.0347 0.1968 0.364 ], Lowest was [0.0987 0.0347 0.1968 0.364 ]
Median for last 10 epochs: [0.105  0.0351 0.1994 0.3658], Epochs since improvement 0
 69%|██████▉   | 345/500 [6:29:35<2:47:27, 64.82s/it] 69%|██████▉   | 346/500 [6:30:56<2:58:22, 69.50s/it]Epoch: 346 done with learning rate 2.90E-03, Train loss: -5.51E+05, Train scatter: [0.1004 0.0362 0.2023 0.3773]
L1 regularization loss: 8.12E+00, L2 regularization loss: 6.64E+00
Test scatter: [0.1056 0.0363 0.2055 0.3693], Lowest was [0.0987 0.0347 0.1968 0.364 ]
Median for last 10 epochs: [0.105  0.0351 0.2027 0.3663], Epochs since improvement 2
 69%|██████▉   | 347/500 [6:31:49<2:44:37, 64.56s/it] 70%|██████▉   | 348/500 [6:33:10<2:56:04, 69.50s/it]Epoch: 348 done with learning rate 2.84E-03, Train loss: -5.61E+05, Train scatter: [0.1038 0.0343 0.1933 0.3666]
L1 regularization loss: 8.17E+00, L2 regularization loss: 6.68E+00
Test scatter: [0.1109 0.0347 0.198  0.3649], Lowest was [0.0987 0.0347 0.1968 0.364 ]
Median for last 10 epochs: [0.105  0.0348 0.1994 0.3649], Epochs since improvement 4
 70%|██████▉   | 349/500 [6:34:03<2:42:27, 64.55s/it]Epoch: 350 done with learning rate 2.77E-03, Train loss: -5.67E+05, Train scatter: [0.0971 0.0339 0.19   0.3625]
L1 regularization loss: 8.23E+00, L2 regularization loss: 6.71E+00
Test scatter: [0.102  0.0344 0.1948 0.3602], Lowest was [0.0987 0.0344 0.1948 0.3602]
Median for last 10 epochs: [0.102  0.0347 0.198  0.3642], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 70%|███████   | 350/500 [6:35:30<2:58:41, 71.48s/it] 70%|███████   | 351/500 [6:36:24<2:43:54, 66.00s/it] 70%|███████   | 352/500 [6:37:44<2:53:26, 70.32s/it]Epoch: 352 done with learning rate 2.71E-03, Train loss: -5.55E+05, Train scatter: [0.0943 0.0348 0.1929 0.365 ]
L1 regularization loss: 8.29E+00, L2 regularization loss: 6.76E+00
Test scatter: [0.1004 0.035  0.1976 0.3622], Lowest was [0.0987 0.0344 0.1948 0.3602]
Median for last 10 epochs: [0.102  0.0347 0.1976 0.364 ], Epochs since improvement 2
 71%|███████   | 353/500 [6:38:37<2:39:30, 65.11s/it] 71%|███████   | 354/500 [6:39:58<2:50:15, 69.97s/it]Epoch: 354 done with learning rate 2.64E-03, Train loss: -5.71E+05, Train scatter: [0.0984 0.0349 0.2023 0.3683]
L1 regularization loss: 8.36E+00, L2 regularization loss: 6.80E+00
Test scatter: [0.1049 0.0351 0.2062 0.3679], Lowest was [0.0987 0.0344 0.1948 0.3602]
Median for last 10 epochs: [0.1049 0.035  0.198  0.3649], Epochs since improvement 4
 71%|███████   | 355/500 [6:40:51<2:36:47, 64.88s/it] 71%|███████   | 356/500 [6:42:12<2:46:53, 69.54s/it]Epoch: 356 done with learning rate 2.58E-03, Train loss: -5.74E+05, Train scatter: [0.0981 0.0345 0.1968 0.362 ]
L1 regularization loss: 8.44E+00, L2 regularization loss: 6.84E+00
Test scatter: [0.1038 0.0348 0.2007 0.3611], Lowest was [0.0987 0.0344 0.1948 0.3602]
Median for last 10 epochs: [0.1038 0.0348 0.198  0.3622], Epochs since improvement 6
 71%|███████▏  | 357/500 [6:43:05<2:33:57, 64.60s/it] 72%|███████▏  | 358/500 [6:44:25<2:44:03, 69.32s/it]Epoch: 358 done with learning rate 2.51E-03, Train loss: -5.75E+05, Train scatter: [0.0911 0.0337 0.1904 0.36  ]
L1 regularization loss: 8.50E+00, L2 regularization loss: 6.87E+00
Test scatter: [0.0982 0.0344 0.1955 0.3593], Lowest was [0.0982 0.0344 0.1948 0.3593]
Median for last 10 epochs: [0.102  0.0348 0.1976 0.3611], Epochs since improvement 0
 72%|███████▏  | 359/500 [6:45:18<2:31:26, 64.44s/it]Epoch: 360 done with learning rate 2.45E-03, Train loss: -5.80E+05, Train scatter: [0.0923 0.0339 0.1922 0.3608]
L1 regularization loss: 8.58E+00, L2 regularization loss: 6.92E+00
Test scatter: [0.0996 0.0345 0.1968 0.362 ], Lowest was [0.0982 0.0344 0.1948 0.3593]
Median for last 10 epochs: [0.1004 0.0348 0.1976 0.362 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 72%|███████▏  | 360/500 [6:46:45<2:46:13, 71.24s/it] 72%|███████▏  | 361/500 [6:47:38<2:32:20, 65.76s/it] 72%|███████▏  | 362/500 [6:48:58<2:41:05, 70.04s/it]Epoch: 362 done with learning rate 2.38E-03, Train loss: -5.77E+05, Train scatter: [0.0914 0.0338 0.1929 0.363 ]
L1 regularization loss: 8.65E+00, L2 regularization loss: 6.96E+00
Test scatter: [0.0982 0.0344 0.198  0.3608], Lowest was [0.0982 0.0344 0.1948 0.3593]
Median for last 10 epochs: [0.0996 0.0345 0.198  0.3611], Epochs since improvement 4
 73%|███████▎  | 363/500 [6:49:51<2:28:15, 64.93s/it] 73%|███████▎  | 364/500 [6:51:12<2:37:43, 69.58s/it]Epoch: 364 done with learning rate 2.32E-03, Train loss: -5.83E+05, Train scatter: [0.0989 0.0344 0.1906 0.3616]
L1 regularization loss: 8.73E+00, L2 regularization loss: 7.01E+00
Test scatter: [0.1051 0.035  0.1959 0.3623], Lowest was [0.0982 0.0344 0.1948 0.3593]
Median for last 10 epochs: [0.0996 0.0345 0.1968 0.3611], Epochs since improvement 6
 73%|███████▎  | 365/500 [6:52:05<2:25:25, 64.63s/it] 73%|███████▎  | 366/500 [6:53:26<2:35:39, 69.70s/it]Epoch: 366 done with learning rate 2.26E-03, Train loss: -5.82E+05, Train scatter: [0.0945 0.0335 0.1888 0.3575]
L1 regularization loss: 8.79E+00, L2 regularization loss: 7.04E+00
Test scatter: [0.1008 0.0343 0.1935 0.3586], Lowest was [0.0982 0.0343 0.1935 0.3586]
Median for last 10 epochs: [0.0996 0.0344 0.1959 0.3608], Epochs since improvement 0
 73%|███████▎  | 367/500 [6:54:19<2:23:23, 64.69s/it] 74%|███████▎  | 368/500 [6:55:41<2:33:48, 69.91s/it]Epoch: 368 done with learning rate 2.20E-03, Train loss: -5.66E+05, Train scatter: [0.1009 0.034  0.1891 0.3574]
L1 regularization loss: 8.86E+00, L2 regularization loss: 7.09E+00
Test scatter: [0.1079 0.0347 0.1945 0.3574], Lowest was [0.0982 0.0343 0.1935 0.3574]
Median for last 10 epochs: [0.1008 0.0345 0.1959 0.3608], Epochs since improvement 0
 74%|███████▍  | 369/500 [6:56:35<2:21:35, 64.85s/it]Epoch: 370 done with learning rate 2.14E-03, Train loss: -5.90E+05, Train scatter: [0.0913 0.0339 0.1894 0.3598]
L1 regularization loss: 8.94E+00, L2 regularization loss: 7.13E+00
Test scatter: [0.0983 0.0347 0.1953 0.3601], Lowest was [0.0982 0.0343 0.1935 0.3574]
Median for last 10 epochs: [0.1008 0.0347 0.1953 0.3601], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 74%|███████▍  | 370/500 [6:58:02<2:35:30, 71.77s/it] 74%|███████▍  | 371/500 [6:58:56<2:22:20, 66.21s/it] 74%|███████▍  | 372/500 [7:00:18<2:31:33, 71.04s/it]Epoch: 372 done with learning rate 2.08E-03, Train loss: -5.91E+05, Train scatter: [0.098  0.0335 0.1898 0.3572]
L1 regularization loss: 9.00E+00, L2 regularization loss: 7.17E+00
Test scatter: [0.1043 0.0343 0.1952 0.3588], Lowest was [0.0982 0.0343 0.1935 0.3574]
Median for last 10 epochs: [0.1043 0.0347 0.1952 0.3588], Epochs since improvement 0
 75%|███████▍  | 373/500 [7:01:11<2:18:52, 65.61s/it] 75%|███████▍  | 374/500 [7:02:31<2:27:00, 70.01s/it]Epoch: 374 done with learning rate 2.02E-03, Train loss: -5.44E+05, Train scatter: [0.0973 0.0348 0.1938 0.3642]
L1 regularization loss: 9.12E+00, L2 regularization loss: 7.21E+00
Test scatter: [0.1013 0.0352 0.1989 0.3623], Lowest was [0.0982 0.0343 0.1935 0.3574]
Median for last 10 epochs: [0.1013 0.0347 0.1952 0.3588], Epochs since improvement 2
 75%|███████▌  | 375/500 [7:03:24<2:15:16, 64.93s/it] 75%|███████▌  | 376/500 [7:04:46<2:24:48, 70.07s/it]Epoch: 376 done with learning rate 1.96E-03, Train loss: -5.92E+05, Train scatter: [0.0939 0.0333 0.1894 0.3573]
L1 regularization loss: 9.17E+00, L2 regularization loss: 7.25E+00
Test scatter: [0.1008 0.0341 0.1947 0.3573], Lowest was [0.0982 0.0341 0.1935 0.3573]
Median for last 10 epochs: [0.1013 0.0347 0.1952 0.3588], Epochs since improvement 0
 75%|███████▌  | 377/500 [7:05:40<2:13:17, 65.02s/it] 76%|███████▌  | 378/500 [7:07:01<2:22:01, 69.85s/it]Epoch: 378 done with learning rate 1.90E-03, Train loss: -6.00E+05, Train scatter: [0.0891 0.033  0.1893 0.3543]
L1 regularization loss: 9.22E+00, L2 regularization loss: 7.28E+00
Test scatter: [0.0955 0.034  0.1951 0.3571], Lowest was [0.0955 0.034  0.1935 0.3571]
Median for last 10 epochs: [0.1008 0.0343 0.1952 0.3588], Epochs since improvement 0
 76%|███████▌  | 379/500 [7:07:54<2:10:43, 64.82s/it]Epoch: 380 done with learning rate 1.84E-03, Train loss: -5.96E+05, Train scatter: [0.1027 0.0338 0.1895 0.3555]
L1 regularization loss: 9.28E+00, L2 regularization loss: 7.32E+00
Test scatter: [0.1089 0.0346 0.1952 0.3575], Lowest was [0.0955 0.034  0.1935 0.3571]
Median for last 10 epochs: [0.1013 0.0343 0.1952 0.3575], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 76%|███████▌  | 380/500 [7:09:21<2:23:15, 71.63s/it] 76%|███████▌  | 381/500 [7:10:15<2:11:12, 66.16s/it] 76%|███████▋  | 382/500 [7:11:37<2:19:29, 70.92s/it]Epoch: 382 done with learning rate 1.78E-03, Train loss: -5.97E+05, Train scatter: [0.0904 0.0331 0.19   0.3548]
L1 regularization loss: 9.34E+00, L2 regularization loss: 7.35E+00
Test scatter: [0.0983 0.0341 0.1956 0.3586], Lowest was [0.0955 0.034  0.1935 0.3571]
Median for last 10 epochs: [0.1008 0.0341 0.1952 0.3575], Epochs since improvement 4
 77%|███████▋  | 383/500 [7:12:30<2:07:55, 65.60s/it] 77%|███████▋  | 384/500 [7:13:51<2:16:03, 70.37s/it]Epoch: 384 done with learning rate 1.73E-03, Train loss: -5.95E+05, Train scatter: [0.0903 0.0333 0.1902 0.3551]
L1 regularization loss: 9.40E+00, L2 regularization loss: 7.38E+00
Test scatter: [0.0978 0.034  0.1955 0.3562], Lowest was [0.0955 0.034  0.1935 0.3562]
Median for last 10 epochs: [0.0983 0.0341 0.1952 0.3573], Epochs since improvement 0
 77%|███████▋  | 385/500 [7:14:45<2:05:00, 65.22s/it] 77%|███████▋  | 386/500 [7:16:06<2:13:13, 70.12s/it]Epoch: 386 done with learning rate 1.67E-03, Train loss: -5.76E+05, Train scatter: [0.0947 0.0341 0.1961 0.3652]
L1 regularization loss: 9.48E+00, L2 regularization loss: 7.42E+00
Test scatter: [0.1016 0.0347 0.2011 0.3613], Lowest was [0.0955 0.034  0.1935 0.3562]
Median for last 10 epochs: [0.0983 0.0341 0.1955 0.3575], Epochs since improvement 2
 77%|███████▋  | 387/500 [7:16:59<2:02:30, 65.05s/it] 78%|███████▊  | 388/500 [7:18:21<2:10:44, 70.04s/it]Epoch: 388 done with learning rate 1.62E-03, Train loss: -5.95E+05, Train scatter: [0.0885 0.0332 0.188  0.3537]
L1 regularization loss: 9.52E+00, L2 regularization loss: 7.45E+00
Test scatter: [0.0962 0.0342 0.194  0.3572], Lowest was [0.0955 0.034  0.1935 0.3562]
Median for last 10 epochs: [0.0983 0.0342 0.1955 0.3575], Epochs since improvement 4
 78%|███████▊  | 389/500 [7:19:14<2:00:14, 64.99s/it]Epoch: 390 done with learning rate 1.56E-03, Train loss: -6.07E+05, Train scatter: [0.0884 0.0328 0.1868 0.3523]
L1 regularization loss: 9.57E+00, L2 regularization loss: 7.47E+00
Test scatter: [0.0962 0.0341 0.1934 0.3559], Lowest was [0.0955 0.034  0.1934 0.3559]
Median for last 10 epochs: [0.0978 0.0341 0.1955 0.3572], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 78%|███████▊  | 390/500 [7:20:42<2:11:33, 71.76s/it] 78%|███████▊  | 391/500 [7:21:35<2:00:11, 66.16s/it] 78%|███████▊  | 392/500 [7:22:55<2:06:50, 70.46s/it]Epoch: 392 done with learning rate 1.51E-03, Train loss: -3.73E+05, Train scatter: [0.1177 0.0422 0.2153 0.3988]
L1 regularization loss: 9.76E+00, L2 regularization loss: 7.52E+00
Test scatter: [0.1174 0.0417 0.2182 0.3919], Lowest was [0.0955 0.034  0.1934 0.3559]
Median for last 10 epochs: [0.0978 0.0342 0.1955 0.3572], Epochs since improvement 2
 79%|███████▊  | 393/500 [7:23:48<1:56:20, 65.23s/it] 79%|███████▉  | 394/500 [7:25:10<2:03:49, 70.09s/it]Epoch: 394 done with learning rate 1.46E-03, Train loss: -5.06E+05, Train scatter: [0.0982 0.0369 0.1983 0.3719]
L1 regularization loss: 9.78E+00, L2 regularization loss: 7.53E+00
Test scatter: [0.1008 0.0368 0.2026 0.365 ], Lowest was [0.0955 0.034  0.1934 0.3559]
Median for last 10 epochs: [0.1008 0.0347 0.2011 0.3613], Epochs since improvement 4
 79%|███████▉  | 395/500 [7:26:03<1:53:45, 65.00s/it] 79%|███████▉  | 396/500 [7:27:24<2:00:45, 69.67s/it]Epoch: 396 done with learning rate 1.41E-03, Train loss: -5.48E+05, Train scatter: [0.095  0.0347 0.1937 0.3649]
L1 regularization loss: 9.80E+00, L2 regularization loss: 7.54E+00
Test scatter: [0.0985 0.035  0.199  0.3644], Lowest was [0.0955 0.034  0.1934 0.3559]
Median for last 10 epochs: [0.0985 0.035  0.199  0.3644], Epochs since improvement 6
 79%|███████▉  | 397/500 [7:28:17<1:51:01, 64.68s/it] 80%|███████▉  | 398/500 [7:29:37<1:57:44, 69.26s/it]Epoch: 398 done with learning rate 1.36E-03, Train loss: -5.67E+05, Train scatter: [0.095  0.034  0.1908 0.3597]
L1 regularization loss: 9.83E+00, L2 regularization loss: 7.56E+00
Test scatter: [0.0992 0.0345 0.1961 0.3574], Lowest was [0.0955 0.034  0.1934 0.3559]
Median for last 10 epochs: [0.0992 0.035  0.199  0.3644], Epochs since improvement 8
 80%|███████▉  | 399/500 [7:30:30<1:48:27, 64.43s/it]Epoch: 400 done with learning rate 1.31E-03, Train loss: -5.78E+05, Train scatter: [0.0916 0.0337 0.1894 0.3569]
L1 regularization loss: 9.85E+00, L2 regularization loss: 7.57E+00
Test scatter: [0.0967 0.0343 0.1946 0.3562], Lowest was [0.0955 0.034  0.1934 0.3559]
Median for last 10 epochs: [0.0992 0.035  0.199  0.3644], Epochs since improvement 10
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 80%|████████  | 400/500 [7:31:57<1:58:47, 71.27s/it] 80%|████████  | 401/500 [7:32:50<1:48:36, 65.83s/it] 80%|████████  | 402/500 [7:34:10<1:54:36, 70.17s/it]Epoch: 402 done with learning rate 1.26E-03, Train loss: -5.87E+05, Train scatter: [0.0924 0.0334 0.1898 0.3578]
L1 regularization loss: 9.88E+00, L2 regularization loss: 7.59E+00
Test scatter: [0.0984 0.034  0.1956 0.3566], Lowest was [0.0955 0.034  0.1934 0.3559]
Median for last 10 epochs: [0.0985 0.0345 0.1961 0.3574], Epochs since improvement 0
 81%|████████  | 403/500 [7:35:03<1:45:07, 65.02s/it] 81%|████████  | 404/500 [7:36:25<1:51:49, 69.89s/it]Epoch: 404 done with learning rate 1.21E-03, Train loss: -6.02E+05, Train scatter: [0.0905 0.0333 0.1897 0.3553]
L1 regularization loss: 9.91E+00, L2 regularization loss: 7.61E+00
Test scatter: [0.097  0.0344 0.196  0.3583], Lowest was [0.0955 0.034  0.1934 0.3559]
Median for last 10 epochs: [0.0984 0.0344 0.196  0.3574], Epochs since improvement 2
 81%|████████  | 405/500 [7:37:18<1:42:37, 64.81s/it] 81%|████████  | 406/500 [7:38:40<1:49:33, 69.93s/it]Epoch: 406 done with learning rate 1.16E-03, Train loss: -6.07E+05, Train scatter: [0.09   0.0328 0.1866 0.3526]
L1 regularization loss: 9.94E+00, L2 regularization loss: 7.63E+00
Test scatter: [0.0963 0.0339 0.1934 0.3548], Lowest was [0.0955 0.0339 0.1934 0.3548]
Median for last 10 epochs: [0.097  0.0343 0.1956 0.3566], Epochs since improvement 0
 81%|████████▏ | 407/500 [7:39:33<1:40:34, 64.89s/it] 82%|████████▏ | 408/500 [7:40:53<1:46:29, 69.45s/it]Epoch: 408 done with learning rate 1.11E-03, Train loss: -4.73E+05, Train scatter: [0.1057 0.0368 0.2024 0.3839]
L1 regularization loss: 1.01E+01, L2 regularization loss: 7.67E+00
Test scatter: [0.1083 0.0367 0.2039 0.3759], Lowest was [0.0955 0.0339 0.1934 0.3548]
Median for last 10 epochs: [0.097  0.0343 0.1956 0.3566], Epochs since improvement 2
 82%|████████▏ | 409/500 [7:41:46<1:37:55, 64.56s/it]Epoch: 410 done with learning rate 1.07E-03, Train loss: -5.49E+05, Train scatter: [0.0953 0.0349 0.1951 0.3668]
L1 regularization loss: 1.01E+01, L2 regularization loss: 7.68E+00
Test scatter: [0.1005 0.0352 0.1992 0.3633], Lowest was [0.0955 0.0339 0.1934 0.3548]
Median for last 10 epochs: [0.0984 0.0344 0.196  0.3583], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 82%|████████▏ | 410/500 [7:43:16<1:48:07, 72.09s/it] 82%|████████▏ | 411/500 [7:44:09<1:38:35, 66.47s/it] 82%|████████▏ | 412/500 [7:45:30<1:43:59, 70.90s/it]Epoch: 412 done with learning rate 1.02E-03, Train loss: -5.75E+05, Train scatter: [0.0935 0.0342 0.1918 0.3611]
L1 regularization loss: 1.01E+01, L2 regularization loss: 7.69E+00
Test scatter: [0.0974 0.0346 0.196  0.3571], Lowest was [0.0955 0.0339 0.1934 0.3548]
Median for last 10 epochs: [0.0974 0.0346 0.196  0.3583], Epochs since improvement 6
 83%|████████▎ | 413/500 [7:46:23<1:35:08, 65.61s/it] 83%|████████▎ | 414/500 [7:47:44<1:40:37, 70.20s/it]Epoch: 414 done with learning rate 9.77E-04, Train loss: -5.88E+05, Train scatter: [0.0933 0.0337 0.1888 0.3576]
L1 regularization loss: 1.01E+01, L2 regularization loss: 7.70E+00
Test scatter: [0.0986 0.0342 0.1941 0.3566], Lowest was [0.0955 0.0339 0.1934 0.3548]
Median for last 10 epochs: [0.0986 0.0346 0.196  0.3571], Epochs since improvement 8
 83%|████████▎ | 415/500 [7:48:38<1:32:18, 65.15s/it] 83%|████████▎ | 416/500 [7:49:59<1:38:06, 70.07s/it]Epoch: 416 done with learning rate 9.34E-04, Train loss: -5.89E+05, Train scatter: [0.0912 0.0334 0.1887 0.3562]
L1 regularization loss: 1.01E+01, L2 regularization loss: 7.71E+00
Test scatter: [0.0968 0.0341 0.1941 0.3551], Lowest was [0.0955 0.0339 0.1934 0.3548]
Median for last 10 epochs: [0.0986 0.0346 0.196  0.3571], Epochs since improvement 10
 83%|████████▎ | 417/500 [7:50:52<1:29:53, 64.98s/it] 84%|████████▎ | 418/500 [7:52:13<1:35:21, 69.77s/it]Epoch: 418 done with learning rate 8.91E-04, Train loss: -5.98E+05, Train scatter: [0.0937 0.0332 0.1883 0.3547]
L1 regularization loss: 1.01E+01, L2 regularization loss: 7.72E+00
Test scatter: [0.0978 0.0341 0.1931 0.355 ], Lowest was [0.0955 0.0339 0.1931 0.3548]
Median for last 10 epochs: [0.0978 0.0342 0.1941 0.3566], Epochs since improvement 0
 84%|████████▍ | 419/500 [7:53:06<1:27:26, 64.77s/it]Epoch: 420 done with learning rate 8.49E-04, Train loss: -6.14E+05, Train scatter: [0.0893 0.033  0.1879 0.3525]
L1 regularization loss: 1.02E+01, L2 regularization loss: 7.73E+00
Test scatter: [0.0954 0.034  0.1938 0.3543], Lowest was [0.0954 0.0339 0.1931 0.3543]
Median for last 10 epochs: [0.0974 0.0341 0.1941 0.3551], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 84%|████████▍ | 420/500 [7:54:35<1:35:51, 71.90s/it] 84%|████████▍ | 421/500 [7:55:28<1:27:14, 66.26s/it] 84%|████████▍ | 422/500 [7:56:50<1:32:09, 70.89s/it]Epoch: 422 done with learning rate 8.09E-04, Train loss: -6.15E+05, Train scatter: [0.0893 0.033  0.1869 0.3517]
L1 regularization loss: 1.02E+01, L2 regularization loss: 7.74E+00
Test scatter: [0.0959 0.0342 0.1932 0.3554], Lowest was [0.0954 0.0339 0.1931 0.3543]
Median for last 10 epochs: [0.0968 0.0341 0.1938 0.3551], Epochs since improvement 2
 85%|████████▍ | 423/500 [7:57:43<1:24:07, 65.55s/it] 85%|████████▍ | 424/500 [7:59:04<1:29:01, 70.28s/it]Epoch: 424 done with learning rate 7.69E-04, Train loss: -6.20E+05, Train scatter: [0.0887 0.0328 0.1876 0.3503]
L1 regularization loss: 1.02E+01, L2 regularization loss: 7.75E+00
Test scatter: [0.0955 0.034  0.1938 0.3539], Lowest was [0.0954 0.0339 0.1931 0.3539]
Median for last 10 epochs: [0.0959 0.0341 0.1938 0.355 ], Epochs since improvement 0
 85%|████████▌ | 425/500 [7:59:57<1:21:21, 65.09s/it] 85%|████████▌ | 426/500 [8:01:18<1:26:15, 69.95s/it]Epoch: 426 done with learning rate 7.30E-04, Train loss: -6.23E+05, Train scatter: [0.0894 0.0328 0.1866 0.3508]
L1 regularization loss: 1.02E+01, L2 regularization loss: 7.76E+00
Test scatter: [0.096  0.0342 0.1928 0.3538], Lowest was [0.0954 0.0339 0.1928 0.3538]
Median for last 10 epochs: [0.0959 0.0341 0.1932 0.3543], Epochs since improvement 0
 85%|████████▌ | 427/500 [8:02:11<1:18:56, 64.89s/it] 86%|████████▌ | 428/500 [8:03:32<1:23:29, 69.58s/it]Epoch: 428 done with learning rate 6.92E-04, Train loss: -6.28E+05, Train scatter: [0.0885 0.0327 0.1861 0.3497]
L1 regularization loss: 1.02E+01, L2 regularization loss: 7.77E+00
Test scatter: [0.0956 0.0339 0.1927 0.354 ], Lowest was [0.0954 0.0339 0.1927 0.3538]
Median for last 10 epochs: [0.0956 0.034  0.1932 0.354 ], Epochs since improvement 0
 86%|████████▌ | 429/500 [8:04:25<1:16:26, 64.61s/it]Epoch: 430 done with learning rate 6.55E-04, Train loss: -6.32E+05, Train scatter: [0.0881 0.0325 0.1856 0.3482]
L1 regularization loss: 1.02E+01, L2 regularization loss: 7.78E+00
Test scatter: [0.0954 0.0339 0.1927 0.3529], Lowest was [0.0954 0.0339 0.1927 0.3529]
Median for last 10 epochs: [0.0956 0.034  0.1928 0.3539], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 86%|████████▌ | 430/500 [8:05:54<1:24:02, 72.04s/it] 86%|████████▌ | 431/500 [8:06:48<1:16:20, 66.38s/it] 86%|████████▋ | 432/500 [8:08:09<1:20:20, 70.88s/it]Epoch: 432 done with learning rate 6.19E-04, Train loss: -6.34E+05, Train scatter: [0.0876 0.0326 0.1861 0.3488]
L1 regularization loss: 1.03E+01, L2 regularization loss: 7.79E+00
Test scatter: [0.0955 0.0341 0.1931 0.3544], Lowest was [0.0954 0.0339 0.1927 0.3529]
Median for last 10 epochs: [0.0955 0.034  0.1928 0.3539], Epochs since improvement 2
 87%|████████▋ | 433/500 [8:09:02<1:13:16, 65.62s/it] 87%|████████▋ | 434/500 [8:10:25<1:17:43, 70.66s/it]Epoch: 434 done with learning rate 5.84E-04, Train loss: -6.38E+05, Train scatter: [0.0873 0.0324 0.1852 0.3474]
L1 regularization loss: 1.03E+01, L2 regularization loss: 7.80E+00
Test scatter: [0.0953 0.034  0.1925 0.3533], Lowest was [0.0953 0.0339 0.1925 0.3529]
Median for last 10 epochs: [0.0955 0.034  0.1927 0.3538], Epochs since improvement 0
 87%|████████▋ | 435/500 [8:11:18<1:10:49, 65.38s/it] 87%|████████▋ | 436/500 [8:12:38<1:14:32, 69.88s/it]Epoch: 436 done with learning rate 5.49E-04, Train loss: -6.39E+05, Train scatter: [0.0873 0.0324 0.185  0.347 ]
L1 regularization loss: 1.03E+01, L2 regularization loss: 7.81E+00
Test scatter: [0.0946 0.034  0.1919 0.3523], Lowest was [0.0946 0.0339 0.1919 0.3523]
Median for last 10 epochs: [0.0954 0.034  0.1927 0.3533], Epochs since improvement 0
 87%|████████▋ | 437/500 [8:13:31<1:08:05, 64.85s/it] 88%|████████▊ | 438/500 [8:14:51<1:11:44, 69.43s/it]Epoch: 438 done with learning rate 5.16E-04, Train loss: -6.41E+05, Train scatter: [0.0872 0.0325 0.186  0.3477]
L1 regularization loss: 1.03E+01, L2 regularization loss: 7.81E+00
Test scatter: [0.0943 0.0341 0.1929 0.3528], Lowest was [0.0943 0.0339 0.1919 0.3523]
Median for last 10 epochs: [0.0953 0.034  0.1927 0.3529], Epochs since improvement 0
 88%|████████▊ | 439/500 [8:15:45<1:05:37, 64.56s/it]Epoch: 440 done with learning rate 4.84E-04, Train loss: -6.35E+05, Train scatter: [0.0871 0.0323 0.1853 0.3475]
L1 regularization loss: 1.03E+01, L2 regularization loss: 7.82E+00
Test scatter: [0.0948 0.034  0.1926 0.3532], Lowest was [0.0943 0.0339 0.1919 0.3523]
Median for last 10 epochs: [0.0948 0.034  0.1926 0.3532], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 88%|████████▊ | 440/500 [8:17:12<1:11:26, 71.45s/it] 88%|████████▊ | 441/500 [8:18:05<1:04:52, 65.98s/it] 88%|████████▊ | 442/500 [8:19:27<1:08:16, 70.63s/it]Epoch: 442 done with learning rate 4.53E-04, Train loss: -6.45E+05, Train scatter: [0.0868 0.0322 0.1853 0.3465]
L1 regularization loss: 1.03E+01, L2 regularization loss: 7.83E+00
Test scatter: [0.0946 0.034  0.1925 0.3524], Lowest was [0.0943 0.0339 0.1919 0.3523]
Median for last 10 epochs: [0.0946 0.034  0.1925 0.3528], Epochs since improvement 4
 89%|████████▊ | 443/500 [8:20:20<1:02:05, 65.36s/it] 89%|████████▉ | 444/500 [8:21:41<1:05:26, 70.12s/it]Epoch: 444 done with learning rate 4.23E-04, Train loss: -6.48E+05, Train scatter: [0.0881 0.0322 0.1847 0.3456]
L1 regularization loss: 1.04E+01, L2 regularization loss: 7.84E+00
Test scatter: [0.0952 0.034  0.1921 0.3524], Lowest was [0.0943 0.0339 0.1919 0.3523]
Median for last 10 epochs: [0.0946 0.034  0.1925 0.3524], Epochs since improvement 6
 89%|████████▉ | 445/500 [8:22:34<59:35, 65.01s/it]   89%|████████▉ | 446/500 [8:23:55<1:02:48, 69.80s/it]Epoch: 446 done with learning rate 3.93E-04, Train loss: -6.51E+05, Train scatter: [0.0868 0.0321 0.1843 0.3453]
L1 regularization loss: 1.04E+01, L2 regularization loss: 7.84E+00
Test scatter: [0.0948 0.034  0.192  0.3528], Lowest was [0.0943 0.0339 0.1919 0.3523]
Median for last 10 epochs: [0.0948 0.034  0.1925 0.3528], Epochs since improvement 8
 89%|████████▉ | 447/500 [8:24:48<57:13, 64.78s/it]   90%|████████▉ | 448/500 [8:26:08<1:00:06, 69.36s/it]Epoch: 448 done with learning rate 3.65E-04, Train loss: -6.47E+05, Train scatter: [0.0865 0.0323 0.1851 0.3467]
L1 regularization loss: 1.04E+01, L2 regularization loss: 7.85E+00
Test scatter: [0.095  0.0341 0.1923 0.3527], Lowest was [0.0943 0.0339 0.1919 0.3523]
Median for last 10 epochs: [0.0948 0.034  0.1923 0.3527], Epochs since improvement 10
 90%|████████▉ | 449/500 [8:27:01<54:47, 64.46s/it]  Epoch: 450 done with learning rate 3.38E-04, Train loss: -6.54E+05, Train scatter: [0.0861 0.0321 0.1841 0.3449]
L1 regularization loss: 1.04E+01, L2 regularization loss: 7.85E+00
Test scatter: [0.0944 0.034  0.1919 0.3525], Lowest was [0.0943 0.0339 0.1919 0.3523]
Median for last 10 epochs: [0.0948 0.034  0.1921 0.3525], Epochs since improvement 12
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 90%|█████████ | 450/500 [8:28:28<59:21, 71.23s/it] 90%|█████████ | 451/500 [8:29:21<53:45, 65.82s/it] 90%|█████████ | 452/500 [8:30:43<56:23, 70.49s/it]Epoch: 452 done with learning rate 3.12E-04, Train loss: -6.58E+05, Train scatter: [0.0867 0.0321 0.184  0.3444]
L1 regularization loss: 1.04E+01, L2 regularization loss: 7.86E+00
Test scatter: [0.0954 0.034  0.1923 0.3525], Lowest was [0.0943 0.0339 0.1919 0.3523]
Median for last 10 epochs: [0.095  0.034  0.1921 0.3525], Epochs since improvement 14
 91%|█████████ | 453/500 [8:31:36<51:05, 65.22s/it] 91%|█████████ | 454/500 [8:32:55<53:17, 69.51s/it]Epoch: 454 done with learning rate 2.87E-04, Train loss: -6.59E+05, Train scatter: [0.0858 0.0319 0.1838 0.3441]
L1 regularization loss: 1.04E+01, L2 regularization loss: 7.86E+00
Test scatter: [0.094  0.034  0.1918 0.3523], Lowest was [0.094  0.0339 0.1918 0.3523]
Median for last 10 epochs: [0.0948 0.034  0.192  0.3525], Epochs since improvement 0
 91%|█████████ | 455/500 [8:33:48<48:25, 64.57s/it] 91%|█████████ | 456/500 [8:35:10<51:08, 69.75s/it]Epoch: 456 done with learning rate 2.62E-04, Train loss: -6.59E+05, Train scatter: [0.0859 0.0321 0.1837 0.3437]
L1 regularization loss: 1.04E+01, L2 regularization loss: 7.87E+00
Test scatter: [0.0941 0.0342 0.192  0.3523], Lowest was [0.094  0.0339 0.1918 0.3523]
Median for last 10 epochs: [0.0944 0.034  0.192  0.3525], Epochs since improvement 0
 91%|█████████▏| 457/500 [8:36:03<46:23, 64.74s/it] 92%|█████████▏| 458/500 [8:37:25<48:55, 69.90s/it]Epoch: 458 done with learning rate 2.39E-04, Train loss: -6.62E+05, Train scatter: [0.0862 0.032  0.1837 0.3437]
L1 regularization loss: 1.04E+01, L2 regularization loss: 7.87E+00
Test scatter: [0.0946 0.0341 0.192  0.3524], Lowest was [0.094  0.0339 0.1918 0.3523]
Median for last 10 epochs: [0.0944 0.034  0.192  0.3524], Epochs since improvement 2
 92%|█████████▏| 459/500 [8:38:18<44:18, 64.84s/it]Epoch: 460 done with learning rate 2.17E-04, Train loss: -6.64E+05, Train scatter: [0.0858 0.0319 0.1837 0.3433]
L1 regularization loss: 1.04E+01, L2 regularization loss: 7.88E+00
Test scatter: [0.0943 0.0341 0.1922 0.3523], Lowest was [0.094  0.0339 0.1918 0.3523]
Median for last 10 epochs: [0.0943 0.0341 0.192  0.3523], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 92%|█████████▏| 460/500 [8:39:46<47:54, 71.87s/it] 92%|█████████▏| 461/500 [8:40:40<43:03, 66.25s/it] 92%|█████████▏| 462/500 [8:42:01<44:55, 70.94s/it]Epoch: 462 done with learning rate 1.96E-04, Train loss: -6.64E+05, Train scatter: [0.0857 0.032  0.1835 0.3431]
L1 regularization loss: 1.04E+01, L2 regularization loss: 7.88E+00
Test scatter: [0.0943 0.0341 0.192  0.3527], Lowest was [0.094  0.0339 0.1918 0.3523]
Median for last 10 epochs: [0.0943 0.0341 0.192  0.3523], Epochs since improvement 6
 93%|█████████▎| 463/500 [8:42:54<40:25, 65.54s/it] 93%|█████████▎| 464/500 [8:44:14<41:54, 69.86s/it]Epoch: 464 done with learning rate 1.76E-04, Train loss: -6.65E+05, Train scatter: [0.0858 0.032  0.1834 0.3431]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.88E+00
Test scatter: [0.0942 0.0342 0.1919 0.3523], Lowest was [0.094  0.0339 0.1918 0.3523]
Median for last 10 epochs: [0.0943 0.0341 0.192  0.3523], Epochs since improvement 8
 93%|█████████▎| 465/500 [8:45:08<37:49, 64.85s/it] 93%|█████████▎| 466/500 [8:46:28<39:22, 69.48s/it]Epoch: 466 done with learning rate 1.57E-04, Train loss: -6.66E+05, Train scatter: [0.0855 0.0319 0.1833 0.3431]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.88E+00
Test scatter: [0.0942 0.0342 0.192  0.3522], Lowest was [0.094  0.0339 0.1918 0.3522]
Median for last 10 epochs: [0.0943 0.0341 0.192  0.3523], Epochs since improvement 0
 93%|█████████▎| 467/500 [8:47:21<35:30, 64.55s/it] 94%|█████████▎| 468/500 [8:48:41<36:57, 69.30s/it]Epoch: 468 done with learning rate 1.40E-04, Train loss: -6.67E+05, Train scatter: [0.0854 0.0319 0.1832 0.3426]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.89E+00
Test scatter: [0.0943 0.0342 0.192  0.3524], Lowest was [0.094  0.0339 0.1918 0.3522]
Median for last 10 epochs: [0.0943 0.0342 0.192  0.3523], Epochs since improvement 2
 94%|█████████▍| 469/500 [8:49:34<33:17, 64.44s/it]Epoch: 470 done with learning rate 1.23E-04, Train loss: -6.68E+05, Train scatter: [0.0853 0.0319 0.1831 0.3426]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.89E+00
Test scatter: [0.0941 0.0342 0.1919 0.352 ], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.192  0.3523], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 94%|█████████▍| 470/500 [8:51:02<35:40, 71.34s/it] 94%|█████████▍| 471/500 [8:51:55<31:50, 65.87s/it] 94%|█████████▍| 472/500 [8:53:16<32:49, 70.34s/it]Epoch: 472 done with learning rate 1.07E-04, Train loss: -6.71E+05, Train scatter: [0.0854 0.0318 0.1831 0.3423]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.89E+00
Test scatter: [0.0941 0.0341 0.192  0.3524], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.192  0.3523], Epochs since improvement 2
 95%|█████████▍| 473/500 [8:54:09<29:19, 65.18s/it] 95%|█████████▍| 474/500 [8:55:29<30:15, 69.81s/it]Epoch: 474 done with learning rate 9.24E-05, Train loss: -6.71E+05, Train scatter: [0.0854 0.0319 0.1831 0.3424]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.89E+00
Test scatter: [0.0942 0.0342 0.192  0.3523], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.192  0.3523], Epochs since improvement 4
 95%|█████████▌| 475/500 [8:56:22<26:59, 64.77s/it] 95%|█████████▌| 476/500 [8:57:43<27:47, 69.48s/it]Epoch: 476 done with learning rate 7.88E-05, Train loss: -6.71E+05, Train scatter: [0.0852 0.0319 0.1831 0.3421]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.89E+00
Test scatter: [0.0942 0.0342 0.1922 0.3526], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.192  0.3524], Epochs since improvement 6
 95%|█████████▌| 477/500 [8:58:36<24:44, 64.56s/it] 96%|█████████▌| 478/500 [8:59:57<25:26, 69.37s/it]Epoch: 478 done with learning rate 6.63E-05, Train loss: -6.73E+05, Train scatter: [0.0852 0.0319 0.183  0.3421]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.90E+00
Test scatter: [0.0943 0.0342 0.1921 0.3524], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.192  0.3524], Epochs since improvement 8
 96%|█████████▌| 479/500 [9:00:49<22:33, 64.43s/it]Epoch: 480 done with learning rate 5.49E-05, Train loss: -6.73E+05, Train scatter: [0.0852 0.0319 0.183  0.342 ]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.90E+00
Test scatter: [0.0943 0.0342 0.1921 0.3524], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.1921 0.3524], Epochs since improvement 10
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 96%|█████████▌| 480/500 [9:02:17<23:45, 71.27s/it] 96%|█████████▌| 481/500 [9:03:10<20:51, 65.85s/it] 96%|█████████▋| 482/500 [9:04:31<21:08, 70.46s/it]Epoch: 482 done with learning rate 4.46E-05, Train loss: -6.64E+05, Train scatter: [0.0857 0.032  0.1836 0.3427]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.90E+00
Test scatter: [0.0942 0.0342 0.1923 0.3531], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.1921 0.3524], Epochs since improvement 12
 97%|█████████▋| 483/500 [9:05:24<18:28, 65.22s/it] 97%|█████████▋| 484/500 [9:06:44<18:33, 69.58s/it]Epoch: 484 done with learning rate 3.53E-05, Train loss: -6.71E+05, Train scatter: [0.0854 0.0319 0.1831 0.3422]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.90E+00
Test scatter: [0.0942 0.0342 0.1924 0.3528], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.1922 0.3526], Epochs since improvement 14
 97%|█████████▋| 485/500 [9:07:37<16:09, 64.66s/it] 97%|█████████▋| 486/500 [9:08:57<16:10, 69.29s/it]Epoch: 486 done with learning rate 2.71E-05, Train loss: -6.72E+05, Train scatter: [0.0853 0.0319 0.183  0.342 ]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.90E+00
Test scatter: [0.0942 0.0342 0.1921 0.3522], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.1921 0.3524], Epochs since improvement 16
 97%|█████████▋| 487/500 [9:09:50<13:57, 64.39s/it] 98%|█████████▊| 488/500 [9:11:11<13:51, 69.27s/it]Epoch: 488 done with learning rate 2.00E-05, Train loss: -6.73E+05, Train scatter: [0.0853 0.0319 0.183  0.342 ]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.90E+00
Test scatter: [0.0942 0.0342 0.1921 0.3524], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.1921 0.3524], Epochs since improvement 18
 98%|█████████▊| 489/500 [9:12:04<11:48, 64.39s/it]Epoch: 490 done with learning rate 1.40E-05, Train loss: -6.74E+05, Train scatter: [0.0852 0.0319 0.183  0.3419]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.90E+00
Test scatter: [0.0942 0.0342 0.1922 0.3524], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.1922 0.3524], Epochs since improvement 20
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 98%|█████████▊| 490/500 [9:13:32<11:56, 71.67s/it] 98%|█████████▊| 491/500 [9:14:26<09:55, 66.18s/it] 98%|█████████▊| 491/500 [9:15:47<10:11, 67.92s/it]
Epoch: 492 done with learning rate 9.12E-06, Train loss: -6.74E+05, Train scatter: [0.0852 0.0319 0.183  0.3419]
L1 regularization loss: 1.05E+01, L2 regularization loss: 7.90E+00
Test scatter: [0.0942 0.0342 0.1922 0.3525], Lowest was [0.094  0.0339 0.1918 0.352 ]
Median for last 10 epochs: [0.0942 0.0342 0.1922 0.3524], Epochs since improvement 22
Exited after 492 epochs due to early stopping
33347.02 seconds spent training, 66.694 seconds per epoch. Processed 1044 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.094203   0.03422783 0.1921965  0.35250023]
{'epoch_exit': 491, 'scatter_m_star': 0.094202995, 'lowest_m_star': 0.094033316, 'last20_m_star': 0.094217, 'last10_m_star': 0.09421686, 'scatter_v_disk': 0.03422783, 'lowest_v_disk': 0.033893466, 'last20_v_disk': 0.03422769, 'last10_v_disk': 0.03422899, 'scatter_m_cold': 0.1921965, 'lowest_m_cold': 0.19177815, 'last20_m_cold': 0.19215558, 'last10_m_cold': 0.19216645, 'scatter_sfr_100': 0.35250023, 'lowest_sfr_100': 0.3519919, 'last20_sfr_100': 0.35240817, 'last10_sfr_100': 0.35244077}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
