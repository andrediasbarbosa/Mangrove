Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_oronod
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:31<4:22:04, 31.51s/it]  0%|          | 2/500 [01:19<5:43:56, 41.44s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.21E+07, Train scatter: [0.9353 0.1747 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1818 0.5356 0.9851], Lowest was [0.9198 0.1818 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1818 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:51<5:05:26, 36.87s/it]  1%|          | 4/500 [02:40<5:43:25, 41.54s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 7.49E+06, Train scatter: [0.9352 0.1757 0.544  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1877 0.5354 0.985 ], Lowest was [0.9197 0.1818 0.5354 0.985 ]
Median for last 10 epochs: [0.9197 0.1848 0.5354 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:11<5:12:37, 37.89s/it]  1%|          | 6/500 [04:00<5:42:41, 41.62s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.64E+06, Train scatter: [0.9346 0.1418 0.5428 0.7249]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9191 0.1449 0.5342 0.7216], Lowest was [0.9191 0.1449 0.5342 0.7216]
Median for last 10 epochs: [0.9191 0.1449 0.5342 0.7216], Epochs since improvement 0
  1%|▏         | 7/500 [04:31<5:14:30, 38.28s/it]  2%|▏         | 8/500 [05:20<5:41:25, 41.64s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.83E+06, Train scatter: [0.9245 0.1257 0.5366 0.6658]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9089 0.1268 0.5282 0.662 ], Lowest was [0.9089 0.1268 0.5282 0.662 ]
Median for last 10 epochs: [0.914  0.1358 0.5312 0.6918], Epochs since improvement 0
  2%|▏         | 9/500 [05:51<5:14:36, 38.45s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.15E+06, Train scatter: [0.7691 0.114  0.5229 0.6223]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7542 0.116  0.515  0.618 ], Lowest was [0.7542 0.116  0.515  0.618 ]
Median for last 10 epochs: [0.9089 0.1268 0.5282 0.662 ], Epochs since improvement 0
  2%|▏         | 10/500 [06:46<5:53:45, 43.32s/it]  2%|▏         | 11/500 [07:17<5:23:24, 39.68s/it]  2%|▏         | 12/500 [08:06<5:44:27, 42.35s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.66E+06, Train scatter: [0.6583 0.1131 0.4425 0.6269]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6641 0.1164 0.4371 0.624 ], Lowest was [0.6641 0.116  0.4371 0.618 ]
Median for last 10 epochs: [0.9089 0.1268 0.5282 0.662 ], Epochs since improvement 0
  3%|▎         | 13/500 [08:37<5:16:59, 39.06s/it]  3%|▎         | 14/500 [09:26<5:40:20, 42.02s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.82E+06, Train scatter: [0.5746 0.1051 0.4166 0.664 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5742 0.1078 0.4198 0.6672], Lowest was [0.5742 0.1078 0.4198 0.618 ]
Median for last 10 epochs: [0.7542 0.1164 0.515  0.662 ], Epochs since improvement 0
  3%|▎         | 15/500 [09:57<5:14:01, 38.85s/it]  3%|▎         | 16/500 [10:46<5:37:38, 41.86s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.31E+06, Train scatter: [0.5478 0.1012 0.3606 0.5924]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5518 0.1085 0.3681 0.6067], Lowest was [0.5518 0.1078 0.3681 0.6067]
Median for last 10 epochs: [0.6641 0.116  0.4371 0.624 ], Epochs since improvement 0
  3%|▎         | 17/500 [11:18<5:11:59, 38.76s/it]  4%|▎         | 18/500 [12:07<5:36:00, 41.83s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.09E+06, Train scatter: [0.6318 0.0977 0.3661 0.6025]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6112 0.1009 0.362  0.6006], Lowest was [0.5518 0.1009 0.362  0.6006]
Median for last 10 epochs: [0.6112 0.1085 0.4198 0.618 ], Epochs since improvement 0
  4%|▍         | 19/500 [12:38<5:10:24, 38.72s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 9.41E+05, Train scatter: [0.5739 0.0917 0.3303 0.5731]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5584 0.0956 0.3364 0.5756], Lowest was [0.5518 0.0956 0.3364 0.5756]
Median for last 10 epochs: [0.5742 0.1078 0.3681 0.6067], Epochs since improvement 0
  4%|▍         | 20/500 [13:32<5:45:39, 43.21s/it]  4%|▍         | 21/500 [14:03<5:16:48, 39.68s/it]  4%|▍         | 22/500 [14:52<5:38:10, 42.45s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 8.15E+05, Train scatter: [0.5043 0.0896 0.3365 0.5889]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.504  0.0929 0.3429 0.5939], Lowest was [0.504  0.0929 0.3364 0.5756]
Median for last 10 epochs: [0.5584 0.1009 0.362  0.6006], Epochs since improvement 0
  5%|▍         | 23/500 [15:24<5:11:18, 39.16s/it]  5%|▍         | 24/500 [16:13<5:34:23, 42.15s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 9.19E+05, Train scatter: [0.5044 0.089  0.3208 0.56  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5023 0.0919 0.3253 0.5609], Lowest was [0.5023 0.0919 0.3253 0.5609]
Median for last 10 epochs: [0.5518 0.0956 0.3429 0.5939], Epochs since improvement 0
  5%|▌         | 25/500 [16:44<5:08:22, 38.95s/it]  5%|▌         | 26/500 [17:33<5:30:57, 41.89s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.26E+05, Train scatter: [0.479  0.0859 0.3197 0.5487]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4771 0.0881 0.3219 0.5499], Lowest was [0.4771 0.0881 0.3219 0.5499]
Median for last 10 epochs: [0.504  0.0929 0.3364 0.5756], Epochs since improvement 0
  5%|▌         | 27/500 [18:05<5:05:42, 38.78s/it]  6%|▌         | 28/500 [18:54<5:28:46, 41.79s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 6.70E+05, Train scatter: [0.5556 0.0836 0.3015 0.534 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.564  0.0857 0.3073 0.5351], Lowest was [0.4771 0.0857 0.3073 0.5351]
Median for last 10 epochs: [0.504  0.0919 0.3253 0.5609], Epochs since improvement 0
  6%|▌         | 29/500 [19:25<5:03:57, 38.72s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 5.97E+05, Train scatter: [0.4921 0.0836 0.3059 0.5291]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5031 0.0863 0.3125 0.5336], Lowest was [0.4771 0.0857 0.3073 0.5336]
Median for last 10 epochs: [0.5031 0.0881 0.3219 0.5499], Epochs since improvement 0
  6%|▌         | 30/500 [20:19<5:40:12, 43.43s/it]  6%|▌         | 31/500 [20:51<5:11:33, 39.86s/it]  6%|▋         | 32/500 [21:40<5:32:12, 42.59s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 5.30E+05, Train scatter: [0.4548 0.0799 0.2958 0.53  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4667 0.0821 0.3024 0.5316], Lowest was [0.4667 0.0821 0.3024 0.5316]
Median for last 10 epochs: [0.5023 0.0863 0.3125 0.5351], Epochs since improvement 0
  7%|▋         | 33/500 [22:11<5:05:16, 39.22s/it]  7%|▋         | 34/500 [23:00<5:26:41, 42.06s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 4.62E+05, Train scatter: [0.4722 0.0792 0.3213 0.5223]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4681 0.0813 0.3211 0.5289], Lowest was [0.4667 0.0813 0.3024 0.5289]
Median for last 10 epochs: [0.4771 0.0857 0.3125 0.5336], Epochs since improvement 0
  7%|▋         | 35/500 [23:32<5:01:24, 38.89s/it]  7%|▋         | 36/500 [24:21<5:24:23, 41.95s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 4.22E+05, Train scatter: [0.4227 0.0803 0.3158 0.568 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4336 0.0837 0.3351 0.574 ], Lowest was [0.4336 0.0813 0.3024 0.5289]
Median for last 10 epochs: [0.4681 0.0837 0.3125 0.5336], Epochs since improvement 0
  7%|▋         | 37/500 [24:52<4:59:29, 38.81s/it]  8%|▊         | 38/500 [25:41<5:22:54, 41.94s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.69E+05, Train scatter: [0.4301 0.0739 0.2848 0.5174]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4281 0.0744 0.2935 0.5205], Lowest was [0.4281 0.0744 0.2935 0.5205]
Median for last 10 epochs: [0.4667 0.0821 0.3125 0.5316], Epochs since improvement 0
  8%|▊         | 39/500 [26:13<4:58:10, 38.81s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: -7.31E+04, Train scatter: [0.3903 0.0707 0.2825 0.4971]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3824 0.0717 0.2925 0.4983], Lowest was [0.3824 0.0717 0.2925 0.4983]
Median for last 10 epochs: [0.4336 0.0813 0.3024 0.5289], Epochs since improvement 0
  8%|▊         | 40/500 [27:07<5:32:43, 43.40s/it]  8%|▊         | 41/500 [27:39<5:04:58, 39.87s/it]  8%|▊         | 42/500 [28:28<5:25:31, 42.64s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.51E+05, Train scatter: [0.4124 0.0675 0.2777 0.4883]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4056 0.0689 0.2871 0.4867], Lowest was [0.3824 0.0689 0.2871 0.4867]
Median for last 10 epochs: [0.4281 0.0744 0.2935 0.5205], Epochs since improvement 0
  9%|▊         | 43/500 [28:59<4:59:32, 39.33s/it]  9%|▉         | 44/500 [29:48<5:20:18, 42.15s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.67E+05, Train scatter: [0.4479 0.0655 0.2793 0.4939]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4499 0.0673 0.2898 0.4941], Lowest was [0.3824 0.0673 0.2871 0.4867]
Median for last 10 epochs: [0.4281 0.0717 0.2925 0.4983], Epochs since improvement 0
  9%|▉         | 45/500 [30:20<4:55:45, 39.00s/it]  9%|▉         | 46/500 [31:08<5:17:17, 41.93s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: -2.75E+05, Train scatter: [0.4003 0.0657 0.2798 0.4946]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.417  0.0677 0.2909 0.4918], Lowest was [0.3824 0.0673 0.2871 0.4867]
Median for last 10 epochs: [0.417  0.0689 0.2909 0.4941], Epochs since improvement 2
  9%|▉         | 47/500 [31:40<4:52:57, 38.80s/it] 10%|▉         | 48/500 [32:29<5:15:58, 41.94s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: -2.08E+05, Train scatter: [0.4    0.0642 0.2851 0.4859]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3927 0.0653 0.2926 0.4836], Lowest was [0.3824 0.0653 0.2871 0.4836]
Median for last 10 epochs: [0.4056 0.0677 0.2909 0.4918], Epochs since improvement 0
 10%|▉         | 49/500 [33:01<4:51:55, 38.84s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: -2.69E+05, Train scatter: [0.423  0.0673 0.2853 0.5041]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4168 0.0682 0.291  0.4984], Lowest was [0.3824 0.0653 0.2871 0.4836]
Median for last 10 epochs: [0.4168 0.0677 0.2909 0.4918], Epochs since improvement 2
 10%|█         | 50/500 [33:55<5:25:33, 43.41s/it] 10%|█         | 51/500 [34:26<4:58:10, 39.85s/it] 10%|█         | 52/500 [35:16<5:18:56, 42.71s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: -2.75E+05, Train scatter: [0.3028 0.0635 0.2833 0.486 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2908 0.0641 0.2891 0.4845], Lowest was [0.2908 0.0641 0.2871 0.4836]
Median for last 10 epochs: [0.4168 0.0673 0.2909 0.4918], Epochs since improvement 0
 11%|█         | 53/500 [35:47<4:53:32, 39.40s/it] 11%|█         | 54/500 [36:36<5:14:14, 42.28s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: -2.76E+05, Train scatter: [0.2524 0.0633 0.2961 0.4849]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2621 0.0641 0.2982 0.4837], Lowest was [0.2621 0.0641 0.2871 0.4836]
Median for last 10 epochs: [0.3927 0.0653 0.291  0.4845], Epochs since improvement 0
 11%|█         | 55/500 [37:08<4:49:42, 39.06s/it] 11%|█         | 56/500 [37:57<5:11:48, 42.14s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: -2.65E+05, Train scatter: [0.374  0.0644 0.2862 0.4737]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3747 0.065  0.2911 0.4769], Lowest was [0.2621 0.0641 0.2871 0.4769]
Median for last 10 epochs: [0.3747 0.065  0.2911 0.4837], Epochs since improvement 0
 11%|█▏        | 57/500 [38:29<4:47:49, 38.98s/it] 12%|█▏        | 58/500 [39:17<5:08:07, 41.83s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: -2.73E+05, Train scatter: [0.288  0.0658 0.5302 0.5002]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2846 0.0661 0.5216 0.5001], Lowest was [0.2621 0.0641 0.2871 0.4769]
Median for last 10 epochs: [0.2908 0.065  0.2911 0.4845], Epochs since improvement 2
 12%|█▏        | 59/500 [39:49<4:44:55, 38.77s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: -2.13E+05, Train scatter: [0.3937 0.0659 0.3149 0.4864]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3902 0.0671 0.3216 0.4863], Lowest was [0.2621 0.0641 0.2871 0.4769]
Median for last 10 epochs: [0.2908 0.065  0.2982 0.4845], Epochs since improvement 4
 12%|█▏        | 60/500 [40:43<5:17:12, 43.26s/it] 12%|█▏        | 61/500 [41:14<4:50:48, 39.74s/it] 12%|█▏        | 62/500 [42:04<5:11:03, 42.61s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: -2.22E+05, Train scatter: [0.3903 0.0749 0.3097 0.4918]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3855 0.074  0.3129 0.4923], Lowest was [0.2621 0.0641 0.2871 0.4769]
Median for last 10 epochs: [0.3747 0.0661 0.3129 0.4863], Epochs since improvement 6
 13%|█▎        | 63/500 [42:35<4:46:06, 39.28s/it] 13%|█▎        | 64/500 [43:24<5:07:04, 42.26s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: -2.67E+05, Train scatter: [0.433  0.0698 0.3213 0.5061]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4367 0.0721 0.3345 0.5132], Lowest was [0.2621 0.0641 0.2871 0.4769]
Median for last 10 epochs: [0.3855 0.0671 0.3216 0.4923], Epochs since improvement 8
 13%|█▎        | 65/500 [43:56<4:43:14, 39.07s/it] 13%|█▎        | 66/500 [44:45<5:04:52, 42.15s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: -2.88E+05, Train scatter: [0.4259 0.0635 0.2918 0.4751]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4194 0.0644 0.2959 0.4755], Lowest was [0.2621 0.0641 0.2871 0.4755]
Median for last 10 epochs: [0.3902 0.0671 0.3216 0.4923], Epochs since improvement 0
 13%|█▎        | 67/500 [45:17<4:41:27, 39.00s/it] 14%|█▎        | 68/500 [46:06<5:02:39, 42.04s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: -2.91E+05, Train scatter: [0.4349 0.0601 0.2968 0.4757]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4216 0.0614 0.3043 0.4781], Lowest was [0.2621 0.0614 0.2871 0.4755]
Median for last 10 epochs: [0.4194 0.0671 0.3129 0.4863], Epochs since improvement 0
 14%|█▍        | 69/500 [46:38<4:39:30, 38.91s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: -3.06E+05, Train scatter: [0.2337 0.059  0.2765 0.4669]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.243  0.0597 0.2818 0.468 ], Lowest was [0.243  0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.4194 0.0644 0.3043 0.4781], Epochs since improvement 0
 14%|█▍        | 70/500 [47:32<5:12:14, 43.57s/it] 14%|█▍        | 71/500 [48:04<4:45:38, 39.95s/it] 14%|█▍        | 72/500 [48:53<5:05:56, 42.89s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: -3.10E+05, Train scatter: [0.2173 0.0618 0.2996 0.4759]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2262 0.0627 0.3057 0.4759], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.4194 0.0627 0.3043 0.4759], Epochs since improvement 0
 15%|█▍        | 73/500 [49:25<4:41:15, 39.52s/it] 15%|█▍        | 74/500 [50:14<5:01:15, 42.43s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.27E+05, Train scatter: [0.9352 0.1719 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1681 0.5355 0.9851], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.4194 0.0627 0.3043 0.4759], Epochs since improvement 2
 15%|█▌        | 75/500 [50:46<4:37:31, 39.18s/it] 15%|█▌        | 76/500 [51:35<4:57:29, 42.10s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.96E+05, Train scatter: [0.9352 0.1719 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1681 0.5355 0.9851], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.4216 0.0627 0.3057 0.4781], Epochs since improvement 4
 15%|█▌        | 77/500 [52:07<4:35:12, 39.04s/it] 16%|█▌        | 78/500 [52:56<4:56:25, 42.14s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.86E+05, Train scatter: [0.9352 0.172  0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1682 0.5355 0.9851], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.9196 0.1681 0.5355 0.9851], Epochs since improvement 6
 16%|█▌        | 79/500 [53:28<4:33:30, 38.98s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.75E+05, Train scatter: [0.9352 0.1721 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1683 0.5355 0.9851], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.9196 0.1681 0.5355 0.9851], Epochs since improvement 8
 16%|█▌        | 80/500 [54:26<5:13:16, 44.75s/it] 16%|█▌        | 81/500 [54:58<4:45:18, 40.86s/it] 16%|█▋        | 82/500 [55:47<5:01:41, 43.30s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.31E+05, Train scatter: [0.9352 0.1722 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1684 0.5355 0.9851], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.9196 0.1682 0.5355 0.9851], Epochs since improvement 10
 17%|█▋        | 83/500 [56:19<4:37:17, 39.90s/it] 17%|█▋        | 84/500 [57:08<4:55:44, 42.66s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 7.50E+04, Train scatter: [0.9352 0.1724 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1686 0.5355 0.9851], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.9196 0.1683 0.5355 0.9851], Epochs since improvement 12
 17%|█▋        | 85/500 [57:40<4:32:51, 39.45s/it] 17%|█▋        | 86/500 [58:30<4:53:51, 42.59s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 7.51E+04, Train scatter: [0.9352 0.1727 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1689 0.5355 0.9851], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.9196 0.1684 0.5355 0.9851], Epochs since improvement 14
 17%|█▋        | 87/500 [59:02<4:31:09, 39.39s/it] 18%|█▊        | 88/500 [59:52<4:52:25, 42.59s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 7.44E+04, Train scatter: [0.9352 0.173  0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1691 0.5355 0.985 ], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.9196 0.1686 0.5355 0.9851], Epochs since improvement 16
 18%|█▊        | 89/500 [1:00:23<4:29:29, 39.34s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 7.35E+04, Train scatter: [0.9352 0.1733 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1694 0.5355 0.985 ], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.9196 0.1689 0.5355 0.9851], Epochs since improvement 18
 18%|█▊        | 90/500 [1:01:18<5:00:39, 44.00s/it] 18%|█▊        | 91/500 [1:01:50<4:34:32, 40.27s/it] 18%|█▊        | 92/500 [1:02:40<4:53:52, 43.22s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 6.88E+04, Train scatter: [0.9351 0.1729 0.544  0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.169  0.5355 0.9847], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 20
 19%|█▊        | 93/500 [1:03:11<4:29:31, 39.73s/it] 19%|█▊        | 93/500 [1:04:01<4:40:13, 41.31s/it]
Epoch: 94 done with learning rate 9.95E-03, Train loss: 9.34E+04, Train scatter: [0.9349 0.1682 0.544  0.993 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9193 0.1645 0.5354 0.9827], Lowest was [0.2262 0.0597 0.2818 0.468 ]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 22
Exited after 94 epochs due to early stopping
3842.31 seconds spent training, 7.685 seconds per epoch. Processed 9062 trees per second
[0.91930467 0.16452657 0.5353894  0.98266464]
{'epoch_exit': 93, 'scatter_m_star': 0.91930467, 'lowest_m_star': 0.22616722, 'last20_m_star': 0.9196124, 'last10_m_star': 0.9195954, 'scatter_v_disk': 0.16452657, 'lowest_v_disk': 0.059728768, 'last20_v_disk': 0.16850282, 'last10_v_disk': 0.16904971, 'scatter_m_cold': 0.5353894, 'lowest_m_cold': 0.281848, 'last20_m_cold': 0.53548825, 'last10_m_cold': 0.5354801, 'scatter_sfr_100': 0.98266464, 'lowest_sfr_100': 0.4680346, 'last20_sfr_100': 0.9850637, 'last10_sfr_100': 0.98500645}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_vwovlg
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:54:48, 28.23s/it]  0%|          | 2/500 [01:12<5:12:26, 37.64s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.45E+07, Train scatter: [0.9354 0.179  0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1876 0.5357 0.9851], Lowest was [0.9198 0.1876 0.5357 0.9851]
Median for last 10 epochs: [0.9198 0.1876 0.5357 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:39<4:32:54, 32.95s/it]  1%|          | 4/500 [02:26<5:17:22, 38.39s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.47E+07, Train scatter: [0.9353 0.174  0.5442 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9198 0.1769 0.5356 0.9851], Lowest was [0.9198 0.1769 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1769 0.5356 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:54<4:44:46, 34.52s/it]  1%|          | 6/500 [03:41<5:19:23, 38.79s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.08E+07, Train scatter: [0.9354 0.1674 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9199 0.1702 0.5356 0.9851], Lowest was [0.9198 0.1702 0.5356 0.9851]
Median for last 10 epochs: [0.9198 0.1702 0.5356 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:08<4:48:23, 35.10s/it]  2%|▏         | 8/500 [04:55<5:17:11, 38.68s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 9.76E+06, Train scatter: [0.9353 0.1488 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9197 0.1476 0.5355 0.9848], Lowest was [0.9197 0.1476 0.5355 0.9848]
Median for last 10 epochs: [0.9198 0.1589 0.5356 0.9849], Epochs since improvement 0
  2%|▏         | 9/500 [05:22<4:47:23, 35.12s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.68E+06, Train scatter: [0.9351 0.1348 0.544  0.733 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1345 0.5355 0.7306], Lowest was [0.9196 0.1345 0.5355 0.7306]
Median for last 10 epochs: [0.9197 0.1476 0.5355 0.9848], Epochs since improvement 0
  2%|▏         | 10/500 [06:15<5:31:27, 40.59s/it]  2%|▏         | 11/500 [06:42<4:58:05, 36.58s/it]  2%|▏         | 12/500 [07:28<5:21:00, 39.47s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.76E+06, Train scatter: [0.9348 0.1269 0.544  0.7092]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9192 0.1245 0.5354 0.7025], Lowest was [0.9192 0.1245 0.5354 0.7025]
Median for last 10 epochs: [0.9197 0.1476 0.5355 0.9848], Epochs since improvement 0
  3%|▎         | 13/500 [07:56<4:50:53, 35.84s/it]  3%|▎         | 14/500 [08:42<5:15:35, 38.96s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.54E+06, Train scatter: [0.9197 0.1215 0.5438 0.6597]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9059 0.1196 0.5352 0.6508], Lowest was [0.9059 0.1196 0.5352 0.6508]
Median for last 10 epochs: [0.9196 0.1345 0.5355 0.7306], Epochs since improvement 0
  3%|▎         | 15/500 [09:09<4:46:59, 35.50s/it]  3%|▎         | 16/500 [09:55<5:11:25, 38.61s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.37E+06, Train scatter: [0.7665 0.1154 0.5419 0.625 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7625 0.1138 0.5336 0.6175], Lowest was [0.7625 0.1138 0.5336 0.6175]
Median for last 10 epochs: [0.9192 0.1245 0.5354 0.7025], Epochs since improvement 0
  3%|▎         | 17/500 [10:23<4:43:43, 35.25s/it]  4%|▎         | 18/500 [11:09<5:09:48, 38.57s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 6.14E+06, Train scatter: [0.5854 0.1081 0.5389 0.5929]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5814 0.1072 0.5307 0.5865], Lowest was [0.5814 0.1072 0.5307 0.5865]
Median for last 10 epochs: [0.9059 0.1196 0.5352 0.6508], Epochs since improvement 0
  4%|▍         | 19/500 [11:36<4:42:26, 35.23s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.92E+06, Train scatter: [0.4995 0.1016 0.536  0.5896]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5076 0.1017 0.5278 0.5895], Lowest was [0.5076 0.1017 0.5278 0.5865]
Median for last 10 epochs: [0.7625 0.1138 0.5336 0.6175], Epochs since improvement 0
  4%|▍         | 20/500 [12:27<5:18:57, 39.87s/it]  4%|▍         | 21/500 [12:55<4:48:43, 36.17s/it]  4%|▍         | 22/500 [13:41<5:12:02, 39.17s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.61E+06, Train scatter: [0.5493 0.0975 0.5298 0.5711]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5466 0.0981 0.5217 0.5659], Lowest was [0.5076 0.0981 0.5217 0.5659]
Median for last 10 epochs: [0.5814 0.1072 0.5307 0.5895], Epochs since improvement 0
  5%|▍         | 23/500 [14:08<4:43:35, 35.67s/it]  5%|▍         | 24/500 [14:54<5:07:50, 38.80s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 5.31E+06, Train scatter: [0.4926 0.0995 0.5202 0.5847]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5073 0.1009 0.5123 0.5867], Lowest was [0.5073 0.0981 0.5123 0.5659]
Median for last 10 epochs: [0.5466 0.1017 0.5278 0.5867], Epochs since improvement 0
  5%|▌         | 25/500 [15:22<4:40:29, 35.43s/it]  5%|▌         | 26/500 [16:08<5:04:10, 38.50s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 5.44E+06, Train scatter: [0.6567 0.1323 0.4926 0.7809]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6524 0.1306 0.4904 0.7749], Lowest was [0.5073 0.0981 0.4904 0.5659]
Median for last 10 epochs: [0.5466 0.1017 0.5217 0.5867], Epochs since improvement 0
  5%|▌         | 27/500 [16:35<4:37:43, 35.23s/it]  6%|▌         | 28/500 [17:22<5:03:42, 38.61s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.73E+06, Train scatter: [0.5725 0.1099 0.4309 0.6495]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5643 0.1071 0.4273 0.6332], Lowest was [0.5073 0.0981 0.4273 0.5659]
Median for last 10 epochs: [0.5466 0.1017 0.5123 0.5895], Epochs since improvement 0
  6%|▌         | 29/500 [17:49<4:36:55, 35.28s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.74E+06, Train scatter: [0.5456 0.1002 0.3759 0.5958]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5527 0.1015 0.374  0.589 ], Lowest was [0.5073 0.0981 0.374  0.5659]
Median for last 10 epochs: [0.5527 0.1015 0.4904 0.589 ], Epochs since improvement 0
  6%|▌         | 30/500 [18:40<5:12:38, 39.91s/it]  6%|▌         | 31/500 [19:08<4:42:50, 36.18s/it]  6%|▋         | 32/500 [19:54<5:06:06, 39.24s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.50E+08, Train scatter: [0.9144 0.1387 0.5487 0.9529]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8967 0.1351 0.5405 0.9407], Lowest was [0.5073 0.0981 0.374  0.5659]
Median for last 10 epochs: [0.5643 0.1071 0.4904 0.6332], Epochs since improvement 2
  7%|▋         | 33/500 [20:21<4:37:59, 35.72s/it]  7%|▋         | 34/500 [21:08<5:02:11, 38.91s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 1.24E+07, Train scatter: [0.6627 0.1663 0.5106 0.9488]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6643 0.1634 0.5067 0.9417], Lowest was [0.5073 0.0981 0.374  0.5659]
Median for last 10 epochs: [0.6524 0.1306 0.4904 0.7749], Epochs since improvement 4
  7%|▋         | 35/500 [21:35<4:34:58, 35.48s/it]  7%|▋         | 36/500 [22:21<4:59:11, 38.69s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 1.02E+07, Train scatter: [0.6163 0.1535 0.5012 0.8971]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6138 0.149  0.4934 0.8917], Lowest was [0.5073 0.0981 0.374  0.5659]
Median for last 10 epochs: [0.6138 0.1351 0.4934 0.8917], Epochs since improvement 6
  7%|▋         | 37/500 [22:49<4:32:32, 35.32s/it]  8%|▊         | 38/500 [23:35<4:57:40, 38.66s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 8.47E+06, Train scatter: [0.5954 0.1354 0.5034 0.8121]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6041 0.1334 0.4961 0.8121], Lowest was [0.5073 0.0981 0.374  0.5659]
Median for last 10 epochs: [0.6138 0.1351 0.4961 0.8917], Epochs since improvement 8
  8%|▊         | 39/500 [24:03<4:31:17, 35.31s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 6.43E+06, Train scatter: [0.5177 0.1137 0.4306 0.6916]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5135 0.1147 0.4271 0.6958], Lowest was [0.5073 0.0981 0.374  0.5659]
Median for last 10 epochs: [0.6138 0.1351 0.4961 0.8917], Epochs since improvement 10
  8%|▊         | 40/500 [24:56<5:10:50, 40.54s/it]  8%|▊         | 41/500 [25:23<4:40:34, 36.68s/it]  8%|▊         | 42/500 [26:10<5:02:27, 39.62s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 4.89E+06, Train scatter: [0.4658 0.1076 0.3992 0.6163]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4761 0.1104 0.3993 0.6234], Lowest was [0.4761 0.0981 0.374  0.5659]
Median for last 10 epochs: [0.6041 0.1334 0.4934 0.8121], Epochs since improvement 0
  9%|▊         | 43/500 [26:37<4:34:15, 36.01s/it]  9%|▉         | 44/500 [27:23<4:56:52, 39.06s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.19E+06, Train scatter: [0.3887 0.1021 0.4001 0.604 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.397  0.1039 0.4008 0.6006], Lowest was [0.397  0.0981 0.374  0.5659]
Median for last 10 epochs: [0.5135 0.1147 0.4271 0.6958], Epochs since improvement 0
  9%|▉         | 45/500 [27:51<4:29:59, 35.60s/it]  9%|▉         | 46/500 [28:37<4:53:59, 38.85s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.78E+06, Train scatter: [0.348  0.099  0.3694 0.5911]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3682 0.1016 0.3698 0.596 ], Lowest was [0.3682 0.0981 0.3698 0.5659]
Median for last 10 epochs: [0.4761 0.1104 0.4008 0.6234], Epochs since improvement 0
  9%|▉         | 47/500 [29:05<4:27:57, 35.49s/it] 10%|▉         | 48/500 [29:52<4:53:42, 38.99s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.66E+06, Train scatter: [0.3753 0.0959 0.3702 0.5826]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3759 0.099  0.3718 0.5886], Lowest was [0.3682 0.0981 0.3698 0.5659]
Median for last 10 epochs: [0.397  0.1039 0.3993 0.6006], Epochs since improvement 2
 10%|▉         | 49/500 [30:20<4:27:16, 35.56s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.30E+06, Train scatter: [0.3622 0.0917 0.3692 0.5731]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3735 0.0947 0.3762 0.5788], Lowest was [0.3682 0.0947 0.3698 0.5659]
Median for last 10 epochs: [0.3759 0.1016 0.3762 0.596 ], Epochs since improvement 0
 10%|█         | 50/500 [31:12<5:04:34, 40.61s/it] 10%|█         | 51/500 [31:40<4:34:25, 36.67s/it] 10%|█         | 52/500 [32:26<4:55:52, 39.63s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.11E+06, Train scatter: [0.3161 0.0906 0.3446 0.5695]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3388 0.0944 0.3478 0.5787], Lowest was [0.3388 0.0944 0.3478 0.5659]
Median for last 10 epochs: [0.3735 0.099  0.3718 0.5886], Epochs since improvement 0
 11%|█         | 53/500 [32:54<4:28:37, 36.06s/it] 11%|█         | 54/500 [33:41<4:52:23, 39.34s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.84E+06, Train scatter: [0.3121 0.0877 0.3592 0.5642]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3245 0.0892 0.356  0.5619], Lowest was [0.3245 0.0892 0.3478 0.5619]
Median for last 10 epochs: [0.3682 0.0947 0.3698 0.5788], Epochs since improvement 0
 11%|█         | 55/500 [34:08<4:25:18, 35.77s/it] 11%|█         | 56/500 [34:55<4:49:50, 39.17s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.73E+06, Train scatter: [0.3194 0.0844 0.333  0.5493]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3274 0.0875 0.3362 0.5548], Lowest was [0.3245 0.0875 0.3362 0.5548]
Median for last 10 epochs: [0.3388 0.0944 0.356  0.5787], Epochs since improvement 0
 11%|█▏        | 57/500 [35:23<4:23:57, 35.75s/it] 12%|█▏        | 58/500 [36:11<4:50:07, 39.38s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.70E+06, Train scatter: [0.2736 0.0826 0.3402 0.537 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2839 0.0847 0.3471 0.5404], Lowest was [0.2839 0.0847 0.3362 0.5404]
Median for last 10 epochs: [0.3274 0.0892 0.3478 0.5619], Epochs since improvement 0
 12%|█▏        | 59/500 [36:38<4:23:01, 35.79s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.33E+06, Train scatter: [0.2706 0.0797 0.3191 0.5267]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2837 0.0823 0.3304 0.5292], Lowest was [0.2837 0.0823 0.3304 0.5292]
Median for last 10 epochs: [0.3245 0.0875 0.3471 0.5548], Epochs since improvement 0
 12%|█▏        | 60/500 [37:30<4:58:03, 40.65s/it] 12%|█▏        | 61/500 [37:58<4:29:26, 36.83s/it] 12%|█▏        | 62/500 [38:45<4:49:14, 39.62s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.03E+06, Train scatter: [0.3483 0.0837 0.3218 0.5461]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3524 0.0848 0.3288 0.5496], Lowest was [0.2837 0.0823 0.3288 0.5292]
Median for last 10 epochs: [0.3245 0.0848 0.3362 0.5496], Epochs since improvement 0
 13%|█▎        | 63/500 [39:12<4:22:27, 36.04s/it] 13%|█▎        | 64/500 [39:59<4:45:38, 39.31s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.02E+06, Train scatter: [0.2704 0.0763 0.322  0.529 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2763 0.0773 0.328  0.5289], Lowest was [0.2763 0.0773 0.328  0.5289]
Median for last 10 epochs: [0.2839 0.0847 0.3304 0.5404], Epochs since improvement 0
 13%|█▎        | 65/500 [40:27<4:19:05, 35.74s/it] 13%|█▎        | 66/500 [41:13<4:41:00, 38.85s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.82E+06, Train scatter: [0.2852 0.0759 0.308  0.5244]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2933 0.0773 0.3143 0.5203], Lowest was [0.2763 0.0773 0.3143 0.5203]
Median for last 10 epochs: [0.2839 0.0823 0.3288 0.5292], Epochs since improvement 0
 13%|█▎        | 67/500 [41:40<4:16:02, 35.48s/it] 14%|█▎        | 68/500 [42:27<4:38:54, 38.74s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.68E+06, Train scatter: [0.2615 0.0736 0.3133 0.5102]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2693 0.0748 0.3186 0.5097], Lowest was [0.2693 0.0748 0.3143 0.5097]
Median for last 10 epochs: [0.2837 0.0773 0.328  0.5289], Epochs since improvement 0
 14%|█▍        | 69/500 [42:54<4:14:11, 35.39s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.57E+06, Train scatter: [0.2918 0.0754 0.3132 0.5223]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3033 0.0767 0.3264 0.5257], Lowest was [0.2693 0.0748 0.3143 0.5097]
Median for last 10 epochs: [0.2933 0.0773 0.3264 0.5257], Epochs since improvement 2
 14%|█▍        | 70/500 [43:46<4:49:45, 40.43s/it] 14%|█▍        | 71/500 [44:14<4:21:04, 36.51s/it] 14%|█▍        | 72/500 [45:00<4:41:27, 39.46s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.49E+06, Train scatter: [0.2639 0.0727 0.3051 0.5206]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2729 0.075  0.3151 0.5207], Lowest was [0.2693 0.0748 0.3143 0.5097]
Median for last 10 epochs: [0.2763 0.0767 0.3186 0.5207], Epochs since improvement 4
 15%|█▍        | 73/500 [45:28<4:15:24, 35.89s/it] 15%|█▍        | 74/500 [46:14<4:38:09, 39.18s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 1.36E+06, Train scatter: [0.2637 0.071  0.3076 0.4995]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2687 0.0721 0.3145 0.5002], Lowest was [0.2687 0.0721 0.3143 0.5002]
Median for last 10 epochs: [0.2729 0.075  0.3151 0.5203], Epochs since improvement 0
 15%|█▌        | 75/500 [46:42<4:12:41, 35.67s/it] 15%|█▌        | 76/500 [47:28<4:34:35, 38.86s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 1.25E+06, Train scatter: [0.2447 0.0705 0.2898 0.5011]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2567 0.0726 0.3012 0.5047], Lowest was [0.2567 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.2693 0.0748 0.3151 0.5097], Epochs since improvement 0
 15%|█▌        | 77/500 [47:56<4:10:19, 35.51s/it] 16%|█▌        | 78/500 [48:43<4:33:39, 38.91s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 1.21E+06, Train scatter: [0.2451 0.0714 0.2919 0.5057]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2538 0.0736 0.303  0.5102], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.2687 0.0736 0.3145 0.5102], Epochs since improvement 0
 16%|█▌        | 79/500 [49:10<4:08:40, 35.44s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 1.52E+06, Train scatter: [0.4645 0.0748 0.4105 0.5727]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4439 0.076  0.4091 0.5698], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.2687 0.0736 0.3145 0.5102], Epochs since improvement 2
 16%|█▌        | 80/500 [50:02<4:43:21, 40.48s/it] 16%|█▌        | 81/500 [50:30<4:15:20, 36.56s/it] 16%|█▋        | 82/500 [51:16<4:34:31, 39.41s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 8.33E+06, Train scatter: [0.9316 0.1694 0.544  0.9908]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9161 0.1656 0.5354 0.9805], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.2687 0.0736 0.3145 0.5102], Epochs since improvement 4
 17%|█▋        | 83/500 [51:44<4:09:21, 35.88s/it] 17%|█▋        | 84/500 [52:30<4:30:24, 39.00s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 5.54E+06, Train scatter: [0.9305 0.1658 0.544  0.9935]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.915  0.1621 0.5354 0.9833], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.4439 0.076  0.4091 0.5698], Epochs since improvement 6
 17%|█▋        | 85/500 [52:57<4:05:46, 35.53s/it] 17%|█▋        | 86/500 [53:44<4:28:53, 38.97s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 4.29E+06, Train scatter: [0.9284 0.1656 0.544  0.9908]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.913  0.1619 0.5354 0.9805], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.913  0.1619 0.5354 0.9805], Epochs since improvement 8
 17%|█▋        | 87/500 [54:12<4:04:20, 35.50s/it] 18%|█▊        | 88/500 [54:58<4:26:24, 38.80s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 3.51E+06, Train scatter: [0.9271 0.1651 0.544  0.9749]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9117 0.1615 0.5354 0.9651], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.913  0.1619 0.5354 0.9805], Epochs since improvement 10
 18%|█▊        | 89/500 [55:26<4:02:46, 35.44s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.97E+06, Train scatter: [0.9257 0.1643 0.5439 0.9242]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9103 0.1607 0.5354 0.9151], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.913  0.1619 0.5354 0.9805], Epochs since improvement 12
 18%|█▊        | 90/500 [56:18<4:36:21, 40.44s/it] 18%|█▊        | 91/500 [56:45<4:09:04, 36.54s/it] 18%|█▊        | 92/500 [57:31<4:28:03, 39.42s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.66E+06, Train scatter: [0.9241 0.1607 0.5439 0.9892]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9088 0.1573 0.5353 0.979 ], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.9117 0.1615 0.5354 0.979 ], Epochs since improvement 14
 19%|█▊        | 93/500 [57:59<4:03:32, 35.90s/it] 19%|█▉        | 94/500 [58:46<4:25:00, 39.16s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.21E+06, Train scatter: [0.9228 0.1598 0.5439 0.9886]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9074 0.1564 0.5353 0.9784], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.9103 0.1607 0.5354 0.9784], Epochs since improvement 16
 19%|█▉        | 95/500 [59:13<4:00:21, 35.61s/it] 19%|█▉        | 96/500 [1:00:01<4:23:39, 39.16s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 1.89E+06, Train scatter: [0.9211 0.1587 0.5439 0.9881]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9058 0.1554 0.5353 0.9779], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.9088 0.1573 0.5353 0.9779], Epochs since improvement 18
 19%|█▉        | 97/500 [1:00:28<3:59:10, 35.61s/it] 20%|█▉        | 98/500 [1:01:14<4:19:46, 38.77s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 1.56E+06, Train scatter: [0.9191 0.1576 0.5439 0.9875]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9039 0.1542 0.5353 0.9773], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.9074 0.1564 0.5353 0.9779], Epochs since improvement 20
 20%|█▉        | 99/500 [1:01:42<3:56:42, 35.42s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 1.27E+06, Train scatter: [0.9168 0.1562 0.5439 0.9869]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9017 0.1529 0.5353 0.9767], Lowest was [0.2538 0.0721 0.3012 0.5002]
Median for last 10 epochs: [0.9058 0.1554 0.5353 0.9779], Epochs since improvement 22
 20%|█▉        | 99/500 [1:02:35<4:13:30, 37.93s/it]
Exited after 100 epochs due to early stopping
3755.15 seconds spent training, 7.510 seconds per epoch. Processed 9272 trees per second
[0.9016459  0.15293293 0.53525716 0.97671586]
{'epoch_exit': 99, 'scatter_m_star': 0.9016459, 'lowest_m_star': 0.25380284, 'last20_m_star': 0.90954125, 'last10_m_star': 0.90580124, 'scatter_v_disk': 0.15293293, 'lowest_v_disk': 0.0721344, 'last20_v_disk': 0.15900645, 'last10_v_disk': 0.15537208, 'scatter_m_cold': 0.53525716, 'lowest_m_cold': 0.30123085, 'last20_m_cold': 0.53533304, 'last10_m_cold': 0.53528816, 'scatter_sfr_100': 0.97671586, 'lowest_sfr_100': 0.50019616, 'last20_sfr_100': 0.9781581, 'last10_sfr_100': 0.9778749}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_tgzxsu
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:48<6:40:32, 48.16s/it]  0%|          | 2/500 [01:59<8:31:31, 61.63s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.47E+07, Train scatter: [0.9352 0.1517 0.5442 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1478 0.5356 0.9851], Lowest was [0.9196 0.1478 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1478 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:46<7:35:26, 54.98s/it]  1%|          | 4/500 [03:57<8:27:51, 61.43s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.65E+07, Train scatter: [0.9343 0.1066 0.5441 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9187 0.105  0.5355 0.9848], Lowest was [0.9187 0.105  0.5355 0.9848]
Median for last 10 epochs: [0.9187 0.105  0.5355 0.9848], Epochs since improvement 0
  1%|          | 5/500 [04:44<7:44:14, 56.27s/it]  1%|          | 6/500 [05:55<8:24:45, 61.31s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.17E+07, Train scatter: [0.9298 0.1357 0.5441 0.9923]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9148 0.1323 0.5355 0.9821], Lowest was [0.9148 0.105  0.5355 0.9821]
Median for last 10 epochs: [0.9148 0.105  0.5355 0.9821], Epochs since improvement 0
  1%|▏         | 7/500 [06:43<7:45:55, 56.70s/it]  2%|▏         | 8/500 [07:54<8:22:53, 61.33s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.10E+06, Train scatter: [0.716  0.0991 0.544  0.6391]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.706  0.0986 0.5354 0.6356], Lowest was [0.706  0.0986 0.5354 0.6356]
Median for last 10 epochs: [0.8104 0.1018 0.5355 0.8089], Epochs since improvement 0
  2%|▏         | 9/500 [08:41<7:45:45, 56.92s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 5.93E+06, Train scatter: [0.5484 0.0904 0.544  0.5745]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5422 0.0899 0.5354 0.5684], Lowest was [0.5422 0.0899 0.5354 0.5684]
Median for last 10 epochs: [0.706  0.0986 0.5354 0.6356], Epochs since improvement 0
  2%|▏         | 10/500 [09:59<8:38:03, 63.44s/it]  2%|▏         | 11/500 [10:46<7:56:37, 58.48s/it]  2%|▏         | 12/500 [11:57<8:26:21, 62.26s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 5.15E+06, Train scatter: [0.4601 0.0824 0.544  0.5406]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4559 0.0823 0.5354 0.5352], Lowest was [0.4559 0.0823 0.5354 0.5352]
Median for last 10 epochs: [0.706  0.0986 0.5354 0.6356], Epochs since improvement 0
  3%|▎         | 13/500 [12:44<7:48:24, 57.71s/it]  3%|▎         | 14/500 [13:56<8:21:49, 61.95s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 4.66E+06, Train scatter: [0.2731 0.0773 0.544  0.5279]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2795 0.0777 0.5355 0.5222], Lowest was [0.2795 0.0777 0.5354 0.5222]
Median for last 10 epochs: [0.5422 0.0899 0.5354 0.5684], Epochs since improvement 0
  3%|▎         | 15/500 [14:43<7:45:05, 57.54s/it]  3%|▎         | 16/500 [15:55<8:18:54, 61.85s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.58E+06, Train scatter: [0.2538 0.0763 0.544  0.5248]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2579 0.0764 0.5354 0.516 ], Lowest was [0.2579 0.0764 0.5354 0.516 ]
Median for last 10 epochs: [0.4559 0.0823 0.5354 0.5352], Epochs since improvement 0
  3%|▎         | 17/500 [16:43<7:43:06, 57.53s/it]  4%|▎         | 18/500 [17:55<8:17:52, 61.98s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.46E+06, Train scatter: [0.2353 0.0746 0.544  0.5198]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2375 0.0742 0.5354 0.5107], Lowest was [0.2375 0.0742 0.5354 0.5107]
Median for last 10 epochs: [0.2795 0.0777 0.5354 0.5222], Epochs since improvement 0
  4%|▍         | 19/500 [18:43<7:41:59, 57.63s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.99E+06, Train scatter: [0.3392 0.0795 0.544  0.5575]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3437 0.0803 0.5354 0.5589], Lowest was [0.2375 0.0742 0.5354 0.5107]
Median for last 10 epochs: [0.2795 0.0777 0.5354 0.5222], Epochs since improvement 2
  4%|▍         | 20/500 [20:01<8:31:44, 63.97s/it]  4%|▍         | 21/500 [20:49<7:50:20, 58.92s/it]  4%|▍         | 22/500 [22:00<8:19:34, 62.71s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.79E+06, Train scatter: [0.2191 0.0717 0.5439 0.5147]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2205 0.0717 0.5353 0.5113], Lowest was [0.2205 0.0717 0.5353 0.5107]
Median for last 10 epochs: [0.2579 0.0764 0.5354 0.516 ], Epochs since improvement 0
  5%|▍         | 23/500 [22:47<7:41:39, 58.07s/it]  5%|▍         | 24/500 [23:59<8:12:05, 62.03s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.49E+06, Train scatter: [0.2551 0.0724 0.5439 0.5337]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2591 0.0723 0.5353 0.533 ], Lowest was [0.2205 0.0717 0.5353 0.5107]
Median for last 10 epochs: [0.2579 0.0742 0.5354 0.516 ], Epochs since improvement 0
  5%|▌         | 25/500 [24:46<7:35:29, 57.54s/it]  5%|▌         | 26/500 [25:57<8:07:48, 61.75s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.47E+06, Train scatter: [0.3173 0.0748 0.5439 0.5289]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3201 0.0739 0.5353 0.5272], Lowest was [0.2205 0.0717 0.5353 0.5107]
Median for last 10 epochs: [0.2591 0.0739 0.5353 0.5272], Epochs since improvement 2
  5%|▌         | 27/500 [26:44<7:32:09, 57.36s/it]  6%|▌         | 28/500 [27:56<8:04:23, 61.58s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.41E+06, Train scatter: [0.2346 0.0705 0.5439 0.5032]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2326 0.07   0.5353 0.4986], Lowest was [0.2205 0.07   0.5353 0.4986]
Median for last 10 epochs: [0.2591 0.0723 0.5353 0.5272], Epochs since improvement 0
  6%|▌         | 29/500 [28:43<7:29:19, 57.24s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.41E+06, Train scatter: [0.214  0.0752 0.5439 0.5056]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2177 0.075  0.5353 0.5007], Lowest was [0.2177 0.07   0.5353 0.4986]
Median for last 10 epochs: [0.2326 0.0723 0.5353 0.5113], Epochs since improvement 0
  6%|▌         | 30/500 [30:01<8:17:56, 63.57s/it]  6%|▌         | 31/500 [30:48<7:38:22, 58.64s/it]  6%|▋         | 32/500 [32:00<8:07:38, 62.52s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.40E+06, Train scatter: [0.3132 0.0859 0.5439 0.5665]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3197 0.0864 0.5353 0.5674], Lowest was [0.2177 0.07   0.5353 0.4986]
Median for last 10 epochs: [0.2591 0.0739 0.5353 0.5272], Epochs since improvement 0
  7%|▋         | 33/500 [32:47<7:30:48, 57.92s/it]  7%|▋         | 34/500 [33:59<8:01:35, 62.01s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.13E+06, Train scatter: [0.3899 0.0774 0.5439 0.5065]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.381  0.0761 0.5353 0.5   ], Lowest was [0.2177 0.07   0.5353 0.4986]
Median for last 10 epochs: [0.3197 0.075  0.5353 0.5007], Epochs since improvement 2
  7%|▋         | 35/500 [34:46<7:25:40, 57.51s/it]  7%|▋         | 36/500 [35:57<7:57:05, 61.69s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.14E+06, Train scatter: [0.8582 0.077  0.544  0.7785]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8419 0.0767 0.5354 0.777 ], Lowest was [0.2177 0.07   0.5353 0.4986]
Median for last 10 epochs: [0.3197 0.0761 0.5353 0.5007], Epochs since improvement 4
  7%|▋         | 37/500 [36:44<7:22:44, 57.37s/it]  8%|▊         | 38/500 [37:56<7:55:42, 61.78s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.97E+06, Train scatter: [0.3684 0.0834 0.5439 0.5088]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3632 0.0823 0.5353 0.5035], Lowest was [0.2177 0.07   0.5353 0.4986]
Median for last 10 epochs: [0.3632 0.0767 0.5353 0.5035], Epochs since improvement 6
  8%|▊         | 39/500 [38:44<7:20:57, 57.39s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.91E+06, Train scatter: [0.3534 0.074  0.5438 0.5556]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3497 0.0736 0.5353 0.553 ], Lowest was [0.2177 0.07   0.5353 0.4986]
Median for last 10 epochs: [0.3632 0.0767 0.5353 0.553 ], Epochs since improvement 0
  8%|▊         | 40/500 [40:02<8:08:49, 63.76s/it]  8%|▊         | 41/500 [40:49<7:29:41, 58.78s/it]  8%|▊         | 42/500 [42:01<7:57:24, 62.54s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.80E+06, Train scatter: [0.4    0.0795 0.5439 0.5374]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4022 0.0784 0.5353 0.5324], Lowest was [0.2177 0.07   0.5353 0.4986]
Median for last 10 epochs: [0.381  0.0767 0.5353 0.5324], Epochs since improvement 2
  9%|▊         | 43/500 [42:48<7:21:08, 57.92s/it]  9%|▉         | 44/500 [44:00<7:52:19, 62.15s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.79E+06, Train scatter: [0.3729 0.0732 0.5438 0.561 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3723 0.0727 0.5352 0.5623], Lowest was [0.2177 0.07   0.5352 0.4986]
Median for last 10 epochs: [0.3723 0.0767 0.5353 0.553 ], Epochs since improvement 0
  9%|▉         | 45/500 [44:47<7:17:06, 57.64s/it]  9%|▉         | 46/500 [45:59<7:48:33, 61.92s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.77E+06, Train scatter: [0.4667 0.0791 0.5438 0.5064]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4562 0.0779 0.5352 0.4995], Lowest was [0.2177 0.07   0.5352 0.4986]
Median for last 10 epochs: [0.3723 0.0779 0.5353 0.5324], Epochs since improvement 0
  9%|▉         | 47/500 [46:46<7:14:12, 57.51s/it] 10%|▉         | 48/500 [47:58<7:45:02, 61.73s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.76E+06, Train scatter: [0.3607 0.0748 0.5438 0.5072]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3545 0.074  0.5352 0.5038], Lowest was [0.2177 0.07   0.5352 0.4986]
Median for last 10 epochs: [0.3723 0.074  0.5352 0.5324], Epochs since improvement 2
 10%|▉         | 49/500 [48:45<7:11:10, 57.36s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.76E+06, Train scatter: [0.5722 0.118  0.5438 0.9712]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5593 0.115  0.5352 0.9607], Lowest was [0.2177 0.07   0.5352 0.4986]
Median for last 10 epochs: [0.4022 0.0779 0.5352 0.5324], Epochs since improvement 4
 10%|█         | 50/500 [50:03<7:56:23, 63.52s/it] 10%|█         | 51/500 [50:50<7:18:34, 58.61s/it] 10%|█         | 52/500 [52:02<7:47:19, 62.59s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 2.74E+06, Train scatter: [0.4158 0.0896 0.5436 0.5362]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4083 0.0886 0.5351 0.537 ], Lowest was [0.2177 0.07   0.5351 0.4986]
Median for last 10 epochs: [0.4083 0.0779 0.5352 0.537 ], Epochs since improvement 0
 11%|█         | 53/500 [52:49<7:11:33, 57.93s/it] 11%|█         | 54/500 [54:00<7:41:04, 62.03s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.71E+06, Train scatter: [0.4271 0.0907 0.5437 0.6025]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4218 0.0901 0.5351 0.5985], Lowest was [0.2177 0.07   0.5351 0.4986]
Median for last 10 epochs: [0.4218 0.0886 0.5352 0.537 ], Epochs since improvement 2
 11%|█         | 55/500 [54:48<7:07:22, 57.62s/it] 11%|█         | 56/500 [56:00<7:38:19, 61.93s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.68E+06, Train scatter: [0.4683 0.0788 0.5428 0.5414]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4564 0.0782 0.5343 0.5372], Lowest was [0.2177 0.07   0.5343 0.4986]
Median for last 10 epochs: [0.4218 0.0886 0.5351 0.5372], Epochs since improvement 0
 11%|█▏        | 57/500 [56:47<7:04:28, 57.49s/it] 12%|█▏        | 58/500 [57:59<7:35:37, 61.85s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.63E+06, Train scatter: [0.4036 0.0739 0.5343 0.505 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.42   0.0734 0.526  0.5019], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.4218 0.0886 0.5351 0.5372], Epochs since improvement 0
 12%|█▏        | 59/500 [58:46<7:02:32, 57.49s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 5.72E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.4218 0.0886 0.5351 0.5372], Epochs since improvement 2
 12%|█▏        | 60/500 [1:00:04<7:46:55, 63.67s/it] 12%|█▏        | 61/500 [1:00:51<7:09:17, 58.67s/it] 12%|█▏        | 62/500 [1:02:03<7:37:49, 62.72s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 5.55E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.4564 0.0901 0.5351 0.5985], Epochs since improvement 4
 13%|█▎        | 63/500 [1:02:51<7:02:54, 58.07s/it] 13%|█▎        | 64/500 [1:04:01<7:29:21, 61.84s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 5.22E+06, Train scatter: [0.9352 0.1727 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1689 0.5355 0.9851], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.9196 0.1689 0.5355 0.985 ], Epochs since improvement 6
 13%|█▎        | 65/500 [1:04:48<6:56:11, 57.41s/it] 13%|█▎        | 66/500 [1:06:00<7:25:41, 61.62s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 5.04E+06, Train scatter: [0.9352 0.1726 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1688 0.5355 0.9851], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.9196 0.1689 0.5355 0.985 ], Epochs since improvement 8
 13%|█▎        | 67/500 [1:06:47<6:53:07, 57.25s/it] 14%|█▎        | 68/500 [1:07:59<7:23:13, 61.56s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 4.64E+06, Train scatter: [0.9352 0.1723 0.5441 0.9957]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1685 0.5355 0.9853], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.9196 0.1689 0.5355 0.9851], Epochs since improvement 10
 14%|█▍        | 69/500 [1:08:46<6:51:02, 57.22s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.83E+06, Train scatter: [0.9352 0.171  0.5441 0.996 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1672 0.5355 0.9856], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.9196 0.1688 0.5355 0.9851], Epochs since improvement 12
 14%|█▍        | 70/500 [1:10:04<7:36:03, 63.64s/it] 14%|█▍        | 71/500 [1:10:51<6:59:53, 58.73s/it] 14%|█▍        | 72/500 [1:12:03<7:27:04, 62.67s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.46E+06, Train scatter: [0.9351 0.1623 0.5441 0.9979]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1588 0.5355 0.9874], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.9196 0.1685 0.5355 0.9853], Epochs since improvement 14
 15%|█▍        | 73/500 [1:12:50<6:52:33, 57.97s/it] 15%|█▍        | 74/500 [1:14:02<7:21:25, 62.17s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.16E+06, Train scatter: [0.9349 0.135  0.5441 0.9989]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9193 0.1327 0.5355 0.9884], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.9196 0.1672 0.5355 0.9856], Epochs since improvement 16
 15%|█▌        | 75/500 [1:14:49<6:48:24, 57.66s/it] 15%|█▌        | 76/500 [1:16:01<7:17:19, 61.89s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.45E+06, Train scatter: [0.934  0.1134 0.5441 0.9996]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9185 0.1118 0.5355 0.9891], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.9195 0.1588 0.5355 0.9874], Epochs since improvement 18
 15%|█▌        | 77/500 [1:16:48<6:45:19, 57.49s/it] 16%|█▌        | 78/500 [1:17:59<7:11:19, 61.33s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.12E+06, Train scatter: [0.9325 0.1165 0.5441 1.0003]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.917  0.1154 0.5355 0.9898], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.9193 0.1327 0.5355 0.9884], Epochs since improvement 20
 16%|█▌        | 79/500 [1:18:46<6:40:14, 57.04s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 1.79E+06, Train scatter: [0.9292 0.1156 0.5441 1.0006]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9138 0.1144 0.5355 0.9901], Lowest was [0.2177 0.07   0.526  0.4986]
Median for last 10 epochs: [0.9185 0.1154 0.5355 0.9891], Epochs since improvement 22
 16%|█▌        | 79/500 [1:20:04<7:06:44, 60.82s/it]
Exited after 80 epochs due to early stopping
4804.62 seconds spent training, 9.609 seconds per epoch. Processed 7247 trees per second
[0.913801   0.11437365 0.53549224 0.9900393 ]
{'epoch_exit': 79, 'scatter_m_star': 0.913801, 'lowest_m_star': 0.2177238, 'last20_m_star': 0.9195395, 'last10_m_star': 0.91845465, 'scatter_v_disk': 0.11437365, 'lowest_v_disk': 0.06996774, 'last20_v_disk': 0.16303994, 'last10_v_disk': 0.115380436, 'scatter_m_cold': 0.53549224, 'lowest_m_cold': 0.52599245, 'last20_m_cold': 0.53550386, 'last10_m_cold': 0.53553665, 'scatter_sfr_100': 0.9900393, 'lowest_sfr_100': 0.49855292, 'last20_sfr_100': 0.9865291, 'last10_sfr_100': 0.98905843}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_zmrlci
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:41<5:48:38, 41.92s/it]  0%|          | 2/500 [01:45<7:32:56, 54.57s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.08E+07, Train scatter: [0.9352 0.1715 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1684 0.5355 0.9851], Lowest was [0.9196 0.1684 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1684 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:25<6:38:45, 48.14s/it]  1%|          | 4/500 [03:29<7:29:27, 54.37s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.32E+07, Train scatter: [0.9352 0.1616 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1581 0.5355 0.9851], Lowest was [0.9196 0.1581 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1581 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:10<6:47:12, 49.36s/it]  1%|          | 6/500 [05:13<7:25:57, 54.17s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.86E+07, Train scatter: [0.9351 0.1387 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1353 0.5355 0.9851], Lowest was [0.9195 0.1353 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1353 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [05:54<6:48:18, 49.69s/it]  2%|▏         | 8/500 [06:57<7:23:44, 54.11s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.49E+07, Train scatter: [0.933  0.1129 0.5441 0.955 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9175 0.1119 0.5355 0.9475], Lowest was [0.9175 0.1119 0.5355 0.9475]
Median for last 10 epochs: [0.9185 0.1236 0.5355 0.9663], Epochs since improvement 0
  2%|▏         | 9/500 [07:38<6:47:57, 49.85s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 1.14E+07, Train scatter: [0.7811 0.1036 0.5441 0.6522]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7713 0.1036 0.5355 0.6493], Lowest was [0.7713 0.1036 0.5355 0.6493]
Median for last 10 epochs: [0.9175 0.1119 0.5355 0.9475], Epochs since improvement 0
  2%|▏         | 10/500 [08:49<7:41:18, 56.49s/it]  2%|▏         | 11/500 [09:30<7:01:29, 51.72s/it]  2%|▏         | 12/500 [10:35<7:32:13, 55.60s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.34E+06, Train scatter: [0.6856 0.0975 0.5441 0.6084]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.6774 0.0978 0.5355 0.6036], Lowest was [0.6774 0.0978 0.5355 0.6036]
Median for last 10 epochs: [0.9175 0.1119 0.5355 0.9475], Epochs since improvement 0
  3%|▎         | 13/500 [11:15<6:54:13, 51.03s/it]  3%|▎         | 14/500 [12:19<7:25:28, 55.00s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.78E+06, Train scatter: [0.5461 0.0932 0.5441 0.5748]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5397 0.0933 0.5355 0.5731], Lowest was [0.5397 0.0933 0.5355 0.5731]
Median for last 10 epochs: [0.7713 0.1036 0.5355 0.6493], Epochs since improvement 0
  3%|▎         | 15/500 [13:00<6:49:54, 50.71s/it]  3%|▎         | 16/500 [14:03<7:20:09, 54.56s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.15E+06, Train scatter: [0.5038 0.0915 0.5441 0.5701]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4957 0.091  0.5355 0.5662], Lowest was [0.4957 0.091  0.5355 0.5662]
Median for last 10 epochs: [0.6774 0.0978 0.5355 0.6036], Epochs since improvement 0
  3%|▎         | 17/500 [14:44<6:46:04, 50.44s/it]  4%|▎         | 18/500 [15:48<7:17:22, 54.44s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 5.73E+06, Train scatter: [0.3348 0.0852 0.544  0.5543]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3417 0.0859 0.5354 0.5499], Lowest was [0.3417 0.0859 0.5354 0.5499]
Median for last 10 epochs: [0.5397 0.0933 0.5355 0.5731], Epochs since improvement 0
  4%|▍         | 19/500 [16:29<6:43:54, 50.38s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.34E+06, Train scatter: [0.2816 0.0915 0.5439 0.5625]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2923 0.0907 0.5353 0.5559], Lowest was [0.2923 0.0859 0.5353 0.5499]
Median for last 10 epochs: [0.4957 0.091  0.5355 0.5662], Epochs since improvement 0
  4%|▍         | 20/500 [17:40<7:32:02, 56.50s/it]  4%|▍         | 21/500 [18:21<6:53:57, 51.85s/it]  4%|▍         | 22/500 [19:25<7:23:30, 55.67s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.13E+06, Train scatter: [0.3043 0.0828 0.5439 0.5251]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3091 0.0827 0.5354 0.5214], Lowest was [0.2923 0.0827 0.5353 0.5214]
Median for last 10 epochs: [0.3417 0.0907 0.5354 0.5559], Epochs since improvement 0
  5%|▍         | 23/500 [20:06<6:47:05, 51.21s/it]  5%|▍         | 24/500 [21:11<7:19:12, 55.36s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.88E+06, Train scatter: [0.4031 0.0821 0.544  0.5675]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4061 0.0813 0.5354 0.5695], Lowest was [0.2923 0.0813 0.5353 0.5214]
Median for last 10 epochs: [0.3417 0.0859 0.5354 0.5559], Epochs since improvement 0
  5%|▌         | 25/500 [21:52<6:44:04, 51.04s/it]  5%|▌         | 26/500 [22:57<7:15:15, 55.10s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.78E+06, Train scatter: [0.3933 0.08   0.544  0.5536]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3984 0.08   0.5354 0.5558], Lowest was [0.2923 0.08   0.5353 0.5214]
Median for last 10 epochs: [0.3417 0.0827 0.5354 0.5558], Epochs since improvement 0
  5%|▌         | 27/500 [23:37<6:40:06, 50.75s/it]  6%|▌         | 28/500 [24:42<7:13:06, 55.06s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.68E+06, Train scatter: [0.4479 0.0792 0.544  0.6031]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.453  0.0792 0.5354 0.6091], Lowest was [0.2923 0.0792 0.5353 0.5214]
Median for last 10 epochs: [0.3984 0.0813 0.5354 0.5559], Epochs since improvement 0
  6%|▌         | 29/500 [25:23<6:38:23, 50.75s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.76E+06, Train scatter: [0.24   0.0774 0.5439 0.5144]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2451 0.0774 0.5353 0.5155], Lowest was [0.2451 0.0774 0.5353 0.5155]
Median for last 10 epochs: [0.3984 0.08   0.5354 0.5558], Epochs since improvement 0
  6%|▌         | 30/500 [26:34<7:23:41, 56.64s/it]  6%|▌         | 31/500 [27:14<6:45:12, 51.84s/it]  6%|▋         | 32/500 [28:18<7:12:32, 55.45s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.58E+06, Train scatter: [0.2789 0.075  0.5439 0.5267]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2868 0.0755 0.5353 0.5188], Lowest was [0.2451 0.0755 0.5353 0.5155]
Median for last 10 epochs: [0.3984 0.0792 0.5354 0.5558], Epochs since improvement 0
  7%|▋         | 33/500 [28:59<6:37:27, 51.06s/it]  7%|▋         | 34/500 [30:03<7:07:03, 54.99s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 4.56E+06, Train scatter: [0.2951 0.0743 0.5438 0.5192]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3    0.0747 0.5353 0.5212], Lowest was [0.2451 0.0747 0.5353 0.5155]
Median for last 10 epochs: [0.3    0.0774 0.5353 0.5212], Epochs since improvement 0
  7%|▋         | 35/500 [30:44<6:33:40, 50.80s/it]  7%|▋         | 36/500 [31:48<7:02:26, 54.63s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 4.53E+06, Train scatter: [0.3335 0.0722 0.5438 0.5517]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3392 0.0725 0.5352 0.5471], Lowest was [0.2451 0.0725 0.5352 0.5155]
Median for last 10 epochs: [0.3    0.0755 0.5353 0.5212], Epochs since improvement 0
  7%|▋         | 37/500 [32:29<6:29:45, 50.51s/it]  8%|▊         | 38/500 [33:32<7:00:03, 54.55s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 4.50E+06, Train scatter: [0.2327 0.0714 0.5437 0.509 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2353 0.0719 0.5351 0.5106], Lowest was [0.2353 0.0719 0.5351 0.5106]
Median for last 10 epochs: [0.2868 0.0747 0.5353 0.5188], Epochs since improvement 0
  8%|▊         | 39/500 [34:13<6:27:02, 50.37s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 4.51E+06, Train scatter: [0.2334 0.0711 0.5437 0.5479]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2414 0.0716 0.5351 0.5472], Lowest was [0.2353 0.0716 0.5351 0.5106]
Median for last 10 epochs: [0.2868 0.0725 0.5352 0.5212], Epochs since improvement 0
  8%|▊         | 40/500 [35:23<7:10:39, 56.17s/it]  8%|▊         | 41/500 [36:03<6:34:00, 51.50s/it]  8%|▊         | 42/500 [37:08<7:02:09, 55.31s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 4.49E+06, Train scatter: [0.4278 0.0868 0.5436 0.5376]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4211 0.0856 0.535  0.5346], Lowest was [0.2353 0.0716 0.535  0.5106]
Median for last 10 epochs: [0.3    0.0725 0.5351 0.5346], Epochs since improvement 0
  9%|▊         | 43/500 [37:48<6:27:45, 50.91s/it]  9%|▉         | 44/500 [38:52<6:56:16, 54.77s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.26E+06, Train scatter: [0.2215 0.0716 0.5436 0.5054]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2806 0.0706 0.5351 0.4969], Lowest was [0.2353 0.0706 0.535  0.4969]
Median for last 10 epochs: [0.2806 0.0719 0.5351 0.5346], Epochs since improvement 0
  9%|▉         | 45/500 [39:33<6:23:16, 50.54s/it]  9%|▉         | 46/500 [40:37<6:54:39, 54.80s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.10E+06, Train scatter: [0.3047 0.0761 0.5437 0.5899]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4909 0.0759 0.5351 0.5981], Lowest was [0.2353 0.0706 0.535  0.4969]
Median for last 10 epochs: [0.2806 0.0719 0.5351 0.5346], Epochs since improvement 2
  9%|▉         | 47/500 [41:18<6:22:05, 50.61s/it] 10%|▉         | 48/500 [42:22<6:51:34, 54.63s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 4.04E+06, Train scatter: [0.279  0.0732 0.5436 0.513 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.439  0.0728 0.535  0.5049], Lowest was [0.2353 0.0706 0.535  0.4969]
Median for last 10 epochs: [0.4211 0.0728 0.5351 0.5346], Epochs since improvement 0
 10%|▉         | 49/500 [43:03<6:19:19, 50.46s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 4.01E+06, Train scatter: [0.226  0.0713 0.5436 0.503 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3414 0.0712 0.535  0.5012], Lowest was [0.2353 0.0706 0.535  0.4969]
Median for last 10 epochs: [0.4211 0.0728 0.535  0.5049], Epochs since improvement 2
 10%|█         | 50/500 [44:13<7:02:08, 56.29s/it] 10%|█         | 51/500 [44:54<6:26:15, 51.61s/it] 10%|█         | 52/500 [45:58<6:53:43, 55.41s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.99E+06, Train scatter: [0.2769 0.0685 0.5435 0.4963]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3143 0.0678 0.535  0.4935], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.3414 0.0712 0.535  0.5012], Epochs since improvement 0
 11%|█         | 53/500 [46:39<6:20:22, 51.06s/it] 11%|█         | 54/500 [47:43<6:49:10, 55.05s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 9.08E+06, Train scatter: [0.9309 0.1744 0.5441 0.9951]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9148 0.1708 0.5355 0.9848], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.439  0.0728 0.535  0.5049], Epochs since improvement 2
 11%|█         | 55/500 [48:24<6:17:13, 50.86s/it] 11%|█         | 56/500 [49:29<6:46:42, 54.96s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 5.91E+06, Train scatter: [0.914  0.1595 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8991 0.1571 0.5355 0.9851], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.439  0.0728 0.535  0.5049], Epochs since improvement 4
 11%|█▏        | 57/500 [50:10<6:14:20, 50.70s/it] 12%|█▏        | 58/500 [51:14<6:43:29, 54.77s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 5.09E+06, Train scatter: [0.8708 0.1555 0.5441 0.9957]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.8582 0.154  0.5355 0.9852], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.8582 0.154  0.5355 0.9848], Epochs since improvement 6
 12%|█▏        | 59/500 [51:55<6:11:54, 50.60s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 4.46E+06, Train scatter: [0.7568 0.1328 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7523 0.1292 0.5355 0.9851], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.8582 0.154  0.5355 0.9851], Epochs since improvement 8
 12%|█▏        | 60/500 [53:07<6:59:31, 57.21s/it] 12%|█▏        | 61/500 [53:48<6:22:50, 52.32s/it] 12%|█▏        | 62/500 [54:52<6:47:28, 55.82s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 4.33E+06, Train scatter: [0.6029 0.1336 0.544  0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5824 0.1305 0.5354 0.9848], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.8582 0.154  0.5355 0.9851], Epochs since improvement 10
 13%|█▎        | 63/500 [55:33<6:14:49, 51.46s/it] 13%|█▎        | 64/500 [56:37<6:40:37, 55.13s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 4.22E+06, Train scatter: [0.5886 0.1178 0.544  0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5864 0.1151 0.5354 0.9847], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.7523 0.1305 0.5355 0.9851], Epochs since improvement 12
 13%|█▎        | 65/500 [57:18<6:08:32, 50.83s/it] 13%|█▎        | 66/500 [58:22<6:37:18, 54.93s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 4.13E+06, Train scatter: [0.5503 0.1084 0.544  0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5511 0.1061 0.5354 0.9846], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.5864 0.1292 0.5354 0.9848], Epochs since improvement 14
 13%|█▎        | 67/500 [59:03<6:06:03, 50.72s/it] 14%|█▎        | 68/500 [1:00:08<6:35:20, 54.91s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 4.35E+06, Train scatter: [0.9289 0.1515 0.544  0.995 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9133 0.1484 0.5355 0.9846], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.5864 0.1292 0.5354 0.9847], Epochs since improvement 16
 14%|█▍        | 69/500 [1:00:49<6:04:30, 50.74s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 4.08E+06, Train scatter: [0.9249 0.1075 0.544  0.9948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9095 0.1062 0.5354 0.9845], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.5864 0.1151 0.5354 0.9846], Epochs since improvement 18
 14%|█▍        | 70/500 [1:02:00<6:47:52, 56.91s/it] 14%|█▍        | 71/500 [1:02:41<6:12:15, 52.06s/it] 14%|█▍        | 72/500 [1:03:44<6:35:10, 55.40s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 4.04E+06, Train scatter: [0.9238 0.1069 0.544  0.9948]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9084 0.1046 0.5354 0.9845], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.9084 0.1062 0.5354 0.9846], Epochs since improvement 20
 15%|█▍        | 73/500 [1:04:25<6:03:16, 51.05s/it] 15%|█▍        | 73/500 [1:05:31<6:23:14, 53.85s/it]
Epoch: 74 done with learning rate 1.00E-02, Train loss: 4.02E+06, Train scatter: [0.9231 0.1032 0.544  0.9949]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9078 0.1012 0.5354 0.9846], Lowest was [0.2353 0.0678 0.535  0.4935]
Median for last 10 epochs: [0.9084 0.1061 0.5354 0.9846], Epochs since improvement 22
Exited after 74 epochs due to early stopping
3931.15 seconds spent training, 7.862 seconds per epoch. Processed 8857 trees per second
[0.9077537  0.10118701 0.5354143  0.9845588 ]
{'epoch_exit': 73, 'scatter_m_star': 0.9077537, 'lowest_m_star': 0.2353327, 'last20_m_star': 0.8786688, 'last10_m_star': 0.9084493, 'scatter_v_disk': 0.101187006, 'lowest_v_disk': 0.06777571, 'last20_v_disk': 0.12210877, 'last10_v_disk': 0.10613922, 'scatter_m_cold': 0.5354143, 'lowest_m_cold': 0.53495014, 'last20_m_cold': 0.535442, 'last10_m_cold': 0.53543, 'scatter_sfr_100': 0.9845588, 'lowest_sfr_100': 0.49345976, 'last20_sfr_100': 0.9846627, 'last10_sfr_100': 0.9845728}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_mfuyqa
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:02<8:38:31, 62.35s/it]  0%|          | 2/500 [02:32<10:53:24, 78.72s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.34E+07, Train scatter: [0.9351 0.1287 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1246 0.5355 0.9851], Lowest was [0.9195 0.1246 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1246 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:34<9:48:10, 71.01s/it]   1%|          | 4/500 [05:05<10:54:12, 79.14s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.35E+07, Train scatter: [0.9306 0.1042 0.5429 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9145 0.105  0.5342 0.9851], Lowest was [0.9145 0.105  0.5342 0.9851]
Median for last 10 epochs: [0.9145 0.105  0.5342 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:07<10:01:24, 72.90s/it]  1%|          | 6/500 [07:39<10:52:35, 79.26s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.29E+08, Train scatter: [0.9351 0.1435 0.543  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9194 0.1383 0.5344 0.9851], Lowest was [0.9145 0.105  0.5342 0.9851]
Median for last 10 epochs: [0.9145 0.105  0.5342 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [08:41<10:03:54, 73.50s/it]  2%|▏         | 8/500 [10:12<10:49:02, 79.15s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.70E+07, Train scatter: [0.9326 0.1083 0.4591 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9166 0.1131 0.4532 0.9851], Lowest was [0.9145 0.105  0.4532 0.9851]
Median for last 10 epochs: [0.9156 0.109  0.4937 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [11:14<10:03:50, 73.79s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 8.06E+07, Train scatter: [0.7325 0.1024 0.4193 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7203 0.1029 0.416  0.985 ], Lowest was [0.7203 0.1029 0.416  0.985 ]
Median for last 10 epochs: [0.9145 0.105  0.4532 0.9851], Epochs since improvement 0
  2%|▏         | 10/500 [12:53<11:05:55, 81.54s/it]  2%|▏         | 11/500 [13:55<10:15:32, 75.53s/it]  2%|▏         | 12/500 [15:26<10:53:40, 80.37s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.60E+07, Train scatter: [0.4298 0.0934 0.3869 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4384 0.094  0.3844 0.985 ], Lowest was [0.4384 0.094  0.3844 0.985 ]
Median for last 10 epochs: [0.9145 0.105  0.4532 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [16:28<10:07:15, 74.82s/it]  3%|▎         | 14/500 [17:59<10:44:52, 79.61s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.44E+07, Train scatter: [0.381  0.086  0.3675 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3853 0.087  0.3681 0.985 ], Lowest was [0.3853 0.087  0.3681 0.985 ]
Median for last 10 epochs: [0.7203 0.1029 0.416  0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [19:01<10:00:38, 74.31s/it]  3%|▎         | 16/500 [20:33<10:42:34, 79.66s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.49E+07, Train scatter: [0.332  0.081  0.3503 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3436 0.082  0.3519 0.985 ], Lowest was [0.3436 0.082  0.3519 0.985 ]
Median for last 10 epochs: [0.4384 0.094  0.3844 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [21:35<9:58:27, 74.34s/it]   4%|▎         | 18/500 [23:06<10:38:43, 79.51s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 2.85E+07, Train scatter: [0.2752 0.0764 0.3348 0.9952]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2844 0.0773 0.3363 0.9849], Lowest was [0.2844 0.0773 0.3363 0.9849]
Median for last 10 epochs: [0.3853 0.087  0.3681 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [24:09<9:55:55, 74.34s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 1.20E+07, Train scatter: [0.2471 0.0759 0.3265 0.6221]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2681 0.0765 0.3327 0.6226], Lowest was [0.2681 0.0765 0.3327 0.6226]
Median for last 10 epochs: [0.3436 0.082  0.3519 0.985 ], Epochs since improvement 0
  4%|▍         | 20/500 [25:47<10:52:35, 81.57s/it]  4%|▍         | 21/500 [26:49<10:04:12, 75.68s/it]  4%|▍         | 22/500 [28:20<10:40:10, 80.36s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.82E+06, Train scatter: [0.2481 0.073  0.3238 0.607 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2641 0.0731 0.3294 0.614 ], Lowest was [0.2641 0.0731 0.3294 0.614 ]
Median for last 10 epochs: [0.2844 0.0773 0.3363 0.9849], Epochs since improvement 0
  5%|▍         | 23/500 [29:22<9:54:57, 74.84s/it]   5%|▍         | 24/500 [30:53<10:32:01, 79.67s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.94E+06, Train scatter: [0.2321 0.0713 0.3172 0.5338]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2449 0.0714 0.3227 0.5342], Lowest was [0.2449 0.0714 0.3227 0.5342]
Median for last 10 epochs: [0.2681 0.0765 0.3327 0.6226], Epochs since improvement 0
  5%|▌         | 25/500 [31:55<9:48:36, 74.35s/it]   5%|▌         | 26/500 [33:27<10:29:26, 79.68s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.48E+06, Train scatter: [0.2163 0.0689 0.3142 0.5133]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2299 0.0691 0.3231 0.5166], Lowest was [0.2299 0.0691 0.3227 0.5166]
Median for last 10 epochs: [0.2641 0.0731 0.3294 0.614 ], Epochs since improvement 0
  5%|▌         | 27/500 [34:29<9:46:20, 74.38s/it]   6%|▌         | 28/500 [36:00<10:24:41, 79.41s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.21E+06, Train scatter: [0.2072 0.0667 0.3049 0.483 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2198 0.0675 0.3145 0.4835], Lowest was [0.2198 0.0675 0.3145 0.4835]
Median for last 10 epochs: [0.2449 0.0714 0.3231 0.5342], Epochs since improvement 0
  6%|▌         | 29/500 [37:02<9:42:08, 74.16s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.29E+06, Train scatter: [0.2211 0.0711 0.3224 0.4913]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.228  0.0707 0.3276 0.4866], Lowest was [0.2198 0.0675 0.3145 0.4835]
Median for last 10 epochs: [0.2299 0.0707 0.3231 0.5166], Epochs since improvement 2
  6%|▌         | 30/500 [38:41<10:37:50, 81.43s/it]  6%|▌         | 31/500 [39:43<9:50:53, 75.59s/it]   6%|▋         | 32/500 [41:14<10:26:50, 80.37s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.11E+06, Train scatter: [0.2587 0.0691 0.3125 0.4784]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2691 0.0689 0.3187 0.4775], Lowest was [0.2198 0.0675 0.3145 0.4775]
Median for last 10 epochs: [0.2299 0.0691 0.3227 0.4866], Epochs since improvement 0
  7%|▋         | 33/500 [42:16<9:42:02, 74.78s/it]   7%|▋         | 34/500 [43:48<10:19:55, 79.82s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.79E+06, Train scatter: [0.2185 0.0663 0.2945 0.4836]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2283 0.0662 0.2972 0.481 ], Lowest was [0.2198 0.0662 0.2972 0.4775]
Median for last 10 epochs: [0.2283 0.0689 0.3187 0.4835], Epochs since improvement 0
  7%|▋         | 35/500 [44:50<9:37:24, 74.50s/it]   7%|▋         | 36/500 [46:22<10:17:28, 79.85s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.65E+06, Train scatter: [0.2293 0.0669 0.3022 0.4735]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2392 0.066  0.3076 0.4741], Lowest was [0.2198 0.066  0.2972 0.4741]
Median for last 10 epochs: [0.2283 0.0675 0.3145 0.481 ], Epochs since improvement 0
  7%|▋         | 37/500 [47:24<9:34:13, 74.41s/it]   8%|▊         | 38/500 [48:56<10:14:35, 79.82s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.68E+06, Train scatter: [0.2057 0.0657 0.2852 0.4601]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.214  0.065  0.2861 0.4604], Lowest was [0.214  0.065  0.2861 0.4604]
Median for last 10 epochs: [0.2283 0.0662 0.3076 0.4775], Epochs since improvement 0
  8%|▊         | 39/500 [49:58<9:32:21, 74.49s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.53E+06, Train scatter: [0.2647 0.0652 0.3353 0.4894]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2656 0.0645 0.3427 0.495 ], Lowest was [0.214  0.0645 0.2861 0.4604]
Median for last 10 epochs: [0.2392 0.066  0.3076 0.4775], Epochs since improvement 0
  8%|▊         | 40/500 [51:37<10:27:08, 81.80s/it]  8%|▊         | 41/500 [52:39<9:39:45, 75.79s/it]   8%|▊         | 42/500 [54:10<10:14:51, 80.55s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.41E+06, Train scatter: [0.2634 0.0648 0.3353 0.4904]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2725 0.0638 0.3392 0.4899], Lowest was [0.214  0.0638 0.2861 0.4604]
Median for last 10 epochs: [0.2392 0.065  0.3076 0.481 ], Epochs since improvement 0
  9%|▊         | 43/500 [55:13<9:31:39, 75.05s/it]   9%|▉         | 44/500 [56:44<10:07:59, 80.00s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.43E+06, Train scatter: [0.219  0.0622 0.3235 0.4583]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2272 0.0623 0.3324 0.46  ], Lowest was [0.214  0.0623 0.2861 0.46  ]
Median for last 10 epochs: [0.2392 0.0645 0.3324 0.4741], Epochs since improvement 0
  9%|▉         | 45/500 [57:46<9:25:11, 74.53s/it]   9%|▉         | 46/500 [59:17<10:01:21, 79.48s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.28E+06, Train scatter: [0.2203 0.0645 0.2823 0.4802]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2253 0.0637 0.2818 0.4765], Lowest was [0.214  0.0623 0.2818 0.46  ]
Median for last 10 epochs: [0.2272 0.0638 0.3324 0.4765], Epochs since improvement 0
  9%|▉         | 47/500 [1:00:19<9:20:25, 74.23s/it] 10%|▉         | 48/500 [1:01:50<9:57:24, 79.30s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.08E+06, Train scatter: [0.2385 0.0621 0.2764 0.4452]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2403 0.0612 0.2822 0.4469], Lowest was [0.214  0.0612 0.2818 0.4469]
Median for last 10 epochs: [0.2403 0.0637 0.3324 0.4765], Epochs since improvement 0
 10%|▉         | 49/500 [1:02:52<9:17:27, 74.16s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.99E+06, Train scatter: [0.2109 0.0604 0.2777 0.4569]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2214 0.0592 0.2782 0.4525], Lowest was [0.214  0.0592 0.2782 0.4469]
Median for last 10 epochs: [0.2272 0.0623 0.2822 0.46  ], Epochs since improvement 0
 10%|█         | 50/500 [1:04:30<10:10:06, 81.35s/it] 10%|█         | 51/500 [1:05:33<9:25:41, 75.59s/it]  10%|█         | 52/500 [1:07:04<9:59:55, 80.35s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.77E+06, Train scatter: [0.205  0.0553 0.2741 0.4356]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2097 0.0558 0.279  0.4328], Lowest was [0.2097 0.0558 0.2782 0.4328]
Median for last 10 epochs: [0.2253 0.0612 0.2818 0.4525], Epochs since improvement 0
 11%|█         | 53/500 [1:08:06<9:17:48, 74.87s/it] 11%|█         | 54/500 [1:09:37<9:52:22, 79.69s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.88E+06, Train scatter: [0.1998 0.0593 0.2927 0.4652]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2049 0.0591 0.2939 0.4644], Lowest was [0.2049 0.0558 0.2782 0.4328]
Median for last 10 epochs: [0.2214 0.0592 0.2818 0.4525], Epochs since improvement 0
 11%|█         | 55/500 [1:10:39<9:11:33, 74.37s/it] 11%|█         | 56/500 [1:12:09<9:45:51, 79.17s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.69E+06, Train scatter: [0.2275 0.055  0.2853 0.4379]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2275 0.0554 0.2857 0.4345], Lowest was [0.2049 0.0554 0.2782 0.4328]
Median for last 10 epochs: [0.2214 0.0591 0.2822 0.4469], Epochs since improvement 0
 11%|█▏        | 57/500 [1:13:12<9:06:59, 74.08s/it] 12%|█▏        | 58/500 [1:14:42<9:42:12, 79.03s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 1.55E+06, Train scatter: [0.1981 0.0565 0.2809 0.4351]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.206  0.0575 0.287  0.4322], Lowest was [0.2049 0.0554 0.2782 0.4322]
Median for last 10 epochs: [0.2097 0.0575 0.2857 0.4345], Epochs since improvement 0
 12%|█▏        | 59/500 [1:15:44<9:03:03, 73.88s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.55E+06, Train scatter: [0.2197 0.0572 0.2812 0.4538]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2254 0.0572 0.2802 0.4477], Lowest was [0.2049 0.0554 0.2782 0.4322]
Median for last 10 epochs: [0.2097 0.0572 0.2857 0.4345], Epochs since improvement 2
 12%|█▏        | 60/500 [1:17:23<9:56:54, 81.40s/it] 12%|█▏        | 61/500 [1:18:25<9:12:43, 75.54s/it] 12%|█▏        | 62/500 [1:19:56<9:46:31, 80.34s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.47E+06, Train scatter: [0.2411 0.0558 0.2831 0.4637]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2409 0.0556 0.2852 0.4624], Lowest was [0.2049 0.0554 0.2782 0.4322]
Median for last 10 epochs: [0.2254 0.0572 0.2857 0.4477], Epochs since improvement 4
 13%|█▎        | 63/500 [1:20:58<9:04:12, 74.72s/it] 13%|█▎        | 64/500 [1:22:30<9:40:22, 79.87s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.45E+06, Train scatter: [0.2059 0.0604 0.3445 0.4318]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.21   0.0602 0.3484 0.4305], Lowest was [0.2049 0.0554 0.2782 0.4305]
Median for last 10 epochs: [0.2254 0.0572 0.2857 0.4345], Epochs since improvement 0
 13%|█▎        | 65/500 [1:23:32<9:00:47, 74.59s/it] 13%|█▎        | 66/500 [1:25:04<9:37:16, 79.81s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.29E+06, Train scatter: [0.2066 0.0527 0.2762 0.4227]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2112 0.053  0.2805 0.4209], Lowest was [0.2049 0.053  0.2782 0.4209]
Median for last 10 epochs: [0.2112 0.0572 0.2852 0.4322], Epochs since improvement 0
 13%|█▎        | 67/500 [1:26:06<8:56:17, 74.31s/it] 14%|█▎        | 68/500 [1:27:37<9:31:57, 79.44s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.27E+06, Train scatter: [0.2341 0.0593 0.2887 0.4556]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2348 0.0588 0.2878 0.4551], Lowest was [0.2049 0.053  0.2782 0.4209]
Median for last 10 epochs: [0.2254 0.0572 0.2852 0.4477], Epochs since improvement 2
 14%|█▍        | 69/500 [1:28:39<8:52:21, 74.11s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.02E+06, Train scatter: [0.2266 0.0622 0.2713 0.4357]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2297 0.0609 0.2723 0.4294], Lowest was [0.2049 0.053  0.2723 0.4209]
Median for last 10 epochs: [0.2297 0.0588 0.2852 0.4305], Epochs since improvement 0
 14%|█▍        | 70/500 [1:30:17<9:42:58, 81.35s/it] 14%|█▍        | 71/500 [1:31:19<8:59:21, 75.43s/it] 14%|█▍        | 72/500 [1:32:49<9:30:27, 79.97s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.00E+06, Train scatter: [0.2233 0.0558 0.2812 0.4378]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2277 0.0558 0.2857 0.4402], Lowest was [0.2049 0.053  0.2723 0.4209]
Median for last 10 epochs: [0.2277 0.0588 0.2857 0.4305], Epochs since improvement 2
 15%|█▍        | 73/500 [1:33:51<8:49:58, 74.47s/it] 15%|█▍        | 74/500 [1:35:22<9:24:02, 79.44s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 9.29E+05, Train scatter: [0.2153 0.0693 0.3057 0.5048]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2227 0.0684 0.303  0.5025], Lowest was [0.2049 0.053  0.2723 0.4209]
Median for last 10 epochs: [0.2277 0.0588 0.2857 0.4402], Epochs since improvement 4
 15%|█▌        | 75/500 [1:36:24<8:45:35, 74.20s/it] 15%|█▌        | 76/500 [1:37:54<9:19:10, 79.13s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 8.78E+05, Train scatter: [0.2758 0.0559 0.2874 0.4379]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2776 0.0558 0.2852 0.4399], Lowest was [0.2049 0.053  0.2723 0.4209]
Median for last 10 epochs: [0.2297 0.0588 0.2857 0.4402], Epochs since improvement 6
 15%|█▌        | 77/500 [1:38:56<8:41:24, 73.96s/it] 16%|█▌        | 78/500 [1:40:27<9:16:01, 79.06s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 8.45E+05, Train scatter: [0.1965 0.052  0.2835 0.4168]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2027 0.0528 0.2858 0.4198], Lowest was [0.2027 0.0528 0.2723 0.4198]
Median for last 10 epochs: [0.2277 0.0558 0.2857 0.4399], Epochs since improvement 0
 16%|█▌        | 79/500 [1:41:29<8:38:38, 73.92s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 7.36E+05, Train scatter: [0.18   0.0507 0.2658 0.4128]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1867 0.0508 0.2705 0.4076], Lowest was [0.1867 0.0508 0.2705 0.4076]
Median for last 10 epochs: [0.2227 0.0558 0.2857 0.4399], Epochs since improvement 0
 16%|█▌        | 80/500 [1:43:08<9:30:06, 81.44s/it] 16%|█▌        | 81/500 [1:44:10<8:47:54, 75.59s/it] 16%|█▋        | 82/500 [1:45:41<9:19:02, 80.25s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 6.26E+05, Train scatter: [0.1672 0.0507 0.2562 0.403 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1731 0.051  0.2567 0.4013], Lowest was [0.1731 0.0508 0.2567 0.4013]
Median for last 10 epochs: [0.2027 0.0528 0.2852 0.4198], Epochs since improvement 0
 17%|█▋        | 83/500 [1:46:43<8:39:26, 74.74s/it] 17%|█▋        | 84/500 [1:48:14<9:11:36, 79.56s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 4.90E+05, Train scatter: [0.1641 0.0489 0.2623 0.4175]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1664 0.0484 0.2625 0.4115], Lowest was [0.1664 0.0484 0.2567 0.4013]
Median for last 10 epochs: [0.1867 0.051  0.2705 0.4115], Epochs since improvement 0
 17%|█▋        | 85/500 [1:49:16<8:33:24, 74.23s/it] 17%|█▋        | 86/500 [1:50:46<9:05:57, 79.13s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 3.70E+05, Train scatter: [0.1696 0.0464 0.2554 0.3998]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1752 0.0469 0.2608 0.3986], Lowest was [0.1664 0.0469 0.2567 0.3986]
Median for last 10 epochs: [0.1752 0.0508 0.2625 0.4076], Epochs since improvement 0
 17%|█▋        | 87/500 [1:51:48<8:29:00, 73.95s/it] 18%|█▊        | 88/500 [1:53:18<9:01:18, 78.83s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.25E+05, Train scatter: [0.2284 0.0482 0.2545 0.4037]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2351 0.0482 0.2555 0.4045], Lowest was [0.1664 0.0469 0.2555 0.3986]
Median for last 10 epochs: [0.1752 0.0484 0.2608 0.4045], Epochs since improvement 0
 18%|█▊        | 89/500 [1:54:20<8:25:07, 73.74s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 8.41E+04, Train scatter: [0.1567 0.0492 0.2662 0.4171]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1621 0.0488 0.2682 0.4109], Lowest was [0.1621 0.0469 0.2555 0.3986]
Median for last 10 epochs: [0.1731 0.0484 0.2608 0.4045], Epochs since improvement 0
 18%|█▊        | 90/500 [1:55:58<9:13:07, 80.94s/it] 18%|█▊        | 91/500 [1:57:00<8:32:23, 75.17s/it] 18%|█▊        | 92/500 [1:58:30<9:02:54, 79.84s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: -5.01E+04, Train scatter: [0.1578 0.0443 0.2333 0.393 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1629 0.0444 0.2368 0.3891], Lowest was [0.1621 0.0444 0.2368 0.3891]
Median for last 10 epochs: [0.1664 0.0482 0.2608 0.4045], Epochs since improvement 0
 19%|█▊        | 93/500 [1:59:32<8:24:41, 74.40s/it] 19%|█▉        | 94/500 [2:01:03<8:57:16, 79.40s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: -1.89E+05, Train scatter: [0.2313 0.0533 0.2417 0.3962]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2353 0.053  0.243  0.394 ], Lowest was [0.1621 0.0444 0.2368 0.3891]
Median for last 10 epochs: [0.1752 0.0482 0.2555 0.3986], Epochs since improvement 2
 19%|█▉        | 95/500 [2:02:05<8:20:27, 74.14s/it] 19%|█▉        | 96/500 [2:03:36<8:53:05, 79.17s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: -2.61E+05, Train scatter: [0.1479 0.0442 0.2514 0.3998]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.152  0.0446 0.2522 0.3965], Lowest was [0.152  0.0444 0.2368 0.3891]
Median for last 10 epochs: [0.1629 0.0482 0.2522 0.3965], Epochs since improvement 0
 19%|█▉        | 97/500 [2:04:38<8:16:48, 73.97s/it] 20%|█▉        | 98/500 [2:06:08<8:49:16, 79.00s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: -2.89E+05, Train scatter: [0.1717 0.048  0.2686 0.4049]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1733 0.0476 0.2707 0.3996], Lowest was [0.152  0.0444 0.2368 0.3891]
Median for last 10 epochs: [0.1629 0.0476 0.2522 0.3965], Epochs since improvement 2
 20%|█▉        | 99/500 [2:07:10<8:13:49, 73.89s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: -3.47E+05, Train scatter: [0.1419 0.0459 0.2303 0.3867]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1472 0.0457 0.2316 0.3826], Lowest was [0.1472 0.0444 0.2316 0.3826]
Median for last 10 epochs: [0.1629 0.0457 0.243  0.394 ], Epochs since improvement 0
 20%|██        | 100/500 [2:08:49<9:02:25, 81.36s/it] 20%|██        | 101/500 [2:09:51<8:22:26, 75.56s/it] 20%|██        | 102/500 [2:11:23<8:52:46, 80.32s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: -3.59E+05, Train scatter: [0.1861 0.0479 0.2397 0.4059]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1918 0.0477 0.2416 0.4019], Lowest was [0.1472 0.0444 0.2316 0.3826]
Median for last 10 epochs: [0.1733 0.0476 0.243  0.3965], Epochs since improvement 2
 21%|██        | 103/500 [2:12:24<8:14:37, 74.76s/it] 21%|██        | 104/500 [2:13:56<8:46:49, 79.82s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: -3.61E+05, Train scatter: [0.1362 0.0458 0.2302 0.3964]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1393 0.0453 0.2323 0.3909], Lowest was [0.1393 0.0444 0.2316 0.3826]
Median for last 10 epochs: [0.152  0.0457 0.2416 0.3965], Epochs since improvement 0
 21%|██        | 105/500 [2:14:58<8:10:32, 74.51s/it] 21%|██        | 106/500 [2:16:29<8:40:28, 79.26s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: -3.78E+05, Train scatter: [0.3585 0.0673 0.3976 0.5458]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3482 0.067  0.3914 0.5397], Lowest was [0.1393 0.0444 0.2316 0.3826]
Median for last 10 epochs: [0.1733 0.0476 0.2416 0.3996], Epochs since improvement 2
 21%|██▏       | 107/500 [2:17:30<8:04:48, 74.02s/it] 22%|██▏       | 108/500 [2:19:02<8:37:39, 79.23s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: -3.98E+05, Train scatter: [0.1284 0.0456 0.247  0.4006]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1354 0.0454 0.2531 0.3985], Lowest was [0.1354 0.0444 0.2316 0.3826]
Median for last 10 epochs: [0.1472 0.0457 0.2416 0.3985], Epochs since improvement 0
 22%|██▏       | 109/500 [2:20:04<8:03:07, 74.14s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: -3.51E+05, Train scatter: [0.1458 0.0506 0.2466 0.4272]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1467 0.05   0.246  0.4136], Lowest was [0.1354 0.0444 0.2316 0.3826]
Median for last 10 epochs: [0.1467 0.0477 0.246  0.4019], Epochs since improvement 2
 22%|██▏       | 110/500 [2:21:45<8:54:04, 82.17s/it] 22%|██▏       | 111/500 [2:22:47<8:13:12, 76.07s/it] 22%|██▏       | 112/500 [2:24:18<8:42:00, 80.72s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: -3.99E+05, Train scatter: [0.1249 0.0412 0.2295 0.3939]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1308 0.0407 0.2317 0.3871], Lowest was [0.1308 0.0407 0.2316 0.3826]
Median for last 10 epochs: [0.1393 0.0454 0.246  0.3985], Epochs since improvement 0
 23%|██▎       | 113/500 [2:25:20<8:04:25, 75.11s/it] 23%|██▎       | 114/500 [2:26:52<8:34:27, 79.97s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: -3.98E+05, Train scatter: [0.1487 0.0441 0.2362 0.4095]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1539 0.0437 0.2379 0.4025], Lowest was [0.1308 0.0407 0.2316 0.3826]
Median for last 10 epochs: [0.1467 0.0454 0.246  0.4025], Epochs since improvement 2
 23%|██▎       | 115/500 [2:27:54<7:58:28, 74.57s/it] 23%|██▎       | 116/500 [2:29:25<8:30:09, 79.71s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: -4.14E+05, Train scatter: [0.1563 0.0423 0.2218 0.4041]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1566 0.0418 0.2237 0.3974], Lowest was [0.1308 0.0407 0.2237 0.3826]
Median for last 10 epochs: [0.1467 0.0437 0.2379 0.3985], Epochs since improvement 0
 23%|██▎       | 117/500 [2:30:27<7:54:33, 74.34s/it] 24%|██▎       | 118/500 [2:31:59<8:27:17, 79.68s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: -3.98E+05, Train scatter: [0.1555 0.0483 0.2511 0.4357]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1554 0.0481 0.2537 0.4292], Lowest was [0.1308 0.0407 0.2237 0.3826]
Median for last 10 epochs: [0.1539 0.0437 0.2379 0.4025], Epochs since improvement 2
 24%|██▍       | 119/500 [2:33:01<7:52:10, 74.36s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: -4.02E+05, Train scatter: [0.1338 0.0428 0.2333 0.4176]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1376 0.0424 0.2347 0.4126], Lowest was [0.1308 0.0407 0.2237 0.3826]
Median for last 10 epochs: [0.1539 0.0424 0.2347 0.4025], Epochs since improvement 4
 24%|██▍       | 120/500 [2:34:40<8:37:14, 81.67s/it] 24%|██▍       | 121/500 [2:35:42<7:58:29, 75.75s/it] 24%|██▍       | 122/500 [2:37:13<8:26:38, 80.42s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: -4.21E+05, Train scatter: [0.1258 0.0426 0.2245 0.4053]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1297 0.0417 0.2249 0.3953], Lowest was [0.1297 0.0407 0.2237 0.3826]
Median for last 10 epochs: [0.1539 0.0424 0.2347 0.4025], Epochs since improvement 0
 25%|██▍       | 123/500 [2:38:15<7:50:11, 74.83s/it] 25%|██▍       | 124/500 [2:39:46<8:19:46, 79.75s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: -4.29E+05, Train scatter: [0.1583 0.0486 0.2234 0.4048]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1899 0.0467 0.2246 0.3944], Lowest was [0.1297 0.0407 0.2237 0.3826]
Median for last 10 epochs: [0.1554 0.0424 0.2249 0.3974], Epochs since improvement 2
 25%|██▌       | 125/500 [2:40:48<7:44:40, 74.35s/it] 25%|██▌       | 126/500 [2:42:20<8:15:50, 79.55s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: -4.30E+05, Train scatter: [0.1462 0.0546 0.3147 0.4332]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1494 0.0534 0.3136 0.4278], Lowest was [0.1297 0.0407 0.2237 0.3826]
Median for last 10 epochs: [0.1494 0.0467 0.2347 0.4126], Epochs since improvement 4
 25%|██▌       | 127/500 [2:43:21<7:41:27, 74.23s/it] 26%|██▌       | 128/500 [2:44:53<8:12:15, 79.40s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -4.08E+05, Train scatter: [0.2199 0.0617 0.2466 0.451 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2226 0.0599 0.2459 0.4371], Lowest was [0.1297 0.0407 0.2237 0.3826]
Median for last 10 epochs: [0.1494 0.0467 0.2347 0.4126], Epochs since improvement 6
 26%|██▌       | 129/500 [2:45:55<7:38:40, 74.18s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -4.26E+05, Train scatter: [0.2877 0.0521 0.232  0.432 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2822 0.0519 0.2314 0.4275], Lowest was [0.1297 0.0407 0.2237 0.3826]
Median for last 10 epochs: [0.1899 0.0519 0.2314 0.4275], Epochs since improvement 8
 26%|██▌       | 130/500 [2:47:34<8:23:38, 81.67s/it] 26%|██▌       | 131/500 [2:48:36<7:45:53, 75.76s/it] 26%|██▋       | 132/500 [2:50:07<8:12:49, 80.35s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -4.30E+05, Train scatter: [0.1257 0.0414 0.2263 0.4081]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1284 0.0407 0.2284 0.401 ], Lowest was [0.1284 0.0407 0.2237 0.3826]
Median for last 10 epochs: [0.1899 0.0519 0.2314 0.4275], Epochs since improvement 0
 27%|██▋       | 133/500 [2:51:09<7:37:37, 74.82s/it] 27%|██▋       | 134/500 [2:52:40<8:06:13, 79.71s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: -4.39E+05, Train scatter: [0.118  0.0403 0.2101 0.4027]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1207 0.0395 0.2124 0.3935], Lowest was [0.1207 0.0395 0.2124 0.3826]
Median for last 10 epochs: [0.1494 0.0519 0.2314 0.4275], Epochs since improvement 0
 27%|██▋       | 135/500 [2:53:42<7:31:55, 74.29s/it] 27%|██▋       | 136/500 [2:55:14<8:02:25, 79.52s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: -4.37E+05, Train scatter: [0.1576 0.0433 0.2202 0.4099]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1551 0.043  0.2226 0.4033], Lowest was [0.1207 0.0395 0.2124 0.3826]
Median for last 10 epochs: [0.1551 0.043  0.2284 0.4033], Epochs since improvement 2
 27%|██▋       | 137/500 [2:56:15<7:28:49, 74.19s/it] 28%|██▊       | 138/500 [2:57:47<7:58:31, 79.31s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -4.50E+05, Train scatter: [0.1348 0.0415 0.2254 0.4197]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1378 0.0409 0.227  0.4122], Lowest was [0.1207 0.0395 0.2124 0.3826]
Median for last 10 epochs: [0.1378 0.0409 0.227  0.4033], Epochs since improvement 4
 28%|██▊       | 139/500 [2:58:49<7:26:46, 74.25s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -4.53E+05, Train scatter: [0.1241 0.0391 0.207  0.3919]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1397 0.0388 0.21   0.3828], Lowest was [0.1207 0.0388 0.21   0.3826]
Median for last 10 epochs: [0.1378 0.0407 0.2226 0.401 ], Epochs since improvement 0
 28%|██▊       | 140/500 [3:00:28<8:09:57, 81.66s/it] 28%|██▊       | 141/500 [3:01:30<7:33:15, 75.75s/it] 28%|██▊       | 142/500 [3:03:00<7:58:28, 80.19s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -4.14E+05, Train scatter: [0.1331 0.041  0.22   0.4019]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1387 0.0408 0.2213 0.3937], Lowest was [0.1207 0.0388 0.21   0.3826]
Median for last 10 epochs: [0.1387 0.0408 0.2213 0.3937], Epochs since improvement 2
 29%|██▊       | 143/500 [3:04:02<7:24:45, 74.75s/it] 29%|██▉       | 144/500 [3:05:34<7:53:16, 79.77s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: -4.63E+05, Train scatter: [0.1156 0.0387 0.2071 0.3958]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1174 0.038  0.2093 0.3861], Lowest was [0.1174 0.038  0.2093 0.3826]
Median for last 10 epochs: [0.1387 0.0408 0.2213 0.3937], Epochs since improvement 0
 29%|██▉       | 145/500 [3:06:36<7:19:58, 74.36s/it] 29%|██▉       | 146/500 [3:08:09<7:51:35, 79.93s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: -4.67E+05, Train scatter: [0.1344 0.0381 0.2042 0.3926]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1379 0.0377 0.2071 0.3837], Lowest was [0.1174 0.0377 0.2071 0.3826]
Median for last 10 epochs: [0.1379 0.0388 0.21   0.3861], Epochs since improvement 0
 29%|██▉       | 147/500 [3:09:10<7:18:11, 74.48s/it] 30%|██▉       | 148/500 [3:10:42<7:46:49, 79.57s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: -4.66E+05, Train scatter: [0.1325 0.0396 0.2046 0.3935]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1331 0.0395 0.2065 0.3855], Lowest was [0.1174 0.0377 0.2065 0.3826]
Median for last 10 epochs: [0.1379 0.0388 0.2093 0.3855], Epochs since improvement 0
 30%|██▉       | 149/500 [3:11:43<7:13:55, 74.17s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: -4.74E+05, Train scatter: [0.1359 0.0391 0.2167 0.4043]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1383 0.0386 0.2178 0.395 ], Lowest was [0.1174 0.0377 0.2065 0.3826]
Median for last 10 epochs: [0.1379 0.0386 0.2093 0.3861], Epochs since improvement 2
 30%|███       | 150/500 [3:13:22<7:55:36, 81.53s/it] 30%|███       | 151/500 [3:14:24<7:19:58, 75.64s/it] 30%|███       | 152/500 [3:15:56<7:47:26, 80.59s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: -4.61E+05, Train scatter: [0.1191 0.0385 0.2091 0.391 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1187 0.038  0.212  0.3822], Lowest was [0.1174 0.0377 0.2065 0.3822]
Median for last 10 epochs: [0.1331 0.038  0.2093 0.3855], Epochs since improvement 0
 31%|███       | 153/500 [3:16:58<7:13:31, 74.96s/it] 31%|███       | 154/500 [3:18:30<7:41:57, 80.11s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: -3.36E+05, Train scatter: [0.1669 0.0486 0.2348 0.4242]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1647 0.0475 0.236  0.4139], Lowest was [0.1174 0.0377 0.2065 0.3822]
Median for last 10 epochs: [0.1379 0.0386 0.212  0.3855], Epochs since improvement 2
 31%|███       | 155/500 [3:19:32<7:09:27, 74.69s/it] 31%|███       | 156/500 [3:21:03<7:36:42, 79.66s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: -4.63E+05, Train scatter: [0.1678 0.0396 0.2135 0.4029]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1652 0.0387 0.2149 0.392 ], Lowest was [0.1174 0.0377 0.2065 0.3822]
Median for last 10 epochs: [0.1383 0.0387 0.2149 0.392 ], Epochs since improvement 4
 31%|███▏      | 157/500 [3:22:06<7:05:17, 74.40s/it] 32%|███▏      | 158/500 [3:23:37<7:32:25, 79.37s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: -4.74E+05, Train scatter: [0.112  0.0384 0.2026 0.3892]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1131 0.0377 0.206  0.3803], Lowest was [0.1131 0.0377 0.206  0.3803]
Median for last 10 epochs: [0.1383 0.0386 0.2149 0.392 ], Epochs since improvement 0
 32%|███▏      | 159/500 [3:24:39<7:01:33, 74.17s/it]Epoch: 160 done with learning rate 9.05E-03, Train loss: -4.68E+05, Train scatter: [0.118  0.0417 0.2062 0.3933]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1188 0.041  0.2082 0.3836], Lowest was [0.1131 0.0377 0.206  0.3803]
Median for last 10 epochs: [0.1188 0.0387 0.212  0.3836], Epochs since improvement 2
 32%|███▏      | 160/500 [3:26:17<7:41:32, 81.45s/it] 32%|███▏      | 161/500 [3:27:19<7:06:52, 75.55s/it] 32%|███▏      | 162/500 [3:28:50<7:32:49, 80.38s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: -4.79E+05, Train scatter: [0.1107 0.0391 0.2118 0.3866]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1123 0.0385 0.2147 0.3774], Lowest was [0.1123 0.0377 0.206  0.3774]
Median for last 10 epochs: [0.1188 0.0387 0.2147 0.3836], Epochs since improvement 0
 33%|███▎      | 163/500 [3:29:52<6:59:54, 74.76s/it] 33%|███▎      | 164/500 [3:31:24<7:27:10, 79.85s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: -4.87E+05, Train scatter: [0.1353 0.0385 0.2069 0.3932]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1379 0.0382 0.2096 0.3866], Lowest was [0.1123 0.0377 0.206  0.3774]
Median for last 10 epochs: [0.1188 0.0385 0.2096 0.3836], Epochs since improvement 2
 33%|███▎      | 165/500 [3:32:26<6:55:40, 74.45s/it] 33%|███▎      | 166/500 [3:33:57<7:22:16, 79.45s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: -4.78E+05, Train scatter: [0.1133 0.038  0.2079 0.3937]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.113  0.0376 0.211  0.3817], Lowest was [0.1123 0.0376 0.206  0.3774]
Median for last 10 epochs: [0.1131 0.0382 0.2096 0.3817], Epochs since improvement 0
 33%|███▎      | 167/500 [3:34:58<6:51:20, 74.12s/it] 34%|███▎      | 168/500 [3:36:30<7:18:32, 79.26s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: -4.93E+05, Train scatter: [0.1143 0.0368 0.2023 0.3838]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1163 0.0362 0.2046 0.3738], Lowest was [0.1123 0.0362 0.2046 0.3738]
Median for last 10 epochs: [0.1163 0.0382 0.2096 0.3817], Epochs since improvement 0
 34%|███▍      | 169/500 [3:37:32<6:48:25, 74.03s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -4.77E+05, Train scatter: [0.1128 0.037  0.2022 0.3842]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1148 0.0367 0.2057 0.3757], Lowest was [0.1123 0.0362 0.2046 0.3738]
Median for last 10 epochs: [0.1148 0.0376 0.2096 0.3774], Epochs since improvement 2
 34%|███▍      | 170/500 [3:39:09<7:26:11, 81.12s/it] 34%|███▍      | 171/500 [3:40:11<6:53:24, 75.39s/it] 34%|███▍      | 172/500 [3:41:43<7:18:46, 80.26s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -4.88E+05, Train scatter: [0.1268 0.0374 0.2032 0.3812]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1283 0.0372 0.2064 0.3701], Lowest was [0.1123 0.0362 0.2046 0.3701]
Median for last 10 epochs: [0.1163 0.0372 0.2064 0.3757], Epochs since improvement 0
 35%|███▍      | 173/500 [3:42:45<6:47:50, 74.83s/it] 35%|███▍      | 174/500 [3:44:17<7:13:59, 79.88s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -4.83E+05, Train scatter: [0.1144 0.0408 0.2116 0.388 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1145 0.0402 0.2136 0.3773], Lowest was [0.1123 0.0362 0.2046 0.3701]
Median for last 10 epochs: [0.1148 0.0372 0.2064 0.3757], Epochs since improvement 2
 35%|███▌      | 175/500 [3:45:19<6:43:37, 74.52s/it] 35%|███▌      | 176/500 [3:46:50<7:10:02, 79.64s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -4.96E+05, Train scatter: [0.1071 0.0358 0.1989 0.3741]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1087 0.0358 0.203  0.3665], Lowest was [0.1087 0.0358 0.203  0.3665]
Median for last 10 epochs: [0.1148 0.0367 0.2057 0.3738], Epochs since improvement 0
 35%|███▌      | 177/500 [3:47:52<6:39:42, 74.25s/it] 36%|███▌      | 178/500 [3:49:24<7:07:35, 79.68s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -5.17E+05, Train scatter: [0.1077 0.0355 0.1964 0.3799]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1095 0.0354 0.2004 0.3703], Lowest was [0.1087 0.0354 0.2004 0.3665]
Median for last 10 epochs: [0.1145 0.0367 0.2057 0.3703], Epochs since improvement 0
 36%|███▌      | 179/500 [3:50:26<6:37:37, 74.32s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -5.18E+05, Train scatter: [0.1054 0.0369 0.1979 0.3748]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1088 0.0363 0.2018 0.3661], Lowest was [0.1087 0.0354 0.2004 0.3661]
Median for last 10 epochs: [0.1095 0.0363 0.203  0.3701], Epochs since improvement 0
 36%|███▌      | 180/500 [3:52:06<7:17:23, 82.01s/it] 36%|███▌      | 181/500 [3:53:08<6:44:07, 76.01s/it] 36%|███▋      | 182/500 [3:54:40<7:08:04, 80.77s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -4.72E+05, Train scatter: [0.1127 0.0367 0.201  0.386 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1128 0.0364 0.2036 0.373 ], Lowest was [0.1087 0.0354 0.2004 0.3661]
Median for last 10 epochs: [0.1095 0.0363 0.203  0.3703], Epochs since improvement 2
 37%|███▋      | 183/500 [3:55:41<6:36:17, 75.01s/it] 37%|███▋      | 184/500 [3:57:13<7:01:45, 80.08s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -5.17E+05, Train scatter: [0.1196 0.0395 0.198  0.3814]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1225 0.0393 0.2013 0.3721], Lowest was [0.1087 0.0354 0.2004 0.3661]
Median for last 10 epochs: [0.1095 0.0363 0.2018 0.3703], Epochs since improvement 4
 37%|███▋      | 185/500 [3:58:15<6:31:39, 74.60s/it] 37%|███▋      | 186/500 [3:59:47<6:57:18, 79.74s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -5.24E+05, Train scatter: [0.1059 0.0365 0.2012 0.3791]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1077 0.0363 0.2047 0.3739], Lowest was [0.1077 0.0354 0.2004 0.3661]
Median for last 10 epochs: [0.1095 0.0363 0.2018 0.3721], Epochs since improvement 0
 37%|███▋      | 187/500 [4:00:49<6:28:23, 74.45s/it] 38%|███▊      | 188/500 [4:02:21<6:54:28, 79.71s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -4.88E+05, Train scatter: [0.1018 0.0356 0.1964 0.3711]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.105  0.0355 0.2002 0.3638], Lowest was [0.105  0.0354 0.2002 0.3638]
Median for last 10 epochs: [0.1088 0.0363 0.2018 0.3721], Epochs since improvement 0
 38%|███▊      | 189/500 [4:03:23<6:25:16, 74.33s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -5.01E+05, Train scatter: [0.1156 0.0364 0.2006 0.3777]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1178 0.0368 0.2055 0.3695], Lowest was [0.105  0.0354 0.2002 0.3638]
Median for last 10 epochs: [0.1128 0.0364 0.2036 0.3721], Epochs since improvement 2
 38%|███▊      | 190/500 [4:05:02<7:01:53, 81.65s/it] 38%|███▊      | 191/500 [4:06:03<6:30:01, 75.73s/it] 38%|███▊      | 192/500 [4:07:35<6:53:15, 80.50s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -5.27E+05, Train scatter: [0.1283 0.0353 0.2029 0.3702]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.128  0.0355 0.2067 0.3631], Lowest was [0.105  0.0354 0.2002 0.3631]
Median for last 10 epochs: [0.1178 0.0363 0.2047 0.3695], Epochs since improvement 0
 39%|███▊      | 193/500 [4:08:37<6:22:47, 74.81s/it] 39%|███▉      | 194/500 [4:10:08<6:47:33, 79.91s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -5.32E+05, Train scatter: [0.1163 0.0349 0.1926 0.3664]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1181 0.035  0.197  0.3603], Lowest was [0.105  0.035  0.197  0.3603]
Median for last 10 epochs: [0.1178 0.0355 0.2047 0.3638], Epochs since improvement 0
 39%|███▉      | 195/500 [4:11:10<6:18:25, 74.44s/it] 39%|███▉      | 196/500 [4:12:42<6:44:12, 79.78s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -5.40E+05, Train scatter: [0.1011 0.0354 0.1915 0.3668]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1042 0.0354 0.1976 0.3622], Lowest was [0.1042 0.035  0.197  0.3603]
Median for last 10 epochs: [0.1178 0.0355 0.2002 0.3631], Epochs since improvement 0
 39%|███▉      | 197/500 [4:13:44<6:15:39, 74.39s/it] 40%|███▉      | 198/500 [4:15:15<6:39:49, 79.43s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -5.33E+05, Train scatter: [0.1003 0.0344 0.191  0.3634]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1029 0.0346 0.196  0.3582], Lowest was [0.1029 0.0346 0.196  0.3582]
Median for last 10 epochs: [0.1178 0.0354 0.1976 0.3622], Epochs since improvement 0
 40%|███▉      | 199/500 [4:16:17<6:11:46, 74.11s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -5.40E+05, Train scatter: [0.1005 0.0345 0.193  0.3655]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1037 0.0347 0.1968 0.3611], Lowest was [0.1029 0.0346 0.196  0.3582]
Median for last 10 epochs: [0.1042 0.035  0.197  0.3611], Epochs since improvement 2
 40%|████      | 200/500 [4:17:56<6:48:12, 81.64s/it] 40%|████      | 201/500 [4:18:58<6:17:46, 75.81s/it] 40%|████      | 202/500 [4:20:30<6:39:22, 80.41s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -5.22E+05, Train scatter: [0.1018 0.0359 0.1926 0.3655]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1061 0.0361 0.197  0.361 ], Lowest was [0.1029 0.0346 0.196  0.3582]
Median for last 10 epochs: [0.1042 0.035  0.197  0.361 ], Epochs since improvement 4
 41%|████      | 203/500 [4:21:32<6:11:46, 75.11s/it] 41%|████      | 204/500 [4:23:03<6:33:51, 79.84s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -5.25E+05, Train scatter: [0.1012 0.036  0.1975 0.3673]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1042 0.0365 0.2028 0.3604], Lowest was [0.1029 0.0346 0.196  0.3582]
Median for last 10 epochs: [0.1042 0.0354 0.197  0.361 ], Epochs since improvement 6
 41%|████      | 205/500 [4:24:05<6:06:06, 74.46s/it] 41%|████      | 206/500 [4:25:36<6:29:03, 79.40s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -5.39E+05, Train scatter: [0.1    0.0351 0.1973 0.3686]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.103  0.0354 0.2022 0.3639], Lowest was [0.1029 0.0346 0.196  0.3582]
Median for last 10 epochs: [0.1037 0.0354 0.197  0.361 ], Epochs since improvement 8
 41%|████▏     | 207/500 [4:26:38<6:02:08, 74.16s/it] 42%|████▏     | 208/500 [4:28:09<6:25:07, 79.14s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -5.43E+05, Train scatter: [0.1059 0.0347 0.1897 0.361 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1081 0.0351 0.195  0.356 ], Lowest was [0.1029 0.0346 0.195  0.356 ]
Median for last 10 epochs: [0.1042 0.0354 0.197  0.361 ], Epochs since improvement 0
 42%|████▏     | 209/500 [4:29:10<5:58:02, 73.82s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -5.20E+05, Train scatter: [0.0973 0.0337 0.1882 0.3586]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1012 0.0342 0.1942 0.356 ], Lowest was [0.1012 0.0342 0.1942 0.356 ]
Median for last 10 epochs: [0.1042 0.0354 0.197  0.3604], Epochs since improvement 0
 42%|████▏     | 210/500 [4:30:49<6:32:52, 81.28s/it] 42%|████▏     | 211/500 [4:31:50<6:03:00, 75.37s/it] 42%|████▏     | 212/500 [4:33:24<6:27:25, 80.71s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -5.56E+05, Train scatter: [0.1053 0.035  0.1947 0.3627]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1069 0.0355 0.2003 0.3586], Lowest was [0.1012 0.0342 0.1942 0.356 ]
Median for last 10 epochs: [0.1042 0.0354 0.2003 0.3586], Epochs since improvement 2
 43%|████▎     | 213/500 [4:34:26<5:59:09, 75.08s/it] 43%|████▎     | 214/500 [4:35:57<6:21:25, 80.02s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: -5.46E+05, Train scatter: [0.0985 0.0344 0.1891 0.3604]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1035 0.035  0.1949 0.3568], Lowest was [0.1012 0.0342 0.1942 0.356 ]
Median for last 10 epochs: [0.1035 0.0351 0.195  0.3568], Epochs since improvement 4
 43%|████▎     | 215/500 [4:36:59<5:54:37, 74.66s/it] 43%|████▎     | 216/500 [4:38:30<6:16:18, 79.50s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -5.65E+05, Train scatter: [0.0974 0.0345 0.19   0.3642]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1013 0.0354 0.1961 0.361 ], Lowest was [0.1012 0.0342 0.1942 0.356 ]
Median for last 10 epochs: [0.1035 0.0351 0.195  0.3568], Epochs since improvement 6
 43%|████▎     | 217/500 [4:39:32<5:50:19, 74.27s/it] 44%|████▎     | 218/500 [4:41:04<6:13:13, 79.41s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -5.31E+05, Train scatter: [0.097  0.034  0.1884 0.3603]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1002 0.0348 0.1953 0.3566], Lowest was [0.1002 0.0342 0.1942 0.356 ]
Median for last 10 epochs: [0.1013 0.035  0.1953 0.3568], Epochs since improvement 0
 44%|████▍     | 219/500 [4:42:05<5:47:19, 74.16s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -5.51E+05, Train scatter: [0.0948 0.0346 0.1884 0.3583]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0983 0.0351 0.1947 0.3566], Lowest was [0.0983 0.0342 0.1942 0.356 ]
Median for last 10 epochs: [0.1013 0.0351 0.1953 0.3568], Epochs since improvement 0
 44%|████▍     | 220/500 [4:43:44<6:20:15, 81.48s/it] 44%|████▍     | 221/500 [4:44:46<5:51:13, 75.53s/it] 44%|████▍     | 222/500 [4:46:17<6:12:31, 80.40s/it]Epoch: 222 done with learning rate 7.33E-03, Train loss: -5.62E+05, Train scatter: [0.1042 0.0358 0.1899 0.3597]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1075 0.0367 0.1968 0.357 ], Lowest was [0.0983 0.0342 0.1942 0.356 ]
Median for last 10 epochs: [0.1013 0.0351 0.1953 0.3568], Epochs since improvement 2
 45%|████▍     | 223/500 [4:47:19<5:44:59, 74.73s/it] 45%|████▍     | 224/500 [4:48:50<6:06:42, 79.72s/it]Epoch: 224 done with learning rate 7.26E-03, Train loss: -5.65E+05, Train scatter: [0.0986 0.0342 0.1988 0.3699]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1004 0.0348 0.2032 0.3624], Lowest was [0.0983 0.0342 0.1942 0.356 ]
Median for last 10 epochs: [0.1004 0.0351 0.1961 0.357 ], Epochs since improvement 4
 45%|████▌     | 225/500 [4:49:52<5:40:21, 74.26s/it] 45%|████▌     | 226/500 [4:51:23<6:02:18, 79.34s/it]Epoch: 226 done with learning rate 7.20E-03, Train loss: -5.37E+05, Train scatter: [0.0938 0.0334 0.1887 0.3575]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0962 0.0343 0.1954 0.3531], Lowest was [0.0962 0.0342 0.1942 0.3531]
Median for last 10 epochs: [0.1002 0.0348 0.1954 0.3566], Epochs since improvement 0
 45%|████▌     | 227/500 [4:52:25<5:37:18, 74.14s/it] 46%|████▌     | 228/500 [4:53:56<5:59:31, 79.31s/it]Epoch: 228 done with learning rate 7.13E-03, Train loss: -5.32E+05, Train scatter: [0.0953 0.0336 0.1889 0.3559]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.099  0.0347 0.1948 0.354 ], Lowest was [0.0962 0.0342 0.1942 0.3531]
Median for last 10 epochs: [0.099  0.0348 0.1954 0.3566], Epochs since improvement 2
 46%|████▌     | 229/500 [4:54:58<5:34:43, 74.11s/it]Epoch: 230 done with learning rate 7.06E-03, Train loss: -5.34E+05, Train scatter: [0.0913 0.0333 0.1857 0.3549]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0965 0.0345 0.1937 0.3557], Lowest was [0.0962 0.0342 0.1937 0.3531]
Median for last 10 epochs: [0.099  0.0347 0.1954 0.3557], Epochs since improvement 0
 46%|████▌     | 230/500 [4:56:37<6:06:42, 81.49s/it] 46%|████▌     | 231/500 [4:57:39<5:39:16, 75.67s/it] 46%|████▋     | 232/500 [4:59:11<5:59:29, 80.48s/it]Epoch: 232 done with learning rate 6.99E-03, Train loss: -4.61E+05, Train scatter: [0.1182 0.0376 0.2031 0.3766]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1134 0.0374 0.2062 0.3701], Lowest was [0.0962 0.0342 0.1937 0.3531]
Median for last 10 epochs: [0.099  0.0347 0.1954 0.3557], Epochs since improvement 2
 47%|████▋     | 233/500 [5:00:13<5:33:29, 74.94s/it] 47%|████▋     | 234/500 [5:01:45<5:55:32, 80.20s/it]Epoch: 234 done with learning rate 6.93E-03, Train loss: -5.46E+05, Train scatter: [0.0941 0.0337 0.1888 0.361 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0996 0.0344 0.195  0.3591], Lowest was [0.0962 0.0342 0.1937 0.3531]
Median for last 10 epochs: [0.099  0.0345 0.195  0.3557], Epochs since improvement 4
 47%|████▋     | 235/500 [5:02:47<5:30:03, 74.73s/it] 47%|████▋     | 236/500 [5:04:17<5:48:48, 79.28s/it]Epoch: 236 done with learning rate 6.86E-03, Train loss: -5.61E+05, Train scatter: [0.0961 0.0333 0.1876 0.3567]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0992 0.0342 0.1947 0.3538], Lowest was [0.0962 0.0342 0.1937 0.3531]
Median for last 10 epochs: [0.0992 0.0345 0.1948 0.3557], Epochs since improvement 6
 47%|████▋     | 237/500 [5:05:19<5:24:15, 73.97s/it] 48%|████▊     | 238/500 [5:06:49<5:44:55, 78.99s/it]Epoch: 238 done with learning rate 6.79E-03, Train loss: -5.68E+05, Train scatter: [0.0982 0.0334 0.188  0.3539]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1027 0.0346 0.1953 0.3548], Lowest was [0.0962 0.0342 0.1937 0.3531]
Median for last 10 epochs: [0.0996 0.0345 0.195  0.3557], Epochs since improvement 8
 48%|████▊     | 239/500 [5:07:51<5:21:04, 73.81s/it]Epoch: 240 done with learning rate 6.72E-03, Train loss: -5.80E+05, Train scatter: [0.0973 0.0333 0.1859 0.3541]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1005 0.0344 0.1934 0.3526], Lowest was [0.0962 0.0342 0.1934 0.3526]
Median for last 10 epochs: [0.1005 0.0344 0.195  0.3548], Epochs since improvement 0
 48%|████▊     | 240/500 [5:09:29<5:51:24, 81.10s/it] 48%|████▊     | 241/500 [5:10:31<5:25:20, 75.37s/it] 48%|████▊     | 242/500 [5:12:03<5:45:34, 80.37s/it]Epoch: 242 done with learning rate 6.65E-03, Train loss: -5.78E+05, Train scatter: [0.0913 0.0331 0.1877 0.3531]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0964 0.0344 0.1941 0.351 ], Lowest was [0.0962 0.0342 0.1934 0.351 ]
Median for last 10 epochs: [0.0996 0.0344 0.1947 0.3538], Epochs since improvement 0
 49%|████▊     | 243/500 [5:13:05<5:20:24, 74.80s/it] 49%|████▉     | 244/500 [5:14:37<5:40:22, 79.78s/it]Epoch: 244 done with learning rate 6.58E-03, Train loss: -5.89E+05, Train scatter: [0.0931 0.0328 0.1861 0.3503]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0974 0.0341 0.194  0.3507], Lowest was [0.0962 0.0341 0.1934 0.3507]
Median for last 10 epochs: [0.0992 0.0344 0.1941 0.3526], Epochs since improvement 0
 49%|████▉     | 245/500 [5:15:39<5:16:42, 74.52s/it] 49%|████▉     | 246/500 [5:17:10<5:36:38, 79.52s/it]Epoch: 246 done with learning rate 6.51E-03, Train loss: -5.23E+05, Train scatter: [0.1381 0.0472 0.2049 0.3796]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1443 0.0473 0.2105 0.381 ], Lowest was [0.0962 0.0341 0.1934 0.3507]
Median for last 10 epochs: [0.1005 0.0344 0.1941 0.3526], Epochs since improvement 2
 49%|████▉     | 247/500 [5:18:12<5:13:36, 74.37s/it] 50%|████▉     | 248/500 [5:19:43<5:33:27, 79.40s/it]Epoch: 248 done with learning rate 6.44E-03, Train loss: -5.80E+05, Train scatter: [0.097  0.0349 0.1877 0.353 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1015 0.0364 0.1958 0.3554], Lowest was [0.0962 0.0341 0.1934 0.3507]
Median for last 10 epochs: [0.1005 0.0344 0.1941 0.3526], Epochs since improvement 4
 50%|████▉     | 249/500 [5:20:45<5:10:00, 74.10s/it]Epoch: 250 done with learning rate 6.37E-03, Train loss: -5.87E+05, Train scatter: [0.0912 0.033  0.1859 0.3503]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0974 0.0342 0.1941 0.3532], Lowest was [0.0962 0.0341 0.1934 0.3507]
Median for last 10 epochs: [0.0974 0.0344 0.1941 0.3532], Epochs since improvement 6
 50%|█████     | 250/500 [5:22:24<5:39:13, 81.41s/it] 50%|█████     | 251/500 [5:23:26<5:13:30, 75.54s/it] 50%|█████     | 252/500 [5:24:58<5:33:13, 80.62s/it]Epoch: 252 done with learning rate 6.30E-03, Train loss: -5.75E+05, Train scatter: [0.0901 0.0323 0.1846 0.3463]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.096  0.0339 0.1927 0.3489], Lowest was [0.096  0.0339 0.1927 0.3489]
Median for last 10 epochs: [0.0974 0.0342 0.1941 0.3532], Epochs since improvement 0
 51%|█████     | 253/500 [5:26:00<5:08:31, 74.94s/it] 51%|█████     | 254/500 [5:27:33<5:29:50, 80.45s/it]Epoch: 254 done with learning rate 6.23E-03, Train loss: -5.91E+05, Train scatter: [0.0903 0.0321 0.1832 0.3456]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0966 0.0339 0.1922 0.35  ], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.0974 0.0342 0.1941 0.3532], Epochs since improvement 0
 51%|█████     | 255/500 [5:28:35<5:05:26, 74.80s/it] 51%|█████     | 256/500 [5:30:07<5:25:11, 79.97s/it]Epoch: 256 done with learning rate 6.15E-03, Train loss: -5.75E+05, Train scatter: [0.0931 0.0337 0.1945 0.3597]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0983 0.0345 0.2006 0.3604], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.0974 0.0342 0.1941 0.3532], Epochs since improvement 2
 51%|█████▏    | 257/500 [5:31:09<5:02:01, 74.57s/it] 52%|█████▏    | 258/500 [5:32:40<5:21:33, 79.73s/it]Epoch: 258 done with learning rate 6.08E-03, Train loss: -6.00E+05, Train scatter: [0.0978 0.0337 0.1886 0.3555]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1042 0.0351 0.1958 0.3586], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.0974 0.0342 0.1941 0.3532], Epochs since improvement 4
 52%|█████▏    | 259/500 [5:33:42<4:58:49, 74.40s/it]Epoch: 260 done with learning rate 6.01E-03, Train loss: -4.84E+05, Train scatter: [0.1474 0.0655 0.2926 0.4448]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1466 0.0644 0.2925 0.4313], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.0983 0.0345 0.1958 0.3586], Epochs since improvement 6
 52%|█████▏    | 260/500 [5:35:21<5:26:50, 81.71s/it] 52%|█████▏    | 261/500 [5:36:23<5:01:42, 75.74s/it] 52%|█████▏    | 262/500 [5:37:55<5:19:59, 80.67s/it]Epoch: 262 done with learning rate 5.94E-03, Train loss: -5.26E+05, Train scatter: [0.097  0.0347 0.1923 0.3606]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0991 0.0352 0.1973 0.3582], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.0991 0.0351 0.1973 0.3586], Epochs since improvement 8
 53%|█████▎    | 263/500 [5:38:57<4:56:36, 75.09s/it] 53%|█████▎    | 264/500 [5:40:28<5:14:03, 79.85s/it]Epoch: 264 done with learning rate 5.86E-03, Train loss: -5.47E+05, Train scatter: [0.0925 0.0341 0.1869 0.3534]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0967 0.035  0.1943 0.3548], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.0991 0.0351 0.1973 0.3586], Epochs since improvement 10
 53%|█████▎    | 265/500 [5:41:30<4:51:28, 74.42s/it] 53%|█████▎    | 266/500 [5:43:02<5:10:49, 79.70s/it]Epoch: 266 done with learning rate 5.79E-03, Train loss: -5.73E+05, Train scatter: [0.094  0.0329 0.1845 0.3493]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0987 0.0342 0.1925 0.3506], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.0991 0.0351 0.1958 0.3582], Epochs since improvement 12
 53%|█████▎    | 267/500 [5:44:04<4:48:36, 74.32s/it] 54%|█████▎    | 268/500 [5:45:36<5:08:22, 79.75s/it]Epoch: 268 done with learning rate 5.72E-03, Train loss: -4.65E+05, Train scatter: [0.1104 0.0422 0.2125 0.3959]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1087 0.0415 0.2136 0.3848], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.0991 0.0352 0.1973 0.3582], Epochs since improvement 14
 54%|█████▍    | 269/500 [5:46:38<4:46:15, 74.35s/it]Epoch: 270 done with learning rate 5.65E-03, Train loss: -5.38E+05, Train scatter: [0.0969 0.0345 0.1931 0.365 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1009 0.0348 0.198  0.3597], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.0991 0.035  0.1973 0.3582], Epochs since improvement 16
 54%|█████▍    | 270/500 [5:48:17<5:13:32, 81.79s/it] 54%|█████▍    | 271/500 [5:49:19<4:49:16, 75.79s/it] 54%|█████▍    | 272/500 [5:50:51<5:07:10, 80.83s/it]Epoch: 272 done with learning rate 5.57E-03, Train loss: -5.47E+05, Train scatter: [0.0937 0.0344 0.1867 0.3546]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0986 0.0351 0.1931 0.3528], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.0987 0.035  0.1943 0.3548], Epochs since improvement 18
 55%|█████▍    | 273/500 [5:51:53<4:44:22, 75.16s/it] 55%|█████▍    | 274/500 [5:53:26<5:03:08, 80.48s/it]Epoch: 274 done with learning rate 5.50E-03, Train loss: -5.77E+05, Train scatter: [0.0926 0.0333 0.187  0.3546]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.0972 0.0343 0.1936 0.3522], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.0987 0.0348 0.1936 0.3528], Epochs since improvement 20
 55%|█████▌    | 275/500 [5:54:28<4:41:20, 75.02s/it] 55%|█████▌    | 275/500 [5:56:00<4:51:17, 77.68s/it]
Epoch: 276 done with learning rate 5.42E-03, Train loss: -2.92E+05, Train scatter: [0.1894 0.0578 0.3075 0.4763]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1935 0.0581 0.308  0.4739], Lowest was [0.096  0.0339 0.1922 0.3489]
Median for last 10 epochs: [0.1009 0.0351 0.198  0.3597], Epochs since improvement 22
Exited after 276 epochs due to early stopping
21360.97 seconds spent training, 42.722 seconds per epoch. Processed 1630 trees per second
[0.19352739 0.05813364 0.30798903 0.47392786]
{'epoch_exit': 275, 'scatter_m_star': 0.19352739, 'lowest_m_star': 0.09601729, 'last20_m_star': 0.099986136, 'last10_m_star': 0.10090497, 'scatter_v_disk': 0.058133636, 'lowest_v_disk': 0.03385637, 'last20_v_disk': 0.035113662, 'last10_v_disk': 0.035120443, 'scatter_m_cold': 0.30798903, 'lowest_m_cold': 0.1921583, 'last20_m_cold': 0.19653763, 'last10_m_cold': 0.19796011, 'scatter_sfr_100': 0.47392786, 'lowest_sfr_100': 0.34893343, 'last20_sfr_100': 0.35837913, 'last10_sfr_100': 0.35967156}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0, 'l2_lambda': 0, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_axaqmq
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:27:11, 53.77s/it]  0%|          | 2/500 [02:14<9:38:57, 69.75s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.17   0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1647 0.5355 0.985 ], Lowest was [0.9196 0.1647 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1647 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:08<8:36:04, 62.30s/it]  1%|          | 4/500 [04:29<9:38:48, 70.02s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 9.05E+07, Train scatter: [0.9352 0.1434 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.1388 0.5355 0.9851], Lowest was [0.9196 0.1388 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1388 0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:23<8:49:04, 64.13s/it]  1%|          | 6/500 [06:45<9:37:45, 70.17s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.58E+07, Train scatter: [0.935  0.1144 0.5441 0.9955]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9194 0.1133 0.5355 0.9851], Lowest was [0.9194 0.1133 0.5355 0.985 ]
Median for last 10 epochs: [0.9194 0.1133 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:39<8:51:56, 64.74s/it]  2%|▏         | 8/500 [09:00<9:34:14, 70.03s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.18E+08, Train scatter: [0.9352 0.1638 0.5441 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9196 0.156  0.5355 0.985 ], Lowest was [0.9194 0.1133 0.5355 0.985 ]
Median for last 10 epochs: [0.9195 0.1261 0.5355 0.985 ], Epochs since improvement 0
  2%|▏         | 9/500 [09:54<8:50:52, 64.87s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 9.63E+07, Train scatter: [0.935  0.1469 0.544  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.9195 0.1423 0.5354 0.985 ], Lowest was [0.9194 0.1133 0.5354 0.985 ]
Median for last 10 epochs: [0.9195 0.1388 0.5355 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:22<9:49:43, 72.21s/it]  2%|▏         | 11/500 [12:16<9:02:03, 66.51s/it]  2%|▏         | 12/500 [13:37<9:38:06, 71.08s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 8.96E+07, Train scatter: [0.7524 0.1259 0.543  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7523 0.1244 0.5344 0.9851], Lowest was [0.7523 0.1133 0.5344 0.985 ]
Median for last 10 epochs: [0.9195 0.1388 0.5355 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:31<8:53:48, 65.77s/it]  3%|▎         | 14/500 [15:52<9:30:43, 70.46s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 8.37E+07, Train scatter: [0.5703 0.1125 0.5384 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5663 0.111  0.5299 0.9851], Lowest was [0.5663 0.111  0.5299 0.985 ]
Median for last 10 epochs: [0.9194 0.1244 0.5354 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [16:46<8:48:42, 65.41s/it]  3%|▎         | 16/500 [18:07<9:26:21, 70.21s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 8.05E+07, Train scatter: [0.5069 0.1057 0.5322 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5037 0.1052 0.5245 0.985 ], Lowest was [0.5037 0.1052 0.5245 0.985 ]
Median for last 10 epochs: [0.7523 0.1244 0.5344 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [19:01<8:45:37, 65.30s/it]  4%|▎         | 18/500 [20:22<9:23:24, 70.13s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.88E+07, Train scatter: [0.4051 0.0986 0.5259 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4085 0.0989 0.5182 0.985 ], Lowest was [0.4085 0.0989 0.5182 0.985 ]
Median for last 10 epochs: [0.5663 0.111  0.5299 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [21:16<8:42:20, 65.16s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.64E+07, Train scatter: [0.334  0.0931 0.4392 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3423 0.0938 0.4364 0.985 ], Lowest was [0.3423 0.0938 0.4364 0.985 ]
Median for last 10 epochs: [0.5037 0.1052 0.5245 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:44<9:35:31, 71.94s/it]  4%|▍         | 21/500 [23:37<8:50:31, 66.45s/it]  4%|▍         | 22/500 [25:00<9:26:45, 71.14s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.51E+07, Train scatter: [0.4284 0.089  0.4076 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4218 0.0899 0.4085 0.985 ], Lowest was [0.3423 0.0899 0.4085 0.985 ]
Median for last 10 epochs: [0.4218 0.0989 0.5182 0.985 ], Epochs since improvement 0
  5%|▍         | 23/500 [25:53<8:42:44, 65.75s/it]  5%|▍         | 24/500 [27:14<9:17:39, 70.29s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.44E+07, Train scatter: [0.3491 0.0862 0.3897 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.362  0.0871 0.3921 0.985 ], Lowest was [0.3423 0.0871 0.3921 0.985 ]
Median for last 10 epochs: [0.4085 0.0938 0.4364 0.985 ], Epochs since improvement 0
  5%|▌         | 25/500 [28:07<8:35:50, 65.16s/it]  5%|▌         | 26/500 [29:27<9:11:02, 69.75s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.37E+07, Train scatter: [0.3413 0.0833 0.3867 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3439 0.0842 0.3924 0.985 ], Lowest was [0.3423 0.0842 0.3921 0.985 ]
Median for last 10 epochs: [0.362  0.0899 0.4085 0.985 ], Epochs since improvement 0
  5%|▌         | 27/500 [30:20<8:30:32, 64.76s/it]  6%|▌         | 28/500 [31:41<9:07:05, 69.55s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.32E+07, Train scatter: [0.2935 0.0828 0.3696 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3093 0.0841 0.3765 0.985 ], Lowest was [0.3093 0.0841 0.3765 0.985 ]
Median for last 10 epochs: [0.3439 0.0871 0.3924 0.985 ], Epochs since improvement 0
  6%|▌         | 29/500 [32:34<8:27:16, 64.62s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.27E+07, Train scatter: [0.32   0.0801 0.3418 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3322 0.0811 0.349  0.985 ], Lowest was [0.3093 0.0811 0.349  0.985 ]
Median for last 10 epochs: [0.3439 0.0842 0.3921 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [34:02<9:21:42, 71.71s/it]  6%|▌         | 31/500 [34:55<8:36:47, 66.11s/it]  6%|▋         | 32/500 [36:15<9:08:02, 70.26s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.38E+07, Train scatter: [0.4675 0.0829 0.3601 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4677 0.0833 0.363  0.985 ], Lowest was [0.3093 0.0811 0.349  0.985 ]
Median for last 10 epochs: [0.3439 0.0841 0.3765 0.985 ], Epochs since improvement 2
  7%|▋         | 33/500 [37:08<8:26:27, 65.07s/it]  7%|▋         | 34/500 [38:28<9:00:06, 69.54s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.26E+07, Train scatter: [0.5436 0.0942 0.3788 0.9953]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.5422 0.0969 0.3802 0.985 ], Lowest was [0.3093 0.0811 0.349  0.985 ]
Median for last 10 epochs: [0.3439 0.0841 0.3765 0.985 ], Epochs since improvement 4
  7%|▋         | 35/500 [39:22<8:21:02, 64.65s/it]  7%|▋         | 36/500 [40:42<8:56:45, 69.41s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 7.18E+07, Train scatter: [0.4283 0.0778 0.324  0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4257 0.0777 0.3321 0.985 ], Lowest was [0.3093 0.0777 0.3321 0.985 ]
Median for last 10 epochs: [0.4257 0.0833 0.363  0.985 ], Epochs since improvement 0
  7%|▋         | 37/500 [41:35<8:18:02, 64.54s/it]  8%|▊         | 38/500 [42:56<8:53:14, 69.25s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 7.03E+07, Train scatter: [0.2745 0.0762 0.3203 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2885 0.0766 0.3305 0.985 ], Lowest was [0.2885 0.0766 0.3305 0.985 ]
Median for last 10 epochs: [0.4257 0.0811 0.349  0.985 ], Epochs since improvement 0
  8%|▊         | 39/500 [43:49<8:15:01, 64.43s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 5.52E+07, Train scatter: [0.2811 0.0789 0.3509 0.9954]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2988 0.0784 0.3563 0.9851], Lowest was [0.2885 0.0766 0.3305 0.985 ]
Median for last 10 epochs: [0.4257 0.0784 0.3563 0.985 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:16<9:06:07, 71.23s/it]  8%|▊         | 41/500 [46:09<8:23:23, 65.80s/it]  8%|▊         | 42/500 [47:30<8:56:21, 70.26s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.20E+07, Train scatter: [0.3306 0.095  0.4482 0.6481]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3577 0.0997 0.4561 0.6447], Lowest was [0.2885 0.0766 0.3305 0.6447]
Median for last 10 epochs: [0.3577 0.0784 0.3563 0.985 ], Epochs since improvement 0
  9%|▊         | 43/500 [48:23<8:15:55, 65.11s/it]  9%|▉         | 44/500 [49:44<8:50:59, 69.87s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 4.67E+06, Train scatter: [0.2525 0.0753 0.3216 0.5759]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2688 0.0752 0.3296 0.5799], Lowest was [0.2688 0.0752 0.3296 0.5799]
Median for last 10 epochs: [0.2988 0.0777 0.3321 0.985 ], Epochs since improvement 0
  9%|▉         | 45/500 [50:37<8:11:20, 64.79s/it]  9%|▉         | 46/500 [51:58<8:48:29, 69.84s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 5.17E+06, Train scatter: [0.2433 0.0753 0.3255 0.5338]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2593 0.0758 0.332  0.534 ], Lowest was [0.2593 0.0752 0.3296 0.534 ]
Median for last 10 epochs: [0.2885 0.0766 0.332  0.6447], Epochs since improvement 0
  9%|▉         | 47/500 [52:51<8:09:19, 64.81s/it] 10%|▉         | 48/500 [54:12<8:43:36, 69.51s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.76E+06, Train scatter: [0.232  0.0732 0.314  0.5141]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.248  0.0727 0.3182 0.5135], Lowest was [0.248  0.0727 0.3182 0.5135]
Median for last 10 epochs: [0.2688 0.0758 0.332  0.5799], Epochs since improvement 0
 10%|▉         | 49/500 [55:05<8:05:17, 64.56s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.43E+06, Train scatter: [0.2413 0.0739 0.3247 0.5239]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2553 0.0734 0.3337 0.525 ], Lowest was [0.248  0.0727 0.3182 0.5135]
Median for last 10 epochs: [0.2593 0.0752 0.332  0.534 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [56:32<8:54:41, 71.29s/it] 10%|█         | 51/500 [57:25<8:12:32, 65.82s/it] 10%|█         | 52/500 [58:46<8:45:12, 70.34s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.28E+06, Train scatter: [0.2616 0.0721 0.3376 0.504 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2746 0.073  0.3446 0.5027], Lowest was [0.248  0.0727 0.3182 0.5027]
Median for last 10 epochs: [0.2593 0.0734 0.332  0.525 ], Epochs since improvement 0
 11%|█         | 53/500 [59:39<8:05:24, 65.16s/it] 11%|█         | 54/500 [1:00:59<8:38:18, 69.73s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.22E+06, Train scatter: [0.2169 0.0679 0.2987 0.4858]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2397 0.0674 0.3035 0.4824], Lowest was [0.2397 0.0674 0.3035 0.4824]
Median for last 10 epochs: [0.2553 0.073  0.332  0.5135], Epochs since improvement 0
 11%|█         | 55/500 [1:01:52<8:00:11, 64.74s/it] 11%|█         | 56/500 [1:03:13<8:34:48, 69.57s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.16E+06, Train scatter: [0.2234 0.0668 0.2936 0.4807]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2474 0.0674 0.3013 0.4826], Lowest was [0.2397 0.0674 0.3013 0.4824]
Median for last 10 epochs: [0.248  0.0727 0.3182 0.5027], Epochs since improvement 0
 11%|█▏        | 57/500 [1:04:06<7:56:58, 64.60s/it] 12%|█▏        | 58/500 [1:05:26<8:30:38, 69.32s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.85E+06, Train scatter: [0.2919 0.0675 0.2965 0.4831]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3109 0.0673 0.2998 0.4833], Lowest was [0.2397 0.0673 0.2998 0.4824]
Median for last 10 epochs: [0.2553 0.0674 0.3035 0.4833], Epochs since improvement 0
 12%|█▏        | 59/500 [1:06:20<7:53:39, 64.44s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.90E+06, Train scatter: [0.2152 0.0664 0.2941 0.4711]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2275 0.0669 0.3011 0.475 ], Lowest was [0.2275 0.0669 0.2998 0.475 ]
Median for last 10 epochs: [0.2474 0.0674 0.3013 0.4826], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:07:48<8:45:31, 71.66s/it] 12%|█▏        | 61/500 [1:08:41<8:03:21, 66.06s/it] 12%|█▏        | 62/500 [1:10:02<8:34:16, 70.45s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.04E+06, Train scatter: [0.2344 0.067  0.2927 0.473 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.248  0.0674 0.2992 0.4766], Lowest was [0.2275 0.0669 0.2992 0.475 ]
Median for last 10 epochs: [0.2474 0.0674 0.3011 0.4824], Epochs since improvement 0
 13%|█▎        | 63/500 [1:10:55<7:55:06, 65.23s/it] 13%|█▎        | 64/500 [1:12:15<8:27:35, 69.85s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.63E+06, Train scatter: [0.2187 0.0646 0.3022 0.4745]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2356 0.065  0.3045 0.4784], Lowest was [0.2275 0.065  0.2992 0.475 ]
Median for last 10 epochs: [0.2474 0.0673 0.3011 0.4784], Epochs since improvement 0
 13%|█▎        | 65/500 [1:13:08<7:49:44, 64.79s/it] 13%|█▎        | 66/500 [1:14:29<8:22:23, 69.46s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.82E+06, Train scatter: [0.2213 0.065  0.3064 0.4813]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2335 0.0654 0.313  0.4841], Lowest was [0.2275 0.065  0.2992 0.475 ]
Median for last 10 epochs: [0.2356 0.0669 0.3011 0.4784], Epochs since improvement 2
 13%|█▎        | 67/500 [1:15:22<7:45:34, 64.51s/it] 14%|█▎        | 68/500 [1:16:42<8:18:07, 69.19s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.99E+06, Train scatter: [0.218  0.0664 0.4187 0.4684]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2399 0.0667 0.4113 0.4711], Lowest was [0.2275 0.065  0.2992 0.4711]
Median for last 10 epochs: [0.2356 0.0667 0.3045 0.4766], Epochs since improvement 0
 14%|█▍        | 69/500 [1:17:35<7:42:01, 64.32s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 2.59E+06, Train scatter: [0.2334 0.0659 0.3182 0.4877]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2627 0.0666 0.334  0.5004], Lowest was [0.2275 0.065  0.2992 0.4711]
Median for last 10 epochs: [0.2399 0.0666 0.313  0.4784], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:19:02<8:30:02, 71.17s/it] 14%|█▍        | 71/500 [1:19:55<7:50:54, 65.86s/it] 14%|█▍        | 72/500 [1:21:16<8:20:18, 70.14s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 2.43E+06, Train scatter: [0.2302 0.063  0.2914 0.4661]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2555 0.0639 0.2952 0.4707], Lowest was [0.2275 0.0639 0.2952 0.4707]
Median for last 10 epochs: [0.2399 0.0654 0.313  0.4784], Epochs since improvement 0
 15%|█▍        | 73/500 [1:22:09<7:43:02, 65.06s/it] 15%|█▍        | 74/500 [1:23:30<8:16:13, 69.89s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.42E+06, Train scatter: [0.2087 0.0604 0.2845 0.457 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2297 0.0608 0.2877 0.4602], Lowest was [0.2275 0.0608 0.2877 0.4602]
Median for last 10 epochs: [0.2399 0.0654 0.313  0.4711], Epochs since improvement 0
 15%|█▌        | 75/500 [1:24:23<7:39:42, 64.90s/it] 15%|█▌        | 76/500 [1:25:44<8:11:33, 69.56s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.51E+06, Train scatter: [0.2095 0.0611 0.2805 0.4569]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2322 0.0616 0.2834 0.4599], Lowest was [0.2275 0.0608 0.2834 0.4599]
Median for last 10 epochs: [0.2399 0.0639 0.2952 0.4707], Epochs since improvement 0
 15%|█▌        | 77/500 [1:26:37<7:36:10, 64.71s/it] 16%|█▌        | 78/500 [1:27:58<8:09:30, 69.60s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.35E+06, Train scatter: [0.2433 0.0668 0.2782 0.4727]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2689 0.067  0.2817 0.475 ], Lowest was [0.2275 0.0608 0.2817 0.4599]
Median for last 10 epochs: [0.2555 0.0639 0.2877 0.4707], Epochs since improvement 0
 16%|█▌        | 79/500 [1:28:51<7:33:52, 64.69s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.74E+06, Train scatter: [0.2936 0.0685 0.3084 0.4837]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3137 0.0683 0.3095 0.4866], Lowest was [0.2275 0.0608 0.2817 0.4599]
Median for last 10 epochs: [0.2555 0.0639 0.2877 0.4707], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:30:19<8:22:02, 71.72s/it] 16%|█▌        | 81/500 [1:31:13<7:42:17, 66.20s/it] 16%|█▋        | 82/500 [1:32:34<8:13:00, 70.77s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 4.17E+06, Train scatter: [0.2617 0.0664 0.3049 0.4988]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2752 0.0668 0.3055 0.4979], Lowest was [0.2275 0.0608 0.2817 0.4599]
Median for last 10 epochs: [0.2689 0.0668 0.2877 0.475 ], Epochs since improvement 4
 17%|█▋        | 83/500 [1:33:27<7:35:10, 65.49s/it] 17%|█▋        | 84/500 [1:34:48<8:04:53, 69.94s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.61E+06, Train scatter: [0.31   0.0624 0.301  0.5026]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3174 0.0624 0.3018 0.5018], Lowest was [0.2275 0.0608 0.2817 0.4599]
Median for last 10 epochs: [0.2752 0.0668 0.3018 0.4866], Epochs since improvement 6
 17%|█▋        | 85/500 [1:35:41<7:29:00, 64.92s/it] 17%|█▋        | 86/500 [1:37:01<7:59:28, 69.49s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.43E+06, Train scatter: [0.2256 0.0642 0.2904 0.4695]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2374 0.0657 0.2947 0.4722], Lowest was [0.2275 0.0608 0.2817 0.4599]
Median for last 10 epochs: [0.2752 0.0668 0.3018 0.4866], Epochs since improvement 8
 17%|█▋        | 87/500 [1:37:54<7:24:52, 64.63s/it] 18%|█▊        | 88/500 [1:39:14<7:55:38, 69.27s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.31E+06, Train scatter: [0.2391 0.061  0.2941 0.4861]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2531 0.0619 0.2938 0.4871], Lowest was [0.2275 0.0608 0.2817 0.4599]
Median for last 10 epochs: [0.2752 0.0657 0.3018 0.4871], Epochs since improvement 10
 18%|█▊        | 89/500 [1:40:07<7:21:22, 64.43s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.23E+06, Train scatter: [0.2325 0.0603 0.29   0.4652]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2503 0.0623 0.2893 0.4684], Lowest was [0.2275 0.0608 0.2817 0.4599]
Median for last 10 epochs: [0.2531 0.0624 0.2947 0.4871], Epochs since improvement 12
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:41:35<8:08:27, 71.48s/it] 18%|█▊        | 91/500 [1:42:29<7:30:07, 66.03s/it] 18%|█▊        | 92/500 [1:43:49<7:58:51, 70.42s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.26E+06, Train scatter: [0.2444 0.0633 0.3037 0.4832]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.257  0.0627 0.303  0.479 ], Lowest was [0.2275 0.0608 0.2817 0.4599]
Median for last 10 epochs: [0.2531 0.0624 0.2947 0.479 ], Epochs since improvement 14
 19%|█▊        | 93/500 [1:44:43<7:22:40, 65.26s/it] 19%|█▉        | 94/500 [1:46:03<7:52:36, 69.84s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.15E+06, Train scatter: [0.2074 0.0583 0.2973 0.4615]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2261 0.0585 0.3007 0.462 ], Lowest was [0.2261 0.0585 0.2817 0.4599]
Median for last 10 epochs: [0.2503 0.0623 0.2947 0.4722], Epochs since improvement 0
 19%|█▉        | 95/500 [1:46:56<7:17:49, 64.86s/it] 19%|█▉        | 96/500 [1:48:17<7:48:48, 69.63s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.10E+06, Train scatter: [0.2593 0.0583 0.2688 0.4457]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2692 0.0582 0.2717 0.4461], Lowest was [0.2261 0.0582 0.2717 0.4461]
Median for last 10 epochs: [0.2531 0.0619 0.2938 0.4684], Epochs since improvement 0
 19%|█▉        | 97/500 [1:49:10<7:14:22, 64.67s/it] 20%|█▉        | 98/500 [1:50:31<7:45:08, 69.42s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.04E+06, Train scatter: [0.2677 0.0562 0.2748 0.4515]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2854 0.0572 0.276  0.4522], Lowest was [0.2261 0.0572 0.2717 0.4461]
Median for last 10 epochs: [0.257  0.0585 0.2893 0.462 ], Epochs since improvement 0
 20%|█▉        | 99/500 [1:51:24<7:11:25, 64.55s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 1.97E+06, Train scatter: [0.2204 0.0589 0.2625 0.4448]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.248  0.0606 0.2641 0.4463], Lowest was [0.2261 0.0572 0.2641 0.4461]
Median for last 10 epochs: [0.257  0.0585 0.276  0.4522], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:52:52<7:56:58, 71.55s/it] 20%|██        | 101/500 [1:53:45<7:19:12, 66.05s/it] 20%|██        | 102/500 [1:55:06<7:47:42, 70.51s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 1.88E+06, Train scatter: [0.2074 0.0568 0.2799 0.4405]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2358 0.0568 0.2844 0.4423], Lowest was [0.2261 0.0568 0.2641 0.4423]
Median for last 10 epochs: [0.248  0.0582 0.276  0.4463], Epochs since improvement 0
 21%|██        | 103/500 [1:55:59<7:12:15, 65.33s/it] 21%|██        | 104/500 [1:57:20<7:41:36, 69.94s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 1.71E+06, Train scatter: [0.2177 0.0603 0.2838 0.4585]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2362 0.0617 0.2897 0.4649], Lowest was [0.2261 0.0568 0.2641 0.4423]
Median for last 10 epochs: [0.248  0.0582 0.276  0.4463], Epochs since improvement 2
 21%|██        | 105/500 [1:58:13<7:07:55, 65.00s/it] 21%|██        | 106/500 [1:59:34<7:37:19, 69.64s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 1.63E+06, Train scatter: [0.2092 0.0556 0.2615 0.4396]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2325 0.0554 0.265  0.4405], Lowest was [0.2261 0.0554 0.2641 0.4405]
Median for last 10 epochs: [0.2362 0.0572 0.276  0.4463], Epochs since improvement 0
 21%|██▏       | 107/500 [2:00:27<7:03:54, 64.72s/it] 22%|██▏       | 108/500 [2:01:47<7:33:22, 69.39s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 1.60E+06, Train scatter: [0.2444 0.0656 0.2648 0.4441]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2615 0.0651 0.2665 0.4421], Lowest was [0.2261 0.0554 0.2641 0.4405]
Median for last 10 epochs: [0.2362 0.0606 0.2665 0.4423], Epochs since improvement 2
 22%|██▏       | 109/500 [2:02:41<7:00:37, 64.55s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 1.46E+06, Train scatter: [0.1951 0.0551 0.252  0.4319]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2135 0.0551 0.2566 0.4354], Lowest was [0.2135 0.0551 0.2566 0.4354]
Median for last 10 epochs: [0.2358 0.0568 0.2665 0.4421], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:04:10<7:48:00, 72.00s/it] 22%|██▏       | 111/500 [2:05:04<7:10:53, 66.46s/it] 22%|██▏       | 112/500 [2:06:25<7:38:07, 70.84s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.48E+06, Train scatter: [0.2208 0.0585 0.2565 0.4296]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2408 0.0588 0.2608 0.4309], Lowest was [0.2135 0.0551 0.2566 0.4309]
Median for last 10 epochs: [0.2362 0.0588 0.265  0.4405], Epochs since improvement 0
 23%|██▎       | 113/500 [2:07:18<7:02:56, 65.57s/it] 23%|██▎       | 114/500 [2:08:39<7:31:46, 70.22s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.35E+06, Train scatter: [0.2161 0.0557 0.248  0.4298]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2305 0.0559 0.2535 0.4308], Lowest was [0.2135 0.0551 0.2535 0.4308]
Median for last 10 epochs: [0.2325 0.0559 0.2608 0.4354], Epochs since improvement 0
 23%|██▎       | 115/500 [2:09:32<6:57:54, 65.13s/it] 23%|██▎       | 116/500 [2:10:54<7:28:10, 70.03s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.38E+06, Train scatter: [0.238  0.0587 0.2615 0.422 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2479 0.0591 0.2654 0.4216], Lowest was [0.2135 0.0551 0.2535 0.4216]
Median for last 10 epochs: [0.2408 0.0588 0.2608 0.4309], Epochs since improvement 0
 23%|██▎       | 117/500 [2:11:47<6:55:22, 65.07s/it] 24%|██▎       | 118/500 [2:13:07<7:23:01, 69.58s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.30E+06, Train scatter: [0.1909 0.0517 0.2512 0.4226]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.214  0.0522 0.2544 0.425 ], Lowest was [0.2135 0.0522 0.2535 0.4216]
Median for last 10 epochs: [0.2305 0.0559 0.2566 0.4308], Epochs since improvement 0
 24%|██▍       | 119/500 [2:14:01<6:51:02, 64.73s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.27E+06, Train scatter: [0.2209 0.0609 0.2525 0.4631]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2369 0.0628 0.2592 0.4633], Lowest was [0.2135 0.0522 0.2535 0.4216]
Median for last 10 epochs: [0.2369 0.0588 0.2592 0.4308], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 24%|██▍       | 120/500 [2:15:29<7:33:57, 71.68s/it] 24%|██▍       | 121/500 [2:16:22<6:58:03, 66.18s/it] 24%|██▍       | 122/500 [2:17:42<7:23:57, 70.47s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 1.26E+06, Train scatter: [0.1759 0.0511 0.2571 0.4178]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1943 0.0517 0.2592 0.4197], Lowest was [0.1943 0.0517 0.2535 0.4197]
Median for last 10 epochs: [0.2305 0.0559 0.2592 0.425 ], Epochs since improvement 0
 25%|██▍       | 123/500 [2:18:36<6:50:25, 65.32s/it] 25%|██▍       | 124/500 [2:19:56<7:17:58, 69.89s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.36E+06, Train scatter: [0.1826 0.0517 0.2572 0.4215]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.201  0.0515 0.2609 0.4228], Lowest was [0.1943 0.0515 0.2535 0.4197]
Median for last 10 epochs: [0.214  0.0522 0.2592 0.4228], Epochs since improvement 0
 25%|██▌       | 125/500 [2:20:50<6:45:45, 64.92s/it] 25%|██▌       | 126/500 [2:22:11<7:15:29, 69.86s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.15E+06, Train scatter: [0.1927 0.0537 0.2602 0.4261]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2084 0.0543 0.2647 0.4316], Lowest was [0.1943 0.0515 0.2535 0.4197]
Median for last 10 epochs: [0.2084 0.0522 0.2592 0.425 ], Epochs since improvement 2
 25%|██▌       | 127/500 [2:23:04<6:43:51, 64.96s/it] 26%|██▌       | 128/500 [2:24:26<7:12:39, 69.78s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 1.04E+06, Train scatter: [0.168  0.0492 0.2474 0.4154]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1891 0.0495 0.2511 0.4185], Lowest was [0.1891 0.0495 0.2511 0.4185]
Median for last 10 epochs: [0.201  0.0517 0.2592 0.4228], Epochs since improvement 0
 26%|██▌       | 129/500 [2:25:19<6:41:10, 64.88s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 9.28E+05, Train scatter: [0.2001 0.051  0.2483 0.4099]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2164 0.0509 0.2524 0.4123], Lowest was [0.1891 0.0495 0.2511 0.4123]
Median for last 10 epochs: [0.201  0.0515 0.2592 0.4197], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 26%|██▌       | 130/500 [2:26:47<7:23:02, 71.84s/it] 26%|██▌       | 131/500 [2:27:40<6:47:44, 66.30s/it] 26%|██▋       | 132/500 [2:29:01<7:13:10, 70.63s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 9.00E+05, Train scatter: [0.1853 0.0521 0.2523 0.4167]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1971 0.0531 0.255  0.4172], Lowest was [0.1891 0.0495 0.2511 0.4123]
Median for last 10 epochs: [0.201  0.0515 0.255  0.4185], Epochs since improvement 2
 27%|██▋       | 133/500 [2:29:54<6:40:08, 65.42s/it] 27%|██▋       | 134/500 [2:31:15<7:06:19, 69.89s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 8.89E+05, Train scatter: [0.163  0.048  0.2412 0.4039]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1805 0.0481 0.2428 0.4036], Lowest was [0.1805 0.0481 0.2428 0.4036]
Median for last 10 epochs: [0.1971 0.0509 0.2524 0.4172], Epochs since improvement 0
 27%|██▋       | 135/500 [2:32:08<6:34:42, 64.88s/it] 27%|██▋       | 136/500 [2:33:28<7:01:32, 69.49s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 8.53E+05, Train scatter: [0.1799 0.0521 0.2582 0.4199]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.194  0.0523 0.26   0.4206], Lowest was [0.1805 0.0481 0.2428 0.4036]
Median for last 10 epochs: [0.194  0.0509 0.2524 0.4172], Epochs since improvement 2
 27%|██▋       | 137/500 [2:34:22<6:31:20, 64.69s/it] 28%|██▊       | 138/500 [2:35:41<6:57:41, 69.23s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: 8.17E+05, Train scatter: [0.1682 0.0508 0.2434 0.402 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1852 0.0508 0.2464 0.4024], Lowest was [0.1805 0.0481 0.2428 0.4024]
Median for last 10 epochs: [0.194  0.0509 0.2524 0.4123], Epochs since improvement 0
 28%|██▊       | 139/500 [2:36:35<6:28:14, 64.53s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: 7.81E+05, Train scatter: [0.1632 0.0519 0.2499 0.4054]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1771 0.0523 0.2526 0.4048], Lowest was [0.1771 0.0481 0.2428 0.4024]
Median for last 10 epochs: [0.1852 0.0523 0.2526 0.4048], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 28%|██▊       | 140/500 [2:38:02<7:08:14, 71.37s/it] 28%|██▊       | 141/500 [2:38:56<6:35:08, 66.04s/it] 28%|██▊       | 142/500 [2:40:17<7:00:22, 70.45s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: 7.48E+05, Train scatter: [0.1619 0.0504 0.263  0.4189]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1761 0.0503 0.2632 0.4118], Lowest was [0.1761 0.0481 0.2428 0.4024]
Median for last 10 epochs: [0.1805 0.0508 0.2526 0.4048], Epochs since improvement 0
 29%|██▊       | 143/500 [2:41:10<6:28:22, 65.27s/it] 29%|██▉       | 144/500 [2:42:31<6:54:34, 69.87s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 7.14E+05, Train scatter: [0.1552 0.0508 0.2494 0.4073]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1712 0.0512 0.2522 0.4093], Lowest was [0.1712 0.0481 0.2428 0.4024]
Median for last 10 epochs: [0.1771 0.0512 0.2526 0.4093], Epochs since improvement 0
 29%|██▉       | 145/500 [2:43:24<6:24:01, 64.90s/it] 29%|██▉       | 146/500 [2:44:44<6:49:55, 69.48s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 6.86E+05, Train scatter: [0.1553 0.049  0.2459 0.4058]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1726 0.0494 0.248  0.4025], Lowest was [0.1712 0.0481 0.2428 0.4024]
Median for last 10 epochs: [0.1761 0.0508 0.2522 0.4048], Epochs since improvement 2
 29%|██▉       | 147/500 [2:45:37<6:19:59, 64.59s/it] 30%|██▉       | 148/500 [2:46:57<6:45:50, 69.18s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 6.89E+05, Train scatter: [0.1981 0.0515 0.2555 0.4259]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2189 0.0516 0.2608 0.4295], Lowest was [0.1712 0.0481 0.2428 0.4024]
Median for last 10 epochs: [0.1761 0.0512 0.2526 0.4093], Epochs since improvement 4
 30%|██▉       | 149/500 [2:47:51<6:17:07, 64.47s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 5.94E+05, Train scatter: [0.1531 0.0463 0.2431 0.398 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1653 0.0468 0.247  0.395 ], Lowest was [0.1653 0.0468 0.2428 0.395 ]
Median for last 10 epochs: [0.1726 0.0503 0.2522 0.4093], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 30%|███       | 150/500 [2:49:17<6:55:17, 71.19s/it] 30%|███       | 151/500 [2:50:11<6:22:50, 65.82s/it] 30%|███       | 152/500 [2:51:31<6:46:52, 70.15s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 5.72E+05, Train scatter: [0.1812 0.0512 0.2536 0.4222]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.19   0.0509 0.257  0.4248], Lowest was [0.1653 0.0468 0.2428 0.395 ]
Median for last 10 epochs: [0.1726 0.0509 0.2522 0.4093], Epochs since improvement 2
 31%|███       | 153/500 [2:52:24<6:16:24, 65.08s/it] 31%|███       | 154/500 [2:53:46<6:43:25, 69.96s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 5.06E+05, Train scatter: [0.166  0.048  0.2375 0.4008]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1783 0.0485 0.2388 0.4004], Lowest was [0.1653 0.0468 0.2388 0.395 ]
Median for last 10 epochs: [0.1783 0.0494 0.248  0.4025], Epochs since improvement 0
 31%|███       | 155/500 [2:54:39<6:13:29, 64.95s/it] 31%|███       | 156/500 [2:55:59<6:38:42, 69.54s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 4.76E+05, Train scatter: [0.1534 0.0457 0.2445 0.4003]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1702 0.0457 0.2484 0.4034], Lowest was [0.1653 0.0457 0.2388 0.395 ]
Median for last 10 epochs: [0.1783 0.0485 0.2484 0.4034], Epochs since improvement 0
 31%|███▏      | 157/500 [2:56:53<6:09:56, 64.71s/it] 32%|███▏      | 158/500 [2:58:12<6:34:56, 69.29s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 4.21E+05, Train scatter: [0.1477 0.0487 0.2614 0.4115]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1585 0.0489 0.2654 0.4159], Lowest was [0.1585 0.0457 0.2388 0.395 ]
Median for last 10 epochs: [0.1702 0.0485 0.2484 0.4034], Epochs since improvement 0
 32%|███▏      | 159/500 [2:59:06<6:06:21, 64.46s/it]Epoch: 160 done with learning rate 9.04E-03, Train loss: 7.80E+05, Train scatter: [0.2434 0.063  0.3527 0.4513]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2677 0.0631 0.3547 0.4514], Lowest was [0.1585 0.0457 0.2388 0.395 ]
Median for last 10 epochs: [0.1783 0.0489 0.257  0.4159], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 32%|███▏      | 160/500 [3:00:34<6:45:21, 71.53s/it] 32%|███▏      | 161/500 [3:01:27<6:13:15, 66.06s/it] 32%|███▏      | 162/500 [3:02:48<6:37:56, 70.64s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: 4.33E+05, Train scatter: [0.1958 0.0552 0.2753 0.4246]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2107 0.0556 0.2805 0.4269], Lowest was [0.1585 0.0457 0.2388 0.395 ]
Median for last 10 epochs: [0.1783 0.0489 0.2654 0.4159], Epochs since improvement 4
 33%|███▎      | 163/500 [3:03:41<6:07:20, 65.40s/it] 33%|███▎      | 164/500 [3:05:03<6:33:09, 70.21s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: 3.03E+05, Train scatter: [0.1564 0.0493 0.2609 0.4089]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1697 0.0496 0.2626 0.4077], Lowest was [0.1585 0.0457 0.2388 0.395 ]
Median for last 10 epochs: [0.1702 0.0496 0.2654 0.4159], Epochs since improvement 6
 33%|███▎      | 165/500 [3:05:56<6:03:36, 65.12s/it] 33%|███▎      | 166/500 [3:07:17<6:29:21, 69.94s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: 1.91E+05, Train scatter: [0.1594 0.0505 0.2662 0.42  ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1753 0.0507 0.266  0.4123], Lowest was [0.1585 0.0457 0.2388 0.395 ]
Median for last 10 epochs: [0.1753 0.0507 0.266  0.4159], Epochs since improvement 8
 33%|███▎      | 167/500 [3:08:11<6:00:18, 64.92s/it] 34%|███▎      | 168/500 [3:09:32<6:26:35, 69.86s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: 1.01E+05, Train scatter: [0.1404 0.0476 0.2515 0.3997]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1463 0.0475 0.2541 0.3972], Lowest was [0.1463 0.0457 0.2388 0.395 ]
Median for last 10 epochs: [0.1753 0.0507 0.266  0.4123], Epochs since improvement 0
 34%|███▍      | 169/500 [3:10:25<5:58:14, 64.94s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: 2.15E+04, Train scatter: [0.1578 0.05   0.258  0.4134]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1647 0.05   0.263  0.4156], Lowest was [0.1463 0.0457 0.2388 0.395 ]
Median for last 10 epochs: [0.1697 0.05   0.263  0.4123], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 34%|███▍      | 170/500 [3:11:53<6:34:16, 71.69s/it] 34%|███▍      | 171/500 [3:12:46<6:03:01, 66.21s/it] 34%|███▍      | 172/500 [3:14:07<6:26:32, 70.71s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -6.28E+04, Train scatter: [0.14   0.0456 0.2574 0.3982]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1579 0.0462 0.2636 0.3955], Lowest was [0.1463 0.0457 0.2388 0.395 ]
Median for last 10 epochs: [0.1647 0.0496 0.263  0.4077], Epochs since improvement 4
 35%|███▍      | 173/500 [3:15:01<5:56:42, 65.45s/it] 35%|███▍      | 174/500 [3:16:21<6:19:22, 69.82s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -1.13E+05, Train scatter: [0.1363 0.0462 0.2373 0.3906]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1434 0.046  0.2391 0.3875], Lowest was [0.1434 0.0457 0.2388 0.3875]
Median for last 10 epochs: [0.1579 0.0475 0.263  0.3972], Epochs since improvement 0
 35%|███▌      | 175/500 [3:17:14<5:51:07, 64.82s/it] 35%|███▌      | 176/500 [3:18:35<6:15:59, 69.63s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -1.27E+05, Train scatter: [0.1541 0.0462 0.2321 0.3983]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1781 0.046  0.2342 0.3905], Lowest was [0.1434 0.0457 0.2342 0.3875]
Median for last 10 epochs: [0.1579 0.0462 0.2541 0.3955], Epochs since improvement 0
 35%|███▌      | 177/500 [3:19:28<5:48:30, 64.74s/it] 36%|███▌      | 178/500 [3:20:48<6:11:51, 69.29s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -2.09E+05, Train scatter: [0.1594 0.0445 0.2311 0.3972]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1629 0.0448 0.2333 0.3945], Lowest was [0.1434 0.0448 0.2333 0.3875]
Median for last 10 epochs: [0.1629 0.046  0.2391 0.3945], Epochs since improvement 0
 36%|███▌      | 179/500 [3:21:41<5:44:54, 64.47s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -2.53E+05, Train scatter: [0.13   0.0429 0.2241 0.395 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1402 0.043  0.2266 0.3887], Lowest was [0.1402 0.043  0.2266 0.3875]
Median for last 10 epochs: [0.1579 0.046  0.2342 0.3905], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 36%|███▌      | 180/500 [3:23:09<6:20:32, 71.35s/it] 36%|███▌      | 181/500 [3:24:02<5:50:37, 65.95s/it] 36%|███▋      | 182/500 [3:25:23<6:13:43, 70.51s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -2.85E+05, Train scatter: [0.1447 0.0484 0.2349 0.4082]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1464 0.0479 0.2379 0.4011], Lowest was [0.1402 0.043  0.2266 0.3875]
Median for last 10 epochs: [0.1464 0.046  0.2342 0.3905], Epochs since improvement 2
 37%|███▋      | 183/500 [3:26:17<5:45:33, 65.40s/it] 37%|███▋      | 184/500 [3:27:37<6:08:38, 69.99s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -3.03E+05, Train scatter: [0.2046 0.0607 0.2522 0.416 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2048 0.0594 0.2531 0.4102], Lowest was [0.1402 0.043  0.2266 0.3875]
Median for last 10 epochs: [0.1629 0.046  0.2342 0.3945], Epochs since improvement 4
 37%|███▋      | 185/500 [3:28:31<5:41:27, 65.04s/it] 37%|███▋      | 186/500 [3:29:51<6:03:48, 69.52s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -3.20E+05, Train scatter: [0.1371 0.0415 0.2205 0.3863]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1435 0.0415 0.2243 0.3828], Lowest was [0.1402 0.0415 0.2243 0.3828]
Median for last 10 epochs: [0.1464 0.0448 0.2333 0.3945], Epochs since improvement 0
 37%|███▋      | 187/500 [3:30:44<5:37:12, 64.64s/it] 38%|███▊      | 188/500 [3:32:05<6:01:30, 69.52s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -3.54E+05, Train scatter: [0.1307 0.0446 0.2307 0.3889]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1359 0.0449 0.2362 0.3897], Lowest was [0.1359 0.0415 0.2243 0.3828]
Median for last 10 epochs: [0.1435 0.0449 0.2362 0.3897], Epochs since improvement 0
 38%|███▊      | 189/500 [3:32:58<5:35:20, 64.70s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -3.41E+05, Train scatter: [0.1298 0.0418 0.223  0.3828]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.133  0.0419 0.2278 0.382 ], Lowest was [0.133  0.0415 0.2243 0.382 ]
Median for last 10 epochs: [0.1435 0.0449 0.2362 0.3897], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 38%|███▊      | 190/500 [3:34:28<6:13:18, 72.25s/it] 38%|███▊      | 191/500 [3:35:22<5:43:03, 66.61s/it] 38%|███▊      | 192/500 [3:36:42<6:03:41, 70.85s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -3.74E+05, Train scatter: [0.1551 0.0413 0.2196 0.3968]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1748 0.0412 0.2222 0.389 ], Lowest was [0.133  0.0412 0.2222 0.382 ]
Median for last 10 epochs: [0.1435 0.0419 0.2278 0.389 ], Epochs since improvement 0
 39%|███▊      | 193/500 [3:37:36<5:35:38, 65.60s/it] 39%|███▉      | 194/500 [3:38:58<5:59:44, 70.54s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -3.82E+05, Train scatter: [0.1583 0.0536 0.2482 0.3988]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1624 0.0537 0.2474 0.395 ], Lowest was [0.133  0.0412 0.2222 0.382 ]
Median for last 10 epochs: [0.1435 0.0419 0.2278 0.389 ], Epochs since improvement 2
 39%|███▉      | 195/500 [3:39:51<5:32:14, 65.36s/it] 39%|███▉      | 196/500 [3:41:12<5:55:31, 70.17s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -3.92E+05, Train scatter: [0.1287 0.0434 0.2146 0.3808]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.133  0.0431 0.2176 0.3789], Lowest was [0.133  0.0412 0.2176 0.3789]
Median for last 10 epochs: [0.1359 0.0431 0.2278 0.389 ], Epochs since improvement 0
 39%|███▉      | 197/500 [3:42:06<5:28:47, 65.11s/it] 40%|███▉      | 198/500 [3:43:28<5:52:53, 70.11s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -3.99E+05, Train scatter: [0.1277 0.0414 0.215  0.3838]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1324 0.041  0.2169 0.3803], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.133  0.0419 0.2222 0.382 ], Epochs since improvement 0
 40%|███▉      | 199/500 [3:44:21<5:26:34, 65.10s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -3.87E+04, Train scatter: [0.7275 0.1257 0.53   0.7408]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.7194 0.1226 0.5219 0.733 ], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.1624 0.0431 0.2222 0.389 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 40%|████      | 200/500 [3:45:49<6:00:27, 72.09s/it] 40%|████      | 201/500 [3:46:43<5:31:27, 66.51s/it] 40%|████      | 202/500 [3:48:04<5:51:36, 70.80s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -1.78E+05, Train scatter: [0.4439 0.0717 0.389  0.521 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.4406 0.0716 0.386  0.5136], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.1624 0.0537 0.2474 0.395 ], Epochs since improvement 4
 41%|████      | 203/500 [3:48:57<5:24:34, 65.57s/it] 41%|████      | 204/500 [3:50:18<5:46:19, 70.20s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -2.67E+05, Train scatter: [0.2381 0.059  0.4284 0.4855]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2388 0.0593 0.4233 0.4792], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.2388 0.0593 0.386  0.4792], Epochs since improvement 6
 41%|████      | 205/500 [3:51:11<5:20:15, 65.14s/it] 41%|████      | 206/500 [3:52:33<5:42:55, 69.99s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -3.17E+05, Train scatter: [0.1757 0.0538 0.284  0.462 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1798 0.0537 0.2841 0.4546], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.2388 0.0593 0.386  0.4792], Epochs since improvement 8
 41%|████▏     | 207/500 [3:53:26<5:17:17, 64.97s/it] 42%|████▏     | 208/500 [3:54:47<5:39:55, 69.85s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -3.01E+05, Train scatter: [0.1599 0.0515 0.2709 0.4543]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1587 0.0501 0.2705 0.4418], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.2388 0.0593 0.386  0.4792], Epochs since improvement 10
 42%|████▏     | 209/500 [3:55:40<5:14:46, 64.90s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -3.60E+05, Train scatter: [0.1446 0.0477 0.2573 0.4446]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.146  0.0464 0.257  0.4316], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.1798 0.0537 0.2841 0.4546], Epochs since improvement 12
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 42%|████▏     | 210/500 [3:57:08<5:46:15, 71.64s/it] 42%|████▏     | 211/500 [3:58:01<5:18:50, 66.20s/it] 42%|████▏     | 212/500 [3:59:22<5:39:01, 70.63s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -3.31E+05, Train scatter: [0.154  0.0461 0.2629 0.4416]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1534 0.0467 0.2668 0.4361], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.1587 0.0501 0.2705 0.4418], Epochs since improvement 14
 43%|████▎     | 213/500 [4:00:16<5:12:59, 65.43s/it] 43%|████▎     | 214/500 [4:01:37<5:34:14, 70.12s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: -3.84E+05, Train scatter: [0.1349 0.0437 0.2372 0.426 ]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.133  0.043  0.2383 0.4157], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.1534 0.0467 0.2668 0.4361], Epochs since improvement 16
 43%|████▎     | 215/500 [4:02:30<5:09:22, 65.13s/it] 43%|████▎     | 216/500 [4:03:51<5:30:12, 69.76s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -3.88E+05, Train scatter: [0.133  0.0445 0.2302 0.4173]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.1328 0.0446 0.2327 0.4108], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.146  0.0464 0.257  0.4316], Epochs since improvement 18
 43%|████▎     | 217/500 [4:04:44<5:05:44, 64.82s/it] 44%|████▎     | 218/500 [4:06:05<5:27:10, 69.61s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -3.28E+05, Train scatter: [0.2233 0.0428 0.2502 0.4189]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.2168 0.0431 0.2545 0.4131], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.146  0.0446 0.2545 0.4157], Epochs since improvement 20
 44%|████▍     | 219/500 [4:06:58<5:03:20, 64.77s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -2.88E+05, Train scatter: [0.355  0.048  0.2371 0.4184]
L1 regularization loss: 0.00E+00, L2 regularization loss: 0.00E+00
Test scatter: [0.3442 0.048  0.242  0.4118], Lowest was [0.1324 0.041  0.2169 0.3789]
Median for last 10 epochs: [0.1534 0.0446 0.242  0.4131], Epochs since improvement 22
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 44%|████▍     | 219/500 [4:08:26<5:18:46, 68.07s/it]
Exited after 220 epochs due to early stopping
14906.33 seconds spent training, 29.813 seconds per epoch. Processed 2336 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.34415743 0.04796118 0.24198112 0.41175508]
{'epoch_exit': 219, 'scatter_m_star': 0.34415743, 'lowest_m_star': 0.13241944, 'last20_m_star': 0.16925146, 'last10_m_star': 0.15338339, 'scatter_v_disk': 0.047961183, 'lowest_v_disk': 0.040977675, 'last20_v_disk': 0.047339745, 'last10_v_disk': 0.044640962, 'scatter_m_cold': 0.24198112, 'lowest_m_cold': 0.21685186, 'last20_m_cold': 0.26190165, 'last10_m_cold': 0.24198794, 'scatter_sfr_100': 0.41175508, 'lowest_sfr_100': 0.37886003, 'last20_sfr_100': 0.43386236, 'last10_sfr_100': 0.41310236}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
