Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_rwzvez
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:32<4:31:26, 32.64s/it]  0%|          | 2/500 [01:20<5:43:01, 41.33s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.27E+07, Train scatter: [0.9352 0.1671 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.31E-01
Test scatter: [0.9196 0.1664 0.5355 0.9851], Lowest was [0.9196 0.1664 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1664 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:51<5:04:33, 36.77s/it]  1%|          | 4/500 [02:39<5:40:12, 41.15s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 6.85E+06, Train scatter: [0.9351 0.1475 0.5439 0.9954]
L1 regularization loss: 1.54E+00, L2 regularization loss: 3.54E-01
Test scatter: [0.9195 0.146  0.5353 0.985 ], Lowest was [0.9195 0.146  0.5353 0.985 ]
Median for last 10 epochs: [0.9195 0.146  0.5353 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:10<5:10:25, 37.63s/it]  1%|          | 6/500 [03:59<5:40:12, 41.32s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.26E+06, Train scatter: [0.9346 0.126  0.5421 0.7182]
L1 regularization loss: 1.57E+00, L2 regularization loss: 3.91E-01
Test scatter: [0.919  0.1254 0.5335 0.7109], Lowest was [0.919  0.1254 0.5335 0.7109]
Median for last 10 epochs: [0.919  0.1254 0.5335 0.7109], Epochs since improvement 0
  1%|▏         | 7/500 [04:30<5:13:18, 38.13s/it]  2%|▏         | 8/500 [05:18<5:37:45, 41.19s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.60E+06, Train scatter: [0.9128 0.1091 0.5328 0.6185]
L1 regularization loss: 1.59E+00, L2 regularization loss: 4.04E-01
Test scatter: [0.8971 0.1097 0.5246 0.6123], Lowest was [0.8971 0.1097 0.5246 0.6123]
Median for last 10 epochs: [0.908  0.1176 0.5291 0.6616], Epochs since improvement 0
  2%|▏         | 9/500 [05:50<5:12:51, 38.23s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 3.59E+06, Train scatter: [0.764  0.1003 0.4637 0.6137]
L1 regularization loss: 1.61E+00, L2 regularization loss: 4.16E-01
Test scatter: [0.7558 0.0996 0.448  0.6035], Lowest was [0.7558 0.0996 0.448  0.6035]
Median for last 10 epochs: [0.8971 0.1097 0.5246 0.6123], Epochs since improvement 0
  2%|▏         | 10/500 [06:43<5:50:46, 42.95s/it]  2%|▏         | 11/500 [07:15<5:21:47, 39.48s/it]  2%|▏         | 12/500 [08:02<5:41:17, 41.96s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.27E+06, Train scatter: [0.6434 0.0938 0.4314 0.6109]
L1 regularization loss: 1.63E+00, L2 regularization loss: 4.27E-01
Test scatter: [0.6624 0.0959 0.4325 0.6199], Lowest was [0.6624 0.0959 0.4325 0.6035]
Median for last 10 epochs: [0.8971 0.1097 0.5246 0.6199], Epochs since improvement 0
  3%|▎         | 13/500 [08:34<5:15:13, 38.84s/it]  3%|▎         | 14/500 [09:22<5:36:35, 41.55s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.48E+06, Train scatter: [0.5529 0.0897 0.3633 0.5907]
L1 regularization loss: 1.64E+00, L2 regularization loss: 4.34E-01
Test scatter: [0.542  0.0913 0.3674 0.5938], Lowest was [0.542  0.0913 0.3674 0.5938]
Median for last 10 epochs: [0.7558 0.0996 0.448  0.6123], Epochs since improvement 0
  3%|▎         | 15/500 [09:54<5:11:50, 38.58s/it]  3%|▎         | 16/500 [10:42<5:34:24, 41.45s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.21E+06, Train scatter: [0.5553 0.0876 0.3459 0.5935]
L1 regularization loss: 1.66E+00, L2 regularization loss: 4.42E-01
Test scatter: [0.5445 0.0894 0.3557 0.5964], Lowest was [0.542  0.0894 0.3557 0.5938]
Median for last 10 epochs: [0.6624 0.0959 0.4325 0.6035], Epochs since improvement 0
  3%|▎         | 17/500 [11:13<5:09:56, 38.50s/it]  4%|▎         | 18/500 [12:02<5:33:00, 41.45s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.04E+06, Train scatter: [0.5542 0.0841 0.3358 0.5764]
L1 regularization loss: 1.68E+00, L2 regularization loss: 4.49E-01
Test scatter: [0.5341 0.0855 0.341  0.5748], Lowest was [0.5341 0.0855 0.341  0.5748]
Median for last 10 epochs: [0.5445 0.0913 0.3674 0.5964], Epochs since improvement 0
  4%|▍         | 19/500 [12:33<5:08:36, 38.50s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 9.08E+05, Train scatter: [0.4863 0.081  0.33   0.5579]
L1 regularization loss: 1.69E+00, L2 regularization loss: 4.59E-01
Test scatter: [0.4829 0.0819 0.3357 0.5564], Lowest was [0.4829 0.0819 0.3357 0.5564]
Median for last 10 epochs: [0.542  0.0894 0.3557 0.5938], Epochs since improvement 0
  4%|▍         | 20/500 [13:27<5:43:43, 42.96s/it]  4%|▍         | 21/500 [13:58<5:15:47, 39.56s/it]  4%|▍         | 22/500 [14:46<5:35:35, 42.12s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.81E+05, Train scatter: [0.5207 0.0843 0.3481 0.5704]
L1 regularization loss: 1.72E+00, L2 regularization loss: 4.72E-01
Test scatter: [0.5038 0.0873 0.3551 0.5776], Lowest was [0.4829 0.0819 0.3357 0.5564]
Median for last 10 epochs: [0.5341 0.0873 0.3551 0.5776], Epochs since improvement 2
  5%|▍         | 23/500 [15:18<5:09:48, 38.97s/it]  5%|▍         | 24/500 [16:06<5:30:49, 41.70s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.03E+05, Train scatter: [0.4578 0.0797 0.3077 0.5443]
L1 regularization loss: 1.76E+00, L2 regularization loss: 4.89E-01
Test scatter: [0.4658 0.0812 0.3107 0.5472], Lowest was [0.4658 0.0812 0.3107 0.5472]
Median for last 10 epochs: [0.5038 0.0855 0.341  0.5748], Epochs since improvement 0
  5%|▌         | 25/500 [16:38<5:05:46, 38.63s/it]  5%|▌         | 26/500 [17:26<5:27:56, 41.51s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 6.09E+05, Train scatter: [0.5272 0.0781 0.2974 0.5381]
L1 regularization loss: 1.80E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.5223 0.0804 0.3062 0.5398], Lowest was [0.4658 0.0804 0.3062 0.5398]
Median for last 10 epochs: [0.5038 0.0819 0.3357 0.5564], Epochs since improvement 0
  5%|▌         | 27/500 [17:57<5:03:34, 38.51s/it]  6%|▌         | 28/500 [18:46<5:27:17, 41.61s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 5.59E+05, Train scatter: [0.5027 0.0751 0.297  0.5255]
L1 regularization loss: 1.84E+00, L2 regularization loss: 5.36E-01
Test scatter: [0.5006 0.0777 0.306  0.5251], Lowest was [0.4658 0.0777 0.306  0.5251]
Median for last 10 epochs: [0.5006 0.0812 0.3107 0.5472], Epochs since improvement 0
  6%|▌         | 29/500 [19:18<5:02:47, 38.57s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.99E+05, Train scatter: [0.5032 0.0764 0.2942 0.5213]
L1 regularization loss: 1.88E+00, L2 regularization loss: 5.61E-01
Test scatter: [0.5222 0.0803 0.3048 0.5239], Lowest was [0.4658 0.0777 0.3048 0.5239]
Median for last 10 epochs: [0.5038 0.0804 0.3062 0.5398], Epochs since improvement 0
  6%|▌         | 30/500 [20:11<5:36:13, 42.92s/it]  6%|▌         | 31/500 [20:42<5:08:30, 39.47s/it]  6%|▋         | 32/500 [21:31<5:30:21, 42.35s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.20E+05, Train scatter: [0.4614 0.0727 0.2865 0.5087]
L1 regularization loss: 1.92E+00, L2 regularization loss: 5.90E-01
Test scatter: [0.4735 0.074  0.2932 0.5087], Lowest was [0.4658 0.074  0.2932 0.5087]
Median for last 10 epochs: [0.5006 0.0803 0.306  0.5251], Epochs since improvement 0
  7%|▋         | 33/500 [22:03<5:04:10, 39.08s/it]  7%|▋         | 34/500 [22:51<5:24:25, 41.77s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.51E+05, Train scatter: [0.4299 0.0703 0.3001 0.5036]
L1 regularization loss: 1.96E+00, L2 regularization loss: 6.21E-01
Test scatter: [0.4353 0.0713 0.3134 0.5048], Lowest was [0.4353 0.0713 0.2932 0.5048]
Median for last 10 epochs: [0.5006 0.0777 0.306  0.5239], Epochs since improvement 0
  7%|▋         | 35/500 [23:22<4:59:41, 38.67s/it]  7%|▋         | 36/500 [24:10<5:21:16, 41.54s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.97E+05, Train scatter: [0.3911 0.0694 0.2791 0.4999]
L1 regularization loss: 1.99E+00, L2 regularization loss: 6.48E-01
Test scatter: [0.4044 0.0708 0.2898 0.502 ], Lowest was [0.4044 0.0708 0.2898 0.502 ]
Median for last 10 epochs: [0.4735 0.074  0.3048 0.5087], Epochs since improvement 0
  7%|▋         | 37/500 [24:42<4:56:59, 38.49s/it]  8%|▊         | 38/500 [25:30<5:19:39, 41.51s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.44E+05, Train scatter: [0.4031 0.0679 0.2884 0.4977]
L1 regularization loss: 2.03E+00, L2 regularization loss: 6.80E-01
Test scatter: [0.4001 0.0695 0.2977 0.4998], Lowest was [0.4001 0.0695 0.2898 0.4998]
Median for last 10 epochs: [0.4353 0.0713 0.2977 0.5048], Epochs since improvement 0
  8%|▊         | 39/500 [26:02<4:55:57, 38.52s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.22E+05, Train scatter: [0.4103 0.0692 0.272  0.4887]
L1 regularization loss: 2.06E+00, L2 regularization loss: 7.09E-01
Test scatter: [0.4087 0.0708 0.2798 0.492 ], Lowest was [0.4001 0.0695 0.2798 0.492 ]
Median for last 10 epochs: [0.4087 0.0708 0.2932 0.502 ], Epochs since improvement 0
  8%|▊         | 40/500 [26:55<5:28:56, 42.90s/it]  8%|▊         | 41/500 [27:26<5:01:42, 39.44s/it]  8%|▊         | 42/500 [28:15<5:21:53, 42.17s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -2.43E+05, Train scatter: [0.5399 0.0735 0.2949 0.5204]
L1 regularization loss: 2.21E+00, L2 regularization loss: 7.64E-01
Test scatter: [0.5361 0.0762 0.3047 0.5207], Lowest was [0.4001 0.0695 0.2798 0.492 ]
Median for last 10 epochs: [0.4087 0.0708 0.2977 0.502 ], Epochs since improvement 2
  9%|▊         | 43/500 [28:46<4:56:42, 38.95s/it]  9%|▉         | 44/500 [29:35<5:17:53, 41.83s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -2.75E+05, Train scatter: [0.395  0.0612 0.2749 0.4661]
L1 regularization loss: 2.21E+00, L2 regularization loss: 7.85E-01
Test scatter: [0.3965 0.0634 0.2862 0.4712], Lowest was [0.3965 0.0634 0.2798 0.4712]
Median for last 10 epochs: [0.4044 0.0708 0.2898 0.4998], Epochs since improvement 0
  9%|▉         | 45/500 [30:06<4:53:21, 38.69s/it]  9%|▉         | 46/500 [30:55<5:14:39, 41.58s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: -2.87E+05, Train scatter: [0.3957 0.0602 0.2728 0.463 ]
L1 regularization loss: 2.23E+00, L2 regularization loss: 8.07E-01
Test scatter: [0.3993 0.0617 0.2845 0.4655], Lowest was [0.3965 0.0617 0.2798 0.4655]
Median for last 10 epochs: [0.4001 0.0695 0.2862 0.492 ], Epochs since improvement 0
  9%|▉         | 47/500 [31:26<4:50:50, 38.52s/it] 10%|▉         | 48/500 [32:15<5:13:13, 41.58s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: -2.88E+05, Train scatter: [0.3621 0.0583 0.2684 0.4548]
L1 regularization loss: 2.28E+00, L2 regularization loss: 8.42E-01
Test scatter: [0.3633 0.06   0.279  0.4588], Lowest was [0.3633 0.06   0.279  0.4588]
Median for last 10 epochs: [0.3993 0.0634 0.2845 0.4712], Epochs since improvement 0
 10%|▉         | 49/500 [32:46<4:49:39, 38.54s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: -2.43E+05, Train scatter: [0.9197 0.0675 0.2911 0.4892]
L1 regularization loss: 2.52E+00, L2 regularization loss: 9.56E-01
Test scatter: [0.9044 0.0683 0.299  0.4899], Lowest was [0.3633 0.06   0.279  0.4588]
Median for last 10 epochs: [0.3993 0.0634 0.2862 0.4712], Epochs since improvement 2
 10%|█         | 50/500 [33:40<5:23:21, 43.11s/it] 10%|█         | 51/500 [34:11<4:56:24, 39.61s/it] 10%|█         | 52/500 [35:00<5:16:12, 42.35s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 6.34E+05, Train scatter: [0.8496 0.1552 0.5415 0.8883]
L1 regularization loss: 3.69E+00, L2 regularization loss: 1.58E+00
Test scatter: [0.835  0.1514 0.5329 0.8788], Lowest was [0.3633 0.06   0.279  0.4588]
Median for last 10 epochs: [0.3993 0.0634 0.2862 0.4712], Epochs since improvement 4
 11%|█         | 53/500 [35:31<4:50:57, 39.05s/it] 11%|█         | 54/500 [36:20<5:11:52, 41.96s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 9.64E+04, Train scatter: [0.5664 0.1118 0.48   0.7092]
L1 regularization loss: 3.74E+00, L2 regularization loss: 1.74E+00
Test scatter: [0.5608 0.1111 0.4691 0.7065], Lowest was [0.3633 0.06   0.279  0.4588]
Median for last 10 epochs: [0.5608 0.0683 0.299  0.4899], Epochs since improvement 6
 11%|█         | 55/500 [36:52<4:47:53, 38.82s/it] 11%|█         | 56/500 [37:40<5:09:24, 41.81s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: -8.35E+04, Train scatter: [0.8011 0.15   0.5281 0.9043]
L1 regularization loss: 3.80E+00, L2 regularization loss: 1.86E+00
Test scatter: [0.797  0.1511 0.5218 0.909 ], Lowest was [0.3633 0.06   0.279  0.4588]
Median for last 10 epochs: [0.797  0.1111 0.4691 0.7065], Epochs since improvement 8
 11%|█▏        | 57/500 [38:12<4:46:00, 38.74s/it] 12%|█▏        | 58/500 [39:01<5:07:24, 41.73s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: -9.18E+03, Train scatter: [0.492  0.1042 0.4679 0.678 ]
L1 regularization loss: 3.85E+00, L2 regularization loss: 1.95E+00
Test scatter: [0.4906 0.1039 0.4602 0.6693], Lowest was [0.3633 0.06   0.279  0.4588]
Median for last 10 epochs: [0.797  0.1111 0.4691 0.7065], Epochs since improvement 10
 12%|█▏        | 59/500 [39:32<4:44:14, 38.67s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: -8.66E+04, Train scatter: [0.4461 0.0986 0.4566 0.6558]
L1 regularization loss: 3.86E+00, L2 regularization loss: 1.98E+00
Test scatter: [0.4433 0.0987 0.4529 0.6501], Lowest was [0.3633 0.06   0.279  0.4588]
Median for last 10 epochs: [0.5608 0.1111 0.4691 0.7065], Epochs since improvement 12
 12%|█▏        | 60/500 [40:26<5:16:21, 43.14s/it] 12%|█▏        | 61/500 [40:57<4:50:01, 39.64s/it] 12%|█▏        | 62/500 [41:46<5:09:21, 42.38s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: -1.20E+05, Train scatter: [0.3973 0.0896 0.4507 0.6083]
L1 regularization loss: 3.88E+00, L2 regularization loss: 2.04E+00
Test scatter: [0.4037 0.0901 0.4451 0.6077], Lowest was [0.3633 0.06   0.279  0.4588]
Median for last 10 epochs: [0.4906 0.1039 0.4602 0.6693], Epochs since improvement 14
 13%|█▎        | 63/500 [42:17<4:44:45, 39.10s/it] 13%|█▎        | 64/500 [43:06<5:05:08, 41.99s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: -1.74E+05, Train scatter: [0.3602 0.0816 0.4138 0.5759]
L1 regularization loss: 3.90E+00, L2 regularization loss: 2.13E+00
Test scatter: [0.3659 0.0823 0.4115 0.5738], Lowest was [0.3633 0.06   0.279  0.4588]
Median for last 10 epochs: [0.4433 0.0987 0.4529 0.6501], Epochs since improvement 16
 13%|█▎        | 65/500 [43:38<4:41:36, 38.84s/it] 13%|█▎        | 66/500 [44:26<5:02:26, 41.81s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: -1.99E+05, Train scatter: [0.3519 0.0765 0.3787 0.5584]
L1 regularization loss: 3.92E+00, L2 regularization loss: 2.22E+00
Test scatter: [0.3472 0.0763 0.3837 0.5506], Lowest was [0.3472 0.06   0.279  0.4588]
Median for last 10 epochs: [0.4037 0.0901 0.4451 0.6077], Epochs since improvement 0
 13%|█▎        | 67/500 [44:58<4:39:21, 38.71s/it] 14%|█▎        | 68/500 [45:47<5:00:00, 41.67s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: -1.95E+05, Train scatter: [0.3302 0.0795 0.3661 0.5466]
L1 regularization loss: 3.96E+00, L2 regularization loss: 2.32E+00
Test scatter: [0.334  0.0798 0.3704 0.5456], Lowest was [0.334  0.06   0.279  0.4588]
Median for last 10 epochs: [0.3659 0.0823 0.4115 0.5738], Epochs since improvement 0
 14%|█▍        | 69/500 [46:18<4:37:33, 38.64s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: -2.25E+05, Train scatter: [0.3295 0.074  0.3711 0.5522]
L1 regularization loss: 3.97E+00, L2 regularization loss: 2.37E+00
Test scatter: [0.3314 0.0741 0.3728 0.5434], Lowest was [0.3314 0.06   0.279  0.4588]
Median for last 10 epochs: [0.3472 0.0798 0.3837 0.5506], Epochs since improvement 0
 14%|█▍        | 70/500 [47:14<5:13:12, 43.70s/it] 14%|█▍        | 71/500 [47:45<4:46:36, 40.08s/it] 14%|█▍        | 72/500 [48:34<5:05:07, 42.77s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: -2.34E+05, Train scatter: [0.38   0.0704 0.3476 0.5263]
L1 regularization loss: 3.98E+00, L2 regularization loss: 2.43E+00
Test scatter: [0.3729 0.0716 0.3511 0.5255], Lowest was [0.3314 0.06   0.279  0.4588]
Median for last 10 epochs: [0.3472 0.0763 0.3728 0.5456], Epochs since improvement 2
 15%|█▍        | 73/500 [49:06<4:40:26, 39.41s/it] 15%|█▍        | 74/500 [49:55<4:59:32, 42.19s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: -2.52E+05, Train scatter: [0.2621 0.0668 0.3319 0.5227]
L1 regularization loss: 3.99E+00, L2 regularization loss: 2.48E+00
Test scatter: [0.2669 0.0669 0.3377 0.5235], Lowest was [0.2669 0.06   0.279  0.4588]
Median for last 10 epochs: [0.334  0.0741 0.3704 0.5434], Epochs since improvement 0
 15%|█▌        | 75/500 [50:26<4:36:31, 39.04s/it] 15%|█▌        | 76/500 [51:16<4:57:43, 42.13s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: -2.59E+05, Train scatter: [0.3201 0.0648 0.3432 0.5145]
L1 regularization loss: 3.99E+00, L2 regularization loss: 2.54E+00
Test scatter: [0.3299 0.0656 0.3552 0.5169], Lowest was [0.2669 0.06   0.279  0.4588]
Median for last 10 epochs: [0.3314 0.0716 0.3552 0.5255], Epochs since improvement 2
 15%|█▌        | 77/500 [51:47<4:34:57, 39.00s/it] 16%|█▌        | 78/500 [52:36<4:54:35, 41.88s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: -2.55E+05, Train scatter: [0.2349 0.0623 0.3494 0.5111]
L1 regularization loss: 3.99E+00, L2 regularization loss: 2.60E+00
Test scatter: [0.2446 0.063  0.3524 0.5101], Lowest was [0.2446 0.06   0.279  0.4588]
Median for last 10 epochs: [0.3299 0.0669 0.3524 0.5235], Epochs since improvement 0
 16%|█▌        | 79/500 [53:07<4:31:43, 38.73s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: -2.74E+05, Train scatter: [0.2748 0.0624 0.3759 0.5079]
L1 regularization loss: 3.99E+00, L2 regularization loss: 2.65E+00
Test scatter: [0.2697 0.0627 0.3718 0.5093], Lowest was [0.2446 0.06   0.279  0.4588]
Median for last 10 epochs: [0.2697 0.0656 0.3524 0.5169], Epochs since improvement 2
 16%|█▌        | 80/500 [54:02<5:05:00, 43.57s/it] 16%|█▌        | 81/500 [54:34<4:39:00, 39.95s/it] 16%|█▋        | 82/500 [55:23<4:58:01, 42.78s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: -2.78E+05, Train scatter: [0.2195 0.0631 0.4126 0.5048]
L1 regularization loss: 3.98E+00, L2 regularization loss: 2.68E+00
Test scatter: [0.2247 0.0639 0.4095 0.5045], Lowest was [0.2247 0.06   0.279  0.4588]
Median for last 10 epochs: [0.2669 0.0639 0.3552 0.5101], Epochs since improvement 0
 17%|█▋        | 83/500 [55:55<4:33:52, 39.41s/it] 17%|█▋        | 84/500 [56:44<4:53:28, 42.33s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: -2.84E+05, Train scatter: [0.2774 0.0613 0.3169 0.5035]
L1 regularization loss: 3.96E+00, L2 regularization loss: 2.71E+00
Test scatter: [0.2557 0.0612 0.3181 0.5035], Lowest was [0.2247 0.06   0.279  0.4588]
Median for last 10 epochs: [0.2557 0.063  0.3552 0.5093], Epochs since improvement 2
 17%|█▋        | 85/500 [57:15<4:30:26, 39.10s/it] 17%|█▋        | 86/500 [58:04<4:50:42, 42.13s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: -2.86E+05, Train scatter: [0.2548 0.0594 0.3101 0.4909]
L1 regularization loss: 3.95E+00, L2 regularization loss: 2.75E+00
Test scatter: [0.2505 0.0605 0.3169 0.4945], Lowest was [0.2247 0.06   0.279  0.4588]
Median for last 10 epochs: [0.2505 0.0627 0.3524 0.5045], Epochs since improvement 4
 17%|█▋        | 87/500 [58:36<4:28:32, 39.01s/it] 18%|█▊        | 88/500 [59:26<4:49:28, 42.16s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: -2.99E+05, Train scatter: [0.2553 0.0589 0.3199 0.4879]
L1 regularization loss: 3.92E+00, L2 regularization loss: 2.77E+00
Test scatter: [0.261  0.0596 0.332  0.4886], Lowest was [0.2247 0.0596 0.279  0.4588]
Median for last 10 epochs: [0.2557 0.0612 0.332  0.5035], Epochs since improvement 0
 18%|█▊        | 89/500 [59:57<4:26:56, 38.97s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: -3.00E+05, Train scatter: [0.2131 0.0558 0.3118 0.4829]
L1 regularization loss: 3.90E+00, L2 regularization loss: 2.81E+00
Test scatter: [0.2167 0.0563 0.3197 0.4846], Lowest was [0.2167 0.0563 0.279  0.4588]
Median for last 10 epochs: [0.2505 0.0605 0.3197 0.4945], Epochs since improvement 0
 18%|█▊        | 90/500 [1:00:51<4:57:31, 43.54s/it] 18%|█▊        | 91/500 [1:01:23<4:32:54, 40.03s/it] 18%|█▊        | 92/500 [1:02:12<4:50:49, 42.77s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: -3.08E+05, Train scatter: [0.21   0.056  0.315  0.4781]
L1 regularization loss: 3.87E+00, L2 regularization loss: 2.84E+00
Test scatter: [0.2157 0.0568 0.3146 0.4794], Lowest was [0.2157 0.0563 0.279  0.4588]
Median for last 10 epochs: [0.2505 0.0596 0.3181 0.4886], Epochs since improvement 0
 19%|█▊        | 93/500 [1:02:44<4:27:57, 39.50s/it] 19%|█▉        | 94/500 [1:03:33<4:46:47, 42.38s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: -3.17E+05, Train scatter: [0.1854 0.0559 0.2775 0.4833]
L1 regularization loss: 3.82E+00, L2 regularization loss: 2.85E+00
Test scatter: [0.1916 0.0556 0.2817 0.4832], Lowest was [0.1916 0.0556 0.279  0.4588]
Median for last 10 epochs: [0.2167 0.0568 0.3169 0.4846], Epochs since improvement 0
 19%|█▉        | 95/500 [1:04:05<4:24:42, 39.22s/it] 19%|█▉        | 96/500 [1:04:54<4:43:52, 42.16s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: -3.18E+05, Train scatter: [0.3562 0.0521 0.2742 0.4688]
L1 regularization loss: 3.77E+00, L2 regularization loss: 2.87E+00
Test scatter: [0.3462 0.0523 0.2812 0.4721], Lowest was [0.1916 0.0523 0.279  0.4588]
Median for last 10 epochs: [0.2167 0.0563 0.3146 0.4832], Epochs since improvement 0
 19%|█▉        | 97/500 [1:05:26<4:22:27, 39.08s/it] 20%|█▉        | 98/500 [1:06:16<4:42:51, 42.22s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: -3.24E+05, Train scatter: [0.2206 0.0558 0.2756 0.4754]
L1 regularization loss: 3.72E+00, L2 regularization loss: 2.91E+00
Test scatter: [0.2171 0.0557 0.2782 0.478 ], Lowest was [0.1916 0.0523 0.2782 0.4588]
Median for last 10 epochs: [0.2167 0.0557 0.2817 0.4794], Epochs since improvement 0
 20%|█▉        | 99/500 [1:06:47<4:21:03, 39.06s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: -3.38E+05, Train scatter: [0.1769 0.0537 0.2833 0.472 ]
L1 regularization loss: 3.68E+00, L2 regularization loss: 2.93E+00
Test scatter: [0.1821 0.0537 0.2897 0.4716], Lowest was [0.1821 0.0523 0.2782 0.4588]
Median for last 10 epochs: [0.2157 0.0556 0.2817 0.478 ], Epochs since improvement 0
 20%|██        | 100/500 [1:07:42<4:51:22, 43.71s/it] 20%|██        | 101/500 [1:08:13<4:26:17, 40.04s/it] 20%|██        | 102/500 [1:09:03<4:43:59, 42.81s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: -3.36E+05, Train scatter: [0.1645 0.0521 0.2794 0.4655]
L1 regularization loss: 3.63E+00, L2 regularization loss: 2.95E+00
Test scatter: [0.1678 0.0522 0.2852 0.4639], Lowest was [0.1678 0.0522 0.2782 0.4588]
Median for last 10 epochs: [0.1916 0.0537 0.2817 0.4721], Epochs since improvement 0
 21%|██        | 103/500 [1:09:34<4:20:47, 39.42s/it] 21%|██        | 104/500 [1:10:24<4:39:48, 42.40s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: -3.46E+05, Train scatter: [0.1628 0.0487 0.2617 0.4529]
L1 regularization loss: 3.62E+00, L2 regularization loss: 3.02E+00
Test scatter: [0.1638 0.0487 0.2688 0.4485], Lowest was [0.1638 0.0487 0.2688 0.4485]
Median for last 10 epochs: [0.1821 0.0523 0.2812 0.4716], Epochs since improvement 0
 21%|██        | 105/500 [1:10:55<4:17:39, 39.14s/it] 21%|██        | 106/500 [1:11:44<4:35:41, 41.98s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: -3.59E+05, Train scatter: [0.1655 0.0502 0.2527 0.4444]
L1 regularization loss: 3.57E+00, L2 regularization loss: 3.02E+00
Test scatter: [0.1649 0.0503 0.2569 0.4414], Lowest was [0.1638 0.0487 0.2569 0.4414]
Median for last 10 epochs: [0.1678 0.0522 0.2782 0.4639], Epochs since improvement 0
 21%|██▏       | 107/500 [1:12:15<4:14:40, 38.88s/it] 22%|██▏       | 108/500 [1:13:05<4:35:01, 42.09s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: -3.64E+05, Train scatter: [0.2314 0.046  0.244  0.4356]
L1 regularization loss: 3.55E+00, L2 regularization loss: 3.05E+00
Test scatter: [0.2236 0.0458 0.2478 0.4339], Lowest was [0.1638 0.0458 0.2478 0.4339]
Median for last 10 epochs: [0.1678 0.0503 0.2688 0.4485], Epochs since improvement 0
 22%|██▏       | 109/500 [1:13:37<4:13:58, 38.97s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: -3.62E+05, Train scatter: [0.3701 0.0455 0.2416 0.4342]
L1 regularization loss: 3.55E+00, L2 regularization loss: 3.09E+00
Test scatter: [0.3578 0.0456 0.2465 0.4294], Lowest was [0.1638 0.0456 0.2465 0.4294]
Median for last 10 epochs: [0.1678 0.0487 0.2569 0.4414], Epochs since improvement 0
 22%|██▏       | 110/500 [1:14:31<4:43:42, 43.65s/it] 22%|██▏       | 111/500 [1:15:03<4:19:31, 40.03s/it] 22%|██▏       | 112/500 [1:15:52<4:36:33, 42.77s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: -3.68E+05, Train scatter: [0.1578 0.0448 0.2413 0.4289]
L1 regularization loss: 3.60E+00, L2 regularization loss: 3.14E+00
Test scatter: [0.1583 0.0445 0.2444 0.427 ], Lowest was [0.1583 0.0445 0.2444 0.427 ]
Median for last 10 epochs: [0.1649 0.0458 0.2478 0.4339], Epochs since improvement 0
 23%|██▎       | 113/500 [1:16:24<4:14:42, 39.49s/it] 23%|██▎       | 114/500 [1:17:13<4:32:53, 42.42s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: -3.78E+05, Train scatter: [0.1613 0.0531 0.2572 0.5688]
L1 regularization loss: 3.59E+00, L2 regularization loss: 3.22E+00
Test scatter: [0.1604 0.0526 0.2582 0.5486], Lowest was [0.1583 0.0445 0.2444 0.427 ]
Median for last 10 epochs: [0.1649 0.0458 0.2478 0.4339], Epochs since improvement 2
 23%|██▎       | 115/500 [1:17:45<4:11:51, 39.25s/it] 23%|██▎       | 116/500 [1:18:34<4:30:03, 42.20s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: -3.86E+05, Train scatter: [0.1602 0.0432 0.2338 0.4464]
L1 regularization loss: 3.54E+00, L2 regularization loss: 3.25E+00
Test scatter: [0.1594 0.0428 0.2349 0.4361], Lowest was [0.1583 0.0428 0.2349 0.427 ]
Median for last 10 epochs: [0.1604 0.0456 0.2465 0.4339], Epochs since improvement 0
 23%|██▎       | 117/500 [1:19:06<4:09:36, 39.10s/it] 24%|██▎       | 118/500 [1:19:54<4:27:13, 41.97s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: -1.85E+05, Train scatter: [0.4002 0.0665 0.353  0.4924]
L1 regularization loss: 4.70E+00, L2 regularization loss: 4.34E+00
Test scatter: [0.3859 0.0659 0.3519 0.4874], Lowest was [0.1583 0.0428 0.2349 0.427 ]
Median for last 10 epochs: [0.1604 0.0456 0.2465 0.4361], Epochs since improvement 2
 24%|██▍       | 119/500 [1:20:26<4:07:15, 38.94s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: -3.28E+05, Train scatter: [0.2115 0.0515 0.3917 0.4521]
L1 regularization loss: 4.57E+00, L2 regularization loss: 4.37E+00
Test scatter: [0.2078 0.0505 0.3826 0.4458], Lowest was [0.1583 0.0428 0.2349 0.427 ]
Median for last 10 epochs: [0.1604 0.0505 0.2582 0.4458], Epochs since improvement 4
 24%|██▍       | 120/500 [1:21:21<4:35:47, 43.55s/it] 24%|██▍       | 121/500 [1:21:52<4:12:21, 39.95s/it] 24%|██▍       | 122/500 [1:22:42<4:30:10, 42.88s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: -3.54E+05, Train scatter: [0.1681 0.0458 0.2548 0.4372]
L1 regularization loss: 4.42E+00, L2 regularization loss: 4.33E+00
Test scatter: [0.1667 0.0457 0.2561 0.4315], Lowest was [0.1583 0.0428 0.2349 0.427 ]
Median for last 10 epochs: [0.1667 0.0505 0.2582 0.4458], Epochs since improvement 6
 25%|██▍       | 123/500 [1:23:14<4:08:13, 39.51s/it] 25%|██▍       | 124/500 [1:24:03<4:26:34, 42.54s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: -3.68E+05, Train scatter: [0.3114 0.1035 0.4843 0.6721]
L1 regularization loss: 4.30E+00, L2 regularization loss: 4.27E+00
Test scatter: [0.3075 0.1021 0.4797 0.6716], Lowest was [0.1583 0.0428 0.2349 0.427 ]
Median for last 10 epochs: [0.2078 0.0505 0.3519 0.4458], Epochs since improvement 8
 25%|██▌       | 125/500 [1:24:35<4:05:21, 39.26s/it] 25%|██▌       | 126/500 [1:25:24<4:23:03, 42.20s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: -3.62E+05, Train scatter: [0.1621 0.0503 0.2574 0.4497]
L1 regularization loss: 4.42E+00, L2 regularization loss: 4.47E+00
Test scatter: [0.1591 0.0499 0.2568 0.445 ], Lowest was [0.1583 0.0428 0.2349 0.427 ]
Median for last 10 epochs: [0.2078 0.0505 0.3519 0.4458], Epochs since improvement 10
 25%|██▌       | 127/500 [1:25:55<4:02:27, 39.00s/it] 26%|██▌       | 128/500 [1:26:45<4:22:10, 42.29s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -3.80E+05, Train scatter: [0.1941 0.0453 0.2448 0.4395]
L1 regularization loss: 4.30E+00, L2 regularization loss: 4.46E+00
Test scatter: [0.1873 0.0448 0.2466 0.4331], Lowest was [0.1583 0.0428 0.2349 0.427 ]
Median for last 10 epochs: [0.1873 0.0499 0.2568 0.445 ], Epochs since improvement 12
 26%|██▌       | 129/500 [1:27:17<4:01:48, 39.11s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -3.77E+05, Train scatter: [0.1461 0.0451 0.2273 0.4286]
L1 regularization loss: 4.22E+00, L2 regularization loss: 4.43E+00
Test scatter: [0.1473 0.0442 0.2298 0.4204], Lowest was [0.1473 0.0428 0.2298 0.4204]
Median for last 10 epochs: [0.1667 0.0457 0.2561 0.4331], Epochs since improvement 0
 26%|██▌       | 130/500 [1:28:12<4:30:47, 43.91s/it] 26%|██▌       | 131/500 [1:28:44<4:07:14, 40.20s/it] 26%|██▋       | 132/500 [1:29:33<4:23:37, 42.98s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -3.80E+05, Train scatter: [0.2789 0.043  0.2337 0.4293]
L1 regularization loss: 4.17E+00, L2 regularization loss: 4.42E+00
Test scatter: [0.2736 0.0428 0.2361 0.4232], Lowest was [0.1473 0.0428 0.2298 0.4204]
Median for last 10 epochs: [0.1873 0.0448 0.2466 0.4331], Epochs since improvement 0
 27%|██▋       | 133/500 [1:30:05<4:02:27, 39.64s/it] 27%|██▋       | 134/500 [1:30:54<4:19:38, 42.56s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: -3.95E+05, Train scatter: [0.3292 0.0444 0.2294 0.4292]
L1 regularization loss: 4.08E+00, L2 regularization loss: 4.40E+00
Test scatter: [0.3164 0.044  0.2289 0.4198], Lowest was [0.1473 0.0428 0.2289 0.4198]
Median for last 10 epochs: [0.1873 0.0442 0.2361 0.4232], Epochs since improvement 0
 27%|██▋       | 135/500 [1:31:26<3:59:33, 39.38s/it] 27%|██▋       | 136/500 [1:32:15<4:16:44, 42.32s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: -3.99E+05, Train scatter: [0.3339 0.043  0.2277 0.4228]
L1 regularization loss: 4.12E+00, L2 regularization loss: 4.48E+00
Test scatter: [0.3251 0.0434 0.232  0.4183], Lowest was [0.1473 0.0428 0.2289 0.4183]
Median for last 10 epochs: [0.2736 0.044  0.232  0.4204], Epochs since improvement 0
 27%|██▋       | 137/500 [1:32:47<3:56:39, 39.12s/it] 28%|██▊       | 138/500 [1:33:36<4:14:15, 42.14s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -4.04E+05, Train scatter: [0.3699 0.0512 0.2365 0.4339]
L1 regularization loss: 4.09E+00, L2 regularization loss: 4.47E+00
Test scatter: [0.3607 0.0514 0.2376 0.4275], Lowest was [0.1473 0.0428 0.2289 0.4183]
Median for last 10 epochs: [0.3164 0.044  0.232  0.4204], Epochs since improvement 2
 28%|██▊       | 139/500 [1:34:08<3:54:42, 39.01s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -4.04E+05, Train scatter: [0.3454 0.0413 0.2222 0.4394]
L1 regularization loss: 4.35E+00, L2 regularization loss: 4.63E+00
Test scatter: [0.3351 0.0407 0.2236 0.4331], Lowest was [0.1473 0.0407 0.2236 0.4183]
Median for last 10 epochs: [0.3251 0.0434 0.232  0.4232], Epochs since improvement 0
 28%|██▊       | 140/500 [1:35:04<4:24:11, 44.03s/it] 28%|██▊       | 141/500 [1:35:36<4:01:51, 40.42s/it] 28%|██▊       | 142/500 [1:36:24<4:15:41, 42.85s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -4.14E+05, Train scatter: [0.1482 0.0413 0.2164 0.4175]
L1 regularization loss: 4.26E+00, L2 regularization loss: 4.65E+00
Test scatter: [0.1479 0.0408 0.2186 0.4095], Lowest was [0.1473 0.0407 0.2186 0.4095]
Median for last 10 epochs: [0.3251 0.0434 0.2289 0.4198], Epochs since improvement 0
 29%|██▊       | 143/500 [1:36:56<3:55:50, 39.64s/it] 29%|██▉       | 144/500 [1:37:45<4:11:43, 42.42s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: -4.21E+05, Train scatter: [0.3283 0.0412 0.2176 0.4259]
L1 regularization loss: 4.23E+00, L2 regularization loss: 4.71E+00
Test scatter: [0.3183 0.0404 0.2161 0.4153], Lowest was [0.1473 0.0404 0.2161 0.4095]
Median for last 10 epochs: [0.3251 0.0408 0.2236 0.4183], Epochs since improvement 0
 29%|██▉       | 145/500 [1:38:17<3:52:27, 39.29s/it] 29%|██▉       | 146/500 [1:39:06<4:09:14, 42.25s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: -4.35E+05, Train scatter: [0.4114 0.0405 0.2156 0.4234]
L1 regularization loss: 4.25E+00, L2 regularization loss: 4.77E+00
Test scatter: [0.3934 0.0403 0.2172 0.4175], Lowest was [0.1473 0.0403 0.2161 0.4095]
Median for last 10 epochs: [0.3351 0.0407 0.2186 0.4175], Epochs since improvement 0
 29%|██▉       | 147/500 [1:39:38<3:50:09, 39.12s/it] 30%|██▉       | 148/500 [1:40:27<4:07:07, 42.12s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: -4.25E+05, Train scatter: [0.3534 0.046  0.211  0.4157]
L1 regularization loss: 4.28E+00, L2 regularization loss: 4.80E+00
Test scatter: [0.3452 0.045  0.2126 0.4084], Lowest was [0.1473 0.0403 0.2126 0.4084]
Median for last 10 epochs: [0.3351 0.0407 0.2172 0.4153], Epochs since improvement 0
 30%|██▉       | 149/500 [1:40:59<3:48:06, 38.99s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: -4.36E+05, Train scatter: [0.2581 0.0408 0.2176 0.4097]
L1 regularization loss: 4.30E+00, L2 regularization loss: 4.85E+00
Test scatter: [0.2541 0.0402 0.2192 0.4006], Lowest was [0.1473 0.0402 0.2126 0.4006]
Median for last 10 epochs: [0.3183 0.0404 0.2172 0.4095], Epochs since improvement 0
 30%|███       | 150/500 [1:41:54<4:15:32, 43.81s/it] 30%|███       | 151/500 [1:42:26<3:53:42, 40.18s/it] 30%|███       | 152/500 [1:43:15<4:08:53, 42.91s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: -4.11E+05, Train scatter: [0.3647 0.0453 0.2301 0.4151]
L1 regularization loss: 4.53E+00, L2 regularization loss: 5.00E+00
Test scatter: [0.3568 0.0444 0.2292 0.4071], Lowest was [0.1473 0.0402 0.2126 0.4006]
Median for last 10 epochs: [0.3452 0.0404 0.2172 0.4084], Epochs since improvement 2
 31%|███       | 153/500 [1:43:47<3:48:35, 39.53s/it] 31%|███       | 154/500 [1:44:36<4:04:34, 42.41s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: -4.44E+05, Train scatter: [0.1847 0.0499 0.2568 0.429 ]
L1 regularization loss: 4.51E+00, L2 regularization loss: 5.05E+00
Test scatter: [0.1851 0.0499 0.2607 0.4259], Lowest was [0.1473 0.0402 0.2126 0.4006]
Median for last 10 epochs: [0.3452 0.0444 0.2192 0.4084], Epochs since improvement 4
 31%|███       | 155/500 [1:45:08<3:45:10, 39.16s/it] 31%|███       | 156/500 [1:45:57<4:02:28, 42.29s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: -4.49E+05, Train scatter: [0.1823 0.0395 0.2181 0.4106]
L1 regularization loss: 4.58E+00, L2 regularization loss: 5.18E+00
Test scatter: [0.1733 0.039  0.2205 0.4015], Lowest was [0.1473 0.039  0.2126 0.4006]
Median for last 10 epochs: [0.2541 0.0444 0.2205 0.4071], Epochs since improvement 0
 31%|███▏      | 157/500 [1:46:29<3:43:29, 39.09s/it] 32%|███▏      | 158/500 [1:47:18<4:00:02, 42.11s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: -4.53E+05, Train scatter: [0.2417 0.0409 0.2114 0.3968]
L1 regularization loss: 4.59E+00, L2 regularization loss: 5.26E+00
Test scatter: [0.2373 0.0402 0.2149 0.3902], Lowest was [0.1473 0.039  0.2126 0.3902]
Median for last 10 epochs: [0.2373 0.0402 0.2205 0.4015], Epochs since improvement 0
 32%|███▏      | 159/500 [1:47:50<3:41:24, 38.96s/it]Epoch: 160 done with learning rate 9.05E-03, Train loss: -4.53E+05, Train scatter: [0.1429 0.039  0.2087 0.396 ]
L1 regularization loss: 4.76E+00, L2 regularization loss: 5.37E+00
Test scatter: [0.1447 0.0386 0.2108 0.3879], Lowest was [0.1447 0.0386 0.2108 0.3879]
Median for last 10 epochs: [0.1851 0.0402 0.2205 0.4015], Epochs since improvement 0
 32%|███▏      | 160/500 [1:48:45<4:08:33, 43.86s/it] 32%|███▏      | 161/500 [1:49:17<3:47:10, 40.21s/it] 32%|███▏      | 162/500 [1:50:06<4:01:56, 42.95s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: -4.42E+05, Train scatter: [0.218  0.0422 0.2279 0.4228]
L1 regularization loss: 4.76E+00, L2 regularization loss: 5.40E+00
Test scatter: [0.2142 0.0415 0.2299 0.4136], Lowest was [0.1447 0.0386 0.2108 0.3879]
Median for last 10 epochs: [0.1851 0.0402 0.2205 0.4015], Epochs since improvement 2
 33%|███▎      | 163/500 [1:50:37<3:42:08, 39.55s/it] 33%|███▎      | 164/500 [1:51:26<3:56:49, 42.29s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: -4.61E+05, Train scatter: [0.1429 0.0382 0.2054 0.3924]
L1 regularization loss: 4.76E+00, L2 regularization loss: 5.46E+00
Test scatter: [0.1444 0.038  0.2077 0.386 ], Lowest was [0.1444 0.038  0.2077 0.386 ]
Median for last 10 epochs: [0.1733 0.039  0.2149 0.3902], Epochs since improvement 0
 33%|███▎      | 165/500 [1:51:58<3:39:00, 39.23s/it] 33%|███▎      | 166/500 [1:52:48<3:55:40, 42.34s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: -4.47E+05, Train scatter: [0.1868 0.0421 0.2125 0.3969]
L1 regularization loss: 4.99E+00, L2 regularization loss: 5.63E+00
Test scatter: [0.181  0.0413 0.2148 0.3864], Lowest was [0.1444 0.038  0.2077 0.386 ]
Median for last 10 epochs: [0.181  0.0402 0.2148 0.3879], Epochs since improvement 2
 33%|███▎      | 167/500 [1:53:20<3:37:38, 39.21s/it] 34%|███▎      | 168/500 [1:54:08<3:52:09, 41.96s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: -4.69E+05, Train scatter: [0.1566 0.0398 0.208  0.3982]
L1 regularization loss: 4.98E+00, L2 regularization loss: 5.67E+00
Test scatter: [0.1567 0.0395 0.2096 0.3889], Lowest was [0.1444 0.038  0.2077 0.386 ]
Median for last 10 epochs: [0.1567 0.0395 0.2108 0.3879], Epochs since improvement 4
 34%|███▍      | 169/500 [1:54:40<3:35:07, 39.00s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -4.70E+05, Train scatter: [0.1281 0.0409 0.2176 0.4786]
L1 regularization loss: 5.02E+00, L2 regularization loss: 5.72E+00
Test scatter: [0.1276 0.0405 0.2181 0.4699], Lowest was [0.1276 0.038  0.2077 0.386 ]
Median for last 10 epochs: [0.1567 0.0405 0.2148 0.3889], Epochs since improvement 0
 34%|███▍      | 170/500 [1:55:34<3:59:24, 43.53s/it] 34%|███▍      | 171/500 [1:56:06<3:38:55, 39.92s/it] 34%|███▍      | 172/500 [1:56:54<3:52:33, 42.54s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -4.78E+05, Train scatter: [0.1384 0.0393 0.207  0.3968]
L1 regularization loss: 5.07E+00, L2 regularization loss: 5.81E+00
Test scatter: [0.1411 0.0394 0.2095 0.3892], Lowest was [0.1276 0.038  0.2077 0.386 ]
Median for last 10 epochs: [0.1444 0.0395 0.2096 0.3889], Epochs since improvement 2
 35%|███▍      | 173/500 [1:57:26<3:33:53, 39.24s/it] 35%|███▍      | 174/500 [1:58:15<3:48:58, 42.14s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -4.78E+05, Train scatter: [0.1175 0.0381 0.2048 0.386 ]
L1 regularization loss: 5.06E+00, L2 regularization loss: 5.85E+00
Test scatter: [0.1206 0.0379 0.208  0.3777], Lowest was [0.1206 0.0379 0.2077 0.3777]
Median for last 10 epochs: [0.1411 0.0395 0.2096 0.3889], Epochs since improvement 0
 35%|███▌      | 175/500 [1:58:47<3:31:16, 39.00s/it] 35%|███▌      | 176/500 [1:59:36<3:47:33, 42.14s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -4.73E+05, Train scatter: [0.1317 0.0377 0.2009 0.3864]
L1 regularization loss: 5.12E+00, L2 regularization loss: 5.92E+00
Test scatter: [0.1341 0.0374 0.2032 0.3773], Lowest was [0.1206 0.0374 0.2032 0.3773]
Median for last 10 epochs: [0.1341 0.0394 0.2095 0.3889], Epochs since improvement 0
 35%|███▌      | 177/500 [2:00:08<3:29:45, 38.96s/it] 36%|███▌      | 178/500 [2:00:57<3:45:13, 41.97s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -4.84E+05, Train scatter: [0.1117 0.0377 0.2075 0.3833]
L1 regularization loss: 5.14E+00, L2 regularization loss: 5.97E+00
Test scatter: [0.1146 0.0374 0.2102 0.3764], Lowest was [0.1146 0.0374 0.2032 0.3764]
Median for last 10 epochs: [0.1276 0.0379 0.2095 0.3777], Epochs since improvement 0
 36%|███▌      | 179/500 [2:01:29<3:28:34, 38.99s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -4.94E+05, Train scatter: [0.1296 0.0379 0.2045 0.3939]
L1 regularization loss: 5.23E+00, L2 regularization loss: 6.05E+00
Test scatter: [0.1299 0.0373 0.2069 0.3879], Lowest was [0.1146 0.0373 0.2032 0.3764]
Median for last 10 epochs: [0.1299 0.0374 0.208  0.3777], Epochs since improvement 0
 36%|███▌      | 180/500 [2:02:23<3:52:50, 43.66s/it] 36%|███▌      | 181/500 [2:02:55<3:32:44, 40.01s/it] 36%|███▋      | 182/500 [2:03:45<3:47:56, 43.01s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -4.86E+05, Train scatter: [0.1275 0.0381 0.2071 0.3889]
L1 regularization loss: 5.36E+00, L2 regularization loss: 6.14E+00
Test scatter: [0.1238 0.0382 0.2113 0.3812], Lowest was [0.1146 0.0373 0.2032 0.3764]
Median for last 10 epochs: [0.1238 0.0374 0.208  0.3777], Epochs since improvement 2
 37%|███▋      | 183/500 [2:04:16<3:28:49, 39.53s/it] 37%|███▋      | 184/500 [2:05:06<3:44:08, 42.56s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -5.00E+05, Train scatter: [0.1454 0.0366 0.2008 0.3863]
L1 regularization loss: 5.26E+00, L2 regularization loss: 6.16E+00
Test scatter: [0.1458 0.0363 0.2027 0.3792], Lowest was [0.1146 0.0363 0.2027 0.3764]
Median for last 10 epochs: [0.1299 0.0374 0.2069 0.3792], Epochs since improvement 0
 37%|███▋      | 185/500 [2:05:37<3:26:19, 39.30s/it] 37%|███▋      | 186/500 [2:06:27<3:41:22, 42.30s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -4.88E+05, Train scatter: [0.136  0.0381 0.2005 0.3898]
L1 regularization loss: 5.49E+00, L2 regularization loss: 6.33E+00
Test scatter: [0.1366 0.0379 0.2029 0.3825], Lowest was [0.1146 0.0363 0.2027 0.3764]
Median for last 10 epochs: [0.1299 0.0374 0.2069 0.3812], Epochs since improvement 2
 37%|███▋      | 187/500 [2:06:58<3:23:48, 39.07s/it] 38%|███▊      | 188/500 [2:07:47<3:38:58, 42.11s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -4.59E+05, Train scatter: [0.1178 0.0367 0.1993 0.3828]
L1 regularization loss: 5.83E+00, L2 regularization loss: 6.63E+00
Test scatter: [0.1225 0.0367 0.2019 0.3753], Lowest was [0.1146 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1299 0.0373 0.2029 0.3812], Epochs since improvement 0
 38%|███▊      | 189/500 [2:08:19<3:22:10, 39.00s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -4.59E+05, Train scatter: [0.1047 0.0374 0.2034 0.386 ]
L1 regularization loss: 5.79E+00, L2 regularization loss: 6.70E+00
Test scatter: [0.1068 0.0373 0.2059 0.3776], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1238 0.0373 0.2029 0.3792], Epochs since improvement 0
 38%|███▊      | 190/500 [2:09:13<3:44:50, 43.52s/it] 38%|███▊      | 191/500 [2:09:45<3:25:48, 39.96s/it] 38%|███▊      | 192/500 [2:10:34<3:39:31, 42.76s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -4.78E+05, Train scatter: [0.1135 0.0368 0.1993 0.3858]
L1 regularization loss: 6.12E+00, L2 regularization loss: 6.98E+00
Test scatter: [0.1171 0.0369 0.2035 0.3769], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1225 0.0369 0.2029 0.3776], Epochs since improvement 2
 39%|███▊      | 193/500 [2:11:06<3:21:25, 39.37s/it] 39%|███▉      | 194/500 [2:11:55<3:36:03, 42.36s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: 2.87E+06, Train scatter: [0.6646 0.1421 0.5427 0.8609]
L1 regularization loss: 8.91E+00, L2 regularization loss: 8.41E+00
Test scatter: [0.6589 0.1401 0.5341 0.857 ], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1225 0.0373 0.2035 0.3776], Epochs since improvement 4
 39%|███▉      | 195/500 [2:12:27<3:18:46, 39.10s/it] 39%|███▉      | 196/500 [2:13:16<3:33:27, 42.13s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -1.73E+05, Train scatter: [0.2379 0.0893 0.3424 0.5128]
L1 regularization loss: 8.82E+00, L2 regularization loss: 8.67E+00
Test scatter: [0.2423 0.0874 0.344  0.5088], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1225 0.0373 0.2059 0.3776], Epochs since improvement 6
 39%|███▉      | 197/500 [2:13:47<3:16:56, 39.00s/it] 40%|███▉      | 198/500 [2:14:37<3:32:24, 42.20s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -2.14E+05, Train scatter: [0.2008 0.0821 0.2808 0.4647]
L1 regularization loss: 8.74E+00, L2 regularization loss: 8.68E+00
Test scatter: [0.1926 0.0824 0.2814 0.4606], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1926 0.0824 0.2814 0.4606], Epochs since improvement 8
 40%|███▉      | 199/500 [2:15:09<3:15:48, 39.03s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -2.50E+05, Train scatter: [0.1678 0.0792 0.2574 0.4507]
L1 regularization loss: 8.66E+00, L2 regularization loss: 8.68E+00
Test scatter: [0.1698 0.079  0.2598 0.4468], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1926 0.0824 0.2814 0.4606], Epochs since improvement 10
 40%|████      | 200/500 [2:16:05<3:40:46, 44.15s/it] 40%|████      | 201/500 [2:16:36<3:21:08, 40.36s/it] 40%|████      | 202/500 [2:17:24<3:31:53, 42.66s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -2.62E+05, Train scatter: [0.1546 0.071  0.2508 0.4453]
L1 regularization loss: 8.55E+00, L2 regularization loss: 8.63E+00
Test scatter: [0.156  0.0705 0.2541 0.4415], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1926 0.0824 0.2814 0.4606], Epochs since improvement 12
 41%|████      | 203/500 [2:17:56<3:14:39, 39.33s/it] 41%|████      | 204/500 [2:18:44<3:27:26, 42.05s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -2.68E+05, Train scatter: [0.1726 0.0651 0.2476 0.4394]
L1 regularization loss: 8.42E+00, L2 regularization loss: 8.56E+00
Test scatter: [0.1855 0.0644 0.2504 0.4331], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1855 0.079  0.2598 0.4468], Epochs since improvement 14
 41%|████      | 205/500 [2:19:16<3:11:18, 38.91s/it] 41%|████      | 206/500 [2:20:05<3:25:02, 41.85s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -2.75E+05, Train scatter: [0.1506 0.0607 0.2435 0.4367]
L1 regularization loss: 8.33E+00, L2 regularization loss: 8.50E+00
Test scatter: [0.1455 0.0602 0.2458 0.4322], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1698 0.0705 0.2541 0.4415], Epochs since improvement 16
 41%|████▏     | 207/500 [2:20:36<3:09:31, 38.81s/it] 42%|████▏     | 208/500 [2:21:25<3:23:38, 41.84s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -2.82E+05, Train scatter: [0.2443 0.059  0.2379 0.4318]
L1 regularization loss: 8.24E+00, L2 regularization loss: 8.43E+00
Test scatter: [0.2176 0.0588 0.2422 0.4255], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1698 0.0644 0.2504 0.4331], Epochs since improvement 18
 42%|████▏     | 209/500 [2:21:57<3:08:08, 38.79s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -2.87E+05, Train scatter: [0.1877 0.0584 0.2413 0.4292]
L1 regularization loss: 8.17E+00, L2 regularization loss: 8.37E+00
Test scatter: [0.1731 0.0578 0.2447 0.4221], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1731 0.0602 0.2458 0.4322], Epochs since improvement 20
 42%|████▏     | 210/500 [2:22:51<3:29:45, 43.40s/it] 42%|████▏     | 211/500 [2:23:23<3:11:52, 39.84s/it] 42%|████▏     | 211/500 [2:24:12<3:17:31, 41.01s/it]
Epoch: 212 done with learning rate 7.65E-03, Train loss: -2.92E+05, Train scatter: [0.1446 0.056  0.2315 0.4256]
L1 regularization loss: 8.09E+00, L2 regularization loss: 8.33E+00
Test scatter: [0.14   0.0561 0.2349 0.4199], Lowest was [0.1068 0.0363 0.2019 0.3753]
Median for last 10 epochs: [0.1731 0.0588 0.2447 0.4255], Epochs since improvement 22
Exited after 212 epochs due to early stopping
8652.94 seconds spent training, 17.306 seconds per epoch. Processed 4024 trees per second
[0.13995567 0.05614747 0.2348821  0.4199154 ]
{'epoch_exit': 211, 'scatter_m_star': 0.13995567, 'lowest_m_star': 0.10681898, 'last20_m_star': 0.17931786, 'last10_m_star': 0.17312019, 'scatter_v_disk': 0.05614747, 'lowest_v_disk': 0.036296204, 'last20_v_disk': 0.06742372, 'last10_v_disk': 0.058836147, 'scatter_m_cold': 0.2348821, 'lowest_m_cold': 0.20188202, 'last20_m_cold': 0.2522351, 'last10_m_cold': 0.24465969, 'scatter_sfr_100': 0.4199154, 'lowest_sfr_100': 0.37525263, 'last20_sfr_100': 0.4373082, 'last10_sfr_100': 0.42546114}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_usdjzq
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:53:31, 28.08s/it]  0%|          | 2/500 [01:12<5:14:36, 37.90s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.36E+07, Train scatter: [0.9353 0.164  0.5442 0.9954]
L1 regularization loss: 1.51E+00, L2 regularization loss: 3.26E-01
Test scatter: [0.9197 0.1662 0.5356 0.9851], Lowest was [0.9197 0.1662 0.5356 0.9851]
Median for last 10 epochs: [0.9197 0.1662 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:39<4:32:51, 32.94s/it]  1%|          | 4/500 [02:24<5:11:24, 37.67s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.20E+07, Train scatter: [0.9353 0.1766 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.32E-01
Test scatter: [0.9197 0.178  0.5355 0.9851], Lowest was [0.9197 0.1662 0.5355 0.9851]
Median for last 10 epochs: [0.9197 0.1721 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:52<4:39:49, 33.92s/it]  1%|          | 6/500 [03:36<5:09:56, 37.64s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.59E+06, Train scatter: [0.9352 0.1698 0.5442 0.9954]
L1 regularization loss: 1.54E+00, L2 regularization loss: 3.44E-01
Test scatter: [0.9196 0.1647 0.5356 0.9851], Lowest was [0.9196 0.1647 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1647 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:04<4:42:08, 34.34s/it]  2%|▏         | 8/500 [04:49<5:09:44, 37.77s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.54E+06, Train scatter: [0.9352 0.1448 0.5441 0.9948]
L1 regularization loss: 1.55E+00, L2 regularization loss: 3.65E-01
Test scatter: [0.9196 0.1392 0.5355 0.9844], Lowest was [0.9196 0.1392 0.5355 0.9844]
Median for last 10 epochs: [0.9196 0.1519 0.5355 0.9847], Epochs since improvement 0
  2%|▏         | 9/500 [05:17<4:42:52, 34.57s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.88E+06, Train scatter: [0.9345 0.1315 0.544  0.6608]
L1 regularization loss: 1.58E+00, L2 regularization loss: 3.94E-01
Test scatter: [0.9189 0.1274 0.5355 0.6513], Lowest was [0.9189 0.1274 0.5355 0.6513]
Median for last 10 epochs: [0.9196 0.1392 0.5355 0.9844], Epochs since improvement 0
  2%|▏         | 10/500 [06:07<5:23:02, 39.56s/it]  2%|▏         | 11/500 [06:35<4:51:32, 35.77s/it]  2%|▏         | 12/500 [07:20<5:14:25, 38.66s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.46E+06, Train scatter: [0.9278 0.1234 0.5438 0.6171]
L1 regularization loss: 1.60E+00, L2 regularization loss: 4.05E-01
Test scatter: [0.9123 0.1193 0.5352 0.6119], Lowest was [0.9123 0.1193 0.5352 0.6119]
Median for last 10 epochs: [0.9196 0.1392 0.5355 0.9844], Epochs since improvement 0
  3%|▎         | 13/500 [07:47<4:45:59, 35.23s/it]  3%|▎         | 14/500 [08:32<5:09:13, 38.18s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.09E+06, Train scatter: [0.8768 0.1149 0.5414 0.6127]
L1 regularization loss: 1.61E+00, L2 regularization loss: 4.13E-01
Test scatter: [0.8629 0.1124 0.533  0.6126], Lowest was [0.8629 0.1124 0.533  0.6119]
Median for last 10 epochs: [0.9189 0.1274 0.5355 0.6513], Epochs since improvement 0
  3%|▎         | 15/500 [09:00<4:43:35, 35.08s/it]  3%|▎         | 16/500 [09:45<5:06:33, 38.00s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.62E+06, Train scatter: [0.6839 0.1102 0.5385 0.5831]
L1 regularization loss: 1.63E+00, L2 regularization loss: 4.23E-01
Test scatter: [0.6784 0.1076 0.5301 0.5776], Lowest was [0.6784 0.1076 0.5301 0.5776]
Median for last 10 epochs: [0.9123 0.1193 0.5352 0.6126], Epochs since improvement 0
  3%|▎         | 17/500 [10:12<4:40:24, 34.83s/it]  4%|▎         | 18/500 [10:57<5:03:52, 37.83s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 6.14E+06, Train scatter: [0.6033 0.1054 0.5359 0.5746]
L1 regularization loss: 1.64E+00, L2 regularization loss: 4.34E-01
Test scatter: [0.6007 0.1029 0.5273 0.5672], Lowest was [0.6007 0.1029 0.5273 0.5672]
Median for last 10 epochs: [0.8629 0.1124 0.533  0.6119], Epochs since improvement 0
  4%|▍         | 19/500 [11:25<4:38:46, 34.77s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.67E+06, Train scatter: [0.4905 0.1004 0.5319 0.5721]
L1 regularization loss: 1.66E+00, L2 regularization loss: 4.45E-01
Test scatter: [0.4894 0.0992 0.5232 0.571 ], Lowest was [0.4894 0.0992 0.5232 0.5672]
Median for last 10 epochs: [0.6784 0.1076 0.5301 0.5776], Epochs since improvement 0
  4%|▍         | 20/500 [12:15<5:16:05, 39.51s/it]  4%|▍         | 21/500 [12:43<4:46:04, 35.84s/it]  4%|▍         | 22/500 [13:28<5:07:25, 38.59s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 5.18E+06, Train scatter: [0.5214 0.0959 0.5293 0.6158]
L1 regularization loss: 1.67E+00, L2 regularization loss: 4.53E-01
Test scatter: [0.5373 0.096  0.52   0.6205], Lowest was [0.4894 0.096  0.52   0.5672]
Median for last 10 epochs: [0.6007 0.1029 0.5273 0.5776], Epochs since improvement 0
  5%|▍         | 23/500 [13:55<4:39:50, 35.20s/it]  5%|▍         | 24/500 [14:41<5:05:53, 38.56s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.28E+06, Train scatter: [0.5045 0.0956 0.4924 0.6058]
L1 regularization loss: 1.68E+00, L2 regularization loss: 4.65E-01
Test scatter: [0.5123 0.0974 0.4813 0.604 ], Lowest was [0.4894 0.096  0.4813 0.5672]
Median for last 10 epochs: [0.5373 0.0992 0.5232 0.5776], Epochs since improvement 0
  5%|▌         | 25/500 [15:09<4:38:48, 35.22s/it]  5%|▌         | 26/500 [15:54<5:01:59, 38.23s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.35E+06, Train scatter: [0.5064 0.0949 0.3833 0.5994]
L1 regularization loss: 1.71E+00, L2 regularization loss: 4.78E-01
Test scatter: [0.5203 0.0989 0.3769 0.6031], Lowest was [0.4894 0.096  0.3769 0.5672]
Median for last 10 epochs: [0.5203 0.0989 0.52   0.6031], Epochs since improvement 0
  5%|▌         | 27/500 [16:21<4:35:35, 34.96s/it]  6%|▌         | 28/500 [17:06<4:58:39, 37.96s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.17E+06, Train scatter: [0.5261 0.091  0.3648 0.6014]
L1 regularization loss: 1.72E+00, L2 regularization loss: 4.85E-01
Test scatter: [0.5376 0.0951 0.3693 0.6035], Lowest was [0.4894 0.0951 0.3693 0.5672]
Median for last 10 epochs: [0.5203 0.0974 0.4813 0.6035], Epochs since improvement 0
  6%|▌         | 29/500 [17:34<4:33:35, 34.85s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 1.82E+06, Train scatter: [0.4535 0.0881 0.3493 0.5868]
L1 regularization loss: 1.74E+00, L2 regularization loss: 4.93E-01
Test scatter: [0.4661 0.0912 0.353  0.5899], Lowest was [0.4661 0.0912 0.353  0.5672]
Median for last 10 epochs: [0.5203 0.096  0.3769 0.6035], Epochs since improvement 0
  6%|▌         | 30/500 [18:25<5:11:11, 39.73s/it]  6%|▌         | 31/500 [18:52<4:41:23, 36.00s/it]  6%|▋         | 32/500 [19:38<5:03:01, 38.85s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 1.72E+06, Train scatter: [0.3403 0.0863 0.3453 0.5675]
L1 regularization loss: 1.76E+00, L2 regularization loss: 5.04E-01
Test scatter: [0.3593 0.0892 0.349  0.5706], Lowest was [0.3593 0.0892 0.349  0.5672]
Median for last 10 epochs: [0.5123 0.0951 0.3693 0.6031], Epochs since improvement 0
  7%|▋         | 33/500 [20:05<4:35:13, 35.36s/it]  7%|▋         | 34/500 [20:50<4:57:56, 38.36s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 1.57E+06, Train scatter: [0.3283 0.0833 0.3271 0.5496]
L1 regularization loss: 1.78E+00, L2 regularization loss: 5.16E-01
Test scatter: [0.3458 0.0849 0.329  0.5533], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.4661 0.0912 0.353  0.5899], Epochs since improvement 0
  7%|▋         | 35/500 [21:18<4:32:02, 35.10s/it]  7%|▋         | 36/500 [22:04<4:56:45, 38.37s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 6.72E+06, Train scatter: [0.6291 0.1635 0.5165 0.9597]
L1 regularization loss: 2.15E+00, L2 regularization loss: 6.31E-01
Test scatter: [0.6275 0.1539 0.5123 0.9523], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.4661 0.0912 0.353  0.5899], Epochs since improvement 2
  7%|▋         | 37/500 [22:31<4:30:44, 35.09s/it]  8%|▊         | 38/500 [23:16<4:52:36, 38.00s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 4.39E+06, Train scatter: [0.5375 0.1379 0.4934 0.8456]
L1 regularization loss: 2.18E+00, L2 regularization loss: 6.80E-01
Test scatter: [0.5682 0.1358 0.4931 0.8494], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.4661 0.0912 0.353  0.5899], Epochs since improvement 4
  8%|▊         | 39/500 [23:44<4:28:39, 34.97s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.53E+06, Train scatter: [0.4828 0.1293 0.4606 0.7799]
L1 regularization loss: 2.21E+00, L2 regularization loss: 7.16E-01
Test scatter: [0.5151 0.129  0.4576 0.8099], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.5151 0.129  0.4576 0.8099], Epochs since improvement 6
  8%|▊         | 40/500 [24:34<5:03:40, 39.61s/it]  8%|▊         | 41/500 [25:02<4:34:38, 35.90s/it]  8%|▊         | 42/500 [25:46<4:54:13, 38.54s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.99E+06, Train scatter: [0.4589 0.124  0.4245 0.7273]
L1 regularization loss: 2.23E+00, L2 regularization loss: 7.39E-01
Test scatter: [0.4967 0.123  0.4208 0.7573], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.5151 0.129  0.4576 0.8099], Epochs since improvement 8
  9%|▊         | 43/500 [26:14<4:27:57, 35.18s/it]  9%|▉         | 44/500 [26:59<4:49:23, 38.08s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.48E+06, Train scatter: [0.45   0.1104 0.3939 0.6701]
L1 regularization loss: 2.25E+00, L2 regularization loss: 7.62E-01
Test scatter: [0.4823 0.1112 0.4004 0.6886], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.5151 0.129  0.4576 0.8099], Epochs since improvement 10
  9%|▉         | 45/500 [27:26<4:24:28, 34.88s/it]  9%|▉         | 46/500 [28:11<4:46:59, 37.93s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.26E+06, Train scatter: [0.4048 0.1054 0.3706 0.6477]
L1 regularization loss: 2.26E+00, L2 regularization loss: 7.82E-01
Test scatter: [0.4372 0.1053 0.3736 0.6515], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.4967 0.123  0.4208 0.7573], Epochs since improvement 12
  9%|▉         | 47/500 [28:38<4:22:24, 34.76s/it] 10%|▉         | 48/500 [29:23<4:43:56, 37.69s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.79E+06, Train scatter: [0.419  0.0988 0.3692 0.6212]
L1 regularization loss: 2.28E+00, L2 regularization loss: 7.95E-01
Test scatter: [0.4567 0.101  0.3785 0.6323], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.4823 0.1112 0.4004 0.6886], Epochs since improvement 14
 10%|▉         | 49/500 [29:50<4:20:38, 34.68s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.67E+06, Train scatter: [0.4204 0.0952 0.3501 0.6031]
L1 regularization loss: 2.29E+00, L2 regularization loss: 8.11E-01
Test scatter: [0.4481 0.0966 0.3638 0.6123], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.4567 0.1053 0.3785 0.6515], Epochs since improvement 16
 10%|█         | 50/500 [30:41<4:56:41, 39.56s/it] 10%|█         | 51/500 [31:09<4:28:20, 35.86s/it] 10%|█         | 52/500 [31:54<4:50:01, 38.84s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 1.52E+06, Train scatter: [0.3647 0.0934 0.3615 0.5996]
L1 regularization loss: 2.31E+00, L2 regularization loss: 8.25E-01
Test scatter: [0.3865 0.0923 0.3615 0.5996], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.4481 0.101  0.3736 0.6323], Epochs since improvement 18
 11%|█         | 53/500 [32:22<4:23:50, 35.42s/it] 11%|█         | 54/500 [33:07<4:45:20, 38.39s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.38E+06, Train scatter: [0.4554 0.091  0.3413 0.5873]
L1 regularization loss: 2.32E+00, L2 regularization loss: 8.41E-01
Test scatter: [0.4614 0.0909 0.3481 0.5895], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.4481 0.0966 0.3638 0.6123], Epochs since improvement 20
 11%|█         | 55/500 [33:35<4:20:01, 35.06s/it] 11%|█         | 55/500 [34:21<4:38:03, 37.49s/it]
Epoch: 56 done with learning rate 8.56E-03, Train loss: 1.17E+06, Train scatter: [0.3273 0.0858 0.3281 0.5717]
L1 regularization loss: 2.33E+00, L2 regularization loss: 8.55E-01
Test scatter: [0.3549 0.0876 0.3371 0.581 ], Lowest was [0.3458 0.0849 0.329  0.5533]
Median for last 10 epochs: [0.4481 0.0923 0.3615 0.5996], Epochs since improvement 22
Exited after 56 epochs due to early stopping
2061.97 seconds spent training, 4.124 seconds per epoch. Processed 16886 trees per second
[0.3549115  0.08760857 0.33713895 0.5809906 ]
{'epoch_exit': 55, 'scatter_m_star': 0.3549115, 'lowest_m_star': 0.3458033, 'last20_m_star': 0.45902252, 'last10_m_star': 0.44807273, 'scatter_v_disk': 0.08760857, 'lowest_v_disk': 0.08488344, 'last20_v_disk': 0.10312941, 'last10_v_disk': 0.092298746, 'scatter_m_cold': 0.33713895, 'lowest_m_cold': 0.32900608, 'last20_m_cold': 0.37603632, 'last10_m_cold': 0.36149308, 'scatter_sfr_100': 0.5809906, 'lowest_sfr_100': 0.5532971, 'last20_sfr_100': 0.6419059, 'last10_sfr_100': 0.5996148}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_vgjmeh
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:48<6:40:12, 48.12s/it]  0%|          | 2/500 [01:58<8:29:26, 61.38s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.30E+07, Train scatter: [0.9351 0.1363 0.544  0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.83E-01
Test scatter: [0.9195 0.1341 0.5354 0.9851], Lowest was [0.9195 0.1341 0.5354 0.9851]
Median for last 10 epochs: [0.9195 0.1341 0.5354 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:46<7:35:01, 54.93s/it]  1%|          | 4/500 [03:57<8:27:34, 61.40s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.49E+07, Train scatter: [0.9311 0.0958 0.544  0.9952]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.11E-01
Test scatter: [0.9152 0.0947 0.5354 0.9848], Lowest was [0.9152 0.0947 0.5354 0.9848]
Median for last 10 epochs: [0.9152 0.0947 0.5354 0.9848], Epochs since improvement 0
  1%|          | 5/500 [04:44<7:44:34, 56.31s/it]  1%|          | 6/500 [05:55<8:23:22, 61.14s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.13E+06, Train scatter: [0.7589 0.0875 0.5439 0.5959]
L1 regularization loss: 2.05E+00, L2 regularization loss: 4.54E-01
Test scatter: [0.7501 0.0877 0.5353 0.5971], Lowest was [0.7501 0.0877 0.5353 0.5971]
Median for last 10 epochs: [0.7501 0.0877 0.5353 0.5971], Epochs since improvement 0
  1%|▏         | 7/500 [06:42<7:45:46, 56.69s/it]  2%|▏         | 8/500 [07:53<8:22:14, 61.25s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 5.49E+06, Train scatter: [0.5363 0.0802 0.5439 0.5671]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.68E-01
Test scatter: [0.535  0.0812 0.5353 0.5652], Lowest was [0.535  0.0812 0.5353 0.5652]
Median for last 10 epochs: [0.6426 0.0845 0.5353 0.5812], Epochs since improvement 0
  2%|▏         | 9/500 [08:40<7:45:14, 56.85s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.16E+06, Train scatter: [0.3658 0.0738 0.5439 0.5305]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.77E-01
Test scatter: [0.3727 0.0746 0.5353 0.5298], Lowest was [0.3727 0.0746 0.5353 0.5298]
Median for last 10 epochs: [0.535  0.0812 0.5353 0.5652], Epochs since improvement 0
  2%|▏         | 10/500 [09:58<8:36:05, 63.19s/it]  2%|▏         | 11/500 [10:45<7:55:28, 58.34s/it]  2%|▏         | 12/500 [11:56<8:24:26, 62.02s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 3.58E+06, Train scatter: [0.2592 0.0714 0.5438 0.5221]
L1 regularization loss: 2.08E+00, L2 regularization loss: 4.84E-01
Test scatter: [0.2646 0.0721 0.5353 0.518 ], Lowest was [0.2646 0.0721 0.5353 0.518 ]
Median for last 10 epochs: [0.535  0.0812 0.5353 0.5652], Epochs since improvement 0
  3%|▎         | 13/500 [12:43<7:46:53, 57.52s/it]  3%|▎         | 14/500 [13:54<8:18:50, 61.59s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 3.39E+06, Train scatter: [0.2433 0.0687 0.5438 0.5113]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.90E-01
Test scatter: [0.25   0.0692 0.5352 0.5088], Lowest was [0.25   0.0692 0.5352 0.5088]
Median for last 10 epochs: [0.3727 0.0746 0.5353 0.5298], Epochs since improvement 0
  3%|▎         | 15/500 [14:41<7:42:20, 57.20s/it]  3%|▎         | 16/500 [15:53<8:16:58, 61.61s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.27E+06, Train scatter: [0.2216 0.0689 0.5437 0.5151]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.94E-01
Test scatter: [0.2267 0.068  0.5351 0.5094], Lowest was [0.2267 0.068  0.5351 0.5088]
Median for last 10 epochs: [0.2646 0.0721 0.5353 0.518 ], Epochs since improvement 0
  3%|▎         | 17/500 [16:40<7:40:42, 57.23s/it]  4%|▎         | 18/500 [17:51<8:14:34, 61.56s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.23E+06, Train scatter: [0.2149 0.0684 0.5436 0.5336]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.98E-01
Test scatter: [0.2222 0.0679 0.5351 0.5269], Lowest was [0.2222 0.0679 0.5351 0.5088]
Median for last 10 epochs: [0.25   0.0692 0.5352 0.518 ], Epochs since improvement 0
  4%|▍         | 19/500 [18:38<7:37:58, 57.13s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.16E+06, Train scatter: [0.2247 0.0653 0.5436 0.5032]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.02E-01
Test scatter: [0.2307 0.066  0.535  0.5005], Lowest was [0.2222 0.066  0.535  0.5005]
Median for last 10 epochs: [0.2307 0.068  0.5351 0.5094], Epochs since improvement 0
  4%|▍         | 20/500 [19:56<8:26:49, 63.35s/it]  4%|▍         | 21/500 [20:43<7:46:09, 58.39s/it]  4%|▍         | 22/500 [21:55<8:18:44, 62.60s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.05E+06, Train scatter: [0.1997 0.0643 0.5434 0.5034]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.06E-01
Test scatter: [0.2043 0.0639 0.5349 0.4985], Lowest was [0.2043 0.0639 0.5349 0.4985]
Median for last 10 epochs: [0.2267 0.0679 0.5351 0.5088], Epochs since improvement 0
  5%|▍         | 23/500 [22:42<7:40:28, 57.92s/it]  5%|▍         | 24/500 [23:54<8:12:50, 62.12s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.01E+06, Train scatter: [0.2403 0.0662 0.5434 0.5162]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.2414 0.0663 0.5348 0.5115], Lowest was [0.2043 0.0639 0.5348 0.4985]
Median for last 10 epochs: [0.2267 0.0663 0.535  0.5094], Epochs since improvement 0
  5%|▌         | 25/500 [24:41<7:34:58, 57.47s/it]  5%|▌         | 26/500 [25:52<8:07:31, 61.71s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.00E+06, Train scatter: [0.1944 0.0636 0.5433 0.4993]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.16E-01
Test scatter: [0.1997 0.0633 0.5348 0.4942], Lowest was [0.1997 0.0633 0.5348 0.4942]
Median for last 10 epochs: [0.2222 0.066  0.5349 0.5005], Epochs since improvement 0
  5%|▌         | 27/500 [26:39<7:31:40, 57.29s/it]  6%|▌         | 28/500 [27:51<8:05:29, 61.72s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.96E+06, Train scatter: [0.1992 0.0638 0.5433 0.4934]
L1 regularization loss: 2.16E+00, L2 regularization loss: 5.22E-01
Test scatter: [0.2078 0.0628 0.5347 0.487 ], Lowest was [0.1997 0.0628 0.5347 0.487 ]
Median for last 10 epochs: [0.2078 0.0639 0.5348 0.4985], Epochs since improvement 0
  6%|▌         | 29/500 [28:38<7:29:32, 57.27s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.17E+06, Train scatter: [0.9263 0.1454 0.5439 0.9847]
L1 regularization loss: 2.23E+00, L2 regularization loss: 5.35E-01
Test scatter: [0.9113 0.1442 0.5354 0.9752], Lowest was [0.1997 0.0628 0.5347 0.487 ]
Median for last 10 epochs: [0.2078 0.0639 0.5348 0.4985], Epochs since improvement 2
  6%|▌         | 30/500 [29:57<8:18:31, 63.64s/it]  6%|▌         | 31/500 [30:44<7:38:12, 58.62s/it]  6%|▋         | 32/500 [31:57<8:10:58, 62.95s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.15E+06, Train scatter: [0.8828 0.1039 0.5438 0.5956]
L1 regularization loss: 2.29E+00, L2 regularization loss: 5.80E-01
Test scatter: [0.8702 0.1037 0.5352 0.5963], Lowest was [0.1997 0.0628 0.5347 0.487 ]
Median for last 10 epochs: [0.2414 0.0663 0.5348 0.5115], Epochs since improvement 4
  7%|▋         | 33/500 [32:43<7:32:14, 58.10s/it]  7%|▋         | 34/500 [33:55<8:01:21, 61.98s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.07E+06, Train scatter: [0.7012 0.093  0.5437 0.5616]
L1 regularization loss: 2.30E+00, L2 regularization loss: 6.04E-01
Test scatter: [0.6978 0.0915 0.5351 0.5569], Lowest was [0.1997 0.0628 0.5347 0.487 ]
Median for last 10 epochs: [0.6978 0.0915 0.5351 0.5569], Epochs since improvement 6
  7%|▋         | 35/500 [34:41<7:24:52, 57.40s/it]  7%|▋         | 36/500 [35:53<7:58:01, 61.81s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.02E+06, Train scatter: [0.4301 0.0806 0.5437 0.5304]
L1 regularization loss: 2.33E+00, L2 regularization loss: 6.26E-01
Test scatter: [0.429  0.0795 0.5351 0.5228], Lowest was [0.1997 0.0628 0.5347 0.487 ]
Median for last 10 epochs: [0.6978 0.0915 0.5351 0.5569], Epochs since improvement 8
  7%|▋         | 37/500 [36:40<7:22:33, 57.35s/it]  8%|▊         | 38/500 [37:52<7:55:44, 61.78s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.99E+06, Train scatter: [0.273  0.0732 0.5435 0.5091]
L1 regularization loss: 2.35E+00, L2 regularization loss: 6.44E-01
Test scatter: [0.2716 0.0726 0.535  0.5038], Lowest was [0.1997 0.0628 0.5347 0.487 ]
Median for last 10 epochs: [0.6978 0.0915 0.5351 0.5569], Epochs since improvement 10
  8%|▊         | 39/500 [38:39<7:20:19, 57.31s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.95E+06, Train scatter: [0.2771 0.0695 0.5434 0.4964]
L1 regularization loss: 2.36E+00, L2 regularization loss: 6.58E-01
Test scatter: [0.2729 0.0691 0.5348 0.4904], Lowest was [0.1997 0.0628 0.5347 0.487 ]
Median for last 10 epochs: [0.429  0.0795 0.5351 0.5228], Epochs since improvement 12
  8%|▊         | 40/500 [39:58<8:07:30, 63.59s/it]  8%|▊         | 41/500 [40:44<7:28:11, 58.59s/it]  8%|▊         | 42/500 [41:56<7:56:29, 62.42s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.95E+06, Train scatter: [0.2394 0.0743 0.5433 0.5122]
L1 regularization loss: 2.39E+00, L2 regularization loss: 6.78E-01
Test scatter: [0.2399 0.0736 0.5348 0.5078], Lowest was [0.1997 0.0628 0.5347 0.487 ]
Median for last 10 epochs: [0.2729 0.0736 0.535  0.5078], Epochs since improvement 14
  9%|▊         | 43/500 [42:43<7:20:11, 57.79s/it]  9%|▉         | 44/500 [43:55<7:51:48, 62.08s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.92E+06, Train scatter: [0.2316 0.069  0.5431 0.5029]
L1 regularization loss: 2.39E+00, L2 regularization loss: 6.99E-01
Test scatter: [0.2407 0.0684 0.5346 0.4961], Lowest was [0.1997 0.0628 0.5346 0.487 ]
Median for last 10 epochs: [0.2716 0.0726 0.5348 0.5038], Epochs since improvement 0
  9%|▉         | 45/500 [44:42<7:16:17, 57.53s/it]  9%|▉         | 46/500 [45:54<7:48:51, 61.96s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.93E+06, Train scatter: [0.2459 0.0645 0.543  0.4982]
L1 regularization loss: 2.44E+00, L2 regularization loss: 7.28E-01
Test scatter: [0.2466 0.0649 0.5345 0.493 ], Lowest was [0.1997 0.0628 0.5345 0.487 ]
Median for last 10 epochs: [0.2466 0.0691 0.5348 0.4961], Epochs since improvement 0
  9%|▉         | 47/500 [46:41<7:13:45, 57.45s/it] 10%|▉         | 48/500 [47:53<7:45:37, 61.81s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.89E+06, Train scatter: [0.203  0.0617 0.5426 0.4878]
L1 regularization loss: 2.47E+00, L2 regularization loss: 7.52E-01
Test scatter: [0.2057 0.0616 0.5341 0.4813], Lowest was [0.1997 0.0616 0.5341 0.4813]
Median for last 10 epochs: [0.2407 0.0684 0.5346 0.493 ], Epochs since improvement 0
 10%|▉         | 49/500 [48:40<7:10:55, 57.33s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.88E+06, Train scatter: [0.227  0.0697 0.5411 0.5028]
L1 regularization loss: 2.50E+00, L2 regularization loss: 7.76E-01
Test scatter: [0.2409 0.0697 0.5326 0.4982], Lowest was [0.1997 0.0616 0.5326 0.4813]
Median for last 10 epochs: [0.2407 0.0684 0.5345 0.4961], Epochs since improvement 0
 10%|█         | 50/500 [49:58<7:55:38, 63.42s/it] 10%|█         | 51/500 [50:44<7:17:33, 58.47s/it] 10%|█         | 52/500 [51:57<7:47:07, 62.56s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 2.85E+06, Train scatter: [0.2611 0.0654 0.5385 0.4947]
L1 regularization loss: 2.53E+00, L2 regularization loss: 8.09E-01
Test scatter: [0.2584 0.0651 0.5302 0.4882], Lowest was [0.1997 0.0616 0.5302 0.4813]
Median for last 10 epochs: [0.2409 0.0651 0.5341 0.493 ], Epochs since improvement 0
 11%|█         | 53/500 [52:43<7:11:04, 57.86s/it] 11%|█         | 54/500 [53:55<7:39:32, 61.82s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.77E+06, Train scatter: [0.2138 0.0627 0.533  0.4889]
L1 regularization loss: 2.56E+00, L2 regularization loss: 8.43E-01
Test scatter: [0.2154 0.0631 0.5246 0.486 ], Lowest was [0.1997 0.0616 0.5246 0.4813]
Median for last 10 epochs: [0.2409 0.0649 0.5326 0.4882], Epochs since improvement 0
 11%|█         | 55/500 [54:41<7:05:18, 57.35s/it] 11%|█         | 56/500 [55:53<7:36:13, 61.65s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.89E+06, Train scatter: [0.4668 0.1327 0.5375 0.7085]
L1 regularization loss: 2.89E+00, L2 regularization loss: 1.01E+00
Test scatter: [0.4755 0.1309 0.529  0.7187], Lowest was [0.1997 0.0616 0.5246 0.4813]
Median for last 10 epochs: [0.2409 0.0651 0.5302 0.4882], Epochs since improvement 2
 11%|█▏        | 57/500 [56:40<7:02:20, 57.20s/it] 12%|█▏        | 58/500 [57:51<7:32:16, 61.39s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.81E+06, Train scatter: [0.5118 0.1089 0.49   0.635 ]
L1 regularization loss: 2.87E+00, L2 regularization loss: 1.06E+00
Test scatter: [0.5136 0.1087 0.4833 0.6333], Lowest was [0.1997 0.0616 0.4833 0.4813]
Median for last 10 epochs: [0.2584 0.0697 0.529  0.4982], Epochs since improvement 0
 12%|█▏        | 59/500 [58:38<6:59:12, 57.04s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.05E+06, Train scatter: [0.4828 0.0852 0.4348 0.5989]
L1 regularization loss: 2.87E+00, L2 regularization loss: 1.11E+00
Test scatter: [0.4937 0.0853 0.4326 0.5962], Lowest was [0.1997 0.0616 0.4326 0.4813]
Median for last 10 epochs: [0.4755 0.0853 0.5246 0.5962], Epochs since improvement 0
 12%|█▏        | 60/500 [59:56<7:45:00, 63.41s/it] 12%|█▏        | 61/500 [1:00:43<7:08:01, 58.50s/it] 12%|█▏        | 62/500 [1:01:54<7:34:06, 62.21s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.90E+06, Train scatter: [0.325  0.0724 0.3872 0.5476]
L1 regularization loss: 2.90E+00, L2 regularization loss: 1.18E+00
Test scatter: [0.3469 0.0742 0.388  0.5488], Lowest was [0.1997 0.0616 0.388  0.4813]
Median for last 10 epochs: [0.4755 0.0853 0.4833 0.5962], Epochs since improvement 0
 13%|█▎        | 63/500 [1:02:41<6:59:22, 57.58s/it] 13%|█▎        | 64/500 [1:03:52<7:27:10, 61.54s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.84E+06, Train scatter: [0.3302 0.0677 0.4061 0.526 ]
L1 regularization loss: 2.96E+00, L2 regularization loss: 1.25E+00
Test scatter: [0.3284 0.0697 0.4103 0.5257], Lowest was [0.1997 0.0616 0.388  0.4813]
Median for last 10 epochs: [0.4755 0.0853 0.4326 0.5962], Epochs since improvement 2
 13%|█▎        | 65/500 [1:04:39<6:54:40, 57.20s/it] 13%|█▎        | 66/500 [1:05:50<7:23:22, 61.30s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.75E+06, Train scatter: [0.3585 0.0642 0.4096 0.5008]
L1 regularization loss: 3.00E+00, L2 regularization loss: 1.33E+00
Test scatter: [0.3553 0.0673 0.4151 0.5015], Lowest was [0.1997 0.0616 0.388  0.4813]
Median for last 10 epochs: [0.3553 0.0742 0.4151 0.5488], Epochs since improvement 4
 13%|█▎        | 67/500 [1:06:37<6:51:37, 57.04s/it] 14%|█▎        | 68/500 [1:07:49<7:22:52, 61.51s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.69E+06, Train scatter: [0.2858 0.0669 0.3591 0.4982]
L1 regularization loss: 3.05E+00, L2 regularization loss: 1.41E+00
Test scatter: [0.2937 0.07   0.3694 0.5047], Lowest was [0.1997 0.0616 0.3694 0.4813]
Median for last 10 epochs: [0.3469 0.07   0.4103 0.5257], Epochs since improvement 0
 14%|█▍        | 69/500 [1:08:36<6:50:37, 57.16s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.68E+06, Train scatter: [0.2396 0.0585 0.3885 0.4816]
L1 regularization loss: 3.14E+00, L2 regularization loss: 1.51E+00
Test scatter: [0.2435 0.0605 0.4    0.4839], Lowest was [0.1997 0.0605 0.3694 0.4813]
Median for last 10 epochs: [0.3284 0.0697 0.4    0.5047], Epochs since improvement 0
 14%|█▍        | 70/500 [1:09:53<7:33:17, 63.25s/it] 14%|█▍        | 71/500 [1:10:40<6:57:55, 58.45s/it] 14%|█▍        | 72/500 [1:11:51<7:22:59, 62.10s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.60E+06, Train scatter: [0.238  0.0612 0.3858 0.4828]
L1 regularization loss: 3.18E+00, L2 regularization loss: 1.61E+00
Test scatter: [0.236  0.063  0.3927 0.482 ], Lowest was [0.1997 0.0605 0.3694 0.4813]
Median for last 10 epochs: [0.2937 0.0673 0.4    0.5015], Epochs since improvement 2
 15%|█▍        | 73/500 [1:12:38<6:50:11, 57.64s/it] 15%|█▍        | 74/500 [1:13:49<7:16:46, 61.52s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 1.45E+06, Train scatter: [0.2187 0.0563 0.3582 0.4795]
L1 regularization loss: 3.26E+00, L2 regularization loss: 1.71E+00
Test scatter: [0.2227 0.058  0.3664 0.4771], Lowest was [0.1997 0.058  0.3664 0.4771]
Median for last 10 epochs: [0.2435 0.063  0.3927 0.4839], Epochs since improvement 0
 15%|█▌        | 75/500 [1:14:36<6:45:26, 57.24s/it] 15%|█▌        | 76/500 [1:15:47<7:13:50, 61.39s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 6.66E+05, Train scatter: [0.2349 0.068  0.2932 0.5069]
L1 regularization loss: 3.31E+00, L2 regularization loss: 1.82E+00
Test scatter: [0.236  0.0681 0.2978 0.4989], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.236  0.063  0.3694 0.4839], Epochs since improvement 0
 15%|█▌        | 77/500 [1:16:34<6:42:47, 57.13s/it] 16%|█▌        | 78/500 [1:17:45<7:09:23, 61.05s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 6.45E+05, Train scatter: [0.9349 0.1726 0.544  0.9955]
L1 regularization loss: 1.01E+01, L2 regularization loss: 4.65E+00
Test scatter: [0.9193 0.1687 0.5354 0.9851], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.236  0.063  0.3927 0.4839], Epochs since improvement 2
 16%|█▌        | 79/500 [1:18:32<6:39:24, 56.92s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 6.28E+05, Train scatter: [0.9347 0.1725 0.544  0.9954]
L1 regularization loss: 1.00E+01, L2 regularization loss: 4.76E+00
Test scatter: [0.9191 0.1687 0.5355 0.985 ], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.236  0.0681 0.3927 0.4989], Epochs since improvement 4
 16%|█▌        | 80/500 [1:19:48<7:19:11, 62.74s/it] 16%|█▌        | 81/500 [1:20:35<6:45:27, 58.06s/it] 16%|█▋        | 82/500 [1:21:46<7:11:48, 61.98s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 6.10E+05, Train scatter: [0.9348 0.1726 0.5441 0.9954]
L1 regularization loss: 1.00E+01, L2 regularization loss: 5.05E+00
Test scatter: [0.9192 0.1688 0.5355 0.985 ], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.9191 0.1687 0.5354 0.985 ], Epochs since improvement 6
 17%|█▋        | 83/500 [1:22:34<6:39:53, 57.54s/it] 17%|█▋        | 84/500 [1:23:45<7:06:43, 61.55s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 5.67E+05, Train scatter: [0.9346 0.1724 0.544  0.9955]
L1 regularization loss: 1.00E+01, L2 regularization loss: 5.73E+00
Test scatter: [0.9191 0.1686 0.5355 0.9851], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.9191 0.1687 0.5355 0.985 ], Epochs since improvement 8
 17%|█▋        | 85/500 [1:24:32<6:35:55, 57.24s/it] 17%|█▋        | 86/500 [1:25:42<7:02:18, 61.20s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 5.35E+05, Train scatter: [0.9345 0.1723 0.5441 0.9954]
L1 regularization loss: 1.00E+01, L2 regularization loss: 6.20E+00
Test scatter: [0.9189 0.1685 0.5355 0.985 ], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.9191 0.1687 0.5355 0.985 ], Epochs since improvement 10
 17%|█▋        | 87/500 [1:26:29<6:32:26, 57.01s/it] 18%|█▊        | 88/500 [1:27:41<7:01:19, 61.36s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 4.71E+05, Train scatter: [0.9335 0.1717 0.544  0.9955]
L1 regularization loss: 1.00E+01, L2 regularization loss: 6.61E+00
Test scatter: [0.9179 0.1678 0.5354 0.9852], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.9191 0.1686 0.5355 0.985 ], Epochs since improvement 12
 18%|█▊        | 89/500 [1:28:28<6:31:09, 57.10s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 4.14E+05, Train scatter: [0.9248 0.1665 0.544  0.9959]
L1 regularization loss: 1.00E+01, L2 regularization loss: 7.10E+00
Test scatter: [0.9084 0.1622 0.5354 0.9856], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.9189 0.1685 0.5355 0.9851], Epochs since improvement 14
 18%|█▊        | 90/500 [1:29:46<7:13:16, 63.40s/it] 18%|█▊        | 91/500 [1:30:33<6:38:52, 58.51s/it] 18%|█▊        | 92/500 [1:31:45<7:04:23, 62.41s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.08E+05, Train scatter: [0.92   0.1299 0.544  0.9985]
L1 regularization loss: 1.02E+01, L2 regularization loss: 7.56E+00
Test scatter: [0.9039 0.1272 0.5354 0.9882], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.9179 0.1678 0.5354 0.9852], Epochs since improvement 16
 19%|█▊        | 93/500 [1:32:32<6:32:05, 57.80s/it] 19%|█▉        | 94/500 [1:33:43<6:58:23, 61.83s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 1.23E+05, Train scatter: [0.5719 0.1189 0.5352 1.0064]
L1 regularization loss: 1.03E+01, L2 regularization loss: 7.81E+00
Test scatter: [0.5506 0.1161 0.5265 0.9962], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.9084 0.1622 0.5354 0.9856], Epochs since improvement 18
 19%|█▉        | 95/500 [1:34:30<6:27:18, 57.38s/it] 19%|█▉        | 96/500 [1:35:41<6:54:42, 61.59s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 9.69E+04, Train scatter: [0.5324 0.11   0.5231 1.0071]
L1 regularization loss: 1.03E+01, L2 regularization loss: 7.93E+00
Test scatter: [0.5137 0.1078 0.5138 0.9969], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.9039 0.1272 0.5354 0.9882], Epochs since improvement 20
 19%|█▉        | 97/500 [1:36:29<6:24:28, 57.24s/it] 19%|█▉        | 97/500 [1:37:39<6:45:45, 60.41s/it]
Epoch: 98 done with learning rate 9.93E-03, Train loss: 8.44E+04, Train scatter: [0.5551 0.1025 0.5072 1.0074]
L1 regularization loss: 1.03E+01, L2 regularization loss: 8.00E+00
Test scatter: [0.5363 0.1009 0.4982 0.9971], Lowest was [0.1997 0.058  0.2978 0.4771]
Median for last 10 epochs: [0.5506 0.1161 0.5265 0.9962], Epochs since improvement 22
Exited after 98 epochs due to early stopping
5859.84 seconds spent training, 11.720 seconds per epoch. Processed 5942 trees per second
[0.536281   0.10094399 0.49815688 0.9970902 ]
{'epoch_exit': 97, 'scatter_m_star': 0.536281, 'lowest_m_star': 0.19971104, 'last20_m_star': 0.9131554, 'last10_m_star': 0.55059206, 'scatter_v_disk': 0.10094399, 'lowest_v_disk': 0.05800298, 'last20_v_disk': 0.16502672, 'last10_v_disk': 0.11607579, 'scatter_m_cold': 0.49815688, 'lowest_m_cold': 0.2978239, 'last20_m_cold': 0.5354302, 'last10_m_cold': 0.52654135, 'scatter_sfr_100': 0.9970902, 'lowest_sfr_100': 0.47705758, 'last20_sfr_100': 0.98537195, 'last10_sfr_100': 0.9962271}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_fucbxf
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:40<5:40:57, 41.00s/it]  0%|          | 2/500 [01:44<7:28:38, 54.05s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.01E+07, Train scatter: [0.9352 0.1712 0.5441 0.9954]
L1 regularization loss: 1.98E+00, L2 regularization loss: 3.76E-01
Test scatter: [0.9196 0.1674 0.5356 0.9851], Lowest was [0.9196 0.1674 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1674 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:24<6:36:56, 47.92s/it]  1%|          | 4/500 [03:27<7:25:29, 53.89s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.21E+07, Train scatter: [0.9352 0.1552 0.5441 0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.85E-01
Test scatter: [0.9196 0.1512 0.5355 0.9851], Lowest was [0.9196 0.1512 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1512 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:08<6:45:06, 49.10s/it]  1%|          | 6/500 [05:11<7:23:48, 53.90s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.69E+07, Train scatter: [0.9347 0.1118 0.544  0.9954]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.01E-01
Test scatter: [0.9191 0.1106 0.5354 0.985 ], Lowest was [0.9191 0.1106 0.5354 0.985 ]
Median for last 10 epochs: [0.9191 0.1106 0.5354 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [05:52<6:47:11, 49.56s/it]  2%|▏         | 8/500 [06:56<7:24:11, 54.17s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.32E+07, Train scatter: [0.9142 0.0959 0.5439 0.8198]
L1 regularization loss: 2.03E+00, L2 regularization loss: 4.26E-01
Test scatter: [0.8987 0.0956 0.5353 0.8093], Lowest was [0.8987 0.0956 0.5353 0.8093]
Median for last 10 epochs: [0.9089 0.1031 0.5354 0.8972], Epochs since improvement 0
  2%|▏         | 9/500 [07:36<6:47:58, 49.85s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 9.54E+06, Train scatter: [0.7621 0.0942 0.5438 0.6672]
L1 regularization loss: 2.06E+00, L2 regularization loss: 4.55E-01
Test scatter: [0.7486 0.0943 0.5352 0.6696], Lowest was [0.7486 0.0943 0.5352 0.6696]
Median for last 10 epochs: [0.8987 0.0956 0.5353 0.8093], Epochs since improvement 0
  2%|▏         | 10/500 [08:46<7:36:10, 55.86s/it]  2%|▏         | 11/500 [09:26<6:57:14, 51.20s/it]  2%|▏         | 12/500 [10:30<7:28:06, 55.09s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.96E+06, Train scatter: [0.5636 0.0895 0.5438 0.6033]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.67E-01
Test scatter: [0.5559 0.0886 0.5352 0.6007], Lowest was [0.5559 0.0886 0.5352 0.6007]
Median for last 10 epochs: [0.8987 0.0956 0.5353 0.8093], Epochs since improvement 0
  3%|▎         | 13/500 [11:11<6:51:39, 50.72s/it]  3%|▎         | 14/500 [12:14<7:22:14, 54.60s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 5.03E+06, Train scatter: [0.3886 0.083  0.5438 0.5616]
L1 regularization loss: 2.08E+00, L2 regularization loss: 4.76E-01
Test scatter: [0.3911 0.0836 0.5353 0.5587], Lowest was [0.3911 0.0836 0.5352 0.5587]
Median for last 10 epochs: [0.7486 0.0943 0.5353 0.6696], Epochs since improvement 0
  3%|▎         | 15/500 [12:55<6:47:03, 50.36s/it]  3%|▎         | 16/500 [13:58<7:18:00, 54.30s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.35E+06, Train scatter: [0.3595 0.0836 0.5437 0.5653]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.82E-01
Test scatter: [0.3602 0.0836 0.5352 0.5607], Lowest was [0.3602 0.0836 0.5352 0.5587]
Median for last 10 epochs: [0.5559 0.0886 0.5352 0.6007], Epochs since improvement 0
  3%|▎         | 17/500 [14:39<6:44:33, 50.26s/it]  4%|▎         | 18/500 [15:42<7:14:07, 54.04s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.11E+06, Train scatter: [0.2616 0.0773 0.5437 0.5459]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.86E-01
Test scatter: [0.2716 0.078  0.5352 0.5427], Lowest was [0.2716 0.078  0.5352 0.5427]
Median for last 10 epochs: [0.3911 0.0836 0.5352 0.5607], Epochs since improvement 0
  4%|▍         | 19/500 [16:23<6:41:34, 50.09s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.87E+06, Train scatter: [0.2809 0.0745 0.5437 0.5245]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.91E-01
Test scatter: [0.2906 0.075  0.5352 0.52  ], Lowest was [0.2716 0.075  0.5352 0.52  ]
Median for last 10 epochs: [0.3602 0.0836 0.5352 0.5587], Epochs since improvement 0
  4%|▍         | 20/500 [17:33<7:28:35, 56.07s/it]  4%|▍         | 21/500 [18:14<6:51:23, 51.53s/it]  4%|▍         | 22/500 [19:17<7:18:42, 55.07s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.82E+06, Train scatter: [0.3772 0.0851 0.5437 0.5614]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.94E-01
Test scatter: [0.3849 0.0845 0.5351 0.5603], Lowest was [0.2716 0.075  0.5351 0.52  ]
Median for last 10 epochs: [0.3602 0.0836 0.5352 0.5587], Epochs since improvement 0
  5%|▍         | 23/500 [19:58<6:43:28, 50.75s/it]  5%|▍         | 24/500 [21:02<7:13:51, 54.69s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.27E+06, Train scatter: [0.3974 0.0765 0.5437 0.5247]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.00E-01
Test scatter: [0.394  0.0759 0.5351 0.5181], Lowest was [0.2716 0.075  0.5351 0.5181]
Median for last 10 epochs: [0.3602 0.078  0.5352 0.5427], Epochs since improvement 0
  5%|▌         | 25/500 [21:42<6:39:31, 50.47s/it]  5%|▌         | 26/500 [22:45<7:07:57, 54.17s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.73E+06, Train scatter: [0.4676 0.0773 0.5436 0.6595]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.05E-01
Test scatter: [0.4667 0.0758 0.5351 0.6587], Lowest was [0.2716 0.075  0.5351 0.5181]
Median for last 10 epochs: [0.3849 0.0759 0.5351 0.5427], Epochs since improvement 0
  5%|▌         | 27/500 [23:26<6:35:12, 50.13s/it]  6%|▌         | 28/500 [24:30<7:06:08, 54.17s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.59E+06, Train scatter: [0.2504 0.0701 0.5436 0.5081]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.10E-01
Test scatter: [0.2521 0.0699 0.535  0.4995], Lowest was [0.2521 0.0699 0.535  0.4995]
Median for last 10 epochs: [0.3849 0.0758 0.5351 0.52  ], Epochs since improvement 0
  6%|▌         | 29/500 [25:10<6:33:00, 50.07s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.58E+06, Train scatter: [0.2092 0.0685 0.5435 0.5184]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.14E-01
Test scatter: [0.2155 0.0691 0.535  0.5085], Lowest was [0.2155 0.0691 0.535  0.4995]
Median for last 10 epochs: [0.3849 0.0758 0.5351 0.5181], Epochs since improvement 0
  6%|▌         | 30/500 [26:22<7:24:09, 56.70s/it]  6%|▌         | 31/500 [27:03<6:45:06, 51.83s/it]  6%|▋         | 32/500 [28:06<7:11:04, 55.27s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.63E+06, Train scatter: [0.2599 0.0736 0.5434 0.5233]
L1 regularization loss: 2.17E+00, L2 regularization loss: 5.20E-01
Test scatter: [0.2664 0.0722 0.5349 0.5122], Lowest was [0.2155 0.0691 0.5349 0.4995]
Median for last 10 epochs: [0.2664 0.0722 0.535  0.5122], Epochs since improvement 0
  7%|▋         | 33/500 [28:47<6:36:31, 50.94s/it]  7%|▋         | 34/500 [29:51<7:06:36, 54.93s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.47E+06, Train scatter: [0.2131 0.0665 0.5434 0.5099]
L1 regularization loss: 2.18E+00, L2 regularization loss: 5.25E-01
Test scatter: [0.218  0.0671 0.5349 0.5042], Lowest was [0.2155 0.0671 0.5349 0.4995]
Median for last 10 epochs: [0.2521 0.0699 0.535  0.5085], Epochs since improvement 0
  7%|▋         | 35/500 [30:32<6:32:36, 50.66s/it]  7%|▋         | 36/500 [31:35<7:00:27, 54.37s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.43E+06, Train scatter: [0.3061 0.0699 0.5435 0.5292]
L1 regularization loss: 2.20E+00, L2 regularization loss: 5.30E-01
Test scatter: [0.3078 0.0708 0.5349 0.523 ], Lowest was [0.2155 0.0671 0.5349 0.4995]
Median for last 10 epochs: [0.2521 0.0699 0.5349 0.5085], Epochs since improvement 2
  7%|▋         | 37/500 [32:15<6:27:20, 50.20s/it]  8%|▊         | 38/500 [33:19<6:56:55, 54.15s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.52E+06, Train scatter: [0.2232 0.0673 0.5434 0.5075]
L1 regularization loss: 2.23E+00, L2 regularization loss: 5.41E-01
Test scatter: [0.231  0.0673 0.5348 0.5026], Lowest was [0.2155 0.0671 0.5348 0.4995]
Median for last 10 epochs: [0.231  0.0691 0.5349 0.5085], Epochs since improvement 0
  8%|▊         | 39/500 [33:59<6:24:27, 50.04s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.38E+06, Train scatter: [0.2055 0.0671 0.5432 0.5053]
L1 regularization loss: 2.24E+00, L2 regularization loss: 5.46E-01
Test scatter: [0.2136 0.0671 0.5347 0.4983], Lowest was [0.2136 0.0671 0.5347 0.4983]
Median for last 10 epochs: [0.231  0.0673 0.5349 0.5042], Epochs since improvement 0
  8%|▊         | 40/500 [35:09<7:10:04, 56.10s/it]  8%|▊         | 41/500 [35:50<6:33:36, 51.45s/it]  8%|▊         | 42/500 [36:54<7:02:18, 55.33s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.21E+06, Train scatter: [0.2128 0.0673 0.5434 0.5096]
L1 regularization loss: 2.26E+00, L2 regularization loss: 5.54E-01
Test scatter: [0.2188 0.0669 0.5349 0.5111], Lowest was [0.2136 0.0669 0.5347 0.4983]
Median for last 10 epochs: [0.2188 0.0671 0.5349 0.5042], Epochs since improvement 0
  9%|▊         | 43/500 [37:35<6:27:15, 50.84s/it]  9%|▉         | 44/500 [38:38<6:54:48, 54.58s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.19E+06, Train scatter: [0.2107 0.0657 0.5434 0.4986]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.60E-01
Test scatter: [0.2189 0.065  0.5348 0.4932], Lowest was [0.2136 0.065  0.5347 0.4932]
Median for last 10 epochs: [0.2189 0.0671 0.5348 0.5026], Epochs since improvement 0
  9%|▉         | 45/500 [39:18<6:21:54, 50.36s/it]  9%|▉         | 46/500 [40:22<6:50:37, 54.27s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.37E+06, Train scatter: [0.4372 0.0787 0.5434 0.5254]
L1 regularization loss: 2.31E+00, L2 regularization loss: 5.81E-01
Test scatter: [0.4297 0.077  0.5349 0.5186], Lowest was [0.2136 0.065  0.5347 0.4932]
Median for last 10 epochs: [0.2189 0.0671 0.5348 0.5026], Epochs since improvement 2
  9%|▉         | 47/500 [41:02<6:18:49, 50.18s/it] 10%|▉         | 48/500 [42:06<6:48:10, 54.18s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.18E+06, Train scatter: [0.3512 0.0911 0.5433 0.5495]
L1 regularization loss: 2.32E+00, L2 regularization loss: 5.86E-01
Test scatter: [0.355  0.0879 0.5347 0.5366], Lowest was [0.2136 0.065  0.5347 0.4932]
Median for last 10 epochs: [0.2189 0.0671 0.5348 0.5111], Epochs since improvement 0
 10%|▉         | 49/500 [42:47<6:16:34, 50.10s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.16E+06, Train scatter: [0.2225 0.0722 0.5433 0.5086]
L1 regularization loss: 2.33E+00, L2 regularization loss: 5.94E-01
Test scatter: [0.2329 0.071  0.5348 0.5011], Lowest was [0.2136 0.065  0.5347 0.4932]
Median for last 10 epochs: [0.2329 0.071  0.5348 0.5111], Epochs since improvement 2
 10%|█         | 50/500 [43:56<6:59:35, 55.95s/it] 10%|█         | 51/500 [44:37<6:23:59, 51.31s/it] 10%|█         | 52/500 [45:41<6:52:33, 55.25s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.15E+06, Train scatter: [0.3773 0.0663 0.5433 0.4966]
L1 regularization loss: 2.33E+00, L2 regularization loss: 6.03E-01
Test scatter: [0.3701 0.0655 0.5348 0.4924], Lowest was [0.2136 0.065  0.5347 0.4924]
Median for last 10 epochs: [0.355  0.071  0.5348 0.5011], Epochs since improvement 0
 11%|█         | 53/500 [46:21<6:18:24, 50.79s/it] 11%|█         | 54/500 [47:26<6:48:34, 54.97s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.14E+06, Train scatter: [0.2115 0.0665 0.5432 0.4947]
L1 regularization loss: 2.34E+00, L2 regularization loss: 6.12E-01
Test scatter: [0.2146 0.0657 0.5347 0.4889], Lowest was [0.2136 0.065  0.5347 0.4889]
Median for last 10 epochs: [0.355  0.071  0.5348 0.5011], Epochs since improvement 0
 11%|█         | 55/500 [48:07<6:15:11, 50.59s/it] 11%|█         | 56/500 [49:10<6:43:43, 54.56s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.13E+06, Train scatter: [0.2135 0.0639 0.5432 0.4968]
L1 regularization loss: 2.35E+00, L2 regularization loss: 6.19E-01
Test scatter: [0.2197 0.0634 0.5347 0.4967], Lowest was [0.2136 0.0634 0.5347 0.4889]
Median for last 10 epochs: [0.2329 0.0657 0.5347 0.4967], Epochs since improvement 0
 11%|█▏        | 57/500 [49:51<6:11:17, 50.29s/it] 12%|█▏        | 58/500 [50:55<6:40:48, 54.41s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.13E+06, Train scatter: [0.2687 0.0694 0.5432 0.5279]
L1 regularization loss: 2.36E+00, L2 regularization loss: 6.29E-01
Test scatter: [0.2723 0.0693 0.5346 0.5332], Lowest was [0.2136 0.0634 0.5346 0.4889]
Median for last 10 epochs: [0.2329 0.0657 0.5347 0.4967], Epochs since improvement 0
 12%|█▏        | 59/500 [51:35<6:09:19, 50.25s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.27E+06, Train scatter: [0.699  0.0951 0.5436 0.5875]
L1 regularization loss: 2.47E+00, L2 regularization loss: 6.76E-01
Test scatter: [0.6822 0.0924 0.535  0.5776], Lowest was [0.2136 0.0634 0.5346 0.4889]
Median for last 10 epochs: [0.2723 0.0657 0.5347 0.4967], Epochs since improvement 2
 12%|█▏        | 60/500 [52:45<6:51:51, 56.16s/it] 12%|█▏        | 61/500 [53:26<6:17:00, 51.53s/it] 12%|█▏        | 62/500 [54:30<6:42:58, 55.20s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.17E+06, Train scatter: [0.3914 0.0781 0.5435 0.5295]
L1 regularization loss: 2.48E+00, L2 regularization loss: 6.91E-01
Test scatter: [0.3833 0.0763 0.5349 0.5245], Lowest was [0.2136 0.0634 0.5346 0.4889]
Median for last 10 epochs: [0.2723 0.0693 0.5347 0.5245], Epochs since improvement 4
 13%|█▎        | 63/500 [55:10<6:10:13, 50.83s/it] 13%|█▎        | 64/500 [56:14<6:37:47, 54.74s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.16E+06, Train scatter: [0.4242 0.0781 0.5433 0.5113]
L1 regularization loss: 2.47E+00, L2 regularization loss: 7.01E-01
Test scatter: [0.4152 0.0773 0.5348 0.5063], Lowest was [0.2136 0.0634 0.5346 0.4889]
Median for last 10 epochs: [0.3833 0.0763 0.5348 0.5245], Epochs since improvement 6
 13%|█▎        | 65/500 [56:55<6:05:34, 50.42s/it] 13%|█▎        | 66/500 [57:58<6:34:04, 54.48s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.08E+06, Train scatter: [0.3244 0.0774 0.5428 0.5147]
L1 regularization loss: 2.50E+00, L2 regularization loss: 7.20E-01
Test scatter: [0.3328 0.0761 0.5342 0.5116], Lowest was [0.2136 0.0634 0.5342 0.4889]
Median for last 10 epochs: [0.3833 0.0763 0.5348 0.5245], Epochs since improvement 0
 13%|█▎        | 67/500 [58:39<6:02:22, 50.21s/it] 14%|█▎        | 68/500 [59:42<6:30:06, 54.18s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.05E+06, Train scatter: [0.3479 0.0676 0.5429 0.4995]
L1 regularization loss: 2.51E+00, L2 regularization loss: 7.30E-01
Test scatter: [0.3429 0.0685 0.5344 0.4986], Lowest was [0.2136 0.0634 0.5342 0.4889]
Median for last 10 epochs: [0.3833 0.0763 0.5348 0.5116], Epochs since improvement 2
 14%|█▍        | 69/500 [1:00:23<5:59:49, 50.09s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.03E+06, Train scatter: [0.334  0.0663 0.5428 0.5212]
L1 regularization loss: 2.52E+00, L2 regularization loss: 7.40E-01
Test scatter: [0.3334 0.0667 0.5344 0.5258], Lowest was [0.2136 0.0634 0.5342 0.4889]
Median for last 10 epochs: [0.3429 0.0761 0.5344 0.5116], Epochs since improvement 4
 14%|█▍        | 70/500 [1:01:33<6:42:25, 56.15s/it] 14%|█▍        | 71/500 [1:02:14<6:08:22, 51.52s/it] 14%|█▍        | 72/500 [1:03:18<6:35:26, 55.44s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.04E+06, Train scatter: [0.2268 0.0657 0.5426 0.4945]
L1 regularization loss: 2.56E+00, L2 regularization loss: 7.61E-01
Test scatter: [0.2302 0.0655 0.5341 0.4953], Lowest was [0.2136 0.0634 0.5341 0.4889]
Median for last 10 epochs: [0.3334 0.0685 0.5344 0.5063], Epochs since improvement 0
 15%|█▍        | 73/500 [1:03:59<6:02:46, 50.97s/it] 15%|█▍        | 74/500 [1:05:03<6:29:20, 54.84s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.01E+06, Train scatter: [0.3862 0.0661 0.5424 0.5072]
L1 regularization loss: 2.60E+00, L2 regularization loss: 7.83E-01
Test scatter: [0.3785 0.0657 0.5339 0.5081], Lowest was [0.2136 0.0634 0.5339 0.4889]
Median for last 10 epochs: [0.3334 0.0667 0.5342 0.5081], Epochs since improvement 0
 15%|█▌        | 75/500 [1:05:44<5:59:28, 50.75s/it] 15%|█▌        | 76/500 [1:06:48<6:27:44, 54.87s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 3.01E+06, Train scatter: [0.3434 0.0658 0.5423 0.5147]
L1 regularization loss: 2.63E+00, L2 regularization loss: 7.96E-01
Test scatter: [0.3377 0.0656 0.5338 0.5177], Lowest was [0.2136 0.0634 0.5338 0.4889]
Median for last 10 epochs: [0.3377 0.0657 0.5341 0.5081], Epochs since improvement 0
 15%|█▌        | 77/500 [1:07:29<5:56:53, 50.62s/it] 16%|█▌        | 78/500 [1:08:33<6:24:00, 54.60s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 3.00E+06, Train scatter: [0.3664 0.0719 0.5422 0.4961]
L1 regularization loss: 2.64E+00, L2 regularization loss: 8.10E-01
Test scatter: [0.36   0.0711 0.5338 0.4933], Lowest was [0.2136 0.0634 0.5338 0.4889]
Median for last 10 epochs: [0.3377 0.0657 0.5339 0.5081], Epochs since improvement 0
 16%|█▌        | 79/500 [1:09:14<5:53:53, 50.44s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.97E+06, Train scatter: [0.4045 0.0606 0.5415 0.4819]
L1 regularization loss: 2.65E+00, L2 regularization loss: 8.21E-01
Test scatter: [0.398  0.0609 0.5331 0.483 ], Lowest was [0.2136 0.0609 0.5331 0.483 ]
Median for last 10 epochs: [0.36   0.0656 0.5338 0.4953], Epochs since improvement 0
 16%|█▌        | 80/500 [1:10:26<6:37:58, 56.85s/it] 16%|█▌        | 81/500 [1:11:06<6:02:37, 51.93s/it] 16%|█▋        | 82/500 [1:12:10<6:26:17, 55.45s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.96E+06, Train scatter: [0.4116 0.0694 0.5402 0.4934]
L1 regularization loss: 2.67E+00, L2 regularization loss: 8.36E-01
Test scatter: [0.4076 0.0697 0.5318 0.4913], Lowest was [0.2136 0.0609 0.5318 0.483 ]
Median for last 10 epochs: [0.3785 0.0657 0.5338 0.4933], Epochs since improvement 0
 17%|█▋        | 83/500 [1:12:50<5:54:21, 50.99s/it] 17%|█▋        | 84/500 [1:13:53<6:17:36, 54.46s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.96E+06, Train scatter: [0.338  0.0671 0.5399 0.5049]
L1 regularization loss: 2.68E+00, L2 regularization loss: 8.52E-01
Test scatter: [0.3329 0.0674 0.5316 0.5054], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.36   0.0674 0.5331 0.4933], Epochs since improvement 0
 17%|█▋        | 85/500 [1:14:33<5:47:51, 50.29s/it] 17%|█▋        | 86/500 [1:15:36<6:13:31, 54.13s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 3.21E+06, Train scatter: [0.9303 0.0974 0.544  0.6311]
L1 regularization loss: 2.98E+00, L2 regularization loss: 1.02E+00
Test scatter: [0.9141 0.0996 0.5354 0.6424], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.398  0.0697 0.5331 0.4933], Epochs since improvement 2
 17%|█▋        | 87/500 [1:16:17<5:44:41, 50.08s/it] 18%|█▊        | 88/500 [1:17:21<6:11:26, 54.09s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 3.15E+06, Train scatter: [0.9304 0.119  0.5439 0.6977]
L1 regularization loss: 2.98E+00, L2 regularization loss: 1.04E+00
Test scatter: [0.913  0.12   0.5354 0.7089], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.4076 0.0697 0.5331 0.5054], Epochs since improvement 4
 18%|█▊        | 89/500 [1:18:01<5:43:11, 50.10s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 3.14E+06, Train scatter: [0.9285 0.1154 0.5439 0.6208]
L1 regularization loss: 2.98E+00, L2 regularization loss: 1.06E+00
Test scatter: [0.9116 0.1154 0.5353 0.6347], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.9116 0.0996 0.5353 0.6347], Epochs since improvement 6
 18%|█▊        | 90/500 [1:19:12<6:24:21, 56.25s/it] 18%|█▊        | 91/500 [1:19:53<5:51:48, 51.61s/it] 18%|█▊        | 92/500 [1:20:55<6:13:12, 54.88s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 3.12E+06, Train scatter: [0.9279 0.0965 0.5438 0.5729]
L1 regularization loss: 2.99E+00, L2 regularization loss: 1.10E+00
Test scatter: [0.9118 0.0972 0.5352 0.5728], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.9118 0.0996 0.5353 0.6347], Epochs since improvement 8
 19%|█▊        | 93/500 [1:21:36<5:43:24, 50.63s/it] 19%|█▉        | 94/500 [1:22:39<6:07:18, 54.28s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 3.10E+06, Train scatter: [0.9206 0.0896 0.5438 0.5564]
L1 regularization loss: 2.99E+00, L2 regularization loss: 1.12E+00
Test scatter: [0.9049 0.0902 0.5352 0.5612], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.9118 0.0996 0.5353 0.6347], Epochs since improvement 10
 19%|█▉        | 95/500 [1:23:19<5:38:26, 50.14s/it] 19%|█▉        | 96/500 [1:24:22<6:02:34, 53.85s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 3.08E+06, Train scatter: [0.8914 0.082  0.5437 0.5504]
L1 regularization loss: 2.99E+00, L2 regularization loss: 1.15E+00
Test scatter: [0.8769 0.0827 0.5351 0.5544], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.9116 0.0972 0.5352 0.5728], Epochs since improvement 12
 19%|█▉        | 97/500 [1:25:02<5:34:42, 49.83s/it] 20%|█▉        | 98/500 [1:26:07<6:03:11, 54.21s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 3.05E+06, Train scatter: [0.6849 0.1179 0.5435 0.574 ]
L1 regularization loss: 3.03E+00, L2 regularization loss: 1.19E+00
Test scatter: [0.6792 0.1168 0.5349 0.5774], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.9049 0.0972 0.5352 0.5728], Epochs since improvement 14
 20%|█▉        | 99/500 [1:26:47<5:34:46, 50.09s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 3.01E+06, Train scatter: [0.4761 0.0902 0.5432 0.5391]
L1 regularization loss: 3.03E+00, L2 regularization loss: 1.22E+00
Test scatter: [0.4715 0.0911 0.5346 0.5439], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.8769 0.0911 0.5351 0.5612], Epochs since improvement 16
 20%|██        | 100/500 [1:27:58<6:16:07, 56.42s/it] 20%|██        | 101/500 [1:28:39<5:43:33, 51.66s/it] 20%|██        | 102/500 [1:29:43<6:07:30, 55.40s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 3.01E+06, Train scatter: [0.9352 0.1729 0.5441 0.9954]
L1 regularization loss: 6.13E+00, L2 regularization loss: 2.57E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.8769 0.0911 0.5351 0.5612], Epochs since improvement 18
 21%|██        | 103/500 [1:30:24<5:37:31, 51.01s/it] 21%|██        | 104/500 [1:31:27<5:59:59, 54.54s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 2.53E+06, Train scatter: [0.9352 0.1729 0.5441 0.9954]
L1 regularization loss: 6.13E+00, L2 regularization loss: 2.57E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.8769 0.1168 0.5351 0.5774], Epochs since improvement 20
 21%|██        | 105/500 [1:32:07<5:32:01, 50.43s/it] 21%|██        | 105/500 [1:33:11<5:50:35, 53.25s/it]
Epoch: 106 done with learning rate 9.87E-03, Train loss: 2.08E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 6.14E+00, L2 regularization loss: 2.58E+00
Test scatter: [0.9196 0.169  0.5355 0.9851], Lowest was [0.2136 0.0609 0.5316 0.483 ]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.9851], Epochs since improvement 22
Exited after 106 epochs due to early stopping
5591.67 seconds spent training, 11.183 seconds per epoch. Processed 6227 trees per second
[0.9195547  0.16900826 0.53547335 0.98504305]
{'epoch_exit': 105, 'scatter_m_star': 0.9195547, 'lowest_m_star': 0.21363981, 'last20_m_star': 0.9117079, 'last10_m_star': 0.91958106, 'scatter_v_disk': 0.16900826, 'lowest_v_disk': 0.06089391, 'last20_v_disk': 0.116135195, 'last10_v_disk': 0.16901308, 'scatter_m_cold': 0.53547335, 'lowest_m_cold': 0.53157586, 'last20_m_cold': 0.53527474, 'last10_m_cold': 0.5354883, 'scatter_sfr_100': 0.98504305, 'lowest_sfr_100': 0.48303828, 'last20_sfr_100': 0.6060441, 'last10_sfr_100': 0.98506826}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_kherqz
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:01<8:31:57, 61.56s/it]  0%|          | 2/500 [02:31<10:49:28, 78.25s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.18E+07, Train scatter: [0.9351 0.1349 0.544  0.9954]
L1 regularization loss: 2.45E+00, L2 regularization loss: 4.24E-01
Test scatter: [0.9195 0.1315 0.5355 0.9851], Lowest was [0.9195 0.1315 0.5355 0.9851]
Median for last 10 epochs: [0.9195 0.1315 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [03:33<9:45:26, 70.68s/it]   1%|          | 4/500 [05:04<10:50:10, 78.65s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.13E+07, Train scatter: [0.934  0.1106 0.544  0.9954]
L1 regularization loss: 2.46E+00, L2 regularization loss: 4.29E-01
Test scatter: [0.9183 0.1091 0.5354 0.9851], Lowest was [0.9183 0.1091 0.5354 0.9851]
Median for last 10 epochs: [0.9183 0.1091 0.5354 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:05<9:58:55, 72.60s/it]   1%|          | 6/500 [07:36<10:48:20, 78.75s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.64E+08, Train scatter: [0.9346 0.1731 0.544  0.9953]
L1 regularization loss: 2.51E+00, L2 regularization loss: 4.40E-01
Test scatter: [0.9189 0.1682 0.5354 0.985 ], Lowest was [0.9183 0.1091 0.5354 0.985 ]
Median for last 10 epochs: [0.9183 0.1091 0.5354 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [08:38<10:01:33, 73.21s/it]  2%|▏         | 8/500 [10:09<10:46:32, 78.85s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.08E+08, Train scatter: [0.9332 0.1574 0.5432 0.9954]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.45E-01
Test scatter: [0.9176 0.1534 0.5346 0.9851], Lowest was [0.9176 0.1091 0.5346 0.985 ]
Median for last 10 epochs: [0.9179 0.1313 0.535  0.985 ], Epochs since improvement 0
  2%|▏         | 9/500 [11:10<10:00:37, 73.40s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 9.67E+07, Train scatter: [0.9314 0.1204 0.5263 0.9955]
L1 regularization loss: 2.54E+00, L2 regularization loss: 4.54E-01
Test scatter: [0.9163 0.1178 0.5183 0.9851], Lowest was [0.9163 0.1091 0.5183 0.985 ]
Median for last 10 epochs: [0.9176 0.1178 0.5346 0.9851], Epochs since improvement 0
  2%|▏         | 10/500 [12:49<11:02:40, 81.14s/it]  2%|▏         | 11/500 [13:50<10:12:31, 75.16s/it]  2%|▏         | 12/500 [15:22<10:51:14, 80.07s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 9.10E+07, Train scatter: [0.9295 0.0998 0.4079 0.9954]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.61E-01
Test scatter: [0.9145 0.1008 0.4073 0.9851], Lowest was [0.9145 0.1008 0.4073 0.985 ]
Median for last 10 epochs: [0.9176 0.1178 0.5346 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [16:23<10:05:09, 74.56s/it]  3%|▎         | 14/500 [17:54<10:43:07, 79.40s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 8.83E+07, Train scatter: [0.9281 0.0956 0.3745 0.9954]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.66E-01
Test scatter: [0.9135 0.0973 0.3783 0.985 ], Lowest was [0.9135 0.0973 0.3783 0.985 ]
Median for last 10 epochs: [0.9163 0.1178 0.5183 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [18:56<9:58:34, 74.05s/it]   3%|▎         | 16/500 [20:26<10:37:58, 79.09s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 8.46E+07, Train scatter: [0.9229 0.0917 0.3576 0.9952]
L1 regularization loss: 2.56E+00, L2 regularization loss: 4.73E-01
Test scatter: [0.9089 0.093  0.3597 0.985 ], Lowest was [0.9089 0.093  0.3597 0.985 ]
Median for last 10 epochs: [0.9145 0.1008 0.4073 0.9851], Epochs since improvement 0
  3%|▎         | 17/500 [21:28<9:54:16, 73.82s/it]   4%|▎         | 18/500 [22:59<10:34:11, 78.95s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 6.50E+07, Train scatter: [0.9022 0.0966 0.4094 0.9846]
L1 regularization loss: 2.57E+00, L2 regularization loss: 4.85E-01
Test scatter: [0.8901 0.0989 0.4138 0.983 ], Lowest was [0.8901 0.093  0.3597 0.983 ]
Median for last 10 epochs: [0.9135 0.0989 0.4073 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [24:01<9:51:45, 73.81s/it] Epoch: 20 done with learning rate 1.99E-03, Train loss: 8.62E+06, Train scatter: [0.5324 0.0879 0.3625 0.6537]
L1 regularization loss: 2.59E+00, L2 regularization loss: 5.03E-01
Test scatter: [0.5346 0.0875 0.3626 0.6636], Lowest was [0.5346 0.0875 0.3597 0.6636]
Median for last 10 epochs: [0.9089 0.0973 0.3783 0.985 ], Epochs since improvement 0
  4%|▍         | 20/500 [25:39<10:49:09, 81.15s/it]  4%|▍         | 21/500 [26:41<10:01:30, 75.35s/it]  4%|▍         | 22/500 [28:11<10:36:46, 79.93s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 6.01E+06, Train scatter: [0.3764 0.0819 0.3526 0.5651]
L1 regularization loss: 2.60E+00, L2 regularization loss: 5.12E-01
Test scatter: [0.3861 0.0821 0.3556 0.571 ], Lowest was [0.3861 0.0821 0.3556 0.571 ]
Median for last 10 epochs: [0.8901 0.093  0.3626 0.983 ], Epochs since improvement 0
  5%|▍         | 23/500 [29:13<9:51:45, 74.43s/it]   5%|▍         | 24/500 [30:44<10:29:12, 79.31s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.80E+06, Train scatter: [0.2988 0.0791 0.3489 0.5403]
L1 regularization loss: 2.61E+00, L2 regularization loss: 5.20E-01
Test scatter: [0.3133 0.0801 0.3511 0.545 ], Lowest was [0.3133 0.0801 0.3511 0.545 ]
Median for last 10 epochs: [0.5346 0.0875 0.3597 0.6636], Epochs since improvement 0
  5%|▌         | 25/500 [31:45<9:45:26, 73.95s/it]   5%|▌         | 26/500 [33:17<10:26:01, 79.24s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 4.42E+06, Train scatter: [0.268  0.0793 0.3457 0.5387]
L1 regularization loss: 2.63E+00, L2 regularization loss: 5.29E-01
Test scatter: [0.279  0.0791 0.346  0.5379], Lowest was [0.279  0.0791 0.346  0.5379]
Median for last 10 epochs: [0.3861 0.0821 0.3556 0.571 ], Epochs since improvement 0
  5%|▌         | 27/500 [34:19<9:43:24, 74.01s/it]   6%|▌         | 28/500 [35:49<10:21:57, 79.06s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 4.21E+06, Train scatter: [0.2513 0.0744 0.339  0.5406]
L1 regularization loss: 2.65E+00, L2 regularization loss: 5.42E-01
Test scatter: [0.2647 0.0747 0.3435 0.5445], Lowest was [0.2647 0.0747 0.3435 0.5379]
Median for last 10 epochs: [0.3133 0.0801 0.3511 0.545 ], Epochs since improvement 0
  6%|▌         | 29/500 [36:51<9:39:58, 73.88s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.06E+06, Train scatter: [0.2575 0.0736 0.3386 0.538 ]
L1 regularization loss: 2.67E+00, L2 regularization loss: 5.54E-01
Test scatter: [0.2689 0.0746 0.3448 0.5398], Lowest was [0.2647 0.0746 0.3435 0.5379]
Median for last 10 epochs: [0.279  0.0791 0.346  0.5445], Epochs since improvement 0
  6%|▌         | 30/500 [38:30<10:35:59, 81.19s/it]  6%|▌         | 31/500 [39:31<9:49:06, 75.37s/it]   6%|▋         | 32/500 [41:02<10:24:28, 80.06s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 4.06E+06, Train scatter: [0.2518 0.0735 0.3333 0.5312]
L1 regularization loss: 2.69E+00, L2 regularization loss: 5.66E-01
Test scatter: [0.2595 0.0742 0.3346 0.5328], Lowest was [0.2595 0.0742 0.3346 0.5328]
Median for last 10 epochs: [0.2689 0.0747 0.3448 0.5398], Epochs since improvement 0
  7%|▋         | 33/500 [42:04<9:40:10, 74.54s/it]   7%|▋         | 34/500 [43:35<10:16:15, 79.35s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.89E+06, Train scatter: [0.2378 0.0708 0.3268 0.5027]
L1 regularization loss: 2.71E+00, L2 regularization loss: 5.80E-01
Test scatter: [0.2485 0.0713 0.3356 0.5038], Lowest was [0.2485 0.0713 0.3346 0.5038]
Median for last 10 epochs: [0.2647 0.0746 0.3435 0.5379], Epochs since improvement 0
  7%|▋         | 35/500 [44:36<9:33:53, 74.05s/it]   7%|▋         | 36/500 [46:07<10:10:51, 78.99s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.57E+06, Train scatter: [0.24   0.0731 0.3351 0.5205]
L1 regularization loss: 2.73E+00, L2 regularization loss: 5.95E-01
Test scatter: [0.2576 0.0735 0.3404 0.5178], Lowest was [0.2485 0.0713 0.3346 0.5038]
Median for last 10 epochs: [0.2595 0.0742 0.3404 0.5328], Epochs since improvement 2
  7%|▋         | 37/500 [47:08<9:29:34, 73.81s/it]   8%|▊         | 38/500 [48:40<10:09:51, 79.20s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.62E+06, Train scatter: [0.216  0.0692 0.3342 0.5086]
L1 regularization loss: 2.76E+00, L2 regularization loss: 6.15E-01
Test scatter: [0.2243 0.0691 0.3422 0.5044], Lowest was [0.2243 0.0691 0.3346 0.5038]
Median for last 10 epochs: [0.2576 0.0735 0.3404 0.5178], Epochs since improvement 0
  8%|▊         | 39/500 [49:42<9:28:08, 73.95s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.41E+06, Train scatter: [0.2511 0.0686 0.3434 0.5383]
L1 regularization loss: 2.79E+00, L2 regularization loss: 6.35E-01
Test scatter: [0.2601 0.0699 0.3465 0.5492], Lowest was [0.2243 0.0691 0.3346 0.5038]
Median for last 10 epochs: [0.2576 0.0713 0.3404 0.5178], Epochs since improvement 2
  8%|▊         | 40/500 [51:20<10:21:58, 81.13s/it]  8%|▊         | 41/500 [52:22<9:36:12, 75.32s/it]   8%|▊         | 42/500 [53:52<10:09:06, 79.79s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.24E+06, Train scatter: [0.2091 0.065  0.308  0.4807]
L1 regularization loss: 2.83E+00, L2 regularization loss: 6.59E-01
Test scatter: [0.2222 0.0653 0.3135 0.4818], Lowest was [0.2222 0.0653 0.3135 0.4818]
Median for last 10 epochs: [0.2485 0.0699 0.3404 0.5044], Epochs since improvement 0
  9%|▊         | 43/500 [54:54<9:26:44, 74.41s/it]   9%|▉         | 44/500 [56:24<10:02:49, 79.32s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.22E+06, Train scatter: [0.2145 0.0642 0.3127 0.4823]
L1 regularization loss: 2.86E+00, L2 regularization loss: 6.86E-01
Test scatter: [0.2161 0.0651 0.3172 0.4814], Lowest was [0.2161 0.0651 0.3135 0.4814]
Median for last 10 epochs: [0.2243 0.0691 0.3404 0.5044], Epochs since improvement 0
  9%|▉         | 45/500 [57:26<9:21:01, 73.98s/it]   9%|▉         | 46/500 [58:57<9:59:23, 79.21s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.83E+06, Train scatter: [0.2181 0.0667 0.3024 0.4771]
L1 regularization loss: 2.89E+00, L2 regularization loss: 7.12E-01
Test scatter: [0.2218 0.0671 0.3078 0.4769], Lowest was [0.2161 0.0651 0.3078 0.4769]
Median for last 10 epochs: [0.2222 0.0671 0.3172 0.4818], Epochs since improvement 0
  9%|▉         | 47/500 [59:59<9:19:12, 74.07s/it] 10%|▉         | 48/500 [1:01:31<9:57:08, 79.27s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.57E+06, Train scatter: [0.1994 0.0629 0.2969 0.6167]
L1 regularization loss: 2.93E+00, L2 regularization loss: 7.42E-01
Test scatter: [0.2091 0.0638 0.2999 0.4675], Lowest was [0.2091 0.0638 0.2999 0.4675]
Median for last 10 epochs: [0.2218 0.0653 0.3135 0.4814], Epochs since improvement 0
 10%|▉         | 49/500 [1:02:32<9:16:06, 73.98s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 5.17E+06, Train scatter: [0.3311 0.0955 0.4215 0.5914]
L1 regularization loss: 3.10E+00, L2 regularization loss: 8.36E-01
Test scatter: [0.3388 0.0945 0.4244 0.5915], Lowest was [0.2091 0.0638 0.2999 0.4675]
Median for last 10 epochs: [0.2218 0.0653 0.3135 0.4814], Epochs since improvement 2
 10%|█         | 50/500 [1:04:10<10:08:00, 81.07s/it] 10%|█         | 51/500 [1:05:12<9:23:28, 75.30s/it]  10%|█         | 52/500 [1:06:44<9:59:07, 80.24s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.42E+06, Train scatter: [0.3103 0.0817 0.4016 0.5498]
L1 regularization loss: 3.14E+00, L2 regularization loss: 8.66E-01
Test scatter: [0.3192 0.083  0.4016 0.5515], Lowest was [0.2091 0.0638 0.2999 0.4675]
Median for last 10 epochs: [0.2218 0.0671 0.3172 0.4814], Epochs since improvement 4
 11%|█         | 53/500 [1:07:45<9:16:33, 74.71s/it] 11%|█         | 54/500 [1:09:16<9:50:40, 79.46s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.94E+06, Train scatter: [0.2646 0.0736 0.3702 0.5418]
L1 regularization loss: 3.16E+00, L2 regularization loss: 8.95E-01
Test scatter: [0.2641 0.0748 0.3719 0.5401], Lowest was [0.2091 0.0638 0.2999 0.4675]
Median for last 10 epochs: [0.2641 0.0748 0.3719 0.5401], Epochs since improvement 6
 11%|█         | 55/500 [1:10:18<9:09:33, 74.10s/it] 11%|█         | 56/500 [1:11:48<9:45:11, 79.08s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.53E+06, Train scatter: [0.2409 0.0691 0.3664 0.507 ]
L1 regularization loss: 3.19E+00, L2 regularization loss: 9.23E-01
Test scatter: [0.249  0.0698 0.3666 0.5036], Lowest was [0.2091 0.0638 0.2999 0.4675]
Median for last 10 epochs: [0.2641 0.0748 0.3719 0.5401], Epochs since improvement 8
 11%|█▏        | 57/500 [1:12:50<9:05:58, 73.95s/it] 12%|█▏        | 58/500 [1:14:21<9:41:40, 78.96s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.78E+06, Train scatter: [0.2723 0.0759 0.3818 0.5447]
L1 regularization loss: 3.24E+00, L2 regularization loss: 9.69E-01
Test scatter: [0.282  0.0769 0.3859 0.5436], Lowest was [0.2091 0.0638 0.2999 0.4675]
Median for last 10 epochs: [0.282  0.0769 0.3859 0.5436], Epochs since improvement 10
 12%|█▏        | 59/500 [1:15:22<9:01:44, 73.71s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 2.15E+06, Train scatter: [0.2352 0.0759 0.3629 0.5176]
L1 regularization loss: 3.26E+00, L2 regularization loss: 9.97E-01
Test scatter: [0.2426 0.0764 0.3659 0.5207], Lowest was [0.2091 0.0638 0.2999 0.4675]
Median for last 10 epochs: [0.2641 0.0764 0.3719 0.5401], Epochs since improvement 12
 12%|█▏        | 60/500 [1:17:01<9:55:36, 81.22s/it] 12%|█▏        | 61/500 [1:18:03<9:12:21, 75.49s/it] 12%|█▏        | 62/500 [1:19:34<9:44:33, 80.08s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.94E+06, Train scatter: [0.2462 0.0702 0.3597 0.5355]
L1 regularization loss: 3.29E+00, L2 regularization loss: 1.02E+00
Test scatter: [0.2507 0.0709 0.3644 0.5413], Lowest was [0.2091 0.0638 0.2999 0.4675]
Median for last 10 epochs: [0.2507 0.0748 0.3666 0.5401], Epochs since improvement 14
 13%|█▎        | 63/500 [1:20:36<9:03:04, 74.56s/it] 13%|█▎        | 64/500 [1:22:07<9:38:57, 79.67s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.19E+06, Train scatter: [0.2492 0.0737 0.3655 0.5158]
L1 regularization loss: 3.34E+00, L2 regularization loss: 1.06E+00
Test scatter: [0.2567 0.0748 0.3686 0.5187], Lowest was [0.2091 0.0638 0.2999 0.4675]
Median for last 10 epochs: [0.2507 0.0748 0.3666 0.5207], Epochs since improvement 16
 13%|█▎        | 65/500 [1:23:09<8:58:39, 74.30s/it] 13%|█▎        | 66/500 [1:24:40<9:33:22, 79.27s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.72E+06, Train scatter: [0.2197 0.0676 0.3542 0.5006]
L1 regularization loss: 3.37E+00, L2 regularization loss: 1.09E+00
Test scatter: [0.2262 0.0689 0.3581 0.5044], Lowest was [0.2091 0.0638 0.2999 0.4675]
Median for last 10 epochs: [0.2507 0.0748 0.3659 0.5207], Epochs since improvement 18
 13%|█▎        | 67/500 [1:25:42<8:53:43, 73.96s/it] 14%|█▎        | 68/500 [1:27:12<9:27:19, 78.79s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.61E+06, Train scatter: [0.2492 0.0655 0.3454 0.5024]
L1 regularization loss: 3.42E+00, L2 regularization loss: 1.13E+00
Test scatter: [0.2494 0.0669 0.3523 0.5068], Lowest was [0.2091 0.0638 0.2999 0.4675]
Median for last 10 epochs: [0.2494 0.0709 0.3644 0.5187], Epochs since improvement 20
 14%|█▍        | 69/500 [1:28:14<8:49:33, 73.72s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.56E+06, Train scatter: [0.2185 0.0618 0.343  0.4836]
L1 regularization loss: 3.47E+00, L2 regularization loss: 1.18E+00
Test scatter: [0.2327 0.0636 0.3519 0.4915], Lowest was [0.2091 0.0636 0.2999 0.4675]
Median for last 10 epochs: [0.2494 0.0689 0.3581 0.5068], Epochs since improvement 0
 14%|█▍        | 70/500 [1:29:52<9:42:28, 81.28s/it] 14%|█▍        | 71/500 [1:30:54<8:59:36, 75.47s/it] 14%|█▍        | 72/500 [1:32:26<9:32:18, 80.23s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.39E+06, Train scatter: [0.206  0.0656 0.3274 0.474 ]
L1 regularization loss: 3.51E+00, L2 regularization loss: 1.22E+00
Test scatter: [0.214  0.0663 0.3297 0.4716], Lowest was [0.2091 0.0636 0.2999 0.4675]
Median for last 10 epochs: [0.2327 0.0669 0.3523 0.5044], Epochs since improvement 2
 15%|█▍        | 73/500 [1:33:27<8:51:36, 74.70s/it] 15%|█▍        | 74/500 [1:34:58<9:24:43, 79.54s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 1.32E+06, Train scatter: [0.2037 0.0574 0.3228 0.4652]
L1 regularization loss: 3.56E+00, L2 regularization loss: 1.29E+00
Test scatter: [0.2134 0.0583 0.3292 0.4619], Lowest was [0.2091 0.0583 0.2999 0.4619]
Median for last 10 epochs: [0.2262 0.0663 0.3519 0.4915], Epochs since improvement 0
 15%|█▌        | 75/500 [1:36:00<8:46:09, 74.28s/it] 15%|█▌        | 76/500 [1:37:30<9:17:07, 78.84s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 1.14E+06, Train scatter: [0.2063 0.057  0.3225 0.4571]
L1 regularization loss: 3.59E+00, L2 regularization loss: 1.33E+00
Test scatter: [0.2086 0.0581 0.3295 0.4555], Lowest was [0.2086 0.0581 0.2999 0.4555]
Median for last 10 epochs: [0.214  0.0636 0.3297 0.4716], Epochs since improvement 0
 15%|█▌        | 77/500 [1:38:31<8:39:27, 73.68s/it] 16%|█▌        | 78/500 [1:40:02<9:13:12, 78.66s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 1.05E+06, Train scatter: [0.1875 0.0563 0.3194 0.4422]
L1 regularization loss: 3.64E+00, L2 regularization loss: 1.38E+00
Test scatter: [0.1919 0.0569 0.3238 0.4401], Lowest was [0.1919 0.0569 0.2999 0.4401]
Median for last 10 epochs: [0.2134 0.0583 0.3295 0.4619], Epochs since improvement 0
 16%|█▌        | 79/500 [1:41:04<8:36:43, 73.64s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 9.07E+05, Train scatter: [0.1912 0.055  0.3132 0.4368]
L1 regularization loss: 3.68E+00, L2 regularization loss: 1.43E+00
Test scatter: [0.1952 0.0561 0.3194 0.4332], Lowest was [0.1919 0.0561 0.2999 0.4332]
Median for last 10 epochs: [0.2086 0.0581 0.3292 0.4555], Epochs since improvement 0
 16%|█▌        | 80/500 [1:42:44<9:31:16, 81.61s/it] 16%|█▌        | 81/500 [1:43:45<8:47:46, 75.58s/it] 16%|█▋        | 82/500 [1:45:17<9:19:59, 80.38s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 7.17E+05, Train scatter: [0.1874 0.0561 0.3084 0.443 ]
L1 regularization loss: 3.73E+00, L2 regularization loss: 1.49E+00
Test scatter: [0.1927 0.0562 0.3123 0.4367], Lowest was [0.1919 0.0561 0.2999 0.4332]
Median for last 10 epochs: [0.1952 0.0569 0.3238 0.4401], Epochs since improvement 2
 17%|█▋        | 83/500 [1:46:19<8:40:04, 74.83s/it] 17%|█▋        | 84/500 [1:47:50<9:13:06, 79.78s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 5.87E+05, Train scatter: [0.1914 0.0535 0.3024 0.4294]
L1 regularization loss: 3.76E+00, L2 regularization loss: 1.54E+00
Test scatter: [0.195  0.0546 0.3125 0.4277], Lowest was [0.1919 0.0546 0.2999 0.4277]
Median for last 10 epochs: [0.195  0.0562 0.3194 0.4367], Epochs since improvement 0
 17%|█▋        | 85/500 [1:48:52<8:34:09, 74.34s/it] 17%|█▋        | 86/500 [1:50:23<9:07:00, 79.28s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 4.49E+05, Train scatter: [0.1783 0.0518 0.3305 0.4203]
L1 regularization loss: 3.79E+00, L2 regularization loss: 1.58E+00
Test scatter: [0.181  0.0524 0.332  0.4177], Lowest was [0.181  0.0524 0.2999 0.4177]
Median for last 10 epochs: [0.1927 0.0561 0.3194 0.4332], Epochs since improvement 0
 17%|█▋        | 87/500 [1:51:25<8:29:52, 74.07s/it] 18%|█▊        | 88/500 [1:52:55<9:02:55, 79.07s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.67E+05, Train scatter: [0.1697 0.0531 0.2929 0.4152]
L1 regularization loss: 3.81E+00, L2 regularization loss: 1.62E+00
Test scatter: [0.1758 0.0535 0.3    0.4167], Lowest was [0.1758 0.0524 0.2999 0.4167]
Median for last 10 epochs: [0.1927 0.0546 0.3125 0.4277], Epochs since improvement 0
 18%|█▊        | 89/500 [1:53:57<8:26:12, 73.90s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 1.05E+05, Train scatter: [0.2416 0.052  0.292  0.423 ]
L1 regularization loss: 3.85E+00, L2 regularization loss: 1.67E+00
Test scatter: [0.2472 0.0524 0.2972 0.4153], Lowest was [0.1758 0.0524 0.2972 0.4153]
Median for last 10 epochs: [0.1927 0.0535 0.3123 0.4177], Epochs since improvement 0
 18%|█▊        | 90/500 [1:55:35<9:14:17, 81.12s/it] 18%|█▊        | 91/500 [1:56:37<8:33:29, 75.33s/it] 18%|█▊        | 92/500 [1:58:07<9:03:19, 79.90s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: -1.61E+04, Train scatter: [0.1685 0.0492 0.2702 0.4097]
L1 regularization loss: 3.92E+00, L2 regularization loss: 1.72E+00
Test scatter: [0.1723 0.0493 0.273  0.4038], Lowest was [0.1723 0.0493 0.273  0.4038]
Median for last 10 epochs: [0.181  0.0524 0.3    0.4167], Epochs since improvement 0
 19%|█▊        | 93/500 [1:59:09<8:25:10, 74.47s/it] 19%|█▉        | 94/500 [2:00:40<8:57:48, 79.48s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: -1.51E+05, Train scatter: [0.1529 0.0471 0.267  0.4032]
L1 regularization loss: 3.91E+00, L2 regularization loss: 1.74E+00
Test scatter: [0.1573 0.0469 0.2678 0.3978], Lowest was [0.1573 0.0469 0.2678 0.3978]
Median for last 10 epochs: [0.1758 0.0524 0.2972 0.4153], Epochs since improvement 0
 19%|█▉        | 95/500 [2:01:42<8:20:29, 74.15s/it] 19%|█▉        | 96/500 [2:03:14<8:55:04, 79.47s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: -2.12E+05, Train scatter: [0.1671 0.0467 0.248  0.414 ]
L1 regularization loss: 3.98E+00, L2 regularization loss: 1.79E+00
Test scatter: [0.1679 0.0468 0.2515 0.4134], Lowest was [0.1573 0.0468 0.2515 0.3978]
Median for last 10 epochs: [0.1723 0.0493 0.273  0.4134], Epochs since improvement 0
 19%|█▉        | 97/500 [2:04:16<8:18:17, 74.19s/it] 20%|█▉        | 98/500 [2:05:47<8:51:34, 79.34s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: -2.86E+05, Train scatter: [0.1534 0.0465 0.2543 0.4182]
L1 regularization loss: 3.97E+00, L2 regularization loss: 1.82E+00
Test scatter: [0.155  0.046  0.2562 0.4102], Lowest was [0.155  0.046  0.2515 0.3978]
Median for last 10 epochs: [0.1679 0.0469 0.2678 0.4102], Epochs since improvement 0
 20%|█▉        | 99/500 [2:06:49<8:14:30, 73.99s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: -2.91E+05, Train scatter: [0.1587 0.0481 0.2794 0.418 ]
L1 regularization loss: 4.10E+00, L2 regularization loss: 1.90E+00
Test scatter: [0.163  0.0476 0.2759 0.4099], Lowest was [0.155  0.046  0.2515 0.3978]
Median for last 10 epochs: [0.163  0.0469 0.2678 0.4099], Epochs since improvement 2
 20%|██        | 100/500 [2:08:27<9:02:29, 81.37s/it] 20%|██        | 101/500 [2:09:29<8:22:21, 75.54s/it] 20%|██        | 102/500 [2:11:01<8:53:48, 80.47s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: -3.28E+05, Train scatter: [0.17   0.0537 0.2453 0.406 ]
L1 regularization loss: 4.10E+00, L2 regularization loss: 1.94E+00
Test scatter: [0.1776 0.0543 0.2487 0.3993], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.163  0.0469 0.2562 0.4099], Epochs since improvement 0
 21%|██        | 103/500 [2:12:03<8:15:31, 74.89s/it] 21%|██        | 104/500 [2:13:34<8:45:55, 79.68s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: -2.49E+05, Train scatter: [0.1562 0.0515 0.2645 0.4326]
L1 regularization loss: 4.29E+00, L2 regularization loss: 2.10E+00
Test scatter: [0.1583 0.0507 0.2669 0.4281], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.163  0.0476 0.2562 0.4102], Epochs since improvement 2
 21%|██        | 105/500 [2:14:36<8:09:30, 74.36s/it] 21%|██        | 106/500 [2:16:06<8:39:43, 79.15s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: -2.08E+05, Train scatter: [0.1564 0.0555 0.5272 0.4563]
L1 regularization loss: 4.63E+00, L2 regularization loss: 2.40E+00
Test scatter: [0.1609 0.056  0.5187 0.4525], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.1609 0.0507 0.2669 0.4102], Epochs since improvement 4
 21%|██▏       | 107/500 [2:17:08<8:04:32, 73.98s/it] 22%|██▏       | 108/500 [2:18:39<8:36:49, 79.11s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: -2.69E+05, Train scatter: [0.2003 0.0564 0.2994 0.4682]
L1 regularization loss: 4.83E+00, L2 regularization loss: 2.61E+00
Test scatter: [0.1994 0.0561 0.2995 0.464 ], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.163  0.0543 0.2759 0.4281], Epochs since improvement 6
 22%|██▏       | 109/500 [2:19:41<8:01:53, 73.95s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: -6.72E+04, Train scatter: [0.5355 0.0972 0.5439 0.62  ]
L1 regularization loss: 5.05E+00, L2 regularization loss: 2.85E+00
Test scatter: [0.5239 0.0987 0.5353 0.608 ], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.1776 0.056  0.2995 0.4525], Epochs since improvement 8
 22%|██▏       | 110/500 [2:21:20<8:49:54, 81.52s/it] 22%|██▏       | 111/500 [2:22:22<8:09:25, 75.49s/it] 22%|██▏       | 112/500 [2:23:52<8:36:56, 79.94s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: -2.42E+05, Train scatter: [0.4216 0.0645 0.3714 0.5251]
L1 regularization loss: 5.06E+00, L2 regularization loss: 3.06E+00
Test scatter: [0.4189 0.0646 0.3732 0.4998], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.1994 0.0561 0.3732 0.464 ], Epochs since improvement 10
 23%|██▎       | 113/500 [2:24:54<8:00:27, 74.49s/it] 23%|██▎       | 114/500 [2:26:25<8:31:36, 79.52s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: -2.17E+05, Train scatter: [0.3938 0.0683 0.3576 0.5222]
L1 regularization loss: 5.32E+00, L2 regularization loss: 3.43E+00
Test scatter: [0.3834 0.0678 0.3534 0.5161], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.3834 0.0646 0.3732 0.4998], Epochs since improvement 12
 23%|██▎       | 115/500 [2:27:27<7:55:53, 74.17s/it] 23%|██▎       | 116/500 [2:28:58<8:27:07, 79.24s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: -2.86E+05, Train scatter: [0.3663 0.0542 0.3024 0.4826]
L1 regularization loss: 5.29E+00, L2 regularization loss: 3.48E+00
Test scatter: [0.3663 0.0546 0.3043 0.4774], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.3834 0.0646 0.3534 0.4998], Epochs since improvement 14
 23%|██▎       | 117/500 [2:30:00<7:52:21, 74.00s/it] 24%|██▎       | 118/500 [2:31:31<8:24:51, 79.30s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: -2.78E+05, Train scatter: [0.312  0.0521 0.2958 0.478 ]
L1 regularization loss: 5.41E+00, L2 regularization loss: 3.70E+00
Test scatter: [0.3121 0.0517 0.2966 0.4706], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.3834 0.0646 0.3534 0.4998], Epochs since improvement 16
 24%|██▍       | 119/500 [2:32:33<7:50:04, 74.03s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: -3.22E+05, Train scatter: [0.2682 0.0533 0.3591 0.463 ]
L1 regularization loss: 5.45E+00, L2 regularization loss: 3.83E+00
Test scatter: [0.2568 0.0535 0.3506 0.4543], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.3663 0.0546 0.3506 0.4774], Epochs since improvement 18
 24%|██▍       | 120/500 [2:34:11<8:35:22, 81.37s/it] 24%|██▍       | 121/500 [2:35:13<7:57:02, 75.52s/it] 24%|██▍       | 122/500 [2:36:45<8:25:30, 80.24s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: -3.32E+05, Train scatter: [0.1627 0.053  0.3793 0.4539]
L1 regularization loss: 5.42E+00, L2 regularization loss: 3.84E+00
Test scatter: [0.1587 0.0526 0.3729 0.4477], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.3121 0.0535 0.3506 0.4706], Epochs since improvement 20
 25%|██▍       | 123/500 [2:37:46<7:49:19, 74.69s/it] 25%|██▍       | 123/500 [2:39:17<8:08:13, 77.70s/it]
Epoch: 124 done with learning rate 9.68E-03, Train loss: -3.59E+05, Train scatter: [0.159  0.0571 0.2815 0.4516]
L1 regularization loss: 5.36E+00, L2 regularization loss: 3.89E+00
Test scatter: [0.1592 0.0558 0.2841 0.4441], Lowest was [0.155  0.046  0.2487 0.3978]
Median for last 10 epochs: [0.2568 0.0535 0.3043 0.4543], Epochs since improvement 22
Exited after 124 epochs due to early stopping
9557.25 seconds spent training, 19.115 seconds per epoch. Processed 3643 trees per second
[0.15920344 0.05576274 0.2841393  0.44409466]
{'epoch_exit': 123, 'scatter_m_star': 0.15920344, 'lowest_m_star': 0.15500057, 'last20_m_star': 0.28446668, 'last10_m_star': 0.25682235, 'scatter_v_disk': 0.055762738, 'lowest_v_disk': 0.045985743, 'last20_v_disk': 0.055904344, 'last10_v_disk': 0.05346159, 'scatter_m_cold': 0.2841393, 'lowest_m_cold': 0.24866313, 'last20_m_cold': 0.35196203, 'last10_m_cold': 0.30428994, 'scatter_sfr_100': 0.44409466, 'lowest_sfr_100': 0.3978209, 'last20_sfr_100': 0.4672646, 'last10_sfr_100': 0.4542847}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_lsldaf
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:53<7:27:39, 53.83s/it]  0%|          | 2/500 [02:16<9:48:14, 70.87s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.1732 0.5441 0.9953]
L1 regularization loss: 2.44E+00, L2 regularization loss: 4.23E-01
Test scatter: [0.9196 0.1678 0.5355 0.985 ], Lowest was [0.9196 0.1678 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1678 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:11<8:44:53, 63.37s/it]  1%|          | 4/500 [04:34<9:48:11, 71.15s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.70E+07, Train scatter: [0.9351 0.1308 0.5441 0.9954]
L1 regularization loss: 2.46E+00, L2 regularization loss: 4.25E-01
Test scatter: [0.9195 0.1274 0.5355 0.9851], Lowest was [0.9195 0.1274 0.5355 0.985 ]
Median for last 10 epochs: [0.9195 0.1274 0.5355 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [05:29<8:59:27, 65.39s/it]  1%|          | 6/500 [06:50<9:43:36, 70.88s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.34E+07, Train scatter: [0.9349 0.1104 0.5441 0.9955]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.28E-01
Test scatter: [0.9192 0.1089 0.5355 0.9851], Lowest was [0.9192 0.1089 0.5355 0.985 ]
Median for last 10 epochs: [0.9192 0.1089 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:44<8:55:42, 65.20s/it]  2%|▏         | 8/500 [09:05<9:37:06, 70.38s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.05E+07, Train scatter: [0.9298 0.1017 0.544  0.9955]
L1 regularization loss: 2.48E+00, L2 regularization loss: 4.33E-01
Test scatter: [0.9142 0.1005 0.5354 0.9851], Lowest was [0.9142 0.1005 0.5354 0.985 ]
Median for last 10 epochs: [0.9167 0.1047 0.5355 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [09:59<8:52:57, 65.13s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.91E+07, Train scatter: [0.7726 0.0916 0.5439 0.9954]
L1 regularization loss: 2.49E+00, L2 regularization loss: 4.41E-01
Test scatter: [0.7626 0.0916 0.5353 0.9851], Lowest was [0.7626 0.0916 0.5353 0.985 ]
Median for last 10 epochs: [0.9142 0.1005 0.5354 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:26<9:47:25, 71.93s/it]  2%|▏         | 11/500 [12:20<9:00:59, 66.38s/it]  2%|▏         | 12/500 [13:41<9:36:01, 70.82s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.73E+07, Train scatter: [0.6163 0.0868 0.5436 0.9954]
L1 regularization loss: 2.51E+00, L2 regularization loss: 4.50E-01
Test scatter: [0.6091 0.0864 0.5351 0.985 ], Lowest was [0.6091 0.0864 0.5351 0.985 ]
Median for last 10 epochs: [0.9142 0.1005 0.5354 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:35<8:52:51, 65.65s/it]  3%|▎         | 14/500 [15:55<9:28:09, 70.14s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.60E+07, Train scatter: [0.5003 0.0853 0.542  0.9953]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.60E-01
Test scatter: [0.4965 0.0847 0.5335 0.985 ], Lowest was [0.4965 0.0847 0.5335 0.985 ]
Median for last 10 epochs: [0.7626 0.0916 0.5353 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [16:49<8:46:31, 65.14s/it]  3%|▎         | 16/500 [18:10<9:25:33, 70.11s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.53E+07, Train scatter: [0.4695 0.0845 0.5328 0.9953]
L1 regularization loss: 2.53E+00, L2 regularization loss: 4.66E-01
Test scatter: [0.4682 0.0842 0.5249 0.985 ], Lowest was [0.4682 0.0842 0.5249 0.985 ]
Median for last 10 epochs: [0.6091 0.0864 0.5351 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [19:04<8:44:34, 65.16s/it]  4%|▎         | 18/500 [20:26<9:24:07, 70.22s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.49E+07, Train scatter: [0.4871 0.0809 0.5422 0.9953]
L1 regularization loss: 2.54E+00, L2 regularization loss: 4.71E-01
Test scatter: [0.4731 0.0803 0.5336 0.985 ], Lowest was [0.4682 0.0803 0.5249 0.985 ]
Median for last 10 epochs: [0.4965 0.0847 0.5336 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [21:20<8:43:00, 65.24s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.41E+07, Train scatter: [0.5129 0.0885 0.527  0.9953]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.76E-01
Test scatter: [0.5183 0.0889 0.5189 0.985 ], Lowest was [0.4682 0.0803 0.5189 0.985 ]
Median for last 10 epochs: [0.4965 0.0847 0.5335 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:48<9:37:08, 72.14s/it]  4%|▍         | 21/500 [23:42<8:51:45, 66.61s/it]  4%|▍         | 22/500 [25:04<9:28:11, 71.32s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.37E+07, Train scatter: [0.5802 0.0978 0.4598 0.9954]
L1 regularization loss: 2.57E+00, L2 regularization loss: 4.84E-01
Test scatter: [0.5738 0.095  0.453  0.985 ], Lowest was [0.4682 0.0803 0.453  0.985 ]
Median for last 10 epochs: [0.4965 0.0847 0.5249 0.985 ], Epochs since improvement 0
  5%|▍         | 23/500 [25:57<8:44:27, 65.97s/it]  5%|▍         | 24/500 [27:18<9:18:10, 70.36s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.25E+07, Train scatter: [0.6214 0.116  0.4536 0.9952]
L1 regularization loss: 2.58E+00, L2 regularization loss: 4.90E-01
Test scatter: [0.6045 0.1141 0.4495 0.9849], Lowest was [0.4682 0.0803 0.4495 0.9849]
Median for last 10 epochs: [0.5183 0.0889 0.5189 0.985 ], Epochs since improvement 0
  5%|▌         | 25/500 [28:12<8:37:15, 65.34s/it]  5%|▌         | 26/500 [29:32<9:11:52, 69.86s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.23E+07, Train scatter: [0.564  0.0983 0.4448 0.9954]
L1 regularization loss: 2.60E+00, L2 regularization loss: 4.96E-01
Test scatter: [0.5611 0.0946 0.4372 0.985 ], Lowest was [0.4682 0.0803 0.4372 0.9849]
Median for last 10 epochs: [0.5611 0.0946 0.453  0.985 ], Epochs since improvement 0
  5%|▌         | 27/500 [30:26<8:32:56, 65.07s/it]  6%|▌         | 28/500 [31:47<9:09:05, 69.80s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.17E+07, Train scatter: [0.505  0.0866 0.3598 0.9953]
L1 regularization loss: 2.62E+00, L2 regularization loss: 5.03E-01
Test scatter: [0.5063 0.0853 0.3543 0.985 ], Lowest was [0.4682 0.0803 0.3543 0.9849]
Median for last 10 epochs: [0.5611 0.0946 0.4495 0.985 ], Epochs since improvement 0
  6%|▌         | 29/500 [32:40<8:30:00, 64.97s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.13E+07, Train scatter: [0.4912 0.1105 0.5004 0.9954]
L1 regularization loss: 2.64E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.4848 0.1111 0.4917 0.9851], Lowest was [0.4682 0.0803 0.3543 0.9849]
Median for last 10 epochs: [0.5611 0.095  0.4495 0.985 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [34:08<9:21:57, 71.74s/it]  6%|▌         | 31/500 [35:01<8:37:55, 66.26s/it]  6%|▋         | 32/500 [36:22<9:10:10, 70.54s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.10E+07, Train scatter: [0.5102 0.0902 0.3584 0.9953]
L1 regularization loss: 2.66E+00, L2 regularization loss: 5.20E-01
Test scatter: [0.5088 0.0896 0.3555 0.985 ], Lowest was [0.4682 0.0803 0.3543 0.9849]
Median for last 10 epochs: [0.5088 0.0946 0.4372 0.985 ], Epochs since improvement 4
  7%|▋         | 33/500 [37:16<8:29:28, 65.46s/it]  7%|▋         | 34/500 [38:37<9:05:05, 70.18s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.02E+07, Train scatter: [0.4698 0.0777 0.3181 0.9954]
L1 regularization loss: 2.68E+00, L2 regularization loss: 5.28E-01
Test scatter: [0.4708 0.0767 0.317  0.985 ], Lowest was [0.4682 0.0767 0.317  0.9849]
Median for last 10 epochs: [0.5063 0.0896 0.3555 0.985 ], Epochs since improvement 0
  7%|▋         | 35/500 [39:30<8:25:07, 65.18s/it]  7%|▋         | 36/500 [40:52<9:03:13, 70.24s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 6.97E+07, Train scatter: [0.8264 0.0788 0.3154 0.9954]
L1 regularization loss: 2.71E+00, L2 regularization loss: 5.40E-01
Test scatter: [0.8167 0.0782 0.3142 0.985 ], Lowest was [0.4682 0.0767 0.3142 0.9849]
Median for last 10 epochs: [0.5063 0.0853 0.3543 0.985 ], Epochs since improvement 0
  7%|▋         | 37/500 [41:46<8:23:24, 65.24s/it]  8%|▊         | 38/500 [43:06<8:57:48, 69.84s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.90E+07, Train scatter: [0.6328 0.1044 0.5207 0.9952]
L1 regularization loss: 2.76E+00, L2 regularization loss: 5.63E-01
Test scatter: [0.6143 0.1025 0.5124 0.9848], Lowest was [0.4682 0.0767 0.3142 0.9848]
Median for last 10 epochs: [0.5088 0.0896 0.3555 0.985 ], Epochs since improvement 0
  8%|▊         | 39/500 [44:00<8:19:21, 64.99s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.57E+07, Train scatter: [0.9311 0.1722 0.5441 0.9954]
L1 regularization loss: 3.25E+00, L2 regularization loss: 7.19E-01
Test scatter: [0.9157 0.1683 0.5355 0.9851], Lowest was [0.4682 0.0767 0.3142 0.9848]
Median for last 10 epochs: [0.6143 0.0896 0.3555 0.985 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:27<9:09:23, 71.66s/it]  8%|▊         | 41/500 [46:21<8:27:18, 66.32s/it]  8%|▊         | 42/500 [47:43<9:00:59, 70.87s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.44E+07, Train scatter: [0.927  0.1697 0.5441 0.9954]
L1 regularization loss: 3.25E+00, L2 regularization loss: 7.36E-01
Test scatter: [0.9117 0.1658 0.5355 0.985 ], Lowest was [0.4682 0.0767 0.3142 0.9848]
Median for last 10 epochs: [0.8167 0.1025 0.5124 0.985 ], Epochs since improvement 4
  9%|▊         | 43/500 [48:36<8:20:17, 65.68s/it]  9%|▉         | 44/500 [49:57<8:53:28, 70.19s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.30E+07, Train scatter: [0.8595 0.1431 0.5421 0.7667]
L1 regularization loss: 3.28E+00, L2 regularization loss: 7.97E-01
Test scatter: [0.8454 0.1397 0.5335 0.76  ], Lowest was [0.4682 0.0767 0.3142 0.76  ]
Median for last 10 epochs: [0.8454 0.1397 0.5335 0.985 ], Epochs since improvement 0
  9%|▉         | 45/500 [50:50<8:14:16, 65.18s/it]  9%|▉         | 46/500 [52:11<8:49:00, 69.91s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 8.92E+06, Train scatter: [0.8    0.1223 0.5101 0.7863]
L1 regularization loss: 3.29E+00, L2 regularization loss: 8.23E-01
Test scatter: [0.7892 0.1199 0.5024 0.7804], Lowest was [0.4682 0.0767 0.3142 0.76  ]
Median for last 10 epochs: [0.8454 0.1397 0.5335 0.9848], Epochs since improvement 2
  9%|▉         | 47/500 [53:05<8:10:28, 64.96s/it] 10%|▉         | 48/500 [54:26<8:45:25, 69.75s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 7.59E+06, Train scatter: [0.5224 0.1048 0.4553 0.6698]
L1 regularization loss: 3.31E+00, L2 regularization loss: 8.47E-01
Test scatter: [0.5109 0.1018 0.4466 0.6548], Lowest was [0.4682 0.0767 0.3142 0.6548]
Median for last 10 epochs: [0.8454 0.1397 0.5335 0.7804], Epochs since improvement 0
 10%|▉         | 49/500 [55:19<8:07:26, 64.85s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 5.46E+06, Train scatter: [0.3913 0.0944 0.4075 0.6047]
L1 regularization loss: 3.35E+00, L2 regularization loss: 8.88E-01
Test scatter: [0.387  0.0934 0.4081 0.5995], Lowest was [0.387  0.0767 0.3142 0.5995]
Median for last 10 epochs: [0.7892 0.1199 0.5024 0.76  ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [56:47<8:58:37, 71.82s/it] 10%|█         | 51/500 [57:41<8:16:35, 66.36s/it] 10%|█         | 52/500 [59:02<8:47:54, 70.70s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 4.85E+06, Train scatter: [0.4094 0.0916 0.3928 0.5784]
L1 regularization loss: 3.37E+00, L2 regularization loss: 9.13E-01
Test scatter: [0.396  0.0915 0.3943 0.5731], Lowest was [0.387  0.0767 0.3142 0.5731]
Median for last 10 epochs: [0.5109 0.1018 0.4466 0.6548], Epochs since improvement 0
 11%|█         | 53/500 [59:55<8:08:15, 65.54s/it] 11%|█         | 54/500 [1:01:16<8:40:42, 70.05s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 4.42E+06, Train scatter: [0.3512 0.0884 0.3735 0.5773]
L1 regularization loss: 3.38E+00, L2 regularization loss: 9.32E-01
Test scatter: [0.3501 0.09   0.3806 0.5774], Lowest was [0.3501 0.0767 0.3142 0.5731]
Median for last 10 epochs: [0.396  0.0934 0.4081 0.5995], Epochs since improvement 0
 11%|█         | 55/500 [1:02:09<8:02:58, 65.12s/it] 11%|█         | 56/500 [1:03:30<8:36:56, 69.86s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.01E+06, Train scatter: [0.3161 0.0794 0.3552 0.5329]
L1 regularization loss: 3.41E+00, L2 regularization loss: 9.55E-01
Test scatter: [0.315  0.0796 0.3606 0.532 ], Lowest was [0.315  0.0767 0.3142 0.532 ]
Median for last 10 epochs: [0.387  0.0915 0.3943 0.5774], Epochs since improvement 0
 11%|█▏        | 57/500 [1:04:24<8:00:04, 65.02s/it] 12%|█▏        | 58/500 [1:05:45<8:34:35, 69.85s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.90E+06, Train scatter: [0.3256 0.0781 0.3442 0.5301]
L1 regularization loss: 3.44E+00, L2 regularization loss: 9.81E-01
Test scatter: [0.3289 0.0772 0.351  0.5283], Lowest was [0.315  0.0767 0.3142 0.5283]
Median for last 10 epochs: [0.3501 0.09   0.3806 0.5731], Epochs since improvement 0
 12%|█▏        | 59/500 [1:06:39<7:57:27, 64.96s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.53E+06, Train scatter: [0.3194 0.0821 0.3489 0.5422]
L1 regularization loss: 3.46E+00, L2 regularization loss: 1.00E+00
Test scatter: [0.3235 0.0854 0.3634 0.5445], Lowest was [0.315  0.0767 0.3142 0.5283]
Median for last 10 epochs: [0.3289 0.0854 0.3634 0.5445], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:08:08<8:50:05, 72.28s/it] 12%|█▏        | 61/500 [1:09:02<8:07:30, 66.63s/it] 12%|█▏        | 62/500 [1:10:22<8:36:56, 70.82s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.46E+06, Train scatter: [0.2834 0.074  0.3578 0.5148]
L1 regularization loss: 3.51E+00, L2 regularization loss: 1.04E+00
Test scatter: [0.2835 0.074  0.3649 0.5137], Lowest was [0.2835 0.074  0.3142 0.5137]
Median for last 10 epochs: [0.3235 0.0796 0.3634 0.532 ], Epochs since improvement 0
 13%|█▎        | 63/500 [1:11:16<7:57:57, 65.62s/it] 13%|█▎        | 64/500 [1:12:36<8:29:35, 70.13s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.29E+06, Train scatter: [0.3495 0.0833 0.3496 0.5401]
L1 regularization loss: 3.52E+00, L2 regularization loss: 1.06E+00
Test scatter: [0.3553 0.0865 0.3554 0.541 ], Lowest was [0.2835 0.074  0.3142 0.5137]
Median for last 10 epochs: [0.3235 0.0796 0.3606 0.532 ], Epochs since improvement 2
 13%|█▎        | 65/500 [1:13:30<7:52:14, 65.14s/it] 13%|█▎        | 66/500 [1:14:51<8:26:48, 70.07s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.20E+06, Train scatter: [0.3047 0.0715 0.3197 0.4969]
L1 regularization loss: 3.55E+00, L2 regularization loss: 1.09E+00
Test scatter: [0.3243 0.072  0.328  0.4979], Lowest was [0.2835 0.072  0.3142 0.4979]
Median for last 10 epochs: [0.3243 0.0772 0.3554 0.5283], Epochs since improvement 0
 13%|█▎        | 67/500 [1:15:45<7:49:59, 65.13s/it] 14%|█▎        | 68/500 [1:17:07<8:24:44, 70.10s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.91E+06, Train scatter: [0.3304 0.0879 0.357  0.569 ]
L1 regularization loss: 3.57E+00, L2 regularization loss: 1.11E+00
Test scatter: [0.3302 0.0922 0.3668 0.5728], Lowest was [0.2835 0.072  0.3142 0.4979]
Median for last 10 epochs: [0.3243 0.0854 0.3634 0.541 ], Epochs since improvement 2
 14%|█▍        | 69/500 [1:18:00<7:47:56, 65.14s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.04E+06, Train scatter: [0.2506 0.0699 0.305  0.49  ]
L1 regularization loss: 3.60E+00, L2 regularization loss: 1.15E+00
Test scatter: [0.2526 0.0689 0.3112 0.4905], Lowest was [0.2526 0.0689 0.3112 0.4905]
Median for last 10 epochs: [0.3243 0.074  0.3554 0.5137], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:19:28<8:36:04, 72.01s/it] 14%|█▍        | 71/500 [1:20:22<7:55:53, 66.56s/it] 14%|█▍        | 72/500 [1:21:43<8:25:48, 70.91s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.35E+06, Train scatter: [0.2748 0.071  0.3046 0.4965]
L1 regularization loss: 3.61E+00, L2 regularization loss: 1.16E+00
Test scatter: [0.2699 0.0694 0.3089 0.4992], Lowest was [0.2526 0.0689 0.3089 0.4905]
Median for last 10 epochs: [0.3243 0.072  0.328  0.4992], Epochs since improvement 0
 15%|█▍        | 73/500 [1:22:37<7:48:12, 65.79s/it] 15%|█▍        | 74/500 [1:23:58<8:19:36, 70.37s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 2.77E+06, Train scatter: [0.2381 0.0674 0.3113 0.487 ]
L1 regularization loss: 3.63E+00, L2 regularization loss: 1.19E+00
Test scatter: [0.2374 0.0679 0.3183 0.4908], Lowest was [0.2374 0.0679 0.3089 0.4905]
Median for last 10 epochs: [0.2699 0.0694 0.3183 0.4979], Epochs since improvement 0
 15%|█▌        | 75/500 [1:24:52<7:43:09, 65.39s/it] 15%|█▌        | 76/500 [1:26:13<8:14:45, 70.01s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.81E+06, Train scatter: [0.2512 0.0664 0.3028 0.4829]
L1 regularization loss: 3.65E+00, L2 regularization loss: 1.22E+00
Test scatter: [0.2583 0.067  0.3065 0.4836], Lowest was [0.2374 0.067  0.3065 0.4836]
Median for last 10 epochs: [0.2583 0.0689 0.3112 0.4908], Epochs since improvement 0
 15%|█▌        | 77/500 [1:27:06<7:39:11, 65.13s/it] 16%|█▌        | 78/500 [1:28:28<8:13:05, 70.11s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.69E+06, Train scatter: [0.245  0.0645 0.2877 0.4776]
L1 regularization loss: 3.68E+00, L2 regularization loss: 1.25E+00
Test scatter: [0.2465 0.0645 0.2933 0.4755], Lowest was [0.2374 0.0645 0.2933 0.4755]
Median for last 10 epochs: [0.2526 0.0679 0.3089 0.4905], Epochs since improvement 0
 16%|█▌        | 79/500 [1:29:22<7:37:32, 65.21s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.50E+06, Train scatter: [0.2265 0.0632 0.2893 0.4668]
L1 regularization loss: 3.69E+00, L2 regularization loss: 1.29E+00
Test scatter: [0.2234 0.0634 0.2925 0.4647], Lowest was [0.2234 0.0634 0.2925 0.4647]
Median for last 10 epochs: [0.2465 0.067  0.3065 0.4836], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:30:53<8:31:11, 73.03s/it] 16%|█▌        | 81/500 [1:31:47<7:49:23, 67.22s/it] 16%|█▋        | 82/500 [1:33:08<8:17:47, 71.45s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 2.58E+06, Train scatter: [0.2484 0.0654 0.2924 0.4883]
L1 regularization loss: 3.71E+00, L2 regularization loss: 1.32E+00
Test scatter: [0.2496 0.0656 0.2973 0.4895], Lowest was [0.2234 0.0634 0.2925 0.4647]
Median for last 10 epochs: [0.2465 0.0656 0.2973 0.4836], Epochs since improvement 2
 17%|█▋        | 83/500 [1:34:02<7:39:13, 66.08s/it] 17%|█▋        | 84/500 [1:35:22<8:08:45, 70.49s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 2.47E+06, Train scatter: [0.2393 0.0634 0.2915 0.4756]
L1 regularization loss: 3.73E+00, L2 regularization loss: 1.36E+00
Test scatter: [0.2448 0.0635 0.2973 0.4788], Lowest was [0.2234 0.0634 0.2925 0.4647]
Median for last 10 epochs: [0.2465 0.0645 0.2973 0.4788], Epochs since improvement 4
 17%|█▋        | 85/500 [1:36:16<7:32:47, 65.46s/it] 17%|█▋        | 86/500 [1:37:38<8:05:09, 70.31s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 2.46E+06, Train scatter: [0.2726 0.0658 0.3029 0.4854]
L1 regularization loss: 3.75E+00, L2 regularization loss: 1.40E+00
Test scatter: [0.2753 0.0665 0.3072 0.4888], Lowest was [0.2234 0.0634 0.2925 0.4647]
Median for last 10 epochs: [0.2465 0.0645 0.2973 0.4788], Epochs since improvement 6
 17%|█▋        | 87/500 [1:38:32<7:30:08, 65.40s/it] 18%|█▊        | 88/500 [1:39:53<8:01:05, 70.06s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 2.21E+06, Train scatter: [0.2571 0.0622 0.2863 0.4698]
L1 regularization loss: 3.76E+00, L2 regularization loss: 1.44E+00
Test scatter: [0.2629 0.0628 0.2917 0.4744], Lowest was [0.2234 0.0628 0.2917 0.4647]
Median for last 10 epochs: [0.2496 0.0635 0.2973 0.4788], Epochs since improvement 0
 18%|█▊        | 89/500 [1:40:46<7:26:14, 65.14s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.21E+06, Train scatter: [0.2188 0.0584 0.2664 0.4515]
L1 regularization loss: 3.78E+00, L2 regularization loss: 1.49E+00
Test scatter: [0.2208 0.058  0.2705 0.4483], Lowest was [0.2208 0.058  0.2705 0.4483]
Median for last 10 epochs: [0.2496 0.0635 0.2973 0.4788], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:42:14<8:11:57, 71.99s/it] 18%|█▊        | 91/500 [1:43:08<7:34:01, 66.61s/it] 18%|█▊        | 92/500 [1:44:29<8:01:45, 70.85s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.24E+06, Train scatter: [0.2428 0.0609 0.2838 0.4587]
L1 regularization loss: 3.80E+00, L2 regularization loss: 1.54E+00
Test scatter: [0.2411 0.0609 0.2845 0.4594], Lowest was [0.2208 0.058  0.2705 0.4483]
Median for last 10 epochs: [0.2448 0.0628 0.2917 0.4744], Epochs since improvement 2
 19%|█▊        | 93/500 [1:45:23<7:25:54, 65.74s/it] 19%|█▉        | 94/500 [1:46:43<7:54:41, 70.15s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.29E+06, Train scatter: [0.2106 0.0571 0.2648 0.448 ]
L1 regularization loss: 3.84E+00, L2 regularization loss: 1.59E+00
Test scatter: [0.2142 0.0569 0.2688 0.4455], Lowest was [0.2142 0.0569 0.2688 0.4455]
Median for last 10 epochs: [0.2411 0.0609 0.2845 0.4594], Epochs since improvement 0
 19%|█▉        | 95/500 [1:47:37<7:20:53, 65.32s/it] 19%|█▉        | 96/500 [1:48:58<7:50:10, 69.83s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.04E+06, Train scatter: [0.2434 0.0582 0.2606 0.4504]
L1 regularization loss: 3.86E+00, L2 regularization loss: 1.64E+00
Test scatter: [0.2434 0.0591 0.2662 0.4514], Lowest was [0.2142 0.0569 0.2662 0.4455]
Median for last 10 epochs: [0.2411 0.0591 0.2705 0.4514], Epochs since improvement 0
 19%|█▉        | 97/500 [1:49:52<7:16:55, 65.05s/it] 20%|█▉        | 98/500 [1:51:12<7:47:04, 69.71s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.02E+06, Train scatter: [0.2076 0.0564 0.2612 0.4478]
L1 regularization loss: 3.87E+00, L2 regularization loss: 1.68E+00
Test scatter: [0.2092 0.0564 0.2646 0.445 ], Lowest was [0.2092 0.0564 0.2646 0.445 ]
Median for last 10 epochs: [0.2208 0.058  0.2688 0.4483], Epochs since improvement 0
 20%|█▉        | 99/500 [1:52:06<7:14:24, 65.00s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 2.01E+06, Train scatter: [0.2106 0.0564 0.2637 0.4409]
L1 regularization loss: 3.89E+00, L2 regularization loss: 1.72E+00
Test scatter: [0.2115 0.0563 0.2703 0.4411], Lowest was [0.2092 0.0563 0.2646 0.4411]
Median for last 10 epochs: [0.2142 0.0569 0.2688 0.4455], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:53:34<7:59:01, 71.85s/it] 20%|██        | 101/500 [1:54:28<7:22:20, 66.52s/it] 20%|██        | 102/500 [1:55:49<7:50:17, 70.90s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 1.90E+06, Train scatter: [0.2216 0.059  0.2636 0.4506]
L1 regularization loss: 3.91E+00, L2 regularization loss: 1.76E+00
Test scatter: [0.2268 0.0604 0.2704 0.4553], Lowest was [0.2092 0.0563 0.2646 0.4411]
Median for last 10 epochs: [0.2142 0.0569 0.2688 0.4455], Epochs since improvement 2
 21%|██        | 103/500 [1:56:43<7:15:14, 65.78s/it] 21%|██        | 104/500 [1:58:04<7:44:10, 70.33s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 1.74E+06, Train scatter: [0.2044 0.0547 0.2641 0.4376]
L1 regularization loss: 3.92E+00, L2 regularization loss: 1.79E+00
Test scatter: [0.2073 0.0544 0.2658 0.4328], Lowest was [0.2073 0.0544 0.2646 0.4328]
Median for last 10 epochs: [0.2115 0.0564 0.2662 0.445 ], Epochs since improvement 0
 21%|██        | 105/500 [1:58:58<7:10:14, 65.35s/it] 21%|██        | 106/500 [2:00:19<7:39:26, 69.97s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 1.72E+06, Train scatter: [0.2018 0.0563 0.2506 0.4366]
L1 regularization loss: 3.94E+00, L2 regularization loss: 1.83E+00
Test scatter: [0.2076 0.0569 0.2549 0.436 ], Lowest was [0.2073 0.0544 0.2549 0.4328]
Median for last 10 epochs: [0.2092 0.0564 0.2658 0.4411], Epochs since improvement 0
 21%|██▏       | 107/500 [2:01:12<7:06:30, 65.12s/it] 22%|██▏       | 108/500 [2:02:33<7:35:03, 69.65s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 1.80E+06, Train scatter: [0.2249 0.0557 0.2982 0.4495]
L1 regularization loss: 3.96E+00, L2 regularization loss: 1.87E+00
Test scatter: [0.2251 0.056  0.3009 0.4471], Lowest was [0.2073 0.0544 0.2549 0.4328]
Median for last 10 epochs: [0.2115 0.0563 0.2703 0.4411], Epochs since improvement 2
 22%|██▏       | 109/500 [2:03:26<7:03:08, 64.93s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 1.68E+06, Train scatter: [0.2121 0.0557 0.2661 0.443 ]
L1 regularization loss: 3.98E+00, L2 regularization loss: 1.91E+00
Test scatter: [0.2152 0.0558 0.2698 0.4421], Lowest was [0.2073 0.0544 0.2549 0.4328]
Median for last 10 epochs: [0.2152 0.056  0.2698 0.4421], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:04:55<7:47:40, 71.95s/it] 22%|██▏       | 111/500 [2:05:49<7:11:29, 66.55s/it] 22%|██▏       | 112/500 [2:07:09<7:37:30, 70.75s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.48E+06, Train scatter: [0.2101 0.0538 0.2551 0.4244]
L1 regularization loss: 3.99E+00, L2 regularization loss: 1.94E+00
Test scatter: [0.2143 0.0539 0.2593 0.4236], Lowest was [0.2073 0.0539 0.2549 0.4236]
Median for last 10 epochs: [0.2143 0.0558 0.2658 0.436 ], Epochs since improvement 0
 23%|██▎       | 113/500 [2:08:03<7:03:48, 65.71s/it] 23%|██▎       | 114/500 [2:09:24<7:32:33, 70.35s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.39E+06, Train scatter: [0.1939 0.0552 0.241  0.425 ]
L1 regularization loss: 4.00E+00, L2 regularization loss: 1.98E+00
Test scatter: [0.1988 0.0551 0.2452 0.4225], Lowest was [0.1988 0.0539 0.2452 0.4225]
Median for last 10 epochs: [0.2143 0.0558 0.2593 0.436 ], Epochs since improvement 0
 23%|██▎       | 115/500 [2:10:18<6:59:55, 65.44s/it] 23%|██▎       | 116/500 [2:11:38<7:26:52, 69.82s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.41E+06, Train scatter: [0.197  0.0578 0.2543 0.4256]
L1 regularization loss: 4.02E+00, L2 regularization loss: 2.02E+00
Test scatter: [0.2007 0.0577 0.2605 0.4268], Lowest was [0.1988 0.0539 0.2452 0.4225]
Median for last 10 epochs: [0.2143 0.0558 0.2605 0.4268], Epochs since improvement 2
 23%|██▎       | 117/500 [2:12:32<6:55:11, 65.04s/it] 24%|██▎       | 118/500 [2:13:53<7:23:40, 69.69s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.34E+06, Train scatter: [0.2019 0.0513 0.245  0.416 ]
L1 regularization loss: 4.04E+00, L2 regularization loss: 2.05E+00
Test scatter: [0.2049 0.0514 0.2495 0.4142], Lowest was [0.1988 0.0514 0.2452 0.4142]
Median for last 10 epochs: [0.2049 0.0551 0.2593 0.4236], Epochs since improvement 0
 24%|██▍       | 119/500 [2:14:47<6:52:17, 64.93s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.26E+06, Train scatter: [0.2322 0.0556 0.2563 0.4392]
L1 regularization loss: 4.06E+00, L2 regularization loss: 2.09E+00
Test scatter: [0.2354 0.0558 0.2586 0.4344], Lowest was [0.1988 0.0514 0.2452 0.4142]
Median for last 10 epochs: [0.2049 0.0551 0.2586 0.4236], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 24%|██▍       | 120/500 [2:16:14<7:33:50, 71.66s/it] 24%|██▍       | 121/500 [2:17:08<6:58:54, 66.32s/it] 24%|██▍       | 122/500 [2:18:30<7:27:13, 70.99s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 1.20E+06, Train scatter: [0.1906 0.0575 0.2522 0.4224]
L1 regularization loss: 4.14E+00, L2 regularization loss: 2.21E+00
Test scatter: [0.1953 0.0572 0.2562 0.4192], Lowest was [0.1953 0.0514 0.2452 0.4142]
Median for last 10 epochs: [0.2007 0.0558 0.2562 0.4225], Epochs since improvement 0
 25%|██▍       | 123/500 [2:19:24<6:53:36, 65.83s/it] 25%|██▍       | 124/500 [2:20:44<7:20:39, 70.32s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.09E+06, Train scatter: [0.1798 0.0509 0.2514 0.4154]
L1 regularization loss: 4.16E+00, L2 regularization loss: 2.28E+00
Test scatter: [0.1873 0.0513 0.2567 0.4164], Lowest was [0.1873 0.0513 0.2452 0.4142]
Median for last 10 epochs: [0.2007 0.0558 0.2567 0.4192], Epochs since improvement 0
 25%|██▌       | 125/500 [2:21:38<6:48:16, 65.32s/it] 25%|██▌       | 126/500 [2:22:59<7:16:01, 69.95s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.26E+06, Train scatter: [0.1907 0.0666 0.2758 0.4292]
L1 regularization loss: 4.52E+00, L2 regularization loss: 2.57E+00
Test scatter: [0.1937 0.0654 0.2823 0.4308], Lowest was [0.1873 0.0513 0.2452 0.4142]
Median for last 10 epochs: [0.1953 0.0558 0.2567 0.4192], Epochs since improvement 2
 25%|██▌       | 127/500 [2:23:52<6:44:32, 65.07s/it] 26%|██▌       | 128/500 [2:25:14<7:13:46, 69.96s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 1.05E+06, Train scatter: [0.1852 0.0541 0.2601 0.419 ]
L1 regularization loss: 4.52E+00, L2 regularization loss: 2.60E+00
Test scatter: [0.1906 0.0538 0.2618 0.4171], Lowest was [0.1873 0.0513 0.2452 0.4142]
Median for last 10 epochs: [0.1937 0.0558 0.2586 0.4192], Epochs since improvement 4
 26%|██▌       | 129/500 [2:26:08<6:42:37, 65.11s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 1.01E+06, Train scatter: [0.1882 0.0579 0.2671 0.4259]
L1 regularization loss: 4.53E+00, L2 regularization loss: 2.62E+00
Test scatter: [0.1929 0.0576 0.2694 0.4278], Lowest was [0.1873 0.0513 0.2452 0.4142]
Median for last 10 epochs: [0.1929 0.0572 0.2618 0.4192], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 26%|██▌       | 130/500 [2:27:36<7:24:29, 72.08s/it] 26%|██▌       | 131/500 [2:28:30<6:49:40, 66.61s/it] 26%|██▋       | 132/500 [2:29:52<7:17:02, 71.26s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 1.02E+06, Train scatter: [0.1801 0.0601 0.2551 0.4185]
L1 regularization loss: 4.53E+00, L2 regularization loss: 2.64E+00
Test scatter: [0.1867 0.059  0.2597 0.4187], Lowest was [0.1867 0.0513 0.2452 0.4142]
Median for last 10 epochs: [0.1906 0.0576 0.2618 0.4187], Epochs since improvement 0
 27%|██▋       | 133/500 [2:30:46<6:43:47, 66.02s/it] 27%|██▋       | 134/500 [2:32:07<7:10:57, 70.65s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 9.13E+05, Train scatter: [0.189  0.0507 0.2516 0.4092]
L1 regularization loss: 4.51E+00, L2 regularization loss: 2.64E+00
Test scatter: [0.193  0.0508 0.255  0.4061], Lowest was [0.1867 0.0508 0.2452 0.4061]
Median for last 10 epochs: [0.1929 0.0576 0.2618 0.4187], Epochs since improvement 0
 27%|██▋       | 135/500 [2:33:01<6:38:47, 65.56s/it] 27%|██▋       | 136/500 [2:34:22<7:06:21, 70.28s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 8.61E+05, Train scatter: [0.185  0.0487 0.2474 0.4032]
L1 regularization loss: 4.51E+00, L2 regularization loss: 2.65E+00
Test scatter: [0.1904 0.0491 0.2513 0.405 ], Lowest was [0.1867 0.0491 0.2452 0.405 ]
Median for last 10 epochs: [0.1906 0.0538 0.2597 0.4171], Epochs since improvement 0
 27%|██▋       | 137/500 [2:35:16<6:34:56, 65.28s/it] 28%|██▊       | 138/500 [2:36:37<7:02:06, 69.96s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: 8.15E+05, Train scatter: [0.1876 0.0519 0.2486 0.4055]
L1 regularization loss: 4.50E+00, L2 regularization loss: 2.66E+00
Test scatter: [0.1916 0.0518 0.2525 0.4048], Lowest was [0.1867 0.0491 0.2452 0.4048]
Median for last 10 epochs: [0.1916 0.0518 0.255  0.4061], Epochs since improvement 0
 28%|██▊       | 139/500 [2:37:30<6:31:27, 65.06s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: 8.07E+05, Train scatter: [0.176  0.0522 0.2512 0.4077]
L1 regularization loss: 4.50E+00, L2 regularization loss: 2.69E+00
Test scatter: [0.1812 0.0519 0.2555 0.4063], Lowest was [0.1812 0.0491 0.2452 0.4048]
Median for last 10 epochs: [0.1904 0.0518 0.255  0.4061], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 28%|██▊       | 140/500 [2:38:59<7:13:18, 72.22s/it] 28%|██▊       | 141/500 [2:39:53<6:38:46, 66.65s/it] 28%|██▊       | 142/500 [2:41:13<7:02:39, 70.84s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: 7.84E+05, Train scatter: [0.2044 0.0534 0.2633 0.4229]
L1 regularization loss: 4.50E+00, L2 regularization loss: 2.71E+00
Test scatter: [0.2059 0.0532 0.265  0.4151], Lowest was [0.1812 0.0491 0.2452 0.4048]
Median for last 10 epochs: [0.1916 0.0518 0.255  0.4061], Epochs since improvement 2
 29%|██▊       | 143/500 [2:42:07<6:30:53, 65.70s/it] 29%|██▉       | 144/500 [2:43:28<6:57:15, 70.32s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 7.42E+05, Train scatter: [0.1823 0.0512 0.2548 0.4201]
L1 regularization loss: 4.49E+00, L2 regularization loss: 2.73E+00
Test scatter: [0.1881 0.0519 0.262  0.4282], Lowest was [0.1812 0.0491 0.2452 0.4048]
Median for last 10 epochs: [0.1904 0.0519 0.2555 0.4063], Epochs since improvement 4
 29%|██▉       | 145/500 [2:44:22<6:26:35, 65.34s/it] 29%|██▉       | 146/500 [2:45:44<6:54:08, 70.19s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 7.35E+05, Train scatter: [0.1759 0.0508 0.2583 0.4108]
L1 regularization loss: 4.49E+00, L2 regularization loss: 2.75E+00
Test scatter: [0.1786 0.0506 0.2609 0.4061], Lowest was [0.1786 0.0491 0.2452 0.4048]
Median for last 10 epochs: [0.1881 0.0519 0.2609 0.4063], Epochs since improvement 0
 29%|██▉       | 147/500 [2:46:37<6:23:40, 65.21s/it] 30%|██▉       | 148/500 [2:47:58<6:49:48, 69.85s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 7.00E+05, Train scatter: [0.1831 0.0523 0.2599 0.4095]
L1 regularization loss: 4.50E+00, L2 regularization loss: 2.78E+00
Test scatter: [0.1866 0.0523 0.2627 0.4125], Lowest was [0.1786 0.0491 0.2452 0.4048]
Median for last 10 epochs: [0.1866 0.0519 0.262  0.4125], Epochs since improvement 2
 30%|██▉       | 149/500 [2:48:51<6:20:13, 65.00s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 5.97E+05, Train scatter: [0.1799 0.0565 0.2516 0.4259]
L1 regularization loss: 4.50E+00, L2 regularization loss: 2.80E+00
Test scatter: [0.1798 0.0557 0.2538 0.4197], Lowest was [0.1786 0.0491 0.2452 0.4048]
Median for last 10 epochs: [0.1866 0.0523 0.262  0.4151], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 30%|███       | 150/500 [2:50:19<6:59:04, 71.84s/it] 30%|███       | 151/500 [2:51:13<6:25:56, 66.35s/it] 30%|███       | 152/500 [2:52:34<6:51:27, 70.94s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 6.03E+05, Train scatter: [0.168  0.047  0.2489 0.4031]
L1 regularization loss: 4.51E+00, L2 regularization loss: 2.83E+00
Test scatter: [0.1739 0.0473 0.252  0.4058], Lowest was [0.1739 0.0473 0.2452 0.4048]
Median for last 10 epochs: [0.1798 0.0519 0.2609 0.4125], Epochs since improvement 0
 31%|███       | 153/500 [2:53:28<6:20:19, 65.76s/it] 31%|███       | 154/500 [2:54:50<6:47:24, 70.65s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 5.48E+05, Train scatter: [0.187  0.0479 0.2445 0.399 ]
L1 regularization loss: 4.53E+00, L2 regularization loss: 2.87E+00
Test scatter: [0.1859 0.0479 0.2476 0.3945], Lowest was [0.1739 0.0473 0.2452 0.3945]
Median for last 10 epochs: [0.1798 0.0506 0.2538 0.4061], Epochs since improvement 0
 31%|███       | 155/500 [2:55:44<6:17:10, 65.60s/it] 31%|███       | 156/500 [2:57:05<6:42:08, 70.14s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 5.19E+05, Train scatter: [0.1927 0.0475 0.2452 0.401 ]
L1 regularization loss: 4.52E+00, L2 regularization loss: 2.89E+00
Test scatter: [0.1927 0.0476 0.2484 0.3963], Lowest was [0.1739 0.0473 0.2452 0.3945]
Median for last 10 epochs: [0.1859 0.0479 0.252  0.4058], Epochs since improvement 2
 31%|███▏      | 157/500 [2:57:58<6:12:37, 65.18s/it] 32%|███▏      | 158/500 [2:59:20<6:39:34, 70.10s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 4.58E+05, Train scatter: [0.1713 0.0486 0.2524 0.4168]
L1 regularization loss: 4.53E+00, L2 regularization loss: 2.92E+00
Test scatter: [0.1779 0.0487 0.256  0.4216], Lowest was [0.1739 0.0473 0.2452 0.3945]
Median for last 10 epochs: [0.1798 0.0479 0.252  0.4058], Epochs since improvement 4
 32%|███▏      | 159/500 [3:00:14<6:10:48, 65.24s/it]Epoch: 160 done with learning rate 9.04E-03, Train loss: 4.14E+05, Train scatter: [0.1709 0.0499 0.248  0.4021]
L1 regularization loss: 4.55E+00, L2 regularization loss: 2.95E+00
Test scatter: [0.1728 0.0497 0.2512 0.3962], Lowest was [0.1728 0.0473 0.2452 0.3945]
Median for last 10 epochs: [0.1779 0.0479 0.2512 0.3963], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 32%|███▏      | 160/500 [3:01:44<6:51:27, 72.61s/it] 32%|███▏      | 161/500 [3:02:37<6:18:12, 66.94s/it] 32%|███▏      | 162/500 [3:03:58<6:40:25, 71.08s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: 3.38E+05, Train scatter: [0.1542 0.0507 0.2499 0.4016]
L1 regularization loss: 4.56E+00, L2 regularization loss: 2.98E+00
Test scatter: [0.1577 0.0503 0.2515 0.3971], Lowest was [0.1577 0.0473 0.2452 0.3945]
Median for last 10 epochs: [0.1779 0.0487 0.2512 0.3963], Epochs since improvement 0
 33%|███▎      | 163/500 [3:04:52<6:09:49, 65.84s/it] 33%|███▎      | 164/500 [3:06:13<6:34:56, 70.52s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: 2.43E+05, Train scatter: [0.1489 0.0499 0.2507 0.4016]
L1 regularization loss: 4.58E+00, L2 regularization loss: 3.02E+00
Test scatter: [0.153  0.0496 0.2531 0.3993], Lowest was [0.153  0.0473 0.2452 0.3945]
Median for last 10 epochs: [0.1728 0.0496 0.2515 0.3971], Epochs since improvement 0
 33%|███▎      | 165/500 [3:07:07<6:05:22, 65.44s/it] 33%|███▎      | 166/500 [3:08:29<6:33:06, 70.62s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: 1.74E+05, Train scatter: [0.1427 0.0462 0.2419 0.3972]
L1 regularization loss: 4.58E+00, L2 regularization loss: 3.06E+00
Test scatter: [0.1449 0.0472 0.2433 0.3944], Lowest was [0.1449 0.0472 0.2433 0.3944]
Median for last 10 epochs: [0.1577 0.0496 0.2515 0.3971], Epochs since improvement 0
 33%|███▎      | 167/500 [3:09:23<6:03:25, 65.48s/it] 34%|███▎      | 168/500 [3:10:44<6:28:56, 70.29s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: 8.32E+04, Train scatter: [0.1567 0.0446 0.2345 0.39  ]
L1 regularization loss: 4.58E+00, L2 regularization loss: 3.08E+00
Test scatter: [0.1598 0.0454 0.2376 0.3934], Lowest was [0.1449 0.0454 0.2376 0.3934]
Median for last 10 epochs: [0.1577 0.0496 0.2512 0.3962], Epochs since improvement 0
 34%|███▍      | 169/500 [3:11:38<6:00:21, 65.32s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: 1.46E+04, Train scatter: [0.1849 0.048  0.247  0.3937]
L1 regularization loss: 4.58E+00, L2 regularization loss: 3.11E+00
Test scatter: [0.1878 0.0481 0.2498 0.3967], Lowest was [0.1449 0.0454 0.2376 0.3934]
Median for last 10 epochs: [0.1577 0.0481 0.2498 0.3967], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 34%|███▍      | 170/500 [3:13:06<6:35:52, 71.98s/it] 34%|███▍      | 171/500 [3:13:59<6:04:45, 66.52s/it] 34%|███▍      | 172/500 [3:15:21<6:28:57, 71.15s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -4.94E+04, Train scatter: [0.1689 0.0463 0.2423 0.3859]
L1 regularization loss: 4.60E+00, L2 regularization loss: 3.14E+00
Test scatter: [0.1668 0.0466 0.2452 0.3852], Lowest was [0.1449 0.0454 0.2376 0.3852]
Median for last 10 epochs: [0.1598 0.0472 0.2452 0.3944], Epochs since improvement 0
 35%|███▍      | 173/500 [3:16:15<5:59:16, 65.92s/it] 35%|███▍      | 174/500 [3:17:36<6:22:40, 70.43s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -1.03E+05, Train scatter: [0.1743 0.0433 0.2262 0.3796]
L1 regularization loss: 4.64E+00, L2 regularization loss: 3.19E+00
Test scatter: [0.1722 0.044  0.2293 0.3837], Lowest was [0.1449 0.044  0.2293 0.3837]
Median for last 10 epochs: [0.1668 0.0466 0.2433 0.3934], Epochs since improvement 0
 35%|███▌      | 175/500 [3:18:30<5:54:27, 65.44s/it] 35%|███▌      | 176/500 [3:19:52<6:19:37, 70.30s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -1.69E+05, Train scatter: [0.1464 0.0426 0.2231 0.385 ]
L1 regularization loss: 4.64E+00, L2 regularization loss: 3.22E+00
Test scatter: [0.1456 0.0426 0.2265 0.3835], Lowest was [0.1449 0.0426 0.2265 0.3835]
Median for last 10 epochs: [0.1668 0.0454 0.2376 0.3852], Epochs since improvement 0
 35%|███▌      | 177/500 [3:20:45<5:51:31, 65.30s/it] 36%|███▌      | 178/500 [3:22:06<6:15:28, 69.97s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -2.17E+05, Train scatter: [0.1517 0.0456 0.2272 0.3901]
L1 regularization loss: 4.64E+00, L2 regularization loss: 3.24E+00
Test scatter: [0.1571 0.0459 0.2304 0.3929], Lowest was [0.1449 0.0426 0.2265 0.3835]
Median for last 10 epochs: [0.1668 0.0459 0.2304 0.3852], Epochs since improvement 2
 36%|███▌      | 179/500 [3:23:00<5:48:19, 65.11s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -2.27E+05, Train scatter: [0.16   0.0464 0.233  0.4004]
L1 regularization loss: 4.75E+00, L2 regularization loss: 3.33E+00
Test scatter: [0.1607 0.0462 0.2333 0.3963], Lowest was [0.1449 0.0426 0.2265 0.3835]
Median for last 10 epochs: [0.1607 0.0459 0.2304 0.3852], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 36%|███▌      | 180/500 [3:24:28<6:24:56, 72.18s/it] 36%|███▌      | 181/500 [3:25:22<5:54:13, 66.63s/it] 36%|███▋      | 182/500 [3:26:44<6:17:47, 71.28s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -2.88E+05, Train scatter: [0.1313 0.0458 0.2239 0.3816]
L1 regularization loss: 4.71E+00, L2 regularization loss: 3.35E+00
Test scatter: [0.1366 0.0457 0.2267 0.3829], Lowest was [0.1366 0.0426 0.2265 0.3829]
Median for last 10 epochs: [0.1571 0.0457 0.2293 0.3837], Epochs since improvement 0
 37%|███▋      | 183/500 [3:27:38<5:48:42, 66.00s/it] 37%|███▋      | 184/500 [3:28:59<6:11:24, 70.52s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -3.15E+05, Train scatter: [0.1567 0.0488 0.2303 0.3842]
L1 regularization loss: 4.69E+00, L2 regularization loss: 3.36E+00
Test scatter: [0.1572 0.048  0.2333 0.3838], Lowest was [0.1366 0.0426 0.2265 0.3829]
Median for last 10 epochs: [0.1571 0.0459 0.2304 0.3838], Epochs since improvement 2
 37%|███▋      | 185/500 [3:29:53<5:43:31, 65.43s/it] 37%|███▋      | 186/500 [3:31:13<6:06:16, 69.99s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -3.30E+05, Train scatter: [0.1238 0.0413 0.2204 0.3763]
L1 regularization loss: 4.70E+00, L2 regularization loss: 3.39E+00
Test scatter: [0.1265 0.0414 0.2237 0.3786], Lowest was [0.1265 0.0414 0.2237 0.3786]
Median for last 10 epochs: [0.1571 0.0459 0.2304 0.3838], Epochs since improvement 0
 37%|███▋      | 187/500 [3:32:07<5:39:26, 65.07s/it] 38%|███▊      | 188/500 [3:33:28<6:02:53, 69.79s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -3.48E+05, Train scatter: [0.1262 0.0422 0.2203 0.381 ]
L1 regularization loss: 4.70E+00, L2 regularization loss: 3.42E+00
Test scatter: [0.1279 0.0419 0.2235 0.3827], Lowest was [0.1265 0.0414 0.2235 0.3786]
Median for last 10 epochs: [0.1366 0.0457 0.2267 0.3829], Epochs since improvement 0
 38%|███▊      | 189/500 [3:34:21<5:36:30, 64.92s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -3.63E+05, Train scatter: [0.1308 0.0457 0.2222 0.39  ]
L1 regularization loss: 4.69E+00, L2 regularization loss: 3.45E+00
Test scatter: [0.1358 0.0455 0.2266 0.3871], Lowest was [0.1265 0.0414 0.2235 0.3786]
Median for last 10 epochs: [0.1358 0.0455 0.2266 0.3829], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 38%|███▊      | 190/500 [3:35:49<6:11:06, 71.83s/it] 38%|███▊      | 191/500 [3:36:43<5:41:46, 66.36s/it] 38%|███▊      | 192/500 [3:38:04<6:03:13, 70.76s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -3.22E+05, Train scatter: [0.1278 0.0413 0.2389 0.386 ]
L1 regularization loss: 4.80E+00, L2 regularization loss: 3.56E+00
Test scatter: [0.1283 0.041  0.2353 0.385 ], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1283 0.0419 0.2266 0.3838], Epochs since improvement 0
 39%|███▊      | 193/500 [3:38:58<5:35:58, 65.66s/it] 39%|███▉      | 194/500 [3:40:19<5:58:34, 70.31s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -3.70E+05, Train scatter: [0.1429 0.042  0.224  0.3827]
L1 regularization loss: 4.77E+00, L2 regularization loss: 3.60E+00
Test scatter: [0.1442 0.0417 0.2249 0.3828], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1283 0.0417 0.2249 0.3828], Epochs since improvement 2
 39%|███▉      | 195/500 [3:41:12<5:32:00, 65.31s/it] 39%|███▉      | 196/500 [3:42:34<5:56:17, 70.32s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -3.82E+05, Train scatter: [0.721  0.1121 0.3342 0.5338]
L1 regularization loss: 4.76E+00, L2 regularization loss: 3.62E+00
Test scatter: [0.7033 0.109  0.3313 0.5258], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1358 0.0419 0.2266 0.385 ], Epochs since improvement 4
 39%|███▉      | 197/500 [3:43:28<5:30:03, 65.36s/it] 40%|███▉      | 198/500 [3:44:50<5:53:28, 70.23s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -2.83E+05, Train scatter: [0.1741 0.0528 0.3095 0.4427]
L1 regularization loss: 5.42E+00, L2 regularization loss: 4.22E+00
Test scatter: [0.1821 0.053  0.31   0.4424], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1442 0.0455 0.2353 0.3871], Epochs since improvement 6
 40%|███▉      | 199/500 [3:45:44<5:27:38, 65.31s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -2.72E+05, Train scatter: [0.1687 0.0457 0.244  0.4156]
L1 regularization loss: 5.44E+00, L2 regularization loss: 4.28E+00
Test scatter: [0.1712 0.0452 0.2452 0.4075], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1712 0.0452 0.2452 0.4075], Epochs since improvement 8
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 40%|████      | 200/500 [3:47:12<6:00:56, 72.19s/it] 40%|████      | 201/500 [3:48:06<5:32:17, 66.68s/it] 40%|████      | 202/500 [3:49:27<5:53:12, 71.11s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -3.62E+05, Train scatter: [0.1398 0.0441 0.2333 0.413 ]
L1 regularization loss: 5.41E+00, L2 regularization loss: 4.28E+00
Test scatter: [0.1394 0.0441 0.2367 0.4093], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1712 0.0452 0.2452 0.4093], Epochs since improvement 10
 41%|████      | 203/500 [3:50:21<5:26:14, 65.91s/it] 41%|████      | 204/500 [3:51:43<5:48:46, 70.70s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -3.49E+05, Train scatter: [0.1652 0.0484 0.2763 0.4203]
L1 regularization loss: 5.40E+00, L2 regularization loss: 4.29E+00
Test scatter: [0.1675 0.0481 0.2787 0.4139], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1712 0.0481 0.2787 0.4139], Epochs since improvement 12
 41%|████      | 205/500 [3:52:36<5:22:21, 65.56s/it] 41%|████      | 206/500 [3:53:59<5:45:47, 70.57s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -3.42E+05, Train scatter: [0.1373 0.0453 0.2463 0.4137]
L1 regularization loss: 5.42E+00, L2 regularization loss: 4.34E+00
Test scatter: [0.1368 0.0453 0.2487 0.4098], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1675 0.0453 0.2487 0.4098], Epochs since improvement 14
 41%|████▏     | 207/500 [3:54:52<5:19:44, 65.47s/it] 42%|████▏     | 208/500 [3:56:14<5:41:54, 70.26s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: 2.92E+04, Train scatter: [0.4407 0.0956 0.4135 0.5796]
L1 regularization loss: 5.88E+00, L2 regularization loss: 4.95E+00
Test scatter: [0.4296 0.094  0.4107 0.5697], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1675 0.0453 0.2487 0.4098], Epochs since improvement 16
 42%|████▏     | 209/500 [3:57:07<5:16:27, 65.25s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -2.39E+05, Train scatter: [0.2142 0.0725 0.336  0.5244]
L1 regularization loss: 5.96E+00, L2 regularization loss: 5.11E+00
Test scatter: [0.2135 0.0718 0.3356 0.5165], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1675 0.0481 0.2787 0.4139], Epochs since improvement 18
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 42%|████▏     | 210/500 [3:58:36<5:49:01, 72.21s/it] 42%|████▏     | 211/500 [3:59:29<5:21:13, 66.69s/it] 42%|████▏     | 212/500 [4:00:51<5:41:32, 71.16s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -3.20E+05, Train scatter: [0.1951 0.0529 0.2964 0.463 ]
L1 regularization loss: 5.97E+00, L2 regularization loss: 5.18E+00
Test scatter: [0.1921 0.0531 0.2977 0.4567], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1921 0.0531 0.2977 0.4567], Epochs since improvement 20
 43%|████▎     | 213/500 [4:01:45<5:15:19, 65.92s/it] 43%|████▎     | 213/500 [4:03:07<5:27:35, 68.49s/it]
Epoch: 214 done with learning rate 7.58E-03, Train loss: -2.85E+05, Train scatter: [0.186  0.0563 0.2988 0.4723]
L1 regularization loss: 6.14E+00, L2 regularization loss: 5.35E+00
Test scatter: [0.1865 0.0553 0.299  0.4629], Lowest was [0.1265 0.041  0.2235 0.3786]
Median for last 10 epochs: [0.1921 0.0553 0.299  0.4629], Epochs since improvement 22
Exited after 214 epochs due to early stopping
14587.90 seconds spent training, 29.176 seconds per epoch. Processed 2387 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.18644525 0.05528381 0.29900378 0.46288994]
{'epoch_exit': 213, 'scatter_m_star': 0.18644525, 'lowest_m_star': 0.12654656, 'last20_m_star': 0.18428652, 'last10_m_star': 0.19210169, 'scatter_v_disk': 0.05528381, 'lowest_v_disk': 0.040981658, 'last20_v_disk': 0.053013578, 'last10_v_disk': 0.055285525, 'scatter_m_cold': 0.29900378, 'lowest_m_cold': 0.22346371, 'last20_m_cold': 0.29833964, 'last10_m_cold': 0.29901233, 'scatter_sfr_100': 0.46288994, 'lowest_sfr_100': 0.37859264, 'last20_sfr_100': 0.44954783, 'last10_sfr_100': 0.46290404}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
