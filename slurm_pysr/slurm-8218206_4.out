Starting process with 6 experiments
{'conv_layers': [1, 2, 3], 'batch_size': [256, 512]}
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_tgukca
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:32<4:26:57, 32.10s/it]  0%|          | 2/500 [01:20<5:45:48, 41.66s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.27E+07, Train scatter: [0.9352 0.1671 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.31E-01
Test scatter: [0.9196 0.1662 0.5355 0.9851], Lowest was [0.9196 0.1662 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1662 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:52<5:07:47, 37.16s/it]  1%|          | 4/500 [02:42<5:49:46, 42.31s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 6.86E+06, Train scatter: [0.9351 0.1477 0.5439 0.9954]
L1 regularization loss: 1.53E+00, L2 regularization loss: 3.54E-01
Test scatter: [0.9195 0.1466 0.5353 0.985 ], Lowest was [0.9195 0.1466 0.5353 0.985 ]
Median for last 10 epochs: [0.9195 0.1466 0.5353 0.985 ], Epochs since improvement 0
  1%|          | 5/500 [03:14<5:19:31, 38.73s/it]  1%|          | 6/500 [04:05<5:52:18, 42.79s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 5.21E+06, Train scatter: [0.9344 0.1254 0.5419 0.7093]
L1 regularization loss: 1.57E+00, L2 regularization loss: 3.90E-01
Test scatter: [0.9189 0.1255 0.5332 0.6982], Lowest was [0.9189 0.1255 0.5332 0.6982]
Median for last 10 epochs: [0.9189 0.1255 0.5332 0.6982], Epochs since improvement 0
  1%|▏         | 7/500 [04:37<5:22:17, 39.22s/it]  2%|▏         | 8/500 [05:27<5:49:27, 42.62s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 4.32E+06, Train scatter: [0.9176 0.1057 0.5331 0.6103]
L1 regularization loss: 1.59E+00, L2 regularization loss: 4.04E-01
Test scatter: [0.9032 0.1049 0.5248 0.6039], Lowest was [0.9032 0.1049 0.5248 0.6039]
Median for last 10 epochs: [0.911  0.1152 0.529  0.651 ], Epochs since improvement 0
  2%|▏         | 9/500 [05:59<5:21:22, 39.27s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 3.38E+06, Train scatter: [0.7489 0.0959 0.5215 0.5711]
L1 regularization loss: 1.61E+00, L2 regularization loss: 4.14E-01
Test scatter: [0.7407 0.0955 0.5138 0.5672], Lowest was [0.7407 0.0955 0.5138 0.5672]
Median for last 10 epochs: [0.9032 0.1049 0.5248 0.6039], Epochs since improvement 0
  2%|▏         | 10/500 [06:54<6:01:00, 44.21s/it]  2%|▏         | 11/500 [07:27<5:33:08, 40.88s/it]  2%|▏         | 12/500 [08:17<5:55:05, 43.66s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 2.07E+06, Train scatter: [0.611  0.0919 0.4038 0.5803]
L1 regularization loss: 1.62E+00, L2 regularization loss: 4.23E-01
Test scatter: [0.6135 0.0922 0.4061 0.5828], Lowest was [0.6135 0.0922 0.4061 0.5672]
Median for last 10 epochs: [0.9032 0.1049 0.5248 0.6039], Epochs since improvement 0
  3%|▎         | 13/500 [08:50<5:26:35, 40.24s/it]  3%|▎         | 14/500 [09:40<5:49:31, 43.15s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 1.49E+06, Train scatter: [0.591  0.0932 0.3707 0.6083]
L1 regularization loss: 1.64E+00, L2 regularization loss: 4.31E-01
Test scatter: [0.5714 0.0944 0.3829 0.6154], Lowest was [0.5714 0.0922 0.3829 0.5672]
Median for last 10 epochs: [0.7407 0.0955 0.5138 0.6039], Epochs since improvement 0
  3%|▎         | 15/500 [10:12<5:22:36, 39.91s/it]  3%|▎         | 16/500 [11:01<5:44:40, 42.73s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 1.26E+06, Train scatter: [0.5053 0.0856 0.3649 0.5678]
L1 regularization loss: 1.65E+00, L2 regularization loss: 4.39E-01
Test scatter: [0.5038 0.0868 0.3711 0.572 ], Lowest was [0.5038 0.0868 0.3711 0.5672]
Median for last 10 epochs: [0.6135 0.0944 0.4061 0.5828], Epochs since improvement 0
  3%|▎         | 17/500 [11:33<5:17:18, 39.42s/it]  4%|▎         | 18/500 [12:23<5:41:56, 42.57s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 1.05E+06, Train scatter: [0.5479 0.0818 0.3377 0.5547]
L1 regularization loss: 1.67E+00, L2 regularization loss: 4.47E-01
Test scatter: [0.5423 0.0823 0.3399 0.5562], Lowest was [0.5038 0.0823 0.3399 0.5562]
Median for last 10 epochs: [0.5714 0.0922 0.3829 0.572 ], Epochs since improvement 0
  4%|▍         | 19/500 [12:55<5:17:06, 39.56s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 9.28E+05, Train scatter: [0.5708 0.0793 0.332  0.5451]
L1 regularization loss: 1.70E+00, L2 regularization loss: 4.57E-01
Test scatter: [0.5513 0.08   0.3387 0.5483], Lowest was [0.5038 0.08   0.3387 0.5483]
Median for last 10 epochs: [0.5513 0.0868 0.3711 0.572 ], Epochs since improvement 0
  4%|▍         | 20/500 [13:51<5:53:59, 44.25s/it]  4%|▍         | 21/500 [14:22<5:22:39, 40.42s/it]  4%|▍         | 22/500 [15:11<5:42:54, 43.04s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.62E+05, Train scatter: [0.4937 0.0779 0.3166 0.5331]
L1 regularization loss: 1.73E+00, L2 regularization loss: 4.71E-01
Test scatter: [0.4878 0.0786 0.3213 0.5323], Lowest was [0.4878 0.0786 0.3213 0.5323]
Median for last 10 epochs: [0.5423 0.0823 0.3399 0.5562], Epochs since improvement 0
  5%|▍         | 23/500 [15:43<5:15:59, 39.75s/it]  5%|▍         | 24/500 [16:34<5:41:12, 43.01s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 6.71E+05, Train scatter: [0.4256 0.0751 0.3041 0.5134]
L1 regularization loss: 1.77E+00, L2 regularization loss: 4.88E-01
Test scatter: [0.4265 0.0757 0.308  0.5143], Lowest was [0.4265 0.0757 0.308  0.5143]
Median for last 10 epochs: [0.5038 0.08   0.3387 0.5483], Epochs since improvement 0
  5%|▌         | 25/500 [17:07<5:15:52, 39.90s/it]  5%|▌         | 26/500 [17:56<5:36:43, 42.62s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 5.67E+05, Train scatter: [0.4182 0.0737 0.3138 0.5067]
L1 regularization loss: 1.81E+00, L2 regularization loss: 5.05E-01
Test scatter: [0.4225 0.0744 0.3161 0.5072], Lowest was [0.4225 0.0744 0.308  0.5072]
Median for last 10 epochs: [0.4878 0.0786 0.3213 0.5323], Epochs since improvement 0
  5%|▌         | 27/500 [18:28<5:13:07, 39.72s/it]  6%|▌         | 28/500 [19:19<5:37:36, 42.92s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 5.33E+05, Train scatter: [0.4581 0.0731 0.287  0.503 ]
L1 regularization loss: 1.85E+00, L2 regularization loss: 5.25E-01
Test scatter: [0.4725 0.074  0.2944 0.5042], Lowest was [0.4225 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.4725 0.0757 0.3161 0.5143], Epochs since improvement 0
  6%|▌         | 29/500 [19:52<5:13:05, 39.88s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 4.39E+05, Train scatter: [0.4394 0.074  0.2888 0.5093]
L1 regularization loss: 1.89E+00, L2 regularization loss: 5.51E-01
Test scatter: [0.464  0.0761 0.2992 0.5126], Lowest was [0.4225 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.464  0.0757 0.308  0.5126], Epochs since improvement 2
  6%|▌         | 30/500 [20:47<5:48:22, 44.47s/it]  6%|▌         | 31/500 [21:20<5:19:58, 40.94s/it]  6%|▋         | 32/500 [22:10<5:41:43, 43.81s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 5.94E+06, Train scatter: [0.9461 0.1324 0.5437 0.9847]
L1 regularization loss: 1.93E+00, L2 regularization loss: 5.78E-01
Test scatter: [0.9311 0.1322 0.5351 0.9746], Lowest was [0.4225 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.464  0.0757 0.308  0.5126], Epochs since improvement 4
  7%|▋         | 33/500 [22:42<5:12:17, 40.12s/it]  7%|▋         | 34/500 [23:32<5:36:10, 43.28s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.82E+06, Train scatter: [0.8118 0.1669 0.528  0.9894]
L1 regularization loss: 2.34E+00, L2 regularization loss: 7.42E-01
Test scatter: [0.8059 0.1629 0.5227 0.9798], Lowest was [0.4225 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.4725 0.0761 0.3161 0.5126], Epochs since improvement 6
  7%|▋         | 35/500 [24:05<5:11:33, 40.20s/it]  7%|▋         | 36/500 [24:55<5:33:36, 43.14s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 1.69E+06, Train scatter: [0.6612 0.1597 0.5219 0.9753]
L1 regularization loss: 2.38E+00, L2 regularization loss: 8.26E-01
Test scatter: [0.6566 0.1558 0.5201 0.9666], Lowest was [0.4225 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.6566 0.1322 0.5201 0.9666], Epochs since improvement 8
  7%|▋         | 37/500 [25:27<5:07:33, 39.86s/it]  8%|▊         | 38/500 [26:17<5:30:29, 42.92s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 7.98E+05, Train scatter: [0.5291 0.1256 0.5019 0.8934]
L1 regularization loss: 2.42E+00, L2 regularization loss: 9.74E-01
Test scatter: [0.5521 0.1253 0.4946 0.8889], Lowest was [0.4225 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.6566 0.1322 0.5201 0.9666], Epochs since improvement 10
  8%|▊         | 39/500 [26:50<5:06:40, 39.91s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.43E+05, Train scatter: [0.45   0.1027 0.4628 0.7534]
L1 regularization loss: 2.44E+00, L2 regularization loss: 1.05E+00
Test scatter: [0.4673 0.1033 0.4525 0.7588], Lowest was [0.4225 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.6566 0.1322 0.5201 0.9666], Epochs since improvement 12
  8%|▊         | 40/500 [27:46<5:42:32, 44.68s/it]  8%|▊         | 41/500 [28:19<5:14:52, 41.16s/it]  8%|▊         | 42/500 [29:10<5:37:27, 44.21s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: -3.08E+04, Train scatter: [0.4807 0.0938 0.4482 0.6936]
L1 regularization loss: 2.45E+00, L2 regularization loss: 1.09E+00
Test scatter: [0.4848 0.0952 0.4398 0.6999], Lowest was [0.4225 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.5521 0.1253 0.4946 0.8889], Epochs since improvement 14
  9%|▊         | 43/500 [29:43<5:10:40, 40.79s/it]  9%|▉         | 44/500 [30:33<5:30:29, 43.49s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: -9.81E+04, Train scatter: [0.4457 0.0893 0.4328 0.6519]
L1 regularization loss: 2.46E+00, L2 regularization loss: 1.12E+00
Test scatter: [0.4451 0.0881 0.4215 0.6456], Lowest was [0.4225 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.4848 0.1033 0.4525 0.7588], Epochs since improvement 16
  9%|▉         | 45/500 [31:05<5:04:00, 40.09s/it]  9%|▉         | 46/500 [31:55<5:25:55, 43.07s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: -1.35E+05, Train scatter: [0.4392 0.0848 0.4129 0.63  ]
L1 regularization loss: 2.48E+00, L2 regularization loss: 1.15E+00
Test scatter: [0.4426 0.0866 0.4099 0.6357], Lowest was [0.4225 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.4673 0.0952 0.4398 0.6999], Epochs since improvement 18
  9%|▉         | 47/500 [32:28<5:02:31, 40.07s/it] 10%|▉         | 48/500 [33:19<5:25:34, 43.22s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: -1.59E+05, Train scatter: [0.4752 0.083  0.4081 0.6203]
L1 regularization loss: 2.50E+00, L2 regularization loss: 1.17E+00
Test scatter: [0.4716 0.084  0.4006 0.6177], Lowest was [0.4225 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.4673 0.0881 0.4215 0.6456], Epochs since improvement 20
 10%|▉         | 49/500 [33:52<5:02:00, 40.18s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: -1.71E+05, Train scatter: [0.3671 0.0802 0.4063 0.6004]
L1 regularization loss: 2.51E+00, L2 regularization loss: 1.20E+00
Test scatter: [0.3772 0.0805 0.4008 0.5987], Lowest was [0.3772 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.4451 0.0866 0.4099 0.6357], Epochs since improvement 0
 10%|█         | 50/500 [34:46<5:32:57, 44.39s/it] 10%|█         | 51/500 [35:20<5:07:39, 41.11s/it] 10%|█         | 52/500 [36:09<5:26:05, 43.67s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: -1.88E+05, Train scatter: [0.498  0.0791 0.3853 0.6247]
L1 regularization loss: 2.53E+00, L2 regularization loss: 1.22E+00
Test scatter: [0.5063 0.0815 0.3956 0.6346], Lowest was [0.3772 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.4451 0.084  0.4008 0.6346], Epochs since improvement 2
 11%|█         | 53/500 [36:41<4:59:23, 40.19s/it] 11%|█         | 54/500 [37:30<5:18:32, 42.85s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: -2.07E+05, Train scatter: [0.407  0.0768 0.3752 0.5808]
L1 regularization loss: 2.52E+00, L2 regularization loss: 1.24E+00
Test scatter: [0.4096 0.0784 0.3805 0.5816], Lowest was [0.3772 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.4426 0.0815 0.4006 0.6177], Epochs since improvement 4
 11%|█         | 55/500 [38:04<4:57:07, 40.06s/it] 11%|█         | 56/500 [38:54<5:18:11, 43.00s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: -1.94E+05, Train scatter: [0.4146 0.0741 0.5301 0.5607]
L1 regularization loss: 2.53E+00, L2 regularization loss: 1.26E+00
Test scatter: [0.4089 0.075  0.5219 0.561 ], Lowest was [0.3772 0.074  0.2944 0.5042]
Median for last 10 epochs: [0.4096 0.0805 0.4006 0.5987], Epochs since improvement 6
 11%|█▏        | 57/500 [39:27<4:56:15, 40.12s/it] 12%|█▏        | 58/500 [40:17<5:16:30, 42.96s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: -2.12E+05, Train scatter: [0.2543 0.0708 0.479  0.5468]
L1 regularization loss: 2.54E+00, L2 regularization loss: 1.30E+00
Test scatter: [0.2605 0.0716 0.4745 0.551 ], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.4089 0.0784 0.4008 0.5816], Epochs since improvement 0
 12%|█▏        | 59/500 [40:49<4:52:36, 39.81s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 1.09E+09, Train scatter: [0.9352 0.1728 0.5441 0.9956]
L1 regularization loss: 5.86E+00, L2 regularization loss: 2.51E+00
Test scatter: [0.9195 0.169  0.5355 0.9853], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.4096 0.0784 0.4745 0.5816], Epochs since improvement 2
 12%|█▏        | 60/500 [41:46<5:28:37, 44.81s/it] 12%|█▏        | 61/500 [42:19<5:02:35, 41.36s/it] 12%|█▏        | 62/500 [43:10<5:22:04, 44.12s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 1.63E+06, Train scatter: [0.9351 0.1728 0.5441 0.9954]
L1 regularization loss: 5.85E+00, L2 regularization loss: 2.52E+00
Test scatter: [0.9195 0.169  0.5355 0.9851], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.4096 0.0784 0.5219 0.5816], Epochs since improvement 4
 13%|█▎        | 63/500 [43:42<4:56:36, 40.72s/it] 13%|█▎        | 64/500 [44:34<5:18:33, 43.84s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 1.47E+06, Train scatter: [0.9351 0.1728 0.5441 0.9953]
L1 regularization loss: 5.85E+00, L2 regularization loss: 2.51E+00
Test scatter: [0.9195 0.169  0.5355 0.985 ], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 6
 13%|█▎        | 65/500 [45:06<4:53:18, 40.46s/it] 13%|█▎        | 66/500 [45:56<5:13:59, 43.41s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.30E+06, Train scatter: [0.9351 0.1728 0.5441 0.9952]
L1 regularization loss: 5.84E+00, L2 regularization loss: 2.51E+00
Test scatter: [0.9195 0.1689 0.5355 0.9849], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 8
 13%|█▎        | 67/500 [46:28<4:48:00, 39.91s/it] 14%|█▎        | 68/500 [47:18<5:08:43, 42.88s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 1.21E+06, Train scatter: [0.9351 0.1728 0.5441 0.9952]
L1 regularization loss: 5.83E+00, L2 regularization loss: 2.51E+00
Test scatter: [0.9195 0.1689 0.5355 0.9848], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.985 ], Epochs since improvement 10
 14%|█▍        | 69/500 [47:50<4:44:34, 39.62s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.11E+06, Train scatter: [0.9351 0.1728 0.5441 0.9951]
L1 regularization loss: 5.83E+00, L2 regularization loss: 2.54E+00
Test scatter: [0.9195 0.1689 0.5355 0.9847], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.9195 0.1689 0.5355 0.9849], Epochs since improvement 12
 14%|█▍        | 70/500 [48:47<5:21:42, 44.89s/it] 14%|█▍        | 71/500 [49:20<4:54:53, 41.24s/it] 14%|█▍        | 72/500 [50:09<5:11:26, 43.66s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.03E+06, Train scatter: [0.9352 0.1728 0.5441 0.9951]
L1 regularization loss: 5.81E+00, L2 regularization loss: 2.56E+00
Test scatter: [0.9195 0.169  0.5355 0.9848], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.9195 0.1689 0.5355 0.9848], Epochs since improvement 14
 15%|█▍        | 73/500 [50:41<4:46:27, 40.25s/it] 15%|█▍        | 74/500 [51:31<5:05:53, 43.08s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 9.42E+05, Train scatter: [0.9351 0.1728 0.5441 0.9949]
L1 regularization loss: 5.79E+00, L2 regularization loss: 2.55E+00
Test scatter: [0.9195 0.169  0.5355 0.9846], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.9195 0.1689 0.5355 0.9848], Epochs since improvement 16
 15%|█▌        | 75/500 [52:03<4:41:50, 39.79s/it] 15%|█▌        | 76/500 [52:54<5:03:52, 43.00s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 8.45E+05, Train scatter: [0.9351 0.1728 0.5441 0.9948]
L1 regularization loss: 5.77E+00, L2 regularization loss: 2.54E+00
Test scatter: [0.9194 0.169  0.5355 0.9844], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.9847], Epochs since improvement 18
 15%|█▌        | 77/500 [53:26<4:40:42, 39.82s/it] 16%|█▌        | 78/500 [54:16<5:01:59, 42.94s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 7.71E+05, Train scatter: [0.9351 0.1728 0.5441 0.995 ]
L1 regularization loss: 5.74E+00, L2 regularization loss: 2.51E+00
Test scatter: [0.9195 0.169  0.5355 0.9846], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.9846], Epochs since improvement 20
 16%|█▌        | 79/500 [54:49<4:39:26, 39.82s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 7.05E+05, Train scatter: [0.9351 0.1728 0.5441 0.995 ]
L1 regularization loss: 5.71E+00, L2 regularization loss: 2.48E+00
Test scatter: [0.9195 0.169  0.5355 0.9846], Lowest was [0.2605 0.0716 0.2944 0.5042]
Median for last 10 epochs: [0.9195 0.169  0.5355 0.9846], Epochs since improvement 22
 16%|█▌        | 79/500 [55:44<4:57:03, 42.34s/it]
Exited after 80 epochs due to early stopping
3344.74 seconds spent training, 6.689 seconds per epoch. Processed 10410 trees per second
[0.9194735  0.16894983 0.5354753  0.98460263]
{'epoch_exit': 79, 'scatter_m_star': 0.9194735, 'lowest_m_star': 0.26048434, 'last20_m_star': 0.91951513, 'last10_m_star': 0.91950077, 'scatter_v_disk': 0.16894983, 'lowest_v_disk': 0.07163158, 'last20_v_disk': 0.16895376, 'last10_v_disk': 0.16895495, 'scatter_m_cold': 0.5354753, 'lowest_m_cold': 0.29444602, 'last20_m_cold': 0.53549135, 'last10_m_cold': 0.5354908, 'scatter_sfr_100': 0.98460263, 'lowest_sfr_100': 0.50416136, 'last20_sfr_100': 0.9847399, 'last10_sfr_100': 0.98461205}
Finished 1/1
Exited training after None epochs
Experiment 1 done: 1 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  1 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 1, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con1bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_avmceq
RelU conv activation
LeakyRelU decode activation
N_params 298056
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:56:31, 28.44s/it]  0%|          | 2/500 [01:14<5:20:39, 38.63s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.36E+07, Train scatter: [0.9353 0.164  0.5442 0.9954]
L1 regularization loss: 1.51E+00, L2 regularization loss: 3.26E-01
Test scatter: [0.9197 0.1662 0.5356 0.9851], Lowest was [0.9197 0.1662 0.5356 0.9851]
Median for last 10 epochs: [0.9197 0.1662 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [01:42<4:39:08, 33.70s/it]  1%|          | 4/500 [02:28<5:18:50, 38.57s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.19E+07, Train scatter: [0.9353 0.1767 0.5441 0.9954]
L1 regularization loss: 1.52E+00, L2 regularization loss: 3.32E-01
Test scatter: [0.9197 0.1779 0.5355 0.9851], Lowest was [0.9197 0.1662 0.5355 0.9851]
Median for last 10 epochs: [0.9197 0.172  0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [02:56<4:47:54, 34.90s/it]  1%|          | 6/500 [03:43<5:20:54, 38.98s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.58E+06, Train scatter: [0.9352 0.1682 0.5441 0.9954]
L1 regularization loss: 1.54E+00, L2 regularization loss: 3.44E-01
Test scatter: [0.9196 0.1637 0.5356 0.9851], Lowest was [0.9196 0.1637 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1637 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [04:11<4:50:19, 35.33s/it]  2%|▏         | 8/500 [04:56<5:16:35, 38.61s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.43E+06, Train scatter: [0.9352 0.1468 0.5441 0.9949]
L1 regularization loss: 1.55E+00, L2 regularization loss: 3.65E-01
Test scatter: [0.9196 0.1417 0.5355 0.9845], Lowest was [0.9196 0.1417 0.5355 0.9845]
Median for last 10 epochs: [0.9196 0.1527 0.5355 0.9848], Epochs since improvement 0
  2%|▏         | 9/500 [05:25<4:49:40, 35.40s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.79E+06, Train scatter: [0.9349 0.1316 0.5441 0.688 ]
L1 regularization loss: 1.58E+00, L2 regularization loss: 3.94E-01
Test scatter: [0.9193 0.1276 0.5355 0.686 ], Lowest was [0.9193 0.1276 0.5355 0.686 ]
Median for last 10 epochs: [0.9196 0.1417 0.5355 0.9845], Epochs since improvement 0
  2%|▏         | 10/500 [06:16<5:29:10, 40.31s/it]  2%|▏         | 11/500 [06:44<4:57:52, 36.55s/it]  2%|▏         | 12/500 [07:30<5:20:23, 39.39s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.20E+06, Train scatter: [0.9302 0.12   0.5439 0.6208]
L1 regularization loss: 1.60E+00, L2 regularization loss: 4.06E-01
Test scatter: [0.9144 0.1169 0.5353 0.6126], Lowest was [0.9144 0.1169 0.5353 0.6126]
Median for last 10 epochs: [0.9196 0.1417 0.5355 0.9845], Epochs since improvement 0
  3%|▎         | 13/500 [07:58<4:51:09, 35.87s/it]  3%|▎         | 14/500 [08:44<5:17:00, 39.14s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 6.77E+06, Train scatter: [0.9308 0.1285 0.5429 0.8719]
L1 regularization loss: 1.62E+00, L2 regularization loss: 4.14E-01
Test scatter: [0.9156 0.1231 0.5344 0.8692], Lowest was [0.9144 0.1169 0.5344 0.6126]
Median for last 10 epochs: [0.9193 0.1276 0.5355 0.8692], Epochs since improvement 0
  3%|▎         | 15/500 [09:13<4:49:50, 35.86s/it]  3%|▎         | 16/500 [09:58<5:12:11, 38.70s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 6.15E+06, Train scatter: [0.8582 0.1056 0.5402 0.5859]
L1 regularization loss: 1.63E+00, L2 regularization loss: 4.26E-01
Test scatter: [0.8451 0.1033 0.5316 0.5773], Lowest was [0.8451 0.1033 0.5316 0.5773]
Median for last 10 epochs: [0.9156 0.1231 0.5353 0.686 ], Epochs since improvement 0
  3%|▎         | 17/500 [10:26<4:46:39, 35.61s/it]  4%|▎         | 18/500 [11:13<5:11:41, 38.80s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 5.74E+06, Train scatter: [0.535  0.1014 0.5366 0.5737]
L1 regularization loss: 1.65E+00, L2 regularization loss: 4.37E-01
Test scatter: [0.5336 0.0997 0.5282 0.5665], Lowest was [0.5336 0.0997 0.5282 0.5665]
Median for last 10 epochs: [0.9144 0.1169 0.5344 0.6126], Epochs since improvement 0
  4%|▍         | 19/500 [11:41<4:46:10, 35.70s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.38E+06, Train scatter: [0.5215 0.0964 0.5326 0.5632]
L1 regularization loss: 1.66E+00, L2 regularization loss: 4.47E-01
Test scatter: [0.5156 0.0945 0.5245 0.5592], Lowest was [0.5156 0.0945 0.5245 0.5592]
Median for last 10 epochs: [0.8451 0.1033 0.5316 0.5773], Epochs since improvement 0
  4%|▍         | 20/500 [12:31<5:20:11, 40.02s/it]  4%|▍         | 21/500 [12:59<4:49:52, 36.31s/it]  4%|▍         | 22/500 [13:45<5:12:57, 39.28s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.95E+06, Train scatter: [0.4961 0.0938 0.5296 0.5879]
L1 regularization loss: 1.67E+00, L2 regularization loss: 4.55E-01
Test scatter: [0.5077 0.0928 0.5207 0.5919], Lowest was [0.5077 0.0928 0.5207 0.5592]
Median for last 10 epochs: [0.5336 0.0997 0.5282 0.5773], Epochs since improvement 0
  5%|▍         | 23/500 [14:13<4:46:03, 35.98s/it]  5%|▍         | 24/500 [15:00<5:10:33, 39.15s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 4.24E+06, Train scatter: [0.544  0.0904 0.5106 0.609 ]
L1 regularization loss: 1.69E+00, L2 regularization loss: 4.66E-01
Test scatter: [0.5704 0.0906 0.5035 0.6135], Lowest was [0.5077 0.0906 0.5035 0.5592]
Median for last 10 epochs: [0.5336 0.0945 0.5245 0.5773], Epochs since improvement 0
  5%|▌         | 25/500 [15:29<4:45:10, 36.02s/it]  5%|▌         | 26/500 [16:14<5:06:36, 38.81s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.15E+06, Train scatter: [0.5752 0.0952 0.3829 0.6123]
L1 regularization loss: 1.71E+00, L2 regularization loss: 4.79E-01
Test scatter: [0.5901 0.0966 0.3884 0.6122], Lowest was [0.5077 0.0906 0.3884 0.5592]
Median for last 10 epochs: [0.5336 0.0945 0.5207 0.5919], Epochs since improvement 0
  5%|▌         | 27/500 [16:42<4:39:54, 35.51s/it]  6%|▌         | 28/500 [17:28<5:04:23, 38.69s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.07E+06, Train scatter: [0.5042 0.0906 0.3437 0.5828]
L1 regularization loss: 1.72E+00, L2 regularization loss: 4.87E-01
Test scatter: [0.5177 0.0905 0.3426 0.5763], Lowest was [0.5077 0.0905 0.3426 0.5592]
Median for last 10 epochs: [0.5177 0.0928 0.5035 0.5919], Epochs since improvement 0
  6%|▌         | 29/500 [17:56<4:38:10, 35.44s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 1.69E+06, Train scatter: [0.5057 0.0893 0.3312 0.5766]
L1 regularization loss: 1.74E+00, L2 regularization loss: 4.99E-01
Test scatter: [0.5296 0.0916 0.3395 0.5747], Lowest was [0.5077 0.0905 0.3395 0.5592]
Median for last 10 epochs: [0.5296 0.0916 0.3884 0.5919], Epochs since improvement 0
  6%|▌         | 30/500 [18:46<5:13:19, 40.00s/it]  6%|▌         | 31/500 [19:15<4:46:35, 36.66s/it]  6%|▋         | 32/500 [20:02<5:09:33, 39.69s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 1.43E+06, Train scatter: [0.4474 0.0837 0.3103 0.547 ]
L1 regularization loss: 1.76E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.4593 0.0835 0.3127 0.5437], Lowest was [0.4593 0.0835 0.3127 0.5437]
Median for last 10 epochs: [0.5296 0.0906 0.3426 0.5763], Epochs since improvement 0
  7%|▋         | 33/500 [20:30<4:42:19, 36.27s/it]  7%|▋         | 34/500 [21:16<5:03:34, 39.09s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 1.21E+06, Train scatter: [0.3885 0.0822 0.3214 0.5488]
L1 regularization loss: 1.78E+00, L2 regularization loss: 5.27E-01
Test scatter: [0.4168 0.0836 0.3251 0.55  ], Lowest was [0.4168 0.0835 0.3127 0.5437]
Median for last 10 epochs: [0.5177 0.0905 0.3395 0.5747], Epochs since improvement 0
  7%|▋         | 35/500 [21:44<4:37:31, 35.81s/it]  7%|▋         | 36/500 [22:30<5:00:20, 38.84s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 1.18E+06, Train scatter: [0.5258 0.0799 0.3023 0.5421]
L1 regularization loss: 1.81E+00, L2 regularization loss: 5.42E-01
Test scatter: [0.5294 0.0809 0.3065 0.5406], Lowest was [0.4168 0.0809 0.3065 0.5406]
Median for last 10 epochs: [0.5177 0.0836 0.3251 0.55  ], Epochs since improvement 0
  7%|▋         | 37/500 [22:59<4:36:18, 35.81s/it]  8%|▊         | 38/500 [23:45<4:59:05, 38.84s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 1.25E+06, Train scatter: [0.5353 0.0799 0.3128 0.5546]
L1 regularization loss: 1.84E+00, L2 regularization loss: 5.60E-01
Test scatter: [0.5288 0.0813 0.3149 0.5471], Lowest was [0.4168 0.0809 0.3065 0.5406]
Median for last 10 epochs: [0.5288 0.0835 0.3149 0.5471], Epochs since improvement 2
  8%|▊         | 39/500 [24:13<4:33:29, 35.59s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 1.25E+06, Train scatter: [0.4297 0.0817 0.3456 0.5542]
L1 regularization loss: 1.88E+00, L2 regularization loss: 5.80E-01
Test scatter: [0.4477 0.0836 0.3482 0.5561], Lowest was [0.4168 0.0809 0.3065 0.5406]
Median for last 10 epochs: [0.4593 0.0835 0.3149 0.5471], Epochs since improvement 4
  8%|▊         | 40/500 [25:05<5:11:34, 40.64s/it]  8%|▊         | 41/500 [25:33<4:41:19, 36.78s/it]  8%|▊         | 42/500 [26:19<5:02:30, 39.63s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.33E+06, Train scatter: [0.3439 0.0797 0.3296 0.5351]
L1 regularization loss: 1.91E+00, L2 regularization loss: 6.02E-01
Test scatter: [0.3832 0.0817 0.3261 0.534 ], Lowest was [0.3832 0.0809 0.3065 0.534 ]
Median for last 10 epochs: [0.4477 0.0817 0.3251 0.5471], Epochs since improvement 0
  9%|▊         | 43/500 [26:47<4:36:16, 36.27s/it]  9%|▉         | 44/500 [27:34<4:59:28, 39.41s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 1.09E+06, Train scatter: [0.3762 0.0803 0.2976 0.5211]
L1 regularization loss: 1.94E+00, L2 regularization loss: 6.26E-01
Test scatter: [0.6675 0.0817 0.3042 0.521 ], Lowest was [0.3832 0.0809 0.3042 0.521 ]
Median for last 10 epochs: [0.5288 0.0817 0.3149 0.5406], Epochs since improvement 0
  9%|▉         | 45/500 [28:02<4:33:15, 36.03s/it]  9%|▉         | 46/500 [28:49<4:57:00, 39.25s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 1.08E+06, Train scatter: [0.383  0.0772 0.3018 0.5286]
L1 regularization loss: 1.97E+00, L2 regularization loss: 6.49E-01
Test scatter: [0.4031 0.078  0.3093 0.5273], Lowest was [0.3832 0.078  0.3042 0.521 ]
Median for last 10 epochs: [0.4477 0.0817 0.3149 0.534 ], Epochs since improvement 0
  9%|▉         | 47/500 [29:17<4:31:01, 35.90s/it] 10%|▉         | 48/500 [30:03<4:53:37, 38.98s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 1.07E+06, Train scatter: [0.3347 0.0807 0.3429 0.5408]
L1 regularization loss: 2.00E+00, L2 regularization loss: 6.71E-01
Test scatter: [0.3809 0.0823 0.3494 0.5434], Lowest was [0.3809 0.078  0.3042 0.521 ]
Median for last 10 epochs: [0.4031 0.0817 0.3261 0.534 ], Epochs since improvement 0
 10%|▉         | 49/500 [30:32<4:29:49, 35.90s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 9.88E+05, Train scatter: [0.3329 0.0759 0.2951 0.5123]
L1 regularization loss: 2.06E+00, L2 regularization loss: 7.01E-01
Test scatter: [0.3524 0.0765 0.3023 0.5106], Lowest was [0.3524 0.0765 0.3023 0.5106]
Median for last 10 epochs: [0.3832 0.0817 0.3093 0.5273], Epochs since improvement 0
 10%|█         | 50/500 [31:24<5:05:30, 40.73s/it] 10%|█         | 51/500 [31:52<4:37:10, 37.04s/it] 10%|█         | 52/500 [32:40<4:59:50, 40.16s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 9.25E+05, Train scatter: [0.3922 0.0773 0.3191 0.5328]
L1 regularization loss: 2.09E+00, L2 regularization loss: 7.25E-01
Test scatter: [0.4102 0.0779 0.3274 0.5342], Lowest was [0.3524 0.0765 0.3023 0.5106]
Median for last 10 epochs: [0.4031 0.078  0.3093 0.5273], Epochs since improvement 2
 11%|█         | 53/500 [33:08<4:32:29, 36.58s/it] 11%|█         | 54/500 [33:55<4:54:50, 39.67s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 9.19E+05, Train scatter: [0.3046 0.0742 0.2726 0.5014]
L1 regularization loss: 2.12E+00, L2 regularization loss: 7.46E-01
Test scatter: [0.3171 0.0757 0.2827 0.5089], Lowest was [0.3171 0.0757 0.2827 0.5089]
Median for last 10 epochs: [0.3809 0.0779 0.3093 0.5273], Epochs since improvement 0
 11%|█         | 55/500 [34:23<4:29:04, 36.28s/it] 11%|█         | 56/500 [35:11<4:52:53, 39.58s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 8.44E+05, Train scatter: [0.3013 0.0747 0.2974 0.5076]
L1 regularization loss: 2.15E+00, L2 regularization loss: 7.71E-01
Test scatter: [0.3438 0.076  0.3062 0.5069], Lowest was [0.3171 0.0757 0.2827 0.5069]
Median for last 10 epochs: [0.3524 0.0765 0.3062 0.5106], Epochs since improvement 0
 11%|█▏        | 57/500 [35:39<4:27:06, 36.18s/it] 12%|█▏        | 58/500 [36:27<4:52:48, 39.75s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 9.96E+05, Train scatter: [0.2903 0.0745 0.2848 0.5073]
L1 regularization loss: 2.19E+00, L2 regularization loss: 8.00E-01
Test scatter: [0.3119 0.0763 0.2947 0.5161], Lowest was [0.3119 0.0757 0.2827 0.5069]
Median for last 10 epochs: [0.3438 0.0763 0.3023 0.5106], Epochs since improvement 0
 12%|█▏        | 59/500 [36:55<4:27:02, 36.33s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 8.84E+05, Train scatter: [0.398  0.0807 0.2899 0.5388]
L1 regularization loss: 2.20E+00, L2 regularization loss: 8.20E-01
Test scatter: [0.4116 0.0818 0.2981 0.5445], Lowest was [0.3119 0.0757 0.2827 0.5069]
Median for last 10 epochs: [0.3438 0.0763 0.2981 0.5161], Epochs since improvement 2
 12%|█▏        | 60/500 [37:47<5:01:10, 41.07s/it] 12%|█▏        | 61/500 [38:15<4:30:50, 37.02s/it] 12%|█▏        | 62/500 [39:03<4:54:03, 40.28s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 7.24E+05, Train scatter: [0.3045 0.0723 0.2793 0.4996]
L1 regularization loss: 2.21E+00, L2 regularization loss: 8.41E-01
Test scatter: [0.3147 0.0737 0.2812 0.5005], Lowest was [0.3119 0.0737 0.2812 0.5005]
Median for last 10 epochs: [0.3171 0.076  0.2947 0.5089], Epochs since improvement 0
 13%|█▎        | 63/500 [39:30<4:25:05, 36.40s/it] 13%|█▎        | 64/500 [40:17<4:47:58, 39.63s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 6.90E+05, Train scatter: [0.3092 0.0715 0.2925 0.5204]
L1 regularization loss: 2.23E+00, L2 regularization loss: 8.62E-01
Test scatter: [0.3229 0.0734 0.2998 0.5232], Lowest was [0.3119 0.0734 0.2812 0.5005]
Median for last 10 epochs: [0.3229 0.076  0.2981 0.5161], Epochs since improvement 0
 13%|█▎        | 65/500 [40:46<4:23:14, 36.31s/it] 13%|█▎        | 66/500 [41:33<4:45:32, 39.48s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.05E+06, Train scatter: [0.2914 0.0712 0.2859 0.505 ]
L1 regularization loss: 2.25E+00, L2 regularization loss: 8.84E-01
Test scatter: [0.3058 0.0724 0.2941 0.5144], Lowest was [0.3058 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.3147 0.0737 0.2947 0.5161], Epochs since improvement 0
 13%|█▎        | 67/500 [42:01<4:20:33, 36.11s/it] 14%|█▎        | 68/500 [42:50<4:47:06, 39.88s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.29E+06, Train scatter: [0.3367 0.0865 0.3912 0.558 ]
L1 regularization loss: 2.35E+00, L2 regularization loss: 9.64E-01
Test scatter: [0.3468 0.0885 0.3986 0.5677], Lowest was [0.3058 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.3229 0.0737 0.2981 0.5232], Epochs since improvement 2
 14%|█▍        | 69/500 [43:17<4:20:01, 36.20s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.09E+06, Train scatter: [0.3359 0.0794 0.3787 0.5619]
L1 regularization loss: 2.43E+00, L2 regularization loss: 1.02E+00
Test scatter: [0.3422 0.0819 0.3961 0.5649], Lowest was [0.3058 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.3229 0.0737 0.2998 0.5232], Epochs since improvement 4
 14%|█▍        | 70/500 [44:10<4:54:58, 41.16s/it] 14%|█▍        | 71/500 [44:38<4:25:05, 37.08s/it] 14%|█▍        | 72/500 [45:25<4:46:03, 40.10s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 8.23E+05, Train scatter: [0.3546 0.076  0.3181 0.5246]
L1 regularization loss: 2.43E+00, L2 regularization loss: 1.04E+00
Test scatter: [0.3627 0.0776 0.3266 0.5307], Lowest was [0.3058 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.3422 0.0776 0.3266 0.5307], Epochs since improvement 6
 15%|█▍        | 73/500 [45:53<4:20:23, 36.59s/it] 15%|█▍        | 74/500 [46:41<4:43:21, 39.91s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 7.86E+05, Train scatter: [0.2731 0.0749 0.3092 0.4985]
L1 regularization loss: 2.48E+00, L2 regularization loss: 1.07E+00
Test scatter: [0.2838 0.0765 0.3133 0.5047], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.3422 0.0776 0.3266 0.5307], Epochs since improvement 0
 15%|█▌        | 75/500 [47:08<4:16:24, 36.20s/it] 15%|█▌        | 76/500 [47:56<4:39:56, 39.61s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 5.56E+05, Train scatter: [0.2878 0.0765 0.3094 0.5009]
L1 regularization loss: 2.48E+00, L2 regularization loss: 1.09E+00
Test scatter: [0.2926 0.0802 0.3251 0.5058], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.3422 0.0802 0.3266 0.5307], Epochs since improvement 2
 15%|█▌        | 77/500 [48:24<4:15:03, 36.18s/it] 16%|█▌        | 78/500 [49:12<4:39:57, 39.80s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 1.73E+10, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.94E+00, L2 regularization loss: 2.61E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.3422 0.0802 0.3266 0.5307], Epochs since improvement 4
 16%|█▌        | 79/500 [49:41<4:15:22, 36.39s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 7.00E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.99E+00, L2 regularization loss: 2.74E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.3627 0.0802 0.3266 0.5307], Epochs since improvement 6
 16%|█▌        | 80/500 [50:34<4:49:13, 41.32s/it] 16%|█▌        | 81/500 [51:02<4:20:24, 37.29s/it] 16%|█▋        | 82/500 [51:49<4:40:56, 40.33s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 5.45E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.99E+00, L2 regularization loss: 2.76E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 8
 17%|█▋        | 83/500 [52:17<4:14:03, 36.56s/it] 17%|█▋        | 84/500 [53:03<4:33:11, 39.40s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 4.57E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.99E+00, L2 regularization loss: 2.77E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 10
 17%|█▋        | 85/500 [53:31<4:09:28, 36.07s/it] 17%|█▋        | 86/500 [54:18<4:31:21, 39.33s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 3.87E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.99E+00, L2 regularization loss: 2.79E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 12
 17%|█▋        | 87/500 [54:46<4:07:48, 36.00s/it] 18%|█▊        | 88/500 [55:33<4:28:58, 39.17s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 3.34E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.99E+00, L2 regularization loss: 2.80E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 14
 18%|█▊        | 89/500 [56:00<4:04:02, 35.63s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 2.97E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.99E+00, L2 regularization loss: 2.82E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 16
 18%|█▊        | 90/500 [56:53<4:37:45, 40.65s/it] 18%|█▊        | 91/500 [57:20<4:10:20, 36.73s/it] 18%|█▊        | 92/500 [58:07<4:30:25, 39.77s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 2.70E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.98E+00, L2 regularization loss: 2.83E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 18
 19%|█▊        | 93/500 [58:35<4:06:08, 36.29s/it] 19%|█▉        | 94/500 [59:22<4:27:06, 39.47s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 2.51E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.98E+00, L2 regularization loss: 2.84E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 20
 19%|█▉        | 95/500 [59:50<4:02:05, 35.87s/it] 19%|█▉        | 95/500 [1:00:36<4:18:22, 38.28s/it]
Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.37E+06, Train scatter: [0.9352 0.1728 0.5441 0.9954]
L1 regularization loss: 5.98E+00, L2 regularization loss: 2.86E+00
Test scatter: [0.9196 0.169  0.5355 0.985 ], Lowest was [0.2838 0.0724 0.2812 0.5005]
Median for last 10 epochs: [0.9196 0.169  0.5355 0.985 ], Epochs since improvement 22
Exited after 96 epochs due to early stopping
3636.44 seconds spent training, 7.273 seconds per epoch. Processed 9575 trees per second
[0.9196029  0.16899763 0.5354738  0.98498136]
{'epoch_exit': 95, 'scatter_m_star': 0.9196029, 'lowest_m_star': 0.2837689, 'last20_m_star': 0.91962105, 'last10_m_star': 0.91962564, 'scatter_v_disk': 0.16899763, 'lowest_v_disk': 0.07238197, 'last20_v_disk': 0.16900142, 'last10_v_disk': 0.16900182, 'scatter_m_cold': 0.5354738, 'lowest_m_cold': 0.28116643, 'last20_m_cold': 0.53548896, 'last10_m_cold': 0.535489, 'scatter_sfr_100': 0.98498136, 'lowest_sfr_100': 0.5005163, 'last20_sfr_100': 0.9850111, 'last10_sfr_100': 0.9850105}
Finished 1/1
Exited training after None epochs
Experiment 2 done: 2 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_gqecrw
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:48<6:42:34, 48.41s/it]  0%|          | 2/500 [01:59<8:30:44, 61.54s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 2.29E+07, Train scatter: [0.9352 0.1371 0.5441 0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.83E-01
Test scatter: [0.9196 0.1341 0.5355 0.9851], Lowest was [0.9196 0.1341 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1341 0.5355 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:47<7:39:17, 55.45s/it]  1%|          | 4/500 [03:59<8:31:28, 61.87s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 1.49E+07, Train scatter: [0.9327 0.1003 0.544  0.9951]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.11E-01
Test scatter: [0.917  0.0991 0.5354 0.9848], Lowest was [0.917  0.0991 0.5354 0.9848]
Median for last 10 epochs: [0.917  0.0991 0.5354 0.9848], Epochs since improvement 0
  1%|          | 5/500 [04:46<7:48:20, 56.77s/it]  1%|          | 6/500 [05:57<8:26:08, 61.47s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.10E+06, Train scatter: [0.7549 0.0907 0.5439 0.6603]
L1 regularization loss: 2.05E+00, L2 regularization loss: 4.53E-01
Test scatter: [0.7439 0.0906 0.5353 0.654 ], Lowest was [0.7439 0.0906 0.5353 0.654 ]
Median for last 10 epochs: [0.7439 0.0906 0.5353 0.654 ], Epochs since improvement 0
  1%|▏         | 7/500 [06:47<7:53:32, 57.63s/it]  2%|▏         | 8/500 [08:00<8:33:18, 62.60s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 5.49E+06, Train scatter: [0.4961 0.0781 0.5438 0.5644]
L1 regularization loss: 2.06E+00, L2 regularization loss: 4.66E-01
Test scatter: [0.4936 0.0787 0.5353 0.5596], Lowest was [0.4936 0.0787 0.5353 0.5596]
Median for last 10 epochs: [0.6188 0.0846 0.5353 0.6068], Epochs since improvement 0
  2%|▏         | 9/500 [08:47<7:53:06, 57.81s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 4.15E+06, Train scatter: [0.4252 0.0743 0.5438 0.539 ]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.74E-01
Test scatter: [0.4295 0.0742 0.5352 0.5342], Lowest was [0.4295 0.0742 0.5352 0.5342]
Median for last 10 epochs: [0.4936 0.0787 0.5353 0.5596], Epochs since improvement 0
  2%|▏         | 10/500 [10:07<8:47:03, 64.54s/it]  2%|▏         | 11/500 [10:55<8:06:13, 59.66s/it]  2%|▏         | 12/500 [12:07<8:34:49, 63.30s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 3.69E+06, Train scatter: [0.2989 0.0719 0.5437 0.5241]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.80E-01
Test scatter: [0.3053 0.0716 0.5352 0.5187], Lowest was [0.3053 0.0716 0.5352 0.5187]
Median for last 10 epochs: [0.4936 0.0787 0.5353 0.5596], Epochs since improvement 0
  3%|▎         | 13/500 [12:56<7:57:41, 58.85s/it]  3%|▎         | 14/500 [14:08<8:29:38, 62.92s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 3.50E+06, Train scatter: [0.2547 0.0699 0.5437 0.513 ]
L1 regularization loss: 2.08E+00, L2 regularization loss: 4.85E-01
Test scatter: [0.2612 0.07   0.5351 0.5076], Lowest was [0.2612 0.07   0.5351 0.5076]
Median for last 10 epochs: [0.4295 0.0742 0.5352 0.5342], Epochs since improvement 0
  3%|▎         | 15/500 [14:57<7:55:09, 58.78s/it]  3%|▎         | 16/500 [16:10<8:27:25, 62.90s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 3.40E+06, Train scatter: [0.2082 0.0683 0.5436 0.5096]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.89E-01
Test scatter: [0.2153 0.0684 0.5351 0.504 ], Lowest was [0.2153 0.0684 0.5351 0.504 ]
Median for last 10 epochs: [0.3053 0.0716 0.5352 0.5187], Epochs since improvement 0
  3%|▎         | 17/500 [16:59<7:52:39, 58.71s/it]  4%|▎         | 18/500 [18:11<8:24:51, 62.85s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 3.26E+06, Train scatter: [0.2084 0.0673 0.5435 0.5071]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.92E-01
Test scatter: [0.2167 0.067  0.535  0.4998], Lowest was [0.2153 0.067  0.535  0.4998]
Median for last 10 epochs: [0.2612 0.07   0.5351 0.5076], Epochs since improvement 0
  4%|▍         | 19/500 [19:00<7:51:14, 58.78s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.20E+06, Train scatter: [0.2115 0.0692 0.5434 0.5177]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.96E-01
Test scatter: [0.219  0.0688 0.5348 0.5099], Lowest was [0.2153 0.067  0.5348 0.4998]
Median for last 10 epochs: [0.219  0.0688 0.5351 0.5076], Epochs since improvement 0
  4%|▍         | 20/500 [20:20<8:39:32, 64.94s/it]  4%|▍         | 21/500 [21:08<7:58:05, 59.89s/it]  4%|▍         | 22/500 [22:20<8:27:30, 63.70s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.06E+06, Train scatter: [0.2182 0.0641 0.5435 0.4974]
L1 regularization loss: 2.12E+00, L2 regularization loss: 5.00E-01
Test scatter: [0.2211 0.0646 0.5349 0.4921], Lowest was [0.2153 0.0646 0.5348 0.4921]
Median for last 10 epochs: [0.219  0.0684 0.535  0.504 ], Epochs since improvement 0
  5%|▍         | 23/500 [23:10<7:52:46, 59.47s/it]  5%|▍         | 24/500 [24:23<8:25:08, 63.67s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 2.94E+06, Train scatter: [0.215  0.0643 0.5433 0.5147]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.06E-01
Test scatter: [0.2261 0.065  0.5348 0.5121], Lowest was [0.2153 0.0646 0.5348 0.4921]
Median for last 10 epochs: [0.219  0.067  0.5349 0.504 ], Epochs since improvement 0
  5%|▌         | 25/500 [25:11<7:46:08, 58.88s/it]  5%|▌         | 26/500 [26:23<8:15:33, 62.73s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 2.89E+06, Train scatter: [0.1956 0.0632 0.5432 0.4953]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.11E-01
Test scatter: [0.1987 0.063  0.5347 0.4908], Lowest was [0.1987 0.063  0.5347 0.4908]
Median for last 10 epochs: [0.219  0.065  0.5348 0.4998], Epochs since improvement 0
  5%|▌         | 27/500 [27:10<7:38:56, 58.22s/it]  6%|▌         | 28/500 [28:24<8:13:55, 62.79s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 2.85E+06, Train scatter: [0.1927 0.0618 0.5431 0.4937]
L1 regularization loss: 2.16E+00, L2 regularization loss: 5.17E-01
Test scatter: [0.2016 0.062  0.5346 0.4885], Lowest was [0.1987 0.062  0.5346 0.4885]
Median for last 10 epochs: [0.219  0.0646 0.5348 0.4921], Epochs since improvement 0
  6%|▌         | 29/500 [29:14<7:42:16, 58.89s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.83E+06, Train scatter: [0.2014 0.0621 0.5431 0.5069]
L1 regularization loss: 2.18E+00, L2 regularization loss: 5.23E-01
Test scatter: [0.2083 0.0622 0.5345 0.5017], Lowest was [0.1987 0.062  0.5345 0.4885]
Median for last 10 epochs: [0.2083 0.063  0.5347 0.4921], Epochs since improvement 0
  6%|▌         | 30/500 [30:31<8:25:06, 64.48s/it]  6%|▌         | 31/500 [31:20<7:46:14, 59.65s/it]  6%|▋         | 32/500 [32:33<8:16:57, 63.71s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.84E+06, Train scatter: [0.3672 0.0611 0.5429 0.4948]
L1 regularization loss: 2.20E+00, L2 regularization loss: 5.32E-01
Test scatter: [0.36   0.0617 0.5343 0.492 ], Lowest was [0.1987 0.0617 0.5343 0.4885]
Median for last 10 epochs: [0.2083 0.0622 0.5346 0.492 ], Epochs since improvement 0
  7%|▋         | 33/500 [33:20<7:38:21, 58.89s/it]  7%|▋         | 34/500 [34:34<8:10:41, 63.18s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.81E+06, Train scatter: [0.2423 0.0634 0.5428 0.5055]
L1 regularization loss: 2.22E+00, L2 regularization loss: 5.40E-01
Test scatter: [0.2445 0.0635 0.5343 0.4981], Lowest was [0.1987 0.0617 0.5343 0.4885]
Median for last 10 epochs: [0.2083 0.0622 0.5345 0.492 ], Epochs since improvement 0
  7%|▋         | 35/500 [35:23<7:37:59, 59.10s/it]  7%|▋         | 36/500 [36:35<8:06:52, 62.96s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.82E+06, Train scatter: [0.4138 0.1064 0.543  0.5629]
L1 regularization loss: 2.25E+00, L2 regularization loss: 5.52E-01
Test scatter: [0.4064 0.1045 0.5344 0.5588], Lowest was [0.1987 0.0617 0.5343 0.4885]
Median for last 10 epochs: [0.2445 0.0622 0.5344 0.4981], Epochs since improvement 2
  7%|▋         | 37/500 [37:23<7:31:06, 58.46s/it]  8%|▊         | 38/500 [38:37<8:05:42, 63.08s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.80E+06, Train scatter: [0.2066 0.068  0.5426 0.5064]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.61E-01
Test scatter: [0.2123 0.0672 0.5341 0.4999], Lowest was [0.1987 0.0617 0.5341 0.4885]
Median for last 10 epochs: [0.2445 0.0635 0.5343 0.4999], Epochs since improvement 0
  8%|▊         | 39/500 [39:26<7:33:10, 58.98s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.80E+06, Train scatter: [0.2367 0.065  0.5423 0.4998]
L1 regularization loss: 2.29E+00, L2 regularization loss: 5.73E-01
Test scatter: [0.2425 0.0657 0.5338 0.4984], Lowest was [0.1987 0.0617 0.5338 0.4885]
Median for last 10 epochs: [0.2445 0.0657 0.5343 0.4984], Epochs since improvement 0
  8%|▊         | 40/500 [40:46<8:18:52, 65.07s/it]  8%|▊         | 41/500 [41:33<7:36:15, 59.64s/it]  8%|▊         | 42/500 [42:45<8:04:32, 63.48s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.85E+06, Train scatter: [0.6667 0.1688 0.5433 0.9429]
L1 regularization loss: 2.45E+00, L2 regularization loss: 6.20E-01
Test scatter: [0.6597 0.1655 0.5347 0.9333], Lowest was [0.1987 0.0617 0.5338 0.4885]
Median for last 10 epochs: [0.2445 0.0672 0.5343 0.4999], Epochs since improvement 2
  9%|▊         | 43/500 [43:33<7:28:58, 58.95s/it]  9%|▉         | 44/500 [44:46<7:58:38, 62.98s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.83E+06, Train scatter: [0.6257 0.0784 0.542  0.5405]
L1 regularization loss: 2.47E+00, L2 regularization loss: 6.48E-01
Test scatter: [0.6105 0.0775 0.5334 0.5359], Lowest was [0.1987 0.0617 0.5334 0.4885]
Median for last 10 epochs: [0.4064 0.0775 0.5341 0.5359], Epochs since improvement 0
  9%|▉         | 45/500 [45:33<7:21:44, 58.25s/it]  9%|▉         | 46/500 [46:46<7:53:12, 62.54s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.82E+06, Train scatter: [0.4637 0.0765 0.5416 0.5142]
L1 regularization loss: 2.50E+00, L2 regularization loss: 6.70E-01
Test scatter: [0.4521 0.0755 0.5332 0.5089], Lowest was [0.1987 0.0617 0.5332 0.4885]
Median for last 10 epochs: [0.4521 0.0755 0.5338 0.5089], Epochs since improvement 0
  9%|▉         | 47/500 [47:35<7:23:18, 58.72s/it] 10%|▉         | 48/500 [48:47<7:51:27, 62.58s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.76E+06, Train scatter: [0.4452 0.0687 0.5383 0.5161]
L1 regularization loss: 2.51E+00, L2 regularization loss: 6.93E-01
Test scatter: [0.4338 0.0684 0.5299 0.5119], Lowest was [0.1987 0.0617 0.5299 0.4885]
Median for last 10 epochs: [0.4521 0.0755 0.5334 0.5119], Epochs since improvement 0
 10%|▉         | 49/500 [49:35<7:16:51, 58.12s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 2.70E+06, Train scatter: [0.2763 0.0745 0.5352 0.5043]
L1 regularization loss: 2.57E+00, L2 regularization loss: 7.33E-01
Test scatter: [0.2765 0.0741 0.527  0.4973], Lowest was [0.1987 0.0617 0.527  0.4885]
Median for last 10 epochs: [0.4521 0.0755 0.5332 0.5119], Epochs since improvement 0
 10%|█         | 50/500 [50:55<8:05:03, 64.67s/it] 10%|█         | 51/500 [51:42<7:25:26, 59.53s/it] 10%|█         | 52/500 [52:55<7:54:54, 63.60s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.01E+06, Train scatter: [0.9035 0.1593 0.544  0.8601]
L1 regularization loss: 2.72E+00, L2 regularization loss: 8.08E-01
Test scatter: [0.8884 0.1562 0.5354 0.8544], Lowest was [0.1987 0.0617 0.527  0.4885]
Median for last 10 epochs: [0.4521 0.0755 0.5332 0.5119], Epochs since improvement 2
 11%|█         | 53/500 [53:43<7:17:21, 58.70s/it] 11%|█         | 54/500 [54:55<7:46:56, 62.82s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 2.74E+06, Train scatter: [0.516  0.1047 0.5387 0.6343]
L1 regularization loss: 2.73E+00, L2 regularization loss: 8.74E-01
Test scatter: [0.5136 0.1038 0.5303 0.6298], Lowest was [0.1987 0.0617 0.527  0.4885]
Median for last 10 epochs: [0.4521 0.0755 0.5303 0.5119], Epochs since improvement 4
 11%|█         | 55/500 [55:42<7:11:41, 58.21s/it] 11%|█         | 56/500 [56:55<7:41:24, 62.35s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 2.64E+06, Train scatter: [0.3131 0.0933 0.5325 0.5235]
L1 regularization loss: 2.73E+00, L2 regularization loss: 9.14E-01
Test scatter: [0.3248 0.0937 0.5245 0.5222], Lowest was [0.1987 0.0617 0.5245 0.4885]
Median for last 10 epochs: [0.4338 0.0937 0.5299 0.5222], Epochs since improvement 0
 11%|█▏        | 57/500 [57:43<7:09:48, 58.21s/it] 12%|█▏        | 58/500 [58:55<7:40:12, 62.47s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 2.55E+06, Train scatter: [0.4387 0.0955 0.5283 0.5245]
L1 regularization loss: 2.74E+00, L2 regularization loss: 9.54E-01
Test scatter: [0.428  0.0961 0.5202 0.5272], Lowest was [0.1987 0.0617 0.5202 0.4885]
Median for last 10 epochs: [0.428  0.0961 0.527  0.5272], Epochs since improvement 0
 12%|█▏        | 59/500 [59:44<7:08:55, 58.36s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.15E+06, Train scatter: [0.5237 0.1039 0.544  0.6391]
L1 regularization loss: 2.94E+00, L2 regularization loss: 1.10E+00
Test scatter: [0.5231 0.1045 0.5354 0.6446], Lowest was [0.1987 0.0617 0.5202 0.4885]
Median for last 10 epochs: [0.5136 0.1038 0.5303 0.6298], Epochs since improvement 2
 12%|█▏        | 60/500 [1:01:04<7:55:31, 64.85s/it] 12%|█▏        | 61/500 [1:01:53<7:19:22, 60.05s/it] 12%|█▏        | 62/500 [1:03:06<7:46:12, 63.86s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.94E+06, Train scatter: [0.4259 0.0734 0.5436 0.5362]
L1 regularization loss: 2.94E+00, L2 regularization loss: 1.13E+00
Test scatter: [0.421  0.0763 0.535  0.5433], Lowest was [0.1987 0.0617 0.5202 0.4885]
Median for last 10 epochs: [0.428  0.0961 0.5303 0.5433], Epochs since improvement 4
 13%|█▎        | 63/500 [1:03:54<7:11:11, 59.20s/it] 13%|█▎        | 64/500 [1:05:06<7:37:10, 62.91s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.70E+06, Train scatter: [0.4377 0.0691 0.5318 0.5146]
L1 regularization loss: 3.01E+00, L2 regularization loss: 1.22E+00
Test scatter: [0.4265 0.0708 0.5238 0.5155], Lowest was [0.1987 0.0617 0.5202 0.4885]
Median for last 10 epochs: [0.4265 0.0937 0.5245 0.5272], Epochs since improvement 6
 13%|█▎        | 65/500 [1:05:54<7:04:26, 58.54s/it] 13%|█▎        | 66/500 [1:07:06<7:32:18, 62.53s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 1.36E+07, Train scatter: [0.9532 0.138  0.5441 1.0246]
L1 regularization loss: 4.64E+00, L2 regularization loss: 2.25E+00
Test scatter: [0.9369 0.1396 0.5355 1.013 ], Lowest was [0.1987 0.0617 0.5202 0.4885]
Median for last 10 epochs: [0.428  0.0961 0.535  0.5433], Epochs since improvement 8
 13%|█▎        | 67/500 [1:07:55<7:01:05, 58.35s/it] 14%|█▎        | 68/500 [1:09:07<7:29:43, 62.46s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 4.53E+06, Train scatter: [0.7361 0.1354 0.5441 1.0243]
L1 regularization loss: 4.74E+00, L2 regularization loss: 2.62E+00
Test scatter: [0.7323 0.1345 0.5355 1.0129], Lowest was [0.1987 0.0617 0.5202 0.4885]
Median for last 10 epochs: [0.5231 0.1045 0.5354 0.6446], Epochs since improvement 10
 14%|█▍        | 69/500 [1:09:55<6:59:29, 58.40s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.43E+06, Train scatter: [0.6563 0.1234 0.5441 1.0179]
L1 regularization loss: 4.74E+00, L2 regularization loss: 2.78E+00
Test scatter: [0.6582 0.1219 0.5355 1.0071], Lowest was [0.1987 0.0617 0.5202 0.4885]
Median for last 10 epochs: [0.6582 0.1219 0.5355 1.0071], Epochs since improvement 12
 14%|█▍        | 70/500 [1:11:14<7:41:29, 64.39s/it] 14%|█▍        | 71/500 [1:12:04<7:08:55, 59.99s/it] 14%|█▍        | 72/500 [1:13:15<7:32:39, 63.46s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.24E+06, Train scatter: [0.8736 0.1152 0.544  1.0162]
L1 regularization loss: 4.74E+00, L2 regularization loss: 2.86E+00
Test scatter: [0.8593 0.1153 0.5354 1.0049], Lowest was [0.1987 0.0617 0.5202 0.4885]
Median for last 10 epochs: [0.7323 0.1219 0.5355 1.0071], Epochs since improvement 14
 15%|█▍        | 73/500 [1:14:05<7:01:58, 59.29s/it] 15%|█▍        | 74/500 [1:15:19<7:32:41, 63.76s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.10E+06, Train scatter: [0.5425 0.1    0.5423 1.0087]
L1 regularization loss: 4.73E+00, L2 regularization loss: 2.93E+00
Test scatter: [0.5286 0.0988 0.5338 0.9974], Lowest was [0.1987 0.0617 0.5202 0.4885]
Median for last 10 epochs: [0.7323 0.1219 0.5355 1.0071], Epochs since improvement 16
 15%|█▌        | 75/500 [1:16:07<6:57:32, 58.95s/it] 15%|█▌        | 76/500 [1:17:20<7:27:42, 63.36s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 2.97E+06, Train scatter: [0.4691 0.0912 0.5321 0.9969]
L1 regularization loss: 4.72E+00, L2 regularization loss: 3.01E+00
Test scatter: [0.4627 0.0905 0.524  0.9862], Lowest was [0.1987 0.0617 0.5202 0.4885]
Median for last 10 epochs: [0.6582 0.1153 0.5354 1.0049], Epochs since improvement 18
 15%|█▌        | 77/500 [1:18:07<6:51:44, 58.40s/it] 16%|█▌        | 78/500 [1:19:20<7:20:26, 62.62s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 2.77E+06, Train scatter: [0.543  0.0919 0.5179 0.9888]
L1 regularization loss: 4.70E+00, L2 regularization loss: 3.08E+00
Test scatter: [0.517  0.0911 0.51   0.9781], Lowest was [0.1987 0.0617 0.51   0.4885]
Median for last 10 epochs: [0.5286 0.0988 0.5338 0.9974], Epochs since improvement 0
 16%|█▌        | 79/500 [1:20:07<6:48:00, 58.15s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 2.83E+06, Train scatter: [0.6283 0.1371 0.525  0.9828]
L1 regularization loss: 4.71E+00, L2 regularization loss: 3.19E+00
Test scatter: [0.628  0.1328 0.5175 0.9739], Lowest was [0.1987 0.0617 0.51   0.4885]
Median for last 10 epochs: [0.5286 0.0988 0.524  0.9862], Epochs since improvement 2
 16%|█▌        | 80/500 [1:21:25<7:29:05, 64.15s/it] 16%|█▌        | 81/500 [1:22:13<6:52:18, 59.04s/it] 16%|█▋        | 82/500 [1:23:26<7:20:46, 63.27s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 1.62E+06, Train scatter: [0.5468 0.0898 0.3905 0.9493]
L1 regularization loss: 4.77E+00, L2 regularization loss: 3.38E+00
Test scatter: [0.5387 0.089  0.3918 0.9416], Lowest was [0.1987 0.0617 0.3918 0.4885]
Median for last 10 epochs: [0.5286 0.0911 0.5175 0.9781], Epochs since improvement 0
 17%|█▋        | 83/500 [1:24:13<6:47:10, 58.59s/it] 17%|█▋        | 84/500 [1:25:24<7:11:43, 62.27s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 1.28E+06, Train scatter: [0.5242 0.0816 0.3629 0.9175]
L1 regularization loss: 4.81E+00, L2 regularization loss: 3.61E+00
Test scatter: [0.5276 0.0797 0.3648 0.91  ], Lowest was [0.1987 0.0617 0.3648 0.4885]
Median for last 10 epochs: [0.5276 0.0905 0.51   0.9739], Epochs since improvement 0
 17%|█▋        | 85/500 [1:26:14<6:44:48, 58.53s/it] 17%|█▋        | 86/500 [1:27:24<7:08:36, 62.12s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 1.14E+06, Train scatter: [0.4564 0.0782 0.367  0.7521]
L1 regularization loss: 4.98E+00, L2 regularization loss: 3.99E+00
Test scatter: [0.443  0.0815 0.3684 0.7625], Lowest was [0.1987 0.0617 0.3648 0.4885]
Median for last 10 epochs: [0.5276 0.089  0.3918 0.9416], Epochs since improvement 2
 17%|█▋        | 87/500 [1:28:14<6:42:10, 58.43s/it] 18%|█▊        | 88/500 [1:29:25<7:06:52, 62.17s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 9.50E+05, Train scatter: [0.447  0.0747 0.3352 0.6136]
L1 regularization loss: 5.02E+00, L2 regularization loss: 4.16E+00
Test scatter: [0.4473 0.0714 0.3382 0.6163], Lowest was [0.1987 0.0617 0.3382 0.4885]
Median for last 10 epochs: [0.5276 0.0815 0.3684 0.91  ], Epochs since improvement 0
 18%|█▊        | 89/500 [1:30:13<6:36:58, 57.95s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 8.46E+05, Train scatter: [0.4585 0.0692 0.3242 0.578 ]
L1 regularization loss: 5.07E+00, L2 regularization loss: 4.30E+00
Test scatter: [0.4505 0.0675 0.3304 0.5757], Lowest was [0.1987 0.0617 0.3304 0.4885]
Median for last 10 epochs: [0.4505 0.0797 0.3648 0.7625], Epochs since improvement 0
 18%|█▊        | 90/500 [1:31:32<7:19:26, 64.31s/it] 18%|█▊        | 91/500 [1:32:21<6:46:49, 59.68s/it] 18%|█▊        | 92/500 [1:33:33<7:11:04, 63.39s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 7.52E+05, Train scatter: [0.4445 0.0633 0.311  0.5476]
L1 regularization loss: 5.09E+00, L2 regularization loss: 4.42E+00
Test scatter: [0.4341 0.0632 0.3195 0.544 ], Lowest was [0.1987 0.0617 0.3195 0.4885]
Median for last 10 epochs: [0.4473 0.0714 0.3382 0.6163], Epochs since improvement 0
 19%|█▊        | 93/500 [1:34:23<6:41:15, 59.15s/it] 19%|█▉        | 94/500 [1:35:37<7:11:31, 63.77s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 6.86E+05, Train scatter: [0.439  0.0616 0.3061 0.5411]
L1 regularization loss: 5.08E+00, L2 regularization loss: 4.50E+00
Test scatter: [0.4272 0.0612 0.3138 0.5387], Lowest was [0.1987 0.0612 0.3138 0.4885]
Median for last 10 epochs: [0.443  0.0675 0.3304 0.5757], Epochs since improvement 0
 19%|█▉        | 95/500 [1:36:26<6:39:50, 59.24s/it] 19%|█▉        | 96/500 [1:37:37<7:03:38, 62.92s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 6.56E+05, Train scatter: [0.4194 0.0619 0.3071 0.5369]
L1 regularization loss: 5.11E+00, L2 regularization loss: 4.61E+00
Test scatter: [0.4131 0.0615 0.3086 0.5342], Lowest was [0.1987 0.0612 0.3086 0.4885]
Median for last 10 epochs: [0.4341 0.0632 0.3195 0.544 ], Epochs since improvement 0
 19%|█▉        | 97/500 [1:38:27<6:35:47, 58.93s/it] 20%|█▉        | 98/500 [1:39:39<7:00:56, 62.83s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 5.82E+05, Train scatter: [0.326  0.0618 0.3051 0.5496]
L1 regularization loss: 5.07E+00, L2 regularization loss: 4.67E+00
Test scatter: [0.3095 0.0614 0.3157 0.5404], Lowest was [0.1987 0.0612 0.3086 0.4885]
Median for last 10 epochs: [0.4272 0.0615 0.3157 0.5404], Epochs since improvement 2
 20%|█▉        | 99/500 [1:40:26<6:28:43, 58.16s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 5.55E+05, Train scatter: [0.4568 0.0633 0.3122 0.5458]
L1 regularization loss: 5.07E+00, L2 regularization loss: 4.78E+00
Test scatter: [0.4427 0.0616 0.3153 0.5326], Lowest was [0.1987 0.0612 0.3086 0.4885]
Median for last 10 epochs: [0.4272 0.0615 0.3153 0.5387], Epochs since improvement 4
 20%|██        | 100/500 [1:41:47<7:12:11, 64.83s/it] 20%|██        | 101/500 [1:42:34<6:36:17, 59.59s/it] 20%|██        | 102/500 [1:43:46<6:59:17, 63.21s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 4.83E+05, Train scatter: [0.4232 0.0723 0.2903 0.5371]
L1 regularization loss: 5.06E+00, L2 regularization loss: 4.88E+00
Test scatter: [0.3942 0.0723 0.2995 0.5249], Lowest was [0.1987 0.0612 0.2995 0.4885]
Median for last 10 epochs: [0.4131 0.0615 0.3138 0.5342], Epochs since improvement 0
 21%|██        | 103/500 [1:44:34<6:28:54, 58.78s/it] 21%|██        | 104/500 [1:45:46<6:54:16, 62.77s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 5.05E+05, Train scatter: [0.434  0.0672 0.3472 0.5646]
L1 regularization loss: 5.10E+00, L2 regularization loss: 5.00E+00
Test scatter: [0.4268 0.0654 0.3497 0.5507], Lowest was [0.1987 0.0612 0.2995 0.4885]
Median for last 10 epochs: [0.4131 0.0616 0.3153 0.5342], Epochs since improvement 2
 21%|██        | 105/500 [1:46:33<6:21:56, 58.02s/it] 21%|██        | 106/500 [1:47:45<6:47:47, 62.10s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 4.43E+05, Train scatter: [0.3476 0.0699 0.2891 0.517 ]
L1 regularization loss: 5.09E+00, L2 regularization loss: 5.11E+00
Test scatter: [0.3474 0.0693 0.3005 0.5117], Lowest was [0.1987 0.0612 0.2995 0.4885]
Median for last 10 epochs: [0.3942 0.0654 0.3153 0.5326], Epochs since improvement 4
 21%|██▏       | 107/500 [1:48:33<6:20:22, 58.07s/it] 22%|██▏       | 108/500 [1:49:46<6:48:12, 62.48s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 3.77E+05, Train scatter: [0.2538 0.0549 0.2674 0.5097]
L1 regularization loss: 5.08E+00, L2 regularization loss: 5.20E+00
Test scatter: [0.2608 0.0559 0.2746 0.5081], Lowest was [0.1987 0.0559 0.2746 0.4885]
Median for last 10 epochs: [0.3942 0.0654 0.3005 0.5249], Epochs since improvement 0
 22%|██▏       | 109/500 [1:50:35<6:21:14, 58.50s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 3.55E+05, Train scatter: [0.2388 0.0554 0.2814 0.5078]
L1 regularization loss: 5.10E+00, L2 regularization loss: 5.30E+00
Test scatter: [0.2377 0.0551 0.2866 0.4991], Lowest was [0.1987 0.0551 0.2746 0.4885]
Median for last 10 epochs: [0.3474 0.0654 0.2995 0.5117], Epochs since improvement 0
 22%|██▏       | 110/500 [1:51:53<6:56:47, 64.12s/it] 22%|██▏       | 111/500 [1:52:44<6:31:39, 60.41s/it] 22%|██▏       | 112/500 [1:53:55<6:50:44, 63.52s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 3.32E+05, Train scatter: [0.2598 0.0543 0.2603 0.4955]
L1 regularization loss: 5.13E+00, L2 regularization loss: 5.42E+00
Test scatter: [0.2556 0.0552 0.2682 0.4907], Lowest was [0.1987 0.0551 0.2682 0.4885]
Median for last 10 epochs: [0.2608 0.0559 0.2866 0.5081], Epochs since improvement 0
 23%|██▎       | 113/500 [1:54:43<6:18:55, 58.75s/it] 23%|██▎       | 114/500 [1:55:57<6:48:03, 63.43s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 2.88E+05, Train scatter: [0.2151 0.0514 0.2673 0.4932]
L1 regularization loss: 5.13E+00, L2 regularization loss: 5.51E+00
Test scatter: [0.2184 0.0524 0.278  0.4903], Lowest was [0.1987 0.0524 0.2682 0.4885]
Median for last 10 epochs: [0.2556 0.0552 0.278  0.4991], Epochs since improvement 0
 23%|██▎       | 115/500 [1:56:46<6:18:54, 59.05s/it] 23%|██▎       | 116/500 [1:57:59<6:45:04, 63.29s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 2.42E+05, Train scatter: [0.2193 0.0504 0.2656 0.4955]
L1 regularization loss: 5.15E+00, L2 regularization loss: 5.61E+00
Test scatter: [0.2196 0.0503 0.2699 0.4903], Lowest was [0.1987 0.0503 0.2682 0.4885]
Median for last 10 epochs: [0.2377 0.0551 0.2746 0.4907], Epochs since improvement 0
 23%|██▎       | 117/500 [1:58:48<6:17:03, 59.07s/it] 24%|██▎       | 118/500 [2:00:01<6:42:07, 63.16s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.90E+05, Train scatter: [0.2426 0.0502 0.2654 0.4879]
L1 regularization loss: 5.15E+00, L2 regularization loss: 5.70E+00
Test scatter: [0.2396 0.0511 0.2776 0.4873], Lowest was [0.1987 0.0503 0.2682 0.4873]
Median for last 10 epochs: [0.2377 0.0524 0.2776 0.4903], Epochs since improvement 0
 24%|██▍       | 119/500 [2:00:50<6:14:07, 58.92s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.69E+05, Train scatter: [0.2404 0.0505 0.2509 0.4851]
L1 regularization loss: 5.22E+00, L2 regularization loss: 5.84E+00
Test scatter: [0.2329 0.0502 0.2576 0.4795], Lowest was [0.1987 0.0502 0.2576 0.4795]
Median for last 10 epochs: [0.2329 0.0511 0.2699 0.4903], Epochs since improvement 0
 24%|██▍       | 120/500 [2:02:09<6:50:52, 64.88s/it] 24%|██▍       | 121/500 [2:02:58<6:19:19, 60.05s/it] 24%|██▍       | 122/500 [2:04:10<6:41:07, 63.67s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 9.49E+04, Train scatter: [0.2597 0.0519 0.2634 0.4688]
L1 regularization loss: 5.26E+00, L2 regularization loss: 5.96E+00
Test scatter: [0.2481 0.0507 0.2659 0.463 ], Lowest was [0.1987 0.0502 0.2576 0.463 ]
Median for last 10 epochs: [0.2329 0.0507 0.2699 0.4873], Epochs since improvement 0
 25%|██▍       | 123/500 [2:04:59<6:13:45, 59.48s/it] 25%|██▍       | 124/500 [2:06:12<6:37:37, 63.45s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.17E+05, Train scatter: [0.4039 0.0526 0.2469 0.4651]
L1 regularization loss: 5.42E+00, L2 regularization loss: 6.14E+00
Test scatter: [0.3857 0.0516 0.2501 0.4592], Lowest was [0.1987 0.0502 0.2501 0.4592]
Median for last 10 epochs: [0.2396 0.0507 0.2659 0.4795], Epochs since improvement 0
 25%|██▌       | 125/500 [2:07:01<6:09:21, 59.10s/it] 25%|██▌       | 126/500 [2:08:15<6:36:25, 63.60s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.20E+05, Train scatter: [0.2454 0.0499 0.2923 0.4735]
L1 regularization loss: 5.60E+00, L2 regularization loss: 6.35E+00
Test scatter: [0.245  0.0491 0.2965 0.4682], Lowest was [0.1987 0.0491 0.2501 0.4592]
Median for last 10 epochs: [0.245  0.0507 0.2659 0.4682], Epochs since improvement 0
 25%|██▌       | 127/500 [2:09:03<6:06:24, 58.94s/it] 26%|██▌       | 128/500 [2:10:17<6:33:30, 63.47s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: -9.88E+04, Train scatter: [0.2705 0.0672 0.2754 0.4921]
L1 regularization loss: 5.51E+00, L2 regularization loss: 6.45E+00
Test scatter: [0.2619 0.0668 0.2798 0.4883], Lowest was [0.1987 0.0491 0.2501 0.4592]
Median for last 10 epochs: [0.2481 0.0507 0.2659 0.4682], Epochs since improvement 2
 26%|██▌       | 129/500 [2:11:05<6:02:28, 58.62s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: -2.08E+05, Train scatter: [0.1821 0.0473 0.2379 0.4494]
L1 regularization loss: 5.52E+00, L2 regularization loss: 6.55E+00
Test scatter: [0.1801 0.0472 0.2453 0.4446], Lowest was [0.1801 0.0472 0.2453 0.4446]
Median for last 10 epochs: [0.2481 0.0507 0.2659 0.463 ], Epochs since improvement 0
 26%|██▌       | 130/500 [2:12:24<6:40:22, 64.92s/it] 26%|██▌       | 131/500 [2:13:13<6:09:19, 60.05s/it] 26%|██▋       | 132/500 [2:14:26<6:31:54, 63.90s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: -2.74E+05, Train scatter: [0.1832 0.0458 0.2264 0.4453]
L1 regularization loss: 5.52E+00, L2 regularization loss: 6.61E+00
Test scatter: [0.1795 0.0455 0.2341 0.4393], Lowest was [0.1795 0.0455 0.2341 0.4393]
Median for last 10 epochs: [0.245  0.0491 0.2501 0.4592], Epochs since improvement 0
 27%|██▋       | 133/500 [2:15:13<6:01:08, 59.04s/it] 27%|██▋       | 134/500 [2:16:25<6:23:02, 62.79s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: -3.20E+05, Train scatter: [0.1713 0.0462 0.2289 0.437 ]
L1 regularization loss: 5.63E+00, L2 regularization loss: 6.74E+00
Test scatter: [0.1709 0.046  0.2392 0.4325], Lowest was [0.1709 0.0455 0.2341 0.4325]
Median for last 10 epochs: [0.1801 0.0472 0.2453 0.4446], Epochs since improvement 0
 27%|██▋       | 135/500 [2:17:15<5:57:56, 58.84s/it] 27%|██▋       | 136/500 [2:18:27<6:21:34, 62.90s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: -3.49E+05, Train scatter: [0.2409 0.0461 0.2274 0.4359]
L1 regularization loss: 5.55E+00, L2 regularization loss: 6.79E+00
Test scatter: [0.2327 0.0461 0.2362 0.4335], Lowest was [0.1709 0.0455 0.2341 0.4325]
Median for last 10 epochs: [0.1801 0.0461 0.2392 0.4393], Epochs since improvement 2
 27%|██▋       | 137/500 [2:19:16<5:55:29, 58.76s/it] 28%|██▊       | 138/500 [2:20:28<6:18:48, 62.79s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: -3.58E+05, Train scatter: [0.1726 0.0464 0.2208 0.4281]
L1 regularization loss: 5.66E+00, L2 regularization loss: 6.88E+00
Test scatter: [0.1719 0.0461 0.2276 0.4241], Lowest was [0.1709 0.0455 0.2276 0.4241]
Median for last 10 epochs: [0.1795 0.0461 0.2362 0.4335], Epochs since improvement 0
 28%|██▊       | 139/500 [2:21:16<5:51:16, 58.38s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: -3.64E+05, Train scatter: [0.2449 0.0511 0.2271 0.4478]
L1 regularization loss: 5.67E+00, L2 regularization loss: 6.98E+00
Test scatter: [0.2406 0.0505 0.2337 0.4451], Lowest was [0.1709 0.0455 0.2276 0.4241]
Median for last 10 epochs: [0.1795 0.0461 0.2341 0.4335], Epochs since improvement 2
 28%|██▊       | 140/500 [2:22:35<6:26:52, 64.48s/it] 28%|██▊       | 141/500 [2:23:24<5:57:41, 59.78s/it] 28%|██▊       | 142/500 [2:24:38<6:21:37, 63.96s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: -3.71E+05, Train scatter: [0.1708 0.0457 0.219  0.4248]
L1 regularization loss: 5.67E+00, L2 regularization loss: 7.11E+00
Test scatter: [0.172  0.0458 0.2265 0.4207], Lowest was [0.1709 0.0455 0.2265 0.4207]
Median for last 10 epochs: [0.172  0.0461 0.2337 0.4325], Epochs since improvement 0
 29%|██▊       | 143/500 [2:25:26<5:53:03, 59.34s/it] 29%|██▉       | 144/500 [2:26:39<6:16:26, 63.45s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: -3.62E+05, Train scatter: [0.3552 0.0609 0.2795 0.4409]
L1 regularization loss: 5.90E+00, L2 regularization loss: 7.25E+00
Test scatter: [0.3449 0.0614 0.2847 0.4347], Lowest was [0.1709 0.0455 0.2265 0.4207]
Median for last 10 epochs: [0.2327 0.0461 0.2337 0.4335], Epochs since improvement 2
 29%|██▉       | 145/500 [2:27:27<5:48:12, 58.85s/it] 29%|██▉       | 146/500 [2:28:39<6:10:15, 62.76s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: -3.75E+05, Train scatter: [0.215  0.0465 0.2498 0.4346]
L1 regularization loss: 5.90E+00, L2 regularization loss: 7.40E+00
Test scatter: [0.2068 0.0464 0.2557 0.434 ], Lowest was [0.1709 0.0455 0.2265 0.4207]
Median for last 10 epochs: [0.2068 0.0464 0.2337 0.434 ], Epochs since improvement 4
 29%|██▉       | 147/500 [2:29:28<5:44:58, 58.64s/it] 30%|██▉       | 148/500 [2:30:40<6:06:47, 62.52s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: -3.78E+05, Train scatter: [0.1534 0.0471 0.2297 0.4408]
L1 regularization loss: 5.87E+00, L2 regularization loss: 7.46E+00
Test scatter: [0.1537 0.0466 0.2355 0.4307], Lowest was [0.1537 0.0455 0.2265 0.4207]
Median for last 10 epochs: [0.2068 0.0466 0.2355 0.434 ], Epochs since improvement 0
 30%|██▉       | 149/500 [2:31:30<5:43:20, 58.69s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: -3.37E+05, Train scatter: [0.4008 0.0759 0.3418 0.5241]
L1 regularization loss: 6.30E+00, L2 regularization loss: 7.77E+00
Test scatter: [0.3908 0.0759 0.3444 0.522 ], Lowest was [0.1537 0.0455 0.2265 0.4207]
Median for last 10 epochs: [0.2068 0.0466 0.2557 0.434 ], Epochs since improvement 2
 30%|███       | 150/500 [2:32:48<6:17:33, 64.72s/it] 30%|███       | 151/500 [2:33:37<5:47:38, 59.77s/it] 30%|███       | 152/500 [2:34:48<6:07:44, 63.40s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: -3.68E+05, Train scatter: [0.1509 0.0467 0.2342 0.4304]
L1 regularization loss: 6.29E+00, L2 regularization loss: 8.13E+00
Test scatter: [0.1453 0.0468 0.2385 0.4241], Lowest was [0.1453 0.0455 0.2265 0.4207]
Median for last 10 epochs: [0.2068 0.0468 0.2557 0.434 ], Epochs since improvement 0
 31%|███       | 153/500 [2:35:38<5:42:06, 59.15s/it] 31%|███       | 154/500 [2:36:52<6:07:36, 63.75s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: -3.75E+05, Train scatter: [0.166  0.0439 0.2285 0.4261]
L1 regularization loss: 6.18E+00, L2 regularization loss: 8.07E+00
Test scatter: [0.1665 0.0436 0.2328 0.4205], Lowest was [0.1453 0.0436 0.2265 0.4205]
Median for last 10 epochs: [0.1665 0.0466 0.2385 0.4307], Epochs since improvement 0
 31%|███       | 155/500 [2:37:41<5:40:36, 59.24s/it] 31%|███       | 156/500 [2:38:54<6:03:25, 63.39s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: -3.85E+05, Train scatter: [0.1683 0.0459 0.229  0.4277]
L1 regularization loss: 6.10E+00, L2 regularization loss: 7.97E+00
Test scatter: [0.1666 0.0455 0.2327 0.4234], Lowest was [0.1453 0.0436 0.2265 0.4205]
Median for last 10 epochs: [0.1665 0.0466 0.2355 0.4241], Epochs since improvement 2
 31%|███▏      | 157/500 [2:39:42<5:35:38, 58.71s/it] 32%|███▏      | 158/500 [2:40:54<5:58:14, 62.85s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: -3.97E+05, Train scatter: [0.1449 0.0454 0.2224 0.4128]
L1 regularization loss: 6.02E+00, L2 regularization loss: 7.93E+00
Test scatter: [0.1475 0.0443 0.2257 0.4063], Lowest was [0.1453 0.0436 0.2257 0.4063]
Median for last 10 epochs: [0.1665 0.0455 0.2328 0.4234], Epochs since improvement 0
 32%|███▏      | 159/500 [2:41:41<5:30:00, 58.07s/it]Epoch: 160 done with learning rate 9.05E-03, Train loss: -3.90E+05, Train scatter: [0.2271 0.0416 0.2189 0.4161]
L1 regularization loss: 6.11E+00, L2 regularization loss: 8.01E+00
Test scatter: [0.2271 0.0414 0.2224 0.4121], Lowest was [0.1453 0.0414 0.2224 0.4063]
Median for last 10 epochs: [0.1665 0.0443 0.2327 0.4205], Epochs since improvement 0
 32%|███▏      | 160/500 [2:43:00<6:04:17, 64.29s/it] 32%|███▏      | 161/500 [2:43:48<5:36:16, 59.52s/it] 32%|███▏      | 162/500 [2:45:02<5:59:07, 63.75s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: -4.02E+05, Train scatter: [0.1448 0.0418 0.2262 0.4206]
L1 regularization loss: 6.07E+00, L2 regularization loss: 7.96E+00
Test scatter: [0.1473 0.0413 0.2287 0.4143], Lowest was [0.1453 0.0413 0.2224 0.4063]
Median for last 10 epochs: [0.1665 0.0436 0.2287 0.4143], Epochs since improvement 0
 33%|███▎      | 163/500 [2:45:50<5:30:44, 58.88s/it] 33%|███▎      | 164/500 [2:47:02<5:52:29, 62.95s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: -4.02E+05, Train scatter: [0.6278 0.1243 0.5152 0.5907]
L1 regularization loss: 6.09E+00, L2 regularization loss: 7.95E+00
Test scatter: [0.6123 0.1212 0.5077 0.5879], Lowest was [0.1453 0.0413 0.2224 0.4063]
Median for last 10 epochs: [0.1666 0.0443 0.2287 0.4143], Epochs since improvement 2
 33%|███▎      | 165/500 [2:47:52<5:29:22, 58.99s/it] 33%|███▎      | 166/500 [2:49:03<5:48:35, 62.62s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: -3.76E+05, Train scatter: [0.1789 0.044  0.2423 0.4353]
L1 regularization loss: 6.60E+00, L2 regularization loss: 8.56E+00
Test scatter: [0.1745 0.0437 0.2444 0.429 ], Lowest was [0.1453 0.0413 0.2224 0.4063]
Median for last 10 epochs: [0.1745 0.0437 0.2287 0.4143], Epochs since improvement 4
 33%|███▎      | 167/500 [2:49:52<5:24:49, 58.53s/it] 34%|███▎      | 168/500 [2:51:05<5:47:54, 62.87s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: -3.65E+05, Train scatter: [0.2215 0.052  0.406  0.4498]
L1 regularization loss: 6.55E+00, L2 regularization loss: 8.50E+00
Test scatter: [0.2169 0.052  0.3981 0.4448], Lowest was [0.1453 0.0413 0.2224 0.4063]
Median for last 10 epochs: [0.2169 0.0437 0.2444 0.429 ], Epochs since improvement 6
 34%|███▍      | 169/500 [2:51:53<5:22:51, 58.52s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -3.81E+05, Train scatter: [0.1475 0.047  0.2482 0.4213]
L1 regularization loss: 6.49E+00, L2 regularization loss: 8.47E+00
Test scatter: [0.1474 0.0467 0.251  0.4131], Lowest was [0.1453 0.0413 0.2224 0.4063]
Median for last 10 epochs: [0.1745 0.0467 0.251  0.429 ], Epochs since improvement 8
 34%|███▍      | 170/500 [2:53:13<5:57:35, 65.02s/it] 34%|███▍      | 171/500 [2:54:02<5:29:51, 60.16s/it] 34%|███▍      | 172/500 [2:55:15<5:49:34, 63.95s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -3.94E+05, Train scatter: [0.1994 0.048  0.2828 0.4372]
L1 regularization loss: 6.45E+00, L2 regularization loss: 8.42E+00
Test scatter: [0.1952 0.0479 0.2863 0.4295], Lowest was [0.1453 0.0413 0.2224 0.4063]
Median for last 10 epochs: [0.1952 0.0479 0.2863 0.4295], Epochs since improvement 10
 35%|███▍      | 173/500 [2:56:03<5:22:37, 59.20s/it] 35%|███▍      | 174/500 [2:57:16<5:43:46, 63.27s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -3.94E+05, Train scatter: [0.1477 0.0444 0.2595 0.4301]
L1 regularization loss: 6.47E+00, L2 regularization loss: 8.43E+00
Test scatter: [0.1472 0.0436 0.2592 0.421 ], Lowest was [0.1453 0.0413 0.2224 0.4063]
Median for last 10 epochs: [0.1745 0.0467 0.2592 0.429 ], Epochs since improvement 12
 35%|███▌      | 175/500 [2:58:05<5:19:07, 58.92s/it] 35%|███▌      | 176/500 [2:59:16<5:37:40, 62.53s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -4.19E+05, Train scatter: [0.2696 0.0514 0.2661 0.4415]
L1 regularization loss: 6.35E+00, L2 regularization loss: 8.35E+00
Test scatter: [0.2609 0.0503 0.2659 0.432 ], Lowest was [0.1453 0.0413 0.2224 0.4063]
Median for last 10 epochs: [0.1952 0.0479 0.2659 0.4295], Epochs since improvement 14
 35%|███▌      | 177/500 [3:00:05<5:16:13, 58.74s/it] 36%|███▌      | 178/500 [3:01:17<5:36:32, 62.71s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -4.02E+05, Train scatter: [0.1707 0.0429 0.235  0.4264]
L1 regularization loss: 6.53E+00, L2 regularization loss: 8.45E+00
Test scatter: [0.1706 0.0424 0.2364 0.4181], Lowest was [0.1453 0.0413 0.2224 0.4063]
Median for last 10 epochs: [0.1706 0.0467 0.2592 0.421 ], Epochs since improvement 16
 36%|███▌      | 179/500 [3:02:05<5:11:40, 58.26s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -4.20E+05, Train scatter: [0.1785 0.0418 0.2265 0.4131]
L1 regularization loss: 6.46E+00, L2 regularization loss: 8.43E+00
Test scatter: [0.1725 0.0411 0.2285 0.4051], Lowest was [0.1453 0.0411 0.2224 0.4051]
Median for last 10 epochs: [0.1725 0.0436 0.2592 0.421 ], Epochs since improvement 0
 36%|███▌      | 180/500 [3:03:26<5:47:04, 65.08s/it] 36%|███▌      | 181/500 [3:04:15<5:19:41, 60.13s/it] 36%|███▋      | 182/500 [3:05:29<5:40:52, 64.32s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -4.26E+05, Train scatter: [0.1302 0.0427 0.227  0.4117]
L1 regularization loss: 6.45E+00, L2 regularization loss: 8.39E+00
Test scatter: [0.1318 0.0424 0.2288 0.4033], Lowest was [0.1318 0.0411 0.2224 0.4033]
Median for last 10 epochs: [0.1706 0.0424 0.2364 0.4181], Epochs since improvement 0
 37%|███▋      | 183/500 [3:06:16<5:13:04, 59.26s/it] 37%|███▋      | 184/500 [3:07:29<5:33:14, 63.27s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -4.32E+05, Train scatter: [0.1754 0.0429 0.2245 0.4062]
L1 regularization loss: 6.44E+00, L2 regularization loss: 8.38E+00
Test scatter: [0.1725 0.042  0.2255 0.3983], Lowest was [0.1318 0.0411 0.2224 0.3983]
Median for last 10 epochs: [0.1725 0.0424 0.2288 0.4051], Epochs since improvement 0
 37%|███▋      | 185/500 [3:08:17<5:08:01, 58.67s/it] 37%|███▋      | 186/500 [3:09:29<5:27:41, 62.62s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -4.16E+05, Train scatter: [0.2258 0.0436 0.2478 0.424 ]
L1 regularization loss: 6.58E+00, L2 regularization loss: 8.47E+00
Test scatter: [0.215  0.0432 0.2497 0.4175], Lowest was [0.1318 0.0411 0.2224 0.3983]
Median for last 10 epochs: [0.1725 0.0424 0.2288 0.4051], Epochs since improvement 2
 37%|███▋      | 187/500 [3:10:16<5:03:03, 58.09s/it] 38%|███▊      | 188/500 [3:11:29<5:25:17, 62.56s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -4.40E+05, Train scatter: [0.1308 0.0395 0.2161 0.406 ]
L1 regularization loss: 6.46E+00, L2 regularization loss: 8.39E+00
Test scatter: [0.1335 0.0391 0.2176 0.4026], Lowest was [0.1318 0.0391 0.2176 0.3983]
Median for last 10 epochs: [0.1725 0.042  0.2285 0.4033], Epochs since improvement 0
 38%|███▊      | 189/500 [3:12:16<5:00:16, 57.93s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -3.99E+05, Train scatter: [0.1673 0.0414 0.2207 0.4148]
L1 regularization loss: 6.69E+00, L2 regularization loss: 8.59E+00
Test scatter: [0.1654 0.0406 0.2219 0.4058], Lowest was [0.1318 0.0391 0.2176 0.3983]
Median for last 10 epochs: [0.1654 0.042  0.2255 0.4033], Epochs since improvement 2
 38%|███▊      | 190/500 [3:13:35<5:31:56, 64.25s/it] 38%|███▊      | 191/500 [3:14:24<5:06:47, 59.57s/it] 38%|███▊      | 192/500 [3:15:36<5:25:33, 63.42s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -4.39E+05, Train scatter: [0.1367 0.0392 0.2102 0.4008]
L1 regularization loss: 6.66E+00, L2 regularization loss: 8.53E+00
Test scatter: [0.1364 0.0389 0.2133 0.3911], Lowest was [0.1318 0.0389 0.2133 0.3911]
Median for last 10 epochs: [0.1654 0.0406 0.2219 0.4026], Epochs since improvement 0
 39%|███▊      | 193/500 [3:16:24<5:00:45, 58.78s/it] 39%|███▉      | 194/500 [3:17:37<5:20:16, 62.80s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -4.54E+05, Train scatter: [0.1929 0.0426 0.2191 0.4047]
L1 regularization loss: 6.64E+00, L2 regularization loss: 8.53E+00
Test scatter: [0.1932 0.0423 0.2227 0.3994], Lowest was [0.1318 0.0389 0.2133 0.3911]
Median for last 10 epochs: [0.1654 0.0406 0.2219 0.4026], Epochs since improvement 2
 39%|███▉      | 195/500 [3:18:24<4:55:35, 58.15s/it] 39%|███▉      | 196/500 [3:19:36<5:15:06, 62.19s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -4.55E+05, Train scatter: [0.1374 0.0417 0.2146 0.4077]
L1 regularization loss: 6.70E+00, L2 regularization loss: 8.55E+00
Test scatter: [0.1367 0.0413 0.2174 0.4025], Lowest was [0.1318 0.0389 0.2133 0.3911]
Median for last 10 epochs: [0.1367 0.0406 0.2176 0.4025], Epochs since improvement 4
 39%|███▉      | 197/500 [3:20:25<4:54:35, 58.34s/it] 40%|███▉      | 198/500 [3:21:38<5:16:39, 62.91s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -4.43E+05, Train scatter: [0.2723 0.0416 0.2149 0.4002]
L1 regularization loss: 6.84E+00, L2 regularization loss: 8.62E+00
Test scatter: [0.2616 0.0418 0.2186 0.3941], Lowest was [0.1318 0.0389 0.2133 0.3911]
Median for last 10 epochs: [0.1654 0.0413 0.2186 0.3994], Epochs since improvement 6
 40%|███▉      | 199/500 [3:22:27<4:54:32, 58.71s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -4.53E+05, Train scatter: [0.117  0.0381 0.2039 0.393 ]
L1 regularization loss: 6.85E+00, L2 regularization loss: 8.62E+00
Test scatter: [0.12   0.0376 0.207  0.3852], Lowest was [0.12   0.0376 0.207  0.3852]
Median for last 10 epochs: [0.1367 0.0413 0.2174 0.3941], Epochs since improvement 0
 40%|████      | 200/500 [3:23:47<5:24:29, 64.90s/it] 40%|████      | 201/500 [3:24:34<4:56:50, 59.57s/it] 40%|████      | 202/500 [3:25:46<5:14:08, 63.25s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -4.72E+05, Train scatter: [0.1324 0.0402 0.2146 0.3933]
L1 regularization loss: 6.80E+00, L2 regularization loss: 8.61E+00
Test scatter: [0.131  0.04   0.2159 0.3862], Lowest was [0.12   0.0376 0.207  0.3852]
Median for last 10 epochs: [0.1367 0.0413 0.2174 0.3941], Epochs since improvement 2
 41%|████      | 203/500 [3:26:34<4:51:06, 58.81s/it] 41%|████      | 204/500 [3:27:46<5:09:54, 62.82s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -4.54E+05, Train scatter: [0.1455 0.0447 0.2349 0.416 ]
L1 regularization loss: 6.95E+00, L2 regularization loss: 8.69E+00
Test scatter: [0.1444 0.0438 0.2354 0.4064], Lowest was [0.12   0.0376 0.207  0.3852]
Median for last 10 epochs: [0.1367 0.0413 0.2174 0.3941], Epochs since improvement 4
 41%|████      | 205/500 [3:28:34<4:46:38, 58.30s/it] 41%|████      | 206/500 [3:29:45<5:04:18, 62.10s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -4.69E+05, Train scatter: [0.1165 0.0377 0.2049 0.3899]
L1 regularization loss: 6.92E+00, L2 regularization loss: 8.69E+00
Test scatter: [0.1204 0.0377 0.2084 0.3846], Lowest was [0.12   0.0376 0.207  0.3846]
Median for last 10 epochs: [0.131  0.04   0.2159 0.3862], Epochs since improvement 0
 41%|████▏     | 207/500 [3:30:34<4:44:25, 58.25s/it] 42%|████▏     | 208/500 [3:31:48<5:05:32, 62.78s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -4.81E+05, Train scatter: [0.1201 0.0387 0.2162 0.3876]
L1 regularization loss: 6.93E+00, L2 regularization loss: 8.69E+00
Test scatter: [0.1196 0.0385 0.2181 0.3821], Lowest was [0.1196 0.0376 0.207  0.3821]
Median for last 10 epochs: [0.1204 0.0385 0.2159 0.3852], Epochs since improvement 0
 42%|████▏     | 209/500 [3:32:37<4:44:35, 58.68s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -4.77E+05, Train scatter: [0.1336 0.0387 0.2148 0.3943]
L1 regularization loss: 7.00E+00, L2 regularization loss: 8.73E+00
Test scatter: [0.1332 0.0384 0.2168 0.3865], Lowest was [0.1196 0.0376 0.207  0.3821]
Median for last 10 epochs: [0.131  0.0385 0.2168 0.3862], Epochs since improvement 2
 42%|████▏     | 210/500 [3:33:58<5:16:33, 65.50s/it] 42%|████▏     | 211/500 [3:34:46<4:50:30, 60.31s/it] 42%|████▏     | 212/500 [3:35:59<5:07:39, 64.09s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -4.85E+05, Train scatter: [0.1147 0.0366 0.201  0.3855]
L1 regularization loss: 7.05E+00, L2 regularization loss: 8.79E+00
Test scatter: [0.1149 0.0364 0.2036 0.3789], Lowest was [0.1149 0.0364 0.2036 0.3789]
Median for last 10 epochs: [0.1204 0.0384 0.2168 0.3846], Epochs since improvement 0
 43%|████▎     | 213/500 [3:36:47<4:43:26, 59.26s/it] 43%|████▎     | 214/500 [3:38:01<5:02:47, 63.52s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: -4.85E+05, Train scatter: [0.1351 0.041  0.2089 0.3926]
L1 regularization loss: 7.13E+00, L2 regularization loss: 8.88E+00
Test scatter: [0.1359 0.0409 0.2111 0.3833], Lowest was [0.1149 0.0364 0.2036 0.3789]
Median for last 10 epochs: [0.1204 0.0384 0.2111 0.3833], Epochs since improvement 2
 43%|████▎     | 215/500 [3:38:48<4:38:28, 58.63s/it] 43%|████▎     | 216/500 [3:40:01<4:58:40, 63.10s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -4.97E+05, Train scatter: [0.1101 0.0386 0.2019 0.3865]
L1 regularization loss: 7.18E+00, L2 regularization loss: 8.95E+00
Test scatter: [0.1147 0.0384 0.2045 0.3798], Lowest was [0.1147 0.0364 0.2036 0.3789]
Median for last 10 epochs: [0.1196 0.0384 0.2111 0.3821], Epochs since improvement 0
 43%|████▎     | 217/500 [3:40:50<4:36:27, 58.61s/it] 44%|████▎     | 218/500 [3:42:02<4:54:26, 62.65s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -4.92E+05, Train scatter: [0.115  0.0382 0.2078 0.3899]
L1 regularization loss: 7.36E+00, L2 regularization loss: 9.06E+00
Test scatter: [0.1191 0.0381 0.2092 0.3835], Lowest was [0.1147 0.0364 0.2036 0.3789]
Median for last 10 epochs: [0.1191 0.0384 0.2092 0.3833], Epochs since improvement 2
 44%|████▍     | 219/500 [3:42:49<4:31:35, 57.99s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -5.04E+05, Train scatter: [0.1133 0.0367 0.1999 0.3833]
L1 regularization loss: 7.39E+00, L2 regularization loss: 9.14E+00
Test scatter: [0.115  0.0365 0.2031 0.3757], Lowest was [0.1147 0.0364 0.2031 0.3757]
Median for last 10 epochs: [0.115  0.0381 0.2045 0.3798], Epochs since improvement 0
 44%|████▍     | 220/500 [3:44:10<5:02:36, 64.84s/it] 44%|████▍     | 221/500 [3:44:57<4:36:53, 59.55s/it] 44%|████▍     | 222/500 [3:46:09<4:54:03, 63.46s/it]Epoch: 222 done with learning rate 7.33E-03, Train loss: -4.98E+05, Train scatter: [0.1108 0.0364 0.2007 0.3802]
L1 regularization loss: 7.76E+00, L2 regularization loss: 9.33E+00
Test scatter: [0.1122 0.0363 0.2035 0.3746], Lowest was [0.1122 0.0363 0.2031 0.3746]
Median for last 10 epochs: [0.115  0.0381 0.2045 0.3798], Epochs since improvement 0
 45%|████▍     | 223/500 [3:46:58<4:32:13, 58.97s/it] 45%|████▍     | 224/500 [3:48:10<4:49:36, 62.96s/it]Epoch: 224 done with learning rate 7.26E-03, Train loss: -5.03E+05, Train scatter: [0.1113 0.0367 0.2032 0.384 ]
L1 regularization loss: 7.75E+00, L2 regularization loss: 9.43E+00
Test scatter: [0.1137 0.0365 0.2058 0.3741], Lowest was [0.1122 0.0363 0.2031 0.3741]
Median for last 10 epochs: [0.1147 0.0365 0.2045 0.3757], Epochs since improvement 0
 45%|████▌     | 225/500 [3:49:00<4:30:45, 59.08s/it] 45%|████▌     | 226/500 [3:50:10<4:44:54, 62.39s/it]Epoch: 226 done with learning rate 7.20E-03, Train loss: -5.13E+05, Train scatter: [0.1069 0.0362 0.1989 0.3796]
L1 regularization loss: 7.84E+00, L2 regularization loss: 9.52E+00
Test scatter: [0.1086 0.0361 0.2013 0.373 ], Lowest was [0.1086 0.0361 0.2013 0.373 ]
Median for last 10 epochs: [0.1137 0.0365 0.2035 0.3746], Epochs since improvement 0
 45%|████▌     | 227/500 [3:50:59<4:24:54, 58.22s/it] 46%|████▌     | 228/500 [3:52:12<4:44:19, 62.72s/it]Epoch: 228 done with learning rate 7.13E-03, Train loss: -5.04E+05, Train scatter: [0.1078 0.0358 0.1981 0.3785]
L1 regularization loss: 7.93E+00, L2 regularization loss: 9.66E+00
Test scatter: [0.1088 0.0359 0.2014 0.3715], Lowest was [0.1086 0.0359 0.2013 0.3715]
Median for last 10 epochs: [0.1122 0.0363 0.2031 0.3741], Epochs since improvement 0
 46%|████▌     | 229/500 [3:53:01<4:24:22, 58.53s/it]Epoch: 230 done with learning rate 7.06E-03, Train loss: -5.18E+05, Train scatter: [0.1069 0.0362 0.1965 0.3745]
L1 regularization loss: 8.06E+00, L2 regularization loss: 9.79E+00
Test scatter: [0.1088 0.0361 0.1994 0.3684], Lowest was [0.1086 0.0359 0.1994 0.3684]
Median for last 10 epochs: [0.1088 0.0361 0.2014 0.373 ], Epochs since improvement 0
 46%|████▌     | 230/500 [3:54:21<4:52:40, 65.04s/it] 46%|████▌     | 231/500 [3:55:09<4:28:33, 59.90s/it] 46%|████▋     | 232/500 [3:56:22<4:45:29, 63.92s/it]Epoch: 232 done with learning rate 6.99E-03, Train loss: -5.16E+05, Train scatter: [0.1151 0.0355 0.2039 0.3744]
L1 regularization loss: 8.26E+00, L2 regularization loss: 1.00E+01
Test scatter: [0.1182 0.0356 0.2061 0.3679], Lowest was [0.1086 0.0356 0.1994 0.3679]
Median for last 10 epochs: [0.1088 0.0361 0.2014 0.3715], Epochs since improvement 0
 47%|████▋     | 233/500 [3:57:09<4:22:08, 58.91s/it] 47%|████▋     | 234/500 [3:58:21<4:38:13, 62.76s/it]Epoch: 234 done with learning rate 6.93E-03, Train loss: -5.18E+05, Train scatter: [0.104  0.036  0.1953 0.3704]
L1 regularization loss: 8.36E+00, L2 regularization loss: 1.02E+01
Test scatter: [0.1073 0.0362 0.1989 0.3635], Lowest was [0.1073 0.0356 0.1989 0.3635]
Median for last 10 epochs: [0.1088 0.0361 0.2013 0.3684], Epochs since improvement 0
 47%|████▋     | 235/500 [3:59:11<4:20:14, 58.92s/it] 47%|████▋     | 236/500 [4:00:25<4:38:47, 63.36s/it]Epoch: 236 done with learning rate 6.86E-03, Train loss: -5.26E+05, Train scatter: [0.1103 0.0352 0.195  0.371 ]
L1 regularization loss: 8.43E+00, L2 regularization loss: 1.03E+01
Test scatter: [0.1103 0.0353 0.1981 0.3625], Lowest was [0.1073 0.0353 0.1981 0.3625]
Median for last 10 epochs: [0.1088 0.0359 0.1994 0.3679], Epochs since improvement 0
 47%|████▋     | 237/500 [4:01:13<4:17:23, 58.72s/it] 48%|████▊     | 238/500 [4:02:25<4:34:44, 62.92s/it]Epoch: 238 done with learning rate 6.79E-03, Train loss: -5.29E+05, Train scatter: [0.0992 0.0347 0.1958 0.3703]
L1 regularization loss: 8.51E+00, L2 regularization loss: 1.04E+01
Test scatter: [0.1027 0.0348 0.1995 0.3626], Lowest was [0.1027 0.0348 0.1981 0.3625]
Median for last 10 epochs: [0.1088 0.0356 0.1994 0.3635], Epochs since improvement 0
 48%|████▊     | 239/500 [4:03:13<4:13:51, 58.36s/it]Epoch: 240 done with learning rate 6.72E-03, Train loss: -5.27E+05, Train scatter: [0.1239 0.0356 0.1965 0.3703]
L1 regularization loss: 8.69E+00, L2 regularization loss: 1.05E+01
Test scatter: [0.1268 0.0357 0.1999 0.3671], Lowest was [0.1027 0.0348 0.1981 0.3625]
Median for last 10 epochs: [0.1103 0.0356 0.1995 0.3635], Epochs since improvement 2
 48%|████▊     | 240/500 [4:04:31<4:38:10, 64.19s/it] 48%|████▊     | 241/500 [4:05:20<4:18:02, 59.78s/it] 48%|████▊     | 242/500 [4:06:33<4:33:26, 63.59s/it]Epoch: 242 done with learning rate 6.65E-03, Train loss: -5.26E+05, Train scatter: [0.1049 0.0351 0.195  0.3708]
L1 regularization loss: 8.79E+00, L2 regularization loss: 1.07E+01
Test scatter: [0.1066 0.0351 0.1981 0.361 ], Lowest was [0.1027 0.0348 0.1981 0.361 ]
Median for last 10 epochs: [0.1073 0.0353 0.1989 0.3626], Epochs since improvement 0
 49%|████▊     | 243/500 [4:07:20<4:11:23, 58.69s/it] 49%|████▉     | 244/500 [4:08:33<4:29:01, 63.05s/it]Epoch: 244 done with learning rate 6.58E-03, Train loss: -5.36E+05, Train scatter: [0.1269 0.0359 0.1983 0.3729]
L1 regularization loss: 8.85E+00, L2 regularization loss: 1.08E+01
Test scatter: [0.1304 0.0361 0.201  0.3663], Lowest was [0.1027 0.0348 0.1981 0.361 ]
Median for last 10 epochs: [0.1103 0.0353 0.1995 0.3626], Epochs since improvement 2
 49%|████▉     | 245/500 [4:09:21<4:08:19, 58.43s/it] 49%|████▉     | 246/500 [4:10:32<4:22:57, 62.12s/it]Epoch: 246 done with learning rate 6.51E-03, Train loss: -5.35E+05, Train scatter: [0.1056 0.0349 0.1934 0.3674]
L1 regularization loss: 9.03E+00, L2 regularization loss: 1.10E+01
Test scatter: [0.108  0.035  0.198  0.3613], Lowest was [0.1027 0.0348 0.198  0.361 ]
Median for last 10 epochs: [0.108  0.0351 0.1995 0.3626], Epochs since improvement 0
 49%|████▉     | 247/500 [4:11:19<4:03:00, 57.63s/it] 50%|████▉     | 248/500 [4:12:32<4:21:17, 62.21s/it]Epoch: 248 done with learning rate 6.44E-03, Train loss: -5.38E+05, Train scatter: [0.0985 0.0355 0.1963 0.3709]
L1 regularization loss: 9.12E+00, L2 regularization loss: 1.11E+01
Test scatter: [0.1032 0.0354 0.1998 0.3651], Lowest was [0.1027 0.0348 0.198  0.361 ]
Median for last 10 epochs: [0.108  0.0354 0.1998 0.3651], Epochs since improvement 2
 50%|████▉     | 249/500 [4:13:20<4:02:35, 57.99s/it]Epoch: 250 done with learning rate 6.37E-03, Train loss: -5.41E+05, Train scatter: [0.109  0.036  0.1981 0.3717]
L1 regularization loss: 9.26E+00, L2 regularization loss: 1.13E+01
Test scatter: [0.1126 0.0361 0.2012 0.3674], Lowest was [0.1027 0.0348 0.198  0.361 ]
Median for last 10 epochs: [0.108  0.0354 0.1998 0.3651], Epochs since improvement 4
 50%|█████     | 250/500 [4:14:40<4:29:22, 64.65s/it] 50%|█████     | 251/500 [4:15:28<4:07:42, 59.69s/it] 50%|█████     | 252/500 [4:16:42<4:23:36, 63.77s/it]Epoch: 252 done with learning rate 6.30E-03, Train loss: -5.46E+05, Train scatter: [0.0984 0.0348 0.1963 0.3707]
L1 regularization loss: 9.40E+00, L2 regularization loss: 1.15E+01
Test scatter: [0.1022 0.0352 0.2    0.3651], Lowest was [0.1022 0.0348 0.198  0.361 ]
Median for last 10 epochs: [0.108  0.0354 0.2    0.3651], Epochs since improvement 0
 51%|█████     | 253/500 [4:17:30<4:03:41, 59.20s/it] 51%|█████     | 254/500 [4:18:44<4:21:10, 63.70s/it]Epoch: 254 done with learning rate 6.23E-03, Train loss: -5.23E+05, Train scatter: [0.0968 0.0363 0.2001 0.3706]
L1 regularization loss: 1.00E+01, L2 regularization loss: 1.19E+01
Test scatter: [0.1017 0.0365 0.2036 0.3652], Lowest was [0.1017 0.0348 0.198  0.361 ]
Median for last 10 epochs: [0.1032 0.0354 0.2    0.3651], Epochs since improvement 0
 51%|█████     | 255/500 [4:19:33<4:01:51, 59.23s/it] 51%|█████     | 256/500 [4:20:46<4:17:00, 63.20s/it]Epoch: 256 done with learning rate 6.15E-03, Train loss: -5.47E+05, Train scatter: [0.1103 0.0365 0.1952 0.3704]
L1 regularization loss: 1.00E+01, L2 regularization loss: 1.20E+01
Test scatter: [0.1119 0.0369 0.1992 0.3636], Lowest was [0.1017 0.0348 0.198  0.361 ]
Median for last 10 epochs: [0.1032 0.0361 0.2    0.3651], Epochs since improvement 2
 51%|█████▏    | 257/500 [4:21:35<3:59:34, 59.15s/it] 52%|█████▏    | 258/500 [4:22:50<4:17:43, 63.90s/it]Epoch: 258 done with learning rate 6.08E-03, Train loss: -5.43E+05, Train scatter: [0.0966 0.0343 0.193  0.3633]
L1 regularization loss: 1.00E+01, L2 regularization loss: 1.21E+01
Test scatter: [0.1025 0.0345 0.1967 0.3572], Lowest was [0.1017 0.0345 0.1967 0.3572]
Median for last 10 epochs: [0.1025 0.0361 0.2    0.3651], Epochs since improvement 0
 52%|█████▏    | 259/500 [4:23:39<3:57:57, 59.24s/it]Epoch: 260 done with learning rate 6.01E-03, Train loss: -5.47E+05, Train scatter: [0.1045 0.0346 0.1936 0.3705]
L1 regularization loss: 1.01E+01, L2 regularization loss: 1.22E+01
Test scatter: [0.1075 0.0347 0.1979 0.3626], Lowest was [0.1017 0.0345 0.1967 0.3572]
Median for last 10 epochs: [0.1025 0.0352 0.1992 0.3636], Epochs since improvement 2
 52%|█████▏    | 260/500 [4:24:58<4:21:01, 65.26s/it] 52%|█████▏    | 261/500 [4:25:45<3:58:19, 59.83s/it] 52%|█████▏    | 262/500 [4:26:58<4:13:16, 63.85s/it]Epoch: 262 done with learning rate 5.94E-03, Train loss: -5.55E+05, Train scatter: [0.0971 0.0358 0.1931 0.366 ]
L1 regularization loss: 1.02E+01, L2 regularization loss: 1.24E+01
Test scatter: [0.1015 0.0358 0.1964 0.358 ], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1025 0.0358 0.1979 0.3626], Epochs since improvement 0
 53%|█████▎    | 263/500 [4:27:47<3:53:54, 59.22s/it] 53%|█████▎    | 264/500 [4:28:59<4:08:29, 63.17s/it]Epoch: 264 done with learning rate 5.86E-03, Train loss: -3.33E+05, Train scatter: [0.1465 0.044  0.2533 0.4376]
L1 regularization loss: 1.22E+01, L2 regularization loss: 1.35E+01
Test scatter: [0.1437 0.043  0.2529 0.4213], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1075 0.0358 0.1979 0.3626], Epochs since improvement 2
 53%|█████▎    | 265/500 [4:29:48<3:50:57, 58.97s/it] 53%|█████▎    | 266/500 [4:31:02<4:06:56, 63.32s/it]Epoch: 266 done with learning rate 5.79E-03, Train loss: -4.65E+05, Train scatter: [0.1499 0.0377 0.2117 0.4005]
L1 regularization loss: 1.21E+01, L2 regularization loss: 1.36E+01
Test scatter: [0.145  0.0373 0.2148 0.3874], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1075 0.0358 0.1979 0.3626], Epochs since improvement 4
 53%|█████▎    | 267/500 [4:31:49<3:47:23, 58.55s/it] 54%|█████▎    | 268/500 [4:33:03<4:04:22, 63.20s/it]Epoch: 268 done with learning rate 5.72E-03, Train loss: -4.91E+05, Train scatter: [0.1195 0.037  0.2042 0.3856]
L1 regularization loss: 1.21E+01, L2 regularization loss: 1.36E+01
Test scatter: [0.1162 0.0368 0.208  0.3761], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1162 0.0368 0.208  0.3761], Epochs since improvement 6
 54%|█████▍    | 269/500 [4:33:51<3:45:10, 58.49s/it]Epoch: 270 done with learning rate 5.65E-03, Train loss: -5.07E+05, Train scatter: [0.1094 0.036  0.203  0.3803]
L1 regularization loss: 1.20E+01, L2 regularization loss: 1.37E+01
Test scatter: [0.1088 0.0359 0.2062 0.3714], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1162 0.0368 0.208  0.3761], Epochs since improvement 8
 54%|█████▍    | 270/500 [4:35:10<4:07:43, 64.62s/it] 54%|█████▍    | 271/500 [4:35:57<3:47:04, 59.49s/it] 54%|█████▍    | 272/500 [4:37:10<4:01:14, 63.48s/it]Epoch: 272 done with learning rate 5.57E-03, Train loss: -5.13E+05, Train scatter: [0.1131 0.0359 0.1991 0.3753]
L1 regularization loss: 1.20E+01, L2 regularization loss: 1.37E+01
Test scatter: [0.1126 0.0357 0.202  0.3677], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1162 0.0368 0.208  0.3761], Epochs since improvement 10
 55%|█████▍    | 273/500 [4:37:57<3:41:44, 58.61s/it] 55%|█████▍    | 274/500 [4:39:11<3:58:07, 63.22s/it]Epoch: 274 done with learning rate 5.50E-03, Train loss: -5.28E+05, Train scatter: [0.1212 0.0357 0.1952 0.3724]
L1 regularization loss: 1.19E+01, L2 regularization loss: 1.38E+01
Test scatter: [0.119  0.0354 0.1986 0.3625], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1162 0.0359 0.2062 0.3714], Epochs since improvement 12
 55%|█████▌    | 275/500 [4:40:00<3:40:31, 58.81s/it] 55%|█████▌    | 276/500 [4:41:14<3:57:06, 63.51s/it]Epoch: 276 done with learning rate 5.42E-03, Train loss: -5.33E+05, Train scatter: [0.1027 0.0351 0.1962 0.3686]
L1 regularization loss: 1.19E+01, L2 regularization loss: 1.38E+01
Test scatter: [0.104  0.0351 0.1988 0.3603], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1126 0.0357 0.202  0.3677], Epochs since improvement 14
 55%|█████▌    | 277/500 [4:42:03<3:39:13, 58.98s/it] 56%|█████▌    | 278/500 [4:43:17<3:55:13, 63.57s/it]Epoch: 278 done with learning rate 5.35E-03, Train loss: -5.27E+05, Train scatter: [0.1014 0.0353 0.1946 0.3672]
L1 regularization loss: 1.19E+01, L2 regularization loss: 1.39E+01
Test scatter: [0.1036 0.0354 0.1979 0.3594], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1088 0.0354 0.1988 0.3625], Epochs since improvement 16
 56%|█████▌    | 279/500 [4:44:06<3:38:02, 59.20s/it]Epoch: 280 done with learning rate 5.28E-03, Train loss: -5.32E+05, Train scatter: [0.1137 0.0349 0.1962 0.366 ]
L1 regularization loss: 1.20E+01, L2 regularization loss: 1.40E+01
Test scatter: [0.1143 0.0351 0.1979 0.358 ], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1126 0.0354 0.1986 0.3603], Epochs since improvement 18
 56%|█████▌    | 280/500 [4:45:26<4:00:33, 65.61s/it] 56%|█████▌    | 281/500 [4:46:14<3:39:44, 60.20s/it] 56%|█████▋    | 282/500 [4:47:26<3:51:36, 63.75s/it]Epoch: 282 done with learning rate 5.20E-03, Train loss: -5.35E+05, Train scatter: [0.1054 0.0365 0.2095 0.369 ]
L1 regularization loss: 1.19E+01, L2 regularization loss: 1.40E+01
Test scatter: [0.1088 0.0365 0.2127 0.3617], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1088 0.0354 0.1986 0.3603], Epochs since improvement 20
 57%|█████▋    | 283/500 [4:48:14<3:33:19, 58.98s/it] 57%|█████▋    | 283/500 [4:49:28<3:41:57, 61.37s/it]
Epoch: 284 done with learning rate 5.13E-03, Train loss: -5.39E+05, Train scatter: [0.1032 0.0349 0.1935 0.3674]
L1 regularization loss: 1.19E+01, L2 regularization loss: 1.41E+01
Test scatter: [0.1045 0.0349 0.1976 0.3591], Lowest was [0.1015 0.0345 0.1964 0.3572]
Median for last 10 epochs: [0.1045 0.0351 0.1979 0.3594], Epochs since improvement 22
Exited after 284 epochs due to early stopping
17368.60 seconds spent training, 34.737 seconds per epoch. Processed 2005 trees per second
[0.10450434 0.0349321  0.19756185 0.3591255 ]
{'epoch_exit': 283, 'scatter_m_star': 0.10450434, 'lowest_m_star': 0.101482056, 'last20_m_star': 0.11068833, 'last10_m_star': 0.10450751, 'scatter_v_disk': 0.034932103, 'lowest_v_disk': 0.03447386, 'last20_v_disk': 0.03556678, 'last10_v_disk': 0.03514652, 'scatter_m_cold': 0.19756185, 'lowest_m_cold': 0.19640009, 'last20_m_cold': 0.20041394, 'last10_m_cold': 0.19789518, 'scatter_sfr_100': 0.3591255, 'lowest_sfr_100': 0.35719913, 'last20_sfr_100': 0.36211902, 'last10_sfr_100': 0.3594381}
Finished 1/1
Exited training after None epochs
Experiment 3 done: 3 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  2 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 2, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con2bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_pyosia
RelU conv activation
LeakyRelU decode activation
N_params 422280
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:41<5:42:53, 41.23s/it]  0%|          | 2/500 [01:45<7:34:06, 54.71s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 3.01E+07, Train scatter: [0.9352 0.1713 0.5441 0.9954]
L1 regularization loss: 1.98E+00, L2 regularization loss: 3.76E-01
Test scatter: [0.9196 0.1674 0.5356 0.9851], Lowest was [0.9196 0.1674 0.5356 0.9851]
Median for last 10 epochs: [0.9196 0.1674 0.5356 0.9851], Epochs since improvement 2
  1%|          | 3/500 [02:25<6:39:33, 48.24s/it]  1%|          | 4/500 [03:29<7:29:59, 54.44s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 2.21E+07, Train scatter: [0.9352 0.1555 0.5441 0.9954]
L1 regularization loss: 1.99E+00, L2 regularization loss: 3.85E-01
Test scatter: [0.9196 0.1519 0.5355 0.9851], Lowest was [0.9196 0.1519 0.5355 0.9851]
Median for last 10 epochs: [0.9196 0.1519 0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [04:10<6:49:26, 49.63s/it]  1%|          | 6/500 [05:14<7:28:23, 54.46s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 1.70E+07, Train scatter: [0.9348 0.1116 0.544  0.9954]
L1 regularization loss: 2.01E+00, L2 regularization loss: 4.01E-01
Test scatter: [0.9192 0.1106 0.5355 0.985 ], Lowest was [0.9192 0.1106 0.5355 0.985 ]
Median for last 10 epochs: [0.9192 0.1106 0.5355 0.985 ], Epochs since improvement 0
  1%|▏         | 7/500 [05:55<6:49:26, 49.83s/it]  2%|▏         | 8/500 [06:58<7:23:42, 54.11s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 1.29E+07, Train scatter: [0.9045 0.0923 0.544  0.7799]
L1 regularization loss: 2.04E+00, L2 regularization loss: 4.28E-01
Test scatter: [0.8901 0.0924 0.5354 0.7855], Lowest was [0.8901 0.0924 0.5354 0.7855]
Median for last 10 epochs: [0.9046 0.1015 0.5354 0.8853], Epochs since improvement 0
  2%|▏         | 9/500 [07:38<6:48:03, 49.86s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 9.59E+06, Train scatter: [0.7545 0.0901 0.5439 0.6032]
L1 regularization loss: 2.06E+00, L2 regularization loss: 4.58E-01
Test scatter: [0.7451 0.0902 0.5354 0.6002], Lowest was [0.7451 0.0902 0.5354 0.6002]
Median for last 10 epochs: [0.8901 0.0924 0.5354 0.7855], Epochs since improvement 0
  2%|▏         | 10/500 [08:49<7:38:53, 56.19s/it]  2%|▏         | 11/500 [09:30<7:00:05, 51.55s/it]  2%|▏         | 12/500 [10:33<7:27:24, 55.01s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 6.73E+06, Train scatter: [0.6191 0.0847 0.5439 0.5767]
L1 regularization loss: 2.07E+00, L2 regularization loss: 4.69E-01
Test scatter: [0.6116 0.0846 0.5354 0.5697], Lowest was [0.6116 0.0846 0.5354 0.5697]
Median for last 10 epochs: [0.8901 0.0924 0.5354 0.7855], Epochs since improvement 0
  3%|▎         | 13/500 [11:13<6:51:05, 50.65s/it]  3%|▎         | 14/500 [12:18<7:25:30, 55.00s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 5.30E+06, Train scatter: [0.5279 0.0831 0.5439 0.5453]
L1 regularization loss: 2.08E+00, L2 regularization loss: 4.80E-01
Test scatter: [0.5234 0.0834 0.5354 0.5419], Lowest was [0.5234 0.0834 0.5354 0.5419]
Median for last 10 epochs: [0.7451 0.0902 0.5354 0.6002], Epochs since improvement 0
  3%|▎         | 15/500 [12:59<6:49:31, 50.66s/it]  3%|▎         | 16/500 [14:02<7:19:52, 54.53s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 4.78E+06, Train scatter: [0.5313 0.0868 0.544  0.5876]
L1 regularization loss: 2.09E+00, L2 regularization loss: 4.88E-01
Test scatter: [0.5199 0.0872 0.5354 0.5832], Lowest was [0.5199 0.0834 0.5354 0.5419]
Median for last 10 epochs: [0.6116 0.0872 0.5354 0.5832], Epochs since improvement 0
  3%|▎         | 17/500 [14:44<6:46:53, 50.54s/it]  4%|▎         | 18/500 [15:48<7:19:19, 54.69s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.21E+06, Train scatter: [0.2996 0.0791 0.5439 0.5457]
L1 regularization loss: 2.10E+00, L2 regularization loss: 4.94E-01
Test scatter: [0.3083 0.0796 0.5353 0.5383], Lowest was [0.3083 0.0796 0.5353 0.5383]
Median for last 10 epochs: [0.5234 0.0846 0.5354 0.5697], Epochs since improvement 0
  4%|▍         | 19/500 [16:30<6:47:11, 50.79s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 3.92E+06, Train scatter: [0.2683 0.082  0.5438 0.5362]
L1 regularization loss: 2.11E+00, L2 regularization loss: 4.99E-01
Test scatter: [0.2723 0.082  0.5352 0.53  ], Lowest was [0.2723 0.0796 0.5352 0.53  ]
Median for last 10 epochs: [0.5199 0.0834 0.5354 0.5419], Epochs since improvement 0
  4%|▍         | 20/500 [17:41<7:34:45, 56.85s/it]  4%|▍         | 21/500 [18:21<6:54:54, 51.97s/it]  4%|▍         | 22/500 [19:25<7:21:36, 55.43s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 3.80E+06, Train scatter: [0.341  0.0776 0.5438 0.535 ]
L1 regularization loss: 2.11E+00, L2 regularization loss: 5.04E-01
Test scatter: [0.3442 0.0778 0.5352 0.5338], Lowest was [0.2723 0.0778 0.5352 0.53  ]
Median for last 10 epochs: [0.3442 0.082  0.5353 0.5383], Epochs since improvement 0
  5%|▍         | 23/500 [20:06<6:47:02, 51.20s/it]  5%|▍         | 24/500 [21:11<7:17:55, 55.20s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.76E+06, Train scatter: [0.2855 0.0773 0.5437 0.5352]
L1 regularization loss: 2.13E+00, L2 regularization loss: 5.09E-01
Test scatter: [0.2889 0.0777 0.5352 0.5367], Lowest was [0.2723 0.0777 0.5352 0.53  ]
Median for last 10 epochs: [0.3083 0.0796 0.5352 0.5367], Epochs since improvement 0
  5%|▌         | 25/500 [21:52<6:43:32, 50.97s/it]  5%|▌         | 26/500 [22:55<7:12:03, 54.69s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.72E+06, Train scatter: [0.3694 0.0743 0.5437 0.5808]
L1 regularization loss: 2.14E+00, L2 regularization loss: 5.14E-01
Test scatter: [0.3719 0.075  0.5351 0.581 ], Lowest was [0.2723 0.075  0.5351 0.53  ]
Median for last 10 epochs: [0.3083 0.0778 0.5352 0.5367], Epochs since improvement 0
  5%|▌         | 27/500 [23:37<6:41:13, 50.89s/it]  6%|▌         | 28/500 [24:43<7:15:04, 55.31s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.69E+06, Train scatter: [0.2425 0.0726 0.5436 0.5276]
L1 regularization loss: 2.15E+00, L2 regularization loss: 5.20E-01
Test scatter: [0.2475 0.0733 0.5351 0.5276], Lowest was [0.2475 0.0733 0.5351 0.5276]
Median for last 10 epochs: [0.2889 0.0777 0.5352 0.5338], Epochs since improvement 0
  6%|▌         | 29/500 [25:23<6:39:10, 50.85s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 3.67E+06, Train scatter: [0.2293 0.071  0.5436 0.5274]
L1 regularization loss: 2.16E+00, L2 regularization loss: 5.25E-01
Test scatter: [0.2353 0.0719 0.535  0.5265], Lowest was [0.2353 0.0719 0.535  0.5265]
Median for last 10 epochs: [0.2889 0.075  0.5351 0.5338], Epochs since improvement 0
  6%|▌         | 30/500 [26:34<7:25:37, 56.89s/it]  6%|▌         | 31/500 [27:16<6:49:11, 52.35s/it]  6%|▋         | 32/500 [28:20<7:15:45, 55.87s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 3.61E+06, Train scatter: [0.2908 0.0758 0.5433 0.5409]
L1 regularization loss: 2.17E+00, L2 regularization loss: 5.31E-01
Test scatter: [0.2928 0.0753 0.5348 0.5372], Lowest was [0.2353 0.0719 0.5348 0.5265]
Median for last 10 epochs: [0.2889 0.075  0.5351 0.5367], Epochs since improvement 0
  7%|▋         | 33/500 [29:02<6:41:12, 51.55s/it]  7%|▋         | 34/500 [30:06<7:09:28, 55.30s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 3.49E+06, Train scatter: [0.2151 0.0718 0.5433 0.5122]
L1 regularization loss: 2.19E+00, L2 regularization loss: 5.37E-01
Test scatter: [0.2232 0.0716 0.5348 0.5089], Lowest was [0.2232 0.0716 0.5348 0.5089]
Median for last 10 epochs: [0.2475 0.0733 0.535  0.5276], Epochs since improvement 0
  7%|▋         | 35/500 [30:47<6:37:05, 51.24s/it]  7%|▋         | 36/500 [31:51<7:04:42, 54.92s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 3.48E+06, Train scatter: [0.4308 0.073  0.5433 0.5856]
L1 regularization loss: 2.20E+00, L2 regularization loss: 5.43E-01
Test scatter: [0.4287 0.0733 0.5348 0.5824], Lowest was [0.2232 0.0716 0.5348 0.5089]
Median for last 10 epochs: [0.2475 0.0733 0.5348 0.5276], Epochs since improvement 2
  7%|▋         | 37/500 [32:33<6:33:41, 51.02s/it]  8%|▊         | 38/500 [33:37<7:02:10, 54.83s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 3.43E+06, Train scatter: [0.2221 0.0689 0.5432 0.5053]
L1 regularization loss: 2.21E+00, L2 regularization loss: 5.49E-01
Test scatter: [0.2299 0.069  0.5347 0.501 ], Lowest was [0.2232 0.069  0.5347 0.501 ]
Median for last 10 epochs: [0.2353 0.0719 0.5348 0.5265], Epochs since improvement 0
  8%|▊         | 39/500 [34:18<6:29:48, 50.73s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 3.44E+06, Train scatter: [0.2003 0.0673 0.5432 0.5024]
L1 regularization loss: 2.22E+00, L2 regularization loss: 5.55E-01
Test scatter: [0.2086 0.0679 0.5347 0.4976], Lowest was [0.2086 0.0679 0.5347 0.4976]
Median for last 10 epochs: [0.2299 0.0716 0.5348 0.5089], Epochs since improvement 0
  8%|▊         | 40/500 [35:28<7:13:09, 56.50s/it]  8%|▊         | 41/500 [36:09<6:36:25, 51.82s/it]  8%|▊         | 42/500 [37:14<7:07:16, 55.98s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 3.46E+06, Train scatter: [0.207  0.0662 0.5431 0.4994]
L1 regularization loss: 2.24E+00, L2 regularization loss: 5.66E-01
Test scatter: [0.2155 0.0668 0.5346 0.5004], Lowest was [0.2086 0.0668 0.5346 0.4976]
Median for last 10 epochs: [0.2232 0.069  0.5347 0.501 ], Epochs since improvement 0
  9%|▊         | 43/500 [37:55<6:31:46, 51.44s/it]  9%|▉         | 44/500 [39:00<7:02:26, 55.58s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 3.39E+06, Train scatter: [0.2582 0.0669 0.543  0.5065]
L1 regularization loss: 2.27E+00, L2 regularization loss: 5.75E-01
Test scatter: [0.2657 0.0676 0.5346 0.5011], Lowest was [0.2086 0.0668 0.5346 0.4976]
Median for last 10 epochs: [0.2299 0.0679 0.5347 0.501 ], Epochs since improvement 0
  9%|▉         | 45/500 [39:42<6:28:57, 51.29s/it]  9%|▉         | 46/500 [40:47<7:00:54, 55.63s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 3.42E+06, Train scatter: [0.2282 0.0692 0.543  0.5224]
L1 regularization loss: 2.28E+00, L2 regularization loss: 5.86E-01
Test scatter: [0.2323 0.0694 0.5345 0.5197], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.2299 0.0679 0.5346 0.501 ], Epochs since improvement 0
  9%|▉         | 47/500 [41:29<6:27:23, 51.31s/it] 10%|▉         | 48/500 [42:33<6:57:12, 55.38s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.43E+06, Train scatter: [0.4995 0.1373 0.5435 0.9034]
L1 regularization loss: 2.38E+00, L2 regularization loss: 6.22E-01
Test scatter: [0.494  0.1341 0.535  0.8969], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.2323 0.0679 0.5346 0.5011], Epochs since improvement 2
 10%|▉         | 49/500 [43:14<6:22:29, 50.89s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 4.14E+06, Train scatter: [0.74   0.1582 0.544  0.9951]
L1 regularization loss: 2.96E+00, L2 regularization loss: 8.54E-01
Test scatter: [0.7391 0.1552 0.5355 0.9847], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.2657 0.0694 0.5346 0.5197], Epochs since improvement 4
 10%|█         | 50/500 [44:25<7:07:25, 56.99s/it] 10%|█         | 51/500 [45:07<6:31:55, 52.37s/it] 10%|█         | 52/500 [46:13<7:01:20, 56.43s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 3.79E+06, Train scatter: [0.6267 0.1247 0.5439 0.976 ]
L1 regularization loss: 2.97E+00, L2 regularization loss: 8.68E-01
Test scatter: [0.6363 0.1254 0.5354 0.9712], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.494  0.1254 0.535  0.8969], Epochs since improvement 6
 11%|█         | 53/500 [46:54<6:26:40, 51.90s/it] 11%|█         | 54/500 [48:01<7:00:03, 56.51s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 3.56E+06, Train scatter: [0.6838 0.1165 0.5438 0.7962]
L1 regularization loss: 2.99E+00, L2 regularization loss: 8.87E-01
Test scatter: [0.6743 0.1181 0.5353 0.8027], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.6363 0.1254 0.5353 0.8969], Epochs since improvement 8
 11%|█         | 55/500 [48:42<6:24:08, 51.79s/it] 11%|█         | 56/500 [49:46<6:50:35, 55.49s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 3.52E+06, Train scatter: [0.6931 0.1088 0.5438 0.7434]
L1 regularization loss: 3.00E+00, L2 regularization loss: 8.95E-01
Test scatter: [0.6828 0.109  0.5353 0.7442], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.6743 0.1254 0.5353 0.8969], Epochs since improvement 10
 11%|█▏        | 57/500 [50:28<6:18:31, 51.27s/it] 12%|█▏        | 58/500 [51:32<6:47:17, 55.29s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.49E+06, Train scatter: [0.6163 0.1019 0.5439 0.6956]
L1 regularization loss: 3.00E+00, L2 regularization loss: 9.01E-01
Test scatter: [0.6127 0.1013 0.5353 0.6969], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.6743 0.1181 0.5353 0.8027], Epochs since improvement 12
 12%|█▏        | 59/500 [52:14<6:16:12, 51.18s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.42E+06, Train scatter: [0.5581 0.1041 0.5438 0.7024]
L1 regularization loss: 3.01E+00, L2 regularization loss: 9.13E-01
Test scatter: [0.5612 0.1041 0.5353 0.7004], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.6363 0.109  0.5353 0.7442], Epochs since improvement 14
 12%|█▏        | 60/500 [53:26<7:01:31, 57.48s/it] 12%|█▏        | 61/500 [54:08<6:26:56, 52.89s/it] 12%|█▏        | 62/500 [55:13<6:53:01, 56.58s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 3.44E+06, Train scatter: [0.552  0.1372 0.5438 0.7398]
L1 regularization loss: 3.02E+00, L2 regularization loss: 9.29E-01
Test scatter: [0.5532 0.1371 0.5352 0.7429], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.6127 0.109  0.5353 0.7429], Epochs since improvement 16
 13%|█▎        | 63/500 [55:55<6:19:54, 52.16s/it] 13%|█▎        | 64/500 [57:00<6:45:56, 55.86s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 3.36E+06, Train scatter: [0.595  0.1146 0.5437 0.6712]
L1 regularization loss: 3.04E+00, L2 regularization loss: 9.43E-01
Test scatter: [0.5997 0.1155 0.5352 0.6736], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.5997 0.109  0.5353 0.7004], Epochs since improvement 18
 13%|█▎        | 65/500 [57:40<6:11:26, 51.23s/it] 13%|█▎        | 66/500 [58:45<6:39:36, 55.25s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 3.35E+06, Train scatter: [0.5391 0.1144 0.5437 0.757 ]
L1 regularization loss: 3.06E+00, L2 regularization loss: 9.60E-01
Test scatter: [0.541  0.1147 0.5351 0.7626], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.5612 0.1147 0.5352 0.7004], Epochs since improvement 20
 13%|█▎        | 67/500 [59:25<6:06:55, 50.84s/it] 13%|█▎        | 67/500 [1:00:30<6:30:59, 54.18s/it]
Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.33E+06, Train scatter: [0.4836 0.0961 0.5437 0.6193]
L1 regularization loss: 3.07E+00, L2 regularization loss: 9.72E-01
Test scatter: [0.4849 0.0955 0.5352 0.6135], Lowest was [0.2086 0.0668 0.5345 0.4976]
Median for last 10 epochs: [0.5532 0.1147 0.5352 0.7004], Epochs since improvement 22
Exited after 68 epochs due to early stopping
3630.03 seconds spent training, 7.260 seconds per epoch. Processed 9592 trees per second
[0.48492908 0.09547214 0.5351472  0.6134583 ]
{'epoch_exit': 67, 'scatter_m_star': 0.48492908, 'lowest_m_star': 0.2086402, 'last20_m_star': 0.6061935, 'last10_m_star': 0.5531671, 'scatter_v_disk': 0.09547214, 'lowest_v_disk': 0.066812225, 'last20_v_disk': 0.11512552, 'last10_v_disk': 0.11474775, 'scatter_m_cold': 0.5351472, 'lowest_m_cold': 0.53453606, 'last20_m_cold': 0.53527135, 'last10_m_cold': 0.5351804, 'scatter_sfr_100': 0.6134583, 'lowest_sfr_100': 0.49756542, 'last20_sfr_100': 0.74357736, 'last10_sfr_100': 0.70037764}
Finished 1/1
Exited training after None epochs
Experiment 4 done: 4 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 256]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 256, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat256'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_uhwbii
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [01:03<8:44:18, 63.04s/it]  0%|          | 2/500 [02:34<11:00:07, 79.53s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 9.34E+07, Train scatter: [0.9352 0.1317 0.5441 0.9955]
L1 regularization loss: 2.45E+00, L2 regularization loss: 4.24E-01
Test scatter: [0.9195 0.1286 0.5355 0.9852], Lowest was [0.9195 0.1286 0.5355 0.9852]
Median for last 10 epochs: [0.9195 0.1286 0.5355 0.9852], Epochs since improvement 2
  1%|          | 3/500 [03:36<9:54:58, 71.83s/it]   1%|          | 4/500 [05:10<11:04:40, 80.40s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.02E+07, Train scatter: [0.9324 0.1039 0.5439 0.9955]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.29E-01
Test scatter: [0.9167 0.1016 0.5353 0.9851], Lowest was [0.9167 0.1016 0.5353 0.9851]
Median for last 10 epochs: [0.9167 0.1016 0.5353 0.9851], Epochs since improvement 0
  1%|          | 5/500 [06:12<10:09:46, 73.91s/it]  1%|          | 6/500 [07:45<11:01:28, 80.34s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 9.87E+07, Train scatter: [0.9352 0.1616 0.5439 0.9954]
L1 regularization loss: 2.50E+00, L2 regularization loss: 4.39E-01
Test scatter: [0.9196 0.1556 0.5353 0.9851], Lowest was [0.9167 0.1016 0.5353 0.9851]
Median for last 10 epochs: [0.9167 0.1016 0.5353 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [08:49<10:16:26, 75.02s/it]  2%|▏         | 8/500 [10:20<10:57:21, 80.17s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.46E+07, Train scatter: [0.9348 0.1108 0.5386 0.9955]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.56E-01
Test scatter: [0.9192 0.1092 0.5299 0.9851], Lowest was [0.9167 0.1016 0.5299 0.9851]
Median for last 10 epochs: [0.918  0.1054 0.5326 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [11:23<10:12:33, 74.85s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.78E+07, Train scatter: [0.6549 0.1022 0.4283 0.9954]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.77E-01
Test scatter: [0.6471 0.1049 0.4232 0.9851], Lowest was [0.6471 0.1016 0.4232 0.9851]
Median for last 10 epochs: [0.9167 0.1049 0.5299 0.9851], Epochs since improvement 0
  2%|▏         | 10/500 [13:02<11:11:24, 82.21s/it]  2%|▏         | 11/500 [14:06<10:24:38, 76.64s/it]  2%|▏         | 12/500 [15:39<11:03:10, 81.54s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.44E+07, Train scatter: [0.5128 0.0933 0.3874 0.9954]
L1 regularization loss: 2.56E+00, L2 regularization loss: 4.88E-01
Test scatter: [0.5176 0.0947 0.3858 0.9851], Lowest was [0.5176 0.0947 0.3858 0.9851]
Median for last 10 epochs: [0.9167 0.1049 0.5299 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [16:42<10:17:12, 76.04s/it]  3%|▎         | 14/500 [18:14<10:53:34, 80.69s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.26E+07, Train scatter: [0.371  0.0859 0.3583 0.9954]
L1 regularization loss: 2.57E+00, L2 regularization loss: 4.96E-01
Test scatter: [0.3894 0.0873 0.3565 0.985 ], Lowest was [0.3894 0.0873 0.3565 0.985 ]
Median for last 10 epochs: [0.6471 0.1049 0.4232 0.9851], Epochs since improvement 0
  3%|▎         | 15/500 [19:19<10:14:03, 75.97s/it]  3%|▎         | 16/500 [20:50<10:49:14, 80.48s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.03E+07, Train scatter: [0.3232 0.0798 0.3308 0.9953]
L1 regularization loss: 2.58E+00, L2 regularization loss: 5.04E-01
Test scatter: [0.3361 0.0809 0.3344 0.985 ], Lowest was [0.3361 0.0809 0.3344 0.985 ]
Median for last 10 epochs: [0.5176 0.0947 0.3858 0.9851], Epochs since improvement 0
  3%|▎         | 17/500 [21:54<10:07:53, 75.51s/it]  4%|▎         | 18/500 [23:26<10:47:30, 80.60s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 4.57E+07, Train scatter: [0.342  0.0794 0.3536 0.9825]
L1 regularization loss: 2.59E+00, L2 regularization loss: 5.15E-01
Test scatter: [0.3506 0.0789 0.3506 0.9738], Lowest was [0.3361 0.0789 0.3344 0.9738]
Median for last 10 epochs: [0.3894 0.0873 0.3565 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [24:28<10:00:36, 74.92s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 5.57E+06, Train scatter: [0.3277 0.0762 0.3318 0.6235]
L1 regularization loss: 2.61E+00, L2 regularization loss: 5.28E-01
Test scatter: [0.3367 0.0763 0.3347 0.6294], Lowest was [0.3361 0.0763 0.3344 0.6294]
Median for last 10 epochs: [0.3506 0.0809 0.3506 0.985 ], Epochs since improvement 0
  4%|▍         | 20/500 [26:07<10:58:44, 82.34s/it]  4%|▍         | 21/500 [27:11<10:11:44, 76.63s/it]  4%|▍         | 22/500 [28:43<10:48:33, 81.41s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 4.03E+06, Train scatter: [0.26   0.074  0.3255 0.528 ]
L1 regularization loss: 2.63E+00, L2 regularization loss: 5.38E-01
Test scatter: [0.2666 0.0746 0.3319 0.5284], Lowest was [0.2666 0.0746 0.3319 0.5284]
Median for last 10 epochs: [0.3367 0.0789 0.3347 0.9738], Epochs since improvement 0
  5%|▍         | 23/500 [29:45<9:59:14, 75.38s/it]   5%|▍         | 24/500 [31:17<10:37:29, 80.36s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 3.49E+06, Train scatter: [0.2682 0.073  0.3131 0.5296]
L1 regularization loss: 2.64E+00, L2 regularization loss: 5.47E-01
Test scatter: [0.2742 0.0731 0.3178 0.5295], Lowest was [0.2666 0.0731 0.3178 0.5284]
Median for last 10 epochs: [0.3361 0.0763 0.3344 0.6294], Epochs since improvement 0
  5%|▌         | 25/500 [32:19<9:53:18, 74.94s/it]   5%|▌         | 26/500 [33:52<10:34:01, 80.26s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 3.21E+06, Train scatter: [0.231  0.0693 0.2966 0.4936]
L1 regularization loss: 2.66E+00, L2 regularization loss: 5.56E-01
Test scatter: [0.2348 0.0698 0.3013 0.494 ], Lowest was [0.2348 0.0698 0.3013 0.494 ]
Median for last 10 epochs: [0.2742 0.0746 0.3319 0.5295], Epochs since improvement 0
  5%|▌         | 27/500 [34:53<9:47:43, 74.55s/it]   6%|▌         | 28/500 [36:26<10:31:34, 80.29s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 3.18E+06, Train scatter: [0.2241 0.069  0.2941 0.4855]
L1 regularization loss: 2.68E+00, L2 regularization loss: 5.66E-01
Test scatter: [0.2301 0.0693 0.2985 0.4867], Lowest was [0.2301 0.0693 0.2985 0.4867]
Median for last 10 epochs: [0.2666 0.0731 0.3178 0.5284], Epochs since improvement 0
  6%|▌         | 29/500 [37:31<9:53:38, 75.62s/it] Epoch: 30 done with learning rate 3.72E-03, Train loss: 2.93E+06, Train scatter: [0.2959 0.0794 0.3477 0.5272]
L1 regularization loss: 2.70E+00, L2 regularization loss: 5.77E-01
Test scatter: [0.3091 0.0802 0.3517 0.5375], Lowest was [0.2301 0.0693 0.2985 0.4867]
Median for last 10 epochs: [0.2666 0.0731 0.3178 0.5284], Epochs since improvement 2
  6%|▌         | 30/500 [39:12<10:50:46, 83.08s/it]  6%|▌         | 31/500 [40:14<10:01:25, 76.94s/it]  6%|▋         | 32/500 [41:48<10:38:35, 81.87s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 2.80E+06, Train scatter: [0.251  0.0663 0.297  0.4844]
L1 regularization loss: 2.72E+00, L2 regularization loss: 5.91E-01
Test scatter: [0.2552 0.0665 0.2991 0.4855], Lowest was [0.2301 0.0665 0.2985 0.4855]
Median for last 10 epochs: [0.2552 0.0698 0.3013 0.494 ], Epochs since improvement 0
  7%|▋         | 33/500 [42:51<9:53:22, 76.24s/it]   7%|▋         | 34/500 [44:22<10:26:29, 80.66s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 2.73E+06, Train scatter: [0.2298 0.0671 0.3099 0.4682]
L1 regularization loss: 2.75E+00, L2 regularization loss: 6.07E-01
Test scatter: [0.2321 0.0667 0.3106 0.469 ], Lowest was [0.2301 0.0665 0.2985 0.469 ]
Median for last 10 epochs: [0.2348 0.0693 0.3013 0.4867], Epochs since improvement 0
  7%|▋         | 35/500 [45:26<9:45:48, 75.59s/it]   7%|▋         | 36/500 [46:59<10:26:21, 80.99s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 2.77E+06, Train scatter: [0.2387 0.0652 0.2997 0.4665]
L1 regularization loss: 2.77E+00, L2 regularization loss: 6.26E-01
Test scatter: [0.2463 0.0651 0.3021 0.4624], Lowest was [0.2301 0.0651 0.2985 0.4624]
Median for last 10 epochs: [0.2463 0.0667 0.3021 0.4855], Epochs since improvement 0
  7%|▋         | 37/500 [48:04<9:46:45, 76.04s/it]   8%|▊         | 38/500 [49:38<10:27:38, 81.51s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 2.70E+06, Train scatter: [0.2145 0.0629 0.284  0.458 ]
L1 regularization loss: 2.80E+00, L2 regularization loss: 6.43E-01
Test scatter: [0.2207 0.0632 0.2873 0.4582], Lowest was [0.2207 0.0632 0.2873 0.4582]
Median for last 10 epochs: [0.2463 0.0665 0.3021 0.469 ], Epochs since improvement 0
  8%|▊         | 39/500 [50:41<9:44:29, 76.07s/it] Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.49E+06, Train scatter: [0.273  0.0636 0.2816 0.4738]
L1 regularization loss: 2.83E+00, L2 regularization loss: 6.64E-01
Test scatter: [0.2816 0.065  0.288  0.4804], Lowest was [0.2207 0.0632 0.2873 0.4582]
Median for last 10 epochs: [0.2463 0.0651 0.2991 0.469 ], Epochs since improvement 2
  8%|▊         | 40/500 [52:23<10:41:41, 83.70s/it]  8%|▊         | 41/500 [53:27<9:55:04, 77.79s/it]   8%|▊         | 42/500 [55:00<10:28:11, 82.30s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 2.38E+06, Train scatter: [0.2216 0.0626 0.2869 0.4515]
L1 regularization loss: 2.87E+00, L2 regularization loss: 6.86E-01
Test scatter: [0.232  0.0647 0.2891 0.4557], Lowest was [0.2207 0.0632 0.2873 0.4557]
Median for last 10 epochs: [0.2321 0.065  0.2891 0.4624], Epochs since improvement 0
  9%|▊         | 43/500 [56:03<9:44:15, 76.71s/it]   9%|▉         | 44/500 [57:35<10:16:32, 81.12s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 2.41E+06, Train scatter: [0.2547 0.0639 0.2902 0.4649]
L1 regularization loss: 2.93E+00, L2 regularization loss: 7.20E-01
Test scatter: [0.2688 0.0641 0.2951 0.4684], Lowest was [0.2207 0.0632 0.2873 0.4557]
Median for last 10 epochs: [0.2463 0.0647 0.2891 0.4624], Epochs since improvement 2
  9%|▉         | 45/500 [58:36<9:30:50, 75.28s/it]   9%|▉         | 46/500 [1:00:09<10:08:33, 80.43s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 2.17E+06, Train scatter: [0.2175 0.0588 0.2746 0.4546]
L1 regularization loss: 2.97E+00, L2 regularization loss: 7.45E-01
Test scatter: [0.2308 0.0592 0.2785 0.4554], Lowest was [0.2207 0.0592 0.2785 0.4554]
Median for last 10 epochs: [0.232  0.0641 0.288  0.4582], Epochs since improvement 0
  9%|▉         | 47/500 [1:01:12<9:29:07, 75.38s/it]  10%|▉         | 48/500 [1:02:43<10:03:16, 80.08s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 2.04E+06, Train scatter: [0.282  0.1119 0.3335 1.7692]
L1 regularization loss: 3.02E+00, L2 regularization loss: 7.79E-01
Test scatter: [0.2841 0.1101 0.3358 3.4912], Lowest was [0.2207 0.0592 0.2785 0.4554]
Median for last 10 epochs: [0.2688 0.0647 0.2891 0.4684], Epochs since improvement 2
 10%|▉         | 49/500 [1:03:46<9:22:42, 74.86s/it] Epoch: 50 done with learning rate 7.60E-03, Train loss: 1.94E+06, Train scatter: [0.2056 0.0572 0.2697 0.4492]
L1 regularization loss: 3.08E+00, L2 regularization loss: 8.24E-01
Test scatter: [0.2446 0.0575 0.2776 0.4469], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.2446 0.0641 0.2891 0.4557], Epochs since improvement 0
 10%|█         | 50/500 [1:05:28<10:23:22, 83.12s/it] 10%|█         | 51/500 [1:06:31<9:36:30, 77.04s/it]  10%|█         | 52/500 [1:08:02<10:04:57, 81.02s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 8.18E+06, Train scatter: [0.9343 0.1728 0.5438 0.9584]
L1 regularization loss: 4.10E+00, L2 regularization loss: 1.21E+00
Test scatter: [0.9186 0.1689 0.5354 0.9517], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.2688 0.0641 0.2951 0.4684], Epochs since improvement 2
 11%|█         | 53/500 [1:09:04<9:22:58, 75.57s/it]  11%|█         | 54/500 [1:10:36<9:58:02, 80.45s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 5.99E+06, Train scatter: [0.6264 0.1084 0.5385 0.7095]
L1 regularization loss: 4.19E+00, L2 regularization loss: 1.32E+00
Test scatter: [0.6229 0.1095 0.5308 0.7058], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.2841 0.1095 0.3358 0.7058], Epochs since improvement 4
 11%|█         | 55/500 [1:11:39<9:18:04, 75.25s/it] 11%|█         | 56/500 [1:13:10<9:51:52, 79.98s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 4.78E+06, Train scatter: [0.5692 0.0994 0.5595 0.6733]
L1 regularization loss: 4.21E+00, L2 regularization loss: 1.36E+00
Test scatter: [0.5692 0.098  0.5925 0.6718], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.5692 0.1095 0.5308 0.7058], Epochs since improvement 6
 11%|█▏        | 57/500 [1:14:13<9:12:42, 74.86s/it] 12%|█▏        | 58/500 [1:15:46<9:49:43, 80.05s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 3.83E+06, Train scatter: [0.4985 0.0915 0.4963 0.6159]
L1 regularization loss: 4.24E+00, L2 regularization loss: 1.44E+00
Test scatter: [0.4904 0.0928 0.4977 0.6163], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.5692 0.098  0.5308 0.6718], Epochs since improvement 8
 12%|█▏        | 59/500 [1:16:49<9:11:30, 75.03s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 3.14E+06, Train scatter: [0.4604 0.085  0.4768 0.6042]
L1 regularization loss: 4.27E+00, L2 regularization loss: 1.50E+00
Test scatter: [0.4629 0.0849 0.4937 0.6114], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.5692 0.098  0.5308 0.6718], Epochs since improvement 10
 12%|█▏        | 60/500 [1:18:27<10:01:28, 82.02s/it] 12%|█▏        | 61/500 [1:19:31<9:20:46, 76.64s/it]  12%|█▏        | 62/500 [1:21:03<9:51:46, 81.06s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 2.74E+06, Train scatter: [0.3736 0.0785 0.4881 0.5548]
L1 regularization loss: 4.29E+00, L2 regularization loss: 1.56E+00
Test scatter: [0.3945 0.0797 0.4855 0.5565], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.4904 0.0928 0.4977 0.6163], Epochs since improvement 12
 13%|█▎        | 63/500 [1:22:06<9:10:36, 75.60s/it] 13%|█▎        | 64/500 [1:23:38<9:46:41, 80.74s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 2.26E+06, Train scatter: [0.3734 0.0781 0.4041 0.531 ]
L1 regularization loss: 4.33E+00, L2 regularization loss: 1.61E+00
Test scatter: [0.3741 0.0774 0.4023 0.5364], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.4629 0.0849 0.4937 0.6114], Epochs since improvement 14
 13%|█▎        | 65/500 [1:24:41<9:05:42, 75.27s/it] 13%|█▎        | 66/500 [1:26:13<9:40:20, 80.23s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 2.06E+06, Train scatter: [0.341  0.0738 0.3986 0.5159]
L1 regularization loss: 4.34E+00, L2 regularization loss: 1.65E+00
Test scatter: [0.3472 0.074  0.3964 0.5193], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.3945 0.0797 0.4855 0.5565], Epochs since improvement 16
 13%|█▎        | 67/500 [1:27:16<9:02:20, 75.15s/it] 14%|█▎        | 68/500 [1:28:46<9:34:09, 79.74s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 2.09E+06, Train scatter: [0.3593 0.0778 0.3909 0.5343]
L1 regularization loss: 4.34E+00, L2 regularization loss: 1.67E+00
Test scatter: [0.3512 0.0765 0.3895 0.5386], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.3741 0.0774 0.4023 0.5386], Epochs since improvement 18
 14%|█▍        | 69/500 [1:29:48<8:53:56, 74.33s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 1.99E+06, Train scatter: [0.3053 0.0717 0.3956 0.512 ]
L1 regularization loss: 4.34E+00, L2 regularization loss: 1.69E+00
Test scatter: [0.3094 0.0728 0.3923 0.5146], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.3512 0.0765 0.3964 0.5364], Epochs since improvement 20
 14%|█▍        | 70/500 [1:31:26<9:44:27, 81.55s/it] 14%|█▍        | 71/500 [1:32:31<9:06:19, 76.41s/it] 14%|█▍        | 71/500 [1:34:04<9:28:26, 79.50s/it]
Epoch: 72 done with learning rate 9.96E-03, Train loss: 1.63E+06, Train scatter: [0.3215 0.0706 0.3952 0.5038]
L1 regularization loss: 4.36E+00, L2 regularization loss: 1.74E+00
Test scatter: [0.3305 0.0714 0.3925 0.5071], Lowest was [0.2207 0.0575 0.2776 0.4469]
Median for last 10 epochs: [0.3472 0.074  0.3925 0.5193], Epochs since improvement 22
Exited after 72 epochs due to early stopping
5644.74 seconds spent training, 11.289 seconds per epoch. Processed 6168 trees per second
[0.3304415  0.07144425 0.3924591  0.5070968 ]
{'epoch_exit': 71, 'scatter_m_star': 0.3304415, 'lowest_m_star': 0.22072524, 'last20_m_star': 0.3842976, 'last10_m_star': 0.34715524, 'scatter_v_disk': 0.07144425, 'lowest_v_disk': 0.057509813, 'last20_v_disk': 0.078535624, 'last10_v_disk': 0.07395743, 'scatter_m_cold': 0.3924591, 'lowest_m_cold': 0.27758595, 'last20_m_cold': 0.44393373, 'last10_m_cold': 0.39247063, 'scatter_sfr_100': 0.5070968, 'lowest_sfr_100': 0.44693568, 'last20_sfr_100': 0.547519, 'last10_sfr_100': 0.51933545}
Finished 1/1
Exited training after None epochs
Experiment 5 done: 5 / 6
Exploring ['conv_layers', 'batch_size']
Currently doing [  3 512]
{'experiment': 'GraphMerge', 'group': 'meta_pysr', 'move': False, 'model': 'MetaEdge', 'log': True, 'run_params': {'n_epochs': 500, 'n_trials': 1, 'batch_size': 512, 'val_epoch': 2, 'early_stopping': True, 'patience': 20, 'l1_lambda': 0.0001, 'l2_lambda': 0.0001, 'loss_func': 'GaussNd', 'metrics': 'test_multi_varrho', 'performance_plot': 'multi_base', 'save': True, 'seed': True, 'num_workers': 4}, 'learn_params': {'learning_rate': 0.01, 'schedule': 'onecycle', 'g_up': 1, 'g_down': 0.95, 'warmup': 4, 'period': 5, 'eta_min': 1e-05}, 'hyper_params': {'hidden_channels': 128, 'conv_layers': 3, 'conv_activation': 'relu', 'decode_activation': 'leakyrelu', 'decode_layers': 2, 'layernorm': True, 'agg': 'sum', 'variance': True, 'rho': 0, 'in_channels': 43, 'out_channels': 4}, 'data_params': {'case': 'vlarge_all_4t_z0.0_quantile_raw', 'targets': [0, 1, 2, 3], 'del_feats': [], 'split': 0.8, 'test': 0, 'scale': 0}, 'experiment_name': 'con3bat512'}
/home/cj1223/../../scratch/gpfs/cj1223/GraphResults/results_meta_pysr_120322/MetaEdge_vlarge_all_4t_z0.0_quantile_raw_xkoveg
RelU conv activation
LeakyRelU decode activation
N_params 546504
Made folder for saving model
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:55<7:38:05, 55.08s/it]  0%|          | 2/500 [02:16<9:46:30, 70.66s/it]Epoch: 2 done with learning rate 4.17E-04, Train loss: 1.19E+08, Train scatter: [0.9352 0.1732 0.5441 0.9953]
L1 regularization loss: 2.44E+00, L2 regularization loss: 4.23E-01
Test scatter: [0.9196 0.1678 0.5355 0.985 ], Lowest was [0.9196 0.1678 0.5355 0.985 ]
Median for last 10 epochs: [0.9196 0.1678 0.5355 0.985 ], Epochs since improvement 2
  1%|          | 3/500 [03:10<8:41:24, 62.95s/it]  1%|          | 4/500 [04:32<9:43:59, 70.64s/it]Epoch: 4 done with learning rate 4.67E-04, Train loss: 8.74E+07, Train scatter: [0.9352 0.1319 0.5441 0.9954]
L1 regularization loss: 2.46E+00, L2 regularization loss: 4.25E-01
Test scatter: [0.9195 0.127  0.5355 0.9851], Lowest was [0.9195 0.127  0.5355 0.985 ]
Median for last 10 epochs: [0.9195 0.127  0.5355 0.9851], Epochs since improvement 0
  1%|          | 5/500 [05:27<8:55:49, 64.95s/it]  1%|          | 6/500 [06:49<9:40:55, 70.56s/it]Epoch: 6 done with learning rate 5.51E-04, Train loss: 8.28E+07, Train scatter: [0.9348 0.1096 0.5441 0.9954]
L1 regularization loss: 2.47E+00, L2 regularization loss: 4.28E-01
Test scatter: [0.9192 0.1086 0.5355 0.9851], Lowest was [0.9192 0.1086 0.5355 0.985 ]
Median for last 10 epochs: [0.9192 0.1086 0.5355 0.9851], Epochs since improvement 0
  1%|▏         | 7/500 [07:43<8:56:46, 65.33s/it]  2%|▏         | 8/500 [09:06<9:40:52, 70.84s/it]Epoch: 8 done with learning rate 6.67E-04, Train loss: 8.01E+07, Train scatter: [0.9268 0.0982 0.544  0.9954]
L1 regularization loss: 2.48E+00, L2 regularization loss: 4.33E-01
Test scatter: [0.9109 0.0964 0.5354 0.9851], Lowest was [0.9109 0.0964 0.5354 0.985 ]
Median for last 10 epochs: [0.915  0.1025 0.5355 0.9851], Epochs since improvement 0
  2%|▏         | 9/500 [10:00<8:56:17, 65.53s/it]Epoch: 10 done with learning rate 8.15E-04, Train loss: 7.84E+07, Train scatter: [0.7794 0.0888 0.5439 0.9953]
L1 regularization loss: 2.49E+00, L2 regularization loss: 4.39E-01
Test scatter: [0.7705 0.0885 0.5354 0.985 ], Lowest was [0.7705 0.0885 0.5354 0.985 ]
Median for last 10 epochs: [0.9109 0.0964 0.5354 0.9851], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  2%|▏         | 10/500 [11:27<9:49:28, 72.18s/it]  2%|▏         | 11/500 [12:22<9:05:11, 66.89s/it]  2%|▏         | 12/500 [13:43<9:38:32, 71.13s/it]Epoch: 12 done with learning rate 9.94E-04, Train loss: 7.74E+07, Train scatter: [0.6352 0.0859 0.5438 0.9953]
L1 regularization loss: 2.50E+00, L2 regularization loss: 4.48E-01
Test scatter: [0.6285 0.0848 0.5352 0.9849], Lowest was [0.6285 0.0848 0.5352 0.9849]
Median for last 10 epochs: [0.9109 0.0964 0.5354 0.9851], Epochs since improvement 0
  3%|▎         | 13/500 [14:37<8:57:11, 66.18s/it]  3%|▎         | 14/500 [15:57<9:29:29, 70.31s/it]Epoch: 14 done with learning rate 1.20E-03, Train loss: 7.59E+07, Train scatter: [0.5416 0.0839 0.5428 0.9953]
L1 regularization loss: 2.52E+00, L2 regularization loss: 4.56E-01
Test scatter: [0.5366 0.0835 0.5344 0.985 ], Lowest was [0.5366 0.0835 0.5344 0.9849]
Median for last 10 epochs: [0.7705 0.0885 0.5354 0.985 ], Epochs since improvement 0
  3%|▎         | 15/500 [16:51<8:49:10, 65.46s/it]  3%|▎         | 16/500 [18:12<9:24:42, 70.01s/it]Epoch: 16 done with learning rate 1.44E-03, Train loss: 7.50E+07, Train scatter: [0.5235 0.0825 0.5348 0.9953]
L1 regularization loss: 2.53E+00, L2 regularization loss: 4.63E-01
Test scatter: [0.5206 0.0813 0.5271 0.985 ], Lowest was [0.5206 0.0813 0.5271 0.9849]
Median for last 10 epochs: [0.6285 0.0848 0.5352 0.985 ], Epochs since improvement 0
  3%|▎         | 17/500 [19:07<8:46:31, 65.41s/it]  4%|▎         | 18/500 [20:29<9:25:53, 70.44s/it]Epoch: 18 done with learning rate 1.70E-03, Train loss: 7.45E+07, Train scatter: [0.5578 0.0837 0.5265 0.9952]
L1 regularization loss: 2.54E+00, L2 regularization loss: 4.68E-01
Test scatter: [0.537  0.0833 0.52   0.9849], Lowest was [0.5206 0.0813 0.52   0.9849]
Median for last 10 epochs: [0.537  0.0835 0.5344 0.985 ], Epochs since improvement 0
  4%|▍         | 19/500 [21:22<8:42:56, 65.23s/it]Epoch: 20 done with learning rate 1.99E-03, Train loss: 7.43E+07, Train scatter: [0.4986 0.0904 0.5432 0.9954]
L1 regularization loss: 2.55E+00, L2 regularization loss: 4.73E-01
Test scatter: [0.5095 0.0883 0.5347 0.985 ], Lowest was [0.5095 0.0813 0.52   0.9849]
Median for last 10 epochs: [0.5366 0.0835 0.5344 0.985 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  4%|▍         | 20/500 [22:49<9:34:14, 71.78s/it]  4%|▍         | 21/500 [23:43<8:51:10, 66.53s/it]  4%|▍         | 22/500 [25:04<9:24:52, 70.90s/it]Epoch: 22 done with learning rate 2.30E-03, Train loss: 7.37E+07, Train scatter: [0.4385 0.0806 0.5205 0.9953]
L1 regularization loss: 2.56E+00, L2 regularization loss: 4.79E-01
Test scatter: [0.4294 0.0792 0.5131 0.985 ], Lowest was [0.4294 0.0792 0.5131 0.9849]
Median for last 10 epochs: [0.5206 0.0833 0.5271 0.985 ], Epochs since improvement 0
  5%|▍         | 23/500 [25:58<8:43:28, 65.84s/it]  5%|▍         | 24/500 [27:19<9:18:12, 70.36s/it]Epoch: 24 done with learning rate 2.63E-03, Train loss: 7.25E+07, Train scatter: [0.5559 0.0887 0.3896 0.9953]
L1 regularization loss: 2.58E+00, L2 regularization loss: 4.88E-01
Test scatter: [0.5471 0.0872 0.389  0.9849], Lowest was [0.4294 0.0792 0.389  0.9849]
Median for last 10 epochs: [0.5206 0.0833 0.52   0.985 ], Epochs since improvement 0
  5%|▌         | 25/500 [28:13<8:36:54, 65.29s/it]  5%|▌         | 26/500 [29:34<9:13:33, 70.07s/it]Epoch: 26 done with learning rate 2.98E-03, Train loss: 7.34E+07, Train scatter: [0.5073 0.0932 0.5235 0.9953]
L1 regularization loss: 2.60E+00, L2 regularization loss: 4.99E-01
Test scatter: [0.5044 0.0921 0.5146 0.985 ], Lowest was [0.4294 0.0792 0.389  0.9849]
Median for last 10 epochs: [0.5095 0.0872 0.5146 0.985 ], Epochs since improvement 2
  5%|▌         | 27/500 [30:28<8:34:36, 65.28s/it]  6%|▌         | 28/500 [31:48<9:08:33, 69.73s/it]Epoch: 28 done with learning rate 3.34E-03, Train loss: 7.20E+07, Train scatter: [0.7842 0.1329 0.5442 0.9954]
L1 regularization loss: 2.62E+00, L2 regularization loss: 5.09E-01
Test scatter: [0.7952 0.1286 0.5356 0.9851], Lowest was [0.4294 0.0792 0.389  0.9849]
Median for last 10 epochs: [0.5095 0.0883 0.5146 0.985 ], Epochs since improvement 4
  6%|▌         | 29/500 [32:43<8:31:33, 65.17s/it]Epoch: 30 done with learning rate 3.72E-03, Train loss: 7.16E+07, Train scatter: [0.5462 0.0918 0.4111 0.9953]
L1 regularization loss: 2.66E+00, L2 regularization loss: 5.22E-01
Test scatter: [0.5426 0.0904 0.4108 0.9849], Lowest was [0.4294 0.0792 0.389  0.9849]
Median for last 10 epochs: [0.5426 0.0904 0.5131 0.985 ], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  6%|▌         | 30/500 [34:11<9:25:37, 72.21s/it]  6%|▌         | 31/500 [35:05<8:41:48, 66.76s/it]  6%|▋         | 32/500 [36:26<9:12:57, 70.89s/it]Epoch: 32 done with learning rate 4.10E-03, Train loss: 7.10E+07, Train scatter: [0.5825 0.0819 0.4341 0.9954]
L1 regularization loss: 2.68E+00, L2 regularization loss: 5.32E-01
Test scatter: [0.5796 0.0815 0.4264 0.9851], Lowest was [0.4294 0.0792 0.389  0.9849]
Median for last 10 epochs: [0.5471 0.0904 0.4264 0.985 ], Epochs since improvement 8
  7%|▋         | 33/500 [37:19<8:31:10, 65.68s/it]  7%|▋         | 34/500 [38:41<9:06:47, 70.40s/it]Epoch: 34 done with learning rate 4.50E-03, Train loss: 7.02E+07, Train scatter: [0.556  0.0796 0.3301 0.9954]
L1 regularization loss: 2.70E+00, L2 regularization loss: 5.41E-01
Test scatter: [0.5586 0.0799 0.3295 0.985 ], Lowest was [0.4294 0.0792 0.3295 0.9849]
Median for last 10 epochs: [0.5586 0.0904 0.4264 0.985 ], Epochs since improvement 0
  7%|▋         | 35/500 [39:34<8:25:49, 65.27s/it]  7%|▋         | 36/500 [40:56<9:02:56, 70.21s/it]Epoch: 36 done with learning rate 4.90E-03, Train loss: 6.96E+07, Train scatter: [0.5167 0.0824 0.3118 0.9954]
L1 regularization loss: 2.72E+00, L2 regularization loss: 5.49E-01
Test scatter: [0.5208 0.0834 0.3138 0.985 ], Lowest was [0.4294 0.0792 0.3138 0.9849]
Median for last 10 epochs: [0.5586 0.0834 0.4108 0.985 ], Epochs since improvement 0
  7%|▋         | 37/500 [41:49<8:22:05, 65.07s/it]  8%|▊         | 38/500 [43:10<8:57:57, 69.87s/it]Epoch: 38 done with learning rate 5.30E-03, Train loss: 6.76E+07, Train scatter: [2.5037 0.1556 0.3923 0.995 ]
L1 regularization loss: 2.73E+00, L2 regularization loss: 5.61E-01
Test scatter: [2.7091 0.1662 0.3989 0.9847], Lowest was [0.4294 0.0792 0.3138 0.9847]
Median for last 10 epochs: [0.5586 0.0834 0.3989 0.985 ], Epochs since improvement 0
  8%|▊         | 39/500 [44:03<8:18:26, 64.87s/it]Epoch: 40 done with learning rate 5.70E-03, Train loss: 2.97E+07, Train scatter: [0.8942 0.1574 0.5437 0.9954]
L1 regularization loss: 2.79E+00, L2 regularization loss: 5.89E-01
Test scatter: [0.8748 0.1529 0.5351 0.9851], Lowest was [0.4294 0.0792 0.3138 0.9847]
Median for last 10 epochs: [0.5796 0.0834 0.3989 0.985 ], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
  8%|▊         | 40/500 [45:32<9:12:16, 72.04s/it]  8%|▊         | 41/500 [46:26<8:29:29, 66.60s/it]  8%|▊         | 42/500 [47:46<8:59:43, 70.71s/it]Epoch: 42 done with learning rate 6.10E-03, Train loss: 1.27E+07, Train scatter: [0.608  0.1166 0.536  0.95  ]
L1 regularization loss: 2.82E+00, L2 regularization loss: 6.12E-01
Test scatter: [0.5906 0.1141 0.5276 0.9376], Lowest was [0.4294 0.0792 0.3138 0.9376]
Median for last 10 epochs: [0.5906 0.1141 0.3989 0.985 ], Epochs since improvement 0
  9%|▊         | 43/500 [48:40<8:19:05, 65.53s/it]  9%|▉         | 44/500 [50:01<8:53:54, 70.25s/it]Epoch: 44 done with learning rate 6.49E-03, Train loss: 5.35E+06, Train scatter: [0.4873 0.084  0.3608 0.6144]
L1 regularization loss: 2.90E+00, L2 regularization loss: 6.61E-01
Test scatter: [0.4859 0.0826 0.359  0.6054], Lowest was [0.4294 0.0792 0.3138 0.6054]
Median for last 10 epochs: [0.5906 0.1141 0.3989 0.9847], Epochs since improvement 0
  9%|▉         | 45/500 [50:54<8:14:17, 65.18s/it]  9%|▉         | 46/500 [52:14<8:45:11, 69.41s/it]Epoch: 46 done with learning rate 6.87E-03, Train loss: 4.46E+06, Train scatter: [0.4701 0.0828 0.3669 0.5976]
L1 regularization loss: 2.94E+00, L2 regularization loss: 6.93E-01
Test scatter: [0.4654 0.0816 0.3637 0.594 ], Lowest was [0.4294 0.0792 0.3138 0.594 ]
Median for last 10 epochs: [0.5906 0.1141 0.3989 0.9376], Epochs since improvement 0
  9%|▉         | 47/500 [53:08<8:09:35, 64.85s/it] 10%|▉         | 48/500 [54:29<8:44:28, 69.62s/it]Epoch: 48 done with learning rate 7.24E-03, Train loss: 3.96E+06, Train scatter: [0.4317 0.0772 0.3235 0.529 ]
L1 regularization loss: 2.99E+00, L2 regularization loss: 7.32E-01
Test scatter: [0.4258 0.0764 0.3241 0.5275], Lowest was [0.4258 0.0764 0.3138 0.5275]
Median for last 10 epochs: [0.4859 0.0826 0.3637 0.6054], Epochs since improvement 0
 10%|▉         | 49/500 [55:22<8:07:21, 64.84s/it]Epoch: 50 done with learning rate 7.60E-03, Train loss: 3.62E+06, Train scatter: [0.4209 0.0785 0.3229 0.5175]
L1 regularization loss: 3.04E+00, L2 regularization loss: 7.75E-01
Test scatter: [0.4194 0.0772 0.3245 0.5128], Lowest was [0.4194 0.0764 0.3138 0.5128]
Median for last 10 epochs: [0.4654 0.0816 0.359  0.594 ], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 10%|█         | 50/500 [56:50<8:57:52, 71.72s/it] 10%|█         | 51/500 [57:45<8:18:19, 66.59s/it] 10%|█         | 52/500 [59:06<8:50:29, 71.05s/it]Epoch: 52 done with learning rate 7.94E-03, Train loss: 6.76E+06, Train scatter: [0.9061 0.1705 0.5439 0.9895]
L1 regularization loss: 3.25E+00, L2 regularization loss: 8.91E-01
Test scatter: [0.8871 0.1666 0.5353 0.9792], Lowest was [0.4194 0.0764 0.3138 0.5128]
Median for last 10 epochs: [0.4654 0.0816 0.359  0.594 ], Epochs since improvement 2
 11%|█         | 53/500 [59:59<8:09:32, 65.71s/it] 11%|█         | 54/500 [1:01:19<8:39:59, 69.95s/it]Epoch: 54 done with learning rate 8.26E-03, Train loss: 1.27E+07, Train scatter: [0.6869 0.1529 0.5423 0.8883]
L1 regularization loss: 3.33E+00, L2 regularization loss: 9.47E-01
Test scatter: [0.6842 0.15   0.5338 0.883 ], Lowest was [0.4194 0.0764 0.3138 0.5128]
Median for last 10 epochs: [0.4654 0.0816 0.3637 0.594 ], Epochs since improvement 4
 11%|█         | 55/500 [1:02:13<8:02:16, 65.03s/it] 11%|█         | 56/500 [1:03:34<8:36:52, 69.85s/it]Epoch: 56 done with learning rate 8.56E-03, Train loss: 9.41E+06, Train scatter: [0.5867 0.1223 0.5224 0.7325]
L1 regularization loss: 3.38E+00, L2 regularization loss: 1.02E+00
Test scatter: [0.6055 0.1202 0.5148 0.7223], Lowest was [0.4194 0.0764 0.3138 0.5128]
Median for last 10 epochs: [0.6055 0.1202 0.5148 0.7223], Epochs since improvement 6
 11%|█▏        | 57/500 [1:04:27<7:58:37, 64.82s/it] 12%|█▏        | 58/500 [1:05:47<8:30:19, 69.27s/it]Epoch: 58 done with learning rate 8.83E-03, Train loss: 6.57E+06, Train scatter: [0.5107 0.1061 0.4989 0.6596]
L1 regularization loss: 3.40E+00, L2 regularization loss: 1.10E+00
Test scatter: [0.5086 0.1047 0.4901 0.6512], Lowest was [0.4194 0.0764 0.3138 0.5128]
Median for last 10 epochs: [0.6055 0.1202 0.5148 0.7223], Epochs since improvement 8
 12%|█▏        | 59/500 [1:06:41<7:56:56, 64.89s/it]Epoch: 60 done with learning rate 9.08E-03, Train loss: 5.73E+06, Train scatter: [0.512  0.0957 0.5025 0.6121]
L1 regularization loss: 3.41E+00, L2 regularization loss: 1.14E+00
Test scatter: [0.5049 0.0956 0.4956 0.6072], Lowest was [0.4194 0.0764 0.3138 0.5128]
Median for last 10 epochs: [0.6055 0.1202 0.5148 0.7223], Epochs since improvement 10
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 12%|█▏        | 60/500 [1:08:09<8:46:27, 71.79s/it] 12%|█▏        | 61/500 [1:09:02<8:04:54, 66.27s/it] 12%|█▏        | 62/500 [1:10:23<8:34:00, 70.41s/it]Epoch: 62 done with learning rate 9.31E-03, Train loss: 5.13E+06, Train scatter: [0.458  0.1037 0.4576 0.6339]
L1 regularization loss: 3.42E+00, L2 regularization loss: 1.17E+00
Test scatter: [0.4564 0.1023 0.4524 0.6277], Lowest was [0.4194 0.0764 0.3138 0.5128]
Median for last 10 epochs: [0.5086 0.1047 0.4956 0.6512], Epochs since improvement 12
 13%|█▎        | 63/500 [1:11:17<7:57:44, 65.59s/it] 13%|█▎        | 64/500 [1:12:38<8:29:37, 70.13s/it]Epoch: 64 done with learning rate 9.50E-03, Train loss: 4.61E+06, Train scatter: [0.5074 0.0882 0.4048 0.5573]
L1 regularization loss: 3.42E+00, L2 regularization loss: 1.21E+00
Test scatter: [0.4994 0.0887 0.4087 0.5548], Lowest was [0.4194 0.0764 0.3138 0.5128]
Median for last 10 epochs: [0.5049 0.1023 0.4901 0.6277], Epochs since improvement 14
 13%|█▎        | 65/500 [1:13:31<7:52:23, 65.16s/it] 13%|█▎        | 66/500 [1:14:52<8:24:24, 69.73s/it]Epoch: 66 done with learning rate 9.66E-03, Train loss: 4.11E+06, Train scatter: [0.4065 0.0815 0.4536 0.5359]
L1 regularization loss: 3.43E+00, L2 regularization loss: 1.24E+00
Test scatter: [0.406  0.081  0.446  0.5334], Lowest was [0.406  0.0764 0.3138 0.5128]
Median for last 10 epochs: [0.4994 0.0956 0.4524 0.6072], Epochs since improvement 0
 13%|█▎        | 67/500 [1:15:45<7:47:15, 64.75s/it] 14%|█▎        | 68/500 [1:17:05<8:20:19, 69.49s/it]Epoch: 68 done with learning rate 9.80E-03, Train loss: 3.99E+06, Train scatter: [0.433  0.0813 0.3727 0.5258]
L1 regularization loss: 3.44E+00, L2 regularization loss: 1.27E+00
Test scatter: [0.4279 0.0809 0.373  0.5249], Lowest was [0.406  0.0764 0.3138 0.5128]
Median for last 10 epochs: [0.4564 0.0887 0.446  0.5548], Epochs since improvement 2
 14%|█▍        | 69/500 [1:18:00<7:47:07, 65.03s/it]Epoch: 70 done with learning rate 9.90E-03, Train loss: 3.69E+06, Train scatter: [0.4974 0.0758 0.3668 0.534 ]
L1 regularization loss: 3.45E+00, L2 regularization loss: 1.29E+00
Test scatter: [0.4822 0.0751 0.3665 0.5281], Lowest was [0.406  0.0751 0.3138 0.5128]
Median for last 10 epochs: [0.4564 0.081  0.4087 0.5334], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 14%|█▍        | 70/500 [1:19:27<8:33:42, 71.68s/it] 14%|█▍        | 71/500 [1:20:21<7:54:39, 66.39s/it] 14%|█▍        | 72/500 [1:21:43<8:25:57, 70.93s/it]Epoch: 72 done with learning rate 9.96E-03, Train loss: 3.40E+06, Train scatter: [0.5512 0.0812 0.3568 0.5106]
L1 regularization loss: 3.49E+00, L2 regularization loss: 1.32E+00
Test scatter: [0.5397 0.0803 0.3575 0.5103], Lowest was [0.406  0.0751 0.3138 0.5103]
Median for last 10 epochs: [0.4822 0.0809 0.373  0.5281], Epochs since improvement 0
 15%|█▍        | 73/500 [1:22:36<7:47:51, 65.74s/it] 15%|█▍        | 74/500 [1:23:57<8:17:53, 70.12s/it]Epoch: 74 done with learning rate 1.00E-02, Train loss: 3.14E+06, Train scatter: [0.4035 0.0741 0.3391 0.5063]
L1 regularization loss: 3.52E+00, L2 regularization loss: 1.36E+00
Test scatter: [0.4027 0.0739 0.341  0.5057], Lowest was [0.4027 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.4279 0.0803 0.3665 0.5249], Epochs since improvement 0
 15%|█▌        | 75/500 [1:24:51<7:43:27, 65.43s/it] 15%|█▌        | 76/500 [1:26:12<8:14:46, 70.02s/it]Epoch: 76 done with learning rate 1.00E-02, Train loss: 9.85E+06, Train scatter: [0.9337 0.1651 0.5436 0.9701]
L1 regularization loss: 4.07E+00, L2 regularization loss: 1.69E+00
Test scatter: [0.9181 0.1616 0.535  0.9604], Lowest was [0.4027 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.4822 0.0803 0.3665 0.5249], Epochs since improvement 2
 15%|█▌        | 77/500 [1:27:06<7:39:10, 65.13s/it] 16%|█▌        | 78/500 [1:28:27<8:12:15, 69.99s/it]Epoch: 78 done with learning rate 1.00E-02, Train loss: 6.84E+06, Train scatter: [0.905  0.1007 0.4736 0.6783]
L1 regularization loss: 4.09E+00, L2 regularization loss: 1.72E+00
Test scatter: [0.8914 0.1023 0.4714 0.6802], Lowest was [0.4027 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.5397 0.0803 0.3665 0.5281], Epochs since improvement 4
 16%|█▌        | 79/500 [1:29:20<7:35:58, 64.98s/it]Epoch: 80 done with learning rate 1.00E-02, Train loss: 5.60E+06, Train scatter: [0.5459 0.0995 0.4217 0.6543]
L1 regularization loss: 4.10E+00, L2 regularization loss: 1.79E+00
Test scatter: [0.546  0.0998 0.4202 0.6507], Lowest was [0.4027 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.546  0.0998 0.4202 0.6507], Epochs since improvement 6
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 16%|█▌        | 80/500 [1:30:47<8:20:31, 71.50s/it] 16%|█▌        | 81/500 [1:31:41<7:42:52, 66.28s/it] 16%|█▋        | 82/500 [1:33:01<8:09:56, 70.33s/it]Epoch: 82 done with learning rate 9.99E-03, Train loss: 4.55E+06, Train scatter: [0.4176 0.0919 0.4079 0.6157]
L1 regularization loss: 4.13E+00, L2 regularization loss: 1.85E+00
Test scatter: [0.4239 0.0926 0.4074 0.6114], Lowest was [0.4027 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.546  0.0998 0.4202 0.6507], Epochs since improvement 8
 17%|█▋        | 83/500 [1:33:54<7:32:37, 65.13s/it] 17%|█▋        | 84/500 [1:35:13<8:01:45, 69.48s/it]Epoch: 84 done with learning rate 9.99E-03, Train loss: 3.99E+06, Train scatter: [0.4129 0.0895 0.3755 0.5895]
L1 regularization loss: 4.16E+00, L2 regularization loss: 1.90E+00
Test scatter: [0.4002 0.0898 0.3774 0.5853], Lowest was [0.4002 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.546  0.0998 0.4202 0.6507], Epochs since improvement 0
 17%|█▋        | 85/500 [1:36:07<7:28:02, 64.78s/it] 17%|█▋        | 86/500 [1:37:28<8:00:13, 69.60s/it]Epoch: 86 done with learning rate 9.98E-03, Train loss: 4.50E+06, Train scatter: [0.4856 0.0873 0.4555 0.5766]
L1 regularization loss: 4.23E+00, L2 regularization loss: 1.97E+00
Test scatter: [0.487  0.0894 0.4527 0.5784], Lowest was [0.4002 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.487  0.0926 0.4202 0.6114], Epochs since improvement 2
 17%|█▋        | 87/500 [1:38:22<7:26:09, 64.82s/it] 18%|█▊        | 88/500 [1:39:43<7:58:43, 69.72s/it]Epoch: 88 done with learning rate 9.98E-03, Train loss: 4.02E+06, Train scatter: [0.4467 0.0797 0.416  0.5383]
L1 regularization loss: 4.25E+00, L2 regularization loss: 2.01E+00
Test scatter: [0.4402 0.0797 0.4142 0.5339], Lowest was [0.4002 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.4402 0.0898 0.4142 0.5853], Epochs since improvement 4
 18%|█▊        | 89/500 [1:40:38<7:26:44, 65.22s/it]Epoch: 90 done with learning rate 9.97E-03, Train loss: 3.17E+06, Train scatter: [0.325  0.0793 0.3419 0.5367]
L1 regularization loss: 4.26E+00, L2 regularization loss: 2.06E+00
Test scatter: [0.3328 0.0794 0.3465 0.531 ], Lowest was [0.3328 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.4239 0.0894 0.4074 0.5784], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 18%|█▊        | 90/500 [1:42:05<8:11:21, 71.91s/it] 18%|█▊        | 91/500 [1:42:59<7:33:39, 66.55s/it] 18%|█▊        | 92/500 [1:44:21<8:03:16, 71.07s/it]Epoch: 92 done with learning rate 9.96E-03, Train loss: 3.04E+06, Train scatter: [0.3179 0.0748 0.3283 0.5162]
L1 regularization loss: 4.27E+00, L2 regularization loss: 2.11E+00
Test scatter: [0.3182 0.0743 0.333  0.5086], Lowest was [0.3182 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.4002 0.0797 0.3774 0.5339], Epochs since improvement 0
 19%|█▊        | 93/500 [1:45:14<7:26:27, 65.82s/it] 19%|█▉        | 94/500 [1:46:36<7:56:48, 70.46s/it]Epoch: 94 done with learning rate 9.95E-03, Train loss: 3.13E+06, Train scatter: [0.3399 0.0844 0.4302 0.5253]
L1 regularization loss: 4.30E+00, L2 regularization loss: 2.16E+00
Test scatter: [0.3496 0.0834 0.4244 0.5203], Lowest was [0.3182 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.3496 0.0797 0.4142 0.531 ], Epochs since improvement 2
 19%|█▉        | 95/500 [1:47:30<7:23:39, 65.73s/it] 19%|█▉        | 96/500 [1:48:52<7:54:15, 70.44s/it]Epoch: 96 done with learning rate 9.94E-03, Train loss: 2.96E+06, Train scatter: [0.292  0.0793 0.3378 0.5129]
L1 regularization loss: 4.29E+00, L2 regularization loss: 2.18E+00
Test scatter: [0.2878 0.0788 0.3402 0.5097], Lowest was [0.2878 0.0739 0.3138 0.5057]
Median for last 10 epochs: [0.3328 0.0794 0.3465 0.5203], Epochs since improvement 0
 19%|█▉        | 97/500 [1:49:45<7:19:09, 65.38s/it] 20%|█▉        | 98/500 [1:51:06<7:49:07, 70.02s/it]Epoch: 98 done with learning rate 9.93E-03, Train loss: 2.51E+06, Train scatter: [0.2785 0.0747 0.3165 0.4977]
L1 regularization loss: 4.31E+00, L2 regularization loss: 2.24E+00
Test scatter: [0.2911 0.0746 0.3203 0.4953], Lowest was [0.2878 0.0739 0.3138 0.4953]
Median for last 10 epochs: [0.3182 0.0788 0.3402 0.5097], Epochs since improvement 0
 20%|█▉        | 99/500 [1:52:01<7:16:34, 65.32s/it]Epoch: 100 done with learning rate 9.91E-03, Train loss: 2.34E+06, Train scatter: [0.284  0.0842 0.3405 0.5254]
L1 regularization loss: 4.31E+00, L2 regularization loss: 2.28E+00
Test scatter: [0.2916 0.0845 0.3478 0.5221], Lowest was [0.2878 0.0739 0.3138 0.4953]
Median for last 10 epochs: [0.2916 0.0788 0.3402 0.5097], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 20%|██        | 100/500 [1:53:29<8:01:32, 72.23s/it] 20%|██        | 101/500 [1:54:23<7:24:25, 66.83s/it] 20%|██        | 102/500 [1:55:43<7:49:25, 70.77s/it]Epoch: 102 done with learning rate 9.90E-03, Train loss: 2.17E+06, Train scatter: [0.2454 0.0733 0.3134 0.4821]
L1 regularization loss: 4.32E+00, L2 regularization loss: 2.33E+00
Test scatter: [0.2546 0.0737 0.3229 0.4839], Lowest was [0.2546 0.0737 0.3138 0.4839]
Median for last 10 epochs: [0.2911 0.0788 0.3402 0.5097], Epochs since improvement 0
 21%|██        | 103/500 [1:56:37<7:15:24, 65.80s/it] 21%|██        | 104/500 [1:57:57<7:42:11, 70.03s/it]Epoch: 104 done with learning rate 9.89E-03, Train loss: 2.04E+06, Train scatter: [0.2534 0.0717 0.3117 0.4746]
L1 regularization loss: 4.32E+00, L2 regularization loss: 2.37E+00
Test scatter: [0.2652 0.072  0.3237 0.4726], Lowest was [0.2546 0.072  0.3138 0.4726]
Median for last 10 epochs: [0.2878 0.0746 0.3237 0.4953], Epochs since improvement 0
 21%|██        | 105/500 [1:58:51<7:08:38, 65.11s/it] 21%|██        | 106/500 [2:00:11<7:37:31, 69.67s/it]Epoch: 106 done with learning rate 9.87E-03, Train loss: 1.91E+06, Train scatter: [0.2545 0.0696 0.3069 0.4834]
L1 regularization loss: 4.33E+00, L2 regularization loss: 2.41E+00
Test scatter: [0.2647 0.0696 0.314  0.4839], Lowest was [0.2546 0.0696 0.3138 0.4726]
Median for last 10 epochs: [0.2652 0.0737 0.3229 0.4839], Epochs since improvement 0
 21%|██▏       | 107/500 [2:01:04<7:03:27, 64.65s/it] 22%|██▏       | 108/500 [2:02:24<7:33:10, 69.36s/it]Epoch: 108 done with learning rate 9.85E-03, Train loss: 1.91E+06, Train scatter: [0.2732 0.0651 0.3078 0.46  ]
L1 regularization loss: 4.34E+00, L2 regularization loss: 2.44E+00
Test scatter: [0.2821 0.0656 0.3182 0.4621], Lowest was [0.2546 0.0656 0.3138 0.4621]
Median for last 10 epochs: [0.2652 0.072  0.3229 0.4839], Epochs since improvement 0
 22%|██▏       | 109/500 [2:03:19<7:02:29, 64.83s/it]Epoch: 110 done with learning rate 9.83E-03, Train loss: 1.79E+06, Train scatter: [0.4093 0.0664 0.3158 0.4922]
L1 regularization loss: 4.35E+00, L2 regularization loss: 2.48E+00
Test scatter: [0.4091 0.0652 0.3207 0.4879], Lowest was [0.2546 0.0652 0.3138 0.4621]
Median for last 10 epochs: [0.2652 0.0696 0.3207 0.4839], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 22%|██▏       | 110/500 [2:04:46<7:45:49, 71.66s/it] 22%|██▏       | 111/500 [2:05:41<7:11:22, 66.54s/it] 22%|██▏       | 112/500 [2:07:02<7:38:22, 70.88s/it]Epoch: 112 done with learning rate 9.81E-03, Train loss: 1.71E+06, Train scatter: [0.2279 0.0607 0.295  0.4508]
L1 regularization loss: 4.36E+00, L2 regularization loss: 2.56E+00
Test scatter: [0.2367 0.0607 0.3013 0.4511], Lowest was [0.2367 0.0607 0.3013 0.4511]
Median for last 10 epochs: [0.2652 0.0656 0.3182 0.4726], Epochs since improvement 0
 23%|██▎       | 113/500 [2:07:55<7:03:07, 65.60s/it] 23%|██▎       | 114/500 [2:09:16<7:31:42, 70.21s/it]Epoch: 114 done with learning rate 9.79E-03, Train loss: 1.68E+06, Train scatter: [0.3012 0.0705 0.3291 0.5131]
L1 regularization loss: 4.36E+00, L2 regularization loss: 2.59E+00
Test scatter: [0.3108 0.0684 0.3323 0.509 ], Lowest was [0.2367 0.0607 0.3013 0.4511]
Median for last 10 epochs: [0.2821 0.0656 0.3182 0.4839], Epochs since improvement 2
 23%|██▎       | 115/500 [2:10:09<6:57:25, 65.05s/it] 23%|██▎       | 116/500 [2:11:29<7:24:30, 69.45s/it]Epoch: 116 done with learning rate 9.77E-03, Train loss: 1.70E+06, Train scatter: [0.2224 0.0608 0.2974 0.4517]
L1 regularization loss: 4.37E+00, L2 regularization loss: 2.65E+00
Test scatter: [0.2308 0.0605 0.3042 0.4503], Lowest was [0.2308 0.0605 0.3013 0.4503]
Median for last 10 epochs: [0.2821 0.0652 0.3182 0.4621], Epochs since improvement 0
 23%|██▎       | 117/500 [2:12:22<6:52:58, 64.70s/it] 24%|██▎       | 118/500 [2:13:44<7:23:14, 69.62s/it]Epoch: 118 done with learning rate 9.75E-03, Train loss: 1.50E+06, Train scatter: [0.2566 0.0662 0.304  0.4723]
L1 regularization loss: 4.37E+00, L2 regularization loss: 2.68E+00
Test scatter: [0.2634 0.0671 0.3105 0.4737], Lowest was [0.2308 0.0605 0.3013 0.4503]
Median for last 10 epochs: [0.2634 0.0652 0.3105 0.4737], Epochs since improvement 2
 24%|██▍       | 119/500 [2:14:38<6:53:06, 65.06s/it]Epoch: 120 done with learning rate 9.73E-03, Train loss: 1.49E+06, Train scatter: [0.2284 0.0619 0.289  0.449 ]
L1 regularization loss: 4.38E+00, L2 regularization loss: 2.72E+00
Test scatter: [0.2357 0.0621 0.2958 0.4481], Lowest was [0.2308 0.0605 0.2958 0.4481]
Median for last 10 epochs: [0.2367 0.0621 0.3042 0.4511], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 24%|██▍       | 120/500 [2:16:05<7:33:11, 71.56s/it] 24%|██▍       | 121/500 [2:16:59<6:58:35, 66.27s/it] 24%|██▍       | 122/500 [2:18:21<7:27:41, 71.06s/it]Epoch: 122 done with learning rate 9.70E-03, Train loss: 1.49E+06, Train scatter: [0.2911 0.0633 0.2875 0.4453]
L1 regularization loss: 4.39E+00, L2 regularization loss: 2.77E+00
Test scatter: [0.2855 0.0638 0.2936 0.446 ], Lowest was [0.2308 0.0605 0.2936 0.446 ]
Median for last 10 epochs: [0.2634 0.0638 0.3042 0.4503], Epochs since improvement 0
 25%|██▍       | 123/500 [2:19:15<6:54:05, 65.90s/it] 25%|██▍       | 124/500 [2:20:36<7:21:34, 70.46s/it]Epoch: 124 done with learning rate 9.68E-03, Train loss: 1.40E+06, Train scatter: [0.2219 0.0574 0.2766 0.4405]
L1 regularization loss: 4.41E+00, L2 regularization loss: 2.86E+00
Test scatter: [0.2338 0.0577 0.2829 0.4385], Lowest was [0.2308 0.0577 0.2829 0.4385]
Median for last 10 epochs: [0.2357 0.0621 0.2958 0.4481], Epochs since improvement 0
 25%|██▌       | 125/500 [2:21:30<6:49:35, 65.53s/it] 25%|██▌       | 126/500 [2:22:50<7:16:19, 70.00s/it]Epoch: 126 done with learning rate 9.65E-03, Train loss: 1.28E+06, Train scatter: [0.2314 0.0583 0.2786 0.4304]
L1 regularization loss: 4.42E+00, L2 regularization loss: 2.89E+00
Test scatter: [0.2391 0.0584 0.2896 0.4321], Lowest was [0.2308 0.0577 0.2829 0.4321]
Median for last 10 epochs: [0.2391 0.0621 0.2936 0.446 ], Epochs since improvement 0
 25%|██▌       | 127/500 [2:23:44<6:45:07, 65.17s/it] 26%|██▌       | 128/500 [2:25:05<7:12:22, 69.74s/it]Epoch: 128 done with learning rate 9.62E-03, Train loss: 1.21E+06, Train scatter: [0.2042 0.0555 0.2731 0.4294]
L1 regularization loss: 4.42E+00, L2 regularization loss: 2.92E+00
Test scatter: [0.2133 0.0558 0.2791 0.4272], Lowest was [0.2133 0.0558 0.2791 0.4272]
Median for last 10 epochs: [0.2357 0.0584 0.2896 0.4385], Epochs since improvement 0
 26%|██▌       | 129/500 [2:25:58<6:40:21, 64.75s/it]Epoch: 130 done with learning rate 9.59E-03, Train loss: 1.36E+06, Train scatter: [0.2123 0.0566 0.2942 0.4435]
L1 regularization loss: 4.44E+00, L2 regularization loss: 2.96E+00
Test scatter: [0.2158 0.0558 0.2974 0.439 ], Lowest was [0.2133 0.0558 0.2791 0.4272]
Median for last 10 epochs: [0.2338 0.0577 0.2896 0.4385], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 26%|██▌       | 130/500 [2:27:27<7:24:20, 72.06s/it] 26%|██▌       | 131/500 [2:28:21<6:50:17, 66.71s/it] 26%|██▋       | 132/500 [2:29:41<7:13:19, 70.65s/it]Epoch: 132 done with learning rate 9.56E-03, Train loss: 1.05E+06, Train scatter: [0.2266 0.0542 0.2773 0.4279]
L1 regularization loss: 4.43E+00, L2 regularization loss: 2.97E+00
Test scatter: [0.2249 0.054  0.2798 0.4271], Lowest was [0.2133 0.054  0.2791 0.4271]
Median for last 10 epochs: [0.2249 0.0558 0.2829 0.4321], Epochs since improvement 0
 27%|██▋       | 133/500 [2:30:35<6:41:49, 65.69s/it] 27%|██▋       | 134/500 [2:31:57<7:10:54, 70.64s/it]Epoch: 134 done with learning rate 9.53E-03, Train loss: 1.04E+06, Train scatter: [0.2089 0.0524 0.2718 0.4283]
L1 regularization loss: 4.43E+00, L2 regularization loss: 3.00E+00
Test scatter: [0.2131 0.0524 0.2742 0.4247], Lowest was [0.2131 0.0524 0.2742 0.4247]
Median for last 10 epochs: [0.2158 0.0558 0.2798 0.4272], Epochs since improvement 0
 27%|██▋       | 135/500 [2:32:51<6:39:37, 65.69s/it] 27%|██▋       | 136/500 [2:34:11<7:04:23, 69.96s/it]Epoch: 136 done with learning rate 9.50E-03, Train loss: 9.54E+05, Train scatter: [0.2323 0.0507 0.2635 0.4165]
L1 regularization loss: 4.43E+00, L2 regularization loss: 3.01E+00
Test scatter: [0.232  0.0507 0.2671 0.4166], Lowest was [0.2131 0.0507 0.2671 0.4166]
Median for last 10 epochs: [0.2158 0.054  0.2791 0.4271], Epochs since improvement 0
 27%|██▋       | 137/500 [2:35:05<6:34:14, 65.16s/it] 28%|██▊       | 138/500 [2:36:25<7:00:28, 69.69s/it]Epoch: 138 done with learning rate 9.47E-03, Train loss: 8.76E+05, Train scatter: [0.2181 0.0515 0.2655 0.4197]
L1 regularization loss: 4.43E+00, L2 regularization loss: 3.04E+00
Test scatter: [0.2156 0.0513 0.269  0.4168], Lowest was [0.2131 0.0507 0.2671 0.4166]
Median for last 10 epochs: [0.2158 0.0524 0.2742 0.4247], Epochs since improvement 2
 28%|██▊       | 139/500 [2:37:20<6:31:49, 65.12s/it]Epoch: 140 done with learning rate 9.43E-03, Train loss: 8.42E+05, Train scatter: [0.207  0.0536 0.2724 0.4313]
L1 regularization loss: 4.43E+00, L2 regularization loss: 3.07E+00
Test scatter: [0.2186 0.0546 0.2749 0.4286], Lowest was [0.2131 0.0507 0.2671 0.4166]
Median for last 10 epochs: [0.2186 0.0524 0.2742 0.4247], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 28%|██▊       | 140/500 [2:38:49<7:13:40, 72.28s/it] 28%|██▊       | 141/500 [2:39:42<6:38:28, 66.60s/it] 28%|██▊       | 142/500 [2:41:03<7:03:03, 70.90s/it]Epoch: 142 done with learning rate 9.40E-03, Train loss: 7.91E+05, Train scatter: [0.186  0.052  0.2642 0.4158]
L1 regularization loss: 4.44E+00, L2 regularization loss: 3.11E+00
Test scatter: [0.1908 0.0517 0.2671 0.4122], Lowest was [0.1908 0.0507 0.2671 0.4122]
Median for last 10 epochs: [0.2156 0.0517 0.269  0.4168], Epochs since improvement 0
 29%|██▊       | 143/500 [2:41:57<6:31:13, 65.75s/it] 29%|██▉       | 144/500 [2:43:18<6:56:31, 70.20s/it]Epoch: 144 done with learning rate 9.36E-03, Train loss: 7.71E+05, Train scatter: [0.1893 0.0503 0.2638 0.419 ]
L1 regularization loss: 4.45E+00, L2 regularization loss: 3.14E+00
Test scatter: [0.1957 0.0506 0.2663 0.4218], Lowest was [0.1908 0.0506 0.2663 0.4122]
Median for last 10 epochs: [0.2156 0.0513 0.2671 0.4168], Epochs since improvement 0
 29%|██▉       | 145/500 [2:44:10<6:24:45, 65.03s/it] 29%|██▉       | 146/500 [2:45:31<6:51:21, 69.72s/it]Epoch: 146 done with learning rate 9.33E-03, Train loss: 7.24E+05, Train scatter: [0.1747 0.0483 0.2611 0.4111]
L1 regularization loss: 4.46E+00, L2 regularization loss: 3.17E+00
Test scatter: [0.1787 0.0483 0.2643 0.4046], Lowest was [0.1787 0.0483 0.2643 0.4046]
Median for last 10 epochs: [0.1957 0.0513 0.2671 0.4168], Epochs since improvement 0
 29%|██▉       | 147/500 [2:46:25<6:22:29, 65.01s/it] 30%|██▉       | 148/500 [2:47:46<6:49:52, 69.87s/it]Epoch: 148 done with learning rate 9.29E-03, Train loss: 7.38E+05, Train scatter: [0.175  0.0476 0.2524 0.402 ]
L1 regularization loss: 4.49E+00, L2 regularization loss: 3.24E+00
Test scatter: [0.1782 0.0476 0.2545 0.402 ], Lowest was [0.1782 0.0476 0.2545 0.402 ]
Median for last 10 epochs: [0.1908 0.0506 0.2663 0.4122], Epochs since improvement 0
 30%|██▉       | 149/500 [2:48:41<6:21:59, 65.30s/it]Epoch: 150 done with learning rate 9.25E-03, Train loss: 6.32E+05, Train scatter: [0.2009 0.0529 0.2812 0.4274]
L1 regularization loss: 4.49E+00, L2 regularization loss: 3.26E+00
Test scatter: [0.209  0.0526 0.28   0.4232], Lowest was [0.1782 0.0476 0.2545 0.402 ]
Median for last 10 epochs: [0.1908 0.0506 0.2663 0.4122], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 30%|███       | 150/500 [2:50:08<6:58:26, 71.73s/it] 30%|███       | 151/500 [2:51:01<6:25:34, 66.29s/it] 30%|███       | 152/500 [2:52:22<6:49:04, 70.53s/it]Epoch: 152 done with learning rate 9.21E-03, Train loss: 5.90E+05, Train scatter: [0.1853 0.0544 0.2865 0.4255]
L1 regularization loss: 4.59E+00, L2 regularization loss: 3.39E+00
Test scatter: [0.188  0.0548 0.2915 0.4297], Lowest was [0.1782 0.0476 0.2545 0.402 ]
Median for last 10 epochs: [0.188  0.0506 0.2663 0.4218], Epochs since improvement 4
 31%|███       | 153/500 [2:53:15<6:17:35, 65.29s/it] 31%|███       | 154/500 [2:54:36<6:43:32, 69.98s/it]Epoch: 154 done with learning rate 9.17E-03, Train loss: 5.36E+05, Train scatter: [0.1688 0.0505 0.2621 0.4047]
L1 regularization loss: 4.57E+00, L2 regularization loss: 3.41E+00
Test scatter: [0.1717 0.0504 0.2637 0.4001], Lowest was [0.1717 0.0476 0.2545 0.4001]
Median for last 10 epochs: [0.1787 0.0504 0.2643 0.4046], Epochs since improvement 0
 31%|███       | 155/500 [2:55:29<6:14:13, 65.08s/it] 31%|███       | 156/500 [2:56:49<6:38:49, 69.56s/it]Epoch: 156 done with learning rate 9.13E-03, Train loss: 4.84E+05, Train scatter: [0.1733 0.0468 0.2464 0.4024]
L1 regularization loss: 4.56E+00, L2 regularization loss: 3.44E+00
Test scatter: [0.1744 0.0464 0.2487 0.3989], Lowest was [0.1717 0.0464 0.2487 0.3989]
Median for last 10 epochs: [0.1782 0.0504 0.2637 0.402 ], Epochs since improvement 0
 31%|███▏      | 157/500 [2:57:43<6:09:46, 64.68s/it] 32%|███▏      | 158/500 [2:59:03<6:35:30, 69.39s/it]Epoch: 158 done with learning rate 9.09E-03, Train loss: 4.27E+05, Train scatter: [0.166  0.047  0.2449 0.401 ]
L1 regularization loss: 4.56E+00, L2 regularization loss: 3.46E+00
Test scatter: [0.1712 0.047  0.2494 0.4012], Lowest was [0.1712 0.0464 0.2487 0.3989]
Median for last 10 epochs: [0.1744 0.0504 0.2637 0.4012], Epochs since improvement 0
 32%|███▏      | 159/500 [2:59:58<6:08:57, 64.92s/it]Epoch: 160 done with learning rate 9.04E-03, Train loss: 3.95E+05, Train scatter: [0.1585 0.0484 0.2495 0.4089]
L1 regularization loss: 4.57E+00, L2 regularization loss: 3.49E+00
Test scatter: [0.1595 0.0479 0.2526 0.4009], Lowest was [0.1595 0.0464 0.2487 0.3989]
Median for last 10 epochs: [0.1717 0.0479 0.2526 0.4009], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 32%|███▏      | 160/500 [3:01:25<6:46:46, 71.78s/it] 32%|███▏      | 161/500 [3:02:19<6:14:01, 66.20s/it] 32%|███▏      | 162/500 [3:03:39<6:36:45, 70.43s/it]Epoch: 162 done with learning rate 9.00E-03, Train loss: 2.97E+05, Train scatter: [0.2173 0.0474 0.2791 0.4025]
L1 regularization loss: 4.56E+00, L2 regularization loss: 3.50E+00
Test scatter: [0.2157 0.0473 0.2791 0.4019], Lowest was [0.1595 0.0464 0.2487 0.3989]
Median for last 10 epochs: [0.1717 0.0473 0.2526 0.4009], Epochs since improvement 2
 33%|███▎      | 163/500 [3:04:32<6:06:55, 65.33s/it] 33%|███▎      | 164/500 [3:05:53<6:31:56, 69.99s/it]Epoch: 164 done with learning rate 8.96E-03, Train loss: 2.34E+05, Train scatter: [0.1723 0.0477 0.2497 0.4039]
L1 regularization loss: 4.55E+00, L2 regularization loss: 3.51E+00
Test scatter: [0.1769 0.0475 0.253  0.4009], Lowest was [0.1595 0.0464 0.2487 0.3989]
Median for last 10 epochs: [0.1744 0.0473 0.2526 0.4009], Epochs since improvement 4
 33%|███▎      | 165/500 [3:06:47<6:02:57, 65.01s/it] 33%|███▎      | 166/500 [3:08:07<6:28:00, 69.70s/it]Epoch: 166 done with learning rate 8.91E-03, Train loss: 1.84E+05, Train scatter: [0.1539 0.0448 0.2366 0.3976]
L1 regularization loss: 4.57E+00, L2 regularization loss: 3.54E+00
Test scatter: [0.1583 0.0447 0.2399 0.3936], Lowest was [0.1583 0.0447 0.2399 0.3936]
Median for last 10 epochs: [0.1712 0.0473 0.2526 0.4009], Epochs since improvement 0
 33%|███▎      | 167/500 [3:09:01<5:59:51, 64.84s/it] 34%|███▎      | 168/500 [3:10:21<6:23:54, 69.38s/it]Epoch: 168 done with learning rate 8.86E-03, Train loss: 6.98E+04, Train scatter: [0.1971 0.0449 0.2435 0.3963]
L1 regularization loss: 4.56E+00, L2 regularization loss: 3.55E+00
Test scatter: [0.1986 0.0449 0.2456 0.3957], Lowest was [0.1583 0.0447 0.2399 0.3936]
Median for last 10 epochs: [0.1769 0.0473 0.2526 0.4009], Epochs since improvement 2
 34%|███▍      | 169/500 [3:11:15<5:58:26, 64.97s/it]Epoch: 170 done with learning rate 8.82E-03, Train loss: -7.34E+03, Train scatter: [0.1961 0.05   0.2535 0.4078]
L1 regularization loss: 4.55E+00, L2 regularization loss: 3.56E+00
Test scatter: [0.203  0.0505 0.2565 0.4093], Lowest was [0.1583 0.0447 0.2399 0.3936]
Median for last 10 epochs: [0.1986 0.0473 0.253  0.4009], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 34%|███▍      | 170/500 [3:12:43<6:34:08, 71.66s/it] 34%|███▍      | 171/500 [3:13:37<6:04:41, 66.51s/it] 34%|███▍      | 172/500 [3:14:57<6:26:07, 70.63s/it]Epoch: 172 done with learning rate 8.77E-03, Train loss: -6.37E+04, Train scatter: [0.1572 0.0491 0.2362 0.3935]
L1 regularization loss: 4.57E+00, L2 regularization loss: 3.59E+00
Test scatter: [0.1605 0.0485 0.2391 0.392 ], Lowest was [0.1583 0.0447 0.2391 0.392 ]
Median for last 10 epochs: [0.1769 0.0475 0.2456 0.3957], Epochs since improvement 0
 35%|███▍      | 173/500 [3:15:51<5:57:43, 65.64s/it] 35%|███▍      | 174/500 [3:17:12<6:21:29, 70.21s/it]Epoch: 174 done with learning rate 8.72E-03, Train loss: -1.24E+05, Train scatter: [0.2234 0.0429 0.2297 0.3838]
L1 regularization loss: 4.56E+00, L2 regularization loss: 3.60E+00
Test scatter: [0.218  0.0432 0.2343 0.3821], Lowest was [0.1583 0.0432 0.2343 0.3821]
Median for last 10 epochs: [0.1986 0.0449 0.2399 0.3936], Epochs since improvement 0
 35%|███▌      | 175/500 [3:18:06<5:53:42, 65.30s/it] 35%|███▌      | 176/500 [3:19:28<6:18:57, 70.18s/it]Epoch: 176 done with learning rate 8.67E-03, Train loss: -1.83E+05, Train scatter: [0.1467 0.0449 0.2354 0.3915]
L1 regularization loss: 4.54E+00, L2 regularization loss: 3.61E+00
Test scatter: [0.1501 0.045  0.2415 0.3898], Lowest was [0.1501 0.0432 0.2343 0.3821]
Median for last 10 epochs: [0.1986 0.045  0.2415 0.392 ], Epochs since improvement 0
 35%|███▌      | 177/500 [3:20:22<5:51:33, 65.31s/it] 36%|███▌      | 178/500 [3:21:43<6:16:47, 70.21s/it]Epoch: 178 done with learning rate 8.62E-03, Train loss: -2.26E+05, Train scatter: [0.1773 0.0428 0.2255 0.3821]
L1 regularization loss: 4.53E+00, L2 regularization loss: 3.62E+00
Test scatter: [0.1804 0.0433 0.2294 0.382 ], Lowest was [0.1501 0.0432 0.2294 0.382 ]
Median for last 10 epochs: [0.1804 0.045  0.2391 0.3898], Epochs since improvement 0
 36%|███▌      | 179/500 [3:22:36<5:47:58, 65.04s/it]Epoch: 180 done with learning rate 8.57E-03, Train loss: -2.56E+05, Train scatter: [0.1779 0.0447 0.2226 0.3835]
L1 regularization loss: 4.53E+00, L2 regularization loss: 3.63E+00
Test scatter: [0.172  0.0449 0.2251 0.3802], Lowest was [0.1501 0.0432 0.2251 0.3802]
Median for last 10 epochs: [0.172  0.0449 0.2343 0.3821], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 36%|███▌      | 180/500 [3:24:04<6:23:30, 71.91s/it] 36%|███▌      | 181/500 [3:24:58<5:53:48, 66.55s/it] 36%|███▋      | 182/500 [3:26:20<6:17:40, 71.26s/it]Epoch: 182 done with learning rate 8.52E-03, Train loss: -2.94E+05, Train scatter: [0.2079 0.0435 0.2235 0.3824]
L1 regularization loss: 4.52E+00, L2 regularization loss: 3.64E+00
Test scatter: [0.205  0.0434 0.2259 0.3813], Lowest was [0.1501 0.0432 0.2251 0.3802]
Median for last 10 epochs: [0.1804 0.0434 0.2294 0.382 ], Epochs since improvement 2
 37%|███▋      | 183/500 [3:27:13<5:47:32, 65.78s/it] 37%|███▋      | 184/500 [3:28:34<6:09:32, 70.17s/it]Epoch: 184 done with learning rate 8.46E-03, Train loss: -3.10E+05, Train scatter: [0.1339 0.042  0.2306 0.3896]
L1 regularization loss: 4.57E+00, L2 regularization loss: 3.67E+00
Test scatter: [0.1372 0.0421 0.2342 0.3873], Lowest was [0.1372 0.0421 0.2251 0.3802]
Median for last 10 epochs: [0.172  0.0434 0.2294 0.382 ], Epochs since improvement 0
 37%|███▋      | 185/500 [3:29:28<5:42:55, 65.32s/it] 37%|███▋      | 186/500 [3:30:49<6:06:08, 69.96s/it]Epoch: 186 done with learning rate 8.41E-03, Train loss: -3.31E+05, Train scatter: [0.1605 0.043  0.2223 0.3847]
L1 regularization loss: 4.65E+00, L2 regularization loss: 3.74E+00
Test scatter: [0.1668 0.0431 0.2244 0.3846], Lowest was [0.1372 0.0421 0.2244 0.3802]
Median for last 10 epochs: [0.172  0.0433 0.2259 0.382 ], Epochs since improvement 0
 37%|███▋      | 187/500 [3:31:42<5:38:38, 64.92s/it] 38%|███▊      | 188/500 [3:33:03<6:02:28, 69.71s/it]Epoch: 188 done with learning rate 8.35E-03, Train loss: -3.50E+05, Train scatter: [0.1798 0.0432 0.2284 0.3934]
L1 regularization loss: 4.65E+00, L2 regularization loss: 3.77E+00
Test scatter: [0.1868 0.0432 0.2319 0.3937], Lowest was [0.1372 0.0421 0.2244 0.3802]
Median for last 10 epochs: [0.172  0.0432 0.2259 0.3846], Epochs since improvement 2
 38%|███▊      | 189/500 [3:33:56<5:36:15, 64.87s/it]Epoch: 190 done with learning rate 8.30E-03, Train loss: -3.57E+05, Train scatter: [0.2357 0.0534 0.2643 0.4296]
L1 regularization loss: 4.65E+00, L2 regularization loss: 3.78E+00
Test scatter: [0.2405 0.0529 0.2642 0.429 ], Lowest was [0.1372 0.0421 0.2244 0.3802]
Median for last 10 epochs: [0.1868 0.0432 0.2319 0.3873], Epochs since improvement 4
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 38%|███▊      | 190/500 [3:35:25<6:12:15, 72.05s/it] 38%|███▊      | 191/500 [3:36:19<5:43:45, 66.75s/it] 38%|███▊      | 192/500 [3:37:39<6:03:09, 70.75s/it]Epoch: 192 done with learning rate 8.24E-03, Train loss: -3.71E+05, Train scatter: [0.183  0.0488 0.2686 0.4269]
L1 regularization loss: 4.66E+00, L2 regularization loss: 3.82E+00
Test scatter: [0.1859 0.0488 0.2734 0.4227], Lowest was [0.1372 0.0421 0.2244 0.3802]
Median for last 10 epochs: [0.1859 0.0432 0.2342 0.3937], Epochs since improvement 6
 39%|███▊      | 193/500 [3:38:32<5:34:39, 65.40s/it] 39%|███▉      | 194/500 [3:39:54<5:58:17, 70.25s/it]Epoch: 194 done with learning rate 8.19E-03, Train loss: -3.85E+05, Train scatter: [0.175  0.0425 0.2175 0.3935]
L1 regularization loss: 4.65E+00, L2 regularization loss: 3.85E+00
Test scatter: [0.1795 0.0425 0.2201 0.3934], Lowest was [0.1372 0.0421 0.2201 0.3802]
Median for last 10 epochs: [0.1859 0.0432 0.2319 0.3937], Epochs since improvement 0
 39%|███▉      | 195/500 [3:40:48<5:32:25, 65.40s/it] 39%|███▉      | 196/500 [3:42:10<5:56:49, 70.43s/it]Epoch: 196 done with learning rate 8.13E-03, Train loss: -3.84E+05, Train scatter: [0.2005 0.0459 0.2305 0.3932]
L1 regularization loss: 4.66E+00, L2 regularization loss: 3.87E+00
Test scatter: [0.2029 0.0455 0.2332 0.3907], Lowest was [0.1372 0.0421 0.2201 0.3802]
Median for last 10 epochs: [0.1868 0.0455 0.2332 0.3937], Epochs since improvement 2
 39%|███▉      | 197/500 [3:43:04<5:29:50, 65.32s/it] 40%|███▉      | 198/500 [3:44:26<5:53:56, 70.32s/it]Epoch: 198 done with learning rate 8.07E-03, Train loss: -3.93E+05, Train scatter: [0.1278 0.0418 0.2192 0.3859]
L1 regularization loss: 4.70E+00, L2 regularization loss: 3.92E+00
Test scatter: [0.1313 0.0418 0.2231 0.3829], Lowest was [0.1313 0.0418 0.2201 0.3802]
Median for last 10 epochs: [0.1859 0.0455 0.2332 0.3934], Epochs since improvement 0
 40%|███▉      | 199/500 [3:45:19<5:26:50, 65.15s/it]Epoch: 200 done with learning rate 8.01E-03, Train loss: -3.27E+05, Train scatter: [0.1401 0.0455 0.2273 0.396 ]
L1 regularization loss: 4.92E+00, L2 regularization loss: 4.09E+00
Test scatter: [0.1448 0.0444 0.2283 0.3882], Lowest was [0.1313 0.0418 0.2201 0.3802]
Median for last 10 epochs: [0.1795 0.0444 0.2283 0.3907], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 40%|████      | 200/500 [3:46:48<6:01:34, 72.32s/it] 40%|████      | 201/500 [3:47:42<5:33:13, 66.87s/it] 40%|████      | 202/500 [3:49:04<5:54:11, 71.31s/it]Epoch: 202 done with learning rate 7.95E-03, Train loss: -3.81E+05, Train scatter: [0.1419 0.0418 0.2229 0.3872]
L1 regularization loss: 4.90E+00, L2 regularization loss: 4.12E+00
Test scatter: [0.1435 0.0415 0.227  0.3843], Lowest was [0.1313 0.0415 0.2201 0.3802]
Median for last 10 epochs: [0.1448 0.0425 0.227  0.3882], Epochs since improvement 0
 41%|████      | 203/500 [3:49:57<5:26:33, 65.97s/it] 41%|████      | 204/500 [3:51:17<5:46:50, 70.31s/it]Epoch: 204 done with learning rate 7.89E-03, Train loss: -3.85E+05, Train scatter: [0.2789 0.0889 0.3363 0.4707]
L1 regularization loss: 4.90E+00, L2 regularization loss: 4.15E+00
Test scatter: [0.2742 0.088  0.3347 0.4683], Lowest was [0.1313 0.0415 0.2201 0.3802]
Median for last 10 epochs: [0.1448 0.0444 0.2283 0.3882], Epochs since improvement 2
 41%|████      | 205/500 [3:52:12<5:22:34, 65.61s/it] 41%|████      | 206/500 [3:53:34<5:44:43, 70.35s/it]Epoch: 206 done with learning rate 7.83E-03, Train loss: -3.88E+05, Train scatter: [0.1683 0.0564 0.2517 0.4122]
L1 regularization loss: 5.17E+00, L2 regularization loss: 4.34E+00
Test scatter: [0.1699 0.0564 0.2533 0.4103], Lowest was [0.1313 0.0415 0.2201 0.3802]
Median for last 10 epochs: [0.1448 0.0444 0.2283 0.3882], Epochs since improvement 4
 41%|████▏     | 207/500 [3:54:28<5:20:36, 65.65s/it] 42%|████▏     | 208/500 [3:55:48<5:40:00, 69.87s/it]Epoch: 208 done with learning rate 7.77E-03, Train loss: -4.08E+05, Train scatter: [0.1295 0.0472 0.2497 0.3942]
L1 regularization loss: 5.14E+00, L2 regularization loss: 4.36E+00
Test scatter: [0.1297 0.046  0.2521 0.3887], Lowest was [0.1297 0.0415 0.2201 0.3802]
Median for last 10 epochs: [0.1448 0.046  0.2521 0.3887], Epochs since improvement 0
 42%|████▏     | 209/500 [3:56:42<5:15:54, 65.14s/it]Epoch: 210 done with learning rate 7.71E-03, Train loss: -4.08E+05, Train scatter: [0.2358 0.0473 0.2651 0.422 ]
L1 regularization loss: 5.12E+00, L2 regularization loss: 4.38E+00
Test scatter: [0.235  0.0466 0.2662 0.4195], Lowest was [0.1297 0.0415 0.2201 0.3802]
Median for last 10 epochs: [0.1699 0.0466 0.2533 0.4103], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 42%|████▏     | 210/500 [3:58:10<5:47:25, 71.88s/it] 42%|████▏     | 211/500 [3:59:04<5:20:24, 66.52s/it] 42%|████▏     | 212/500 [4:00:24<5:39:12, 70.67s/it]Epoch: 212 done with learning rate 7.65E-03, Train loss: -3.76E+05, Train scatter: [0.129  0.0487 0.2347 0.4045]
L1 regularization loss: 5.15E+00, L2 regularization loss: 4.43E+00
Test scatter: [0.1282 0.0479 0.2358 0.3967], Lowest was [0.1282 0.0415 0.2201 0.3802]
Median for last 10 epochs: [0.1699 0.0479 0.2533 0.4103], Epochs since improvement 0
 43%|████▎     | 213/500 [4:01:19<5:15:08, 65.88s/it] 43%|████▎     | 214/500 [4:02:40<5:35:27, 70.38s/it]Epoch: 214 done with learning rate 7.58E-03, Train loss: -1.98E+05, Train scatter: [0.2894 0.0473 0.2613 0.4378]
L1 regularization loss: 5.65E+00, L2 regularization loss: 4.90E+00
Test scatter: [0.2851 0.0473 0.2634 0.4303], Lowest was [0.1282 0.0415 0.2201 0.3802]
Median for last 10 epochs: [0.1699 0.0473 0.2533 0.4103], Epochs since improvement 2
 43%|████▎     | 215/500 [4:03:33<5:10:06, 65.29s/it] 43%|████▎     | 216/500 [4:04:54<5:31:01, 69.93s/it]Epoch: 216 done with learning rate 7.52E-03, Train loss: -3.94E+05, Train scatter: [0.1358 0.0451 0.2264 0.4073]
L1 regularization loss: 5.74E+00, L2 regularization loss: 5.07E+00
Test scatter: [0.1353 0.045  0.2284 0.3973], Lowest was [0.1282 0.0415 0.2201 0.3802]
Median for last 10 epochs: [0.1353 0.0466 0.2521 0.3973], Epochs since improvement 4
 43%|████▎     | 217/500 [4:05:48<5:07:20, 65.16s/it] 44%|████▎     | 218/500 [4:07:09<5:29:04, 70.01s/it]Epoch: 218 done with learning rate 7.46E-03, Train loss: -3.85E+05, Train scatter: [0.1376 0.0426 0.228  0.4046]
L1 regularization loss: 5.77E+00, L2 regularization loss: 5.19E+00
Test scatter: [0.1381 0.042  0.2341 0.396 ], Lowest was [0.1282 0.0415 0.2201 0.3802]
Median for last 10 epochs: [0.1381 0.0466 0.2358 0.3973], Epochs since improvement 6
 44%|████▍     | 219/500 [4:08:02<5:04:02, 64.92s/it]Epoch: 220 done with learning rate 7.39E-03, Train loss: -3.90E+05, Train scatter: [0.153  0.0496 0.2312 0.4162]
L1 regularization loss: 5.80E+00, L2 regularization loss: 5.27E+00
Test scatter: [0.1539 0.0495 0.2361 0.4132], Lowest was [0.1282 0.0415 0.2201 0.3802]
Median for last 10 epochs: [0.1381 0.0473 0.2358 0.3973], Epochs since improvement 8
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 44%|████▍     | 220/500 [4:09:31<5:37:01, 72.22s/it] 44%|████▍     | 221/500 [4:10:25<5:10:02, 66.68s/it] 44%|████▍     | 222/500 [4:11:47<5:29:26, 71.10s/it]Epoch: 222 done with learning rate 7.33E-03, Train loss: -3.87E+05, Train scatter: [0.3496 0.0425 0.2225 0.4105]
L1 regularization loss: 5.91E+00, L2 regularization loss: 5.40E+00
Test scatter: [0.3399 0.0419 0.2254 0.4035], Lowest was [0.1282 0.0415 0.2201 0.3802]
Median for last 10 epochs: [0.1539 0.045  0.2341 0.4035], Epochs since improvement 10
 45%|████▍     | 223/500 [4:12:40<5:04:14, 65.90s/it] 45%|████▍     | 224/500 [4:14:03<5:25:34, 70.78s/it]Epoch: 224 done with learning rate 7.26E-03, Train loss: -4.18E+05, Train scatter: [0.1687 0.0417 0.2217 0.4035]
L1 regularization loss: 5.91E+00, L2 regularization loss: 5.46E+00
Test scatter: [0.1682 0.0413 0.2259 0.3936], Lowest was [0.1282 0.0413 0.2201 0.3802]
Median for last 10 epochs: [0.1539 0.042  0.2284 0.3973], Epochs since improvement 0
 45%|████▌     | 225/500 [4:14:56<5:01:14, 65.73s/it] 45%|████▌     | 226/500 [4:16:18<5:21:25, 70.39s/it]Epoch: 226 done with learning rate 7.20E-03, Train loss: -3.83E+05, Train scatter: [0.3467 0.0438 0.2369 0.4188]
L1 regularization loss: 5.90E+00, L2 regularization loss: 5.46E+00
Test scatter: [0.3365 0.0429 0.2387 0.4097], Lowest was [0.1282 0.0413 0.2201 0.3802]
Median for last 10 epochs: [0.1682 0.042  0.2341 0.4035], Epochs since improvement 2
 45%|████▌     | 227/500 [4:17:12<4:58:48, 65.67s/it] 46%|████▌     | 228/500 [4:18:34<5:19:37, 70.51s/it]Epoch: 228 done with learning rate 7.13E-03, Train loss: -4.19E+05, Train scatter: [0.1395 0.0498 0.2653 0.4271]
L1 regularization loss: 5.90E+00, L2 regularization loss: 5.48E+00
Test scatter: [0.1396 0.049  0.2671 0.4222], Lowest was [0.1282 0.0413 0.2201 0.3802]
Median for last 10 epochs: [0.1682 0.0429 0.2361 0.4097], Epochs since improvement 4
 46%|████▌     | 229/500 [4:19:28<4:55:49, 65.50s/it]Epoch: 230 done with learning rate 7.06E-03, Train loss: -4.15E+05, Train scatter: [0.3526 0.0413 0.2188 0.4007]
L1 regularization loss: 5.90E+00, L2 regularization loss: 5.50E+00
Test scatter: [0.3419 0.0405 0.2215 0.3954], Lowest was [0.1282 0.0405 0.2201 0.3802]
Median for last 10 epochs: [0.3365 0.0419 0.2259 0.4035], Epochs since improvement 0
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 46%|████▌     | 230/500 [4:20:55<5:24:12, 72.05s/it] 46%|████▌     | 231/500 [4:21:50<4:59:45, 66.86s/it] 46%|████▋     | 232/500 [4:23:12<5:18:18, 71.26s/it]Epoch: 232 done with learning rate 6.99E-03, Train loss: -4.17E+05, Train scatter: [0.27   0.0522 0.2944 0.4378]
L1 regularization loss: 5.93E+00, L2 regularization loss: 5.53E+00
Test scatter: [0.2638 0.0521 0.2927 0.4341], Lowest was [0.1282 0.0405 0.2201 0.3802]
Median for last 10 epochs: [0.2638 0.0429 0.2387 0.4097], Epochs since improvement 2
 47%|████▋     | 233/500 [4:24:05<4:52:46, 65.79s/it] 47%|████▋     | 234/500 [4:25:26<5:12:34, 70.50s/it]Epoch: 234 done with learning rate 6.93E-03, Train loss: -4.35E+05, Train scatter: [0.1332 0.0514 0.2242 0.4071]
L1 regularization loss: 5.93E+00, L2 regularization loss: 5.56E+00
Test scatter: [0.135  0.0499 0.227  0.3975], Lowest was [0.1282 0.0405 0.2201 0.3802]
Median for last 10 epochs: [0.2638 0.049  0.2387 0.4097], Epochs since improvement 4
 47%|████▋     | 235/500 [4:26:20<4:49:36, 65.57s/it] 47%|████▋     | 236/500 [4:27:41<5:09:02, 70.24s/it]Epoch: 236 done with learning rate 6.86E-03, Train loss: -3.79E+05, Train scatter: [0.2195 0.0484 0.2319 0.4263]
L1 regularization loss: 6.02E+00, L2 regularization loss: 5.63E+00
Test scatter: [0.2211 0.0478 0.236  0.415 ], Lowest was [0.1282 0.0405 0.2201 0.3802]
Median for last 10 epochs: [0.2211 0.049  0.236  0.415 ], Epochs since improvement 6
 47%|████▋     | 237/500 [4:28:34<4:45:19, 65.09s/it] 48%|████▊     | 238/500 [4:29:56<5:05:39, 70.00s/it]Epoch: 238 done with learning rate 6.79E-03, Train loss: -2.51E+05, Train scatter: [0.3675 0.0505 0.2604 0.4587]
L1 regularization loss: 6.28E+00, L2 regularization loss: 5.85E+00
Test scatter: [0.3545 0.0493 0.2623 0.4485], Lowest was [0.1282 0.0405 0.2201 0.3802]
Median for last 10 epochs: [0.2638 0.0493 0.236  0.415 ], Epochs since improvement 8
 48%|████▊     | 239/500 [4:30:51<4:44:33, 65.41s/it]Epoch: 240 done with learning rate 6.72E-03, Train loss: -4.08E+05, Train scatter: [0.1603 0.0503 0.264  0.4373]
L1 regularization loss: 6.35E+00, L2 regularization loss: 5.93E+00
Test scatter: [0.1579 0.0493 0.2663 0.4318], Lowest was [0.1282 0.0405 0.2201 0.3802]
Median for last 10 epochs: [0.2211 0.0493 0.2623 0.4318], Epochs since improvement 10
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 48%|████▊     | 240/500 [4:32:17<5:11:12, 71.82s/it] 48%|████▊     | 241/500 [4:33:10<4:45:49, 66.21s/it] 48%|████▊     | 242/500 [4:34:31<5:03:43, 70.63s/it]Epoch: 242 done with learning rate 6.65E-03, Train loss: -4.23E+05, Train scatter: [0.2051 0.0465 0.2384 0.44  ]
L1 regularization loss: 6.37E+00, L2 regularization loss: 5.98E+00
Test scatter: [0.2051 0.0456 0.24   0.4312], Lowest was [0.1282 0.0405 0.2201 0.3802]
Median for last 10 epochs: [0.2051 0.0493 0.24   0.4312], Epochs since improvement 12
 49%|████▊     | 243/500 [4:35:24<4:39:51, 65.34s/it] 49%|████▉     | 244/500 [4:36:45<4:58:22, 69.93s/it]Epoch: 244 done with learning rate 6.58E-03, Train loss: -4.15E+05, Train scatter: [0.3803 0.0446 0.2241 0.4041]
L1 regularization loss: 6.45E+00, L2 regularization loss: 6.06E+00
Test scatter: [0.3686 0.0435 0.2259 0.3925], Lowest was [0.1282 0.0405 0.2201 0.3802]
Median for last 10 epochs: [0.2211 0.0478 0.24   0.4312], Epochs since improvement 14
 49%|████▉     | 245/500 [4:37:39<4:36:53, 65.15s/it] 49%|████▉     | 246/500 [4:38:59<4:54:29, 69.57s/it]Epoch: 246 done with learning rate 6.51E-03, Train loss: -4.27E+05, Train scatter: [0.3382 0.0423 0.2162 0.3976]
L1 regularization loss: 6.44E+00, L2 regularization loss: 6.08E+00
Test scatter: [0.3284 0.0419 0.2206 0.3904], Lowest was [0.1282 0.0405 0.2201 0.3802]
Median for last 10 epochs: [0.3284 0.0456 0.24   0.4312], Epochs since improvement 16
 49%|████▉     | 247/500 [4:39:53<4:33:33, 64.88s/it] 50%|████▉     | 248/500 [4:41:14<4:53:13, 69.82s/it]Epoch: 248 done with learning rate 6.44E-03, Train loss: -4.08E+05, Train scatter: [0.13   0.0407 0.2222 0.3982]
L1 regularization loss: 6.44E+00, L2 regularization loss: 6.10E+00
Test scatter: [0.1284 0.0403 0.2258 0.3912], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.2051 0.0435 0.2259 0.3925], Epochs since improvement 0
 50%|████▉     | 249/500 [4:42:09<4:33:00, 65.26s/it]Epoch: 250 done with learning rate 6.37E-03, Train loss: -4.41E+05, Train scatter: [0.1274 0.0415 0.2182 0.4026]
L1 regularization loss: 6.47E+00, L2 regularization loss: 6.12E+00
Test scatter: [0.1294 0.0414 0.2223 0.3968], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.2051 0.0419 0.2258 0.3925], Epochs since improvement 2
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 50%|█████     | 250/500 [4:43:36<4:59:45, 71.94s/it] 50%|█████     | 251/500 [4:44:31<4:36:48, 66.70s/it] 50%|█████     | 252/500 [4:45:51<4:52:38, 70.80s/it]Epoch: 252 done with learning rate 6.30E-03, Train loss: -4.44E+05, Train scatter: [0.1266 0.0432 0.2238 0.3971]
L1 regularization loss: 6.47E+00, L2 regularization loss: 6.13E+00
Test scatter: [0.1283 0.0427 0.2262 0.3922], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.1294 0.0419 0.2258 0.3922], Epochs since improvement 4
 51%|█████     | 253/500 [4:46:45<4:30:15, 65.65s/it] 51%|█████     | 254/500 [4:48:05<4:47:24, 70.10s/it]Epoch: 254 done with learning rate 6.23E-03, Train loss: -4.48E+05, Train scatter: [0.2228 0.0424 0.2172 0.4117]
L1 regularization loss: 6.47E+00, L2 regularization loss: 6.14E+00
Test scatter: [0.215  0.0415 0.2201 0.4031], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.1294 0.0415 0.2223 0.3922], Epochs since improvement 6
 51%|█████     | 255/500 [4:48:59<4:25:40, 65.06s/it] 51%|█████     | 256/500 [4:50:19<4:43:21, 69.68s/it]Epoch: 256 done with learning rate 6.15E-03, Train loss: -3.91E+04, Train scatter: [0.9349 0.1728 0.544  0.9956]
L1 regularization loss: 7.06E+00, L2 regularization loss: 6.42E+00
Test scatter: [0.9194 0.169  0.5355 0.9853], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.1294 0.0415 0.2258 0.3968], Epochs since improvement 8
 51%|█████▏    | 257/500 [4:51:13<4:23:19, 65.02s/it] 52%|█████▏    | 258/500 [4:52:34<4:41:17, 69.74s/it]Epoch: 258 done with learning rate 6.08E-03, Train loss: -6.62E+04, Train scatter: [0.5475 0.1118 0.5226 0.6876]
L1 regularization loss: 7.07E+00, L2 regularization loss: 6.46E+00
Test scatter: [0.5352 0.1086 0.5149 0.6799], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.215  0.0427 0.2262 0.4031], Epochs since improvement 10
 52%|█████▏    | 259/500 [4:53:28<4:21:11, 65.03s/it]Epoch: 260 done with learning rate 6.01E-03, Train loss: -2.23E+05, Train scatter: [0.3906 0.0778 0.4532 0.5455]
L1 regularization loss: 7.27E+00, L2 regularization loss: 6.58E+00
Test scatter: [0.3816 0.0778 0.4446 0.536 ], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.3816 0.0778 0.4446 0.536 ], Epochs since improvement 12
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 52%|█████▏    | 260/500 [4:54:55<4:46:12, 71.55s/it] 52%|█████▏    | 261/500 [4:55:49<4:24:31, 66.41s/it] 52%|█████▏    | 262/500 [4:57:11<4:41:34, 70.99s/it]Epoch: 262 done with learning rate 5.94E-03, Train loss: -2.87E+05, Train scatter: [0.1996 0.0589 0.3322 0.4956]
L1 regularization loss: 7.33E+00, L2 regularization loss: 6.65E+00
Test scatter: [0.1945 0.0592 0.3345 0.4928], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.3816 0.0778 0.4446 0.536 ], Epochs since improvement 14
 53%|█████▎    | 263/500 [4:58:05<4:20:27, 65.94s/it] 53%|█████▎    | 264/500 [4:59:27<4:38:28, 70.80s/it]Epoch: 264 done with learning rate 5.86E-03, Train loss: -3.33E+05, Train scatter: [0.2145 0.05   0.2805 0.4767]
L1 regularization loss: 7.39E+00, L2 regularization loss: 6.73E+00
Test scatter: [0.2164 0.0494 0.2809 0.4705], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.3816 0.0778 0.4446 0.536 ], Epochs since improvement 16
 53%|█████▎    | 265/500 [5:00:22<4:18:37, 66.03s/it] 53%|█████▎    | 266/500 [5:01:43<4:35:01, 70.52s/it]Epoch: 266 done with learning rate 5.79E-03, Train loss: -3.48E+05, Train scatter: [0.1778 0.0525 0.2871 0.4785]
L1 regularization loss: 7.42E+00, L2 regularization loss: 6.77E+00
Test scatter: [0.182  0.0522 0.2885 0.4761], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.2164 0.0592 0.3345 0.4928], Epochs since improvement 18
 53%|█████▎    | 267/500 [5:02:38<4:15:23, 65.76s/it] 54%|█████▎    | 268/500 [5:03:58<4:31:37, 70.25s/it]Epoch: 268 done with learning rate 5.72E-03, Train loss: -7.60E+04, Train scatter: [0.6024 0.1361 0.521  0.7785]
L1 regularization loss: 7.85E+00, L2 regularization loss: 7.01E+00
Test scatter: [0.5703 0.1296 0.5112 0.7658], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.2164 0.0592 0.3345 0.4928], Epochs since improvement 20
 54%|█████▍    | 269/500 [5:04:53<4:11:46, 65.40s/it]Epoch: 270 done with learning rate 5.64E-03, Train loss: -1.63E+05, Train scatter: [0.425  0.0915 0.4273 0.6082]
L1 regularization loss: 8.03E+00, L2 regularization loss: 7.18E+00
Test scatter: [0.4194 0.0899 0.4222 0.5963], Lowest was [0.1282 0.0403 0.2201 0.3802]
Median for last 10 epochs: [0.2164 0.0592 0.3345 0.4928], Epochs since improvement 22
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
 54%|█████▍    | 269/500 [5:06:20<4:23:03, 68.33s/it]
Exited after 270 epochs due to early stopping
18380.02 seconds spent training, 36.760 seconds per epoch. Processed 1894 trees per second
/home/cj1223/work/GraphMerge/dev/eval_plot.py:26: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax =plt.subplots(1,2, figsize=(12,6))
[0.41940707 0.08990896 0.4222059  0.59629786]
{'epoch_exit': 269, 'scatter_m_star': 0.41940707, 'lowest_m_star': 0.12820938, 'last20_m_star': 0.29897943, 'last10_m_star': 0.21637712, 'scatter_v_disk': 0.08990896, 'lowest_v_disk': 0.0403399, 'last20_v_disk': 0.06847837, 'last10_v_disk': 0.059204224, 'scatter_m_cold': 0.4222059, 'lowest_m_cold': 0.2201374, 'last20_m_cold': 0.3783498, 'last10_m_cold': 0.33448136, 'scatter_sfr_100': 0.59629786, 'lowest_sfr_100': 0.3801781, 'last20_sfr_100': 0.51440597, 'last10_sfr_100': 0.49281174}
Finished 1/1
Exited training after None epochs
Experiment 6 done: 6 / 6
